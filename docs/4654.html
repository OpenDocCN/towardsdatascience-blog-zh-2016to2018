<html>
<head>
<title>Convolutional Neural Network — A Bird’s eye view with an implementation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络——实施的鸟瞰图</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convolutional-neural-network-a-birds-eye-view-with-an-implementation-1bff505dd3d9?source=collection_archive---------12-----------------------#2018-08-28">https://towardsdatascience.com/convolutional-neural-network-a-birds-eye-view-with-an-implementation-1bff505dd3d9?source=collection_archive---------12-----------------------#2018-08-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="01cf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">这篇文章正在被移到我的</em> <a class="ae km" href="https://vishalramesh.substack.com/" rel="noopener ugc nofollow" target="_blank"> <em class="kl">子栈发布</em> </a> <em class="kl">。这里</em>  <em class="kl">可以免费阅读文章</em> <a class="ae km" href="https://vishalramesh.substack.com/p/convolutional-neural-network-a-birds-eye-view-with-an-implementation-1bff505dd3d9?s=w" rel="noopener ugc nofollow" target="_blank"> <em class="kl">。这篇文章将于 2022 年 5 月 18 日被删除。</em></a></p><p id="6827" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个内核旨在给出一个卷积神经网络(CNN)的简单理解。这将按以下顺序实现:</p><ul class=""><li id="5c2f" class="kn ko iq jp b jq jr ju jv jy kp kc kq kg kr kk ks kt ku kv bi translated">理解卷积运算</li><li id="e0be" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">理解神经网络</li><li id="97fa" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">数据预处理</li><li id="0712" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">了解使用的 CNN</li><li id="633f" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">了解优化器</li><li id="e6be" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">理解<code class="fe lb lc ld le b">ImageDataGenerator</code></li><li id="4956" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">做出预测并计算精确度</li><li id="2a9b" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">看到神经网络的运行</li></ul><h1 id="c28d" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">什么是卷积？</h1><blockquote class="md me mf"><p id="fd85" class="jn jo kl jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated"><em class="iq">在数学(尤其是泛函分析)中，卷积是对两个函数(f 和 g)进行数学运算，以产生第三个函数，该函数表示一个函数的形状如何被另一个函数修改。</em></p><p id="dfb9" class="jn jo kl jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated">(来源:<a class="ae km" href="https://en.wikipedia.org/wiki/Convolution" rel="noopener ugc nofollow" target="_blank">维基百科</a>)</p></blockquote><p id="fb5d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种运算应用于多个领域，如概率、统计、计算机视觉、自然语言处理、图像和信号处理、工程和微分方程。</p><p id="15ea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该操作在数学上表示为</p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/9471ff84c27cb32730f6d2038aa81815.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*cKXhBHksEY7JgAvRfUINkw.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">The Convolution operation</figcaption></figure><p id="9593" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(图片来源:<a class="ae km" href="https://en.wikipedia.org/wiki/Convolution#Definition" rel="noopener ugc nofollow" target="_blank">维基百科</a>)</p><p id="df1c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">检查此<a class="ae km" href="https://github.com/vdumoulin/conv_arithmetic" rel="noopener ugc nofollow" target="_blank">链接</a>以直观了解卷积运算</p><h1 id="bc2a" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">什么是人工神经网络？</h1><blockquote class="md me mf"><p id="de54" class="jn jo kl jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated">人工神经网络(ANN)或连接主义系统是由构成动物大脑的生物神经网络模糊启发的计算系统。这种系统通过考虑例子来“学习”执行任务，通常没有用任何特定于任务的规则来编程。</p><p id="74ef" class="jn jo kl jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated">(来源:<a class="ae km" href="https://en.wikipedia.org/wiki/Artificial_neural_network" rel="noopener ugc nofollow" target="_blank">维基百科</a>)</p></blockquote><p id="a0e9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">人工神经网络是一个被称为人工神经元的更小的处理单元的集合，它与生物神经元大致相似。</p><p id="40bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">生物神经回路</strong></p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/beed7c84847f1b30c5023fdd78d150c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*dB9djDS9VKu7aDNS2mInHQ.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">A Biological Neural Circuit</figcaption></figure><p id="0d06" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">(图片来源:</em> <a class="ae km" href="https://en.wikipedia.org/wiki/Neural_circuit" rel="noopener ugc nofollow" target="_blank"> <em class="kl">维基百科</em> </a> <em class="kl"> ) </em></p><p id="52ca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">互连电路的集合构成一个网络</p><p id="a65a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">人工神经网络</strong></p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/be82b2341185f626d2d9b4ea4154218c.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*6E0xMPmMuiaTWOyjL5IeNw.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">Artificial Neural Network</figcaption></figure><p id="4d42" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">(图片来源:</em> <a class="ae km" href="https://en.wikipedia.org/wiki/Artificial_neural_network" rel="noopener ugc nofollow" target="_blank"> <em class="kl">维基百科</em> </a> <em class="kl"> ) </em></p><p id="e3ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们从实现开始</p><h1 id="916f" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">导入必要的库</h1><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="cd66" class="nb lg iq le b gy nc nd l ne nf">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/><br/>import tflearn.data_utils as du<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D<br/>from keras.optimizers import RMSprop<br/>from keras.preprocessing.image import ImageDataGenerator<br/>from sklearn.metrics import confusion_matrix</span></pre><h1 id="e6da" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">加载数据集</h1><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="2907" class="nb lg iq le b gy nc nd l ne nf">train_data = pd.read_csv('../input/csvTrainImages 13440x1024.csv', header = None)<br/>train_label = pd.read_csv('../input/csvTrainLabel 13440x1.csv', header = None)<br/>test_data = pd.read_csv('../input/csvTestImages 3360x1024.csv', header = None)<br/>test_label = pd.read_csv('../input/csvTestLabel 3360x1.csv', header = None)</span></pre><h1 id="81fa" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">数据集</h1><p id="5cda" class="pw-post-body-paragraph jn jo iq jp b jq ng js jt ju nh jw jx jy ni ka kb kc nj ke kf kg nk ki kj kk ij bi translated">这里使用的数据集是<a class="ae km" href="https://www.kaggle.com/mloey1/ahcd1" rel="noopener ugc nofollow" target="_blank">阿拉伯手写字符数据集</a>。</p><p id="a28c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">trainImages.csv 有 1024 列和 13440 行。每一列代表图像中的一个像素，每一行代表一个单独的灰度图像。每个像素的值在 0 -255 之间变化。</p><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="135e" class="nb lg iq le b gy nc nd l ne nf">train_data = train_data.iloc[:,:].values.astype('float32')<br/>train_label = train_label.iloc[:,:].values.astype('int32')-1<br/>test_data = test_data.iloc[:,:].values.astype('float32')<br/>test_label = test_label.iloc[:,:].values.astype('int32')-1</span></pre><h1 id="0e28" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">可视化数据集</h1><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="735b" class="nb lg iq le b gy nc nd l ne nf">def row_calculator(number_of_images, number_of_columns):<br/>    if number_of_images % number_of_columns != 0:<br/>        return (number_of_images / number_of_columns)+1<br/>    else:<br/>        return (number_of_images / number_of_columns)</span><span id="ad0b" class="nb lg iq le b gy nl nd l ne nf">def display_image(x, img_size, number_of_images):<br/>    plt.figure(figsize = (8, 7))<br/>    if x.shape[0] &gt; 0:<br/>        n_samples = x.shape[0]<br/>        x = x.reshape(n_samples, img_size, img_size)<br/>        number_of_rows = row_calculator(number_of_images, 4)<br/>        for i in range(number_of_images):<br/>            plt.subplot(number_of_rows, 4, i+1)<br/>            plt.imshow(x[i])</span></pre><p id="f807" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">训练集</strong></p><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="8648" class="nb lg iq le b gy nc nd l ne nf">display_image(train_data, 32, 16)</span></pre><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/4e14111ad2ac92e3af258a8e3ed2cb69.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*CYMGupG4462rbDRJx67SDQ.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">The training dataset</figcaption></figure><p id="22e6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">测试设置</strong></p><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="9e15" class="nb lg iq le b gy nc nd l ne nf">display_image(test_data, 32, 16)</span></pre><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/dd6308181ad8fac994b94bce43d6765b.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*eDqTdTuN-KIRmyY5JtiaWg.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">The test data</figcaption></figure><h1 id="8925" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">数据预处理</h1><p id="f222" class="pw-post-body-paragraph jn jo iq jp b jq ng js jt ju nh jw jx jy ni ka kb kc nj ke kf kg nk ki kj kk ij bi translated"><strong class="jp ir">编码分类变量</strong></p><p id="6ef4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kl">什么是分类变量？</em>T19】</strong></p><blockquote class="md me mf"><p id="9981" class="jn jo kl jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated"><em class="iq">在统计学中，分类变量是一个变量，它可以取有限的、通常是固定数量的可能值中的一个，根据一些定性属性将每个个体或其他观察单位分配到特定的组或名义类别。</em></p><p id="cd1b" class="jn jo kl jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated">(<em class="iq">来源:</em> <a class="ae km" href="https://en.wikipedia.org/wiki/Categorical_variable" rel="noopener ugc nofollow" target="_blank"> <em class="iq">维基百科</em> </a>)</p></blockquote><p id="903b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">简单地说，分类变量的值代表一个类别或类。</p><h2 id="0953" class="nb lg iq bd lh nn no dn ll np nq dp lp jy nr ns lt kc nt nu lx kg nv nw mb nx bi translated">为什么我们需要对分类变量进行编码？</h2><p id="0fa0" class="pw-post-body-paragraph jn jo iq jp b jq ng js jt ju nh jw jx jy ni ka kb kc nj ke kf kg nk ki kj kk ij bi translated">对代表一个类别的数字执行运算是没有意义的。因此，需要进行分类编码。</p><p id="8d18" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">查看 stackoverflow 上的这个链接，通过一个例子来理解。</p><p id="6c7c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">阿拉伯字母表中有 28 个字母。所以，有 28 节课。</p><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="54ec" class="nb lg iq le b gy nc nd l ne nf">train_label = du.to_categorical(train_label,28)</span></pre><h1 id="f203" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">正常化</h1><h2 id="d530" class="nb lg iq bd lh nn no dn ll np nq dp lp jy nr ns lt kc nt nu lx kg nv nw mb nx bi translated">什么是正常化？</h2><p id="1405" class="pw-post-body-paragraph jn jo iq jp b jq ng js jt ju nh jw jx jy ni ka kb kc nj ke kf kg nk ki kj kk ij bi translated">进行标准化是为了将整个数据带入一个明确定义的范围内，最好在 0 和 1 之间</p><blockquote class="md me mf"><p id="ce0b" class="jn jo kl jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated"><em class="iq">在神经网络中，不仅要对数据进行标准化，还要对其进行缩放，这是一个好主意。这是为了在误差表面更快地接近全局最小值。</em></p><p id="f10e" class="jn jo kl jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated"><em class="iq">(来源:</em> <a class="ae km" href="https://stackoverflow.com/questions/4674623/why-do-we-have-to-normalize-the-input-for-an-artificial-neural-network" rel="noopener ugc nofollow" target="_blank"> <em class="iq">堆栈溢出</em> </a> <em class="iq"> ) </em></p></blockquote><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="07e7" class="nb lg iq le b gy nc nd l ne nf">train_data = train_data/255<br/>test_data = test_data/255</span><span id="6659" class="nb lg iq le b gy nl nd l ne nf">train_data = train_data.reshape([-1, 32, 32, 1])<br/>test_data = test_data.reshape([-1, 32, 32, 1])</span></pre><p id="8fbd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">进行整形以使数据代表 2D 图像</p><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="6368" class="nb lg iq le b gy nc nd l ne nf">train_data, mean1 = du.featurewise_zero_center(train_data)<br/>test_data, mean2 = du.featurewise_zero_center(test_data)</span></pre><p id="bc94" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基于特征的零中心化是用指定的平均值对每个样本进行零中心化。如果未指定，则评估所有样本的平均值。</p><h1 id="76a0" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">构建 CNN</h1><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="37e0" class="nb lg iq le b gy nc nd l ne nf">recognizer = Sequential()</span><span id="5bae" class="nb lg iq le b gy nl nd l ne nf">recognizer.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (32,32,1)))<br/>recognizer.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))<br/>recognizer.add(MaxPool2D(pool_size=(2,2)))<br/>recognizer.add(Dropout(0.25))<br/></span><span id="e9a9" class="nb lg iq le b gy nl nd l ne nf">recognizer.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))<br/>recognizer.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))<br/>recognizer.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))<br/>recognizer.add(Dropout(0.25))<br/></span><span id="d68d" class="nb lg iq le b gy nl nd l ne nf">recognizer.add(Flatten())<br/>recognizer.add(Dense(units = 256, input_dim = 1024, activation = 'relu'))<br/>recognizer.add(Dense(units = 256, activation = "relu"))<br/>recognizer.add(Dropout(0.5))<br/>recognizer.add(Dense(28, activation = "softmax"))</span></pre><h2 id="86da" class="nb lg iq bd lh nn no dn ll np nq dp lp jy nr ns lt kc nt nu lx kg nv nw mb nx bi translated">什么是最大池？</h2><p id="ecd0" class="pw-post-body-paragraph jn jo iq jp b jq ng js jt ju nh jw jx jy ni ka kb kc nj ke kf kg nk ki kj kk ij bi translated">汇集意味着组合一组数据。组合数据的过程遵循一些规则。</p><blockquote class="md me mf"><p id="e606" class="jn jo kl jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated"><em class="iq">根据定义，最大池取定义网格的最大值。</em></p><p id="425a" class="jn jo kl jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated">(<em class="iq">来源:</em><a class="ae km" href="https://machinelearningonline.blog/2017/06/29/max-pooling/" rel="noopener ugc nofollow" target="_blank"><em class="iq">machine learning online . blog</em></a>)</p></blockquote><p id="6589" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最大池用于减少维度。也可以避免过度拟合。查看<a class="ae km" href="https://machinelearningonline.blog/2017/06/29/max-pooling/" rel="noopener ugc nofollow" target="_blank">这篇</a>博客，更好地理解最大池。</p><h2 id="affe" class="nb lg iq bd lh nn no dn ll np nq dp lp jy nr ns lt kc nt nu lx kg nv nw mb nx bi translated">什么是辍学？</h2><blockquote class="md me mf"><p id="e066" class="jn jo kl jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated"><em class="iq"> Dropout 是一种正则化技术，通过防止对训练数据的复杂协同适应来减少神经网络中的过拟合。这是用神经网络进行模型平均的一种非常有效的方法。术语“丢失”是指在神经网络中丢失单元(隐藏的和可见的)。</em></p><p id="281a" class="jn jo kl jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated">(<em class="iq">来源:</em> <a class="ae km" href="https://en.wikipedia.org/wiki/Dropout_(neural_networks" rel="noopener ugc nofollow" target="_blank"> <em class="iq">维基百科</em> </a> <em class="iq"> ) </em>)</p></blockquote><h2 id="11b5" class="nb lg iq bd lh nn no dn ll np nq dp lp jy nr ns lt kc nt nu lx kg nv nw mb nx bi translated">什么是扁平化？</h2><p id="c45e" class="pw-post-body-paragraph jn jo iq jp b jq ng js jt ju nh jw jx jy ni ka kb kc nj ke kf kg nk ki kj kk ij bi translated">进行展平是为了将多维数据转换成 1D 特征向量，以供作为密集层的下一层使用</p><h2 id="2295" class="nb lg iq bd lh nn no dn ll np nq dp lp jy nr ns lt kc nt nu lx kg nv nw mb nx bi translated">什么是密集层？</h2><p id="01bf" class="pw-post-body-paragraph jn jo iq jp b jq ng js jt ju nh jw jx jy ni ka kb kc nj ke kf kg nk ki kj kk ij bi translated">密集层只是一层人工神经网络</p><h1 id="3c40" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">CNN 的优化器</h1><h2 id="4e79" class="nb lg iq bd lh nn no dn ll np nq dp lp jy nr ns lt kc nt nu lx kg nv nw mb nx bi translated">什么是优化器？</h2><blockquote class="md me mf"><p id="bfe4" class="jn jo kl jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated"><em class="iq">优化算法帮助我们最小化(或最大化)目标函数(误差函数的另一个名称)E(x ),它是一个简单的数学函数，依赖于模型的内部可学习参数，这些参数用于根据模型中使用的一组预测值(X)计算目标值(Y)。例如，我们将神经网络的权重(W)和偏差(b)值称为其内部可学习参数，用于计算输出值，并在最佳解决方案的方向上学习和更新，即通过网络的训练过程最小化损失，并且在神经网络模型的训练过程中也起主要作用。</em></p><p id="cb7a" class="jn jo kl jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated"><em class="iq">(来源:</em> <a class="ae km" rel="noopener" target="_blank" href="/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f"> <em class="iq">走向数据科学</em> </a>)</p></blockquote><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="a0bf" class="nb lg iq le b gy nc nd l ne nf">optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)</span></pre><p id="fb64" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里使用的优化器是一个 RMSprop。点击<a class="ae km" href="https://engmrk.com/rmsprop/" rel="noopener ugc nofollow" target="_blank">此处</a>了解更多关于 RMSprop 的信息</p><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="48cc" class="nb lg iq le b gy nc nd l ne nf">recognizer.compile(optimizer = optimizer , loss = "categorical_crossentropy", metrics=["accuracy"])</span></pre><h1 id="59e6" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">什么是<code class="fe lb lc ld le b">ImageDataGenerator</code>？</h1><p id="29bb" class="pw-post-body-paragraph jn jo iq jp b jq ng js jt ju nh jw jx jy ni ka kb kc nj ke kf kg nk ki kj kk ij bi translated">图像数据生成器用于生成具有实时增强的批量张量图像数据。这些数据是成批循环的。</p><p id="a41f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它用于批量加载图像。</p><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="51e9" class="nb lg iq le b gy nc nd l ne nf">datagen = ImageDataGenerator(<br/>        featurewise_center=False, <br/>        samplewise_center=False,  <br/>        featurewise_std_normalization=False,<br/>        samplewise_std_normalization=False,<br/>        zca_whitening=False,<br/>        rotation_range=10,<br/>        zoom_range = 0.1,  <br/>        width_shift_range=0.1, <br/>        height_shift_range=0.1,<br/>        horizontal_flip=False,<br/>        vertical_flip=False)</span><span id="05eb" class="nb lg iq le b gy nl nd l ne nf">datagen.fit(train_data)</span></pre><h1 id="7bc2" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">用 CNN 拟合训练数据</h1><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="f1af" class="nb lg iq le b gy nc nd l ne nf">recognizer.fit_generator(datagen.flow(train_data,train_label, batch_size=100), epochs = 30, verbose = 2, steps_per_epoch=train_data.shape[0] // 100)</span></pre><h1 id="eef0" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">做出预测</h1><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="23a3" class="nb lg iq le b gy nc nd l ne nf">predictions = recognizer.predict(test_data)<br/>predictions = np.argmax(predictions,axis = 1)</span></pre><h1 id="d9e0" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">生成混淆矩阵</h1><h2 id="431d" class="nb lg iq bd lh nn no dn ll np nq dp lp jy nr ns lt kc nt nu lx kg nv nw mb nx bi translated">什么是混淆矩阵？</h2><blockquote class="md me mf"><p id="f9cb" class="jn jo kl jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated">混淆矩阵是一种总结分类算法性能的技术。如果每个类中的观测值数量不相等，或者数据集中有两个以上的类，那么分类精度本身就可能会产生误导。计算混淆矩阵可以让您更好地了解您的分类模型是正确的，以及它正在犯什么类型的错误。</p><p id="d374" class="jn jo kl jp b jq jr js jt ju jv jw jx mg jz ka kb mh kd ke kf mi kh ki kj kk ij bi translated"><a class="ae km" href="https://machinelearningmastery.com/confusion-matrix-machine-learning/" rel="noopener ugc nofollow" target="_blank">来源</a></p></blockquote><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="a98d" class="nb lg iq le b gy nc nd l ne nf">cm = confusion_matrix(test_label, predictions)</span></pre><h1 id="e635" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">计算精确度</h1><pre class="mk ml mm mn gt mx le my mz aw na bi"><span id="6084" class="nb lg iq le b gy nc nd l ne nf">accuracy = sum(cm[i][i] for i in range(28)) / test_label.shape[0]<br/>print("accuracy = " + str(accuracy))</span></pre><p id="0b58" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">获得了 97%的准确度</p><h1 id="b364" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">观看 CNN 的运作</h1><p id="64bf" class="pw-post-body-paragraph jn jo iq jp b jq ng js jt ju nh jw jx jy ni ka kb kc nj ke kf kg nk ki kj kk ij bi translated">要实时了解 CNN 的工作情况，请点击<a class="ae km" href="http://scs.ryerson.ca/~aharley/vis/conv/flat.html" rel="noopener ugc nofollow" target="_blank">中的</a>链接。它展示了一个 CNN 的工作原理，这个 CNN 被训练来识别手写数字。</p></div></div>    
</body>
</html>