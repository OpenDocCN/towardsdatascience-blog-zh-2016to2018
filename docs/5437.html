<html>
<head>
<title>Mastering The New Generation of Gradient Boosting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">掌握新一代梯度推进技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/https-medium-com-talperetz24-mastering-the-new-generation-of-gradient-boosting-db04062a7ea2?source=collection_archive---------1-----------------------#2018-10-18">https://towardsdatascience.com/https-medium-com-talperetz24-mastering-the-new-generation-of-gradient-boosting-db04062a7ea2?source=collection_archive---------1-----------------------#2018-10-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/046d3aa3895e9d515cacb1f53865954e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2p1GIUUcRSzyyJjSj4x7Iw.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Catboost</figcaption></figure><p id="a657" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">梯度提升决策树</strong>和随机森林是我最喜欢的表格异构数据集的 ML 模型。这些模型是在<a class="ae la" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>比赛中表现最好的，并在行业中广泛使用。</p><p id="031c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> Catboost </strong>，这个街区的新小子，到现在已经有一年多一点的时间了，它已经在威胁<em class="lb"> XGBoost </em>、<em class="lb"> LightGBM </em>和<em class="lb"> H2O </em>。</p><h1 id="5122" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">为什么选择 Catboost？</h1><h2 id="9ff2" class="ma ld iq bd le mb mc dn li md me dp lm kn mf mg lq kr mh mi lu kv mj mk ly ml bi translated">更好的结果</h2><p id="59e0" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">Catboost 在基准测试中取得了最好的结果，这很好，但是我不知道我是否会仅仅为了对数损失改进的一小部分而替换一个工作的生产模型(特别是当进行基准测试的公司对 Catboost 有明显的兴趣时😅).<br/>然而，当你看到<strong class="ke ir">分类特征发挥巨大作用的数据集</strong>时，比如<em class="lb">亚马逊</em>和<em class="lb">互联网</em>数据集，这种改进变得显著且不可否认。</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mr"><img src="../Images/002a53d46f5bc8e73e4a711fd79c1263.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vsg1IUlGtzCoNuGo9XqGwg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">GBDT Algorithms Benchmark</figcaption></figure><h2 id="e995" class="ma ld iq bd le mb mc dn li md me dp lm kn mf mg lq kr mh mi lu kv mj mk ly ml bi translated">更快的预测</h2><p id="1f07" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">虽然训练时间可能比其他 GBDT 实现要长，但根据 Yandex 基准测试，预测时间比其他库快 13-16 倍。</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mw"><img src="../Images/5fa9f0b212e0ed21e624b39d836ed196.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BE8PZe54DMWe6gFdHlYsxg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Left: CPU, Right: GPU</figcaption></figure><h2 id="69b3" class="ma ld iq bd le mb mc dn li md me dp lm kn mf mg lq kr mh mi lu kv mj mk ly ml bi translated">含电池</h2><p id="b945" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">与其他 GBDT 算法相比，Catboost 的默认参数是一个更好的起点。对于想要一个即插即用模型来开始体验树合奏或 Kaggle 比赛的初学者来说，这是一个好消息。<br/>然而，我们必须解决一些非常重要的参数，我们稍后会谈到这些参数。</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/65d3d097ceda2b471b2ffe303afd0422.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*znsWIb1X3Eez5LjNf4mg_g.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">GBDT Algorithms with default parameters Benchmark</figcaption></figure><p id="9b40" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">Catboost 的一些更值得注意的改进是功能交互、对象重要性和快照支持。</p><p id="b224" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">除了分类和回归，Catboost 支持开箱即用的<strong class="ke ir">排名</strong>。</p><h2 id="1fa5" class="ma ld iq bd le mb mc dn li md me dp lm kn mf mg lq kr mh mi lu kv mj mk ly ml bi translated">经过战斗考验</h2><p id="6bae" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">Yandex 严重依赖 Catboost 进行排名、预测和推荐。这种模式每月为 7000 多万用户提供服务。</p><blockquote class="my mz na"><p id="0c10" class="kc kd lb ke b kf kg kh ki kj kk kl km nb ko kp kq nc ks kt ku nd kw kx ky kz ij bi translated">CatBoost 是决策树上<strong class="ke ir">梯度提升的算法。它由 Yandex 的研究人员和工程师开发，是公司内部广泛用于任务排名、预测和提出建议的<a class="ae la" href="https://yandex.com/company/technologies/matrixnet/" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ir"> MatrixNet 算法</strong> </a>的继任者。它是通用的，可以应用于广泛的领域和各种问题。</strong></p></blockquote><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ne"><img src="../Images/e626292ce10ea1a5637bb6dc7d7e0c0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_zP6KFIA76MQOgkslmQFzw.png"/></div></div></figure><h1 id="e9a5" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">该算法</h1><h2 id="6d92" class="ma ld iq bd le mb mc dn li md me dp lm kn mf mg lq kr mh mi lu kv mj mk ly ml bi translated">经典梯度增强</h2><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nf"><img src="../Images/e01d71f7027ec59401ef268a1aaf40c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0QYf5MRTzwtMpWuzDFTKdQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Gradient Boosting on Wikipedia</figcaption></figure><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ng"><img src="../Images/cc7a8328ad558dede3e67e10aadd775a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6dGA56_UXJzuDAlAOd9Otw.png"/></div></div></figure><h1 id="5044" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">Catboost 秘制酱</h1><p id="1a05" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">Catboost 引入了两个关键的算法进步——实现了<strong class="ke ir">有序提升</strong>,这是一种替代经典算法的置换驱动算法，以及一种用于处理分类特征的创新算法<strong class="ke ir">。<br/>这两种技术都使用训练样本的随机排列来对抗<em class="lb">预测偏移</em>，这种偏移是由一种特殊的<em class="lb">目标泄漏</em>引起的，这种泄漏出现在梯度增强算法的所有现有实现中。</strong></p><h1 id="3c04" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">卡特彼勒</strong>电气特征处理</h1><h2 id="0c92" class="ma ld iq bd le mb mc dn li md me dp lm kn mf mg lq kr mh mi lu kv mj mk ly ml bi translated">有序目标统计</h2><p id="7aee" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">大多数 GBDT 算法和 Kaggle 竞争对手已经熟悉了目标统计(或目标均值编码)的使用。<br/>这是一种简单而有效的方法，其中我们用类别条件下的预期目标 y 的估计值对每个分类特征进行编码。<br/>事实证明，不小心应用这种编码(y 在具有相同类别的训练示例上的平均值)会导致目标泄漏。</p><p id="fea3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为了对抗这种<em class="lb">预测转变</em> CatBoost 使用了一种更有效的策略。它依赖于排序原则，并受到在线学习算法的启发，该算法按时间顺序获取训练样本。在这种设置下，每个示例的 TS 值仅依赖于观察到的历史。<br/>为了使这种想法适应标准的离线设置，Catboost 引入了一个人工“时间”——训练示例的随机排列<em class="lb"> σ1 </em>。<br/>然后，对于每个示例，它使用所有可用的“历史”来计算其目标统计。<br/>注意，仅使用一个随机排列，导致前面的例子比后面的例子具有更高的目标统计方差。为此，CatBoost 对梯度增强的不同步骤使用不同的排列。</p><h2 id="3c09" class="ma ld iq bd le mb mc dn li md me dp lm kn mf mg lq kr mh mi lu kv mj mk ly ml bi translated">一个热编码</h2><p id="be52" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">Catboost 对所有具有最多<em class="lb"> one_hot_max_size </em>唯一值的特征使用一键编码。默认值为 2。</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nh"><img src="../Images/b9a3f028557285307b1b5d6f80bffb20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nTMRk-U4KRFra3j8VMFz0A.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Catboost’s Secret Sauce</figcaption></figure><h1 id="2b30" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">有序推进</h1><p id="ce70" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">CatBoost 有两种选择树结构的模式，有序和简单。<strong class="ke ir">普通模式</strong>对应于标准 GBDT 算法与有序目标统计的组合。<br/>在<strong class="ke ir">有序模式</strong>提升中，我们执行训练示例的随机排列- <em class="lb"> σ2，</em>并维护 n 个不同的支持模型- <em class="lb"> M1。。。，Mn </em>，使得仅使用排列中的第一个<em class="lb"> i </em>样本来训练模型<em class="lb"> Mi </em>。<br/>在每一步，为了获得第<em class="lb"> j </em>个样本的残差，我们使用模型<em class="lb">mj1</em>。<br/>遗憾的是，由于需要维护 n 个不同的模型，这种算法在大多数实际任务中并不可行，增加了 n 倍的复杂度和内存需求。Catboost 在梯度推进算法的基础上实现了对该算法的修改，使用了所有要建立的模型共享的一个树结构。</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ni"><img src="../Images/b1cdb56457c6084b8158cb565b7b65a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SgwurdYEN5wMX-o3h6BeXw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Catboost Ordered Boosting and Tree Building</figcaption></figure><p id="b03c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为了避免<em class="lb">预测偏移</em>，Catboost 使用排列使得<em class="lb"> σ1 </em> = <em class="lb"> σ2 </em>。这保证了目标<em class="lb"> yi </em>不用于训练<em class="lb"> Mi </em>，既不用于目标统计计算，也不用于梯度估计。</p><h1 id="f933" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">把手放在某物或者某人身上</h1><p id="24a1" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">对于这一部分，我们将使用<a class="ae la" href="https://www.kaggle.com/c/amazon-employee-access-challenge/data" rel="noopener ugc nofollow" target="_blank"> <em class="lb">亚马逊数据集</em> </a>，因为它很干净，并且非常强调分类特征。</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nj"><img src="../Images/73c0af6d1dc3b537700e8355ed5a7359.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*su6jiARoKMTWk-YmFvZzMg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Dataset in a brief</figcaption></figure><h1 id="8d01" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">调谐 Catboost</h1><h2 id="4f8e" class="ma ld iq bd le mb mc dn li md me dp lm kn mf mg lq kr mh mi lu kv mj mk ly ml bi translated">重要参数</h2><p id="bf89" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated"><code class="fe nk nl nm nn b">cat_features</code> —为了利用 Catboost 对分类特征的预处理，该参数是必需的，如果您自己对分类特征进行编码，并且没有将列索引作为<em class="lb"> cat_features </em>传递，那么您就错过了 Catboost 的精髓<em class="lb">。</em></p><p id="d4c4" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><code class="fe nk nl nm nn b">one_hot_max_size</code> —如前所述，<em class="lb"> </em> Catboost 对所有具有最多<em class="lb"> one_hot_max_size </em>唯一值的特征使用 one-hot 编码。在我们的例子中，分类特征有许多唯一值，因此我们不会使用一个热编码，但根据数据集调整该参数可能是个好主意。</p><p id="1935" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><code class="fe nk nl nm nn b">learning_rate</code>&amp;<code class="fe nk nl nm nn b">n_estimators</code>—learning _ rate 越小，利用模型需要的 n 个估计量就越多。通常，方法是以相对高的<em class="lb">学习率</em>开始，调整其他参数，然后降低<em class="lb">学习率</em>，同时增加<em class="lb">n _ 估计量</em>。</p><p id="f3ee" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><code class="fe nk nl nm nn b">max_depth</code> —基树深度<em class="lb">，</em>该参数对训练时间<em class="lb">有很大影响。</em></p><p id="93de" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><code class="fe nk nl nm nn b">subsample</code> —行的采样率，不能用于<em class="lb">贝叶斯</em>增强类型设置。</p><p id="d377" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><code class="fe nk nl nm nn b">colsample_bylevel, colsample_bytree, colsample_bynode</code> —列的采样率。</p><p id="b4c5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><code class="fe nk nl nm nn b">l2_leaf_reg</code> — L2 正则化系数</p><p id="1bfc" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><code class="fe nk nl nm nn b">random_strength</code> — <em class="lb"> </em>每一次分裂都会得到一个分数，random_strength 为分数增加了一些随机性，这有助于减少过度拟合。</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi no"><img src="../Images/b824047c9e817037fc3e063466351393.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1zY3PG861GMn7tdzZvD7ug.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Check out the recommended spaces for tuning <a class="ae la" href="https://github.com/talperetz/hyperspace/tree/master/GBDTs" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><h1 id="7743" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">使用 Catboost 进行模型探索</h1><p id="fd1c" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">除了 GBDT 模型非常流行的特性重要性之外，Catboost 还提供了<strong class="ke ir">特性交互</strong>和<strong class="ke ir">对象(行)重要性</strong></p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi np"><img src="../Images/db932ac8ef62dd9164804e16be3b0689.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Y9gHBQLxk-PoIJLd2wr1g.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Catboost’s Feature Importance</figcaption></figure><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nq"><img src="../Images/91968b5dcbdfc03a83cc42866e87c9d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VV1eH5Iwz3hJmKWAaV_Y6w.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Catboost’s Feature Interactions</figcaption></figure><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nr"><img src="../Images/16fa9e087d847307096c4ca63da51d1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZoMzKdiIyLU9wDelELQMvg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Catboost’s Object Importance</figcaption></figure><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ns"><img src="../Images/bc31d57997557ee20fe074af8addae92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PUUt_CiVtLQ9PFOFEK91cA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><a class="ae la" href="https://catboost.ai/news/new-ways-to-explore-your-data" rel="noopener ugc nofollow" target="_blank">SHAP</a> values can be used for other ensembles as well</figcaption></figure><h1 id="97bd" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">完整的笔记本</h1><p id="835d" class="pw-post-body-paragraph kc kd iq ke b kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">查看一些有用的 Catboost 代码片段</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="nt nu l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Catboost Playground Notebook</figcaption></figure><h1 id="e13c" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">结果</h1><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nv"><img src="../Images/c709f382939399c2d6ea713796079bda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CBEhmpV8rdKWWwWnN4Db5g.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Catboost vs. XGBoost (default, greedy and exhaustive parameter search)</figcaption></figure><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nw"><img src="../Images/54d1245e2ace64ceb05efce1fe0ac054.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LChQ07fA-MjChwv_yladpw.png"/></div></div></figure><h1 id="d981" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">拿走</h1><ul class=""><li id="b296" class="nx ny iq ke b kf mm kj mn kn nz kr oa kv ob kz oc od oe of bi translated">Catboost 的构建方法和属性与“老”一代 GBDT 车型相似。</li><li id="d5f0" class="nx ny iq ke b kf og kj oh kn oi kr oj kv ok kz oc od oe of bi translated">Catboost 的强大之处在于它的<strong class="ke ir">分类特征预处理</strong>、<strong class="ke ir">预测时间</strong>和<strong class="ke ir">模型分析</strong>。</li><li id="dff4" class="nx ny iq ke b kf og kj oh kn oi kr oj kv ok kz oc od oe of bi translated">Catboost 的弱点是它的<strong class="ke ir">训练和优化时间</strong>。</li><li id="cef5" class="nx ny iq ke b kf og kj oh kn oi kr oj kv ok kz oc od oe of bi translated">不要忘记将<strong class="ke ir"> <em class="lb"> cat_features </em> </strong>参数传递给分类器对象。没有它，你就不能真正利用 Catboost 的能力。</li><li id="17ad" class="nx ny iq ke b kf og kj oh kn oi kr oj kv ok kz oc od oe of bi translated">尽管 Catboost 在默认参数下表现良好，但有几个参数在优化时可以显著改善结果。</li></ul><h1 id="3c05" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">进一步阅读</h1><ul class=""><li id="068d" class="nx ny iq ke b kf mm kj mn kn nz kr oa kv ob kz oc od oe of bi translated"><a class="ae la" href="https://tech.yandex.com/catboost/doc/dg/concepts/about-docpage/" rel="noopener ugc nofollow" target="_blank"> Catboost 文档</a></li><li id="b935" class="nx ny iq ke b kf og kj oh kn oi kr oj kv ok kz oc od oe of bi translated"><a class="ae la" href="https://github.com/catboost/catboost" rel="noopener ugc nofollow" target="_blank"> Catboost Github </a></li><li id="6970" class="nx ny iq ke b kf og kj oh kn oi kr oj kv ok kz oc od oe of bi translated"><a class="ae la" href="https://catboost.ai/" rel="noopener ugc nofollow" target="_blank"> Catboost 官网</a></li><li id="a031" class="nx ny iq ke b kf og kj oh kn oi kr oj kv ok kz oc od oe of bi translated">我强烈推荐您深入研究 arXiv 上的<a class="ae la" href="https://arxiv.org/abs/1706.09516" rel="noopener ugc nofollow" target="_blank"> CatBoost:带有分类特征的无偏增强论文。</a></li><li id="8de4" class="nx ny iq ke b kf og kj oh kn oi kr oj kv ok kz oc od oe of bi translated"><a class="ae la" href="https://gist.github.com/talperetz/6030f4e9997c249b09409dcf00e78f91" rel="noopener ugc nofollow" target="_blank"> Catboost 游乐场笔记本</a></li><li id="9fd4" class="nx ny iq ke b kf og kj oh kn oi kr oj kv ok kz oc od oe of bi translated"><a class="ae la" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> SHAP 值</a></li></ul><p id="2c47" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">非常感谢 Catboost 团队负责人<a class="ol om ep" href="https://medium.com/u/bdf771da88f3?source=post_page-----db04062a7ea2--------------------------------" rel="noopener" target="_blank">安娜·维罗妮卡·多罗古什</a>。</p><p id="013e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果你喜欢这篇文章，请按下鼓掌键👏🏽如果你对接下来的帖子感兴趣，一定要关注我</p><p id="d2a5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">中:</strong><a class="ae la" href="https://medium.com/@talperetz24" rel="noopener"><strong class="ke ir">https://medium.com/@talperetz24</strong></a><strong class="ke ir"><br/>推特:</strong><a class="ae la" href="https://twitter.com/talperetz24" rel="noopener ugc nofollow" target="_blank"><strong class="ke ir">https://twitter.com/talperetz24</strong></a><strong class="ke ir"><br/>领英:</strong><a class="ae la" href="https://www.linkedin.com/in/tal-per/" rel="noopener ugc nofollow" target="_blank"><strong class="ke ir">https://www.linkedin.com/in/tal-per/</strong></a></p><p id="7aff" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">像每年一样，我想提一下<a class="ae la" href="https://www.datahack.org.il/" rel="noopener ugc nofollow" target="_blank">data hack</a>——最好的数据驱动黑客马拉松。今年，我和דור פרץ在我们的项目中使用了 Catboost，并获得了第一名🏆。</p></div></div>    
</body>
</html>