<html>
<head>
<title>Useful Keras features</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">有用的 Keras 功能</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/https-medium-com-manishchablani-useful-keras-features-4bac0724734c?source=collection_archive---------0-----------------------#2017-06-03">https://towardsdatascience.com/https-medium-com-manishchablani-useful-keras-features-4bac0724734c?source=collection_archive---------0-----------------------#2017-06-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="8459" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下是一些有趣功能的总结，我觉得在我构建深度学习管道时，我会发现参考这些功能很有用，也就是我通常不记得的东西。来自 Keras 文档 https://keras.io 和其他在线帖子。</p><h1 id="e67c" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">当验证损失不再减少时，我如何中断培训？</h1><p id="5af5" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">您可以使用<code class="fe ls lt lu lv b">EarlyStopping</code>回调:</p><pre class="lw lx ly lz gt ma lv mb mc aw md bi"><span id="776f" class="me kq it lv b gy mf mg l mh mi"><strong class="lv iu">from</strong> keras.callbacks <strong class="lv iu">import</strong> EarlyStopping<br/>early_stopping = EarlyStopping(monitor='val_loss', patience=2)<br/>model.fit(X, y, validation_split=0.2, callbacks=[early_stopping])</span></pre><h1 id="ab8c" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">如何获得中间层的输出？</h1><p id="9f45" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">一个简单的方法是创建一个新的<code class="fe ls lt lu lv b">Model</code>，它将输出您感兴趣的图层:</p><pre class="lw lx ly lz gt ma lv mb mc aw md bi"><span id="23bc" class="me kq it lv b gy mf mg l mh mi"><strong class="lv iu">from</strong> keras.models <strong class="lv iu">import</strong> Model</span><span id="b44c" class="me kq it lv b gy mj mg l mh mi">model = ...  <em class="mk"># create the original model</em></span><span id="48d5" class="me kq it lv b gy mj mg l mh mi">layer_name = 'my_layer'<br/>intermediate_layer_model = Model(inputs=model.input,<br/>                                 outputs=model.get_layer(layer_name).output)<br/>intermediate_output = intermediate_layer_model.predict(data)</span></pre><p id="8c95" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">或者，您可以构建一个 Keras 函数，在给定特定输入的情况下返回特定图层的输出，例如:</p><pre class="lw lx ly lz gt ma lv mb mc aw md bi"><span id="c42e" class="me kq it lv b gy mf mg l mh mi"><strong class="lv iu">from</strong> keras <strong class="lv iu">import</strong> backend <strong class="lv iu">as</strong> K</span><span id="6e93" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># with a Sequential model</em><br/>get_3rd_layer_output = K.function([model.layers[0].input],<br/>                                  [model.layers[3].output])<br/>layer_output = get_3rd_layer_output([X])[0]</span></pre><p id="3275" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">类似地，您可以直接构建一个 Theano 和 TensorFlow 函数。</p><p id="5fba" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意，如果您的模型在训练和测试阶段有不同的行为(例如，如果它使用<code class="fe ls lt lu lv b">Dropout</code>、<code class="fe ls lt lu lv b">BatchNormalization</code>等)。)，您需要将学习阶段标志传递给您的函数:</p><pre class="lw lx ly lz gt ma lv mb mc aw md bi"><span id="8efb" class="me kq it lv b gy mf mg l mh mi">get_3rd_layer_output = K.function([model.layers[0].input, K.learning_phase()],<br/>                                  [model.layers[3].output])</span><span id="4493" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># output in test mode = 0</em><br/>layer_output = get_3rd_layer_output([X, 0])[0]</span><span id="8ab5" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># output in train mode = 1</em><br/>layer_output = get_3rd_layer_output([X, 1])[0]</span></pre><h1 id="554a" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">如何在 Keras 中使用预训练模型？</h1><p id="31cd" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">代码和预训练权重可用于以下影像分类模型:</p><ul class=""><li id="ce1d" class="ml mm it js b jt ju jx jy kb mn kf mo kj mp kn mq mr ms mt bi translated">例外</li><li id="a2f2" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">VGG16</li><li id="038c" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">VGG19</li><li id="b3c9" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">ResNet50</li><li id="d6c6" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">盗梦空间 v3</li></ul><p id="eb03" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它们可以从<code class="fe ls lt lu lv b">keras.applications</code>模块导入:</p><pre class="lw lx ly lz gt ma lv mb mc aw md bi"><span id="9de3" class="me kq it lv b gy mf mg l mh mi"><strong class="lv iu">from</strong> keras.applications.xception <strong class="lv iu">import</strong> Xception<br/><strong class="lv iu">from</strong> keras.applications.vgg16 <strong class="lv iu">import</strong> VGG16<br/><strong class="lv iu">from</strong> keras.applications.vgg19 <strong class="lv iu">import</strong> VGG19<br/><strong class="lv iu">from</strong> keras.applications.resnet50 <strong class="lv iu">import</strong> ResNet50<br/><strong class="lv iu">from</strong> keras.applications.inception_v3 <strong class="lv iu">import</strong> InceptionV3</span><span id="e98b" class="me kq it lv b gy mj mg l mh mi">model = VGG16(weights='imagenet', include_top=<strong class="lv iu">True</strong>)</span></pre><p id="f43b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">关于一些简单的使用示例，请参见<a class="ae ko" href="https://keras.io/applications" rel="noopener ugc nofollow" target="_blank">应用模块</a>的文档。</p><p id="190f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有关如何使用这种预训练模型进行特征提取或微调的详细示例，请参见<a class="ae ko" href="http://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html" rel="noopener ugc nofollow" target="_blank">这篇博文</a>。</p><p id="c855" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">VGG16 模型也是几个 Keras 示例脚本的基础:</p><ul class=""><li id="e44d" class="ml mm it js b jt ju jx jy kb mn kf mo kj mp kn mq mr ms mt bi translated"><a class="ae ko" href="https://github.com/fchollet/keras/blob/master/examples/neural_style_transfer.py" rel="noopener ugc nofollow" target="_blank">风格转移</a></li><li id="587f" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated"><a class="ae ko" href="https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py" rel="noopener ugc nofollow" target="_blank">特征可视化</a></li><li id="2aa3" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated"><a class="ae ko" href="https://github.com/fchollet/keras/blob/master/examples/deep_dream.py" rel="noopener ugc nofollow" target="_blank">深梦</a></li></ul><h1 id="5494" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><a class="ae ko" href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html" rel="noopener ugc nofollow" target="_blank">使用非常少的数据构建强大的图像分类模型</a></h1><h2 id="28ba" class="me kq it bd kr mz na dn kv nb nc dp kz kb nd ne ld kf nf ng lh kj nh ni ll nj bi translated"><a class="ae ko" href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html" rel="noopener ugc nofollow" target="_blank">https://blog . keras . io/building-powerful-image-class ification-models-using-very-little-data . html</a></h2><h2 id="4538" class="me kq it bd kr mz na dn kv nb nc dp kz kb nd ne ld kf nf ng lh kj nh ni ll nj bi translated">数据预处理和数据扩充</h2><pre class="lw lx ly lz gt ma lv mb mc aw md bi"><span id="aaf1" class="me kq it lv b gy mf mg l mh mi">from keras.preprocessing.image import ImageDataGenerator<br/><br/>datagen = ImageDataGenerator(<br/>        rotation_range=40,<br/>        width_shift_range=0.2,<br/>        height_shift_range=0.2,<br/>        rescale=1./255,<br/>        shear_range=0.2,<br/>        zoom_range=0.2,<br/>        horizontal_flip=True,<br/>        fill_mode='nearest')</span></pre><p id="ea85" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这些只是可用选项中的一部分(更多信息，请参见文档)。让我们快速回顾一下我们刚刚写的内容:</p><ul class=""><li id="0694" class="ml mm it js b jt ju jx jy kb mn kf mo kj mp kn mq mr ms mt bi translated"><code class="fe ls lt lu lv b">rotation_range</code>是以度为单位的值(0-180)，在此范围内随机旋转图片</li><li id="35e6" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated"><code class="fe ls lt lu lv b">width_shift</code>和<code class="fe ls lt lu lv b">height_shift</code>是随机垂直或水平平移图片的范围(作为总宽度或高度的一部分)</li><li id="0274" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated"><code class="fe ls lt lu lv b">rescale</code>是一个值，在进行任何其他处理之前，我们会将数据乘以该值。我们的原始图像由 0-255 的 RGB 系数组成，但是这样的值对于我们的模型来说太高而无法处理(给定典型的学习率)，所以我们通过 1/255 的缩放将目标值设置在 0 和 1 之间。因素。</li><li id="9514" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated"><code class="fe ls lt lu lv b">shear_range</code>用于随机应用<a class="ae ko" href="https://en.wikipedia.org/wiki/Shear_mapping" rel="noopener ugc nofollow" target="_blank">剪切变换</a></li><li id="e278" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated"><code class="fe ls lt lu lv b">zoom_range</code>用于图片内部随机缩放</li><li id="e81a" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated"><code class="fe ls lt lu lv b">horizontal_flip</code>用于在没有水平不对称假设的情况下，随机翻转一半水平相关的图像(如真实图片)。</li><li id="fda3" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated"><code class="fe ls lt lu lv b">fill_mode</code>是用于填充新创建像素的策略，可在旋转或宽度/高度移动后出现。</li></ul><p id="ed23" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，让我们开始使用该工具生成一些图片，并将它们保存到一个临时目录中，这样我们就可以感受一下我们的增强策略正在做什么——在这种情况下，我们禁用了重新缩放，以保持图像可显示:</p><p id="c7d8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们准备我们的数据。我们将使用<code class="fe ls lt lu lv b">.flow_from_directory()</code>直接从各自文件夹中的 jpg 生成批量图像数据(及其标签)。</p><pre class="lw lx ly lz gt ma lv mb mc aw md bi"><span id="6daf" class="me kq it lv b gy mf mg l mh mi">img = load_img('data/train/cats/cat.0.jpg')  # this is a PIL image<br/>x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)<br/>x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)<br/><br/># the .flow() command below generates batches of randomly transformed images<br/># and saves the results to the `preview/` directory<br/>i = 0<br/>for batch in datagen.flow(x, batch_size=1,<br/>                          save_to_dir='preview', save_prefix='cat', save_format='jpeg'):<br/>    i += 1<br/>    if i &gt; 20:<br/>        break  # otherwise the generator would loop indefinitely</span><span id="aca2" class="me kq it lv b gy mj mg l mh mi">batch_size = 16<br/><br/># this is the augmentation configuration we will use for training<br/>train_datagen = ImageDataGenerator(<br/>        rescale=1./255,<br/>        shear_range=0.2,<br/>        zoom_range=0.2,<br/>        horizontal_flip=True)<br/><br/># this is the augmentation configuration we will use for testing:<br/># only rescaling<br/>test_datagen = ImageDataGenerator(rescale=1./255)<br/><br/># this is a generator that will read pictures found in<br/># subfolers of 'data/train', and indefinitely generate<br/># batches of augmented image data<br/>train_generator = train_datagen.flow_from_directory(<br/>        'data/train',  # this is the target directory<br/>        target_size=(150, 150),  # all images will be resized to 150x150<br/>        batch_size=batch_size,<br/>        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels<br/><br/># this is a similar generator, for validation data<br/>validation_generator = test_datagen.flow_from_directory(<br/>        'data/validation',<br/>        target_size=(150, 150),<br/>        batch_size=batch_size,<br/>        class_mode='binary')</span></pre><p id="7420" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们现在可以使用这些生成器来训练我们的模型。每个历元在 GPU 上需要 20–30 秒，在 CPU 上需要 300–400 秒。所以如果你不着急的话，在 CPU 上运行这个模型是完全可行的。</p><pre class="lw lx ly lz gt ma lv mb mc aw md bi"><span id="c53a" class="me kq it lv b gy mf mg l mh mi">model.fit_generator(<br/>        train_generator,<br/>        steps_per_epoch=2000 // batch_size,<br/>        epochs=50,<br/>        validation_data=validation_generator,<br/>        validation_steps=800 // batch_size)<br/>model.save_weights('first_try.h5')  # always save your weights after training or during training</span></pre><p id="78ab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这种方法使我们在 50 个时期后达到 0.79–0.81 的验证精度(这是一个任意选取的数字，因为模型很小，并且使用了积极的压降，所以到那时它似乎不会过度拟合)</p><h2 id="f0b5" class="me kq it bd kr mz na dn kv nb nc dp kz kb nd ne ld kf nf ng lh kj nh ni ll nj bi translated">使用预训练网络的瓶颈功能:一分钟内 90%的准确率</h2><p id="5eaa" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">我们的策略如下:我们将只实例化模型的卷积部分，直到全连接层。然后，我们将在我们的训练和验证数据上运行该模型一次，在两个 numpy 阵列中记录输出(来自 VGG16 模型的“瓶颈特性”:全连接层之前的最后激活映射)。然后，我们将在存储的特征之上训练一个小的全连接模型。</p><p id="703f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们离线存储特征而不是在冻结的卷积基础上直接添加全连接模型并运行整个过程的原因是计算效率。运行 VGG16 是很昂贵的，尤其是如果你在 CPU 上工作，我们希望只做一次。请注意，这阻止了我们使用数据扩充。</p><figure class="lw lx ly lz gt nk"><div class="bz fp l di"><div class="nl nm l"/></div></figure><p id="ddc3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们达到了 0.90–0.91 的验证精度:一点也不差。这肯定部分是由于基础模型是在已经有狗和猫的数据集上训练的(在数百个其他类中)。</p><h2 id="3b8c" class="me kq it bd kr mz na dn kv nb nc dp kz kb nd ne ld kf nf ng lh kj nh ni ll nj bi translated">微调预训练网络的顶层</h2><p id="ad51" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">为了进一步改善我们之前的结果，我们可以尝试在顶级分类器旁边“微调”VGG16 模型的最后一个卷积块。微调包括从训练好的网络开始，然后使用非常小的权重更新在新的数据集上重新训练它。在我们的案例中，这可以通过 3 个步骤来完成:</p><ul class=""><li id="e79f" class="ml mm it js b jt ju jx jy kb mn kf mo kj mp kn mq mr ms mt bi translated">实例化 VGG16 的卷积基并加载其权重</li><li id="b4a5" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">在顶部添加我们之前定义的全连接模型，并加载其权重</li><li id="6aed" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">冻结 VGG16 模型的层，直到最后一个卷积块</li></ul><p id="7bce" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意:</p><ul class=""><li id="3a70" class="ml mm it js b jt ju jx jy kb mn kf mo kj mp kn mq mr ms mt bi translated">为了进行微调，所有层都应该从经过适当训练的权重开始:例如，你不应该在预先训练的卷积基础上，加上随机初始化的全连接网络。这是因为由随机初始化的权重触发的大梯度更新会破坏卷积基中的学习权重。在我们的情况下，这就是为什么我们首先训练顶级分类器，然后才开始微调卷积权重。</li><li id="d2cf" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">我们选择仅微调最后一个卷积块，而不是整个网络，以防止过拟合，因为整个网络将具有非常大的熵容量，因此很容易过拟合。低级卷积块学习到的特征比高级卷积块更通用，更不抽象，因此保持前几个块固定(更通用的特征)并且只微调最后一个(更专用的特征)是明智的。</li><li id="7206" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">微调应该以非常慢的学习速率进行，通常使用 SGD 优化器，而不是自适应学习速率优化器，如 RMSProp。这是为了确保更新的幅度保持很小，以免破坏先前学习的功能。</li></ul><figure class="lw lx ly lz gt nk"><div class="bz fp l di"><div class="nl nm l"/></div></figure><h1 id="daae" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">什么是全球平均池？</h1><h2 id="00ee" class="me kq it bd kr mz na dn kv nb nc dp kz kb nd ne ld kf nf ng lh kj nh ni ll nj bi translated">引用谷歌搜索“全球平均池”的第一篇论文。<a class="ae ko" href="http://arxiv.org/pdf/1312.4400.pdf" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/pdf/1312.4400.pdf</a></h2><blockquote class="nn no np"><p id="a3d5" class="jq jr mk js b jt ju jv jw jx jy jz ka nq kc kd ke nr kg kh ki ns kk kl km kn im bi translated"><em class="it">CNN 没有采用传统的全连接层进行分类，而是通过全局平均池层直接输出最后一层 mlpconv 特征图的空间平均值作为类别的置信度，然后将得到的向量送入 softmax 层。在传统的 CNN 中，很难解释来自目标成本层的类别级信息如何传递回先前的卷积层，因为完全连接的层在它们之间充当黑盒。相比之下，全局平均池更有意义和可解释性，因为它加强了特征地图和类别之间的对应性，这通过使用微观网络的更强的局部建模而成为可能。此外，完全连接的层容易过拟合，并严重依赖于下降正则化[4] [5]，而全局平均池本身就是一个结构正则化，它本身可以防止整个结构的过拟合。</em></p></blockquote><p id="5b09" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">和</p><blockquote class="nn no np"><p id="6980" class="jq jr mk js b jt ju jv jw jx jy jz ka nq kc kd ke nr kg kh ki ns kk kl km kn im bi translated"><em class="it">在本文中，我们提出了另一种称为全局平均池的策略来取代 CNN 中传统的全连接层。其思想是在最后的 mlpconv 层中为分类任务的每个相应类别生成一个特征图。我们没有在特征地图上添加完全连接的层，而是取每个特征地图的平均值，并将结果向量直接输入 softmax 层。与完全连接的图层相比，全局平均池的一个优势是，它通过加强要素地图和类别之间的对应关系，更适合卷积结构。因此，特征图可以很容易地解释为类别置信度图。另一个优点是在全局平均池中没有要优化的参数，因此在这一层避免了过拟合。此外，全局平均池汇总了空间信息，因此对输入的空间平移更具鲁棒性。</em></p><p id="692f" class="jq jr mk js b jt ju jv jw jx jy jz ka nq kc kd ke nr kg kh ki ns kk kl km kn im bi translated"><em class="it">我们可以将全局平均池视为一种结构正则化器，它明确地将特征映射强制为概念(类别)的置信度映射。这通过 mlpconv 层成为可能，因为它们比 GLMs 更好地逼近置信图。</em></p></blockquote><p id="1e07" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在有 10 个分类的情况下(CIFAR10，MNIST)。</p><p id="230c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这意味着，如果在最后一次卷积结束时有一个 3D 8，8，128 张量，在传统方法中，你要将其展平为大小为 8x8x128 的 1D 矢量。然后添加一个或几个完全连接的层，最后添加一个 softmax 层，将大小减少到 10 个分类类别，并应用 softmax 运算符。</p><p id="6ab6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">全局平均池意味着你有一个 3D 8，8，10 张量，计算 8，8 切片的平均值，你最终得到一个形状为 1，1，10 的 3D 张量，你将它整形为形状为 10 的 1D 向量。然后添加一个 softmax 运算符，中间没有任何运算。平均池之前的张量应该具有与您的模型具有的分类类别一样多的通道。</p><p id="6c85" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该文件并不清楚，但当他们说“softmax 层”时，他们指的是 softmax 操作符，而不是与 softmax 激活完全连接的层。</p><p id="73e0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">不是 y=softmax(W*flatten(GAP(x))+b)而是 y=softmax(flatten(GAP(x)))。</p><h1 id="4516" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">在一组新的类上微调 InceptionV3</h1><pre class="lw lx ly lz gt ma lv mb mc aw md bi"><span id="7c5a" class="me kq it lv b gy mf mg l mh mi"><strong class="lv iu">from</strong> keras.applications.inception_v3 <strong class="lv iu">import</strong> InceptionV3<br/><strong class="lv iu">from</strong> keras.preprocessing <strong class="lv iu">import</strong> image<br/><strong class="lv iu">from</strong> keras.models <strong class="lv iu">import</strong> Model<br/><strong class="lv iu">from</strong> keras.layers <strong class="lv iu">import</strong> Dense, GlobalAveragePooling2D<br/><strong class="lv iu">from</strong> keras <strong class="lv iu">import</strong> backend <strong class="lv iu">as</strong> K</span><span id="af5e" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># create the base pre-trained model</em><br/>base_model = InceptionV3(weights='imagenet', include_top=<strong class="lv iu">False</strong>)</span><span id="4353" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># add a global spatial average pooling layer</em><br/>x = base_model.output<br/>x = GlobalAveragePooling2D()(x)<br/><em class="mk"># let's add a fully-connected layer</em><br/>x = Dense(1024, activation='relu')(x)<br/><em class="mk"># and a logistic layer -- let's say we have 200 classes</em><br/>predictions = Dense(200, activation='softmax')(x)</span><span id="a1f4" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># this is the model we will train</em><br/>model = Model(inputs=base_model.input, outputs=predictions)</span><span id="9c4e" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># first: train only the top layers (which were randomly initialized)</em><br/><em class="mk"># i.e. freeze all convolutional InceptionV3 layers</em><br/><strong class="lv iu">for</strong> layer <strong class="lv iu">in</strong> base_model.layers:<br/>    layer.trainable = <strong class="lv iu">False</strong></span><span id="56b8" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># compile the model (should be done *after* setting layers to non-trainable)</em><br/>model.compile(optimizer='rmsprop', loss='categorical_crossentropy')</span><span id="6bff" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># train the model on the new data for a few epochs</em><br/>model.fit_generator(...)</span><span id="34c6" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># at this point, the top layers are well trained and we can start fine-tuning</em><br/><em class="mk"># convolutional layers from inception V3. We will freeze the bottom N layers</em><br/><em class="mk"># and train the remaining top layers.</em></span><span id="fe05" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># let's visualize layer names and layer indices to see how many layers</em><br/><em class="mk"># we should freeze:</em><br/><strong class="lv iu">for</strong> i, layer <strong class="lv iu">in</strong> enumerate(base_model.layers):<br/>   print(i, layer.name)</span><span id="3988" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># we chose to train the top 2 inception blocks, i.e. we will freeze</em><br/><em class="mk"># the first 172 layers and unfreeze the rest:</em><br/><strong class="lv iu">for</strong> layer <strong class="lv iu">in</strong> model.layers[:172]:<br/>   layer.trainable = <strong class="lv iu">False</strong><br/><strong class="lv iu">for</strong> layer <strong class="lv iu">in</strong> model.layers[172:]:<br/>   layer.trainable = <strong class="lv iu">True</strong></span><span id="cd01" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># we need to recompile the model for these modifications to take effect</em><br/><em class="mk"># we use SGD with a low learning rate</em><br/><strong class="lv iu">from</strong> keras.optimizers <strong class="lv iu">import</strong> SGD<br/>model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')</span><span id="62b5" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># we train our model again (this time fine-tuning the top 2 inception blocks</em><br/><em class="mk"># alongside the top Dense layers</em><br/>model.fit_generator(...)</span></pre><h1 id="2484" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">如何使用有状态 rnn？</h1><p id="7191" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">使 RNN 有状态意味着每批样本的状态将被重新用作下一批样本的初始状态。</p><p id="de53" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，当使用有状态 rnn 时，假设:</p><ul class=""><li id="369f" class="ml mm it js b jt ju jx jy kb mn kf mo kj mp kn mq mr ms mt bi translated">所有批次都有相同数量的样本</li><li id="7410" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">如果<code class="fe ls lt lu lv b">X1</code>和<code class="fe ls lt lu lv b">X2</code>是连续批次的样品，那么<code class="fe ls lt lu lv b">X2[i]</code>是<code class="fe ls lt lu lv b">X1[i]</code>的后续序列，对于每个<code class="fe ls lt lu lv b">i</code>。</li></ul><p id="944f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要在 RNNs 中使用状态，您需要:</p><ul class=""><li id="1f88" class="ml mm it js b jt ju jx jy kb mn kf mo kj mp kn mq mr ms mt bi translated">通过向模型中的第一层传递一个<code class="fe ls lt lu lv b">batch_size</code>参数，显式指定您正在使用的批量大小。例如<code class="fe ls lt lu lv b">batch_size=32</code>对于 10 个时间步长的 32 样本批次序列，每个时间步长具有 16 个特征。</li><li id="3ecf" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">在你的 RNN 图层中设置<code class="fe ls lt lu lv b">stateful=True</code>。</li><li id="b143" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">调用 fit()时指定<code class="fe ls lt lu lv b">shuffle=False</code>。</li></ul><p id="eec0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要重置累积的状态:</p><ul class=""><li id="7639" class="ml mm it js b jt ju jx jy kb mn kf mo kj mp kn mq mr ms mt bi translated">使用<code class="fe ls lt lu lv b">model.reset_states()</code>重置模型中所有层的状态</li><li id="a82b" class="ml mm it js b jt mu jx mv kb mw kf mx kj my kn mq mr ms mt bi translated">使用<code class="fe ls lt lu lv b">layer.reset_states()</code>重置特定有状态 RNN 层的状态</li></ul><p id="e148" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">示例:</p><pre class="lw lx ly lz gt ma lv mb mc aw md bi"><span id="18d1" class="me kq it lv b gy mf mg l mh mi">X  <em class="mk"># this is our input data, of shape (32, 21, 16)</em><br/><em class="mk"># we will feed it to our model in sequences of length 10</em></span><span id="886e" class="me kq it lv b gy mj mg l mh mi">model = Sequential()<br/>model.add(LSTM(32, input_shape=(10, 16), batch_size=32, stateful=<strong class="lv iu">True</strong>))<br/>model.add(Dense(16, activation='softmax'))</span><span id="768c" class="me kq it lv b gy mj mg l mh mi">model.compile(optimizer='rmsprop', loss='categorical_crossentropy')</span><span id="edc2" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># we train the network to predict the 11th timestep given the first 10:</em><br/>model.train_on_batch(X[:, :10, :], np.reshape(X[:, 10, :], (32, 16)))</span><span id="70a6" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># the state of the network has changed. We can feed the follow-up sequences:</em><br/>model.train_on_batch(X[:, 10:20, :], np.reshape(X[:, 20, :], (32, 16)))</span><span id="1a96" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># let's reset the states of the LSTM layer:</em><br/>model.reset_states()</span><span id="b758" class="me kq it lv b gy mj mg l mh mi"><em class="mk"># another way to do it in this case:</em><br/>model.layers[0].reset_states()</span></pre><p id="b1d3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">注意，方法有<code class="fe ls lt lu lv b">predict</code>、<code class="fe ls lt lu lv b">fit</code>、<code class="fe ls lt lu lv b">train_on_batch</code>、<code class="fe ls lt lu lv b">predict_classes</code>等。所有的将更新模型中有状态层的状态。这不仅允许您进行状态训练，还允许您进行状态预测。</p></div></div>    
</body>
</html>