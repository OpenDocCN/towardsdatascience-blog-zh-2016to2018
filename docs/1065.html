<html>
<head>
<title>[Learning Note] Single Shot MultiBox Detector with Pytorch — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">[学习笔记]带 Pytorch 的单次多盒检测器—第 2 部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learning-note-single-shot-multibox-detector-with-pytorch-part-2-dd96bdf4f434?source=collection_archive---------1-----------------------#2017-07-26">https://towardsdatascience.com/learning-note-single-shot-multibox-detector-with-pytorch-part-2-dd96bdf4f434?source=collection_archive---------1-----------------------#2017-07-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8a66" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">平铺和匹配策略</h2></div><p id="7584" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lb" href="https://medium.com/towards-data-science/learning-note-single-shot-multibox-detector-with-pytorch-part-1-38185e84bd79" rel="noopener">在上一篇</a>中，我们讨论了 SSD 的网络结构和预测方案。现在，我们继续将默认框和基本事实结合起来，这样就可以确定预测的质量(并通过训练进行改进)。</p><p id="c874" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">(提醒:<a class="ae lb" href="https://arxiv.org/abs/1512.02325" rel="noopener ugc nofollow" target="_blank">本文使用的 SSD 纸</a>和<a class="ae lb" href="https://github.com/amdegroot/ssd.pytorch" rel="noopener ugc nofollow" target="_blank">py torch 实现</a></p><h2 id="e6c0" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">将默认框映射到输入图像上的坐标</h2><p id="c4e9" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">在<a class="ae lb" href="https://github.com/amdegroot/ssd.pytorch/blob/master/data/config.py" rel="noopener ugc nofollow" target="_blank"> data/config.py </a>中预先计算并硬编码了每个特征映射的默认框的参数:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="20b4" class="lc ld iq mf b gy mj mk l ml mm">#SSD300 CONFIGS                      <br/># newer version: use additional conv11_2 layer as last layer before multibox layers                       <br/>v2 = {                           <br/>    'feature_maps' : [38, 19, 10, 5, 3, 1],<br/>    'min_dim' : 300,                                                    <br/>    'steps' : [8, 16, 32, 64, 100, 300],                                                   <br/>    'min_sizes' : [30, 60, 111, 162, 213, 264],                                                   <br/>    'max_sizes' : [60, 111, 162, 213, 264, 315],                                                   <br/>    'aspect_ratios' : [[2], [2, 3], [2, 3], [2, 3], [2], [2]],                                                   <br/>    'variance' : [0.1, 0.2],                                                   <br/>    'clip' : True,                                                   <br/>    'name' : 'v2',                       <br/>}</span></pre><p id="94ae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">实际的映射发生在<a class="ae lb" href="https://github.com/amdegroot/ssd.pytorch/blob/master/layers/functions/prior_box.py" rel="noopener ugc nofollow" target="_blank">层/函数/prior_box.py </a> (P.S .默认框在实现中称为 prior boxed):</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="7280" class="lc ld iq mf b gy mj mk l ml mm">from itertools import product as product</span><span id="efed" class="lc ld iq mf b gy mn mk l ml mm">class PriorBox(object):<br/>    def __init__(self, cfg):<br/>        super(PriorBox, self).__init__()<br/>        # self.type = cfg.name<br/>        self.image_size = cfg['min_dim']<br/>        self.variance = cfg['variance'] or [0.1]</span><span id="e52b" class="lc ld iq mf b gy mn mk l ml mm">        […]</span><span id="9997" class="lc ld iq mf b gy mn mk l ml mm">        for v in self.variance:<br/>            if v &lt;= 0:<br/>                raise ValueError(<br/>                    'Variances must be greater than 0')</span><span id="6c18" class="lc ld iq mf b gy mn mk l ml mm">    def forward(self):<br/>        mean = []<br/>        if self.version == 'v2':<br/>            for k, f in enumerate(self.feature_maps):<br/>                for i, j in product(range(f), repeat=2):<br/>                    f_k = self.image_size / self.steps[k]<br/>                    # unit center x,y<br/>                    cx = (j + 0.5) / f_k<br/>                    cy = (i + 0.5) / f_k</span><span id="c948" class="lc ld iq mf b gy mn mk l ml mm">                    # aspect_ratio: 1<br/>                    # rel size: min_size<br/>                    s_k = self.min_sizes[k]/self.image_size<br/>                    mean += [cx, cy, s_k, s_k]</span><span id="108b" class="lc ld iq mf b gy mn mk l ml mm">                    # aspect_ratio: 1<br/>                    # rel size: sqrt(s_k * s_(k+1))<br/>                    s_k_prime = sqrt(<br/>                        s_k * (self.max_sizes[k]/self.image_size))<br/>                    mean += [cx, cy, s_k_prime, s_k_prime]</span><span id="ef0c" class="lc ld iq mf b gy mn mk l ml mm">                    # rest of aspect ratios<br/>                    for ar in self.aspect_ratios[k]:<br/>                        mean += [<br/>                            cx, cy, s_k*sqrt(ar), s_k/sqrt(ar)]<br/>                        mean += [<br/>                            cx, cy, s_k/sqrt(ar), s_k*sqrt(ar)]<br/>        <br/>        […] </span><span id="0f2f" class="lc ld iq mf b gy mn mk l ml mm">        # back to torch land<br/>        output = torch.Tensor(mean).view(-1, 4)<br/>        if self.clip:<br/>            output.clamp_(max=1, min=0)<br/>        return output</span></pre><figure class="ma mb mc md gt mp gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/f6291348e0a4f3aa7c3947260478f758.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*kHrku-Db5LLfC-L1eEUqeA.png"/></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">Layout of the four default boxes (from original paper)</figcaption></figure><p id="2210" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mw">(</em><a class="ae lb" href="https://docs.python.org/3/library/itertools.html#itertools.product" rel="noopener ugc nofollow" target="_blank"><em class="mw">ITER tools . product</em></a><em class="mw">创建输入可迭代对象的笛卡尔积。所以 product(range(4)，repeat=2)得出(0，1，2，3)和(0，1，2，3)之间的所有组合，即(0，0)，(0，1) …，(3，2)，(3，3)。)</em></p><p id="de6b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以第一张特征图(38x38)为例。<code class="fe mx my mz mf b">f_k=300/8=37.5</code>。<code class="fe mx my mz mf b">i+0.5</code>和<code class="fe mx my mz mf b">j+0.5</code>的范围从<em class="mw"> 0.5 </em>到<em class="mw"> 37.5 </em>。所以中心点坐标<em class="mw"> cx </em>和<em class="mw"> cy </em>转化为(0.0133，0.0133)，(0.0133，0.04) …，(1，0.9733)，(1，1)。请注意，代码将坐标归一化为(0，1)，并且记住大多数特征图都是零填充的(最外面的单元总是零)。可以自己验证一下倒数第二个(未填充)要素图中最外面的中心点离 0 和 1 有一点距离。并且最后的特征图只有一个中心点正好位于(0.5，0.5)。</p><p id="fb84" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们有了每个默认框的中心点。接下来我们要计算宽度和高度。有六种默认的方框布局:</p><ol class=""><li id="9bbb" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated">尺寸<em class="mw"> (s_k，s_k) </em>的小方块</li><li id="550f" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">大小为<em class="mw"> (sqrt(s_k * s_(k+1))、sqrt(s_k * s_(k+1))) </em>的大正方形</li><li id="168b" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">尺寸为 1:2 的矩形<em class="mw"> (s_k * 0.7071，s_k * 1.414) </em></li><li id="4b37" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">2:1 矩形尺寸<em class="mw"> (s_k * 1.414，s_k * 0.7071) </em></li><li id="9303" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">尺寸为<em class="mw"> (s_k * 0.5774，s_k * 1.7321) </em>的 1:3 矩形</li><li id="b643" class="na nb iq kh b ki nj kl nk ko nl ks nm kw nn la nf ng nh ni bi translated">3:1 大小的矩形<em class="mw"> (s_k * 1.7321，s_k * 0.5774) </em></li></ol><p id="d91e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于具有 4 个默认框的要素地图，仅使用前四种布局。矩形的面积与小正方形的面积相同。这和上图不一样，上图面积好像和大正方形一样。</p><p id="da74" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">s_k 来自以下公式，第一个特征图除外:</p><figure class="ma mb mc md gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi no"><img src="../Images/7c845da87dbd30c2b351928bcb8747d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yU04-KmA7dAY4CYKPwPQoA.png"/></div></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">Formula (4) from the original paper</figcaption></figure><p id="e2f3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">默认框实际上是根据经验设计的，如论文中所述:</p><blockquote class="nt nu nv"><p id="c1c4" class="kf kg mw kh b ki kj jr kk kl km ju kn nw kp kq kr nx kt ku kv ny kx ky kz la ij bi translated">在实践中，还可以设计默认框的分布，以最适合特定的数据集。如何设计最优的镶嵌也是一个公开的问题。</p></blockquote><p id="6aea" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，您可以根据自己的需要自由修改<em class="mw"> prior_box.py </em>。</p><h2 id="a9f1" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">找到最符合实际情况的默认框</h2><p id="42a7" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">这就是所谓的“文中匹配策略”。这个想法非常简单——如果任何一对基础真值框和默认框的<a class="ae lb" href="https://www.wikiwand.com/en/Jaccard_index" rel="noopener ugc nofollow" target="_blank"> Jaccard overlap </a>大于一个阈值(0.5)，那么它们就被认为是匹配的。在(希望)简单的英语中，如果重叠区域大于两个盒子覆盖区域的一半，这就是匹配。</p><figure class="ma mb mc md gt mp gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/50aa0c63a2e2010383f3e5f6eb253fd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*Q1TZiQsksnNfue4YEP23uA.png"/></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">The intersection need to be larger than half of the union. (Image from <a class="ae lb" href="https://www.wikiwand.com/en/Jaccard_index#/overview" rel="noopener ugc nofollow" target="_blank">Wikipedia</a>)</figcaption></figure><p id="1e0a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">相关代码位于<a class="ae lb" href="https://github.com/amdegroot/ssd.pytorch/blob/master/layers/box_utils.py" rel="noopener ugc nofollow" target="_blank"> layers/box_utils.py </a>:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="7dbe" class="lc ld iq mf b gy mj mk l ml mm">def intersect(box_a, box_b):<br/>    """ We resize both tensors to [A,B,2] without new malloc:<br/>    [A,2] -&gt; [A,1,2] -&gt; [A,B,2]<br/>    [B,2] -&gt; [1,B,2] -&gt; [A,B,2]<br/>    Then we compute the area of intersect between box_a and box_b.<br/>    Args:<br/>      box_a: (tensor) bounding boxes, Shape: [A,4].<br/>      box_b: (tensor) bounding boxes, Shape: [B,4].<br/>    Return:<br/>      (tensor) intersection area, Shape: [A,B].<br/>    """<br/>    A = box_a.size(0)<br/>    B = box_b.size(0)<br/>    max_xy = torch.min(box_a[:, 2:].unsqueeze(1).expand(A, B, 2),<br/>                       box_b[:, 2:].unsqueeze(0).expand(A, B, 2))<br/>    min_xy = torch.max(box_a[:, :2].unsqueeze(1).expand(A, B, 2),<br/>                       box_b[:, :2].unsqueeze(0).expand(A, B, 2))<br/>    inter = torch.clamp((max_xy - min_xy), min=0)<br/>    return inter[:, :, 0] * inter[:, :, 1]</span></pre><p id="e44d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mw">(</em><a class="ae lb" href="http://pytorch.org/docs/master/torch.html#torch.unsqueeze" rel="noopener ugc nofollow" target="_blank"><em class="mw">tensor . unsqueeze</em></a><em class="mw">在指定位置插入一个尺寸为 1 的新尺寸。应该相当于</em><a class="ae lb" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.expand_dims.html" rel="noopener ugc nofollow" target="_blank"><em class="mw">numpy . expand _ dims</em></a><em class="mw">。</em><a class="ae lb" href="http://pytorch.org/docs/master/tensors.html#torch.Tensor.expand" rel="noopener ugc nofollow" target="_blank"><em class="mw">tensor . expand</em></a><em class="mw">以记忆高效的方式扩展大小 1 维。当组合</em> <a class="ae lb" href="https://github.com/pytorch/pytorch/issues/491" rel="noopener ugc nofollow" target="_blank"> <em class="mw">时，它们在功能上等同于张量。重复</em> </a> <em class="mw">，但是</em> <a class="ae lb" href="http://pytorch.org/docs/master/tensors.html#torch.Tensor.expand" rel="noopener ugc nofollow" target="_blank"> <em class="mw">张量。重复</em> </a> <em class="mw">创建一个新的张量。)</em></p><p id="a3a7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mw"> ( </em> <a class="ae lb" href="http://pytorch.org/docs/master/torch.html#torch.clamp" rel="noopener ugc nofollow" target="_blank"> <em class="mw">)张量钳位</em> </a> <em class="mw">限制一个张量的最大值和最小值。应该相当于</em><a class="ae lb" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.clip.html" rel="noopener ugc nofollow" target="_blank"><em class="mw">numpy . clip</em></a><em class="mw">。)</em></p><p id="428b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者巧妙的计算了交集。通过展开张量，我们现在能够在没有任何 for 循环的情况下，在一次运行中计算 box_a(基本事实)和 box_b(默认盒子)的每个组合的交集。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="1cbf" class="lc ld iq mf b gy mj mk l ml mm">def jaccard(box_a, box_b):<br/>    """Compute the jaccard overlap of two sets of boxes.  <br/>       The jaccard overlap is simply the intersection over <br/>       union of two boxes.  Here we operate on ground truth <br/>       boxes and default boxes.<br/>       E.g.:<br/>          A ∩ B / A ∪ B = A ∩ B / (area(A) + area(B) - A ∩ B)<br/>       Args:<br/>          box_a: (tensor) Ground truth bounding boxes, <br/>                 Shape:    [num_objects,4]<br/>          box_b: (tensor) Prior boxes from priorbox layers, <br/>                 Shape: [num_priors,4]<br/>       Return:<br/>          jaccard overlap: (tensor) <br/>                           Shape: [box_a.size(0), box_b.size(0)]<br/>    """<br/>    inter = intersect(box_a, box_b)<br/>    area_a = ((box_a[:, 2] - box_a[:, 0]) *<br/>              (box_a[:, 3] - <br/>               box_a[:, 1])).unsqueeze(1).expand_as(inter)<br/>    area_b = ((box_b[:, 2] - box_b[:, 0]) *<br/>              (box_b[:, 3] - <br/>               box_b[:, 1])).unsqueeze(0).expand_as(inter)  <br/>    union = area_a + area_b - inter<br/>    return inter / union  # [A,B]</span></pre><p id="3595" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，作者使用同样的技巧来计算每个盒子的面积，然后得到并集。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="20b8" class="lc ld iq mf b gy mj mk l ml mm">def match(threshold, truths, priors, variances, <br/>          labels, loc_t, conf_t, idx):<br/>    """Match each prior box with the ground truth box of <br/>       the highest jaccard overlap, encode the bounding boxes,<br/>       then return the matched indices corresponding to both <br/>       confidence and location preds.<br/>    <br/>       Args:<br/>         threshold: (float) The overlap threshold <br/>                    used when mathing boxes.<br/>         truths: (tensor) Ground truth boxes, <br/>                 Shape: [num_obj, num_priors].<br/>         priors: (tensor) Prior boxes from priorbox layers, <br/>                 Shape: [n_priors,4].<br/>         variances: (tensor) Variances corresponding <br/>                    to each prior coord,<br/>                    Shape: [num_priors, 4].<br/>         labels: (tensor) All the class labels for the image,<br/>                 Shape: [num_obj].<br/>         loc_t: (tensor) Tensor to be filled w/ endcoded <br/>                location targets.<br/>         conf_t: (tensor) Tensor to be filled w/ matched <br/>                 indices for conf preds.<br/>         idx: (int) current batch index<br/>       Return:<br/>         The matched indices corresponding to <br/>         1)location and 2)confidence preds.<br/>    """<br/>    # jaccard index<br/>    overlaps = jaccard(<br/>        truths,<br/>        point_form(priors)<br/>    )<br/>    # (Bipartite Matching)<br/>    # [num_objects, 1] best prior for each ground truth<br/>    best_prior_overlap, best_prior_idx = overlaps.max(1)<br/>    # [1, num_priors] best ground truth for each prior<br/>    best_truth_overlap, best_truth_idx = overlaps.max(0)<br/>    best_truth_idx.squeeze_(0)<br/>    best_truth_overlap.squeeze_(0)<br/>    best_prior_idx.squeeze_(1)<br/>    best_prior_overlap.squeeze_(1)<br/>    # ensure best prior    <br/>    best_truth_overlap.index_fill_(0, best_prior_idx, 2)     <br/>    for j in range(best_prior_idx.size(0)):<br/>        best_truth_idx[best_prior_idx[j]] = j<br/>    # Shape: [num_priors,4]<br/>    matches = truths[best_truth_idx] <br/>    # Shape: [num_priors]         <br/>    conf = labels[best_truth_idx] + 1<br/>    # label as background<br/>    conf[best_truth_overlap &lt; threshold] = 0  <br/>    loc = encode(matches, priors, variances)<br/>    # [num_priors,4] encoded offsets to learn<br/>    loc_t[idx] = loc    <br/>    # [num_priors] top class label for each prior<br/>    conf_t[idx] = conf</span></pre><p id="fea0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mw">(</em><a class="ae lb" href="http://pytorch.org/docs/master/torch.html#torch.max" rel="noopener ugc nofollow" target="_blank"><em class="mw">tensor . max</em></a><em class="mw">和 Tensor.min 在传递一个</em> <code class="fe mx my mz mf b"><em class="mw">dim</em></code> <em class="mw">参数时返回两个张量:1。沿指定轴的实际最大/最小值。2.沿该轴的最大/最小值的索引)</em></p><p id="08de" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mw">(</em><a class="ae lb" href="http://pytorch.org/docs/master/tensors.html#torch.Tensor.squeeze_" rel="noopener ugc nofollow" target="_blank"><em class="mw">Tensor.squeeze _</em></a><em class="mw">是 tensor . squeeze 的就地版本，返回一个去掉了所有尺寸为 1 的维度的张量。)</em></p><p id="477c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mw">(</em><a class="ae lb" href="http://pytorch.org/docs/master/tensors.html#torch.Tensor.index_fill_" rel="noopener ugc nofollow" target="_blank"><em class="mw">tensor . index _ fill _</em></a><em class="mw">用传递的索引值填充原始张量的元素)</em></p><p id="e710" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">还记得我们从<em class="mw">那里得到的 prior_box.py </em>是(cx，cy，w，h)格式吗？这里我们用<code class="fe mx my mz mf b">point_from</code>将其转换成(xmin，ymin，xmax，ymax)格式。为了节省空间，代码没有公布(<a class="ae lb" href="http://layers/box_utils.py" rel="noopener ugc nofollow" target="_blank">在这里找到</a>)。</p><p id="df17" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这部分代码可能是最令人困惑的:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="8d47" class="lc ld iq mf b gy mj mk l ml mm"># ensure best prior    <br/>best_truth_overlap.index_fill_(0, best_prior_idx, 2)     <br/>for j in range(best_prior_idx.size(0)):<br/>    best_truth_idx[best_prior_idx[j]] = j</span></pre><p id="116d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">张量<em class="mw"/><strong class="kh ir"><em class="mw">best _ prior _ idx</em></strong>包含每个基础事实框的最佳匹配默认框的索引。所以第一行代码要做的是确保每个基本事实框至少有一个默认框通过了阈值。</p><p id="c889" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">for 循环将变化从第一行传播回张量<strong class="kh ir"> <em class="mw"> best_truth_idx </em> </strong>，<em class="mw"> </em>，该张量包含每个默认框的最佳匹配基础真值框的索引。这种循环的效果是，当存在更需要它的另一个基本事实时，迫使先前的框放弃原始的最佳匹配基本事实(否则没有用于该基本事实的默认框)。</p><p id="f9d4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，我们将每个默认框与一个真实背景相匹配，并为所有最大 Jaccard 重叠小于阈值(即背景)的默认框分配一个特殊的标签/类别零<strong class="kh ir">。</strong></p><p id="14d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有一个<code class="fe mx my mz mf b">encode</code>函数将匹配的真实和默认框对转换成损失函数理解的格式。损失函数将在下一篇文章中讨论。</p><h1 id="fc8b" class="oa ld iq bd le ob oc od lh oe of og lk jw oh jx ln jz oi ka lq kc oj kd lt ok bi translated">待续</h1><p id="3831" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">我们讨论了如何将缺省框映射到实际坐标，以及如何匹配基础真值框和缺省框。这比我预期的要长，所以将会有第 3 部分讨论目标函数，最后是如何在测试阶段预测/检测。</p><p id="33be" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">(2017/07/28 更新:这里是该系列第三部的<a class="ae lb" href="https://medium.com/@ceshine/learning-note-single-shot-multibox-detector-with-pytorch-part-3-f0711caa65ad" rel="noopener">链接)</a></p></div></div>    
</body>
</html>