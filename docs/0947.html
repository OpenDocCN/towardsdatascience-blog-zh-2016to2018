<html>
<head>
<title>Galaxy Zoo classification with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Keras对银河动物园进行分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/galaxy-zoo-classification-with-keras-219184aff581?source=collection_archive---------2-----------------------#2017-07-12">https://towardsdatascience.com/galaxy-zoo-classification-with-keras-219184aff581?source=collection_archive---------2-----------------------#2017-07-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/860f195e408aa23a41450e2fc07061e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*YyZpqjCKkoKx-au9.jpg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">A typical <a class="ae jd" href="https://en.wikipedia.org/wiki/Spiral_galaxy" rel="noopener ugc nofollow" target="_blank">spiral galaxy</a>, we’re going to build a convolutional neural network to classify these guys. Taken from wikipedia.</figcaption></figure><div class=""/><p id="1e1d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">完整的代码可以在我的Github上的</em><a class="ae jd" href="https://github.com/jameslawlor/kaggle_galaxy_zoo" rel="noopener ugc nofollow" target="_blank"><em class="lb">【https://github.com/jameslawlor/kaggle_galaxy_zoo】</em></a><em class="lb">找到。</em></p><p id="cb86" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我最近参加了几周的关于实用深度学习的<a class="lc ld ep" href="https://medium.com/u/34ab754f8c5e?source=post_page-----219184aff581--------------------------------" rel="noopener" target="_blank">杰瑞米·霍华德</a>和<a class="lc ld ep" href="https://medium.com/u/ee56d0bac1b7?source=post_page-----219184aff581--------------------------------" rel="noopener" target="_blank">瑞秋·托马斯</a>优秀<em class="lb"> fast.ai </em> MOOC。我过去学过几门神经网络课程，虽然我理解数学和理论，但我没有太多使用常用工具的实践经验，比如TensorFlow和keras。这个课程用一种“自顶向下，代码优先”的方法完美地填补了我的知识空白，非常令人耳目一新。</p><p id="64cb" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以直接进入正题:本课程第二课的作业是为我们选择的数据集创建一个深度学习模型。我选择<a class="ae jd" href="https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge" rel="noopener ugc nofollow" target="_blank"> Kaggle银河动物园竞赛</a>是因为太空相当酷。比赛是大约4年前直播的，所以我来参加派对有点晚了！在这篇文章中，我将介绍我的解决方案，它的RMSE得分为0.12875，这将使我处于排行榜的上半部分。对于几个小时的工作来说还不错。当然还有很多需要改进和试验的地方，我将在最后谈到，但我对结果很满意，因为我现在对<em class="lb"> keras更加熟悉和熟悉了。</em>我在谷歌的前几页没有找到任何关于银河动物园与<em class="lb"> keras </em>比赛的代码或演练，也许是因为比赛已经有4年了，而keras是两年前才发布的，所以希望这对试图解决这个问题的人有用。</p><h1 id="59ff" class="le lf jg bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">数据准备</h1><p id="1676" class="pw-post-body-paragraph kd ke jg kf b kg mc ki kj kk md km kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">在训练集中有大约60，000幅图像，在测试集中有80，000幅图像，每幅图像都是424x424彩色JPEG。通过检查图像，您可以看到只有图像的中心部分是有用的。我决定围绕中心裁剪为212x212，并向下采样到一半分辨率，以减少我们必须调整的参数数量。</p><div class="mh mi mj mk gt ab cb"><figure class="ml is mm mn mo mp mq paragraph-image"><img src="../Images/e9a918c82bf186f89fc78223990fdaac.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*QZLWiJOF9lW2b0TcVQg6XQ.png"/></figure><figure class="ml is mm mn mo mp mq paragraph-image"><img src="../Images/1f1cb485bf7fde23210b41163ab71f9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*kji2v7yueSiCEW4rAwCZ1Q.png"/><figcaption class="iz ja gj gh gi jb jc bd b be z dk mr di ms mt">Left — An example from the training data. We only really care about the centre of each image, so crop and downsample to get the image on the right.</figcaption></figure></div><p id="ae86" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">完成此操作的代码如下:</p><figure class="mh mi mj mk gt is"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="6167" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一个考虑是，我们有大量的训练和测试数据，太多了，无法加载到GPU内存中。我编写了一些<em class="lb">批处理生成器</em>来顺序抓取一批图像，通过图像处理代码运行它们，然后将它们的解码数据传递给卷积神经网络(CNN)。下面是批处理生成器代码的一个例子</p><figure class="mh mi mj mk gt is"><div class="bz fp l di"><div class="mu mv l"/></div></figure><h1 id="f4ad" class="le lf jg bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">模型架构</h1><figure class="mh mi mj mk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mw"><img src="../Images/68f0a7761d0c669d00d16097975f7f04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sIi63vhlOiQ6cngw.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Similar to my model architecture. Taken from <a class="ae jd" href="http://blog.christianperone.com" rel="noopener ugc nofollow" target="_blank">http://blog.christianperone.com</a></figcaption></figure><p id="3ba9" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我决定采用类似VGG16的CNN架构——这是一堆卷积/Max池层，后面是一些大型FC块和最后一个37级sigmoidal激活层，用于预测星系级概率。我选择这种架构是因为众所周知VGG16在图像问题上做得非常好，网上的共识似乎是它在易于实现、训练时间和体面的结果之间取得了良好的平衡。有一种方法可以通过简单的导入在keras中加载预训练的VGG16，然后您可以通过微调来适应您的问题，但我选择通过从头构建和训练来做一些困难的事情。所以你不会认为我在GPU时间上浪费金钱是完全疯狂的，我的动机是我想看看一个“新鲜”的神经网络在问题中会如何表现。我的理由是，因为我们希望我们的网络在星系数据集中检测和识别的功能和类别与ImageNet相比并不庞大，ImageNet是“真正的”可预加载VGG16经过数周训练的，包含来自狗或牙齿或战舰的对象。因此，我们不应该需要长时间的训练来获得好的结果，因为输入之间的差异不是很大。我会试着想象一些模型过滤器来测试这个想法，并在我有时间的时候编辑它。这是我心中的一个很好的例子<a class="ae jd" href="https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html" rel="noopener ugc nofollow" target="_blank">https://blog . keras . io/how-convolutionary-neural-networks-see-the-world . html</a>。</p><p id="c586" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基于模型简单的想法，如果我们移除或减少一些层，看看我的模型如何工作会很有趣。我有一种预感，完整的VGG16架构对这个问题来说可能是大材小用，但YOLO正如古语所说。</p><p id="2148" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是实现该架构的代码:</p><figure class="mh mi mj mk gt is"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="79c9" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我用的是RMSProp优化器，学习率1.0e-6。这是训练的样子，我从训练集中拿出4000张图片放在一个单独的文件夹中进行验证。</p><figure class="mh mi mj mk gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mx"><img src="../Images/0b83048b185985c88208c1a7d3945726.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ys3jDnzoawz9XMaJpK3_mQ.png"/></div></div></figure><p id="7ffe" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在具有1/2 K80 GPU的Azure NV6机器上，训练进行了大约90分钟，进行了42个周期(提前停止)。</p><h1 id="ee66" class="le lf jg bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">摘要</h1><p id="cbf3" class="pw-post-body-paragraph kd ke jg kf b kg mc ki kj kk md km kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">这个模型获得了0.12875的RMSE分数，从开始编码到提交Kaggle只需几个小时，这将使我处于排行榜的上半部分。有很多方法可以改进模型，我可能会回来，特别是数字预测——这些不是典型的概率，而是不同类别之间的加权。37个类中的每一个的简单的sigmoid是天真的，没有捕捉到这个条件。我还想尝试更简单的架构、改进的图像处理等等。我可能会在某个时候回来，因为我确实很喜欢它，但现在我专注于完成<em class="lb"> fast.ai </em>课程。</p><p id="627b" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你对改编我的方法感兴趣，代码在我的Github上，在https://github.com/jameslawlor/kaggle_galaxy_zoo。同样值得一提的是竞赛获胜者Sander Dieleman的评论，可以在他们位于http://benanne.github.io/2014/04/05/galaxy-zoo.htmlT2的博客上找到。</p></div></div>    
</body>
</html>