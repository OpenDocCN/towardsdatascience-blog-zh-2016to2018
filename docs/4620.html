<html>
<head>
<title>Automatic Speech Recognition Data Collection with Youtube V3 API, Mask-RCNN and Google Vision API</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Youtube V3 API、Mask-RCNN 和 Google Vision API 自动收集语音识别数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automatic-speech-recognition-data-collection-with-youtube-v3-api-mask-rcnn-and-google-vision-api-2370d6776109?source=collection_archive---------3-----------------------#2018-08-26">https://towardsdatascience.com/automatic-speech-recognition-data-collection-with-youtube-v3-api-mask-rcnn-and-google-vision-api-2370d6776109?source=collection_archive---------3-----------------------#2018-08-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/eda2738283d75739f191b3a4466af20b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7pACR7XSrtGIUuZHwyWbrw.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Image source: Pixabay</figcaption></figure><h1 id="4ec2" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">背景</h1><p id="4069" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">随着机器学习特别是深度学习的快速发展，语音识别得到了显著的提高。这种技术依赖于大量高质量的数据。然而，为非流行语言建立的模型比那些流行语言(如英语)的模型表现差。这是因为只有几个可用的训练数据集，并且很难有效地收集高质量的数据。这篇博文将向你展示如何高效地<strong class="lc ir"/><strong class="lc ir">收集任何语言的语音识别数据</strong>。</p><p id="9a5f" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">虽然 Mozilla 去年推出了一个名为<a class="ae md" href="https://mzl.la/voice" rel="noopener ugc nofollow" target="_blank"> Common Voice </a>的开源项目，鼓励人们贡献自己的声音，但大多数人要么不知道这个项目，要么不愿意参与其中。下图显示了来自 Common Voice 的不同语言的小数据收集进度。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi me"><img src="../Images/5526f91f05be34cf101a808d85ec9d9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pzNkK8Md5Fg7u2NOYshZ0Q.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Little collection progress of Common Voice (<a class="ae md" href="https://voice.mozilla.org/en/languages" rel="noopener ugc nofollow" target="_blank">https://voice.mozilla.org/en/languages</a>)</figcaption></figure><p id="b60a" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">由于 Youtube 上有大量的电视节目和电视剧，几乎没有人的参与，就可以高效地收集语音识别数据。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mj"><img src="../Images/208cdb39541e5d41b9bb5a7a24e39467.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G7o1a9qaaVuNM504k_iFCg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Ｍeteor Garden (<a class="ae md" href="https://www.youtube.com/watch?v=DsuN185H58I&amp;list=PLpSFccUgAbkHgWFjKDUMPX70gLsNoe90T&amp;ab_channel=BingLawSir" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=DsuN185H58I</a>)</figcaption></figure><p id="4c29" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">如上图所示，这些剧或者节目中，有的嵌入了字幕，可以通过 OCR 提取出来。提取的文本和剪辑的音频可以形成语音识别数据的样本。</p><h1 id="c1b1" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">概观</h1><p id="0574" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">下图概述了包含几个模块的整个数据收集管道。我们首先使用 Youtube V3 API 来搜索下载与我们指定的电视节目名称相关联的视频。FFMPEG 被用来将视频分割成帧，每个帧都由一个自训练的 Mask-RCNN(稍后将详细介绍)进行处理，以仅保留图像的字幕区域。然后，处理后的图像被发送到 Google Vision API，以获得预测的文本和置信度。通过 Pandas 库，我们按照时间戳对结果进行排序，然后将它们聚合起来，为每个视频生成一个 SRT 文件。下面将向您展示如何实现这些模块。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mk"><img src="../Images/747ad36bda72fcfac1efa2dfa8a5d992.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XPxJ4kXxDJSWNATr"/></div></div></figure><h1 id="1228" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">先决条件</h1><ul class=""><li id="4487" class="ml mm iq lc b ld le lh li ll mn lp mo lt mp lx mq mr ms mt bi translated">Python==3.6</li><li id="5da3" class="ml mm iq lc b ld mu lh mv ll mw lp mx lt my lx mq mr ms mt bi translated">FFMPEG</li><li id="db45" class="ml mm iq lc b ld mu lh mv ll mw lp mx lt my lx mq mr ms mt bi translated">joblib==0.12.0</li><li id="4f1d" class="ml mm iq lc b ld mu lh mv ll mw lp mx lt my lx mq mr ms mt bi translated">numpy==1.13.3</li><li id="08e7" class="ml mm iq lc b ld mu lh mv ll mw lp mx lt my lx mq mr ms mt bi translated">熊猫==0.23.3</li><li id="70b5" class="ml mm iq lc b ld mu lh mv ll mw lp mx lt my lx mq mr ms mt bi translated">张量流-gpu==1.4.0</li><li id="1d83" class="ml mm iq lc b ld mu lh mv ll mw lp mx lt my lx mq mr ms mt bi translated">keras==2.1.3</li><li id="0e93" class="ml mm iq lc b ld mu lh mv ll mw lp mx lt my lx mq mr ms mt bi translated">谷歌云视觉==0.32.0</li><li id="7935" class="ml mm iq lc b ld mu lh mv ll mw lp mx lt my lx mq mr ms mt bi translated">pafy==0.5.4</li><li id="3bd3" class="ml mm iq lc b ld mu lh mv ll mw lp mx lt my lx mq mr ms mt bi translated">youtube-dl==2017.12.2</li><li id="de73" class="ml mm iq lc b ld mu lh mv ll mw lp mx lt my lx mq mr ms mt bi translated">tqdm==4.23.4</li><li id="f007" class="ml mm iq lc b ld mu lh mv ll mw lp mx lt my lx mq mr ms mt bi translated">编辑距离==0.4</li></ul><h1 id="e337" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">履行</h1><p id="b6ba" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">该部分由数据收集管道中的模块划分，每个子部分对应一个模块。</p><h2 id="c4ce" class="mz kd iq bd ke na nb dn ki nc nd dp km ll ne nf kq lp ng nh ku lt ni nj ky nk bi translated">下载视频和提取音频</h2><p id="1738" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">去 Youtube 搜一部你感兴趣的电视剧。确保您可以找到该节目播放列表，因为播放列表中的视频质量趋于一致。检查第一个视频是否包含嵌入的字幕，我们可以假设整个播放列表都是嵌入字幕的。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nl"><img src="../Images/83acc0beb9b4b6af671c8b881aa0bc87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ytWkeyglYHJstkbJolyTLw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Youtube videos in a playlist</figcaption></figure><figure class="mf mg mh mi gt jr"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="0494" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">上面的代码向你展示了如何搜索 Youtube 播放列表。您需要申请一个 API 密钥才能使用 Youtube V3 API 客户端。在第 27 行，</p><pre class="mf mg mh mi gt no np nq nr aw ns bi"><span id="2583" class="mz kd iq np b gy nt nu l nv nw">youtube.search().list(q=name, type="playlist",part="id",maxResults=1).execute()</span></pre><p id="57c8" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">使用 query 作为戏剧名称执行 Youtube 搜索，并返回第一个结果的播放列表 id。</p><p id="f0b4" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">有了播放列表 ID，我们就可以得到这个播放列表中所有视频的视频 ID。</p><figure class="mf mg mh mi gt jr"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="b83c" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">类似地，在第 15 行，</p><pre class="mf mg mh mi gt no np nq nr aw ns bi"><span id="d384" class="mz kd iq np b gy nt nu l nv nw">youtube.playlistItems().list(part='contentDetails',maxResults=50, playlistId=playlist_id).execute()</span></pre><p id="5e36" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">给定播放列表 ID，搜索多达 50 个视频的 ID(受 API 限制)。</p><p id="9963" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">然后，我们可以开始下载视频。</p><figure class="mf mg mh mi gt jr"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="9286" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">Pafy Python 包用于下载可用的最高分辨率的视频。下载完视频后，我们利用 FFMPEG 从每个视频中提取音频。</p><figure class="mf mg mh mi gt jr"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="45f5" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">由于 FFMPEG 不支持 python SDK，我们需要在 shell 中调用它。通过触发 subprocess.call()函数，我们可以执行参数中指定的 shell 命令。现在，您已经成功下载了您指定的电视节目的视频和音频。</p><h1 id="5b67" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">分割视频</h1><p id="599e" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">然后，我们将下载的视频分割成帧，并运行 OCR。</p><figure class="mf mg mh mi gt jr"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="5e94" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">只有视频的中间 60%部分被分割成帧，因为第一和最后 20%部分可能包含开始或结束歌曲，这不能用于语音识别。</p><p id="d59c" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">同样，在 shell 中用子进程调用 FFMPEG。分割视频的参数描述如下:</p><ul class=""><li id="8875" class="ml mm iq lc b ld ly lh lz ll nx lp ny lt nz lx mq mr ms mt bi translated">ss:以秒为单位的开始时间</li><li id="6add" class="ml mm iq lc b ld mu lh mv ll mw lp mx lt my lx mq mr ms mt bi translated">t:分割视频的时间跨度，单位为秒</li><li id="5b46" class="ml mm iq lc b ld mu lh mv ll mw lp mx lt my lx mq mr ms mt bi translated">r:采样速率</li></ul><p id="acbf" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">采样率越高，预测的字幕时间跨度就越精确。然而，在时间和准确性之间有一个权衡。在这里，我把它设置为 2。</p><h1 id="21ae" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">训练和评估 Mask-RCNN</h1><p id="0afe" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">现在，你已经有了每个视频的画面。如果你在<a class="ae md" href="https://cloud.google.com/vision/docs/ocr" rel="noopener ugc nofollow" target="_blank"> Google Vision API 官网试用几张图片进行 OCR </a>(文档文本检测，由于字幕是打字字符)。你会发现结果并不令人满意，因为这些图像的背景非常复杂。</p><p id="f8a5" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">这就是 Mask-RCNN 发挥作用的时候。Mask-RCNN 是 2017 年发布的用于对象检测和实例分割的 RCNN 家族的一部分。它能够在像素级别进行分类。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oa"><img src="../Images/3500f9323fd63d00efab3ee21da572db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*l7FhDl7tgjLByOXM.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Mask-RCNN demo (<a class="ae md" href="https://github.com/matterport/Mask_RCNN" rel="noopener ugc nofollow" target="_blank">https://github.com/matterport/Mask_RCNN</a>)</figcaption></figure><p id="39d5" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">我们的目标是训练 Mask-RCNN 来帮助我们识别哪些像素是字幕。</p><h2 id="5899" class="mz kd iq bd ke na nb dn ki nc nd dp km ll ne nf kq lp ng nh ku lt ni nj ky nk bi translated">培养</h2><p id="5477" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">为了确保训练好的模型足够通用，适合各种视频，我从十几部电视剧和动画中下载了视频。应用不同的字体大小、字体类型和字体垂直位置来丰富训练数据集。底部 40%的图像被裁剪，以确保手动添加到训练数据上的字幕不会与原始字幕重叠。这也确保了非字幕部分来自高度相似的色彩空间分布。</p><figure class="mf mg mh mi gt jr"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="df4d" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi">The above code leverages Python PIL package to add texts onto images. Since Mask-RCNN treats each connected component as an instance, in some languages, a character can be composed of different instances. For example, the character “把” comprises the left and right two components. To find the connected component, we can use the label() function in the skimage package as shown in the following code.</p><figure class="mf mg mh mi gt jr"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="bf6a" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">生成的训练数据显示在下图中。左侧显示输入图像，而右侧显示地面实况。正如您从右侧一些字符的颜色差异中所看到的，一个字符可以由几个实例组成。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ob"><img src="../Images/bdb3d6e5b7558e7e5f7593a6258d2ca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zx-HUfd1Ro8NooRuf56WlA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Generated Mask-RCNN Training Data</figcaption></figure><p id="8837" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">为了训练 Mask-RCNN，我在这个<a class="ae md" href="https://github.com/matterport/Mask_RCNN" rel="noopener ugc nofollow" target="_blank"> Github Repo </a>中使用了一个使用 Keras 和 Tensorflow 的优秀实现。我们需要做的是指定我们的训练模型的配置，如下所示。</p><figure class="mf mg mh mi gt jr"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="d158" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">你只需要设置 NUM_CLASSES = 1+1(字幕+背景)，指定 IMAGE_MIN_DIM 以及 IMAGE_MAX_DIM，这取决于你训练数据的分辨率。MEAN_PIXEL 需要手动计算，以便在预处理阶段标准化。然后，就可以开始加载数据和训练了。</p><h2 id="aa51" class="mz kd iq bd ke na nb dn ki nc nd dp km ll ne nf kq lp ng nh ku lt ni nj ky nk bi translated">估价</h2><p id="61bb" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">在训练了 100 个纪元之后，让我们开始在一些图像上运行训练好的模型。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oc"><img src="../Images/c41b5c002621e764d9f62ce42a9b18d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0M-prvpchsOlZu4MKhoziQ.png"/></div></div></figure><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi od"><img src="../Images/7dbe7cb4582ee099f5fb69f9bd431f39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LYiNVnUTFG5ISIgc72X3BQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Evaluation Results on Different TV Shows</figcaption></figure><p id="026c" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi">The left shows the input images, whereas the right show the output one. You can see that the subtitle has been clearly identified. Although there are some noise above they have no effect on the prediction of the subtitle below when running OCR. The main issue is that sometimes Mask-RCNN is too strict that it removes some parts of the text. In the second example above, the second character “難” was partially erased, which might decrease the performance of OCR. In order to recover this error, I decided to use Ensemble.</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oe"><img src="../Images/26c51e4d93109946b642054e17f5626a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YhqI2OZIUYEsKFl0-xC8Rw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Single model prediction</figcaption></figure><p id="417c" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">集成是指使用多个模型进行预测。我没有使用上图所示的单一模型进行预测，而是训练了另一个具有不同配置的模型。输入图像被输入到这两个模型中，最终结果将是这两个模型预测的联合。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/4f1188c94b5f9ffbd5c963d28eaf624e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VKUZIiBu5pEDH_a8kdSBdw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Ensemble prediction</figcaption></figure><p id="c3f0" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">由 Mask-RCNN 处理的结果帧如下所示。左下方是原始输入图像，右下方是只有一个模型的预测，左上方是集成结果。(右上方是测试时间增强结果，该结果已被当前管道中的系综所取代)</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi og"><img src="../Images/dd4c0104647fb6d6b4d46f8c9a26e631.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NmgguUv8p2U0BoUp4BvYqg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Mask-RCNN processed images. bottom-left: original. bottom-right: single model. top-left: ensemble. top-right: test-time-augmented (not discussed).</figcaption></figure><h1 id="613e" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">运行 OCR</h1><p id="53c9" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">用 Mask-RCNN 模块处理完图像后，我们就可以对这些图像运行 OCR 了。与 Youtube API Key 不同的是，你需要在 Google 云平台上申请一个 Vision API 凭据，并存储在本地磁盘中。</p><figure class="mf mg mh mi gt jr"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="4e71" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">上面的代码编码你的图像文件，发送到 OCR API，并接收响应。响应包含预测字符、每个字符的边界框坐标以及每个字符的置信度。您可以决定自己的阈值来过滤掉低置信度的结果。最终结果被写入 CSV 文件，每行代表一帧。</p><figure class="mf mg mh mi gt jr"><div class="bz fp l di"><div class="nm nn l"/></div></figure><h1 id="8b0a" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">生成 SRT 最终结果</h1><p id="b6fb" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">最后，流水线的最后一个模块来了！通常一段字幕持续 2-3 秒，这意味着大约有 4-6 个连续的帧包含相同的字幕。剩下的问题是我们如何将不同帧的结果合并成一个，决定演讲的开始时间、结束时间和字幕。我们只需要检查当前字幕是否与上一个匹配。一个主要挑战是，有时两个帧具有相同的字幕，但 OCR 预测了不同的结果。你判断两个字幕是否相同的算法应该可以处理这些情况。</p><figure class="mf mg mh mi gt jr"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="1634" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">上面的代码是基于启发式的。如果当前帧和最后一帧的这两个字符串中的字符有 70%相同，而不考虑每个字符的顺序，则返回 True。</p><h1 id="25b2" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">结论</h1><p id="03c0" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">如果您正确地遵循了上面的说明，那么您已经成功地构建了一个自动语音识别数据集收集管道。您可以很容易地根据 FFMPEG 指定的时间分割音频，但我将把这留给您。一个小问题是，由于字幕出现的时间和相应语音的时间可能有些不同，所以语音和文本之间可能会有一点不对齐。这可以通过语言模型来解决，以根据语音稍微调整每个字幕的时间。更多信息和详细实现，请参考本<a class="ae md" href="https://github.com/khuangaf/ITRI-speech-recognition-dataset-generation" rel="noopener ugc nofollow" target="_blank"> Github Repo </a>。如果您有任何问题，请随时通过电子邮件联系我:【huangkh19951228@gmail.com<a class="ae md" href="http://huangkh19951228@gmail.com" rel="noopener ugc nofollow" target="_blank"/>。</p></div></div>    
</body>
</html>