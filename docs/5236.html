<html>
<head>
<title>The Ethics of Digitally Networked Beings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数字网络生物的伦理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-ethics-of-digitally-networked-beings-82de76fec3b3?source=collection_archive---------17-----------------------#2018-10-05">https://towardsdatascience.com/the-ethics-of-digitally-networked-beings-82de76fec3b3?source=collection_archive---------17-----------------------#2018-10-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="8b89" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">“算法无法领悟真理。他们只是重复过去。”—凯西·奥尼尔</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/bb1c2b24bee6d3ae9b1dafbfbd5d69c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xm0fAgKkCI37WbamXsFLQA.jpeg"/></div></div></figure><p id="6894" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">自从我读了凯茜·奥尼尔的<em class="kx">数学毁灭的武器，</em>以来，基于算法的决策中的伦理问题一直在我的脑海中挥之不去，它提出了一个令人信服的论点，即我们的算法通过将人类偏见编码到我们的技术中，正在延续、巩固甚至放大不公正的模式。我目前正在阅读的弗吉尼亚·尤班克斯的《T2:不平等的自动化》(T3)只会加深这些担忧。</p><p id="4390" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们正在做什么来防止技术造成伤害？我想知道。我开始研究当前的努力，发现了许多从事伦理和人工智能领域工作的组织——<a class="ae ky" href="https://ainowinstitute.org/" rel="noopener ugc nofollow" target="_blank">人工智能研究所</a>、<a class="ae ky" href="https://deepmind.com/applied/deepmind-ethics-society/" rel="noopener ugc nofollow" target="_blank">深度思维伦理学会、</a> <a class="ae ky" href="https://www.partnershiponai.org/" rel="noopener ugc nofollow" target="_blank">人工智能合作伙伴</a>，仅举几例。凯茜·奥尼尔创办了一家审计算法的<a class="ae ky" href="http://www.oneilrisk.com/#about-1-section" rel="noopener ugc nofollow" target="_blank">公司，而像</a><a class="ae ky" href="http://ai-4-all.org/" rel="noopener ugc nofollow" target="_blank"> AI4ALL </a>这样的非营利组织正在从另一个角度解决这个问题，通过为未被充分代表的人才建立管道来增加人工智能的多样性和包容性。</p><p id="72db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这个过程中，我偶然发现了<a class="ae ky" href="https://standards.ieee.org/industry-connections/ec/autonomous-systems.html" rel="noopener ugc nofollow" target="_blank"> <em class="kx">伦理上一致的设计:用自主和智能系统优先考虑人类福祉的愿景</em> </a>，这是电气和电子工程师协会(IEEE)的一个项目。IEEE 是一个由工程师、科学家和相关专业人员组成的大型专业组织，参与编写该文件的 250 名专业人员被描述为来自“六大洲的参与者，他们是来自学术界、工业界、公民社会、政策和政府的思想领袖。”该指南目前是一个提案，被命名为“第二版——公众讨论”提交意见的截止日期已经过了，但是反馈(超过 72 个人/组织的超过 316 页的反馈)已经公布在网上，所以我也通读了一遍。该文件的最终版本将于 2019 年发布。</p><p id="4d7d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">执行摘要的开头是:</p><blockquote class="kz"><p id="14c4" class="la lb iq bd lc ld le lf lg lh li kk dk translated">随着自主智能系统(A/IS)的使用和影响变得无处不在，我们需要建立社会和政策指南，以便这些系统保持以人为本，服务于人类的价值观和伦理原则。</p></blockquote><p id="bdf6" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">我带着兴趣、欣赏和紧迫感读了下去，无论是在合作和所涉及的专业知识方面，还是在文件本身的范围方面，我都对这一努力的规模印象深刻，这一范围从经典伦理到性爱机器人，从福祉指标到自主和智能系统的法律地位。</p><p id="fb30" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我不想在这里总结 263 页的提案草案和对它的广泛评论。相反，我选择了一些我认为特别发人深省的段落。</p><p id="c47b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，起初，我对文件语言中的预设印象最深，这些预设让我感到惊讶，例如:“如果自治系统是我们信任的、有创造力的伙伴”，或者“人类将面临更大的压力，以有效地与这些系统‘合作’。”我一直认为技术是一种工具，但这些描述意味着一种不同的关系，一种更加合作和平等的关系。这份文件承诺为技术与人类价值观的结合提供指导，但有时我发现它令人担忧。关于混合现实的一个候选推荐(“其中<a class="ae ky" href="https://standards.ieee.org/content/dam/ieee-standards/standards/web/documents/other/eadv2_glossary.pdf" rel="noopener ugc nofollow" target="_blank">真实世界和虚拟</a>世界对象一起呈现在单个显示器内”)如下:</p><blockquote class="kz"><p id="aaa7" class="la lb iq bd lc ld le lf lg lh li kk dk translated">就混合现实的性质将如何影响我们的社会互动开展广泛的教育，以避免广泛的负面社会后果。</p></blockquote><p id="8e55" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">在这句话的结构中嵌入的不仅仅是潜在的伤害，还有这样一种想法，即在没有<em class="kx">广泛</em>教育干预的情况下使用混合现实可能会产生巨大而有害的影响。当我读到这一行，也是关于混合现实的时候，我感到了类似的不适:</p><blockquote class="kz"><p id="e19f" class="la lb iq bd lc ld le lf lg lh li kk dk translated">通过这种方式，个人可以“满足”自己的社会需求，而无需回报他人的需求。这种通过完全沉浸式技术人为“满足”基本社会需求的方式，可能会对社会结构产生意想不到的影响</p></blockquote><p id="becb" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">社会的基本结构？光是这个索赔的范围就让我很不舒服。该案文尽管仍是草稿，但却是由一个专家小组提出的，并得到了一个大型和非常有声望的组织的赞助。换句话说，我非常认真地对待在此表达的关切和建议。在某一点上，指南建议，好像我们已经忘记了，“广泛的关于积极的人际关系/接触的益处的教育课程。”甚至在提议的标签系统中对图像的选择也让我犹豫了:</p><blockquote class="kz"><p id="66b2" class="la lb iq bd lc ld le lf lg lh li kk dk translated">政府批准的标签系统，如在含有有毒化合物的家用清洁用品上发现的骷髅和交叉骨，可以用于这一目的，以提高用户在与 A/IS 互动时意识到的机会。</p></blockquote><p id="fb67" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">在第 102 页,“真实”这个词的特点让我觉得如此愤世嫉俗，以至于我怀疑自己是否误读了这句话。</p><blockquote class="kz"><p id="bdf5" class="la lb iq bd lc ld le lf lg lh li kk dk translated">对于个人来说，要在算法时代实现并保持个人信息的平等，有必要包括一个主动的算法工具，作为他们在数字和“真实”世界中的代理人或监护人。(“真实”是指物理或公共空间，用户不会意识到自己处于面部识别、生物识别或其他工具的监视之下，这些工具可以跟踪、存储和利用他们的数据，而无需事先征得同意或许可)。</p></blockquote><p id="6a15" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">我们是否创造了一个需要监护人的世界，或者一个相信我们的在线或离线行为都是隐私的错觉世界？我想我们可能有。但这是我们想要的世界吗？这一愿景与我们的福祉一致吗？即使我们想避免，我们能避免吗？</p><p id="00bd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">虽然我对那些从小说中熟悉的想法感到正式到来——以及需要讨论——感到震惊(一个候选建议涉及围绕死亡的新“社会规范”,例如，包括“向家人和朋友发送卡片，让他们知道某人的意识已经从碳基转移到硅上”，但我也觉得这些指导方针正在竞相赶上我们已经达到的水平。我阅读并同意对透明度的呼吁以及个人理解和控制其数字信息的需要，但我们目前也在使用多年来未能满足这些标准承诺的技术。</p><p id="0854" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">“根据皮尤最近的研究，91%的美国成年人认为消费者已经失去了对公司如何收集和使用个人信息的控制，”迈克·奥克特在为<a class="ae ky" href="https://www.technologyreview.com/s/607830/personal-ai-privacy-watchdog-could-help-you-regain-control-of-your-data/" rel="noopener ugc nofollow" target="_blank">麻省理工科技评论撰写的一篇文章中写道。</a>正如 IEEE 指南正确指出的那样，“通过 A/IS 轻松或随意共享的数据可用于做出个人可能不希望共享的推断。”斯坦福大学<a class="ae ky" href="https://www.theguardian.com/technology/2017/sep/07/new-artificial-intelligence-can-tell-whether-youre-gay-or-straight-from-a-photograph" rel="noopener ugc nofollow" target="_blank">的研究</a>就是一个例子，其中公开发布到约会网站的照片被用来训练神经网络来检测性取向。</p><p id="959e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">“弱势群体需要保护，”IEEE 指南指出。老年人和智力受损的成年人被确定，但这些人口统计数据只构成了我所认为的我们最脆弱人口的一部分。“根据美国教育部和国家扫盲研究所的数据，美国约有 3200 万成年人不识字，”瓦莱丽·斯特劳斯在 2016 年为《华盛顿邮报》撰写的一篇文章中写道。“经济合作与发展组织发现，50%的美国成年人不能阅读八年级水平的书籍”，“19%的成年人不能阅读报纸，更不用说填写求职申请了。”我想我可以在“报纸”这个词旁边加上“服务协议条款”，没有人会反对，尽管大多数人，包括我自己，很少阅读它们。</p><p id="b784" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">“‘我已经阅读并同意条款’是网络上最大的谎言。我们的目标是解决这个问题，”<a class="ae ky" href="https://tosdr.org" rel="noopener ugc nofollow" target="_blank">服务条款上这样写道；没看</a>，一个“用户权利倡议对网站条款&amp;隐私政策进行评级和标注，从很好的<strong class="jp ir">A 级</strong>到很差的<strong class="jp ir">E 级</strong>”我发现了这个组织，因为它与 IEEE 指南有联系，我去了那个网站了解更多。谷歌收一个 B 类；脸书和推特——许多人经常使用的社交媒体网站——还“没有上课”，因为即使是这些关心的志愿者也没有“充分审查条款”</p><p id="68ec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">“六年前，34%的青少年每天使用社交媒体超过一次；《常识》杂志最近的一份报告称:“如今，70%的人使用手机，其中 16%的人“几乎经常”使用，另外 22%的人一小时使用几次。”。与其争论青少年是否是一个弱势群体(我会说是的，但这是基于我对年轻时自己的回忆，而不是一项正式的研究)，我想指出这些青少年已经创造的数字记录，一个可能永远留在他们身后的“数字足迹”(我也有一个，但我的数字足迹在晚年才开始加剧)。准则认识到这一点:</p><blockquote class="kz"><p id="db84" class="la lb iq bd lc ld le lf lg lh li kk dk translated">PII 被定义为基于个人独特的物理、数字或虚拟身份可以合理地与个人联系起来的任何数据。因此，通过每一次数字交易(显式的或观察到的)，人类都在生成自己身体的独特数字影子。</p></blockquote><p id="1107" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">你只需要去剑桥大学的<a class="ae ky" href="https://applymagicsauce.com" rel="noopener ugc nofollow" target="_blank"> Apply Magic Sauce </a>，一个“从人类行为的数字足迹中准确预测心理特征的个性化引擎”，看看陌生人可能会从我们的社交媒体使用中推断出我们的什么。该技术承诺:“通过分析你在线行为的各个方面，我们的预测 API 引擎可以让你看到其他人如何看待你，预测一系列变量，包括个性、幸福度、智力、创业潜力等。”“我们的工具旨在帮助人们了解数字自我对其他人来说可能是什么样子，以及这可能会告诉你你到底是谁。”</p><p id="0a44" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我到底是谁？这一说法让我想起了 IEEE 指南中的另一句话——这句话来自经典伦理学的一个章节——它也让我停下来思考，因为它指出人类正开始“将我们的存在转变为数字网络存在”换句话说，不仅仅是技术，人类本身也在进化；我们与技术的关系已经改变了我们的本质。</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><p id="fb64" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">“亚里士多德阐明的幸福是一种实践，它将人类福祉定义为一个社会的最高美德。IEEE 指南解释说:“大致翻译为“繁荣”，幸福生活的好处始于有意识的沉思，伦理方面的考虑帮助我们确定我们希望如何生活。”该准则的任务声明如下:</p><blockquote class="kz"><p id="76ba" class="la lb iq bd lc ld le lf lg lh li kk dk translated">确保参与自主和智能系统设计和开发的每一个利益相关者都受到教育、培训，并有能力优先考虑伦理因素，从而使这些技术为人类造福。</p></blockquote><p id="545e" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">该指南倡导“整体经济繁荣”，而不是“生产率提高或 GDP 增长等单向目标”这种智慧在<a class="ae ky" href="https://www.newyorker.com/contributors/john-lanchester" rel="noopener ugc nofollow" target="_blank">约翰·兰彻斯特</a>的《纽约客》 的<a class="ae ky" href="https://www.newyorker.com/magazine/2018/07/23/can-economists-and-humanists-ever-be-friends" rel="noopener ugc nofollow" target="_blank">文章中有所体现，他在文章中讨论了一种治疗失明的方法:“这个项目取得了巨大的成功，因为它防止了成千上万的人失明，但有一个问题:参与其中的经济学家无法证明这项冒险是值得的。一项成本效益分析是“不确定的”:接受帮助的人太穷了，以至于保护他们视力的好处没有产生太多的金钱影响。"</a></p><p id="46ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本着造福人类而不仅仅是底线的理念，该指南建议我们使用反映福祉的指标，如社会幸福，以更广泛地了解技术的影响。包容性和多样性反复出现，无论是在我们必须考虑的哲学体系方面，还是在技术评审委员会中应该找到的背景和经验范围方面，还是在创建文档本身的过程中。一次又一次，我在这篇文章中听到的信息是技术必须为我们服务；技术应该与我们的福祉相一致。技术应该帮助人类繁荣。</p><p id="e75d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我发现自己在思考自动驾驶汽车。如果将社会福祉考虑在内，我不认为自动驾驶汽车会成为如此多当前伦理和人工智能辩论的试金石。相反，我们应该投资于安全、快捷、廉价的公共交通，并找出最佳的新路线。但是我们有了自动驾驶汽车，现在我们正在努力解决围绕它们的问题，在我们部署它们之前，它们应该有多安全，我们如何判断，它们将如何影响人类和我们的环境，以及汽车本身应该如何做出选择。我们可能正在成为数字化网络生物，但我们也在要求我们的数字技术做出传统上只属于我们自己的决定。IEEE 指南内容如下:</p><blockquote class="kz"><p id="d157" class="la lb iq bd lc ld le lf lg lh li kk dk translated">自动驾驶汽车在决策中对一个因素的优先顺序需要反映其目标用户群体的价值优先顺序，即使这一顺序与个别设计师、制造商或客户的顺序相冲突</p></blockquote><p id="8353" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">2017 年对纽约市居民的一项调查发现，80%的受访者选择“转向以避免撞到行人。”只有 5%的人优先考虑车内乘客(15%的人说“不知道”)；一篇 2016 年的<a class="ae ky" href="https://www.caranddriver.com/news/self-driving-mercedes-will-prioritize-occupant-safety-over-pedestrians" rel="noopener ugc nofollow" target="_blank">汽车和司机</a>报道称，“梅赛德斯-奔驰只是想给它的自动驾驶汽车编程，以拯救车内的人。每次都是。”梅赛德斯-奔驰自动驾驶汽车会被禁止在纽约街道上行驶吗？一辆汽车能根据它的位置自动切换进入或退出杀死行人模式吗？当我点击了一个名为“玩这个杀手级自动驾驶汽车伦理游戏”的<a class="ae ky" href="https://techcrunch.com/2016/10/04/did-you-save-the-cat-or-the-kid/" rel="noopener ugc nofollow" target="_blank"> TechCrunch </a>故事的链接，发现自己在麻省理工学院的<a class="ae ky" href="http://moralmachine.mit.edu" rel="noopener ugc nofollow" target="_blank">道德机器</a>上时，我想到了这些。事实上，当我坐在电脑前选择谁能活下来——怀孕的行人或没怀孕的行人，三名乘客或过马路的单身女人——以及谁会死的时候，我觉得自己好像在玩游戏。我既不是司机也不是行人，我是被排除在外的决策者，在两条车道中选择一条，哪怕只是因为我没有选择直接右转撞墙。</p><p id="d2f2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">IEEE 指南包括一个词汇表<a class="ae ky" href="https://standards.ieee.org/content/dam/ieee-standards/standards/web/documents/other/eadv2_glossary.pdf" rel="noopener ugc nofollow" target="_blank"/>,其中包含术语以及作者确定的在四个专业领域使用的“通用定义”:计算学科；工程；政府、政策和社会科学；伦理和哲学；以及“普通语言”。如果没有确定共同的定义，术语表欢迎提出建议。例如，对于“透明”这个词，普通的语言定义是“容易被看穿、识别、理解或察觉(OED)”；足够的照明来赋予理解；”在工程和计算学科领域，还没有提供透明性的通用定义。当我看到占位符文本时，“我们欢迎推荐！”我再次想到了自动驾驶汽车。该准则指出:</p><blockquote class="kz"><p id="0901" class="la lb iq bd lc ld le lf lg lh li kk dk translated">A/IS 的设计应以透明度和问责制为主要目标。如果可能的话，嵌入在系统中的逻辑和规则必须对系统的监督者可用。然而，如果系统的逻辑或算法不能用于检查，那么必须有替代方法来维护透明度的价值。此类系统应接受风险评估和严格测试。</p></blockquote><p id="3b7e" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">在最近为《卫报》 撰写的一篇文章中，安德鲁·史密斯指出，“目前正在测试的自动驾驶汽车可能包含 1 亿行代码，鉴于没有程序员能够预测现实世界道路上所有可能的情况，他们必须学习并接受不断的更新。”他指出，在汽车无缘无故加速后，对丰田凯美瑞的软件进行故障排除需要 20 个月的时间和两名专家，“揭示了程序员所说的“意大利面条代码”的扭曲质量，充满了算法的碰撞和争斗，产生了异常的、不可预测的输出。”</p><p id="00f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我想起了迪恩·波默罗(Dean Pomerleau)1991 年的自动驾驶汽车研究，这项研究似乎进展顺利，直到有一天他的车驶近一座桥，突然转向。“只有在广泛测试了他的软件对各种视觉刺激的反应后，Pomerleau 才发现了问题，”<a class="ae ky" href="https://www.nature.com/news/can-we-open-the-black-box-of-ai-1.20731" rel="noopener ugc nofollow" target="_blank"> Davide Castelvecchi 为<em class="kx"> Nature </em> </a>写道，“网络一直使用绿草如茵的路边作为道路方向的指南，所以桥的出现让它感到困惑。”</p><p id="41bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我读过一些论点，认为自动驾驶汽车——通过消除分心、疲惫等导致的人为错误——将使我们的街道更加安全。车道可以被花园和带操场的停车场取代。我不认为这是一个糟糕的愿景，但我仍然担心我们如何到达那里，以及当我们到达那里时，谁将能够点击智能手机应用程序，从操场上抢一辆车回家，而谁(从更远的公园或低收入地区打电话，也许)不会。</p><p id="c55a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">明确的说，我想到自动驾驶汽车是因为它们的存在。他们在这里，尽管仍处于测试模式。我阅读 IEEE 的<em class="kx">伦理上一致的设计</em>不仅仅是为了指导我们的未来，也是为了支撑我们现在的世界，因为我们会问，我们到底在哪里？</p><p id="7e8c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">凯茜·奥尼尔在今年早些时候接受《连线》杂志采访时提出了一个令人信服的观点:“我们仍然关注错误的事情。我们并没有衡量对民主造成的实际损害，因为民主很难衡量。相反，我们将关注无人驾驶汽车造成的行人死亡等问题。”</p><p id="2d46" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我承认。我一直在思考很多关于汽车的问题，但话说回来，即使是自动驾驶汽车也可以在反乌托邦的监控状态中发挥作用。<a class="ae ky" href="https://www.economist.com/leaders/2018/03/01/self-driving-cars-offer-huge-benefits-but-have-a-dark-side" rel="noopener ugc nofollow" target="_blank">经济学家</a>报道说:“首先，AVs 将记录他们身边发生的一切。”。"犯罪发生时，警察会询问附近的汽车是否看到了什么。"<a class="ae ky" href="https://www.technologyreview.com/s/612123/the-secret-data-collected-by-dockless-bikes-is-helping-cities-map-your-movement/" rel="noopener ugc nofollow" target="_blank">麻省理工科技评论</a>最近刊登了一篇报道，引起了人们对目前由无人驾驶自行车收集并与城市共享的数据的隐私问题的担忧。</p><p id="0654" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与隐私相关的问题和建议在 IEEE 指南中非常普遍，从数字监护人到表达有意义的同意，再到识别数据滥用的隐私评估，以及承认政府可以访问并可能滥用我们的数据。指导方针如下:</p><blockquote class="kz"><p id="c8b1" class="la lb iq bd lc ld le lf lg lh li kk dk translated">自从技术公司和信号情报机构(如美国国家安全局和英国政府通信总部)之间的合作指控被披露以来，政府大规模监控一直是一个主要问题。</p></blockquote><p id="3d44" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated"><a class="ae ky" href="https://www.eff.org" rel="noopener ugc nofollow" target="_blank">电子前沿基金会</a> (EFF)，在其对草案的<a class="ae ky" href="https://standards.ieee.org/content/dam/ieee-standards/standards/web/documents/other/ead_v2_feedback_rfi_responses.pdf" rel="noopener ugc nofollow" target="_blank">反馈</a>中，以令人钦佩的清晰明了阐述了我们的情况:</p><blockquote class="kz"><p id="08a9" class="la lb iq bd lc ld le lf lg lh li kk dk translated">只有像东德这样的社会，愿意为每 6.5 个公民招募一名线人，才有可能观察和关注所有公民的行动。但是，已经部署的监控技术和用于分析数据的机器学习的结合将意味着彻底的监控成为可能，而不需要投入如此巨大的金钱和劳动力。机器学习实现如此有效的大规模监控的潜力降低了威权主义的价格标签，并对自由开放的社会构成了新的威胁。</p></blockquote><p id="0e8f" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">《大西洋月刊》最近用了整整一期来讨论这个问题，<em class="kx">民主正在消亡吗？</em>在他的作品<a class="ae ky" href="https://www.theatlantic.com/magazine/archive/2018/10/editors-note-the-crisis-in-democracy/568276/" rel="noopener ugc nofollow" target="_blank">中，杰弗里·戈德堡</a>写道:</p><blockquote class="kz"><p id="b4af" class="la lb iq bd lc ld le lf lg lh li kk dk translated">我们发现自己正处于一个巨大的、不受监管的、未经充分检验的实验中，以确定自由民主是否能够在社交媒体、生物技术和人工智能中生存。</p></blockquote><p id="df84" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">皮尤 2017 年关于网络言论自由未来的报告也很值得一读，这份报告向我介绍了“武器化叙事”这个术语。有一句话特别引人注目，因为它引起了我最近阅读的许多其他东西的共鸣，这就是布鲁克林学院新闻和媒体研究主任约翰·安德松的观察:</p><blockquote class="kz"><p id="733b" class="la lb iq bd lc ld le lf lg lh li kk dk translated">卡斯·桑斯坦(Cass Sunstein)曾称之为“大众利益中介”的报纸、网络电视等的持续萎缩。这意味着我们的社会已经到了一个地步，人们可以选择和定制各种不同版本的“现实”，以适应他们现有的意识形态和其他偏见。在这种环境下，合作对话和共识的希望渺茫。</p></blockquote><p id="12c1" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">安妮·阿普尔鲍姆在一篇关于波兰向专制主义转变的文章中，也提到了技术在人类操控中的作用。她写道，今天两极分化的政治运动不需要 20 世纪的“列队行进、火炬点燃的游行、恐怖警察”。相反，人们只是被鼓励去面对另一个现实。“有时，替代现实已经有机地发展起来了；更多情况下，它是在现代营销技术、受众细分和社交媒体宣传的帮助下精心设计的。”</p><p id="e608" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">IEEE 指南包括情感计算领域(与情绪和类情绪控制相关的问题)以及虚拟和混合现实的建议，但在我阅读时，我意识到这些建议不仅针对孤立的游戏环境或个人助理，它们“推动”我们做出“健康的选择”，还针对我们的“真实”世界，在这个世界中，我们可能没有意识到自己被监视和操纵。 在这个世界里，像脸书和 Twitter 这样的公司通过算法塑造我们看到的内容，机器人传播错误信息，试图说服我们或把我们推向我们可能不会去的方向，<a class="ae ky" href="https://www.scientificamerican.com/article/will-democracy-survive-big-data-and-artificial-intelligence/?utm_campaign=QC%20Newsletter&amp;utm_source=hs_email&amp;utm_medium=email&amp;_hsenc=p2ANqtz--462hRSr4gKgXic5WxH8-h4awLwhmxNjZTGQ8mWHdjgitVJbyBnFukz8b1aGvwQJMfT-6z" rel="noopener ugc nofollow" target="_blank">90%的人</a>点击由像谷歌这样的<a class="ae ky" href="https://ivc.lib.rochester.edu/google-search-hyper-visibility-as-a-means-of-rendering-black-women-and-girls-invisible/" rel="noopener ugc nofollow" target="_blank">搜索算法</a>返回的前两个结果之一。 如果我们正在进化成数字网络生物，世界也在进化以适应我们笨拙的新形式。</p><p id="54aa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<a class="ae ky" href="https://www.nature.com/news/there-is-a-blind-spot-in-ai-research-1.20805" rel="noopener ugc nofollow" target="_blank">《自然》杂志</a>一篇题为“人工智能研究中有一个盲点”的文章中，Crawford 和 Calo 写道，“从医院到法庭，自动自治系统已经部署在我们最重要的社会机构中。然而，还没有商定的方法来评估这种应用对人类的持续影响。”</p><p id="f09e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在关于福祉和旨在复制人类任务、行为或情感的人工智能技术的一节中，IEEE 指南指出:</p><blockquote class="kz"><p id="6ffe" class="la lb iq bd lc ld le lf lg lh li kk dk translated">拥有复杂操作技术(所谓的“大推动”)的人工智能将能够指导个人完成整个行动过程，无论是复杂的工作流程、免费内容的消费还是政治说服。</p></blockquote><p id="a56e" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">本节中给我印象最深的候选建议是，需要“确定人工智能/信息系统对人类福祉的影响问题的学术研究状况”，并将研究汇总到“人工智能/信息系统社区的集中存储库中”，这似乎只是因为它是我们思考过程中的一个早期步骤。"</p><p id="95a7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于其他原因，我也一直在考虑集中式存储库。在最近为大西洋<a class="ae ky" href="https://www.theatlantic.com/magazine/archive/2018/10/yuval-noah-harari-technology-tyranny/568330/" rel="noopener ugc nofollow" target="_blank"><em class="kx"/></a>撰写的一篇文章中，哈拉里指出民主和独裁是不同的数据处理系统。“民主将处理信息和决策的权力分配给许多人和机构，而独裁将信息和权力集中在一个地方，”他写道。这种想法让我很不舒服，因为我意识到我们产生了多少数字数据，而我们对如何使用这些数据的控制又是如此之少。我想到了中国的公民分数。以下是达琳·斯托姆在<a class="ae ky" href="https://www.computerworld.com/article/2990203/security/aclu-orwellian-citizen-score-chinas-credit-score-system-is-a-warning-for-americans.html" rel="noopener ugc nofollow" target="_blank">电脑世界</a>中的故事概述:</p><blockquote class="kz"><p id="0db7" class="la lb iq bd lc ld le lf lg lh li kk dk translated">新的“<a class="ae ky" href="https://chinacopyrightandmedia.wordpress.com/2014/06/14/planning-outline-for-the-construction-of-a-social-credit-system-2014-2020/" rel="noopener ugc nofollow" target="_blank">社会信用系统</a>与 13 亿中国公民的国民身份证相连，根据他们的行为<a class="ae ky" href="http://boingboing.net/2015/10/06/reputation-economy-dystopia-c.html" rel="noopener ugc nofollow" target="_blank">和</a>对“你社交图谱中朋友的活动——你在社交媒体上确定为朋友的人”进行评分。公民的信用分数，或者说“公民分数”，会受到他们自己和他们朋友的政治观点的影响。该系统利用“信息时代的所有工具——电子购买数据、社交网络、算法分类——来构建社会控制的终极工具，”美国公民自由联盟言论、隐私技术项目的高级政策分析师 Jay Stanley 说。</p></blockquote><p id="4c6f" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">《科学美国人》  <em class="kx">的一篇文章写道:“根据最近的报道，每个中国公民都将获得一个所谓的‘公民分数’，这将决定他们在什么条件下可以获得贷款、工作或去其他国家的旅游签证。”。</em>在这篇文章中，作者还指出，“特斯拉汽车公司的埃隆·马斯克、微软公司的比尔·盖茨和苹果公司的联合创始人史蒂夫·沃兹尼亚克都警告说，超级智能对人类来说是一个严重的危险，甚至可能比核武器更危险。”</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><p id="e924" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">IEEE 指南中让我印象深刻的一行不是候选人推荐，而是一行背景信息，在一个专门讨论幸福和意外后果的章节中分享。该生产线将智能轮椅视为智能轮椅，在<a class="ae ky" href="https://www.aaai.org/Papers/Symposia/Fall/2008/FS-08-02/FS08-02-024.pdf" rel="noopener ugc nofollow" target="_blank">链接文件</a>中描述为使用“机器视觉和学习技术……来帮助防止与障碍物碰撞，并通过自适应提示提供提醒和导航帮助”:</p><blockquote class="kz"><p id="d715" class="la lb iq bd lc ld le lf lg lh li kk dk translated">例如，一个寻求提高使用轮椅的人的福祉的团队发现，当提供使用智能轮椅的机会时，一些用户对更多移动的机会感到高兴，而其他人则认为这会减少他们的社会接触机会，导致他们的福祉整体下降。</p></blockquote><p id="83d3" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">与推椅子的人的接触比智能轮椅所承诺的机动性更受重视。我想知道这项研究的受试者有多少人际交往。在福祉部分，指导方针还指出:</p><blockquote class="kz"><p id="417e" class="la lb iq bd lc ld le lf lg lh li kk dk translated">只需花费很少的资源，一个陪伴机器人就能提供重要的心理帮助。一方面，这让社会更有爱心，但另一方面，对人工陪伴的依赖表明了这方面社会资源的缺乏。</p></blockquote><p id="87ab" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">在这里,“缺乏社会资源”这个词让我觉得它代表了对我们当前制度的更详细、更直白的描述。我们的社交网络中有一个洞，我们通过这个洞扔进了科技，并带来了闪闪发光但往往未经证实的美好承诺。机器人伴侣的想法也出现在情感计算部分，指导方针写道:</p><blockquote class="kz"><p id="15a6" class="la lb iq bd lc ld le lf lg lh li kk dk translated">人与人之间的关系目前被认为更有回报，但也比使用未来的机器人性工作者更难维持。</p></blockquote><p id="9f38" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">该指南包含一整节专门介绍性爱机器人的内容，承认“这些系统会干扰人类伴侣之间的关系动态，引起嫉妒或厌恶感。”我读了反对性爱机器人运动的立场文件，并被提醒权力和性的动态是多么复杂，即使只限于人类。本节中的候选人建议之一是:</p><blockquote class="kz"><p id="f694" class="la lb iq bd lc ld le lf lg lh li kk dk translated">商业营销的 AI 不应该被认为是法律意义上的人，也不应该作为人进行营销。</p></blockquote><p id="1997" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">自主智能系统的法律地位是一个我没有花太多时间思考的问题，直到我阅读了 IEEE 指南，其中有一节讨论了 A/IS 技术应该如何由法律来描述的问题。例如，在给予法人地位方面，准则规定:</p><blockquote class="kz"><p id="4d04" class="la lb iq bd lc ld le lf lg lh li kk dk translated">这种地位起初似乎很显著，直到考虑到给予公司、政府实体等的长期法人地位——它们都不是人，尽管它们由人管理。</p></blockquote><p id="8646" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">注意到的其他选择是将 A/IS 视为“其人类开发者和用户的纯粹产品和工具”或“完全没有先例的东西，这就提出了一个问题，即一种或多种类型的 A/IS 是否可以被赋予一种中间的——也许是新的——类型的法律地位。”</p><p id="7b2d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我想到了 HitchBot，一个在费城<a class="ae ky" href="https://www.cnn.com/2015/08/03/us/hitchbot-robot-beheaded-philadelphia-feat/index.html" rel="noopener ugc nofollow" target="_blank">被斩首的搭便车机器人</a>和<a class="ae ky" href="https://techxplore.com/news/2015-10-incident-drunk-humanoid-robot-legal.html" rel="noopener ugc nofollow" target="_blank">人形迎宾机器人</a>，一个愤怒的顾客在日本软银商店购物时踢了他一脚。“根据警方的报告，该男子说他对一名店员的态度感到愤怒。‘胡椒机器人’现在移动速度更慢了，它的内部计算机系统可能已经受损。”当一个孩子看到一个成年人攻击一个看起来像人类的机器人时，她会学到什么？击打人形机器人如何改变或反映我们对彼此的看法？指导方针指出:</p><blockquote class="kz"><p id="8383" class="la lb iq bd lc ld le lf lg lh li kk dk translated">我们的结论是……A/IS 还不值得任何形式的“人格”——然而，A/IS 是否能够或应该被授予这种地位的事实表明了技术以及相关的法律和伦理问题的增长速度</p></blockquote><p id="51dc" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">然而，给我印象最深的一句话是这样的:“作者希望这篇文章能为立法过程提供信息，并激励更多的法律界人士参与进来<em class="kx">现在</em>。”</p><p id="e1d4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">斜体的<em class="kx">现在</em>在我看来像是在呼救。</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><p id="4734" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我欣赏 IEEE 指南提案的一个地方是“进一步阅读”部分，它包含了一个文章和论文的列表，我阅读了其中的许多文章，有时还会在本文中引用。对于任何希望更好地了解我们在这些问题上的想法的人——我相信我们每个人都是这场讨论的利益相关者——该文件提供了一个文献速成班。</p><p id="e7cd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我发现不祥的事情之一是包括自主武器。指导方针如下:</p><blockquote class="kz"><p id="aa22" class="la lb iq bd lc ld le lf lg lh li kk dk translated">职业道德准则的制定是为了恰当地解决自主系统的发展和自主系统造成伤害的意图。</p></blockquote><p id="819f" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">对人类造成伤害与人类的繁荣是不一致的。将这一讨论纳入准则破坏了文件的整个前提，并使之有问题。我知道这项工作正在进行。我也读过一些无意伤害人类的自主武器。<a class="ae ky" href="https://bgr.com/2018/08/27/lionfish-robot-reef-invasive-species/" rel="noopener ugc nofollow" target="_blank">迈克·韦纳</a>写道:</p><blockquote class="kz"><p id="63c5" class="la lb iq bd lc ld le lf lg lh li kk dk translated">现在，来自伍斯特理工学院的研究人员已经开发出一种能够独自猎杀狮子鱼的自主机器人。但是这个机器人不仅仅是识别和杀死入侵的鱼——用锋利的长矛钩住鱼并把它放倒——它还允许渔民把死鱼取出来，收获并出售。</p></blockquote><p id="95b0" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">我们在哪里划线？一个自治系统能拿什么命？</p><p id="3e54" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在他们的文章《<a class="ae ky" href="http://journals.sagepub.com/doi/pdf/10.1177/2053951716650211" rel="noopener ugc nofollow" target="_blank">中，大数据研究中的人类主体在哪里？雅各布·梅特卡夫和凯特·克劳福德指出，“道德准则往往在危机事件后出现。”当我让我们的世界遵守这些被提议的指导方针，思考我们的现状和未来时，我经常想起这句话。</a></p><p id="0359" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我非常感谢那些为 IEEE 指南投入如此多时间和精力的人们。这是一次重要的谈话，我们都应该收听，我相信你的声音会让我们受益匪浅。</p><p id="dca2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi">— — — —</p><p id="3924" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kx">IEEE 自主智能系统伦理全球倡议。符合伦理的设计:用自主和智能系统优先考虑人类福祉的愿景</em>，第 2 版。IEEE，2017。<a class="ae ky" href="https://standards.ieee.org/industry-connections/ec/autonomous-systems.html" rel="noopener ugc nofollow" target="_blank">https://standards . IEEE . org/industry-connections/EC/autonomous-systems . html</a></p></div></div>    
</body>
</html>