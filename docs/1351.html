<html>
<head>
<title>Machine Learning : Decision Tree using Spark For Layman</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习:外行使用Spark的决策树</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-decision-tree-using-spark-for-layman-8eca054c8843?source=collection_archive---------2-----------------------#2017-08-26">https://towardsdatascience.com/machine-learning-decision-tree-using-spark-for-layman-8eca054c8843?source=collection_archive---------2-----------------------#2017-08-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="56ae" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">目标</h1><p id="ac12" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在本文中，我们将回顾决策树的定义、直觉和算法。</p><p id="e1bf" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">然后，我们将编写自己的代码，<strong class="kn ir">而不使用任何ML库(如tensorflow等)。这将为实施决策树提供很好的理解和实践经验。</strong></p><h1 id="5a61" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">什么是决策树</h1><p id="1fbc" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">study.com的定义</p><p id="2952" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">决策树是基于特定条件的决策的可能解决方案的图形表示。它被称为决策树，因为它从单个框(或根)开始，然后分支成许多解决方案，就像树一样。</p><h1 id="e8a0" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">直觉</h1><p id="e896" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">让我们考虑一些访问ecom网站的用户的数据。让我们假设我们知道访问网站的用户的概况，如他们的年龄、工作、信用额度等。</p><p id="80b4" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">该表包含一些销售记录，数据的模式是</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/bf6e7cfbc1fa0573aa0fc57733b496f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/0*Q7oGLYKuALAAPb0V.png"/></div></figure><ul class=""><li id="6207" class="lw lx iq kn b ko lj ks lk kw ly la lz le ma li mb mc md me bi translated">第一列是购买者来自的城市。</li><li id="43d7" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">第二列“工作”表示采购员正在做的工作。</li><li id="d488" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">第三列是该人的信用额度</li><li id="8056" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">第四栏是购买者的年龄</li></ul><p id="90ea" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">最后一个最重要的列表示用户最终是否购买了任何商品。“是”表示用户购买了商品，“否”表示用户没有购买。</p><p id="565a" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们想要做的是，基于这些数据，我们想要建立一个决策树来进一步预测任何新用户是否会在网站上购买任何商品。</p><h1 id="8b1c" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">怎么</h1><p id="09b7" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">让我们看看数据，看看四个因素(城市、职业、cc_limit和年龄)中的哪一个可能会影响用户购买或不购买的决定。</p><p id="16e8" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">考虑到“年龄”，该属性对于每一行都有不同值。即使对于唯一的输出——“是”和“否”，该属性的值也是随机的。所以我们可以说，年龄肯定不是用户购买产品的决定因素。</p><p id="c135" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">但是我们如何从数学上证明年龄不是一个因素，至少不是决定结果的主要因素？让我们看看熵。</p><h1 id="92fd" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">熵</h1><p id="2bc5" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">熵是随机性(或杂质)的量度。在上面的例子中，年龄是最随机的属性。</p><p id="428d" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">但是我们如何测量熵呢？测量熵的公式是。这也被称为香农熵</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="ml mm di mn bf mo"><div class="gh gi mk"><img src="../Images/e224ba38a60ab045e51d4198f748bdf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:368/format:webp/0*cazjBQhonSd4B8Of.png"/></div></div></figure><ul class=""><li id="5f85" class="lw lx iq kn b ko lj ks lk kw ly la lz le ma li mb mc md me bi translated">n是值的数量，并且</li><li id="e789" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">p是类中的元素数除以总元素数。</li></ul><p id="ba9b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">让我们深入了解细节。考虑我们上面的样本数据列有结果值</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/7b72534479b7aa2dff388f46984c84ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:336/format:webp/0*Pa3SEP1Dsv1airN5.png"/></div></figure><p id="7b2a" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">该属性(即y)的“是”(“是”类)的数量= 4</p><p id="4c63" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">‘否’的数目(‘否’类)都= 3</p><p id="2603" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">元素总数= 7</p><ul class=""><li id="2643" class="lw lx iq kn b ko lj ks lk kw ly la lz le ma li mb mc md me bi translated">p(0) is =是类中的元素数/元素总数= 4/7</li><li id="e8da" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">p(1)is = no类中的元素数/元素总数= 3/7</li></ul><p id="f8bd" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">熵=(-4/7 * log2(4/7)-3/7 * log2(3/7))=(-0.57 *-0.81–0.43 *-1.22)=(0.4617+0.5246)= 0.9863</p><p id="334b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">0.9863是数据的熵。</p><h1 id="1d1f" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">属性的可变性</h1><p id="d640" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在我们知道了基于结果的数据集的熵，我们如何从数学上找出对决策有贡献的最有影响力的顶级属性。这将是我们试图构建的决策树的根。</p><p id="5433" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">如上所述,“年龄”不能成为任何顾客做出购买决定的因素，因为我们看到人们的年龄几乎随着每个记录而变化。年龄的太多变化使其成为决策中最不重要的因素，因此反过来，变化最小的属性将是最有影响的属性，或者更确切地说是随着结果而变化的属性？提示，是后者。让我看看。</p><p id="b939" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们已经有了数据集的熵(杂质),对于上面的例子是0.9863。所以，我们做下面的工作来获得一个属性的信息增益</p><ul class=""><li id="5a2c" class="lw lx iq kn b ko lj ks lk kw ly la lz le ma li mb mc md me bi translated">求每个属性中每个类的熵。在我们的示例中，Eg city有2个班，即班加罗尔和钦奈</li><li id="0a86" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">按比例分配每个类的熵wrt数据集类。</li></ul><p id="ce3a" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">对于城市属性</p><p id="a308" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">(班加罗尔市的记录总数/记录总数)*班加罗尔熵</p><p id="de4d" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">(钦奈市的总记录数/总记录数)*钦奈熵</p><p id="0888" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">对每个类的上述值求和，并从数据集的熵中减去它</p><p id="1fd3" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">让我们找出班加罗尔城市熵。查一下班加罗尔的记录。其中2个有“是”输出，1个有“否”输出。所以，班加罗尔熵就是</p><p id="d689" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">班加罗尔熵=-2/3log2(⅔)—1/3log2(⅓)= 0.39+0.53 = 0.92</p><p id="ad3c" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">同样，Chennai熵= -2/2log2(2/2) — 2/2log2(2/2) = 0(其完全一致的性质，相等数量的它属于‘是’和‘否’的结果)</p><p id="a660" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">因此，城市的信息增益将如上所述= 0.9863 — { (3/7)*0.92 + 0 } = 0.592</p><h1 id="29d6" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">其他属性</h1><p id="4464" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">“工作”的信息增益— 0.9863 — { 4/7 *就业熵+ 2/7 *失业熵+ }</p><p id="0c6c" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">类似地，我们也得到“信用额度”的信息增益。</p><h1 id="ba6c" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">特例</h1><p id="46be" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">让我们添加另一个名为“ownshouse”的属性，它的值随着输出的变化而变化。所以数据集现在看起来像</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/3350b2260e1be8034ce058616952a326.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/0*uJw24j7iMz3GLIqM.png"/></div></figure><p id="67e0" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">“拥有房屋”表示客户是否拥有房屋。它与结果属性“y”具有相同的值。让我们调整这个属性的信息增益。</p><p id="eb58" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">它有两类'是'和'否'。</p><p id="7ac4" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">“是”的熵= — 4/4log2(4/4) — 0(没有属于“否”类的项目)= 0</p><p id="3c39" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">“否”的熵=—0–3/3 log2(3/3)= 0</p><p id="cf66" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">“ownshouse”属性的信息增益= 0.9863–0 = 9.9863</p><p id="6a42" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">刚刚发生了什么？由于该属性的“ownshouse”值的变化与结果完全相同，因此其信息增益与数据集的熵相同。</p><h1 id="f147" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">计算了属性的信息增益，接下来呢？</h1><p id="319f" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">一旦我们有了属性的信息增益</p><ul class=""><li id="a0df" class="lw lx iq kn b ko lj ks lk kw ly la lz le ma li mb mc md me bi translated">我们得到具有最大信息增益的属性</li><li id="747d" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">将该属性作为树的头</li><li id="23d1" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">获取该属性的值，并创建该标题的这些分支，例如，假设“城市”具有最大信息增益(实际上，在我们的示例中它没有最大增益，但为了讨论起见，假设它)。</li></ul><p id="62e8" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">总部设在城市，分支机构设在班加罗尔和钦奈</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/285caae3d93291d37b1d73c221b4d282.png" data-original-src="https://miro.medium.com/v2/resize:fit:316/format:webp/0*0RxVJFk_Ok4OzE58.png"/></div></figure><ul class=""><li id="d7ce" class="lw lx iq kn b ko lj ks lk kw ly la lz le ma li mb mc md me bi translated">在下一次迭代中-从属性列表中移除城市。</li><li id="5d96" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">对于待定属性，获取属于Bangalore下分支的每个属性的city = Bangalore的记录。</li><li id="5ec3" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">计算Bangalore city下属性的信息增益，得到增益最大的属性，成为Bangalore下的节点。</li><li id="0f9d" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">继续这样做，直到我们用尽所有属性或者熵为零。</li></ul><p id="97c2" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我还有另一个例子，在最后有代码，它为其他数据集实现了这个逻辑，所以你可以看一下它是如何实现的。</p><h1 id="22f8" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">我们什么时候停止构建决策树</h1><p id="049f" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如上所述，我们在下列情况下停止</p><ul class=""><li id="3055" class="lw lx iq kn b ko lj ks lk kw ly la lz le ma li mb mc md me bi translated">我们已经经历了所有的属性或</li><li id="a9d0" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">找到熵为零的属性。</li></ul><p id="3441" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">实际上在我们的特例中，我们在第一次迭代中遇到了熵为零的属性。该属性是“ownshouse”。</p><h1 id="cc74" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">带代码的完整示例</h1><p id="116b" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们从这里开始动手练习。如果您对编码不感兴趣，那么本文将在这里为您总结。</p><p id="3996" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir">使用的工具——pySpark、networkx python lib来可视化决策树</strong></p><p id="b88d" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">代码也在github上，网址是<a class="ae ms" href="https://github.com/skhurana333/ml/blob/master/decision_tree/decision_tree_model_complex.py" rel="noopener ugc nofollow" target="_blank">https://github . com/skhurana 333/ml/blob/master/decision _ tree/decision _ tree _ model _ complex . py</a></p><p id="cc87" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">基本上，这个数据集列出了影响网球比赛是否可以在室外进行的条件。描述了前景、温度、湿度和风的值，以及在这些条件下是否玩游戏的结果。我们现在将构建决策树。</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="0a50" class="my jo iq mu b gy mz na l nb nc">outlook;temp;humidity;wind;y<br/>Sunny;Hot;High;Weak;no<br/>Sunny;Hot;High;Strong;no<br/>Overcast;Hot;High;Weak;yes<br/>Rain;Mild;High;Weak;yes<br/>Rain;Cool;Normal;Weak;yes<br/>Rain;Cool;Normal;Strong;no<br/>Overcast;Cool;Normal;Strong;yes<br/>Sunny;Mild;High;Weak;no<br/>Sunny;Cool;Normal;Weak;yes<br/>Rain;Mild;Normal;Weak;yes<br/>Sunny;Mild;Normal;Strong;yes<br/>Overcast;Mild;High;Strong;yes<br/>Overcast;Hot;Normal;Weak;yes<br/>Rain;Mild;High;Strong;no</span></pre><p id="d955" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">假设具有上述数据的文件保存在位置=<strong class="kn ir">/home/me/ml/practice/decision _ tree/datasets/simple _ dataset</strong></p><p id="9895" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们将讨论流程和算法</p><p id="6d96" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">让我们加载数据集。</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="e2cc" class="my jo iq mu b gy mz na l nb nc">data = sqlContext.read.format('com.databricks.spark.csv').option('header', 'true')\<br/> .option('delimiter', ';') \ .load("/home/me/ml/practice/decision_tree/datasets/simple_dataset")</span></pre><ul class=""><li id="5422" class="lw lx iq kn b ko lj ks lk kw ly la lz le ma li mb mc md me bi translated">因为它包含header，所以我们在选项中将header设置为true。</li><li id="ec7c" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">分隔符是；</li><li id="c5be" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">它是csv格式的。</li></ul><p id="c687" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们将把它注册为表，因为我们需要用不同的where条件查询这个数据集。</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="a5a6" class="my jo iq mu b gy mz na l nb nc">data.registerTempTable('data')</span></pre><p id="1d9c" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir">计算数据集的熵</strong></p><p id="02af" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">获取结果为“是”和“否”的行数。下面是pyspark查询</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="df9c" class="my jo iq mu b gy mz na l nb nc">played = sqlContext.sql("select * from data WHERE y like '%y%' ").count()</span><span id="aa29" class="my jo iq mu b gy nd na l nb nc">notplayed = sqlContext.sql("select * from data WHERE y like '%n%' ").count()</span></pre><p id="31e9" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">因为我们需要获得每个属性的信息增益，并找到具有最大信息增益的属性，所以我们将对所有属性的信息增益计算应用相同的逻辑。创建“流程_数据集”函数。</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="7eb7" class="my jo iq mu b gy mz na l nb nc">def process_dataset(excludedAttrs, data, played, notplayed, where_condition):</span></pre><ul class=""><li id="3560" class="lw lx iq kn b ko lj ks lk kw ly la lz le ma li mb mc md me bi translated">excludedAtttts将包含已经处理过的属性列表，因此我们不需要再次处理。</li><li id="7bd8" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">数据是该文件的spark数据帧</li><li id="871d" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">比赛时间——计算比赛时间</li><li id="f4bc" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">未播放—当比赛未播放时计数</li><li id="c70a" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">Where_condition —用于选择数据的条件，在处理属性时，我们会不断更改此条件</li></ul><p id="58d8" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">让我们从主函数中调用这个函数，</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="8462" class="my jo iq mu b gy mz na l nb nc">def main():</span><span id="a08e" class="my jo iq mu b gy nd na l nb nc">   data = sqlContext.read.format('com.databricks.spark.csv').option('header', 'true')\</span><span id="c328" class="my jo iq mu b gy nd na l nb nc">       .option('delimiter', ';').load("/home/me/ml/practice/decision_tree/datasets/simple_dataset")</span><span id="7361" class="my jo iq mu b gy nd na l nb nc">   data.registerTempTable('data')</span><span id="c2e1" class="my jo iq mu b gy nd na l nb nc">   played = sqlContext.sql("select * from data WHERE y like  '%y%' ").count()</span><span id="12ef" class="my jo iq mu b gy nd na l nb nc">   notplayed = sqlContext.sql("select * from data WHERE y like  '%n%' ").count()</span><span id="2d37" class="my jo iq mu b gy nd na l nb nc">   process_dataset([], data, played, notplayed, '')</span></pre><p id="0ddf" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> 2)加工数据</strong></p><p id="5334" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">Process_dataset将首先计算数据集的熵，然后获得每个属性的信息增益。</p><p id="0a20" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们将声明全局级变量来存储属性的信息增益。并且还会创建有向图来可视化决策树。</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="45fe" class="my jo iq mu b gy mz na l nb nc">attr_name_info_gain = {}</span><span id="29c8" class="my jo iq mu b gy nd na l nb nc">G = nx.DiGraph()</span></pre><p id="6589" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">让我们也声明数据集的模式。我创建了两个变量来存储模式和类型。如果愿意，您可以创建一个并相应地修改后续代码。</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="8f6d" class="my jo iq mu b gy mz na l nb nc">attrs = ["outlook","temp","humidity","wind"]</span><span id="75c9" class="my jo iq mu b gy nd na l nb nc">attrs_type = {"outlook":"string","temp":"string","humidity":"string","wind":"string"}</span></pre><p id="dbcc" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir">流程_数据集函数</strong></p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="825f" class="my jo iq mu b gy mz na l nb nc">def process_dataset(excludedAttrs, data, played, notplayed, where_condition):</span><span id="5635" class="my jo iq mu b gy nd na l nb nc">   total_elements = played + notplayed</span><span id="e99a" class="my jo iq mu b gy nd na l nb nc">   subs_info = {"played" : played, "notplayed" : notplayed}</span><span id="dcd1" class="my jo iq mu b gy nd na l nb nc">   entropy = calculate_entropy(total_elements, subs_info)</span><span id="d926" class="my jo iq mu b gy nd na l nb nc">   print "entropy is " + str(entropy)</span><span id="674f" class="my jo iq mu b gy nd na l nb nc">   global attr_name_info_gain</span><span id="8f79" class="my jo iq mu b gy nd na l nb nc">   attr_name_info_gain = dict()</span><span id="c79d" class="my jo iq mu b gy nd na l nb nc">   for attr in attrs:</span><span id="49ec" class="my jo iq mu b gy nd na l nb nc">       if attr not in excludedAttrs:</span><span id="8c41" class="my jo iq mu b gy nd na l nb nc">           get_attr_info_gain_data_prep(attr, data, entropy, total_elements, where_condition)</span></pre><p id="d0ba" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">它调用calculate_entropy函数，然后为每个属性调用get_attr_info_gain函数。</p><p id="19c5" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> 3)计算_熵函数</strong></p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="5a04" class="my jo iq mu b gy mz na l nb nc">def calculate_entropy(total_elements, elements_in_each_class):</span><span id="7dfc" class="my jo iq mu b gy nd na l nb nc">   <em class="ne"># for target set S having 2 class 0 and 1, the entropy is -p0logp0 -p1logp1</em></span><span id="da61" class="my jo iq mu b gy nd na l nb nc">   <em class="ne"># here the log is of base 2</em></span><span id="ae3c" class="my jo iq mu b gy nd na l nb nc">   <em class="ne"># elements_in_each_class is a dictionary where the key is class label and the</em></span><span id="92ac" class="my jo iq mu b gy nd na l nb nc">   <em class="ne"># value is number of elements in that class</em></span><span id="dc61" class="my jo iq mu b gy nd na l nb nc">   keysInMap = list(elements_in_each_class.keys())</span><span id="16c1" class="my jo iq mu b gy nd na l nb nc">   entropy = 0.0</span><span id="f121" class="my jo iq mu b gy nd na l nb nc">   for aKey in keysInMap:</span><span id="264f" class="my jo iq mu b gy nd na l nb nc">       number_of_elements_in_class = elements_in_each_class.get(aKey)</span><span id="dc87" class="my jo iq mu b gy nd na l nb nc">       if number_of_elements_in_class == 0:</span><span id="5a63" class="my jo iq mu b gy nd na l nb nc">           continue</span><span id="b657" class="my jo iq mu b gy nd na l nb nc">       ratio = number_of_elements_in_class/total_elements</span><span id="e067" class="my jo iq mu b gy nd na l nb nc">       entropy = entropy - ratio * np.log2(ratio)</span><span id="5143" class="my jo iq mu b gy nd na l nb nc">   return entropy</span></pre><p id="9b65" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> 4)属性信息增益数据准备功能</strong></p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="15d2" class="my jo iq mu b gy mz na l nb nc">def get_attr_info_gain_data_prep(attr_name, data, entropy, total_elements, where_condition):</span><span id="d704" class="my jo iq mu b gy nd na l nb nc">   if not where_condition:<br/>       attr_grp_y = data.where(col('y') == 'yes').groupBy(attr_name).agg({"y": 'count'})\<br/>           .withColumnRenamed('count(y)','played_count')<br/>   else:<br/>       attr_grp_y = data.where(" y like '%yes%'  " + where_condition).groupBy(attr_name).agg({"y": 'count'})\<br/>           .withColumnRenamed('count(y)','played_count')</span><span id="47cc" class="my jo iq mu b gy nd na l nb nc">   if not where_condition:<br/>       attr_grp_n = data.where(col('y') == 'no').groupBy(attr_name).agg({"y": 'count'})\<br/>           .withColumnRenamed(attr_name,'n_' + attr_name)\<br/>           .withColumnRenamed('count(y)','not_played_count')<br/>   else:<br/>       attr_grp_n = data.where(" y like '%no%'  " + where_condition).groupBy(attr_name).agg({"y": 'count'})\<br/>           .withColumnRenamed(attr_name,'n_' + attr_name)\<br/>           .withColumnRenamed('count(y)','not_played_count')</span><span id="92d5" class="my jo iq mu b gy nd na l nb nc">   joined_df = attr_grp_y.join(attr_grp_n, on = [col(attr_grp_y.columns[0]) == col(attr_grp_n.columns[0])], how='outer' )\<br/>       .withColumn("total", col(attr_grp_y.columns[0]) + col(attr_grp_n.columns[0]))\<br/>       .select(attr_grp_y.columns[0], attr_grp_y.columns[1],\<br/>                attr_grp_n.columns[1]) \</span><span id="55cc" class="my jo iq mu b gy nd na l nb nc">   gain_for_attribute = calculate_info_gain(entropy, joined_df, total_elements)<br/>   attr_name_info_gain[attr_name] = gain_for_attribute</span></pre><p id="f248" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir">功能说明</strong></p><p id="e442" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">它从文件中读取数据。当我们构建树时，我们将只需要获得对应于树的那个分支的数据。“where_condition”属性将包含这些谓词。</p><p id="337d" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">对于传递的属性名称，我们将文件中结果为“是”的记录分组</p><ul class=""><li id="f783" class="lw lx iq kn b ko lj ks lk kw ly la lz le ma li mb mc md me bi translated">第一次，where_condition将为空，</li><li id="6346" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">第二次迭代之后，在找到树根之后，我们将得到where_condition</li></ul><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="f781" class="my jo iq mu b gy mz na l nb nc">if not where_condition:<br/>   attr_grp_y = data.where(col('y') == 'yes').groupBy(attr_name).agg({"y": 'count'})\<br/>       .withColumnRenamed('count(y)','played_count')<br/>else:<br/>   attr_grp_y = data.where(" y like '%yes%'  " + where_condition).groupBy(attr_name).agg({"y": 'count'})\<br/>       .withColumnRenamed('count(y)','played_count')</span></pre><ul class=""><li id="f717" class="lw lx iq kn b ko lj ks lk kw ly la lz le ma li mb mc md me bi translated">类似地，它将文件中结果为“否”的记录分组为传递的属性名。</li></ul><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="28b5" class="my jo iq mu b gy mz na l nb nc">if not where_condition:<br/>   attr_grp_n = data.where(col('y') == 'no').groupBy(attr_name).agg({"y": 'count'})\<br/>       .withColumnRenamed(attr_name,'n_' + attr_name)\<br/>       .withColumnRenamed('count(y)','not_played_count')<br/>else:<br/>   attr_grp_n = data.where(" y like '%no%'  " + where_condition).groupBy(attr_name).agg({"y": 'count'})\<br/>       .withColumnRenamed(attr_name,'n_' + attr_name)\<br/>       .withColumnRenamed('count(y)','not_played_count')</span></pre><ul class=""><li id="f41c" class="lw lx iq kn b ko lj ks lk kw ly la lz le ma li mb mc md me bi translated">我们将列<strong class="kn ir"> count(y) </strong>重命名为played_count，将<strong class="kn ir"> count(n) </strong>重命名为not_played_count</li><li id="64b9" class="lw lx iq kn b ko mf ks mg kw mh la mi le mj li mb mc md me bi translated">将attr_name列重命名为n</li></ul><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="6b33" class="my jo iq mu b gy mz na l nb nc">.withColumnRenamed(attr_name,'n_' + attr_name)\</span></pre><ul class=""><li id="08e5" class="lw lx iq kn b ko lj ks lk kw ly la lz le ma li mb mc md me bi translated">现在，我们将这两个数据帧连接起来，一个具有该属性“是”结果的计数，另一个具有同一属性“否”结果的计数</li></ul><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="c085" class="my jo iq mu b gy mz na l nb nc">joined_df = attr_grp_y.join(attr_grp_n, on = [col(attr_grp_y.columns[0]) == col(attr_grp_n.columns[0])], how='outer' )\</span></pre><p id="8b5b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们在属性名上连接。我们需要外部连接，如果一个属性没有“是”或“否”结果的记录，那么我们仍然需要当前的“是”或“否”计数。</p><p id="748b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">此外，由于我们有是和否结果的计数，我们还需要总计数(有是和否的记录总数)来计算熵。因此，我们添加了一个新列，其中包含总数</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="25a4" class="my jo iq mu b gy mz na l nb nc">.withColumn("total", col(attr_grp_y.columns[0]) + col(attr_grp_n.columns[0]))\</span></pre><p id="61e1" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们不会选择连接列两次</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="83b0" class="my jo iq mu b gy mz na l nb nc">.select(attr_grp_y.columns[0], attr_grp_y.columns[1],\<br/>        attr_grp_n.columns[1])</span></pre><p id="6a8f" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们做了所有这些练习来计算这个特定属性的信息增益，所以让我们来计算一下</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="8fae" class="my jo iq mu b gy mz na l nb nc">gain_for_attribute = calculate_info_gain(entropy, joined_df, total_elements)</span></pre><p id="0633" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们将在全局变量attr_name_info_gain中保存该属性<strong class="kn ir">的信息增益。</strong>我们稍后将对该字典进行排序，以获得具有最大信息增益的属性。接下来描述调用的Calculate_info_gain函数。</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="dae2" class="my jo iq mu b gy mz na l nb nc">gain_for_attribute = calculate_info_gain(entropy, joined_df, total_elements)  <em class="ne">#</em><br/> attr_name_info_gain[attr_name] = gain_for_attribute</span></pre><p id="1e2f" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> 5)信息增益功能</strong></p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="b2ad" class="my jo iq mu b gy mz na l nb nc">def calculate_info_gain(entropy, joined_df, total_elements):<br/>   attr_entropy = 0.0<br/>   for anAttributeData in joined_df.rdd.collect():<br/>       yes_class_count = anAttributeData[1]<br/>       no_class_count = anAttributeData[2]<br/>       if yes_class_count is None:<br/>           yes_class_count = 0<br/>       elif no_class_count is None:<br/>           no_class_count = 0</span><span id="7020" class="my jo iq mu b gy nd na l nb nc">       count_of_class = yes_class_count + no_class_count<br/>       <em class="ne"># do the summation part e.g. if age is 56, 60, 45 then its sum of entropy for each of these element</em><br/>       classmap = {'y' : yes_class_count, 'n' : no_class_count}<br/>       attr_entropy = attr_entropy + ((count_of_class / total_elements) *\<br/>                                      calculate_entropy(count_of_class, classmap))</span><span id="d281" class="my jo iq mu b gy nd na l nb nc">   gain = entropy - attr_entropy</span><span id="73b6" class="my jo iq mu b gy nd na l nb nc">   return gain</span></pre><p id="025a" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">如果您已经阅读了前面的章节，那么这个函数是不言自明的</p><p id="2e11" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> 6)再次返回主功能</strong></p><p id="bf0f" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们一直处理到这个代码行—-&gt;“process _ dataset([]，data，played，notplayed，<strong class="kn ir"> '' </strong>)”</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="7549" class="my jo iq mu b gy mz na l nb nc">def main():<br/>   data = sqlContext.read.format('com.databricks.spark.csv').option('header', 'true')\<br/>       .option('delimiter', ';').load("/home/me/ml/practice/decision_tree/datasets/simple_dataset")</span><span id="90eb" class="my jo iq mu b gy nd na l nb nc">   data.registerTempTable('data')<br/>   played = sqlContext.sql("select * from data WHERE y like  '%y%' ").count()<br/>   notplayed = sqlContext.sql("select * from data WHERE y like  '%n%' ").count()<br/>   process_dataset([], data, played, notplayed, '')<br/>   <em class="ne"># sort by info gain</em><br/>   sorted_by_info_gain = sorted(attr_name_info_gain.items(), key=operator.itemgetter(1), reverse=True)</span><span id="3ef0" class="my jo iq mu b gy nd na l nb nc">   processed_attrs = []<br/>   max_gain_attr = sorted_by_info_gain[0][0]<br/>   processed_attrs.append(max_gain_attr)<br/>   build_tree(max_gain_attr, processed_attrs, data, '')</span><span id="39ac" class="my jo iq mu b gy nd na l nb nc">   nx.draw(G, with_labels=True)<br/>   plt.show()</span></pre><p id="3a07" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">对信息增益函数进行排序，得到增益最大的属性，将其作为根节点。现在我们调用构建树函数。这是最后一个也是最重要的功能。</p><p id="ada6" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">此方法的输入是具有最大信息增益的属性的名称。这将成为树的根节点。我们希望获得该属性的不同值。这些值将成为该节点的分支。</p><p id="d24c" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">这个函数将递归地构建完整的树。</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="9eb7" class="my jo iq mu b gy mz na l nb nc">def build_tree(max_gain_attr, processed_attrs, data, where_condition):<br/>   attrValues = sqlContext.sql("select distinct " + max_gain_attr + " from data  where 1==1 " + where_condition)<br/>   orig_where_condition = where_condition</span><span id="1642" class="my jo iq mu b gy nd na l nb nc">   for aValueForMaxGainAttr in attrValues.rdd.collect():<br/>       adistinct_value_for_attr = aValueForMaxGainAttr[0]<br/>       G.add_edges_from([(max_gain_attr, adistinct_value_for_attr)])</span><span id="d97b" class="my jo iq mu b gy nd na l nb nc">       if attrs_type[max_gain_attr] == "string":<br/>           where_condition = str(orig_where_condition + " and " + max_gain_attr + "=='" + adistinct_value_for_attr + "'")<br/>       else:<br/>           where_condition = str(orig_where_condition + " and " + max_gain_attr + "==" + adistinct_value_for_attr)</span><span id="e458" class="my jo iq mu b gy nd na l nb nc">       played_for_attr = sqlContext.sql("select * from data where y like '%yes%' " + where_condition).count()<br/>       notplayed_for_attr = sqlContext.sql("select * from data where y like '%no%' " + where_condition).count()<br/>       <em class="ne"># if either has zero value then entropy for this attr will be zero and its the last attr in the tree</em><br/>       leaf_values = []<br/>       if played_for_attr == 0 or notplayed_for_attr == 0:<br/>           leaf_node = sqlContext.sql("select distinct y from data where 1==1 " + where_condition)<br/>           for leaf_node_data in leaf_node.rdd.collect():<br/>               G.add_edges_from([(adistinct_value_for_attr, str(leaf_node_data[0]))])<br/>           continue</span><span id="fbfd" class="my jo iq mu b gy nd na l nb nc">       process_dataset(processed_attrs, data, played_for_attr, notplayed_for_attr, where_condition)<br/>       if not attr_name_info_gain: <em class="ne"># we processed all attributes</em><br/>           <em class="ne"># attach leaf node</em><br/>           leaf_node = sqlContext.sql("select distinct y from data where 1==1 " + where_condition)<br/>           for leaf_node_data in leaf_node.rdd.collect():<br/>               G.add_edges_from([(adistinct_value_for_attr, str(leaf_node_data[0]))])<br/>           continue <em class="ne"># we are done for this branch of tree</em></span><span id="f2a4" class="my jo iq mu b gy nd na l nb nc">       <em class="ne"># get the attr with max info gain under aValueForMaxGainAttr</em><br/>       <em class="ne"># sort by info gain</em><br/>       sorted_by_info_gain = sorted(attr_name_info_gain.items(), key=operator.itemgetter(1), reverse=True)<br/>       new_max_gain_attr = sorted_by_info_gain[0][0]<br/>       if sorted_by_info_gain[0][1] == 0:<br/>           <em class="ne"># under this where condition, records dont have entropy</em><br/>           leaf_node = sqlContext.sql("select distinct y from data where 1==1 " + where_condition)<br/>           <em class="ne"># there might be more than one leaf node</em><br/>           for leaf_node_data in leaf_node.rdd.collect():<br/>               G.add_edges_from([(adistinct_value_for_attr, str(leaf_node_data[0]))])<br/>           continue <em class="ne"># we are done for this branch of tree</em></span><span id="cc32" class="my jo iq mu b gy nd na l nb nc">       G.add_edges_from([(adistinct_value_for_attr, new_max_gain_attr)])<br/>       processed_attrs.append(new_max_gain_attr)<br/>       build_tree(new_max_gain_attr, processed_attrs, data, where_condition)</span></pre><p id="53dc" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir">解释</strong></p><p id="2c0d" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们希望节点有不同的值。</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="be6d" class="my jo iq mu b gy mz na l nb nc">attrValues = sqlContext.sql("select distinct " + max_gain_attr + " from data  where 1==1 " + where_condition)</span></pre><p id="61d6" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">对于该节点的每个值</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="5aa8" class="my jo iq mu b gy mz na l nb nc">for aValueForMaxGainAttr in attrValues.rdd.collect():</span></pre><p id="00a0" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">获取该迭代下的属性值</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="3648" class="my jo iq mu b gy mz na l nb nc">adistinct_value_for_attr = aValueForMaxGainAttr[0]</span></pre><p id="ce9c" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">将此值添加为节点的分支</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="5627" class="my jo iq mu b gy mz na l nb nc">G.add_edges_from([(max_gain_attr, adistinct_value_for_attr)])</span></pre><p id="fd15" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们需要得到这个属性值下的数据。如果树是</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/73e9ac4d1da5a4ca496773545d17200c.png" data-original-src="https://miro.medium.com/v2/resize:fit:248/format:webp/0*yG38pkAxPc5E0zt-.png"/></div></figure><p id="df10" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们正在处理父节点的“Sunny”值，然后在同一个分支(outlook -&gt; sunny)下继续，我们需要获得outlook = sunny的数据。所以我们把它作为新的where条件添加进来。</p><p id="3ae6" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">此外，如果我们需要在引号下添加值时属性类型是string，而它是int类型，那么我们不添加引号。</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="dad5" class="my jo iq mu b gy mz na l nb nc">if attrs_type[max_gain_attr] == "string":<br/>           where_condition = str(orig_where_condition + " and " + max_gain_attr + "=='" + adistinct_value_for_attr + "'")<br/>       else:<br/>           where_condition = str(orig_where_condition + " and " + max_gain_attr + "==" + adistinct_value_for_attr)</span></pre><p id="c265" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们将再次从属性列表中找出具有最大信息增益的属性，不包括已经被处理的属性。因此，对于父属性的这个值，我们想知道有多少记录的结果为“是”和“否”</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="0b88" class="my jo iq mu b gy mz na l nb nc">played_for_attr = sqlContext.sql("select * from data where y like '%yes%' " + where_condition).count()<br/>notplayed_for_attr = sqlContext.sql("select * from data where y like '%no%' " + where_condition).count()</span></pre><p id="45a5" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">如注释所述，如果我们得到的熵值为零，那么我们就到达了这个分支的叶节点，我们只需将结果添加到这个节点下的树中。</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="e2c4" class="my jo iq mu b gy mz na l nb nc"><em class="ne"># if either has zero value then entropy for this attr will be zero and its the last attr in the tree</em><br/>       leaf_values = []<br/>       if played_for_attr == 0 or notplayed_for_attr == 0:<br/>           leaf_node = sqlContext.sql("select distinct y from data where 1==1 " + where_condition)<br/>           for leaf_node_data in leaf_node.rdd.collect():<br/>               G.add_edges_from([(adistinct_value_for_attr, str(leaf_node_data[0]))])<br/>           continue</span></pre><p id="c7e4" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">如果没有，那么我们继续处理。类似下面的代码已经在主函数中处理并解释过了。也许我们应该把这一次迭代也作为这个递归的一部分，让这成为你的练习。</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="b0d3" class="my jo iq mu b gy mz na l nb nc">process_dataset(processed_attrs, data, subscribed_for_attr, unsubscribed_for_attr, where_condition)<br/>if not attr_name_info_gain: <em class="ne"># we processed all attributes</em><br/>   <em class="ne"># attach leaf node</em><br/>   leaf_node = sqlContext.sql("select distinct y from data where 1==1 " + where_condition)<br/>   for leaf_node_data in leaf_node.rdd.collect():<br/>       G.add_edges_from([(adistinct_value_for_attr, str(leaf_node_data[0]))])<br/>   continue <em class="ne"># we are done for this branch of tree</em></span><span id="7cde" class="my jo iq mu b gy nd na l nb nc"><em class="ne"># get the attr with max info gain under aValueForMaxGainAttr</em><br/><em class="ne"># sort by info gain</em><br/>sorted_by_info_gain = sorted(attr_name_info_gain.items(), key=operator.itemgetter(1), reverse=True)<br/>new_max_gain_attr = sorted_by_info_gain[0][0]<br/>if sorted_by_info_gain[0][1] == 0:<br/>   <em class="ne"># under this where condition, records dont have entropy</em><br/>   leaf_node = sqlContext.sql("select distinct y from data where 1==1 " + where_condition)<br/>   <em class="ne"># there might be more than one leaf node</em><br/>   for leaf_node_data in leaf_node.rdd.collect():<br/>       G.add_edges_from([(adistinct_value_for_attr, str(leaf_node_data[0]))])<br/>   continue <em class="ne"># we are done for this branch of tree</em></span><span id="f50f" class="my jo iq mu b gy nd na l nb nc">G.add_edges_from([(adistinct_value_for_attr, new_max_gain_attr)])<br/>processed_attrs.append(new_max_gain_attr)<br/>build_tree(new_max_gain_attr, processed_attrs, data, where_condition)</span></pre><p id="39b1" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">现在，如果我们执行了main函数的最后两行，那么您可以直观地看到构建的决策树:-)</p><pre class="lp lq lr ls gt mt mu mv mw aw mx bi"><span id="a32f" class="my jo iq mu b gy mz na l nb nc">nx.draw(G, with_labels=True)<br/>plt.show()</span></pre><p id="c2d3" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">尽情享受吧！！！如果可能的话，提供关于拼写错误或任何其他此类编辑(没有做任何审查或校对)，关于算法，优化等的反馈。</p></div></div>    
</body>
</html>