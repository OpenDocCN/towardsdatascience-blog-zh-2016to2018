<html>
<head>
<title>Machine Learning Workflow on Diabetes Data: Part 01</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">糖尿病数据的机器学习工作流程:第1部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-workflow-on-diabetes-data-part-01-573864fcc6b8?source=collection_archive---------1-----------------------#2018-02-26">https://towardsdatascience.com/machine-learning-workflow-on-diabetes-data-part-01-573864fcc6b8?source=collection_archive---------1-----------------------#2018-02-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><blockquote class="jn"><p id="c1cd" class="jo jp iq bd jq jr js jt ju jv jw jx dk translated">“医疗环境中的机器学习可以帮助显著增强医疗诊断。”</p></blockquote><p id="0f68" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku jx ij bi translated">本文将描述如何利用与糖尿病相关的数据来预测一个人是否患有糖尿病。更具体地说，本文将重点关注如何利用机器学习来预测糖尿病等疾病。在本系列文章结束时，您将能够理解数据探索、数据清理、特性选择、模型选择、模型评估等概念，并以实际的方式应用它们。</p><h1 id="040b" class="kv kw iq bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">什么是糖尿病？</h1><p id="0766" class="pw-post-body-paragraph jy jz iq ka b kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr lx kt ku jx ij bi translated"><a class="ae ly" href="https://www.niddk.nih.gov/health-information/diabetes" rel="noopener ugc nofollow" target="_blank">糖尿病</a>是一种当血糖水平变高时发生的疾病，最终会导致其他健康问题，如心脏病、肾病等。糖尿病主要是由于食用高度加工食品、不良消费习惯等引起的。据<a class="ae ly" href="http://www.who.int/mediacentre/factsheets/fs312/en/" rel="noopener ugc nofollow" target="_blank">世卫组织</a>报道，这些年来糖尿病患者的数量一直在增加。</p><h1 id="c099" class="kv kw iq bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">先决条件</h1><ul class=""><li id="f06f" class="lz ma iq ka b kb lt kf lu kj mb kn mc kr md jx me mf mg mh bi translated">Python 3。+</li><li id="611d" class="lz ma iq ka b kb mi kf mj kj mk kn ml kr mm jx me mf mg mh bi translated">蟒蛇(Scikit Learn，Numpy，Pandas，Matplotlib，Seaborn)</li><li id="aa9b" class="lz ma iq ka b kb mi kf mj kj mk kn ml kr mm jx me mf mg mh bi translated">朱庇特笔记本。</li><li id="5012" class="lz ma iq ka b kb mi kf mj kj mk kn ml kr mm jx me mf mg mh bi translated">对监督机器学习方法的基本理解:特别是分类。</li></ul><h1 id="67b3" class="kv kw iq bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated"><strong class="ak">第0阶段—数据准备</strong></h1><p id="6693" class="pw-post-body-paragraph jy jz iq ka b kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr lx kt ku jx ij bi translated">作为一名数据科学家，我们遇到的最乏味的任务是获取和准备数据集。即使这个时代有大量的数据，仍然很难找到一个合适的数据集来解决你试图解决的问题。如果找不到任何合适的数据集，您可能需要创建自己的数据集。</p><p id="dad8" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">在本教程中，我们不会创建自己的数据集，相反，我们将使用由UCI机器学习资源库(著名的机器学习数据集资源库)提供的名为“<a class="ae ly" href="https://github.com/LahiruTjay/Machine-Learning-With-Python/blob/master/datasets/diabetes.csv" rel="noopener ugc nofollow" target="_blank"> <strong class="ka ir">皮马印第安人糖尿病数据库</strong> </a>”的现有数据集。我们将使用上面提供的<strong class="ka ir">糖尿病数据集</strong>执行机器学习工作流。</p><h1 id="8c05" class="kv kw iq bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated"><strong class="ak">第一阶段—数据探索</strong></h1><p id="82d5" class="pw-post-body-paragraph jy jz iq ka b kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr lx kt ku jx ij bi translated">当遇到一个数据集时，首先我们应该分析并"<strong class="ka ir">了解</strong>"这个数据集。这一步对于熟悉数据、了解潜在特征以及确定是否需要清理数据是必要的。</p><p id="46f2" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">首先，我们将导入必要的库，并将数据集导入Jupyter笔记本。我们可以观察数据集中提到的列。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="4b00" class="nb kw iq mx b gy nc nd l ne nf">%matplotlib inline<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="1531" class="nb kw iq mx b gy ng nd l ne nf">diabetes = pd.read_csv('datasets/diabetes.csv')<br/>diabetes.columns </span></pre><p id="cbbc" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated"><em class="nh">指数(['妊娠'，'血糖'，'血压'，'皮肤厚度'，'胰岛素'，<br/>，'身体质量指数'，'糖尿病患者血糖'，'年龄'，'结果']，<br/> dtype= '对象')</em></p><blockquote class="ni nj nk"><p id="7281" class="jy jz nh ka b kb mn kd ke kf mo kh ki nl mp kl km nm mq kp kq nn mr kt ku jx ij bi translated">重要提示:需要注意的是，上述数据集仅包含有限的特征，而实际上有许多特征在起作用。</p></blockquote><p id="7f88" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">我们可以使用熊猫的<strong class="ka ir"> head() </strong>方法来检查数据集。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="1233" class="nb kw iq mx b gy nc nd l ne nf">diabetes.head()</span></pre><figure class="ms mt mu mv gt np gh gi paragraph-image"><div role="button" tabindex="0" class="nq nr di ns bf nt"><div class="gh gi no"><img src="../Images/07a4ed0e44dc847dc2152554c238cdd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7oBA91Rc-yuui1DbKlg48g.jpeg"/></div></div><figcaption class="nw nx gj gh gi ny nz bd b be z dk">Fig — Diabetes data set</figcaption></figure><p id="34e6" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">我们可以使用panda Dataframes的“shape”属性找到数据集的维度。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="e336" class="nb kw iq mx b gy nc nd l ne nf">print("Diabetes data set dimensions : {}".format(diabetes.shape))</span></pre><p id="5f0f" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated"><em class="nh">糖尿病数据集维度:(768，9) </em></p><p id="e62b" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">我们可以观察到数据集包含768行和9列。<em class="nh">结果</em>是我们将要预测的列，表示患者是否患有糖尿病。1表示该人是糖尿病患者，0表示该人不是。我们可以确定，在768人中，500人被标记为0(非糖尿病)，268人被标记为1(糖尿病)</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="4ba1" class="nb kw iq mx b gy nc nd l ne nf">diabetes.groupby('Outcome').size()</span></pre><figure class="ms mt mu mv gt np gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/5f5c603f7bb7ffc3f5ee45b234f86efc.png" data-original-src="https://miro.medium.com/v2/resize:fit:270/format:webp/1*SS81dtyFCSRXDSB-zMKC3Q.jpeg"/></div><figcaption class="nw nx gj gh gi ny nz bd b be z dk">Fig— Class distribution</figcaption></figure><p id="69d9" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">数据可视化是数据科学的一个重要方面。这有助于理解数据，也有助于向他人解释数据。Python有几个有趣的可视化库比如Matplotlib，Seaborn等。</p><p id="4fab" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">在本教程中，我们将使用构建在matplotlib之上的pandas可视化工具来查找要素的数据分布。</p><figure class="ms mt mu mv gt np gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/0c641b87b75cf3f127f2f0e65633fe9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*ZjIaB1isxpxEKaqTwviycg.jpeg"/></div><figcaption class="nw nx gj gh gi ny nz bd b be z dk">Fig— Data distribution</figcaption></figure><p id="fe2d" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">我们可以使用下面的代码分别为这两个响应绘制直方图。(此处未显示图像。)</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="5ddf" class="nb kw iq mx b gy nc nd l ne nf">diabetes.groupby(‘Outcome’).hist(figsize=(9, 9))</span></pre><h1 id="84c2" class="kv kw iq bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">阶段2—数据清理</h1><p id="30d1" class="pw-post-body-paragraph jy jz iq ka b kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr lx kt ku jx ij bi translated">机器学习工作流程的下一个阶段是数据清理。被认为是工作流程的关键步骤之一，因为它可以决定模型的成败。机器学习中有一句谚语<strong class="ka ir">“更好的数据胜过更好的算法”</strong>，这表明更好的数据会给你带来更好的结果模型。</p><p id="369b" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">在数据清理过程中，有几个因素需要考虑。</p><ol class=""><li id="c16c" class="lz ma iq ka b kb mn kf mo kj oc kn od kr oe jx of mf mg mh bi translated">重复或不相关的观察。</li><li id="203f" class="lz ma iq ka b kb mi kf mj kj mk kn ml kr mm jx of mf mg mh bi translated">数据标签错误，同一类别出现多次。</li><li id="245b" class="lz ma iq ka b kb mi kf mj kj mk kn ml kr mm jx of mf mg mh bi translated">数据点缺失或为空。</li><li id="266c" class="lz ma iq ka b kb mi kf mj kj mk kn ml kr mm jx of mf mg mh bi translated">意外的异常值。</li></ol><blockquote class="ni nj nk"><p id="1ed3" class="jy jz nh ka b kb mn kd ke kf mo kh ki nl mp kl km nm mq kp kq nn mr kt ku jx ij bi translated">在本教程中，我们不会详细讨论数据清理过程。</p></blockquote><p id="e835" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">由于我们使用的是标准数据集，我们可以有把握地假设因素1、2已经处理过了。意外的异常值要么有用，要么有潜在的危害。</p><h2 id="12c2" class="nb kw iq bd kx og oh dn lb oi oj dp lf kj ok ol lj kn om on ln kr oo op lr oq bi translated">缺失或空数据点</h2><p id="e8a7" class="pw-post-body-paragraph jy jz iq ka b kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr lx kt ku jx ij bi translated">我们可以使用下面的pandas函数找到数据集的任何缺失或空数据点(如果有的话)。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="396d" class="nb kw iq mx b gy nc nd l ne nf">diabetes.isnull().sum()<br/>diabetes.isna().sum()</span></pre><p id="b053" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">我们可以观察到数据集中没有数据点丢失。如果有，我们应该相应地处理它们。</p><figure class="ms mt mu mv gt np gh gi paragraph-image"><div class="gh gi or"><img src="../Images/2209e6f82570c564ae9debfa234a0448.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/1*Q-gDYUVcp2ZGXYgp-2cc1g.jpeg"/></div><figcaption class="nw nx gj gh gi ny nz bd b be z dk">Fig — Observe missing data</figcaption></figure><h2 id="e309" class="nb kw iq bd kx og oh dn lb oi oj dp lf kj ok ol lj kn om on ln kr oo op lr oq bi translated"><strong class="ak">意外异常值</strong></h2><p id="b67f" class="pw-post-body-paragraph jy jz iq ka b kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr lx kt ku jx ij bi translated">当分析直方图时，我们可以发现在一些列中有一些异常值。我们将进一步分析这些异常值，并确定我们可以做些什么。</p><p id="9dd5" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated"><strong class="ka ir">血压:</strong>通过观察数据我们可以看到，血压有0个值。很明显，数据集的读数似乎是错误的，因为一个活人的舒张压不可能为零。通过观察数据，我们可以看到值为0的35个计数。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="4db8" class="nb kw iq mx b gy nc nd l ne nf">print("Total : ", diabetes[diabetes.BloodPressure == 0].shape[0])</span><span id="a29d" class="nb kw iq mx b gy ng nd l ne nf">Total :  35</span><span id="f6ba" class="nb kw iq mx b gy ng nd l ne nf">print(diabetes[diabetes.BloodPressure == 0].groupby('Outcome')['Age'].count())</span><span id="b7e2" class="nb kw iq mx b gy ng nd l ne nf">Outcome<br/>0    19<br/>1    16<br/>Name: Age, dtype: int64</span></pre><p id="c9a4" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated"><strong class="ka ir">血浆葡萄糖水平:</strong>即使空腹后血糖水平也不会低至零。因此，零是无效的读数。通过观察数据，我们可以看到值为0的5个计数。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="d2f9" class="nb kw iq mx b gy nc nd l ne nf">print("Total : ", diabetes[diabetes.Glucose == 0].shape[0])</span><span id="40ac" class="nb kw iq mx b gy ng nd l ne nf">Total :  5</span><span id="94b5" class="nb kw iq mx b gy ng nd l ne nf">print(diabetes[diabetes.Glucose == 0].groupby('Outcome')['Age'].count())</span><span id="fb48" class="nb kw iq mx b gy ng nd l ne nf">Total :  5<br/>Outcome<br/>0    3<br/>1    2<br/>Name: Age, dtype: int64</span></pre><p id="5008" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated"><strong class="ka ir">皮褶厚度:</strong>对于正常人来说，皮褶厚度不可能小于10 mm最好为零。值为0: 227的总计数。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="629e" class="nb kw iq mx b gy nc nd l ne nf">print("Total : ", diabetes[diabetes.SkinThickness == 0].shape[0])</span><span id="118b" class="nb kw iq mx b gy ng nd l ne nf">Total :  227</span><span id="95f9" class="nb kw iq mx b gy ng nd l ne nf">print(diabetes[diabetes.SkinThickness == 0].groupby('Outcome')['Age'].count())</span><span id="6f16" class="nb kw iq mx b gy ng nd l ne nf">Outcome<br/>0    139<br/>1     88<br/>Name: Age, dtype: int64</span></pre><p id="d497" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">身体质量指数:不应该是零或接近零，除非这个人真的体重不足，这可能会危及生命。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="24b0" class="nb kw iq mx b gy nc nd l ne nf">print("Total : ", diabetes[diabetes.BMI == 0].shape[0])</span><span id="56d3" class="nb kw iq mx b gy ng nd l ne nf">Total :  11</span><span id="4cd3" class="nb kw iq mx b gy ng nd l ne nf">print(diabetes[diabetes.BMI == 0].groupby('Outcome')['Age'].count())</span><span id="3474" class="nb kw iq mx b gy ng nd l ne nf">Outcome<br/>0    9<br/>1    2<br/>Name: Age, dtype: int64</span></pre><p id="28e1" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated"><strong class="ka ir">胰岛素:</strong>在极少数情况下，一个人可以没有胰岛素，但通过观察数据，我们可以发现总共有374个计数。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="5a47" class="nb kw iq mx b gy nc nd l ne nf">print("Total : ", diabetes[diabetes.Insulin == 0].shape[0])</span><span id="f22c" class="nb kw iq mx b gy ng nd l ne nf">Total :  374</span><span id="45d0" class="nb kw iq mx b gy ng nd l ne nf">print(diabetes[diabetes.Insulin == 0].groupby('Outcome')['Age'].count())</span><span id="d251" class="nb kw iq mx b gy ng nd l ne nf">Outcome<br/>0    236<br/>1    138<br/>Name: Age, dtype: int64</span></pre><p id="1749" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">以下是处理无效数据值的几种方法:</p><ol class=""><li id="3fe2" class="lz ma iq ka b kb mn kf mo kj oc kn od kr oe jx of mf mg mh bi translated">忽略/删除这些情况:这在大多数情况下实际上是不可能的，因为这将意味着丢失有价值的信息。在这种情况下，“皮肤厚度”和“胰岛素”列意味着有许多无效点。但它可能适用于“身体质量指数”、“葡萄糖”和“血压”数据点。</li><li id="fafd" class="lz ma iq ka b kb mi kf mj kj mk kn ml kr mm jx of mf mg mh bi translated">放入平均值:这可能对一些数据集有效，但是在我们的例子中，把平均值放入血压列会给模型发送一个错误的信号。</li><li id="38f9" class="lz ma iq ka b kb mi kf mj kj mk kn ml kr mm jx of mf mg mh bi translated">避免使用特性:对于模型来说，不使用具有大量无效值的特性是可能的。这可能对“皮肤厚度”有效，但很难预测。</li></ol><p id="643f" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">在数据清理过程结束时，我们得出结论，这个给定的数据集是不完整的。由于这是机器学习的演示，我们将对给定的数据进行一些小的调整。</p><p id="79e7" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">我们将删除“血压”、“身体质量指数”和“葡萄糖”为零的行。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="dff9" class="nb kw iq mx b gy nc nd l ne nf">diabetes_mod = diabetes[(diabetes.BloodPressure != 0) &amp; (diabetes.BMI != 0) &amp; (diabetes.Glucose != 0)]</span><span id="7055" class="nb kw iq mx b gy ng nd l ne nf">print(diabetes_mod.shape)</span><span id="9fc5" class="nb kw iq mx b gy ng nd l ne nf">(724, 9)</span></pre><h1 id="b3ac" class="kv kw iq bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">第3阶段—特征工程</h1><p id="208e" class="pw-post-body-paragraph jy jz iq ka b kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr lx kt ku jx ij bi translated">特征工程是将收集的数据转换为更好地代表我们试图解决的模型问题的特征的过程，以提高模型的性能和准确性。</p><p id="66a7" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">特征工程从现有特征中创建更多的输入特征，并组合多个特征以生成更直观的特征来输入模型。</p><p id="4ece" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated"><strong class="ka ir"> <em class="nh">“特征工程使我们能够突出重要的特征，并便于将问题领域的专业知识带到桌面上来。尽管提供了许多输入特征，它还允许避免过度拟合模型”。</em>T11】</strong></p><p id="91ad" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">我们试图解决的问题领域需要许多相关的特性。由于数据集已经提供，并且通过检查数据，我们不能在这一点上进一步创建或删除任何数据。在数据集中，我们有以下特征。</p><blockquote class="ni nj nk"><p id="2129" class="jy jz nh ka b kb mn kd ke kf mo kh ki nl mp kl km nm mq kp kq nn mr kt ku jx ij bi translated">怀孕'，'葡萄糖'，'血压'，'皮肤厚度'，'胰岛素'，'身体质量指数'，'糖尿病谱系功能'，'年龄'</p></blockquote><p id="a023" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">通过粗略的观察，我们可以说“皮肤厚度”不是糖尿病的指标。但是我们不能否认在这一点上它是不可用的。</p><p id="bef9" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">因此，我们将使用所有可用的功能。我们将数据集分成特征和我们将要预测的响应。我们将把特征分配给X变量的<strong class="ka ir">，把响应分配给y变量</strong>的<strong class="ka ir">。</strong></p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="5ef0" class="nb kw iq mx b gy nc nd l ne nf">feature_names = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']</span><span id="6cb3" class="nb kw iq mx b gy ng nd l ne nf">X = diabetes_mod[feature_names]<br/>y = diabetes_mod.Outcome</span></pre><p id="7ae0" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">通常，特征工程在选择模型之前执行。然而，对于本教程，我们遵循不同的方法。最初，我们将利用数据集中提供给模型的所有功能，我们将再次讨论功能工程，以讨论所选模型的功能重要性。</p><p id="0bc5" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">这篇文章很好地解释了<a class="ae ly" href="https://elitedatascience.com/feature-engineering-best-practices" rel="noopener ugc nofollow" target="_blank">特征工程</a>。</p><h1 id="c249" class="kv kw iq bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">阶段4—型号选择</h1><p id="125c" class="pw-post-body-paragraph jy jz iq ka b kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr lx kt ku jx ij bi translated">模型选择或算法选择阶段是最令人兴奋的，也是机器学习的核心。在这个阶段，我们选择最适合手头数据集的模型。</p><p id="4faf" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">首先，我们将使用默认参数计算一组给定分类模型的<strong class="ka ir">“分类准确度(测试准确度)”</strong>，以确定哪个模型在糖尿病数据集上表现更好。</p><p id="3fd4" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">我们将为笔记本导入必要的库。我们导入7个分类器，即<strong class="ka ir">K-最近邻、支持向量分类器、逻辑回归、高斯朴素贝叶斯、随机森林和梯度提升</strong>作为最佳分类器的竞争者。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="a650" class="nb kw iq mx b gy nc nd l ne nf">from sklearn.neighbors import KNeighborsClassifier<br/>from sklearn.svm import SVC<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.naive_bayes import GaussianNB<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.ensemble import GradientBoostingClassifier</span></pre><p id="4946" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">我们将使用默认参数初始化分类器模型，并将它们添加到模型列表中。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="11e1" class="nb kw iq mx b gy nc nd l ne nf">models = []</span><span id="020e" class="nb kw iq mx b gy ng nd l ne nf">models.append(('KNN', KNeighborsClassifier()))<br/>models.append(('SVC', SVC()))<br/>models.append(('LR', LogisticRegression()))<br/>models.append(('DT', DecisionTreeClassifier()))<br/>models.append(('GNB', GaussianNB()))<br/>models.append(('RF', RandomForestClassifier()))<br/>models.append(('GB', GradientBoostingClassifier()))</span></pre><blockquote class="ni nj nk"><p id="b2ed" class="jy jz nh ka b kb mn kd ke kf mo kh ki nl mp kl km nm mq kp kq nn mr kt ku jx ij bi translated">例:通常用Scikit learn训练模型如下。</p><p id="1d07" class="jy jz nh ka b kb mn kd ke kf mo kh ki nl mp kl km nm mq kp kq nn mr kt ku jx ij bi translated">KNN = KNeighborsClassifier()<br/>KNN . fit(X _ train，y_train)</p></blockquote><h2 id="7962" class="nb kw iq bd kx og oh dn lb oi oj dp lf kj ok ol lj kn om on ln kr oo op lr oq bi translated">评估方法</h2><p id="07c1" class="pw-post-body-paragraph jy jz iq ka b kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr lx kt ku jx ij bi translated">通常的做法是避免对相同的数据进行训练和测试。原因是模型的目标是预测<strong class="ka ir">样本外数据</strong>，模型可能过于复杂，导致<strong class="ka ir">过度拟合</strong>。为了避免上述问题，有两个预防措施。</p><ol class=""><li id="13dd" class="lz ma iq ka b kb mn kf mo kj oc kn od kr oe jx of mf mg mh bi translated">训练/测试分割</li><li id="3239" class="lz ma iq ka b kb mi kf mj kj mk kn ml kr mm jx of mf mg mh bi translated">k倍交叉验证</li></ol><p id="4602" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">我们将为<strong class="ka ir">训练/测试拆分</strong>导入<em class="nh">“train _ test _ split”</em>，为 <strong class="ka ir"> <em class="nh">导入<em class="nh">“cross _ val _ score】k倍交叉验证</em> </em></strong> <em class="nh">。【accuracy _ score】</em>是评估训练/测试拆分方法中模型的准确性。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="1e1b" class="nb kw iq mx b gy nc nd l ne nf">from sklearn.model_selection import train_test_split<br/>from sklearn.model_selection import cross_val_score<br/>from sklearn.metrics import accuracy_score</span></pre><p id="4589" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">我们将执行上述方法，以找到性能最佳的基础模型。</p><h2 id="f8aa" class="nb kw iq bd kx og oh dn lb oi oj dp lf kj ok ol lj kn om on ln kr oo op lr oq bi translated"><strong class="ak">训练/测试分割</strong></h2><p id="c42a" class="pw-post-body-paragraph jy jz iq ka b kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr lx kt ku jx ij bi translated">这种方法将数据集分成两部分:一个<strong class="ka ir">训练集</strong>和一个<strong class="ka ir">测试集</strong>。<strong class="ka ir">训练集</strong>用于训练模型。<strong class="ka ir">测试装置</strong>用于测试模型，评估精度。</p><blockquote class="ni nj nk"><p id="5109" class="jy jz nh ka b kb mn kd ke kf mo kh ki nl mp kl km nm mq kp kq nn mr kt ku jx ij bi translated"><strong class="ka ir">优点:</strong>但是，训练/测试分割仍然有用，因为它的<strong class="ka ir">灵活性和速度</strong></p><p id="ccfe" class="jy jz nh ka b kb mn kd ke kf mo kh ki nl mp kl km nm mq kp kq nn mr kt ku jx ij bi translated"><strong class="ka ir">缺点:</strong>提供样本外精度的<strong class="ka ir">高方差估计</strong></p></blockquote><figure class="ms mt mu mv gt np gh gi paragraph-image"><div class="gh gi os"><img src="../Images/ad3d091020971da59513527ee6c1e971.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*u03UsvBGwkYD4E7BObpcaw.png"/></div><figcaption class="nw nx gj gh gi ny nz bd b be z dk">Fig — Train/Test Split</figcaption></figure><p id="ff9b" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated"><strong class="ka ir">用Scikit学习进行训练/测试分割:</strong></p><p id="271e" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">接下来，我们可以将特征和响应分成训练和测试部分。我们对样本进行分层(在此过程中，每个响应类别在每个部分中的比例应该相等)。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="a865" class="nb kw iq mx b gy nc nd l ne nf">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = diabetes_mod.Outcome, random_state=0)</span></pre><p id="2a27" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">然后，我们在一个循环中拟合每个模型，并使用<em class="nh">“accuracy _ score”</em>计算各个模型的精确度。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="35ae" class="nb kw iq mx b gy nc nd l ne nf">names = []<br/>scores = []</span><span id="7ed7" class="nb kw iq mx b gy ng nd l ne nf">for name, model in models:<br/>    model.fit(X_train, y_train)<br/>    y_pred = model.predict(X_test)<br/>    scores.append(accuracy_score(y_test, y_pred))<br/>    names.append(name)</span><span id="a574" class="nb kw iq mx b gy ng nd l ne nf">tr_split = pd.DataFrame({'Name': names, 'Score': scores})<br/>print(tr_split)</span></pre><figure class="ms mt mu mv gt np gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/29e4173824589967991148d963f67ae6.png" data-original-src="https://miro.medium.com/v2/resize:fit:426/format:webp/1*COXlYrcxGFfA75-NwbKaTQ.jpeg"/></div><figcaption class="nw nx gj gh gi ny nz bd b be z dk">Fig — Train/Test Split Accuracy Scores</figcaption></figure><h2 id="c6dc" class="nb kw iq bd kx og oh dn lb oi oj dp lf kj ok ol lj kn om on ln kr oo op lr oq bi translated"><strong class="ak"> K倍交叉验证</strong></h2><p id="e9a1" class="pw-post-body-paragraph jy jz iq ka b kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr lx kt ku jx ij bi translated">这种方法将数据集分成<strong class="ka ir"> K个等分</strong>(“折叠”)，然后使用1个折叠作为<strong class="ka ir">测试集</strong>，其他折叠的并集作为<strong class="ka ir">训练集</strong>。然后测试模型的准确性。该过程将遵循上述步骤K次，每次使用不同的折叠作为测试集。该工序的平均测试精度<strong class="ka ir">为测试精度。</strong></p><blockquote class="ni nj nk"><p id="3bb8" class="jy jz nh ka b kb mn kd ke kf mo kh ki nl mp kl km nm mq kp kq nn mr kt ku jx ij bi translated"><strong class="ka ir">优点:</strong>更精确的样本外精度估计。更“有效”地使用数据(每个观察结果都用于训练和测试)</p><p id="07b4" class="jy jz nh ka b kb mn kd ke kf mo kh ki nl mp kl km nm mq kp kq nn mr kt ku jx ij bi translated"><strong class="ka ir">缺点:</strong>比训练/测试分割慢得多。</p></blockquote><figure class="ms mt mu mv gt np gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/2348bed11268c9e0a5d7babff4b5eecb.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*8gAGGakxUIg8beFFJizOkw.png"/></div><figcaption class="nw nx gj gh gi ny nz bd b be z dk">Fig— 5-Fold cross validation process</figcaption></figure><blockquote class="ni nj nk"><p id="6f82" class="jy jz nh ka b kb mn kd ke kf mo kh ki nl mp kl km nm mq kp kq nn mr kt ku jx ij bi translated"><strong class="ka ir">在计算能力不匮乏的情况下，最好使用这种方法。从现在开始我们将使用这种方法。</strong></p></blockquote><p id="f8a6" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated"><strong class="ka ir">使用Scikit Learn进行K倍交叉验证:</strong></p><p id="5275" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">我们将继续进行K-Fold交叉验证，因为它更准确，并能更有效地利用数据。我们将使用10倍交叉验证来训练模型，并计算模型的平均准确度。“cross_val_score”提供了自己的训练和精度计算接口。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="00c6" class="nb kw iq mx b gy nc nd l ne nf">names = []<br/>scores = []</span><span id="12ae" class="nb kw iq mx b gy ng nd l ne nf">for name, model in models:<br/>    <br/>    kfold = KFold(n_splits=10, random_state=10) <br/>    score = cross_val_score(model, X, y, cv=kfold, scoring='accuracy').mean()<br/>    <br/>    names.append(name)<br/>    scores.append(score)</span><span id="57d7" class="nb kw iq mx b gy ng nd l ne nf">kf_cross_val = pd.DataFrame({'Name': names, 'Score': scores})<br/>print(kf_cross_val)</span></pre><figure class="ms mt mu mv gt np gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/66f4e71d720af66badb2a6462400b0f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*PbBBvPNRmFJ1Iomp2AHV5A.jpeg"/></div><figcaption class="nw nx gj gh gi ny nz bd b be z dk">Fig — K-Fold Cross Validation Accuracy Scores</figcaption></figure><p id="9951" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">我们可以使用seaborn来绘制准确度分数</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="4c12" class="nb kw iq mx b gy nc nd l ne nf">axis = sns.barplot(x = 'Name', y = 'Score', data = kf_cross_val)<br/>axis.set(xlabel='Classifier', ylabel='Accuracy')</span><span id="94c4" class="nb kw iq mx b gy ng nd l ne nf">for p in axis.patches:<br/>    height = p.get_height()<br/>    axis.text(p.get_x() + p.get_width()/2, height + 0.005, '{:1.4f}'.format(height), ha="center") <br/>    <br/>plt.show()</span></pre><figure class="ms mt mu mv gt np gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/b8738f3a095108a951e3e31635f578a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*9CUEFLHXYkuyEhtDp46yng.jpeg"/></div><figcaption class="nw nx gj gh gi ny nz bd b be z dk">Fig — Accuracy of Classifiers</figcaption></figure><p id="284d" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">我们可以看到逻辑回归、高斯朴素贝叶斯、随机森林和梯度推进比其他方法表现得更好。从基础水平上，我们可以观察到逻辑回归比其他算法表现更好。</p><blockquote class="jn"><p id="b3cb" class="jo jp iq bd jq jr ox oy oz pa pb jx dk translated">在基线时，逻辑回归设法实现了77.64 %的分类准确度。这将被选为下一阶段的主要候选项目。</p></blockquote><h1 id="963a" class="kv kw iq bd kx ky kz la lb lc ld le lf lg pc li lj lk pd lm ln lo pe lq lr ls bi translated">摘要</h1><p id="0577" class="pw-post-body-paragraph jy jz iq ka b kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr lx kt ku jx ij bi translated">在本文中，我们讨论了基本的机器学习工作流程步骤，如使用Scikit Learn库进行数据探索、数据清理步骤、特征工程基础知识和模型选择。在下一篇文章中，我将更多地讨论特征工程和超参数调整。</p><h1 id="9d28" class="kv kw iq bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">更新</h1><p id="57ef" class="pw-post-body-paragraph jy jz iq ka b kb lt kd ke kf lu kh ki kj lv kl km kn lw kp kq kr lx kt ku jx ij bi translated">您可以在下面的链接中找到本系列的第2部分。</p><div class="pf pg gp gr ph pi"><a rel="noopener follow" target="_blank" href="/machine-learning-workflow-on-diabetes-data-part-02-11262b7f7a5c"><div class="pj ab fo"><div class="pk ab pl cl cj pm"><h2 class="bd ir gy z fp pn fr fs po fu fw ip bi translated">糖尿病数据的机器学习工作流程:第2部分</h2><div class="pp l"><h3 class="bd b gy z fp pn fr fs po fu fw dk translated">在本系列的上一篇文章中，我们讨论了关于糖尿病数据集的机器学习工作流。还有…</h3></div><div class="pq l"><p class="bd b dl z fp pn fr fs po fu fw dk translated">towardsdatascience.com</p></div></div><div class="pr l"><div class="ps l pt pu pv pr pw nu pi"/></div></div></a></div><p id="71dd" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">创建这篇文章的源代码可以在下面找到。</p><div class="pf pg gp gr ph pi"><a href="https://github.com/LahiruTjay/Machine-Learning-With-Python/blob/master/Machine%20Learning%20Workflow%20on%20Diabetes%20Data.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="pj ab fo"><div class="pk ab pl cl cj pm"><h2 class="bd ir gy z fp pn fr fs po fu fw ip bi translated">LahiruTjay/用Python学习机器</h2><div class="pp l"><h3 class="bd b gy z fp pn fr fs po fu fw dk translated">这个库包含了各种用Python完成的机器学习的例子。</h3></div><div class="pq l"><p class="bd b dl z fp pn fr fs po fu fw dk translated">github.com</p></div></div><div class="pr l"><div class="px l pt pu pv pr pw nu pi"/></div></div></a></div><p id="7f10" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">如果你对这篇文章有任何问题，请不要犹豫，在下面留言或者给我发电子邮件:lahiru.tjay@gmail.com</p><p id="125b" class="pw-post-body-paragraph jy jz iq ka b kb mn kd ke kf mo kh ki kj mp kl km kn mq kp kq kr mr kt ku jx ij bi translated">希望你喜欢这篇文章。干杯！！！</p></div></div>    
</body>
</html>