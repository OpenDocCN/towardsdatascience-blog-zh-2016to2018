<html>
<head>
<title>Machine Learning — Multiclass Classification with Imbalanced Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习——不平衡数据集下的多类分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a?source=collection_archive---------0-----------------------#2018-12-22">https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a?source=collection_archive---------0-----------------------#2018-12-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="52dd" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">分类和提高性能的技术方面的挑战</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/6c8299545ff569d9664ac7be639f5c4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*D7LIBtVbQYLufYkx"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">source [<a class="ae kv" href="https://unsplash.com/photos/1CsaVdwfIew" rel="noopener ugc nofollow" target="_blank">Unsplash</a>]</figcaption></figure><p id="302c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">具有不平衡数据集的多个类的分类问题比二元分类问题提出了不同的挑战。偏斜分布使得许多传统的机器学习算法效率较低，尤其是在预测少数类示例时。为了做到这一点，让我们首先理解手头的问题，然后讨论克服这些问题的方法。</p><ol class=""><li id="04b3" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir">多类分类:</strong>两个以上类的分类任务；例如对一组水果图像进行分类，这些水果可以是橙子、苹果或梨。多类分类假设每个样本被赋予一个且仅一个标签:水果可以是苹果或梨，但不能同时是两者。</li><li id="eb21" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">不平衡数据集:</strong>不平衡数据通常指的是分类问题，其中类没有被平等地表示。例如，您可能有一个 3 类分类问题，将一组水果分类为总共有 100 个实例的橙子、苹果或梨。共有 80 个实例被标记为 1 类(橙子)，10 个实例被标记为 2 类(苹果)，其余 10 个实例被标记为 3 类(梨)。这是一个不平衡的数据集，比例为 8:1:1。大多数分类数据集在每个类中的实例数量并不完全相等，但是微小的差异通常并不重要。在一些问题中，阶层失衡不仅是普遍现象，也是意料之中的。例如，在描述欺诈交易的数据集中，数据是不平衡的。绝大多数交易属于“非欺诈”类，极少数属于“欺诈”类。</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/07c2038fe81938bed8a91fb3ad46c5d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*Luq-XVilHedVhBmUOfl7wA.png"/></div></figure><h1 id="979b" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">资料组</h1><p id="8bbb" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">我们将在这个例子中使用的数据集是著名的<a class="ae kv" href="http://qwone.com/~jason/20Newsgroups/" rel="noopener ugc nofollow" target="_blank">“20 个新闻组”</a>数据集。20 个新闻组数据集是大约 20，000 个新闻组文档的集合，平均分布在 20 个不同的新闻组中。20 个新闻组集合已经成为机器学习技术的文本应用实验的流行数据集，例如文本分类和文本聚类。</p><p id="c519" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> scikit-learn </strong>提供了预处理数据集的工具，更多详情请参考<a class="ae kv" href="https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html" rel="noopener ugc nofollow" target="_blank">此处的</a>。下面给出的每个新闻组的文章数量大致相同。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/d69865ac67572a3dd88cb957b4d78720.png" data-original-src="https://miro.medium.com/v2/resize:fit:460/format:webp/1*-lB8tGY7zJGJ296wXVcMNw.png"/></div></figure><p id="de13" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从一些组中删除一些新闻文章，以使整个数据集不平衡，如下所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/57d652eb2eb38fb44211fae5357b76ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:392/format:webp/1*-42z5YZr0hxBbNPWyl1jAw.png"/></div></figure><p id="c8e9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们有 20 个类的不平衡数据集可以做进一步的分析了。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/26e8878721cf976bcb7ae1a73f8be967.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z0n24YYWAi9zjrBVSwCtLg.png"/></div></div></figure><h1 id="adfe" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated"><strong class="ak">建立模型</strong></h1><p id="ad49" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">由于这是一个分类问题，我们将使用我之前的<a class="ae kv" rel="noopener" target="_blank" href="/machine-learning-word-embedding-sentiment-classification-using-keras-b83c28087456">文章</a>中描述的相似方法进行情感分析。唯一的区别是这里我们处理的是多类分类问题。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/effae6c3fe49f651dd4b23e4fba24a57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6lcfeP1cigOigxKlM3wzBQ.png"/></div></div></figure><p id="845a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ni">模型中最后一层是</em> <code class="fe nj nk nl nm b"><em class="ni">Dense(num_labels, activation =’softmax')</em></code> <em class="ni">，用</em> <code class="fe nj nk nl nm b"><em class="ni">num_labels=20</em></code> <em class="ni">类，用‘soft max’代替‘sigmoid’。模型中的另一个变化是将损失函数改为适用于多类问题的</em> <code class="fe nj nk nl nm b"><em class="ni">loss = ‘categorical_crossentropy’,</em></code> <em class="ni">。</em></p><h1 id="3f50" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated"><strong class="ak">列车型号</strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/77d800cdce7a3dfba1880826b8fa2634.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*tO60rAZ-DNhpggZOeC90Bg.png"/></div></figure><p id="bf18" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用 20%验证集<code class="fe nj nk nl nm b">validation_split=20</code>训练模型，并使用<code class="fe nj nk nl nm b">verbose=2,</code>，我们可以看到每个时期后的验证准确性。仅仅在 10 个时期之后，我们就达到了 90%的验证准确度。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/7c866a7fc4f2dc71cdf4c9eac8ce6613.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6flxOhOw80mW0ucLZ4gEuA.png"/></div></div></figure><h1 id="ceb8" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated"><strong class="ak">评估模型</strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/b42bc9be75bff54a90540d32b02728fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*qzLuvSXNu4MGHVLBIL8NpQ.png"/></div></figure><p id="69e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这看起来是一个非常好的精确度，但是这个模型真的做得很好吗？</p><blockquote class="nq nr ns"><p id="9684" class="kw kx ni ky b kz la jr lb lc ld ju le nt lg lh li nu lk ll lm nv lo lp lq lr ij bi translated"><strong class="ky ir">如何衡量模型表现？</strong>让我们考虑一下，我们在水果的早期示例的不平衡数据上训练我们的模型，由于数据严重偏向 1 类(橙子)，模型过度拟合 1 类标签，并在大多数情况下预测它，我们实现了 80%的准确度，乍一看似乎非常好，但仔细观察，它可能永远无法正确分类苹果或梨。现在的问题是，在这种情况下，如果准确性不是选择的正确指标，那么使用什么指标来衡量模型的性能呢？</p></blockquote><h1 id="8b3e" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">混淆矩阵</h1><p id="5264" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">对于不平衡的类，很容易获得高精度，而实际上没有做出有用的预测。所以，<strong class="ky ir">精度</strong>作为一个评价指标只有在类标签均匀分布的情况下才有意义。在不平衡类别的情况下，混淆矩阵是总结分类算法性能的好技术。</p><blockquote class="nq nr ns"><p id="da5b" class="kw kx ni ky b kz la jr lb lc ld ju le nt lg lh li nu lk ll lm nv lo lp lq lr ij bi translated">混淆矩阵是分类算法的性能度量，其中输出可以是两个或多个类别。</p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/933db40c0d14370daaa98284b8325737.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m_6tNlvUtYjpb4QBOZ0-rA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">x-axis=Predicted label, y-axis, True label</figcaption></figure><p id="0a19" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当我们仔细观察混淆矩阵时，我们会发现，与样本数量较多的类别[<em class="ni">rec . sport . hockey、rec.motorcycles </em> ]相比，样本数量较少的类别[<em class="ni">alt . athiesm、talk.politics.misc、soc.religion.christian </em> ]的得分[0.42、0.56、0.65]确实很低。因此，查看混淆矩阵，可以清楚地看到模型如何对各种类别进行分类。</p><h1 id="eec0" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">如何提高性能？</h1><p id="9dfd" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">有各种各样的技术可以提高不平衡数据集的性能。</p><h2 id="f694" class="nx mi iq bd mj ny nz dn mn oa ob dp mr lf oc od mt lj oe of mv ln og oh mx oi bi translated">重采样数据集</h2><p id="75ea" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">要使我们的数据集平衡，有两种方法:</p><ol class=""><li id="b3e1" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><strong class="ky ir">欠采样:</strong>从过度表示的类中移除样本；如果您有大量数据集，请使用此选项</li><li id="b2b7" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><strong class="ky ir">过采样:</strong>从代表性不足的类别中添加更多样本；如果数据集很小，请使用此选项</li></ol><h2 id="5f02" class="nx mi iq bd mj ny nz dn mn oa ob dp mr lf oc od mt lj oe of mv ln og oh mx oi bi translated">合成少数过采样技术</h2><p id="7518" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">SMOTE 是一种过采样方法。它创造了少数民族的合成样本。我们使用<a class="ae kv" href="https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir"><em class="ni">imb learn</em></strong></a>python 包对少数类进行过采样。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oj"><img src="../Images/efdd20c49ff822626c9d130142c1aaac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mHuRZW7Wg_yrv_IX3vT-tA.png"/></div></div></figure><p id="4886" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们在应用 SMOTE 之前有 4197 个样本，在应用 SMOTE 之后有 4646 个样本，看起来 SMOTE 增加了少数类的样本。我们将使用新数据集检查模型的性能。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ok"><img src="../Images/183b080295eaca69b891e02238cb969e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z6jWcOqGh74RZ_gK-GiC1A.png"/></div></div></figure><p id="5664" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">验证准确性从 90%提高到 94%。让我们测试一下这个模型:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/d2d3c946676362d8f9a760331aa84500.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*I5adsEnHL003Mt_ABZHTDQ.png"/></div></figure><p id="8d1d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">测试准确率比以前提高很少(从 87%提高到 88%)。现在让我们来看看混淆矩阵。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi om"><img src="../Images/666c4fdb88442492b0929416ff02000d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tgd8Za4vZqPXxVasplYXSw.png"/></div></div></figure><p id="f8f6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们看到[ <em class="ni"> alt.athiesm </em>，<em class="ni"> talk.politics.misc </em>，<em class="ni"> sci.electronics </em>，<em class="ni">SOC . religion . Christian</em>]这几门课比之前提高了分数【0.76，0.58，0.75，0.72】。因此，在对类别进行分类时，即使精确度相似，该模型的性能也比以前更好。</p><h2 id="3c27" class="nx mi iq bd mj ny nz dn mn oa ob dp mr lf oc od mt lj oe of mv ln og oh mx oi bi translated"><strong class="ak">另一招:</strong></h2><p id="d219" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">既然阶层不均衡，那给少数阶层提供一些偏向怎么样？在训练模型时，我们可以通过使用<code class="fe nj nk nl nm b">compute_class_weight</code>和使用参数<code class="fe nj nk nl nm b">‘class_weight’</code>来估计<a class="ae kv" href="https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html" rel="noopener ugc nofollow" target="_blank"> scikit_learn </a>中的类权重。这有助于在训练模型时提供对少数类的一些偏向，从而有助于在对各种类进行分类时提高模型的性能。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/2e2f5b287eba70ccff27c9652733a130.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MMrQa2B3EMSd_s4unRNvLw.png"/></div></div></figure><h1 id="349a" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">精确召回曲线</h1><p id="9431" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">当类别非常不平衡时，精确召回是预测成功的有用度量。<strong class="ky ir">精度</strong>是对分类模型仅识别相关数据点的<em class="ni">能力的度量，</em>而<strong class="ky ir"> <em class="ni">回忆</em> </strong> <em class="ni"> i </em> s 是对模型在数据集内找到所有相关案例的<em class="ni">能力的度量。</em></p><p id="4e3d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">精确度-召回率曲线显示了不同阈值的精确度和召回率之间的折衷。曲线下的高区域表示高召回率和高精度，其中高精度与低假阳性率相关，高召回率与低假阴性率相关。</p><blockquote class="oo"><p id="e1e6" class="op oq iq bd or os ot ou ov ow ox lr dk translated"><em class="oy"/><strong class="ak"><em class="oy">精度</em> </strong> <em class="oy">和</em> <strong class="ak"> <em class="oy">召回</em> </strong> <em class="oy">的高分表明分类器正在返回准确的结果(精度)，以及返回所有肯定结果(召回)的大部分。一个高精度、高召回率的理想系统会返回很多结果，所有结果都标注正确。</em></p></blockquote><p id="3b0b" class="pw-post-body-paragraph kw kx iq ky b kz oz jr lb lc pa ju le lf pb lh li lj pc ll lm ln pd lp lq lr ij bi translated">下面是使用<a class="ae kv" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>的<a class="ae kv" href="http://qwone.com/~jason/20Newsgroups/" rel="noopener ugc nofollow" target="_blank"> 20 个新闻组</a>数据集的精确召回图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pe"><img src="../Images/c52441457dd44ea27e0a79ee5098aa36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ydtd35PzAA_8hhXi3hBhpA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Precision-Recall Curve</figcaption></figure><p id="3ea3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们希望每一类的 P-R 曲线面积接近 1。除了 0 级、3 级和 18 级，其余级别的面积都在 0.75 以上。您可以尝试使用不同的分类模型和超参数调整技术来进一步改善结果。</p><h1 id="b1cc" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">结论</h1><p id="d451" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">我们讨论了与不平衡数据集中的多类分类相关的问题。我们还展示了使用正确的工具和技术如何帮助我们开发更好的分类模型。</p><p id="efe8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ni">感谢阅读。代码可以在<a class="ae kv" href="https://github.com/javaidnabi31/Multi-class-with-imbalanced-dataset-classification/blob/master/20-news-group-classification.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。</em></p><h1 id="0dad" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated"><strong class="ak">参考文献</strong></h1><div class="pf pg gp gr ph pi"><a href="https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/" rel="noopener  ugc nofollow" target="_blank"><div class="pj ab fo"><div class="pk ab pl cl cj pm"><h2 class="bd ir gy z fp pn fr fs po fu fw ip bi translated">应对机器学习数据集中不平衡类别的 8 种策略</h2><div class="pp l"><h3 class="bd b gy z fp pn fr fs po fu fw dk translated">你遇到过这种情况吗？您正在处理数据集。您创建了一个分类模型，并获得了 90%的准确率…</h3></div><div class="pq l"><p class="bd b dl z fp pn fr fs po fu fw dk translated">machinelearningmastery.com</p></div></div><div class="pr l"><div class="ps l pt pu pv pr pw kp pi"/></div></div></a></div><div class="pf pg gp gr ph pi"><a href="https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/" rel="noopener  ugc nofollow" target="_blank"><div class="pj ab fo"><div class="pk ab pl cl cj pm"><h2 class="bd ir gy z fp pn fr fs po fu fw ip bi translated">如何处理机器学习中的不平衡分类问题？</h2><div class="pp l"><h3 class="bd b gy z fp pn fr fs po fu fw dk translated">如果你在机器学习和数据科学上花了一些时间，你肯定会遇到…</h3></div><div class="pq l"><p class="bd b dl z fp pn fr fs po fu fw dk translated">www.analyticsvidhya.com</p></div></div><div class="pr l"><div class="px l pt pu pv pr pw kp pi"/></div></div></a></div><div class="pf pg gp gr ph pi"><a rel="noopener follow" target="_blank" href="/working-with-highly-imbalanced-datasets-in-machine-learning-projects-c70c5f2a7b16"><div class="pj ab fo"><div class="pk ab pl cl cj pm"><h2 class="bd ir gy z fp pn fr fs po fu fw ip bi translated">利用不平衡数据集提高机器学习模型性能的三种技术</h2><div class="pp l"><h3 class="bd b gy z fp pn fr fs po fu fw dk translated">这个项目是我最近“机器学习工程师”职位面试技能测试的一部分。我不得不…</h3></div><div class="pq l"><p class="bd b dl z fp pn fr fs po fu fw dk translated">towardsdatascience.com</p></div></div><div class="pr l"><div class="py l pt pu pv pr pw kp pi"/></div></div></a></div><div class="pf pg gp gr ph pi"><a rel="noopener follow" target="_blank" href="/understanding-confusion-matrix-a9ad42dcfd62"><div class="pj ab fo"><div class="pk ab pl cl cj pm"><h2 class="bd ir gy z fp pn fr fs po fu fw ip bi translated">理解混淆矩阵</h2><div class="pp l"><h3 class="bd b gy z fp pn fr fs po fu fw dk translated">当我们得到数据，经过数据清洗，预处理和争论，我们做的第一步是把它提供给一个…</h3></div><div class="pq l"><p class="bd b dl z fp pn fr fs po fu fw dk translated">towardsdatascience.com</p></div></div><div class="pr l"><div class="pz l pt pu pv pr pw kp pi"/></div></div></a></div><div class="pf pg gp gr ph pi"><a href="https://www.opencodez.com/python/text-classification-using-keras.htm" rel="noopener  ugc nofollow" target="_blank"><div class="pj ab fo"><div class="pk ab pl cl cj pm"><h2 class="bd ir gy z fp pn fr fs po fu fw ip bi translated">使用 Keras 深度学习 Python 库 opencodez 进行简单的文本分类</h2><div class="pp l"><h3 class="bd b gy z fp pn fr fs po fu fw dk translated">深度学习无处不在。所有组织，无论大小，都试图利用技术，发明一些很酷的…</h3></div><div class="pq l"><p class="bd b dl z fp pn fr fs po fu fw dk translated">www.opencodez.com</p></div></div><div class="pr l"><div class="qa l pt pu pv pr pw kp pi"/></div></div></a></div></div></div>    
</body>
</html>