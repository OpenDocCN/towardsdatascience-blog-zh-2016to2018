<html>
<head>
<title>BYOD: Build Your Own Dataset (for free using web scraping)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自带设备:建立自己的数据集(免费使用网络抓取)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/byod-build-your-own-dataset-for-free-67133840dc85?source=collection_archive---------2-----------------------#2018-07-19">https://towardsdatascience.com/byod-build-your-own-dataset-for-free-67133840dc85?source=collection_archive---------2-----------------------#2018-07-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/d276de10bb7e34e18147070c5db16c23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LDhLFA8DqhE9w3qZGfldhg.jpeg"/></div></div></figure><p id="9b5a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">十秒外卖:</strong> <em class="kw">了解如何通过简单的网络抓取创建自己的数据集，使用 python 的 beautiful soup 挖掘整个 Metacritic 网站的游戏评论，并免费托管在谷歌云平台(GCP)微(始终免费层)</em></p><p id="0841" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有抱负的数据科学家总是对学习理论后的第一步感到困惑。他们能够应用积累的知识的地方很少。当然，有大量的数据集可用，但免费的数据集永远不会给你解决实际问题的务实见解，或者有时它们太小，无法用于深度学习应用程序。</p><p id="5091" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">获取强大数据集的一种方式是付费或注册昂贵的课程，另一种方式是网络抓取。在这里，我告诉你如何免费使用 python 抓取大型数据集！</p><h2 id="0d01" class="kx ky iq bd kz la lb dn lc ld le dp lf kj lg lh li kn lj lk ll kr lm ln lo lp bi translated">为什么我选择了网络抓取和使用谷歌云？</h2><ul class=""><li id="c292" class="lq lr iq ka b kb ls kf lt kj lu kn lv kr lw kv lx ly lz ma bi translated"><strong class="ka ir">数据变得陈旧:</strong>当你搜集数据时，你可能会得到任何主题的最新数据。虽然你可以从 Kaggle 获得强大的数据集，但如果你想为你或你的公司创造一些新鲜的东西，比如说，抓取就是一种方法。如果你想为鞋子建立一个价格建议，你会想要来自亚马逊的最新趋势和价格，而不是两年前的数据。</li><li id="1114" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated"><strong class="ka ir">可定制:</strong>你可以定制代码，只从你想要的任何来源获取你需要的数据。</li><li id="cf74" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated"><strong class="ka ir">为什么不是本地的？由于云计算市场上有谷歌和亚马逊这样的大公司，出租一台电脑几个小时是非常便宜的。他们也给你一个免费层，这是完美的简单的东西，如网页抓取。GCP 稍微便宜一点，而且一开始会给你 300 美元的积分，所以我选择了 GCP。此外，我不希望我的 IP 被封锁(呵)</strong></li><li id="1d46" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated">有趣:这是我对周五晚上的想法！</li></ul><p id="f840" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在我的例子中，我没有找到一个很新的游戏评论数据集，因为 Metacrtic 拥有最大的游戏库，并且会定期更新，所以我决定使用它。</p><h2 id="9bdf" class="kx ky iq bd kz la lb dn lc ld le dp lf kj lg lh li kn lj lk ll kr lm ln lo lp bi translated"><strong class="ak">入门</strong></h2><p id="563a" class="pw-post-body-paragraph jy jz iq ka b kb ls kd ke kf lt kh ki kj mg kl km kn mh kp kq kr mi kt ku kv ij bi translated">您所需要做的就是遍历 URL 列表，识别数据容器，提取数据并将其存储在 csv 中。</p><p id="c2ae" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 1。使用的库</strong></p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="fa65" class="kx ky iq mo b gy ms mt l mu mv">import urllib2<br/>import csv<br/>from bs4 import BeautifulSoup<br/>import pandas as pd</span></pre><ul class=""><li id="df5b" class="lq lr iq ka b kb kc kf kg kj mw kn mx kr my kv lx ly lz ma bi translated"><strong class="ka ir"> urllib2 </strong>:我们的用于进行 url 请求的库。</li><li id="b5c7" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated">csv :以 csv 格式存储数据的库</li><li id="e6f5" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated"><strong class="ka ir"> bs4 </strong>:漂亮的汤库，让从网页中提取数据变得非常容易。</li><li id="9cc3" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated">熊猫:以漂亮的表格格式存储数据。</li></ul><p id="e556" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 2。了解网站的流程</strong></p><p id="9dd5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">元符号布局非常简单。所有数据的结构如下</p><p id="b796" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">http://www.metacritic.com/browse/<strong class="ka ir">游戏</strong>/发布日期/可用/pc/metascore？view=detailed &amp; page=1</p><p id="39a5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们来分解一下:</p><ul class=""><li id="589f" class="lq lr iq ka b kb kc kf kg kj mw kn mx kr my kv lx ly lz ma bi translated"><strong class="ka ir">http://www.metacritic.com/browse/</strong>:是域</li><li id="a6b8" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated"><strong class="ka ir">游戏:</strong>这给出了子部分，并且可以被其他子部分的电影/音乐替换</li><li id="0760" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated"><strong class="ka ir">可用/pc/ </strong>:此部分为 pc 提供数据。对于 ps4 游戏的数据，请将其更改为 ps4。</li><li id="5291" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated"><strong class="ka ir"> metascore </strong>:这给出了根据元分数的排名，我们可以将其更改为“<strong class="ka ir">user _ rating”</strong>以根据用户评分获得数据。</li><li id="f5b2" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated"><strong class="ka ir"> view=detailed : </strong>这给出了我们选择的视图类型 detailed，因为它包含更多的数据，如流派和成熟度等级。</li><li id="2ea0" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated"><strong class="ka ir"> page=x: </strong>这给出了页码<strong class="ka ir"> x </strong>。如果页码不存在，站点会返回一个没有数据的空白模板页面，并且不会抛出错误</li></ul><p id="ef35" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，我们决定包含数据的 html 元素。为此，我们使用 Chrome 中的<strong class="ka ir">检查</strong>工具。我们选择元素并突出显示子部分，以获得 html 元素及其类。</p><figure class="mj mk ml mm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/1ca089c45e91db50023a8527479df2bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VJfnmaJru1HQXZAVu9HdnQ.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">use the inspect button on the top right (circled) then highlight the area you want the HTML element for</figcaption></figure><figure class="mj mk ml mm gt jr gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/3610c53605b6968db05a5bd94d569070.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*i4tKEJHzIh2elfpCrzQdDA.png"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">the release data is in the element<strong class="bd nf"> li </strong>and has class<strong class="bd nf"> <em class="ng">stat release_date</em></strong></figcaption></figure><p id="6507" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们知道我们需要提取什么元素，让我们继续提取它们。</p><p id="7e0b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 3。发出 URL 请求</strong></p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="b843" class="kx ky iq mo b gy ms mt l mu mv">metacritic_base = “http://www.metacritic.com/browse/games/release-date/available/pc/metascore?view=detailed&amp;page="</span><span id="0f9d" class="kx ky iq mo b gy nh mt l mu mv">hdr= {‘Accept’: ‘text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8’, ‘User-Agent’ : “Magic Browser”}</span><span id="13c4" class="kx ky iq mo b gy nh mt l mu mv">filepath=’/Users/rra/Downloads/’</span><span id="a794" class="kx ky iq mo b gy nh mt l mu mv">for i in range(0,54):<br/>    metacritic = metacritic_base+str(i)<br/>    page = urllib2.Request(metacritic, headers=hdr )<br/>    content = urllib2.urlopen(page).read()</span></pre><p id="94e2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Metacritic 有一个简单的站点布局，带有一个静态 URL，其中每个页面的页码都是变化的。</p><p id="89df" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们使用了<strong class="ka ir"> urllib2。请求</strong>请求页面和<strong class="ka ir"> Urllib2 </strong>。<strong class="ka ir"> urlopen </strong>读取页面数据</p><p id="e0b4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">提示:有 53 页，所以我把我的计数器的最大值设为 54，但是你可以简单地在一次尝试中包括所有这些，除了遇到错误时退出。</p><p id="4501" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 4。提取数据</strong></p><p id="1d1d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然后我们读取数据</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="f428" class="kx ky iq mo b gy ms mt l mu mv">soup = BeautifulSoup(content, ‘html.parser’)<br/>right_class=soup.find_all(‘div’, class_=’product_wrap’)<br/>for item in right_class:</span><span id="822a" class="kx ky iq mo b gy nh mt l mu mv">    try:<br/>      link=item.find(‘h3’, class_=”product_title”).find(“a”)<br/>      g=link.get(‘href’)<br/>      except: g=’'</span><span id="b0cb" class="kx ky iq mo b gy nh mt l mu mv">      try:<br/>        score = item.find(“span”, class_=”metascore_w”)<br/>        s=score.text<br/>      except: s =’’</span><span id="0406" class="kx ky iq mo b gy nh mt l mu mv">      try:<br/>       dt = item.find("li", class_="release_date").find("span",    class_="data")<br/>       d=dt.text<br/>      except: dt=''</span><span id="1077" class="kx ky iq mo b gy nh mt l mu mv">     try:<br/>       rating=item.find("li",class_="stat  maturity_rating").find("span", class_="data")<br/>       r= rating.text<br/>     except: r=""</span><span id="d89a" class="kx ky iq mo b gy nh mt l mu mv">    try:<br/>      pub =item.find("li",class_="stat publisher").find("span", class_="data")<br/>      p= pub.text<br/>    except: p=''<br/>   <br/>   try:<br/>     genre= item.find("li",class_="stat genre").find("span", class_="data")<br/>     gr = genre.text<br/>   except: gr=''</span><span id="8eeb" class="kx ky iq mo b gy nh mt l mu mv">  try:<br/>   user_score=item.find("span", class_="textscore")<br/>   u = user_score.text<br/>   except: u=''</span></pre><p id="a3e1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们使用<strong class="ka ir"> BeautifulSoup(content，' html.parser') </strong>来完成解析大量 html 的所有繁重工作。</p><p id="f3f3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们在上一节中看到，每个游戏数据都在一个 div 中，其中包含一个名为<strong class="ka ir"> product_wrap </strong>的类。因此，我们提取所有这样的 div，并迭代每个 div 以获得数据。我们在这里存储以下数据:</p><ul class=""><li id="0773" class="lq lr iq ka b kb kc kf kg kj mw kn mx kr my kv lx ly lz ma bi translated">g:游戏名称</li><li id="bfc1" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated">学生:metascore</li><li id="7216" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated">发布日期</li><li id="e1d1" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated">出版商</li><li id="b7eb" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated">r:安全等级</li><li id="ce1d" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated">u:用户评级</li><li id="4008" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated">gr:流派</li></ul><p id="5665" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">提示</strong> : HTML 不可靠，所以最好使用<strong class="ka ir"> try:除了</strong>切换每个提取</p><p id="2239" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 5。保存数据</strong></p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="3c40" class="kx ky iq mo b gy ms mt l mu mv">game=[g,s,d,r,p,gr.strip(),u]<br/>df = pd.DataFrame([game])<br/>with open(filepath+'gamenames.csv', 'a') as f:<br/>   df.to_csv(f, header=False, index=False, quoting=csv.QUOTE_NONNUMERIC, sep="|")</span></pre><p id="41f6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们使用 pandas 将 list 的列表转换成表格，然后将数据写入 csv。这里我们使用<strong class="ka ir"> | </strong>作为分隔符，因为流派列包含<strong class="ka ir">、</strong>(逗号)</p><p id="110f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 6。在谷歌云上运行代码</strong></p><p id="385e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我想你应该知道如何开设一个 GCP 账户。如果现在，请跟随<a class="ae ni" href="https://www.datacamp.com/community/tutorials/google-cloud-data-science" rel="noopener ugc nofollow" target="_blank">这篇博文</a>学习如何做。您需要创建一个实例，如下所示。</p><figure class="mj mk ml mm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nj"><img src="../Images/2634c7ce0166f1457af4afcb3561a9ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AE6ppjxVglB9CfqyAx1hDQ.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Creating a GCP instance</figcaption></figure><p id="849a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一旦它运行，您需要在它上面安装 python，并将代码从您的本地机器复制到实例中。这里<strong class="ka ir">球形乌鸦</strong>是项目名称，<strong class="ka ir">实例-2 </strong>是实例名称。你还需要指定谷歌的时区。</p><p id="7fdc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">提示</strong>:记得在 ssh 到实例后更新你的 ubuntu。</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="615a" class="kx ky iq mo b gy ms mt l mu mv">gcloud compute — project “spheric-crow” ssh — zone “us-east1-b” “instance-2”</span><span id="a777" class="kx ky iq mo b gy nh mt l mu mv">gcloud compute scp scrap.py instance-1:scrap</span></pre><p id="3032" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> scp </strong>将文件从本地机器复制到 GCP 实例。接下来，您需要在您的实例上安装上述库。接下来安装<a class="ae ni" href="http://byobu.co/" rel="noopener ugc nofollow" target="_blank"> <strong class="ka ir"> byobu </strong> </a>这是一个基于文本的 windows 管理器。这将保持会话完整，即使您的 ssh 连接中断。</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="f450" class="kx ky iq mo b gy ms mt l mu mv">Sudo apt-get install byobu<br/>byobu</span></pre><figure class="mj mk ml mm gt jr gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/5e04e2b9883d2cbbdf4ee28ad20005d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*skQxsqihnjAgwzpV5wYQtg.png"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">byobu interface, you create separate tabs and run multiple code at the same time</figcaption></figure><p id="8242" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后使用下面的命令运行代码，就完成了。</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="3ea4" class="kx ky iq mo b gy ms mt l mu mv">python scrap.py</span></pre><p id="a3f6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">提示:您可以从我的 github 帐户中选择 scp 或简单的 git pull。</p><p id="6ea3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 7。检索挖掘的数据</strong></p><p id="78e9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您可以再次使用 scp 从云中获取挖掘的数据，现在您有了一个非常酷的数据集可以使用了！</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="3088" class="kx ky iq mo b gy ms mt l mu mv">gcloud compute scp instance-1:scrap/game_review.csv /Users/</span></pre><p id="8284" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然后，您可以使用 python 作为</p><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="05a9" class="kx ky iq mo b gy ms mt l mu mv">import pandas as pd<br/>df= pd.read_csv(“/metacritic_scrap/gamenames.csv”, sep=”|”)<br/>df.columns=[“game”, “metascore”,”release_date”, “maturity_rating”,”publisher”, “genre”, “user_rating”]</span></pre><p id="7663" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你的数据集看起来会像</p><figure class="mj mk ml mm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nl"><img src="../Images/7c70eb453b142cf935b851e28f40ce07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dRKQCg-ZNBZ6mkU7zAAq1A.png"/></div></div></figure><p id="cc0b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">看看这个结构有多好！</p><p id="93ff" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">提示</strong>:你也可以自动完成这项工作！</p><h2 id="ff0e" class="kx ky iq bd kz la lb dn lc ld le dp lf kj lg lh li kn lj lk ll kr lm ln lo lp bi translated"><strong class="ak">提示和技巧</strong></h2><ol class=""><li id="8e12" class="lq lr iq ka b kb ls kf lt kj lu kn lv kr lw kv nm ly lz ma bi translated"><strong class="ka ir">礼貌点:</strong>大多数网站会反对你挖掘他们的内容，因为这会给他们的服务器带来很大压力。尽量避免在短时间内提出过多的请求，并阅读<strong class="ka ir"> robots.txt </strong>文件。这里有一些尽可能减少错误的技巧:</li></ol><ul class=""><li id="6275" class="lq lr iq ka b kb kc kf kg kj mw kn mx kr my kv lx ly lz ma bi translated"><strong class="ka ir"> Sleep </strong>:包括<strong class="ka ir"> sleep </strong>，在下一个请求发出前将代码延迟几秒钟。我更喜欢使用<strong class="ka ir"> sleep (randint(a，b)) </strong>即使用随机整数而不是固定值。</li></ul><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="25c5" class="kx ky iq mo b gy ms mt l mu mv">from random import randint<br/>from time import sleep<br/>#pause for 20-100 seconds randomly<br/>sleep(randint(20,100))</span></pre><ul class=""><li id="3c54" class="lq lr iq ka b kb kc kf kg kj mw kn mx kr my kv lx ly lz ma bi translated"><strong class="ka ir">用户代理:</strong>是浏览器或 app 发送给你访问的每个网站的字符串。我们使用一个<strong class="ka ir">用户代理生成器</strong>来欺骗网站，让它认为请求来自不同的浏览器。由于许多机构使用同一个 IP，我们通常不会冒太多请求错误的风险。<a class="ae ni" href="https://developers.whatismybrowser.com/useragents/explore/" rel="noopener ugc nofollow" target="_blank"> <strong class="ka ir">这里的</strong> </a>是你可以使用的热门用户代理列表。</li></ul><pre class="mj mk ml mm gt mn mo mp mq aw mr bi"><span id="0978" class="kx ky iq mo b gy ms mt l mu mv">from user_agent import generate_user_agent</span></pre><ul class=""><li id="dd07" class="lq lr iq ka b kb kc kf kg kj mw kn mx kr my kv lx ly lz ma bi translated">VPN 和代理:如果你正在挖掘一个大的数据集，你最终会得到一个太多请求的错误。就我而言，大约每 2000 页。因此，为了应对这种情况，您可以轮换几个代理，并在每次实例运行时获得大约 5k 的页面。你可以在这里获得一些免费代理<a class="ae ni" href="https://free-proxy-list.net/" rel="noopener ugc nofollow" target="_blank">。</a></li></ul><p id="b701" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 2。陷入验证码中:</strong>一些网站真的不想让你抓取他们的数据，他们会在适当的地方设置验证码。如果这是一个简单的 4-5 个字母数字的验证码，你可以尝试使用<strong class="ka ir"> Python 宇宙魔方</strong>和<a class="ae ni" href="https://medium.com/@ageitgey/how-to-break-a-captcha-system-in-15-minutes-with-machine-learning-dbebb035a710" rel="noopener">这种技术来破解。</a>如果是谷歌重新验证码，你每次都要像这些人一样手动解决。</p><p id="eea6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 3。异常处理:</strong> HTML 非常不可靠，站点可能不会一直遵循严格的模式，所以最佳实践是在<strong class="ka ir"> try:except </strong>语句中包含每个元素。</p><p id="3b8b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">4.<strong class="ka ir">定期保存:</strong> Web 抓取是一项有风险的业务，如果您不定期保存数据，您可能会丢失迄今挖掘的整个数据集。一个简单的解决方案是定期将数据保存在 csv 中(像我一样)或使用 SQLite(像聪明人一样)。关于 sqlite 的介绍可以在<a class="ae ni" href="http://stackabuse.com/a-sqlite-tutorial-with-python/" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h2 id="df2e" class="kx ky iq bd kz la lb dn lc ld le dp lf kj lg lh li kn lj lk ll kr lm ln lo lp bi translated">下一步是什么？</h2><p id="831b" class="pw-post-body-paragraph jy jz iq ka b kb ls kd ke kf lt kh ki kj mg kl km kn mh kp kq kr mi kt ku kv ij bi translated">我们可以使用相同的代码来挖掘其他内容负载的元符号，只需更改基本 url:</p><ul class=""><li id="77d5" class="lq lr iq ka b kb kc kf kg kj mw kn mx kr my kv lx ly lz ma bi translated">电影评论/评级</li><li id="f0b3" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated">电视节目评论/收视率</li><li id="cb5d" class="lq lr iq ka b kb mb kf mc kj md kn me kr mf kv lx ly lz ma bi translated">音乐评论/评级</li></ul><p id="d26e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我扩展了我的代码，以挖掘大约 5k 个 PC 游戏的所有大约 100k 个用户评论的数据，并且我已经提到我将把它用于游戏推荐引擎(随后是博客帖子)。如果你想分一杯羹<a class="ae ni" href="mailto:rra.iitk@gmail.com" rel="noopener ugc nofollow" target="_blank"> <strong class="ka ir">发邮件</strong> </a>给我，我会给你发一部分数据集！</p><p id="350b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Metracritic 的网站布局非常容易理解，并且通过一个简单的 for 循环来复制，但对于挖掘更复杂的网站，如亚马逊，我们使用一个名为<strong class="ka ir">木偶师</strong>的浏览器自动化工具，它模拟点击来生成下一页等等。</p><p id="f7a0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">看看艾玛德·艾山关于如何使用木偶师的博客。</p><p id="782e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这篇博客的全部代码可以在我的 git 上找到。用户评论抓取的完整代码也可以在这里找到。</p><p id="e3b3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在下一篇博客中，我将对这个伟大的数据集进行一些数据辩论和深度学习。敬请期待！</p><p id="89e1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是我的第一篇帖子，如果你喜欢，请评论并鼓掌:)</p></div></div>    
</body>
</html>