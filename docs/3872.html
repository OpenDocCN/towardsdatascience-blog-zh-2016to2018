<html>
<head>
<title>Building Convolutional Neural Network using NumPy from Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 NumPy 从头构建卷积神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-convolutional-neural-network-using-numpy-from-scratch-b30aac50e50a?source=collection_archive---------2-----------------------#2018-06-27">https://towardsdatascience.com/building-convolutional-neural-network-using-numpy-from-scratch-b30aac50e50a?source=collection_archive---------2-----------------------#2018-06-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="e97c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在某些情况下，使用 ML/DL 库中已经存在的模型可能会有所帮助。但是要有更好的控制和理解，你应该试着自己实现它们。这篇文章展示了如何使用 NumPy 实现 CNN。</p></div><div class="ab cl kl km hu kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ij ik il im in"><h1 id="35d8" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">介绍</h1><p id="7146" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">卷积神经网络(CNN)是用于分析图像等多维信号的最先进技术。已经有不同的库实现了 CNN，比如 TensorFlow 和 Keras。这种库将开发人员与一些细节隔离开来，只是给出一个抽象的 API，使生活变得更容易，并避免实现中的复杂性。但实际上，这些细节可能会有所不同。有时，数据科学家必须仔细检查这些细节以提高性能。在这种情况下，解决方法是构建你自己的模型的每一部分。这提供了对网络的最高级别的控制。此外，建议实现这样的模型，以便更好地理解它们。</p><p id="53d1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，CNN 仅使用 NumPy 库创建。只创建了三层，分别是卷积(简称 conv)、ReLU 和最大池。涉及的主要步骤如下:</p><p id="4a45" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1.读取输入图像。</p><p id="1cf3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2.准备过滤器。</p><p id="a32e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3.Conv 层:卷积每个滤波器与输入图像。</p><p id="1f04" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">4.ReLU 图层:在特征地图上应用 ReLU 激活功能(conv 图层的输出)。</p><p id="6138" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">5.最大池层:在 ReLU 层的输出上应用池操作。</p><p id="7ff7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">6.堆叠 conv、ReLU 和 max 池层。</p></div><div class="ab cl kl km hu kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ij ik il im in"><h1 id="5d30" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">1.读取输入图像</h1><p id="f491" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">以下代码从 skimage Python 库中读取一个已经存在的图像，并将其转换为灰色。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="5626" class="me kt iq ma b gy mf mg l mh mi"><strong class="ma ir">import</strong> skimage.data</span><span id="6650" class="me kt iq ma b gy mj mg l mh mi"># Reading the image</span><span id="88ee" class="me kt iq ma b gy mj mg l mh mi">img = skimage.data.chelsea()</span><span id="b907" class="me kt iq ma b gy mj mg l mh mi"># Converting the image into gray.</span><span id="b212" class="me kt iq ma b gy mj mg l mh mi">img = skimage.color.rgb2gray(img)</span></pre><p id="0cde" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">读取图像是第一步，因为后续步骤取决于输入尺寸。转换为灰色后的图像如下所示。</p><figure class="lv lw lx ly gt ml gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/241452d95951bf539b5d6395b132b15a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*boLyxBSCco5OckXCR3-k5Q.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk"><strong class="bd ms">Figure 1. Original Gray Image. It is the Skimage image named Chelsea accessed via skimage.data.chelsea()</strong></figcaption></figure><h1 id="5b8c" class="ks kt iq bd ku kv mt kx ky kz mu lb lc ld mv lf lg lh mw lj lk ll mx ln lo lp bi translated">2.准备过滤器</h1><p id="3318" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">下面的代码为第一个 conv 图层准备了滤波器组(简称为<strong class="jp ir"> l1 </strong>):</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="d0f4" class="me kt iq ma b gy mf mg l mh mi">l1_filter = numpy.zeros((2,3,3))</span></pre><p id="0f2b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">根据过滤器的数量和每个过滤器的大小创建零数组。创建大小为<strong class="jp ir">3×3</strong>的<strong class="jp ir"> 2 </strong>个过滤器，这就是为什么零数组的大小为(<strong class="jp ir">2</strong>=数量 _ 过滤器，<strong class="jp ir">3</strong>=数量 _ 行 _ 过滤器，<strong class="jp ir">3</strong>=数量 _ 列 _ 过滤器)。滤波器的大小被选择为没有深度的 2D 阵列，因为输入图像是灰色的并且没有深度(即 2D)。如果图像是具有 3 个通道的 RGB，则滤镜大小必须为(3，3，<strong class="jp ir">3</strong>=深度)。</p><p id="395d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">滤波器组的大小由上述零数组指定，而不是由滤波器的实际值指定。可以覆盖如下值来检测垂直和水平边缘。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="ad37" class="me kt iq ma b gy mf mg l mh mi">l1_filter[0, :, :] = numpy.array([[[-1, 0, 1],</span><span id="8d95" class="me kt iq ma b gy mj mg l mh mi">                                   [-1, 0, 1],</span><span id="3ad9" class="me kt iq ma b gy mj mg l mh mi">                                   [-1, 0, 1]]])</span><span id="d6b8" class="me kt iq ma b gy mj mg l mh mi">l1_filter[1, :, :] = numpy.array([[[1,   1,  1],</span><span id="53a1" class="me kt iq ma b gy mj mg l mh mi">                                   [0,   0,  0],</span><span id="1b15" class="me kt iq ma b gy mj mg l mh mi">                                   [-1, -1, -1]]])</span></pre><h1 id="9dab" class="ks kt iq bd ku kv mt kx ky kz mu lb lc ld mv lf lg lh mw lj lk ll mx ln lo lp bi translated">3.Conv 层</h1><p id="a335" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">准备好滤波器后，下一步是用它们对输入图像进行卷积。下一行使用名为<strong class="jp ir"> conv </strong>的函数将图像与滤波器组进行卷积:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="0909" class="me kt iq ma b gy mf mg l mh mi">l1_feature_map = conv(img, l1_filter)</span></pre><p id="c654" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该函数只接受两个参数，即图像和滤波器组，如下所示。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="4c61" class="me kt iq ma b gy mf mg l mh mi">def conv(img, conv_filter):<br/>    if len(img.shape) &gt; 2 or len(conv_filter.shape) &gt; 3: # Check if number of image channels matches the filter depth.<br/>        if img.shape[-1] != conv_filter.shape[-1]:<br/>            print("Error: Number of channels in both image and filter must match.")<br/>            sys.exit()<br/>    if conv_filter.shape[1] != conv_filter.shape[2]: # Check if filter dimensions are equal.<br/>        print('Error: Filter must be a square matrix. I.e. number of rows and columns must match.')<br/>        sys.exit()<br/>    if conv_filter.shape[1]%2==0: # Check if filter diemnsions are odd.<br/>        print('Error: Filter must have an odd size. I.e. number of rows and columns must be odd.')<br/>        sys.exit()<br/><br/>    # An empty feature map to hold the output of convolving the filter(s) with the image.<br/>    feature_maps = numpy.zeros((img.shape[0]-conv_filter.shape[1]+1, <br/>                                img.shape[1]-conv_filter.shape[1]+1, <br/>                                conv_filter.shape[0]))<br/><br/>    # Convolving the image by the filter(s).<br/>    for filter_num in range(conv_filter.shape[0]):<br/>        print("Filter ", filter_num + 1)<br/>        curr_filter = conv_filter[filter_num, :] # getting a filter from the bank.<br/>        """ <br/>        Checking if there are mutliple channels for the single filter.<br/>        If so, then each channel will convolve the image.<br/>        The result of all convolutions are summed to return a single feature map.<br/>        """<br/>        if len(curr_filter.shape) &gt; 2:<br/>            conv_map = conv_(img[:, :, 0], curr_filter[:, :, 0]) # Array holding the sum of all feature maps.<br/>            for ch_num in range(1, curr_filter.shape[-1]): # Convolving each channel with the image and summing the results.<br/>                conv_map = conv_map + conv_(img[:, :, ch_num], <br/>                                  curr_filter[:, :, ch_num])<br/>        else: # There is just a single channel in the filter.<br/>            conv_map = conv_(img, curr_filter)<br/>        feature_maps[:, :, filter_num] = conv_map # Holding feature map with the current filter.<br/>    return feature_maps # Returning all feature maps.</span></pre><p id="5835" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该功能首先确保每个滤镜的深度等于图像通道的数量。在下面的代码中，外部的<strong class="jp ir"> if </strong>检查通道和过滤器是否有深度。如果深度已经存在，那么内部的<strong class="jp ir"> if </strong>检查它们的不相等。如果不匹配，那么脚本将退出。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="f6ab" class="me kt iq ma b gy mf mg l mh mi">if len(img.shape) &gt; 2 or len(conv_filter.shape) &gt; 3: # Check if number of image channels matches the filter depth.<br/>        if img.shape[-1] != conv_filter.shape[-1]:<br/>            print("Error: Number of channels in both image and filter must match.")<br/>            sys.exit()</span></pre><p id="1e40" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，过滤器的大小应该是奇数，并且过滤器尺寸相等(即，行数和列数是奇数并且相等)。根据以下两个<strong class="jp ir"> if </strong>块进行检查。如果不满足这些条件，脚本将退出。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="a561" class="me kt iq ma b gy mf mg l mh mi">if conv_filter.shape[1] != conv_filter.shape[2]: # Check if filter dimensions are equal.<br/>        print('Error: Filter must be a square matrix. I.e. number of rows and columns must match.')<br/>        sys.exit()<br/>    if conv_filter.shape[1]%2==0: # Check if filter diemnsions are odd.<br/>        print('Error: Filter must have an odd size. I.e. number of rows and columns must be odd.')<br/>        sys.exit()</span></pre><p id="c6bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不满足上面的任何条件都证明滤波器深度适合图像，并且卷积准备好被应用。通过滤波器对图像进行卷积，首先初始化一个数组，通过根据以下代码指定其大小来保存卷积的输出(即特征图):</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="793e" class="me kt iq ma b gy mf mg l mh mi"># An empty feature map to hold the output of convolving the filter(s) with the image.<br/>    feature_maps = numpy.zeros((img.shape[0]-conv_filter.shape[1]+1, <br/>                                img.shape[1]-conv_filter.shape[1]+1, <br/>                                conv_filter.shape[0]))</span></pre><p id="7c58" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为既没有步幅也没有填充，所以特征映射的大小将等于(img_rows-filter_rows+1，image_columns-filter_columns+1，num_filters ),如上面代码中所示。注意，组中的每个滤波器都有一个输出特征映射。这就是为什么滤波器组中的滤波器数量(<strong class="jp ir">conv _ 滤波器.形状[0] </strong>)被用来指定大小作为第三个参数。</p><p id="b354" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">准备好卷积运算的输入和输出后，接下来是根据以下代码应用它:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="d6af" class="me kt iq ma b gy mf mg l mh mi"># Convolving the image by the filter(s).<br/>    for filter_num in range(conv_filter.shape[0]):<br/>        print("Filter ", filter_num + 1)<br/>        curr_filter = conv_filter[filter_num, :] # getting a filter from the bank.<br/>        """ <br/>        Checking if there are mutliple channels for the single filter.<br/>        If so, then each channel will convolve the image.<br/>        The result of all convolutions are summed to return a single feature map.<br/>        """<br/>        if len(curr_filter.shape) &gt; 2:<br/>            conv_map = conv_(img[:, :, 0], curr_filter[:, :, 0]) # Array holding the sum of all feature maps.<br/>            for ch_num in range(1, curr_filter.shape[-1]): # Convolving each channel with the image and summing the results.<br/>                conv_map = conv_map + conv_(img[:, :, ch_num], <br/>                                  curr_filter[:, :, ch_num])<br/>        else: # There is just a single channel in the filter.<br/>            conv_map = conv_(img, curr_filter)<br/>        feature_maps[:, :, filter_num] = conv_map # Holding feature map with the current filter.<br/>    return feature_maps # Returning all feature maps.</span></pre><p id="9356" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">外部循环对滤波器组中的每个滤波器进行迭代，并根据以下代码行返回它以进行进一步的步骤:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="9e52" class="me kt iq ma b gy mf mg l mh mi">curr_filter = conv_filter[filter_num, :] # getting a filter from the bank.</span></pre><p id="93e5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果要卷积的图像有不止一个通道，那么滤波器的深度必须等于这些通道的数量。在这种情况下，卷积是通过将每个图像通道与其在滤波器中的对应通道进行卷积来完成的。最后，结果的总和将是输出特征图。如果图像只有一个通道，那么卷积将是直接的。确定这样的行为是在这样的<strong class="jp ir"> if-else </strong>块中完成的:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="9e5b" class="me kt iq ma b gy mf mg l mh mi">if len(curr_filter.shape) &gt; 2:<br/>            conv_map = conv_(img[:, :, 0], curr_filter[:, :, 0]) # Array holding the sum of all feature maps.<br/>            for ch_num in range(1, curr_filter.shape[-1]): # Convolving each channel with the image and summing the results.<br/>                conv_map = conv_map + conv_(img[:, :, ch_num], <br/>                                  curr_filter[:, :, ch_num])<br/>        else: # There is just a single channel in the filter.<br/>            conv_map = conv_(img, curr_filter)</span></pre><p id="14d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可能会注意到，卷积是由一个名为<strong class="jp ir"> conv_ </strong>的函数应用的，它不同于<strong class="jp ir"> conv </strong>函数。函数<strong class="jp ir"> conv </strong>只接受输入图像和滤波器组，但不应用自己的卷积。它只是将每组输入滤波器对传递给<strong class="jp ir"> conv_ </strong>函数进行卷积。这只是为了使代码更容易研究。下面是<strong class="jp ir"> conv_ </strong>函数的实现:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="17a6" class="me kt iq ma b gy mf mg l mh mi">def conv_(img, conv_filter):<br/>    filter_size = conv_filter.shape[1]<br/>    result = numpy.zeros((img.shape))<br/>    #Looping through the image to apply the convolution operation.<br/>    for r in numpy.uint16(numpy.arange(filter_size/2.0, <br/>                          img.shape[0]-filter_size/2.0+1)):<br/>        for c in numpy.uint16(numpy.arange(filter_size/2.0, <br/>                                           img.shape[1]-filter_size/2.0+1)):<br/>            """<br/>            Getting the current region to get multiplied with the filter.<br/>            How to loop through the image and get the region based on <br/>            the image and filer sizes is the most tricky part of convolution.<br/>            """<br/>            curr_region = img[r-numpy.uint16(numpy.floor(filter_size/2.0)):r+numpy.uint16(numpy.ceil(filter_size/2.0)), <br/>                              c-numpy.uint16(numpy.floor(filter_size/2.0)):c+numpy.uint16(numpy.ceil(filter_size/2.0))]<br/>            #Element-wise multipliplication between the current region and the filter.<br/>            curr_result = curr_region * conv_filter<br/>            conv_sum = numpy.sum(curr_result) #Summing the result of multiplication.<br/>            result[r, c] = conv_sum #Saving the summation in the convolution layer feature map.<br/>            <br/>    #Clipping the outliers of the result matrix.<br/>    final_result = result[numpy.uint16(filter_size/2.0):result.shape[0]-numpy.uint16(filter_size/2.0), <br/>                          numpy.uint16(filter_size/2.0):result.shape[1]-numpy.uint16(filter_size/2.0)]<br/>    return final_result</span></pre><p id="e0d1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它对图像进行迭代，并根据以下代码行提取与过滤器大小相等的区域:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="5cea" class="me kt iq ma b gy mf mg l mh mi">curr_region = img[r-numpy.uint16(numpy.floor(filter_size/2.0)):r+numpy.uint16(numpy.ceil(filter_size/2.0)), <br/>                              c-numpy.uint16(numpy.floor(filter_size/2.0)):c+numpy.uint16(numpy.ceil(filter_size/2.0))]</span></pre><p id="7c7a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，它在区域和过滤器之间应用元素级乘法，并对它们求和，以获得作为输出的单个值，如下所示:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="adf6" class="me kt iq ma b gy mf mg l mh mi">#Element-wise multipliplication between the current region and the filter.<br/>            curr_result = curr_region * conv_filter<br/>            conv_sum = numpy.sum(curr_result) #Summing the result of multiplication.<br/>            result[r, c] = conv_sum #Saving the summation in the convolution layer feature map.</span></pre><p id="a547" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在通过输入对每个滤波器进行卷积之后，特征图由<strong class="jp ir"> conv </strong>函数返回。图 2 显示了此类 conv 图层返回的要素地图。</p><figure class="lv lw lx ly gt ml gh gi paragraph-image"><div class="gh gi my"><img src="../Images/cf1b53e01222467b14c1a2bebf91934a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*dnG3xqMsIurrJAXX8dh8oA.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk"><strong class="bd ms">Figure 2. Output feature maps of the first conv layer.</strong></figcaption></figure><p id="7766" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该层的输出将被应用到 ReLU 层。</p><h1 id="37cc" class="ks kt iq bd ku kv mt kx ky kz mu lb lc ld mv lf lg lh mw lj lk ll mx ln lo lp bi translated">4.ReLU 层</h1><p id="af5a" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">ReLU 图层对 conv 图层返回的每个要素地图应用 ReLU 激活函数。根据下面的代码行，使用<strong class="jp ir"> relu </strong>函数调用它:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="3d5f" class="me kt iq ma b gy mf mg l mh mi">l1_feature_map_relu = relu(l1_feature_map)</span></pre><p id="79b1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> relu </strong>功能实现如下:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="1e43" class="me kt iq ma b gy mf mg l mh mi">def relu(feature_map):<br/>    #Preparing the output of the ReLU activation function.<br/>    relu_out = numpy.zeros(feature_map.shape)<br/>    for map_num in range(feature_map.shape[-1]):<br/>        for r in numpy.arange(0,feature_map.shape[0]):<br/>            for c in numpy.arange(0, feature_map.shape[1]):<br/>                relu_out[r, c, map_num] = numpy.max([feature_map[r, c, map_num], 0])<br/>    return relu_out</span></pre><p id="525f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这很简单。只需遍历特征映射中的每个元素，如果大于 0，则返回特征映射中的原始值。否则，返回 0。ReLU 层的输出如图 3 所示。</p><figure class="lv lw lx ly gt ml gh gi paragraph-image"><div class="gh gi my"><img src="../Images/80ed3beece429b705c89412a1d7c63f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*9dUr9gS21hzybj2mcWkHjw.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk"><strong class="bd ms">Figure 3. ReLU layer output applied to the output of the first conv layer</strong></figcaption></figure><p id="dff4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">ReLU 层的输出被应用到 max pooling 层。</p><h1 id="c409" class="ks kt iq bd ku kv mt kx ky kz mu lb lc ld mv lf lg lh mw lj lk ll mx ln lo lp bi translated">5.最大池层</h1><p id="b412" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">最大池层接受 ReLU 层的输出，并根据以下代码行应用最大池操作:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="f00a" class="me kt iq ma b gy mf mg l mh mi">l1_feature_map_relu_pool = pooling(l1_feature_map_relu, 2, 2)</span></pre><p id="1f6c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它是使用<strong class="jp ir">池</strong>函数实现的，如下所示:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="9398" class="me kt iq ma b gy mf mg l mh mi">def pooling(feature_map, size=2, stride=2):<br/>    #Preparing the output of the pooling operation.<br/>    pool_out = numpy.zeros((numpy.uint16((feature_map.shape[0]-size+1)/stride),<br/>                            numpy.uint16((feature_map.shape[1]-size+1)/stride),<br/>                            feature_map.shape[-1]))<br/>    for map_num in range(feature_map.shape[-1]):<br/>        r2 = 0<br/>        for r in numpy.arange(0,feature_map.shape[0]-size-1, stride):<br/>            c2 = 0<br/>            for c in numpy.arange(0, feature_map.shape[1]-size-1, stride):<br/>                pool_out[r2, c2, map_num] = numpy.max([feature_map[r:r+size,  c:c+size, map_num]])<br/>                c2 = c2 + 1<br/>            r2 = r2 +1<br/>    return pool_out</span></pre><p id="78db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该函数接受三个输入，即 ReLU 层的输出、汇集遮罩大小和跨距。和前面一样，它只是创建一个空数组来保存该层的输出。此类数组的大小是根据 size 和 stride 参数指定的，如下所示:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="f06b" class="me kt iq ma b gy mf mg l mh mi">pool_out = numpy.zeros((numpy.uint16((feature_map.shape[0]-size+1)/stride),<br/>                            numpy.uint16((feature_map.shape[1]-size+1)/stride),<br/>                            feature_map.shape[-1]))</span></pre><p id="9da1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，它根据使用循环变量<strong class="jp ir"> map_num </strong>的外部循环，逐个通道地循环输入。对于输入中的每个通道，应用最大池操作。根据所使用的步幅和大小，该区域被剪裁，并且它的最大值根据以下行返回到输出数组中:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="fcb3" class="me kt iq ma b gy mf mg l mh mi">pool_out[r2, c2, map_num] = numpy.max([feature_map[r:r+size,  c:c+size, map_num]])</span></pre><p id="76e2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下图显示了这种池层的输出。请注意，池层输出的大小小于其输入，即使它们在图表中看起来相同。</p><figure class="lv lw lx ly gt ml gh gi paragraph-image"><div class="gh gi my"><img src="../Images/9f5455ef24e8131706a531c9202ca4a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*c7Sra4egYRI3o5Acd5YaMA.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk"><strong class="bd ms">Figure 4. Pooling layer output applied to the output of the first ReLU layer</strong></figcaption></figure><h1 id="bfcf" class="ks kt iq bd ku kv mt kx ky kz mu lb lc ld mv lf lg lh mw lj lk ll mx ln lo lp bi translated">6.堆叠层</h1><p id="45d9" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">至此，具有 conv、ReLU 和 max 池层的 CNN 架构已经完成。除了前面的层之外，可能还有一些其他层需要堆叠，如下所示。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="7edd" class="me kt iq ma b gy mf mg l mh mi"># Second conv layer</span><span id="8907" class="me kt iq ma b gy mj mg l mh mi">l2_filter = numpy.random.rand(3, 5, 5, l1_feature_map_relu_pool.shape[-1])</span><span id="b0d2" class="me kt iq ma b gy mj mg l mh mi"><strong class="ma ir">print</strong>("\n**Working with conv layer 2**")</span><span id="b77d" class="me kt iq ma b gy mj mg l mh mi">l2_feature_map = conv(l1_feature_map_relu_pool, l2_filter)</span><span id="fad2" class="me kt iq ma b gy mj mg l mh mi"><strong class="ma ir">print</strong>("\n**ReLU**")</span><span id="5bbb" class="me kt iq ma b gy mj mg l mh mi">l2_feature_map_relu = relu(l2_feature_map)</span><span id="e236" class="me kt iq ma b gy mj mg l mh mi"><strong class="ma ir">print</strong>("\n**Pooling**")</span><span id="72f3" class="me kt iq ma b gy mj mg l mh mi">l2_feature_map_relu_pool = pooling(l2_feature_map_relu, 2, 2)</span><span id="1370" class="me kt iq ma b gy mj mg l mh mi"><strong class="ma ir">print</strong>("**End of conv layer 2**\n")</span></pre><p id="168e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">先前的 conv 层使用 3 个<strong class="jp ir">过滤器，它们的值是随机生成的。这就是为什么会有<strong class="jp ir"> 3 </strong>这样的 conv 图层生成的特征图。这对于连续的 ReLU 和 pooling 层也是一样的。这些层的输出如图 5 所示。</strong></p><figure class="lv lw lx ly gt ml gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/f562ca96faa026fbf91d22cfa58d1b73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*jy4htkW1IV-fVsbfk7Hfkg.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk"><strong class="bd ms">Figure 5. Output of the second conv-ReLU-Pooling layers</strong></figcaption></figure><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="94e6" class="me kt iq ma b gy mf mg l mh mi"># Third conv layer<br/>l3_filter = numpy.random.rand(1, 7, 7, l2_feature_map_relu_pool.shape[-1])<br/>print("\n**Working with conv layer 3**")<br/>l3_feature_map = numpycnn.conv(l2_feature_map_relu_pool, l3_filter)<br/>print("\n**ReLU**")<br/>l3_feature_map_relu = numpycnn.relu(l3_feature_map)<br/>print("\n**Pooling**")<br/>l3_feature_map_relu_pool = numpycnn.pooling(l3_feature_map_relu, 2, 2)<br/>print("**End of conv layer 3**\n")</span></pre><p id="1962" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">图 6 显示了前几层的输出。先前的 conv 层只接受一个过滤器。这就是为什么只有一个要素地图作为输出。</p><figure class="lv lw lx ly gt ml gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/f9d1116df1b70aad8022d8f0803a95c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*JTa4szDEWsRf3L9Nzxm32w.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk"><strong class="bd ms">Figure 6. Outputs of the third conv-ReLU-Pooling layers</strong></figcaption></figure><p id="cb1f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是要记住，每一层的输出都是下一层的输入。例如，这些行接受以前的输出作为它们的输入。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="b53f" class="me kt iq ma b gy mf mg l mh mi">l2_feature_map = conv(l1_feature_map_relu_pool, l2_filter)</span><span id="1227" class="me kt iq ma b gy mj mg l mh mi">l3_feature_map = conv(l2_feature_map_relu_pool, l3_filter)</span></pre><h1 id="6b0c" class="ks kt iq bd ku kv mt kx ky kz mu lb lc ld mv lf lg lh mw lj lk ll mx ln lo lp bi translated">7.完全码</h1><p id="b033" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">完整代码在<a class="ae mz" href="https://github.com/ahmedfgad/NumPyCNN" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">github</strong></a>(【https://github.com/ahmedfgad/NumPyCNN】<a class="ae mz" href="https://github.com/ahmedfgad/NumPyCNN" rel="noopener ugc nofollow" target="_blank"/>)中。代码包含使用<strong class="jp ir"> Matplotlib </strong>库的每层输出的可视化。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="effe" class="me kt iq ma b gy mf mg l mh mi">import skimage.data<br/>import numpy<br/>import matplotlib<br/>import sys</span><span id="83ab" class="me kt iq ma b gy mj mg l mh mi">def conv_(img, conv_filter):<br/>    filter_size = conv_filter.shape[1]<br/>    result = numpy.zeros((img.shape))<br/>    #Looping through the image to apply the convolution operation.<br/>    for r in numpy.uint16(numpy.arange(filter_size/2.0, <br/>                          img.shape[0]-filter_size/2.0+1)):<br/>        for c in numpy.uint16(numpy.arange(filter_size/2.0, <br/>                                           img.shape[1]-filter_size/2.0+1)):<br/>            """<br/>            Getting the current region to get multiplied with the filter.<br/>            How to loop through the image and get the region based on <br/>            the image and filer sizes is the most tricky part of convolution.<br/>            """<br/>            curr_region = img[r-numpy.uint16(numpy.floor(filter_size/2.0)):r+numpy.uint16(numpy.ceil(filter_size/2.0)), <br/>                              c-numpy.uint16(numpy.floor(filter_size/2.0)):c+numpy.uint16(numpy.ceil(filter_size/2.0))]<br/>            #Element-wise multipliplication between the current region and the filter.<br/>            curr_result = curr_region * conv_filter<br/>            conv_sum = numpy.sum(curr_result) #Summing the result of multiplication.<br/>            result[r, c] = conv_sum #Saving the summation in the convolution layer feature map.<br/>            <br/>    #Clipping the outliers of the result matrix.<br/>    final_result = result[numpy.uint16(filter_size/2.0):result.shape[0]-numpy.uint16(filter_size/2.0), <br/>                          numpy.uint16(filter_size/2.0):result.shape[1]-numpy.uint16(filter_size/2.0)]<br/>    return final_result<br/>def conv(img, conv_filter):<br/>    if len(img.shape) &gt; 2 or len(conv_filter.shape) &gt; 3: # Check if number of image channels matches the filter depth.<br/>        if img.shape[-1] != conv_filter.shape[-1]:<br/>            print("Error: Number of channels in both image and filter must match.")<br/>            sys.exit()<br/>    if conv_filter.shape[1] != conv_filter.shape[2]: # Check if filter dimensions are equal.<br/>        print('Error: Filter must be a square matrix. I.e. number of rows and columns must match.')<br/>        sys.exit()<br/>    if conv_filter.shape[1]%2==0: # Check if filter diemnsions are odd.<br/>        print('Error: Filter must have an odd size. I.e. number of rows and columns must be odd.')<br/>        sys.exit()</span><span id="c9cc" class="me kt iq ma b gy mj mg l mh mi"># An empty feature map to hold the output of convolving the filter(s) with the image.<br/>    feature_maps = numpy.zeros((img.shape[0]-conv_filter.shape[1]+1, <br/>                                img.shape[1]-conv_filter.shape[1]+1, <br/>                                conv_filter.shape[0]))</span><span id="a36d" class="me kt iq ma b gy mj mg l mh mi"># Convolving the image by the filter(s).<br/>    for filter_num in range(conv_filter.shape[0]):<br/>        print("Filter ", filter_num + 1)<br/>        curr_filter = conv_filter[filter_num, :] # getting a filter from the bank.<br/>        """ <br/>        Checking if there are mutliple channels for the single filter.<br/>        If so, then each channel will convolve the image.<br/>        The result of all convolutions are summed to return a single feature map.<br/>        """<br/>        if len(curr_filter.shape) &gt; 2:<br/>            conv_map = conv_(img[:, :, 0], curr_filter[:, :, 0]) # Array holding the sum of all feature maps.<br/>            for ch_num in range(1, curr_filter.shape[-1]): # Convolving each channel with the image and summing the results.<br/>                conv_map = conv_map + conv_(img[:, :, ch_num], <br/>                                  curr_filter[:, :, ch_num])<br/>        else: # There is just a single channel in the filter.<br/>            conv_map = conv_(img, curr_filter)<br/>        feature_maps[:, :, filter_num] = conv_map # Holding feature map with the current filter.<br/>    return feature_maps # Returning all feature maps.</span><span id="a0c9" class="me kt iq ma b gy mj mg l mh mi">def pooling(feature_map, size=2, stride=2):<br/>    #Preparing the output of the pooling operation.<br/>    pool_out = numpy.zeros((numpy.uint16((feature_map.shape[0]-size+1)/stride),<br/>                            numpy.uint16((feature_map.shape[1]-size+1)/stride),<br/>                            feature_map.shape[-1]))<br/>    for map_num in range(feature_map.shape[-1]):<br/>        r2 = 0<br/>        for r in numpy.arange(0,feature_map.shape[0]-size-1, stride):<br/>            c2 = 0<br/>            for c in numpy.arange(0, feature_map.shape[1]-size-1, stride):<br/>                pool_out[r2, c2, map_num] = numpy.max([feature_map[r:r+size,  c:c+size, map_num]])<br/>                c2 = c2 + 1<br/>            r2 = r2 +1<br/>    return pool_out</span><span id="f92a" class="me kt iq ma b gy mj mg l mh mi">def relu(feature_map):<br/>    #Preparing the output of the ReLU activation function.<br/>    relu_out = numpy.zeros(feature_map.shape)<br/>    for map_num in range(feature_map.shape[-1]):<br/>        for r in numpy.arange(0,feature_map.shape[0]):<br/>            for c in numpy.arange(0, feature_map.shape[1]):<br/>                relu_out[r, c, map_num] = numpy.max([feature_map[r, c, map_num], 0])<br/>    return relu_out</span><span id="05ea" class="me kt iq ma b gy mj mg l mh mi"># Reading the image<br/>#img = skimage.io.imread("fruits2.png")<br/>img = skimage.data.chelsea()<br/># Converting the image into gray.<br/>img = skimage.color.rgb2gray(img)</span><span id="bdb2" class="me kt iq ma b gy mj mg l mh mi"># First conv layer<br/>#l1_filter = numpy.random.rand(2,7,7)*20 # Preparing the filters randomly.<br/>l1_filter = numpy.zeros((2,3,3))<br/>l1_filter[0, :, :] = numpy.array([[[-1, 0, 1], <br/>                                   [-1, 0, 1], <br/>                                   [-1, 0, 1]]])<br/>l1_filter[1, :, :] = numpy.array([[[1,   1,  1], <br/>                                   [0,   0,  0], <br/>                                   [-1, -1, -1]]])</span><span id="9959" class="me kt iq ma b gy mj mg l mh mi">print("\n**Working with conv layer 1**")<br/>l1_feature_map = conv(img, l1_filter)<br/>print("\n**ReLU**")<br/>l1_feature_map_relu = relu(l1_feature_map)<br/>print("\n**Pooling**")<br/>l1_feature_map_relu_pool = pooling(l1_feature_map_relu, 2, 2)<br/>print("**End of conv layer 1**\n")</span><span id="823d" class="me kt iq ma b gy mj mg l mh mi"># Second conv layer<br/>l2_filter = numpy.random.rand(3, 5, 5, l1_feature_map_relu_pool.shape[-1])<br/>print("\n**Working with conv layer 2**")<br/>l2_feature_map = conv(l1_feature_map_relu_pool, l2_filter)<br/>print("\n**ReLU**")<br/>l2_feature_map_relu = relu(l2_feature_map)<br/>print("\n**Pooling**")<br/>l2_feature_map_relu_pool = pooling(l2_feature_map_relu, 2, 2)<br/>print("**End of conv layer 2**\n")</span><span id="2ff8" class="me kt iq ma b gy mj mg l mh mi"># Third conv layer<br/>l3_filter = numpy.random.rand(1, 7, 7, l2_feature_map_relu_pool.shape[-1])<br/>print("\n**Working with conv layer 3**")<br/>l3_feature_map = conv(l2_feature_map_relu_pool, l3_filter)<br/>print("\n**ReLU**")<br/>l3_feature_map_relu = relu(l3_feature_map)<br/>print("\n**Pooling**")<br/>l3_feature_map_relu_pool = pooling(l3_feature_map_relu, 2, 2)<br/>print("**End of conv layer 3**\n")</span><span id="8208" class="me kt iq ma b gy mj mg l mh mi"># Graphing results<br/>fig0, ax0 = matplotlib.pyplot.subplots(nrows=1, ncols=1)<br/>ax0.imshow(img).set_cmap("gray")<br/>ax0.set_title("Input Image")<br/>ax0.get_xaxis().set_ticks([])<br/>ax0.get_yaxis().set_ticks([])<br/>matplotlib.pyplot.savefig("in_img.png", bbox_inches="tight")<br/>matplotlib.pyplot.close(fig0)</span><span id="be39" class="me kt iq ma b gy mj mg l mh mi"># Layer 1<br/>fig1, ax1 = matplotlib.pyplot.subplots(nrows=3, ncols=2)<br/>ax1[0, 0].imshow(l1_feature_map[:, :, 0]).set_cmap("gray")<br/>ax1[0, 0].get_xaxis().set_ticks([])<br/>ax1[0, 0].get_yaxis().set_ticks([])<br/>ax1[0, 0].set_title("L1-Map1")</span><span id="14c9" class="me kt iq ma b gy mj mg l mh mi">ax1[0, 1].imshow(l1_feature_map[:, :, 1]).set_cmap("gray")<br/>ax1[0, 1].get_xaxis().set_ticks([])<br/>ax1[0, 1].get_yaxis().set_ticks([])<br/>ax1[0, 1].set_title("L1-Map2")</span><span id="9101" class="me kt iq ma b gy mj mg l mh mi">ax1[1, 0].imshow(l1_feature_map_relu[:, :, 0]).set_cmap("gray")<br/>ax1[1, 0].get_xaxis().set_ticks([])<br/>ax1[1, 0].get_yaxis().set_ticks([])<br/>ax1[1, 0].set_title("L1-Map1ReLU")</span><span id="7400" class="me kt iq ma b gy mj mg l mh mi">ax1[1, 1].imshow(l1_feature_map_relu[:, :, 1]).set_cmap("gray")<br/>ax1[1, 1].get_xaxis().set_ticks([])<br/>ax1[1, 1].get_yaxis().set_ticks([])<br/>ax1[1, 1].set_title("L1-Map2ReLU")</span><span id="bded" class="me kt iq ma b gy mj mg l mh mi">ax1[2, 0].imshow(l1_feature_map_relu_pool[:, :, 0]).set_cmap("gray")<br/>ax1[2, 0].get_xaxis().set_ticks([])<br/>ax1[2, 0].get_yaxis().set_ticks([])<br/>ax1[2, 0].set_title("L1-Map1ReLUPool")</span><span id="3f60" class="me kt iq ma b gy mj mg l mh mi">ax1[2, 1].imshow(l1_feature_map_relu_pool[:, :, 1]).set_cmap("gray")<br/>ax1[2, 0].get_xaxis().set_ticks([])<br/>ax1[2, 0].get_yaxis().set_ticks([])<br/>ax1[2, 1].set_title("L1-Map2ReLUPool")</span><span id="4c35" class="me kt iq ma b gy mj mg l mh mi">matplotlib.pyplot.savefig("L1.png", bbox_inches="tight")<br/>matplotlib.pyplot.close(fig1)</span><span id="0997" class="me kt iq ma b gy mj mg l mh mi"># Layer 2<br/>fig2, ax2 = matplotlib.pyplot.subplots(nrows=3, ncols=3)<br/>ax2[0, 0].imshow(l2_feature_map[:, :, 0]).set_cmap("gray")<br/>ax2[0, 0].get_xaxis().set_ticks([])<br/>ax2[0, 0].get_yaxis().set_ticks([])<br/>ax2[0, 0].set_title("L2-Map1")</span><span id="b456" class="me kt iq ma b gy mj mg l mh mi">ax2[0, 1].imshow(l2_feature_map[:, :, 1]).set_cmap("gray")<br/>ax2[0, 1].get_xaxis().set_ticks([])<br/>ax2[0, 1].get_yaxis().set_ticks([])<br/>ax2[0, 1].set_title("L2-Map2")</span><span id="0a16" class="me kt iq ma b gy mj mg l mh mi">ax2[0, 2].imshow(l2_feature_map[:, :, 2]).set_cmap("gray")<br/>ax2[0, 2].get_xaxis().set_ticks([])<br/>ax2[0, 2].get_yaxis().set_ticks([])<br/>ax2[0, 2].set_title("L2-Map3")</span><span id="3578" class="me kt iq ma b gy mj mg l mh mi">ax2[1, 0].imshow(l2_feature_map_relu[:, :, 0]).set_cmap("gray")<br/>ax2[1, 0].get_xaxis().set_ticks([])<br/>ax2[1, 0].get_yaxis().set_ticks([])<br/>ax2[1, 0].set_title("L2-Map1ReLU")</span><span id="fd2a" class="me kt iq ma b gy mj mg l mh mi">ax2[1, 1].imshow(l2_feature_map_relu[:, :, 1]).set_cmap("gray")<br/>ax2[1, 1].get_xaxis().set_ticks([])<br/>ax2[1, 1].get_yaxis().set_ticks([])<br/>ax2[1, 1].set_title("L2-Map2ReLU")</span><span id="fe72" class="me kt iq ma b gy mj mg l mh mi">ax2[1, 2].imshow(l2_feature_map_relu[:, :, 2]).set_cmap("gray")<br/>ax2[1, 2].get_xaxis().set_ticks([])<br/>ax2[1, 2].get_yaxis().set_ticks([])<br/>ax2[1, 2].set_title("L2-Map3ReLU")</span><span id="e5f2" class="me kt iq ma b gy mj mg l mh mi">ax2[2, 0].imshow(l2_feature_map_relu_pool[:, :, 0]).set_cmap("gray")<br/>ax2[2, 0].get_xaxis().set_ticks([])<br/>ax2[2, 0].get_yaxis().set_ticks([])<br/>ax2[2, 0].set_title("L2-Map1ReLUPool")</span><span id="243c" class="me kt iq ma b gy mj mg l mh mi">ax2[2, 1].imshow(l2_feature_map_relu_pool[:, :, 1]).set_cmap("gray")<br/>ax2[2, 1].get_xaxis().set_ticks([])<br/>ax2[2, 1].get_yaxis().set_ticks([])<br/>ax2[2, 1].set_title("L2-Map2ReLUPool")</span><span id="3a4d" class="me kt iq ma b gy mj mg l mh mi">ax2[2, 2].imshow(l2_feature_map_relu_pool[:, :, 2]).set_cmap("gray")<br/>ax2[2, 2].get_xaxis().set_ticks([])<br/>ax2[2, 2].get_yaxis().set_ticks([])<br/>ax2[2, 2].set_title("L2-Map3ReLUPool")</span><span id="73a8" class="me kt iq ma b gy mj mg l mh mi">matplotlib.pyplot.savefig("L2.png", bbox_inches="tight")<br/>matplotlib.pyplot.close(fig2)</span><span id="651d" class="me kt iq ma b gy mj mg l mh mi"># Layer 3<br/>fig3, ax3 = matplotlib.pyplot.subplots(nrows=1, ncols=3)<br/>ax3[0].imshow(l3_feature_map[:, :, 0]).set_cmap("gray")<br/>ax3[0].get_xaxis().set_ticks([])<br/>ax3[0].get_yaxis().set_ticks([])<br/>ax3[0].set_title("L3-Map1")</span><span id="fae7" class="me kt iq ma b gy mj mg l mh mi">ax3[1].imshow(l3_feature_map_relu[:, :, 0]).set_cmap("gray")<br/>ax3[1].get_xaxis().set_ticks([])<br/>ax3[1].get_yaxis().set_ticks([])<br/>ax3[1].set_title("L3-Map1ReLU")</span><span id="59b4" class="me kt iq ma b gy mj mg l mh mi">ax3[2].imshow(l3_feature_map_relu_pool[:, :, 0]).set_cmap("gray")<br/>ax3[2].get_xaxis().set_ticks([])<br/>ax3[2].get_yaxis().set_ticks([])<br/>ax3[2].set_title("L3-Map1ReLUPool")</span><span id="1f7b" class="me kt iq ma b gy mj mg l mh mi">matplotlib.pyplot.savefig("L3.png", bbox_inches="tight")<br/>matplotlib.pyplot.close(fig3)</span></pre></div><div class="ab cl kl km hu kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ij ik il im in"><p id="e9c3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">原文可在 LinkedIn 上找到，链接如下:</p><div class="na nb gp gr nc nd"><a href="https://www.linkedin.com/pulse/building-convolutional-neural-network-using-numpy-from-ahmed-gad/" rel="noopener  ugc nofollow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ir gy z fp ni fr fs nj fu fw ip bi translated">使用 NumPy 从头构建卷积神经网络</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">在某些情况下，使用 ML/DL 库中已经存在的模型可能会有所帮助。但是为了更好地控制和…</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">www.linkedin.com</p></div></div><div class="nm l"><div class="nn l no np nq nm nr mm nd"/></div></div></a></div></div><div class="ab cl kl km hu kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ij ik il im in"><h1 id="cc95" class="ks kt iq bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">联系作者</h1><p id="b6bc" class="pw-post-body-paragraph jn jo iq jp b jq lq js jt ju lr jw jx jy ls ka kb kc lt ke kf kg lu ki kj kk ij bi translated">艾哈迈德·法齐·加德</p><p id="a2a9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">LinkedIn:</p><div class="na nb gp gr nc nd"><a href="https://linkedin.com/in/ahmedfgad" rel="noopener  ugc nofollow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ir gy z fp ni fr fs nj fu fw ip bi translated">艾哈迈德·加德-撰稿人-艾·论坛报| LinkedIn</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">查看 Ahmed Gad 在世界上最大的职业社区 LinkedIn 上的个人资料。艾哈迈德有 11 个工作列在他们的…</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">linkedin.com</p></div></div><div class="nm l"><div class="ns l no np nq nm nr mm nd"/></div></div></a></div><p id="2975" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">电子邮件:</p><p id="d94d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">ahmed.f.gad@gmail.com</p></div></div>    
</body>
</html>