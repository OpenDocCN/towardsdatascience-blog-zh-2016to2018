<html>
<head>
<title>Vectorization Implementation in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的矢量化实现</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/vectorization-implementation-in-machine-learning-ca652920c55d?source=collection_archive---------3-----------------------#2018-10-14">https://towardsdatascience.com/vectorization-implementation-in-machine-learning-ca652920c55d?source=collection_archive---------3-----------------------#2018-10-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/09020195623fdd0ff96a48b57ec8ba8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bSTwFahbxKHLCcN-CQzrPQ.jpeg"/></div></div></figure><h1 id="ab14" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">介绍</h1><p id="2980" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在机器学习领域，高级玩家需要编写自己的成本函数或优化算法来实现更定制的模型，而不仅仅是使用现有的机器学习库。为了充分利用当今计算机的计算能力，算法实现的现有技术是对所有计算进行矢量化。这允许您实现并行计算，例如充分利用 GPU 的处理器。本文介绍了机器学习矢量化的实现。本帖使用的所有代码都可以在我的<a class="ae lu" href="https://github.com/liuy14/vectorization" rel="noopener ugc nofollow" target="_blank"> github </a>中找到。</p><h1 id="eba5" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">先决条件:Numpy 数组</h1><p id="ecab" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">我们将在 numpy array 的矢量化过程中使用的最重要的工具。注意，我们不使用 numpy 矩阵，因为 numpy 矩阵是严格的二维矩阵。实际上，numpy 矩阵是 numpy 数组的子集。因此，为了方便起见，我们总是使用 numpy 数组。这里回顾一下 numpy 数组算法，以便更好地理解后面的内容。下面是如何<strong class="ky ir">定义 numpy 数组</strong>:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="707f" class="me jz iq ma b gy mf mg l mh mi"># import numpy<br/>import numpy as np</span><span id="8e06" class="me jz iq ma b gy mj mg l mh mi"># define two numpy arrays<br/>a = np.array([[1,2],[3,4]])<br/>b = np.array([[1,1],[1,1]])</span><span id="9b13" class="me jz iq ma b gy mj mg l mh mi">print(a)<br/>&gt;&gt;&gt; array([[1, 2],<br/>           [3, 4]])<br/>print(b)<br/>&gt;&gt;&gt; array([[1, 1],<br/>           [1, 1]])</span></pre><h2 id="4a3a" class="me jz iq bd ka mk ml dn ke mm mn dp ki lh mo mp km ll mq mr kq lp ms mt ku mu bi translated">Numpy 数组加法</h2><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="b937" class="me jz iq ma b gy mf mg l mh mi"># addition<br/>print(a + b)</span><span id="e113" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; array([[2, 3],<br/>           [4, 5]])</span></pre><h2 id="1a59" class="me jz iq bd ka mk ml dn ke mm mn dp ki lh mo mp km ll mq mr kq lp ms mt ku mu bi translated">Numpy 数组减法</h2><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="49e5" class="me jz iq ma b gy mf mg l mh mi"># substraction<br/>print(a - b)</span><span id="8449" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; array([[0, 1],<br/>           [2, 3]])</span></pre><h2 id="7e2d" class="me jz iq bd ka mk ml dn ke mm mn dp ki lh mo mp km ll mq mr kq lp ms mt ku mu bi translated">Numpy 数组乘法</h2><p id="5cdb" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">注意，如果直接使用' * '乘法，这不同于称为点积矩阵乘法。两个数组之间的' * '操作只是将相同位置的元素相乘。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="ea70" class="me jz iq ma b gy mf mg l mh mi"># multiplication: <br/>print(a * b)</span><span id="5ede" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; array([[1, 2],<br/>          [3, 4]])</span></pre><h2 id="0f9b" class="me jz iq bd ka mk ml dn ke mm mn dp ki lh mo mp km ll mq mr kq lp ms mt ku mu bi translated">Numpy 数组点积</h2><p id="bf73" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">我们使用 numpy 的点函数来实现矩阵乘法。一个如此方便的方法是通过使用<strong class="ky ir">“@”符号</strong>，它以完全相同的方式工作。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="c21e" class="me jz iq ma b gy mf mg l mh mi"># matrix multiplication<br/>print(np.dot(a,b))</span><span id="7e86" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; array([[1, 2],<br/>          [3, 4]])</span><span id="ebc8" class="me jz iq ma b gy mj mg l mh mi"># matrix product alternative<br/>print(a@b)</span><span id="942f" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; array([[3, 3],<br/>          [7, 7]])</span></pre><h2 id="8833" class="me jz iq bd ka mk ml dn ke mm mn dp ki lh mo mp km ll mq mr kq lp ms mt ku mu bi translated">Numpy 数组维数</h2><p id="92eb" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">这里我们展示了两个例子，展示了 dimension 如何在 numpy 数组中工作。请注意，在第一种情况下，它是一个一行三列的数组，而在第二种情况下，它是一个三行一列的数组。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="6f1b" class="me jz iq ma b gy mf mg l mh mi"># numpy array with one row<br/>a =  np.array([1,2,3])<br/>print(a.shape)</span><span id="efc2" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; (3,)</span><span id="83ff" class="me jz iq ma b gy mj mg l mh mi"># numpy array with three rows<br/>b = np.array([[1],[2],[3]])<br/>print(b.shape)</span><span id="cfbe" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; (3, 1)</span></pre><h2 id="3ca0" class="me jz iq bd ka mk ml dn ke mm mn dp ki lh mo mp km ll mq mr kq lp ms mt ku mu bi translated">Numpy 数组索引和切片</h2><p id="bf86" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">对于 2D numpy 数组，当我们在表示为 A 的数组中切片一个元素时，我们可以使用 A[i，j],其中 I 是行索引，j 是列索引。如果想选择一整行 I，使用 A[i，:]，类似地对于选择一整列 j 使用 A[:，j]。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="5e51" class="me jz iq ma b gy mf mg l mh mi"># Define an 3x3 2d array<br/>a = np.array([[1,2,3],[4,5,6],[7,8,9]])<br/>print(a)</span><span id="5407" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; array([[1, 2, 3],<br/>          [4, 5, 6],<br/>          [7, 8, 9]])</span><span id="d16b" class="me jz iq ma b gy mj mg l mh mi"># select first element in the array<br/>print(a[0,0])</span><span id="8633" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; 1</span><span id="3eb8" class="me jz iq ma b gy mj mg l mh mi"># select first row of the array<br/>print(a[0,:])</span><span id="5894" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; array([1, 2, 3])</span><span id="fb89" class="me jz iq ma b gy mj mg l mh mi"># select second coulumn of the array<br/>print(a[:,1])</span><span id="ba07" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; array([2, 5, 8])</span></pre><h1 id="d645" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">先决条件:线性回归成本函数</h1><p id="4ff8" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在这一节中，我们将回顾线性回归的一些概念及其数学表达式。由于我们需要使用这些公式来实现梯度下降算法，在下一节，看看如何实现矢量化。</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mv"><img src="../Images/6cf08bb27943668d8edcc01869b43660.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JJI71Cg0upbdSoxePCH_JA.png"/></div></div></figure><p id="ec0e" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">线性回归的假设定义为:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/942e44f3dd3a78f5469ff2ad319dbaba.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*k-sttEqbKIOSlAas3C36CA.png"/></div></figure><p id="86b0" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">线性回归的成本函数定义为:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/5378564995f619979ba268737a0abaf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*E-iWjE3o9luiVapwzYkR7w.png"/></div></figure><p id="c8b0" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">成本函数对每个θ的导数定义为:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/b1280751b0716ea1269972dfde536fbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*vYspf1L6Omqh91nEdHsgEw.png"/></div></figure><p id="9b0f" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">在梯度下降的每次迭代中，我们使用以下等式更新所有θ:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/69b54f2be8e7262cf4b2608515eb32ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*CkcmVCUKmbA-qUn7y8srNQ.png"/></div></figure><h1 id="d66b" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">资料组</h1><p id="4525" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">我们使用的数据集是来自<a class="ae lu" href="https://archive.ics.uci.edu/ml/machine-learning-databases/housing/" rel="noopener ugc nofollow" target="_blank"> UCI 机器学习资源库</a>的“波士顿住宅”。它使用了房屋面积大小、建造年份等特征。来预测波士顿地区的房价。数据如下所示:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nf"><img src="../Images/9358bf33719b119c1023a1bf56fc4a16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7rfGRAy3pTCmS8mOaoCFZg.png"/></div></div></figure><p id="127e" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">我们的数据集有 506 个条目，我们将其表示为条目数 m。特征数 n=14，包括我们初始化为全 1 的截取特征。见下文:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="5466" class="me jz iq ma b gy mf mg l mh mi"># Insert X0 Column<br/>Xd = df.drop(columns=['MEDV'])<br/>Xd.insert(0, 'X0', 1)<br/>Xd.head()</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ng"><img src="../Images/dff02be17453e4733930de26a39fed36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nwsDpE1uXYtu5qWVe6_Ckw.png"/></div></div></figure><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="5d7f" class="me jz iq ma b gy mf mg l mh mi"># numpy array format<br/>X = Xd.values<br/>y = df.MEDV.values</span><span id="9534" class="me jz iq ma b gy mj mg l mh mi"># sample size<br/>m = len(df.index)<br/>print(m)</span><span id="ece7" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; 506</span><span id="b865" class="me jz iq ma b gy mj mg l mh mi"># number of features<br/>n = X.shape[1]<br/>print(n)</span><span id="1cfe" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; 14</span></pre><h1 id="3d33" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">对于循环垂直向量化</h1><p id="02b8" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在本节中，我们通过对线性回归应用梯度下降算法，对 for 循环和矢量化方法进行逐步比较。我们在线性回归部分比较了每个公式实现的运行时间。</p><p id="fe15" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">我们将所有 thetas 初始化为 1:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="e0a9" class="me jz iq ma b gy mf mg l mh mi"># Initialize theta<br/>theta = np.ones(n)</span><span id="1627" class="me jz iq ma b gy mj mg l mh mi">print(theta)<br/>&gt;&gt;&gt; array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])</span></pre><h2 id="53a3" class="me jz iq bd ka mk ml dn ke mm mn dp ki lh mo mp km ll mq mr kq lp ms mt ku mu bi translated">假设实现:For 循环</h2><p id="6778" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">为了实现线性回归的假设功能，如果我们使用 for 循环，可以使用下面的代码来实现:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="67d7" class="me jz iq ma b gy mf mg l mh mi"># hypothesis for the first sample<br/>hypo = 0<br/>for j in range(n):<br/>    hypo += theta[j]*X[0,j]</span></pre><p id="5e44" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">为了获得每个样本的假设，我们需要一个列表来存储它，并需要另一个 for 循环来迭代所有样本:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="c331" class="me jz iq ma b gy mf mg l mh mi">%%time<br/># hypothesis for all the samples<br/>all_hypo = []<br/>for i in range(m):<br/>    hypo_i = 0<br/>    for j in range(n):<br/>        hypo_i += theta[j]*X[i,j]<br/>    all_hypo.append(hypo_i)</span><span id="ad61" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; Wall time: 4 ms</span></pre><p id="07ee" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">我们可以看到运行时间是 4 ms，这并不太疯狂，因为这个实现足够简单，数据集也很小。</p><p id="9b49" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">结果显示为:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/5fe6ca9e17eee599ca08566a0cd2cd3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:492/format:webp/1*9qYXZjDFT8fynt9Uy-figQ.png"/></div></figure><h2 id="f1f3" class="me jz iq bd ka mk ml dn ke mm mn dp ki lh mo mp km ll mq mr kq lp ms mt ku mu bi translated">假设实现:矢量化</h2><p id="d80a" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">每个样本的假设可以使用以下公式进行矢量化:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/4dc567bb724f83242318ebc72a904903.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*K6bwmo5ZA00aQau-_S4ryg.png"/></div></figure><p id="1ec4" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">为了实现将所有样本作为一个列表的假设，我们使用下面的数组点积:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/c978185947a3d5277c2038f3964086ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*U4W4RljYFmJQVsLi4YVozw.png"/></div></figure><p id="2d27" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">代码实现非常简单明了:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="52d7" class="me jz iq ma b gy mf mg l mh mi">%%time<br/># matrix format<br/>hypo = X@theta</span><span id="36a1" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; Wall time: 0 ns</span></pre><p id="3fde" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">我们可以发现，它只需要很少的时间来计算，甚至可以不显示。计算结果如下所示。与 for 循环结果相比，我们可以看到我们获得了完全相同的结果。</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nk"><img src="../Images/ce5cde14708f94e88ddd7d288b31c433.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dp0pPCju7Pkpenc1de3xgA.png"/></div></div></figure><h2 id="c0b6" class="me jz iq bd ka mk ml dn ke mm mn dp ki lh mo mp km ll mq mr kq lp ms mt ku mu bi translated">成本函数实施:For 循环</h2><p id="0709" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">基于我们从假设中获得的结果，我们需要另一个循环来迭代所有样本以计算成本函数。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="5b85" class="me jz iq ma b gy mf mg l mh mi">%%time<br/># cost function<br/>cost = 0<br/>for i in range(m):<br/>    hypo_i = 0<br/>    for j in range(n):<br/>        hypo_i += theta[j]*X[i,j]<br/>    cost_i = (hypo_i - y[i])**2<br/>    cost += cost_i<br/>cost = (1/(2*m))*cost</span><span id="27ed" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; Wall time: 4 ms</span></pre><p id="9779" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">运行时间为 4 ms，结果显示如下:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="a9ea" class="me jz iq ma b gy mf mg l mh mi">print(cost)</span><span id="809c" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; 1.399752908228425</span></pre><h2 id="31de" class="me jz iq bd ka mk ml dn ke mm mn dp ki lh mo mp km ll mq mr kq lp ms mt ku mu bi translated">成本函数实现:矢量化</h2><p id="1556" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">基于假设的矢量化，我们可以很容易地将成本函数矢量化为:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nl"><img src="../Images/2269e56ca83ade92a711b39f745f1f9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*rZjirMxeNnyJvziPsOv6Xw.png"/></div></div></figure><p id="6748" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">代码实现仍然非常简洁:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="52f0" class="me jz iq ma b gy mf mg l mh mi">%%time<br/># cost function<br/>cost = (1/(2*m))*np.transpose((X@theta - y))@(X@theta - y)</span><span id="ce2e" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; Wall time: 0 ns</span></pre><p id="f10c" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">同样，这种矢量化计算是即时的。计算结果与 for 循环结果相同:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="af97" class="me jz iq ma b gy mf mg l mh mi">print(cost)</span><span id="0f8d" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; 1.3997529082284244</span></pre><h2 id="12f6" class="me jz iq bd ka mk ml dn ke mm mn dp ki lh mo mp km ll mq mr kq lp ms mt ku mu bi translated">派生实现:For 循环</h2><p id="7ba4" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">计算成本函数对指定θ的导数，编码如下:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="eecd" class="me jz iq ma b gy mf mg l mh mi">dev_sum = 0<br/>for i in range(m):<br/>    hypo_i = 0<br/>    for j in range(n):<br/>        hypo_i += theta[j]*X[i,j]<br/>    dev_i = (hypo_i - y[i])*X[i,k]<br/>    dev_sum += dev_i<br/>dev_sum = (1/m)*dev_sum</span></pre><p id="074a" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">为了计算所有θ的导数并输出一个列表，我们需要另一个 for 循环迭代所有列:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="bc0d" class="me jz iq ma b gy mf mg l mh mi">%%time<br/># derivation<br/>dev_list = []<br/>for k in range(n):<br/>    dev_sum = 0<br/>    for i in range(m):<br/>        hypo_i = 0<br/>        for j in range(n):<br/>            hypo_i += theta[j]*X[i,j]<br/>        dev_i = (hypo_i - y[i])*X[i,k]<br/>        dev_sum += dev_i<br/>    dev_sum = (1/m)*dev_sum<br/>    <br/>    dev_list.append(dev_sum)</span><span id="2607" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; Wall time: 47 ms</span></pre><p id="503f" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">运行时间为 47 ms，随着循环的增多，for 循环和矢量化的时间成本差异开始变得显著。</p><p id="e87b" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">for 循环的推导结果是:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="6941" class="me jz iq ma b gy mf mg l mh mi">print(dev_list)</span><span id="d0b3" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; [0.9999999999999983,<br/> 0.07814620360307895,<br/> -0.11042922261438312,<br/> 0.2620302340552936,<br/> 0.05504439083525137,<br/> 0.23892542562534522,<br/> -0.06454255823702795,<br/> 0.2611634394125097,<br/> -0.1453677181065729,<br/> 0.43106386997897883,<br/> 0.38303455280215737,<br/> 0.16591512402899725,<br/> -0.09920797306076046,<br/> 0.1835280968258358]</span></pre><h2 id="06cd" class="me jz iq bd ka mk ml dn ke mm mn dp ki lh mo mp km ll mq mr kq lp ms mt ku mu bi translated">派生实现:矢量化</h2><p id="117f" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">关于每个θ的成本函数的推导可以矢量化为:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/de28f4803ac1e48c80277cc3dacf20f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/1*LirPy3hWR--o3bCXkZzsVQ.png"/></div></figure><p id="9123" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">成本函数对所有θ的推导可矢量化为:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/1b1a04d37409e16175ce68e374f5b824.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/1*TYSV4TecQ9DgSZ_sAQD1mw.png"/></div></figure><p id="3a3a" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">代码实现仍然非常简洁:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="3d9b" class="me jz iq ma b gy mf mg l mh mi">%%time<br/>dev = (1/m)*np.transpose(X)@(X@theta - y)</span><span id="c026" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; Wall time: 999 µs</span></pre><p id="9ec1" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">直接比较是 999μs vs . s . 47 ms，以下是矢量化计算结果:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="4ecb" class="me jz iq ma b gy mf mg l mh mi">print(dev)</span><span id="8835" class="me jz iq ma b gy mj mg l mh mi">array([ 1.        ,  0.0781462 , -0.11042922,  0.26203023,  0.05504439, 0.23892543, -0.06454256,  0.26116344, -0.14536772,  0.43106387, 0.38303455,  0.16591512, -0.09920797,  0.1835281 ])</span></pre><p id="abf6" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">两种方法的结果也是一样的。</p><h1 id="f2cb" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">将一切放在一起:优化</h1><p id="7c1b" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在本节中，我们使用我们之前开发的所有实现，并编写一个梯度下降迭代来比较这两种方法。</p><h2 id="9724" class="me jz iq bd ka mk ml dn ke mm mn dp ki lh mo mp km ll mq mr kq lp ms mt ku mu bi translated">梯度下降:用于循环</h2><p id="9ada" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">为了获得下降优化结果，我们将迭代次数设置为 10 万次。为了实现梯度下降算法，我们需要嵌套四个 for 循环。学习率被设置为 0.0005，θ被初始化为全 1。代码如下所示:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="3527" class="me jz iq ma b gy mf mg l mh mi">%%time<br/>a = 0.0005<br/>theta = np.ones(n)</span><span id="2ad7" class="me jz iq ma b gy mj mg l mh mi">cost_list = []</span><span id="2dfc" class="me jz iq ma b gy mj mg l mh mi">for itr in range(100000):<br/>    <br/>    dev_list = []<br/>    for k in range(n):<br/>        dev_sum = 0<br/>        for i in range(m):<br/>            hypo_i = 0<br/>            for j in range(n):<br/>                hypo_i += theta[j]*X[i,j]<br/>            dev_i = (hypo_i - y[i])*X[i,k]<br/>            dev_sum += dev_i<br/>        dev_sum = (1/m)*dev_sum</span><span id="6c6c" class="me jz iq ma b gy mj mg l mh mi">dev_list.append(dev_sum)<br/>    <br/>    theta = theta - a*np.array(dev_list)<br/>    <br/>    cost_val = cost_loop(theta)<br/>    <br/>    cost_list.append(cost_val)</span><span id="fd6a" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; Wall time: 1h 15min 58s</span></pre><p id="6bc7" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">总运行时间为 1 小时 15 分钟。以下是我们获得的最小成本。我们还提供了一个曲线图，显示了成本函数相对于迭代的变化。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="d741" class="me jz iq ma b gy mf mg l mh mi">print(cost_val)</span><span id="649f" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; 0.017663350184258856</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/a64a62f64f63be9d82eb0860a4d1c59e.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*ig-sjIZWST1wIztqMEByig.png"/></div></figure><h2 id="8032" class="me jz iq bd ka mk ml dn ke mm mn dp ki lh mo mp km ll mq mr kq lp ms mt ku mu bi translated">梯度下降:矢量化</h2><p id="feb8" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">矢量化梯度下降的实现非常干净优雅。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="7ce9" class="me jz iq ma b gy mf mg l mh mi">%%time<br/>a = 0.0005<br/>theta = np.ones(n)</span><span id="23fe" class="me jz iq ma b gy mj mg l mh mi">cost_list = []</span><span id="238e" class="me jz iq ma b gy mj mg l mh mi">for i in range(100000):<br/>    <br/>    theta = theta - a*(1/m)*np.transpose(X)@(X@theta - y)<br/>           <br/>    cost_val = cost(theta)<br/>    cost_list.append(cost_val)</span><span id="864a" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; Wall time: 1.75 s</span></pre><p id="c40e" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">矢量化方法具有如下最小成本函数值。同样，提供了关于迭代的成本变化:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="aafe" class="me jz iq ma b gy mf mg l mh mi">print(cost_val)</span><span id="5331" class="me jz iq ma b gy mj mg l mh mi">&gt;&gt;&gt; 0.017663350184258835</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi no"><img src="../Images/a9a0efadc0e411ac9634226aa0db64f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*fWSNMlU60DZbTrcbGC-MtA.png"/></div></figure><p id="119d" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">我们可以看到两种方法的最小成本值几乎完全相同。但是使用矢量化的算法实现时间为 1.75 秒，而使用 for 循环的算法实现时间为 1 小时 15 分钟。</p><h1 id="b4e6" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">结论</h1><p id="b574" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">这里有一个图，显示了实现相同算法并使用完全相同的学习速率和初始θ值的两种方法的运行时间差异。这两种方法达到了同样的精度。然而，矢量化方法花费了 1.75 秒，而 for 循环花费了 4558 秒。矢量化方法比 for 循环方法快 2600 倍。</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/7b2060837f24a86e505bd50aa28cefa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*sEJko2YfX0oINarE3sZLVQ.png"/></div></figure><p id="63ae" class="pw-post-body-paragraph kw kx iq ky b kz mw lb lc ld mx lf lg lh my lj lk ll mz ln lo lp na lr ls lt ij bi translated">矢量化方法的时间复杂度为 O(s)，其中 s 为迭代次数。相比之下，for 循环方法的时间复杂度为 O(s*n*m*n)，其中 s 是迭代次数，m 是数据集样本数，n 是数据集特征数。在这种情况下，我们的数据集足够小，m=506，n=14，但是我们观察到时间复杂度的巨大差异。为大数据成像，这种差异会有多大。由于 noway 的计算机和 GPU 是由成千上万个“核心”组成的，我们甚至可以有多个 GPU 或使用一个计算机集群，我们需要充分利用这些计算能力。方法是通过并行计算实现你的算法。因此，在我们的机器学习算法中使用矢量化是提升算法并节省大量训练时间的关键。矢量化是我们需要考虑的一个很好的方法，值得花时间去研究。</p></div></div>    
</body>
</html>