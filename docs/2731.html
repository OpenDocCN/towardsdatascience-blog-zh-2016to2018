<html>
<head>
<title>Four fails and a win at a big data stack for realtime analytics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">针对实时分析的大数据堆栈四败一胜</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/four-fails-and-a-win-at-a-big-data-stack-for-realtime-analytics-4f82f651d476?source=collection_archive---------8-----------------------#2018-02-26">https://towardsdatascience.com/four-fails-and-a-win-at-a-big-data-stack-for-realtime-analytics-4f82f651d476?source=collection_archive---------8-----------------------#2018-02-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="aa2e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">构建一个用户友好的应用程序来实时分析大数据(即保持响应时间低于 60 秒)是一项挑战。在大数据世界中，你要么进行批量分析，没有人真正关心查询时间(大多数企业)；或者你在做流媒体(优步、脸书和 kin)，在这种情况下，查询时间至关重要，但数据总量很大——每个用户只看到或使用很小一部分，并且后台正在进行批处理作业。</p><p id="5072" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我正在开发一个 web 应用程序，该应用程序使非数据科学家用户能够实时构建和可视化地理数据的复杂分析，随着我们的数据和用户以及我们产品复杂性的增长，我们不得不修改堆栈以满足性能标准。我们的问题似乎应该是一个常见的问题，但奇怪的是，在用户友好的时间框架内对大量数据进行密集只读计算的指导非常少。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/220daf884a80dd1a1f9d74841a450829.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q6MBSl6mZcVJ2G4hSX4AAg.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">How analyses look in the web app</figcaption></figure><p id="031e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一年前，我还不是大数据领域的专家，这个领域有足够多的工具、术语和观点，很难知道从哪里开始。我还不知道所有的答案，但我已经想出了足够的办法，可以试探性地、谦恭地帮助其他人朝着对我们有用的堆栈前进。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="8860" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">失败 1:幼稚的 Postgres</h1><p id="9190" class="pw-post-body-paragraph jn jo iq jp b jq mg js jt ju mh jw jx jy mi ka kb kc mj ke kf kg mk ki kj kk ij bi translated">首先，我会说不到万不得已不要修改你的堆栈。这可能是数据应该被视为<em class="ml">大</em>的时候——当您现有的基础设施难以应对时。我们愉快地用 SQL 做了很长时间的事情。Postgres 是一个令人惊叹的数据库，我的经验是，通过正确的索引和构造良好的查询，可以实时聚合和查询多达 8000 万行的表。</p><p id="f92a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(虽然我提到了地理空间领域，但在本文中，我并不是在谈论地理计算，比如使用<em class="ml"> PostGIS </em>。它们在计算上非常昂贵，但是我们在最初的 ETL/数据摄取过程中完成了大部分工作。)</p><p id="498a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不幸的是，执行所有必要的数据库维护、找出正确的索引以及编写和重写查询可能相当痛苦。您还必须将数据正确地存储在整齐规范化的行和列中。</p><h1 id="9658" class="li lj iq bd lk ll mm ln lo lp mn lr ls lt mo lv lw lx mp lz ma mb mq md me mf bi translated">失败 2:反规范化</h1><p id="0699" class="pw-post-body-paragraph jn jo iq jp b jq mg js jt ju mh jw jx jy mi ka kb kc mj ke kf kg mk ki kj kk ij bi translated">还是你？总的来说，保持 SQL 数据的规范化和单一的真实来源是好的，但是复杂和频繁的表连接会降低性能。由于我们无法再满足用户的需求，我们不得不停止愚蠢的查询，并对一些较大的表进行反规范化。比如说，</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="da5c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这需要我们在 ETL 步骤中做更多的工作，并确保良好的数据治理，但这大大提高了速度。为了在团队规模保持不变的情况下弥补额外的时间，我们从自托管 Postgres 迁移到 AWS Aurora Postgres。性能没有改变，但它确实消除了一些数据库管理难题。</p><h1 id="12dd" class="li lj iq bd lk ll mm ln lo lp mn lr ls lt mo lv lw lx mp lz ma mb mq md me mf bi translated">失败三:极光</h1><p id="9b56" class="pw-post-body-paragraph jn jo iq jp b jq mg js jt ju mh jw jx jy mi ka kb kc mj ke kf kg mk ki kj kk ij bi translated">只不过这也带来了新的性能问题。我们的应用程序的最大特点之一是，它可以根据用户指定的标准，对城市的微小六边形区域进行评分和聚类。一个城市可能由 50 万个六边形组成；对于每一个妖术，用户可能想要根据其夜间居民和白天工作者的中值收入和心理特征，以及它离最近的星巴克有多远来评价它。这需要大量的数据和计算。</p><p id="acb7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">迁移到 Aurora 让我们失去了将数据保存在自己机器的内存缓存中的能力。当不同的用户试图依次或者更糟的是同时给不同的城市打分时，数据被拉入(大概是从 S3)并从我们的虚拟机中弹出。这种数据加载时间，就像某种页面抖动一样，大大超过了计算时间:最终结果是，当数据可用时，一个城市的得分需要 3 分钟——对于打算实时进行的事情来说，这本身不是一个很好的结果——迅速增加到 10 分钟或超时。</p><p id="4c4c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，在大数据领域，我可以说，我并没有参与太久，目前“没有人因为收购 IBM 而被解雇”的是 Apache Spark。我努力着手创建一个 Spark 机器集群，看看它是否能有所帮助。</p><p id="71f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于我们现在处理的表有数亿行，Postgres 运行缓慢，如果我们的应用程序要扩展，就必须对数据进行分区，并在多个节点上进行计算。</p><h1 id="73cb" class="li lj iq bd lk ll mm ln lo lp mn lr ls lt mo lv lw lx mp lz ma mb mq md me mf bi translated">次要胜利 1:集群</h1><p id="a156" class="pw-post-body-paragraph jn jo iq jp b jq mg js jt ju mh jw jx jy mi ka kb kc mj ke kf kg mk ki kj kk ij bi translated">多亏了 Kubernetes 和 Kops，在 AWS 上创建一个集群并不困难。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="ab1f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此时，您将获得一批新的 AWS 资源，包括集群主机和计算节点的实例。Docker 容器可以部署到这些实例中，由于 Kubernetes magic，它们将能够相互通信，与同一 VPC 上的其他机器通信，如果您选择通过暴露的负载平衡器与外界通信。</p><p id="66a5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">借助<a class="ae mt" href="https://github.com/kubernetes/helm" rel="noopener ugc nofollow" target="_blank"> Helm </a>，我能够快速启动并运行一系列 Spark 节点，以及一些用于 HDFS 文件存储的 Hadoop 节点。</p><h1 id="5663" class="li lj iq bd lk ll mm ln lo lp mn lr ls lt mo lv lw lx mp lz ma mb mq md me mf bi translated">失败 4:火花</h1><p id="6573" class="pw-post-body-paragraph jn jo iq jp b jq mg js jt ju mh jw jx jy mi ka kb kc mj ke kf kg mk ki kj kk ij bi translated">我发现 Spark 很难管理，很难使用(它都是 Java 的，并且是为 Java 应用程序设计的，尽管 PySpark 的承诺可能会让您相信)，而且总体来说没有那么快。</p><p id="8396" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我确信 Spark 可以在一些人的批处理工作流中发挥作用，并且我知道它也有流扩展。然而，即使是简单的工作也需要几分钟来启动机器，这使得它在实时用例中毫无用处。</p><p id="c9bd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，HDFS 跑得并不快，现在我们有了 S3，这看起来有点无关紧要了。</p><p id="20af" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，如果你像我一样来自 Python 生态系统，就不可能不去想念我们所拥有的大量工具。如果你是这样的人，并且你今天正在开始或发展一个大数据项目，我知道有一个更好的方法。</p><h1 id="0127" class="li lj iq bd lk ll mm ln lo lp mn lr ls lt mo lv lw lx mp lz ma mb mq md me mf bi translated">胜利:与 Dask 一起分发熊猫</h1><p id="ed91" class="pw-post-body-paragraph jn jo iq jp b jq mg js jt ju mh jw jx jy mi ka kb kc mj ke kf kg mk ki kj kk ij bi translated">Pandas 处理数字数据的速度已经是最快的了。数组计算以本机速度进行(感谢 Cython ),并且经常利用向量指令(感谢 NumPy)。</p><p id="0643" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">尽管如此，我一直认为 Pandas 实际上是用于处理数据的 ETL 和分析部分；更像是一个数据科学工具，而不是一个可以部署到生产中的库。<a class="ae mt" href="https://pandas.pydata.org/pandas-docs/stable/" rel="noopener ugc nofollow" target="_blank">我错了</a>:</p><blockquote class="mu mv mw"><p id="8b18" class="jn jo ml jp b jq jr js jt ju jv jw jx mx jz ka kb my kd ke kf mz kh ki kj kk ij bi translated">熊猫已被广泛应用于生产和金融领域</p></blockquote><p id="543d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae mt" href="http://dask.pydata.org/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> <em class="ml"> Dask </em> </a>，Anaconda 背后的同一批人制作的分布式计算库，将大型数据帧划分到不同的节点上，在这些节点上调度并行计算(构建一个图，像 Spark 一样将计算延迟到最后一分钟)，收集结果并管理分布式数据。它与熊猫集成在一起，并且在很大程度上可以与熊猫互操作，所以一起工作是一种乐趣。</p><p id="5f9a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(不是 100%；有些事情，例如在多列上索引一个数据帧，对于一个分区的数据帧没有意义)。</p><p id="eded" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">而且速度很快:每个节点都利用了 Pandas 及其矢量化的代码。分布式计算不是免费的；Dask 需要一些时间和网络延迟来构建图形和调度每个节点的计算，以及在最后合并/减少数据。如果能够将整个数据帧放入内存，基本的 Pandas 会更快——如果我们扩展我们的基本机器，这是可能的，但这不会永远持续下去:我们仍然需要在某些时候水平扩展我们的平台。</p><p id="aa6f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">用 Dask 编码很大程度上是熟悉的。例如，下面是 SQL <code class="fe na nb nc nd b">SELECT MAX(col + col2) FROM table WHERE zip_code IN ('94105', '94106') AND day_of_week IN (1,2,3)</code>的替换</p><pre class="km kn ko kp gt ne nd nf ng aw nh bi"><span id="5dd1" class="ni lj iq nd b gy nj nk l nl nm">from dask.distributed import Client<br/>import dask.dataframe as dd<br/>c = Client('172.x.x.x:8786')<br/>df = dd.read_parquet('s3://my-bucket/mydatafile.parquet')<br/>df = c.persist(df)<br/>subset = df[df["zip_code"].isin(['94105', '94106']) &amp; df["day_of_week"].isin([1,2,3])]<br/>df["sum"] = df["col1"] + df["col2"]<br/>print(df["sum"].max().compute())</span></pre><p id="a32c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将 Dask 部署到我之前制作的 Kubernetes 集群中也是相当容易的:他们有自己的掌舵图<a class="ae mt" href="http://dask.pydata.org/en/latest/setup/kubernetes-helm.html" rel="noopener ugc nofollow" target="_blank">记录在这里</a>。我们的基础设施现在看起来像这样:</p><ul class=""><li id="4f38" class="nn no iq jp b jq jr ju jv jy np kc nq kg nr kk ns nt nu nv bi translated">单片 Node.js 后端</li><li id="79f3" class="nn no iq jp b jq nw ju nx jy ny kc nz kg oa kk ns nt nu nv bi translated">它调用 Python 微服务(用<em class="ml"> Flask </em>构建，并将任务队列与 SQS 集成)</li><li id="4222" class="nn no iq jp b jq nw ju nx jy ny kc nz kg oa kk ns nt nu nv bi translated">连接到集群并指示节点</li><li id="6217" class="nn no iq jp b jq nw ju nx jy ny kc nz kg oa kk ns nt nu nv bi translated">从 S3 下载他们的数据部分(使用预先分区的<em class="ml"> Parquet </em>文件非常快，因为从每个节点的读取是并行发生的)</li><li id="22cd" class="nn no iq jp b jq nw ju nx jy ny kc nz kg oa kk ns nt nu nv bi translated">用 Dask/Pandas/NumPy 处理其数据</li><li id="4370" class="nn no iq jp b jq nw ju nx jy ny kc nz kg oa kk ns nt nu nv bi translated">并向后端返回一个 JSON 响应，后端将其转发给客户端 webapp</li></ul><p id="65b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在 Postgres 中需要几分钟的分析，如果需要从持久存储中读取数据，则通常需要更长时间，现在不到 30 秒就可以返回到客户端。</p><h1 id="3562" class="li lj iq bd lk ll mm ln lo lp mn lr ls lt mo lv lw lx mp lz ma mb mq md me mf bi translated">结论</h1><p id="b255" class="pw-post-body-paragraph jn jo iq jp b jq mg js jt ju mh jw jx jy mi ka kb kc mj ke kf kg mk ki kj kk ij bi translated">如果你有钱花，尤其是如果你还没有证明产品/市场适合，就去找供应商解决方案。一个快速的、面向列的内存 SQL 数据库不需要对我们的流程和代码做太多的修改。</p><p id="70db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">否则，对于作为 SaaS 的一部分实时处理大数据，我建议看看 Dask 是否能满足您的需求:它速度快，可水平扩展，允许您使用您习惯的相同库以相同的方式编写代码，并且它目前正在生产中使用(至少被我们使用)。</p><p id="c121" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">显然，我认为 Dask 杀死了 Spark，但是如果你感兴趣的话，Dask 的作者确实给出了一个更微妙的观点。</p></div></div>    
</body>
</html>