<html>
<head>
<title>Automatic Vehicle Detection for Self Driving Cars</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动驾驶汽车的自动车辆检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automatic-vehicle-detection-for-self-driving-cars-8d98c086b161?source=collection_archive---------3-----------------------#2017-03-19">https://towardsdatascience.com/automatic-vehicle-detection-for-self-driving-cars-8d98c086b161?source=collection_archive---------3-----------------------#2017-03-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><blockquote class="jn jo jp"><p id="1853" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated">第2章:用数据做酷事！</p></blockquote><p id="6ac7" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">我们如何教会自动驾驶汽车“看到”路上的其他汽车，并在它们移动时跟踪它们？仅仅用一个比雷达和激光雷达便宜得多的相机就能做到吗？</p><p id="d7d4" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">是啊！请看下面的视频。</p><figure class="ks kt ku kv gt kw"><div class="bz fp l di"><div class="kx ky l"/></div></figure><p id="2863" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">这是通过使用计算机视觉技术和支持向量机(SVM)分类器来完成的。使用深度学习也可以做到这一点，但是我更喜欢计算机视觉，因为它比深度学习更直接，深度学习可能是一个黑盒。</p><p id="ef3b" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">链接到我的<a class="ae kz" href="https://github.com/priya-dwivedi/CarND/blob/master/CarND-Vehicle-Detection-P5/P5_vehicle_detection_final.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="jt ir"> GitHub </strong> </a>用Python写的完整代码。</p><p id="193c" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">我们是这样做的:</p><ol class=""><li id="1765" class="la lb iq jt b ju jv jy jz kp lc kq ld kr le ko lf lg lh li bi translated">HOG特征提取寻找图像的特征</li></ol><p id="7465" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><a class="ae kz" href="http://www.learnopencv.com/histogram-of-oriented-gradients/" rel="noopener ugc nofollow" target="_blank"> HOG(梯度下降直方图)</a>是一种强大的计算机视觉技术，利用沿边缘的梯度方向来识别对象的形状。我们可以使用<em class="js"> skimage.hog() </em>函数来实现。关键参数是“方向”、“每个单元的像素”和“每个单元的块”。方向是渐变方向的数量。pixels_per_cell参数指定计算每个梯度直方图的像元大小。cells_per_block参数指定给定像元的直方图计数将被归一化的局部区域。为了感受pixels_per_cell和cells_per_block的影响，我查看了每单元像素和每块单元的不同设置的hog图像。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi lj"><img src="../Images/f3b2dab1509ca80c36c3fd3c02177179.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*sGFyoII1lhYbUVH9JrYcRg.png"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">HOG — 8 pixels per cell and 1 cell per block</figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/85f974e28228cb706d4fdf9e6a5de7a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*A8pmrgv-s831zfTZmg_qRg.png"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">HOG — 16 pixels per cell and 1 cell per block</figcaption></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/c3611f22338a96150a92eb06200795ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*to2WXK_F5N_xT1dK8_4NaA.png"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">HOG — 8 pixels per cell and 2 cell per block</figcaption></figure><p id="beba" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">每次调用的低像素数和每块的高单元数(上图的最后一张)具有最大的HOG特征，使得检测汽车相当容易。然而，这也意味着缓慢的计算</p><p id="e409" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">2.训练支持向量机(SVM)分类器</p><p id="39e7" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">一旦我们从汽车中提取了猪的特征，我们就可以训练SVM分类器来学习汽车和非汽车图像。在这个练习中，Udacity提供了2826辆汽车和8968张非汽车图片的数据集。非汽车图像是由非汽车的前置摄像头可视化的任何图像。</p><p id="90c9" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">为了给SVM选择最佳的HOG参数，我尝试了各种参数组合并观察了视频中的性能。最佳选择是:</p><ul class=""><li id="3864" class="la lb iq jt b ju jv jy jz kp lc kq ld kr le ko ls lg lh li bi translated">color_space = 'YCrCb' — YCrCb的性能远远优于RGB、HSV和HLS</li><li id="0e86" class="la lb iq jt b ju lt jy lu kp lv kq lw kr lx ko ls lg lh li bi translated">orient = 9 # HOG orientations——我试过6、9和12。模型性能变化不大</li><li id="37b9" class="la lb iq jt b ju lt jy lu kp lv kq lw kr lx ko ls lg lh li bi translated">pix_per_cell = 16 —我尝试了8和16，最终选择了16，因为它显著减少了计算时间</li><li id="d211" class="la lb iq jt b ju lt jy lu kp lv kq lw kr lx ko ls lg lh li bi translated">cell_per_block = 1 —我尝试了1和2。性能差异不大，但每个块1个单元的特征数量明显减少，并加快了训练和流水线的速度</li><li id="3dbd" class="la lb iq jt b ju lt jy lu kp lv kq lw kr lx ko ls lg lh li bi translated">hog_channel = 'ALL' —所有这些都比任何其他单个通道产生了更好的性能</li></ul><p id="b207" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">使用<em class="js"> sklearn.svm.LinearSVC()训练线性SVM。</em></p><p id="2221" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">3.实现滑动窗口以检测图像中汽车的存在</p><p id="2342" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">为了检测图像中的汽车，我们定义了不同大小的窗口，并在图像中滑动它们。在每一点上，我们提取HOG特征并通过我们的分类器来预测窗口中汽车的存在。如果检测到汽车，我们保存窗口位置。下面是一个用不同大小的窗口进行搜索的例子。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/9fb996ad548e88bab4a78aa277963d75.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*dMJnw_xJYwvLm00N0pX7yQ.png"/></div></figure><p id="6889" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">下面是在一些测试图像上运行上述步骤的一些例子。如您所见，存在多重检测和误报。为了平滑多次检测并消除假阳性，我们可以创建所有检测的热图，并对其进行阈值处理以消除假阳性。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi lz"><img src="../Images/a87b56c58ed9fb214c71742377b7d8c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AUbbOFDyC23JZHTSZO7CYg.png"/></div></div></figure><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi me"><img src="../Images/ecf2cdf61638df57cdf429258ad8a20f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dc5TtnYBXbzHPRUTgdB3Vw.png"/></div></div></figure><p id="fe1e" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">4.组合重叠的框并移除假阳性检测</p><p id="89b4" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">快到了！正如你所看到的，上面的技术容易产生误报和多重包围盒。为了解决这个问题，我们可以结合多个窗口帧的检测(~20)和热图阈值(~22检测)，以消除出现在几个帧中但不一致的假阳性“噪声”。</p><p id="f0e0" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">结果是对道路上的其他车辆的相当鲁棒的检测。这种技术也可以扩展到检测道路上的行人。</p><p id="d336" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">车道线的检测由我在另一篇<a class="ae kz" href="https://medium.com/@priya.dwivedi/https-medium-com-priya-dwivedi-automatic-lane-detection-for-self-driving-cars-4f8b3dc0fb65#.wcweiwa5k" rel="noopener">博客</a>上发表。</p><p id="1fe5" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">然而，这种技术有一些缺点。首先，我不确定这个模型在有多辆车的交通拥挤的情况下是否表现良好。你需要有近乎完美的准确性，以避免撞到其他车辆，或确保在交叉路口没有碰撞。更重要的是，该模型运行缓慢。处理1分钟的视频需要6–7分钟。我不确定这个模型在现实生活中有汽车和行人的情况下是否有效。</p><p id="ada4" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">参考资料:</p><p id="3e63" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated"><a class="ae kz" href="https://www.udacity.com/" rel="noopener ugc nofollow" target="_blank"> Udacity </a>无人驾驶汽车Nano Degree——我感谢Udacity给我机会成为他们新的无人驾驶汽车项目的一部分。这是一次非常有趣的旅程。我使用的大部分代码都是在课堂讲课中建议的。</p><p id="5ea8" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">Python <a class="ae kz" href="http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_tutorials.html" rel="noopener ugc nofollow" target="_blank"> OpenCV </a>库让应用计算机视觉技术变得如此简单</p></div></div>    
</body>
</html>