<html>
<head>
<title>Review: DilatedNet — Dilated Convolution (Semantic Segmentation)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">综述:扩展网络—扩展卷积(语义分割)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-dilated-convolution-semantic-segmentation-9d5a5bd768f5?source=collection_archive---------2-----------------------#2018-11-17">https://towardsdatascience.com/review-dilated-convolution-semantic-segmentation-9d5a5bd768f5?source=collection_archive---------2-----------------------#2018-11-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4b90" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">又名“<strong class="ak"> atrous 卷积</strong>”、“<strong class="ak">算法à trous </strong>”和“<strong class="ak">空洞算法</strong></h2></div><p id="7671" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi lb translated"><span class="l lc ld le bm lf lg lh li lj di"> T </span>他的时代，<strong class="kh ir">膨胀卷积，</strong>来自<strong class="kh ir"> </strong>普林斯顿大学和英特尔实验室，简要回顾。扩展卷积的思想来源于小波分解。又称为“<strong class="kh ir"> atrous 卷积</strong>”、“<strong class="kh ir"> algorithme à trous </strong>”和“<strong class="kh ir"> hole algorithm </strong>”。因此，如果我们可以将过去的任何想法转化为深度学习框架，它们仍然是有用的。</p><p id="a0fd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">而这个膨胀的卷积在我写这个故事的时候已经发表在<strong class="kh ir"> 2016 ICLR </strong>上有超过<strong class="kh ir"> 1000 次引用</strong>。(<a class="lk ll ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----9d5a5bd768f5--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p></div><div class="ab cl lm ln hu lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="ij ik il im in"><h1 id="76f5" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">涵盖哪些内容</h1><ol class=""><li id="465f" class="ml mm iq kh b ki mn kl mo ko mp ks mq kw mr la ms mt mu mv bi translated"><strong class="kh ir">扩张回旋</strong></li><li id="861a" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated"><strong class="kh ir">多尺度上下文聚合(上下文模块)</strong></li><li id="5bcf" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la ms mt mu mv bi translated"><strong class="kh ir">结果</strong></li></ol></div><div class="ab cl lm ln hu lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="ij ik il im in"><h1 id="be89" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">1.扩张卷积</h1><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/9e3e6cabce90ce1aa524137ea8015b85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*mlHFvK6H_wMCyURSZNZWGQ.png"/></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk"><strong class="bd nn">Standard Convolution (Left), Dilated Convolution (Right)</strong></figcaption></figure><p id="2fa9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">左边的是标准卷积。右边的是扩张的回旋。我们可以看到在求和的时候，就是 s+ <em class="no"> l </em> t=p 我们在卷积的时候会跳过一些点。</p><p id="5191" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">当<em class="no"> l </em> =1 时，为标准卷积。</strong></p><p id="8add" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">当<em class="no">l</em>T62】1 时，为扩张卷积。</strong></p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi np"><img src="../Images/52771ad7e88ddc79d0325bf94af65e3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/0*oX5IPr7TlVM2NpEU.gif"/></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk"><strong class="bd nn">Standard Convolution (l=1)</strong></figcaption></figure><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div class="gh gi np"><img src="../Images/a11a4a1628e788bc92394e2004470128.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/0*3cTXIemm0k3Sbask.gif"/></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk"><strong class="bd nn">Dilated Convolution (l=2)</strong></figcaption></figure><p id="ba86" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以上举例说明了当<em class="no"> l </em> =2 时<strong class="kh ir">展开卷积的例子。我们可以看到<strong class="kh ir">感受野比标准感受野大</strong>。</strong></p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi nq"><img src="../Images/186bca6f4f13418c459406d119cd6227.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tnDNIyPePgHvb8JIx8SbqA.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk"><strong class="bd nn">l=1 (left), l=2 (Middle), l=4 (Right)</strong></figcaption></figure><p id="d258" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上图显示了更多关于感受野的例子。</p><h1 id="fa1e" class="lt lu iq bd lv lw nv ly lz ma nw mc md jw nx jx mf jz ny ka mh kc nz kd mj mk bi translated"><strong class="ak"> 2。多尺度上下文聚合(上下文模块)</strong></h1><p id="f553" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko oa kq kr ks ob ku kv kw oc ky kz la ij bi translated">基于扩展卷积构建<strong class="kh ir">上下文模块</strong>如下:</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi od"><img src="../Images/48393ffef07ba6ea5355903de02a9c26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aj0ymQMfAOCXbvhnSlTY_w.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk"><strong class="bd nn">The Basic Context Module and The Large Context Module</strong></figcaption></figure><p id="b9ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上下文模块有 7 层，应用具有不同膨胀因子的 3×3 卷积。<strong class="kh ir">扩容 1，1，2，4，8，16，1。</strong></p><p id="0944" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后一个是 1×1 卷积，用于将通道数映射为与输入通道数相同。因此，<strong class="kh ir">输入和输出有相同数量的通道。</strong>并且可以插入不同种类的卷积神经网络。</p><p id="cd03" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">基本上下文模块</strong>在整个模块中只有<strong class="kh ir">1 个通道(1C ),而<strong class="kh ir">大型上下文模块</strong>有<strong class="kh ir">增加通道数，从 1C 输入到第 7 层的 32C</strong>。</strong></p></div><div class="ab cl lm ln hu lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="ij ik il im in"><h1 id="e94e" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">3.结果</h1><h2 id="fc13" class="oe lu iq bd lv of og dn lz oh oi dp md ko oj ok mf ks ol om mh kw on oo mj op bi translated">3.1.帕斯卡 VOC 2012</h2><p id="8543" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko oa kq kr ks ob ku kv kw oc ky kz la ij bi translated"><a class="ae oq" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener"> <em class="no"> VGG-16 </em> </a>作为<strong class="kh ir">前端模块</strong>。最后两个池层和跨层被完全移除，并插入了上下文模块。中间特征图的填充也被移除。作者仅填充宽度为 33 的输入要素地图。在我们的实验中，零填充和反射填充产生了类似的结果。此外，使用考虑输入和输出通道数量的权重初始化来代替标准随机初始化。</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi or"><img src="../Images/82bb45961eb22370aed6d88f7c839b24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jev8T1E-iYKPnpjbGIHoEQ.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk"><strong class="bd nn">PASCAL VOC 2012 Test Set</strong></figcaption></figure><p id="f557" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过对比原作者训练的公开模型，在测试集上，扩张卷积比<a class="ae oq" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1"><em class="no">【FCN-8s】</em></a>和<a class="ae oq" rel="noopener" target="_blank" href="/review-deeplabv1-deeplabv2-atrous-convolution-semantic-segmentation-b51c5fbde92d"> <em class="no"> DeepLabv1 </em> </a>均高出约 5 个百分点。</p><p id="f534" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以获得 67.6%的平均 IoU。</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi os"><img src="../Images/9fe34d020c16c0b1a168e5dd43b26842.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FBK7CmAZNrOexqLDhrtHWw.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk"><strong class="bd nn">PASCAL VOC 2012 Validation Set</strong></figcaption></figure><p id="8d9b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过对来自 Microsoft COCO 数据集的额外图像进行训练，对扩张卷积本身进行消融研究，如上所示。</p><ul class=""><li id="8313" class="ml mm iq kh b ki kj kl km ko ot ks ou kw ov la ow mt mu mv bi translated"><strong class="kh ir">前端</strong>:前端模块</li><li id="cd07" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la ow mt mu mv bi translated"><strong class="kh ir">基本</strong>:基本上下文模块</li><li id="2806" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la ow mt mu mv bi translated"><strong class="kh ir">大</strong>:大上下文模块</li><li id="989b" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la ow mt mu mv bi translated"><strong class="kh ir"> CRF </strong>:使用<a class="ae oq" rel="noopener" target="_blank" href="/review-deeplabv1-deeplabv2-atrous-convolution-semantic-segmentation-b51c5fbde92d"><em class="no">deeplab v1</em></a><em class="no"/>和<a class="ae oq" rel="noopener" target="_blank" href="/review-deeplabv1-deeplabv2-atrous-convolution-semantic-segmentation-b51c5fbde92d"> <em class="no"> DeepLabv2 </em> </a>中条件随机字段的后处理步骤</li><li id="efa4" class="ml mm iq kh b ki mw kl mx ko my ks mz kw na la ow mt mu mv bi translated"><strong class="kh ir"> RNN </strong>:通过递归神经网络使用条件随机场的后处理步骤</li></ul><p id="d846" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到，<strong class="kh ir">膨胀卷积(基本或大)总是可以改善结果，并且不与任何其他后处理步骤重叠。</strong></p><p id="2d09" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">并且可以获得 73.9%的平均 IoU。</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi ox"><img src="../Images/b0381ac0a5fd9e12dcbfb90b78e6af0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*znpzd2Rq2Ji6AfPTYZHftA.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk"><strong class="bd nn">PASCAL VOC 2012 Test Set</strong></figcaption></figure><p id="3eec" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上表中的前端模块也是通过对来自微软 COCO 数据集的附加图像进行训练而获得的。使用通用报告格式-RNN(即上表中的 RNN)，平均 IoU 为 75.3%。</p><h2 id="187e" class="oe lu iq bd lv of og dn lz oh oi dp md ko oj ok mf ks ol om mh kw on oo mj op bi translated">3.2.定性结果</h2><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi oy"><img src="../Images/72cec15fea04876ab293b3bbdc06d158.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xGVI8PDBzKVuZfOPoPtPOQ.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk"><strong class="bd nn">PASCAL VOC 2012</strong></figcaption></figure><p id="690e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">全部采用<a class="ae oq" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener"> <em class="no"> VGG-16 </em> </a>进行特征提取，使用扩张卷积在分割结果上有更好的质量</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi oz"><img src="../Images/3d259873f3ca3e92e316738bfc0eb80c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mEzsCzRCVxqcnTgfE84Prg.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk"><strong class="bd nn">PASCAL VOC 2012</strong></figcaption></figure><p id="7e0e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">用条件随机场 RNN 作为后处理步骤，得到了稍好的结果。但是 CRF-RNN 使这个过程不是一个端到端的学习。</p><figure class="nc nd ne nf gt ng gh gi paragraph-image"><div role="button" tabindex="0" class="nr ns di nt bf nu"><div class="gh gi pa"><img src="../Images/fc451f9476d842d9705feb0a77f15b33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AoRBUEbyrEvDsAwc1ONeCQ.png"/></div></div><figcaption class="nj nk gj gh gi nl nm bd b be z dk"><strong class="bd nn">Failure Cases</strong></figcaption></figure><p id="5b80" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一些失败案例如上图，<strong class="kh ir">当物体被遮挡时，分割出错。</strong></p></div><div class="ab cl lm ln hu lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="ij ik il im in"><p id="8720" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">附录中尝试了不同的数据集，即 CamVid、KITTI 和 Cityscapes，请随意阅读本文。他们还发表了<strong class="kh ir">扩张的残余网络</strong>。希望以后能覆盖。:)</p><h1 id="0736" class="lt lu iq bd lv lw nv ly lz ma nw mc md jw nx jx mf jz ny ka mh kc nz kd mj mk bi translated">参考</h1><p id="d3fb" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko oa kq kr ks ob ku kv kw oc ky kz la ij bi translated">【2016 ICLR】【扩张卷积】<br/> <a class="ae oq" href="https://arxiv.org/abs/1511.07122" rel="noopener ugc nofollow" target="_blank">扩张卷积的多尺度上下文聚合</a></p><h1 id="d767" class="lt lu iq bd lv lw nv ly lz ma nw mc md jw nx jx mf jz ny ka mh kc nz kd mj mk bi translated">我的相关评论</h1><p id="4143" class="pw-post-body-paragraph kf kg iq kh b ki mn jr kk kl mo ju kn ko oa kq kr ks ob ku kv kw oc ky kz la ij bi translated">[<a class="ae oq" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener">VGGNet</a>][<a class="ae oq" rel="noopener" target="_blank" href="/review-fcn-semantic-segmentation-eb8c9b50d2d1">FCN</a>][<a class="ae oq" rel="noopener" target="_blank" href="/review-deconvnet-unpooling-layer-semantic-segmentation-55cf8a6e380e">DeconvNet</a>][<a class="ae oq" rel="noopener" target="_blank" href="/review-deeplabv1-deeplabv2-atrous-convolution-semantic-segmentation-b51c5fbde92d">deep lab v1&amp;deep lab v2</a>]</p></div></div>    
</body>
</html>