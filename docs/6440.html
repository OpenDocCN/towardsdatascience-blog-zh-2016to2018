<html>
<head>
<title>Animated RNN, LSTM and GRU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">动画 RNN，LSTM 和 GRU</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/animated-rnn-lstm-and-gru-ef124d06cf45?source=collection_archive---------0-----------------------#2018-12-14">https://towardsdatascience.com/animated-rnn-lstm-and-gru-ef124d06cf45?source=collection_archive---------0-----------------------#2018-12-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/e9b1f321fe947ada53c3cf92cfd724f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*goJVQs-p9kgLODFNyhl9zA.gif"/></div></div></figure><div class=""/><div class=""><h2 id="8cb5" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">gif 中的递归神经网络细胞</h2></div><p id="eeef" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="lp">变更日志:</em></p><p id="cb24" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">【2020 年 7 月 4 日:移除 GRU 的“输出门”标签</p><p id="ffb5" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi lq translated"><span class="l lr ls lt bm lu lv lw lx ly di"> R </span>通用神经网络(RNNs)是一类人工神经网络，通常用于序列数据。3 种最常见的递归神经网络是</p><ol class=""><li id="a058" class="lz ma je kv b kw kx kz la lc mb lg mc lk md lo me mf mg mh bi translated">香草 RNN，</li><li id="16e1" class="lz ma je kv b kw mi kz mj lc mk lg ml lk mm lo me mf mg mh bi translated">长短期记忆(LSTM)，由<a class="ae mn" href="https://www.researchgate.net/publication/13853244_Long_Short-term_Memory" rel="noopener ugc nofollow" target="_blank"> Hochreiter 和 Schmidhuber 于 1997 年</a>提出，以及</li><li id="df7a" class="lz ma je kv b kw mi kz mj lc mk lg ml lk mm lo me mf mg mh bi translated">门控循环单元(GRU)，由 Cho 等人提出。2014 年的 al。</li></ol><blockquote class="mo mp mq"><p id="2789" class="kt ku lp kv b kw kx kf ky kz la ki lb mr ld le lf ms lh li lj mt ll lm ln lo im bi translated">请注意，我将使用“RNNs”来统称固有递归的神经网络架构，使用“香草 RNN”来指代最简单的递归神经网络架构，如图<a class="ae mn" href="#50f0" rel="noopener ugc nofollow">图 1 </a>所示。</p></blockquote><p id="a6cb" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">有许多关于循环神经网络的图解。我个人最喜欢的是迈克尔·阮(Michael Nguyen)在《走向数据科学》中发表的文章，因为他为我们提供了对这些模型的直觉，更重要的是，他提供了美丽的插图，使我们易于理解。但是我的帖子背后的动机是为了更好地可视化这些细胞中发生的事情，以及节点是如何被共享的，以及它们如何转化为输出节点。我也受到了迈克尔的动画的启发。</p><p id="f3a3" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这篇文章探讨了香草 RNN，LSTM 和 GRU 细胞。这是一篇简短的阅读材料，是为那些对这些主题有所了解的人准备的。(我建议在看这个帖子之前先看看 Michael 的文章。)重要的是要注意，以下动画是连续的以引导人眼，但并不反映矢量化机器计算期间的时间顺序。</p><p id="23aa" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这是我在插图中使用的图例。</p><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mu"><img src="../Images/36893d7d0c7c5edb03a086f3952706ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kLIkXgfeGRdi1Mds5CV5xA.png"/></div></div><figcaption class="mz na gj gh gi nb nc bd b be z dk">Fig. 0: Legend for animations</figcaption></figure><p id="f0a6" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">注意，动画显示了在<strong class="kv jf">一个时间步长</strong>中发生的数学运算(由<em class="lp"> t </em>索引)。此外，我使用了输入大小为 3(绿色)和 2 个隐藏单元(红色)，批量大小为 1。</p><p id="c17d" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">我们开始吧！</p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><h2 id="50f0" class="nk nl je bd nm nn no dn np nq nr dp ns lc nt nu nv lg nw nx ny lk nz oa ob oc bi translated">香草 RNN</h2><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi od"><img src="../Images/5b78a8c0646f87c81a4acbff247ae038.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*xn5kA92_J5KLaKcP7BMRLA.gif"/></div></div><figcaption class="mz na gj gh gi nb nc bd b be z dk">Fig. 1: Animated vanilla RNN cell</figcaption></figure><ul class=""><li id="1107" class="lz ma je kv b kw kx kz la lc mb lg mc lk md lo oe mf mg mh bi translated"><em class="lp"> t </em> —时间步长</li><li id="f5c6" class="lz ma je kv b kw mi kz mj lc mk lg ml lk mm lo oe mf mg mh bi translated"><em class="lp"> X — </em>输入</li><li id="a8c7" class="lz ma je kv b kw mi kz mj lc mk lg ml lk mm lo oe mf mg mh bi translated"><em class="lp"> h — </em>隐藏状态</li><li id="fc57" class="lz ma je kv b kw mi kz mj lc mk lg ml lk mm lo oe mf mg mh bi translated"><em class="lp"> X 的长度— </em>输入的大小/尺寸</li><li id="8455" class="lz ma je kv b kw mi kz mj lc mk lg ml lk mm lo oe mf mg mh bi translated"><em class="lp"> h 的长度— </em>隐蔽单元的数量。注意，不同的库对它们的称呼不同，但意思是一样的:<br/> - Keras — <code class="fe of og oh oi b"><a class="ae mn" href="https://keras.io/layers/recurrent/" rel="noopener ugc nofollow" target="_blank">state_size</a></code> <em class="lp">，</em><code class="fe of og oh oi b"><a class="ae mn" href="https://keras.io/layers/recurrent/#lstm" rel="noopener ugc nofollow" target="_blank">units</a><br/></code>-py torch—<code class="fe of og oh oi b"><a class="ae mn" href="https://pytorch.org/docs/stable/nn.html#rnn" rel="noopener ugc nofollow" target="_blank">hidden_size</a></code><br/>-tensor flow—<code class="fe of og oh oi b"><a class="ae mn" href="https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/BasicLSTMCell" rel="noopener ugc nofollow" target="_blank">num_units</a></code></li></ul><h2 id="b2ce" class="nk nl je bd nm nn no dn np nq nr dp ns lc nt nu nv lg nw nx ny lk nz oa ob oc bi translated">LSTM</h2><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/e9b1f321fe947ada53c3cf92cfd724f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*goJVQs-p9kgLODFNyhl9zA.gif"/></div></div><figcaption class="mz na gj gh gi nb nc bd b be z dk">Fig. 2: Animated LSTM cell</figcaption></figure><ul class=""><li id="4829" class="lz ma je kv b kw kx kz la lc mb lg mc lk md lo oe mf mg mh bi translated"><em class="lp"> C — </em>细胞状态</li></ul><p id="805f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">请注意，单元状态的维度与隐藏状态的维度相同。</p><h2 id="76d7" class="nk nl je bd nm nn no dn np nq nr dp ns lc nt nu nv lg nw nx ny lk nz oa ob oc bi translated">苏军总参谋部情报总局</h2><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oj"><img src="../Images/55d4db584c76fa2b441353d03c60c5bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*lNNJOWnMjxLzdUnUQqwKcw.gif"/></div></div><figcaption class="mz na gj gh gi nb nc bd b be z dk">Fig. 3: Animated GRU cell</figcaption></figure></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><p id="b595" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">希望这些动画对你有所帮助！以下是静态图像中单元格的摘要:</p><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi od"><img src="../Images/f48101008c0614a22845fe403672fc8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DQ_mD_mIN3M6gpVoe2NALA.png"/></div></div><figcaption class="mz na gj gh gi nb nc bd b be z dk">Fig. 4: Vanilla RNN cell</figcaption></figure><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/8503b1f17e3ca5ad34cc1be203df0f35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ht2-sUJHi65wDwnR276k3A.png"/></div></div><figcaption class="mz na gj gh gi nb nc bd b be z dk">Fig. 5: LSTM cell</figcaption></figure><figure class="mv mw mx my gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oj"><img src="../Images/ce3f8fc6dac3d2669a84aa28c3074bec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QbRz9BuSgSMqMnSKzSY-dw.png"/></div></div><figcaption class="mz na gj gh gi nb nc bd b be z dk">Fig. 6: GRU cell</figcaption></figure><h2 id="3ee2" class="nk nl je bd nm nn no dn np nq nr dp ns lc nt nu nv lg nw nx ny lk nz oa ob oc bi translated">笔记</h2><p id="c99b" class="pw-post-body-paragraph kt ku je kv b kw ok kf ky kz ol ki lb lc om le lf lg on li lj lk oo lm ln lo im bi translated">我用谷歌制图创建了这些图形。</p><h2 id="0504" class="nk nl je bd nm nn no dn np nq nr dp ns lc nt nu nv lg nw nx ny lk nz oa ob oc bi translated">参考</h2><div class="is it gp gr iu op"><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener  ugc nofollow" target="_blank"><div class="oq ab fo"><div class="or ab os cl cj ot"><h2 class="bd jf gy z fp ou fr fs ov fu fw jd bi translated">了解 LSTM 网络——colah 的博客</h2><div class="ow l"><h3 class="bd b gy z fp ou fr fs ov fu fw dk translated">这些循环使得循环神经网络看起来有点神秘。然而，如果你想得更多一点，事实证明…</h3></div><div class="ox l"><p class="bd b dl z fp ou fr fs ov fu fw dk translated">colah.github.io</p></div></div></div></a></div><div class="is it gp gr iu op"><a rel="noopener follow" target="_blank" href="/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21"><div class="oq ab fo"><div class="or ab os cl cj ot"><h2 class="bd jf gy z fp ou fr fs ov fu fw jd bi translated">LSTM 和 GRU 的图解指南:一步一步的解释</h2><div class="ow l"><h3 class="bd b gy z fp ou fr fs ov fu fw dk translated">嗨，欢迎来到长短期记忆(LSTM)和门控循环单位(GRU)的图解指南。我是迈克尔…</h3></div><div class="ox l"><p class="bd b dl z fp ou fr fs ov fu fw dk translated">towardsdatascience.com</p></div></div><div class="oy l"><div class="oz l pa pb pc oy pd ja op"/></div></div></a></div><h2 id="af45" class="nk nl je bd nm nn no dn np nq nr dp ns lc nt nu nv lg nw nx ny lk nz oa ob oc bi translated">深度学习相关文章</h2><p id="5307" class="pw-post-body-paragraph kt ku je kv b kw ok kf ky kz ol ki lb lc om le lf lg on li lj lk oo lm ln lo im bi translated"><a class="ae mn" rel="noopener" target="_blank" href="/an-implementation-guide-to-word2vec-using-numpy-and-google-sheets-13445eebd281">逐行 Word2Vec 实现</a>(关于单词嵌入)</p><p id="7124" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><a class="ae mn" rel="noopener" target="_blank" href="/step-by-step-tutorial-on-linear-regression-with-stochastic-gradient-descent-1d35b088a843">带随机梯度下降的线性回归分步指南</a></p><p id="7232" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><a class="ae mn" rel="noopener" target="_blank" href="/10-gradient-descent-optimisation-algorithms-86989510b5e9"> 10 种梯度下降优化算法+备忘单</a></p><p id="698e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><a class="ae mn" rel="noopener" target="_blank" href="/counting-no-of-parameters-in-deep-learning-models-by-hand-8f1716241889">统计深度学习模型中的参数数量</a></p><p id="1eeb" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><a class="ae mn" rel="noopener" target="_blank" href="/attn-illustrated-attention-5ec4ad276ee3">经办人:图文并茂</a></p><p id="9899" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><a class="ae mn" rel="noopener" target="_blank" href="/illustrated-self-attention-2d627e33b20a">图文并茂:自我关注</a></p></div><div class="ab cl nd ne hx nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="im in io ip iq"><p id="3af0" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="lp">感谢</em> <a class="ae mn" href="https://medium.com/@derekchia" rel="noopener"> <em class="lp">德里克</em></a><em class="lp"/><a class="ae mn" href="https://medium.com/@renjietan" rel="noopener"><em class="lp">任杰</em> </a> <em class="lp">对本文的想法、建议和修正。</em></p><p id="4d00" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="lp">关注我上</em> <a class="ae mn" href="https://www.twitter.com/remykarem" rel="noopener ugc nofollow" target="_blank"> <em class="lp">推特</em> </a> <em class="lp"> @remykarem 或者</em><a class="ae mn" href="http://www.linkedin.com/in/raimibkarim" rel="noopener ugc nofollow" target="_blank"><em class="lp">LinkedIn</em></a><em class="lp">。你也可以通过 raimi.bkarim@gmail.com 联系我。欢迎访问我的网站</em><a class="ae mn" href="https://remykarem.github.io/" rel="noopener ugc nofollow" target="_blank"><em class="lp">remykarem . github . io</em></a><em class="lp">。</em></p></div></div>    
</body>
</html>