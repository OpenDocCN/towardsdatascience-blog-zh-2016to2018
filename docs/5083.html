<html>
<head>
<title>The intuitions behind Bayesian Optimization with Gaussian Processes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">高斯过程贝叶斯优化背后的直觉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-intuitions-behind-bayesian-optimization-with-gaussian-processes-7e00fcc898a0?source=collection_archive---------5-----------------------#2018-09-26">https://towardsdatascience.com/the-intuitions-behind-bayesian-optimization-with-gaussian-processes-7e00fcc898a0?source=collection_archive---------5-----------------------#2018-09-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="631d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">更新</strong>:我开了一家科技<a class="ae kl" href="http://www.legislate.tech/" rel="noopener ugc nofollow" target="_blank">公司</a>。你可以在这里找到更多<a class="ae kl" href="https://medium.com/legislate/eliminate-the-work-in-paperwork-c053bfb0188c" rel="noopener"/></p><p id="f816" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在某些应用中，目标函数是昂贵的或难以评估的。在这些情况下，一般的方法包括创建目标函数的更简单的替代模型，该替代模型评估起来更便宜，并且将替代地用于解决优化问题。此外，由于评估目标函数的高成本，经常推荐迭代方法。迭代优化器通过在域中的一系列点上迭代地请求函数的评估来工作。贝叶斯优化通过在可能的目标函数空间上结合先验模型，将贝叶斯方法添加到迭代优化器范例中。本文介绍了高斯过程贝叶斯优化背后的基本概念和直觉，并介绍了<a class="ae kl" href="https://mindfoundry.ai/optaas" rel="noopener ugc nofollow" target="_blank"> OPTaaS </a>，一个用于贝叶斯优化的<a class="ae kl" href="https://optaas.mindfoundry.ai" rel="noopener ugc nofollow" target="_blank"> API </a>。</p><h2 id="f099" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">最佳化</h2><p id="2297" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">优化方法试图将域<strong class="jp ir"><em class="lk"/></strong>中的输入<strong class="jp ir"> <em class="lk"> x* </em> </strong>定位到函数<strong class="jp ir"> <em class="lk"> f </em> </strong>中，该函数在<strong class="jp ir"><em class="lk"/></strong>上最大化(或最小化)该函数的值:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/d8e291939777f7c8ed867e378a71ad8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*fkv006r9Qhk2GNByIdj3Iw.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">The general Optimization framework</figcaption></figure><p id="3e91" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在实践中，函数<em class="lk"> f </em>表示需要优化的过程的结果，例如交易策略的整体盈利能力、工厂生产线上的质量控制指标，或者具有许多参数和超参数的数据科学管道的性能。</p><p id="aa6f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">输入域<strong class="jp ir"> <em class="lk"> 𝒳 </em> </strong>代表需要优化的过程的有效参数选择。这些可以是交易策略中使用的市场预测，工厂流程中使用的原材料数量，或者数据科学管道中 ML 模型的参数。正是输入域<strong class="jp ir"><em class="lk">【,𝒳</em></strong>的描述，连同函数<strong class="jp ir"> <em class="lk"> f </em> </strong>的性质，表征了优化问题。流程域的有效输入，<strong class="jp ir"> <em class="lk"> 𝒳 </em> </strong>，可以是离散的、连续的、受约束的或这些的任意组合。类似地，结果函数<strong class="jp ir"> <em class="lk"> f </em> </strong>可以是凸的、可微的、多模态的、有噪声的、缓慢变化的，或者具有许多其他重要性质。</p><p id="7cd8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在某些应用中，目标函数评估起来很昂贵(计算上或经济上)，很难评估(化学实验、石油钻探)。在这些情况下，一般的方法包括创建目标函数<strong class="jp ir"><em class="lk"/></strong><em class="lk"/>的更简单的替代模型<strong class="jp ir"> <em class="lk"> f ̂ </em> </strong>，该替代模型评估起来更便宜，并且将替代地用于解决优化问题。</p><p id="8d54" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，由于评估目标函数的高成本，经常推荐迭代方法。迭代优化器通过在域<em class="lk"> x </em> 1、<em class="lk"> x </em> 2、<em class="lk">中的一系列点处迭代地请求函数<em class="lk"> f </em>的评估来工作。。。∈<strong class="jp ir">t37】𝒳</strong></em>t39】。通过这些评估，优化器能够构建函数<strong class="jp ir"> <em class="lk"> f </em> </strong>的图像。对于梯度下降算法，这个图像是局部的，但是对于代理模型方法，这个图像是全局的。在任何时候，或者在函数评估的预分配预算结束时，迭代优化器将能够陈述其对<strong class="jp ir"> <em class="lk"> x* </em> </strong>的真实值的最佳近似。</p><p id="2de8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用<strong class="jp ir"> <em class="lk"> N </em> </strong> <em class="lk"> </em>已知的评价值<strong class="jp ir"><em class="lk"/></strong>:<strong class="jp ir"><em class="lk">F =(f1，f2，…，fN)</em></strong>at<strong class="jp ir"><em class="lk">【XN =(x1，x2，…，xN) </em> </strong>来训练代理模型。有许多方法用于建立替代模型，如多项式插值、神经网络、支持向量机、随机森林和高斯过程。在 Mind Foundry，我们选择的方法是使用高斯过程进行回归。</p><h2 id="11ff" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">高斯过程</h2><p id="8618" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">高斯过程(GPs)在函数空间上提供了一类丰富而灵活的非参数统计模型，其域可以是连续的、离散的、混合的，甚至是分层的。此外，GP 不仅提供关于<strong class="jp ir"><em class="lk"/></strong>的可能值的信息，而且重要的是还提供关于该值的不确定性的信息。</p><p id="25e5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">高斯过程回归背后的思想是针对在某些点的一组观察值<strong class="jp ir"><em class="lk"/></strong><em class="lk"/><strong class="jp ir"><em class="lk">【XN】</em></strong><em class="lk"/>我们假设这些值对应于具有先验分布的多变量高斯过程的实现:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/3de89acd6088af69d0e53ee1d323d7de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*kxbBpnbn8cY2YiQMa2Bvtg.png"/></div></figure><p id="bc38" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中<strong class="jp ir"> <em class="lk"> KN </em> </strong> <em class="lk"> </em>是一个<strong class="jp ir"><em class="lk">N</em>x<em class="lk">N</em></strong><em class="lk"/>协方差矩阵及其系数用一个相关函数(或核)<strong class="jp ir"> <em class="lk"> Kmn =K(xm，xn，θ) </em> </strong>来表示。根据最大似然原则校准内核的超参数<strong class="jp ir"> <em class="lk"> θ </em> </strong> <em class="lk"> </em>。<strong class="jp ir"> <em class="lk"> KN </em> </strong> <em class="lk"> </em>被选择来反映函数的一个先验假设，因此核的选择将对回归的正确性产生重大影响。图 2 给出了几个协方差函数的示例。</p><p id="4969" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过数学变换并使用条件概率规则，可以估计后验分布<em class="lk">p</em>(<em class="lk">f n+1</em>|<em class="lk">f N</em>，<em class="lk"> XN+1 </em>)并将<strong class="jp ir"> <em class="lk"> f ̂N+1 </em> </strong>表示为 KN 和 fn 的函数，具有不确定性。这允许我们从我们的观察中构建一个概率代理，如图 1 所示:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ly"><img src="../Images/8e662abd538cc71bbc02ef4cf0c082ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7sbv73g2ar67vS06AujuiA.png"/></div></div></figure><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi md"><img src="../Images/5e11671859fd1440088bc76c360cf1cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qAxgbAxPYzvEq-BMYQOmGA.png"/></div></div></figure><h2 id="5188" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">贝叶斯优化</h2><p id="31bf" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">贝叶斯优化是一类迭代优化方法，专注于一般优化设置，其中𝒳的描述是可用的，但对<em class="lk"> f </em>的属性的了解是有限的。贝叶斯优化方法有两个特点:</p><ul class=""><li id="141a" class="me mf iq jp b jq jr ju jv jy mg kc mh kg mi kk mj mk ml mm bi translated"><strong class="jp ir"> <em class="lk">代理模型 f ̂ </em> </strong>，对于函数<em class="lk"> f </em>、</li><li id="293c" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">以及从代理计算的<strong class="jp ir"> <em class="lk">获取函数</em> </strong>，用于指导下一个评估点的选择</li></ul><p id="ead6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">BO 通过在可能的目标函数空间上结合<strong class="jp ir"><em class="lk"/></strong><em class="lk">f</em>的先验模型，将贝叶斯方法添加到迭代优化器范例中。通过在每次报告函数评估时更新该模型，贝叶斯优化例程保持目标函数<em class="lk"> f </em>的后验模型。这个后验模型是函数<em class="lk"> f </em>的代理<strong class="jp ir"> <em class="lk"> f ̂ </em> </strong>。具有 GP 先验的贝叶斯优化例程的伪代码是:</p><p id="a93c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">初始化</strong> : <br/>根据初始空间填充实验设计，在<em class="lk"> f <br/> </em>之前放置高斯过程，在<em class="lk"> n </em> 0 点观察<em class="lk"> f </em>。</p><p id="8edb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将<em class="lk"> n </em>设定在<em class="lk"> n </em> 0</p><p id="04ab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">而</strong>T30】N≤<em class="lk">N</em>T34】do:</p><ul class=""><li id="a15e" class="me mf iq jp b jq jr ju jv jy mg kc mh kg mi kk mj mk ml mm bi translated">使用所有可用数据更新 f 上的后验概率分布</li><li id="ba50" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">识别𝒳上采集函数的最大值<strong class="jp ir"><em class="lk">【xn】</em></strong><em class="lk"/>，其中采集函数是使用当前后验分布计算的</li><li id="7349" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">观察<em class="lk">yn</em>=<em class="lk">f</em>(<em class="lk">xn</em>)</li><li id="106a" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">增量<em class="lk"> n </em></li></ul><p id="6415" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">结束而</strong></p><p id="3ac8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">返回</strong>具有最大<em class="lk"> f </em> ( <em class="lk"> x </em>)的点或者具有最大后验均值的点。</p><p id="0f70" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">标准采集函数的一个例子是<strong class="jp ir"> <em class="lk">预期改善标准</em> </strong> (EI)，对于<em class="lk"> x </em> ∈ 𝒳中的任何给定点，该标准是<em class="lk"> x </em>处的<em class="lk"> f </em>的值相对于<strong class="jp ir"> <em class="lk"> f </em> </strong> <em class="lk"> </em>的最佳值的预期改善。 鉴于函数<strong class="jp ir"> <em class="lk"> f </em> </strong> <em class="lk"> </em>在<em class="lk"> x </em>处确实高于<strong class="jp ir"> <em class="lk"> f </em> </strong> <em class="lk"> </em>的最佳值；所以如果我们在寻找<strong class="jp ir"> <em class="lk"> f </em> </strong>的最大值，EI 可以写成:</p><p id="12e2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"><em class="lk">e I</em>(<em class="lk">x</em>)= 𝔼(max(<em class="lk">f</em>(<em class="lk">x</em>)<em class="lk">f</em>*，0)</strong></p><p id="099f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中<em class="lk"> f </em> *是目前看到的<em class="lk"> f </em>的最大值。</p><p id="f6e0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">采集功能的其他示例有:</p><ul class=""><li id="3073" class="me mf iq jp b jq jr ju jv jy mg kc mh kg mi kk mj mk ml mm bi translated">熵搜索，其在于寻求最小化我们在最佳值位置的不确定性</li><li id="4ff2" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">置信上限</li><li id="3d09" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">预期损失标准</li></ul><p id="c354" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">图 3 示出了代理的演变以及它与获取函数的交互，因为它在它试图最小化的基础函数的每次迭代之后改进了它的知识。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi ms"><img src="../Images/b2d125b905966e813977c44c90365d2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UWvMP_dtt1lQhwQvfNOjLw.png"/></div></div></figure><h2 id="8625" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">使用 OPTaaS 实施业务对象</h2><p id="eff2" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">OPTaaS 是一个通用的贝叶斯优化器，它通过 web 服务提供最佳的参数配置。它可以处理任何参数类型，并且不需要知道底层的过程、模型或数据。它要求客户端指定参数及其域，并回传 OPTaaS 推荐的每个参数配置的准确度分数。OPTaaS 使用这些分数对底层系统进行建模，并更快地搜索最佳配置。</p><p id="477a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Mind Foundry 已经在 OPTaaS 中实现了一套代理模型和采集功能，它将根据所提供的参数的性质和数量自动选择和配置，如图 4 所示。这种选择是基于彻底的科学测试和研究，因此 OPTaaS 总是做出最合适的选择。此外，Mind Foundry 能够为客户的特定问题设计定制协方差函数，这将显著提高优化过程的速度和准确性。OPTaaS 的大多数用户需要优化复杂的流程，这种流程运行起来很昂贵，而且反馈有限。出于这个原因，OPTaaS 将其 API 集中于提供一个简单的迭代优化器接口。然而，如果有更多关于被优化的过程的信息，它总是可以被用来更快地收敛到最优。因此，OPTaaS 还支持关于域𝒳的信息的通信，例如关于输入的约束，以及关于函数<em class="lk"> f </em>的评估，例如噪声或梯度或部分完整的评估。此外，客户通常能够利用本地基础设施来分发优化搜索，也可以请求 OPTaaS 进行批量评估。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="gh gi mt"><img src="../Images/a414c612fee7ac3753fcc1e4aa08fc3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*73E0r2uiLmjY_i-eNyuq7g.png"/></div></div></figure><p id="461e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">优化过程如下:</p><ol class=""><li id="4184" class="me mf iq jp b jq jr ju jv jy mg kc mh kg mi kk mu mk ml mm bi translated">OPTaaS 向客户推荐一种配置</li><li id="adb7" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mu mk ml mm bi translated">客户评估他们机器上的配置</li><li id="2a5b" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mu mk ml mm bi translated">客户发回一个分数(准确性、夏普比率、投资回报等)</li><li id="4c19" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mu mk ml mm bi translated">OPTaaS 使用该分数来更新其代理模型，并且循环重复，直到达到最佳配置。</li></ol><p id="6c5c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在整个过程中，OPTaaS 不访问底层数据或模型。更多关于 OPTaaS (Mind Foundry Optimize)的信息可以在<a class="ae kl" href="https://www.mindfoundry.ai/mind-foundry-optimize" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="e5c3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">【<strong class="jp ir">更新</strong>:我开了一家法律科技公司。如果你已经做到了这一步，你可能会有兴趣在这里找到更多的<a class="ae kl" href="https://medium.com/legislate/the-contract-is-dead-51b022fd1b24" rel="noopener"/></p><h2 id="e321" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">团队和资源</h2><p id="83b2" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">Mind Foundry 是牛津大学的一个分支机构，由斯蒂芬·罗伯茨(Stephen Roberts)和迈克尔·奥斯本(Michael Osborne)教授创建，他们在数据分析领域已经工作了 35 年。Mind Foundry 团队由 30 多名世界级的机器学习研究人员和精英软件工程师组成，其中许多人曾是牛津大学的博士后。此外，Mind Foundry 通过其分拆地位，拥有超过 30 名牛津大学机器学习博士的特权。Mind Foundry 是牛津大学的投资组合公司，其投资者包括<a class="ae kl" href="https://www.oxfordsciencesinnovation.com" rel="noopener ugc nofollow" target="_blank">牛津科学创新</a>、<a class="ae kl" href="http://www.oxfordtechnology.com" rel="noopener ugc nofollow" target="_blank">牛津技术与创新基金、</a>、<a class="ae kl" href="https://innovation.ox.ac.uk/award-details/university-oxford-isis-fund-uoif/" rel="noopener ugc nofollow" target="_blank">牛津大学创新基金</a>和<a class="ae kl" href="http://parkwalkadvisors.com" rel="noopener ugc nofollow" target="_blank"> Parkwalk Advisors </a>。</p><p id="4b6d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">文档</strong></p><p id="04fd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">教程:<a class="ae kl" href="https://tutorial.optaas.mindfoundry.ai" rel="noopener ugc nofollow" target="_blank">https://tutorial . opta as . mind foundry . ai</a>API 文档:<a class="ae kl" href="https://optaas.mindfoundry.ai" rel="noopener ugc nofollow" target="_blank">https://opta as . mind foundry . ai</a></p><p id="1108" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">研究</strong><a class="ae kl" href="http://www.robots.ox.ac.uk/~mosb/projects/project/2009/01/01/bayesopt/" rel="noopener ugc nofollow" target="_blank">http://www . robots . ox . AC . uk/~ mosb/projects/project/2009/01/01/bayesopt/</a></p><p id="c037" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">参考文献</strong></p><p id="7643" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">奥斯本，硕士(2010)。顺序预测、优化和求积的贝叶斯高斯过程(博士论文)。牛津大学博士论文。</p><p id="eaa4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">演示:</strong>Charles . brecke @ mind foundry . ai</p></div></div>    
</body>
</html>