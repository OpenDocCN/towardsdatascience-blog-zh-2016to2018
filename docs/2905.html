<html>
<head>
<title>Training Object Detection (YOLOv2) from scratch using Cyclic Learning Rates</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用循环学习率从头开始训练对象检测(YOLOv2)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-object-detection-yolov2-from-scratch-using-cyclic-learning-rates-b3364f7e4755?source=collection_archive---------2-----------------------#2018-03-19">https://towardsdatascience.com/training-object-detection-yolov2-from-scratch-using-cyclic-learning-rates-b3364f7e4755?source=collection_archive---------2-----------------------#2018-03-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="ea84" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对象检测的任务是识别图像中的所有对象以及它们的类别标签和边界框。这是一项具有挑战性的计算机视觉任务，最近已被Faster-RCNN、SSD、Yolo等深度学习算法接管。这篇文章重点介绍了最新的Yolo v2算法，据说它是最快的(在Titan X上运行时，在低分辨率图像上大约90 FPS)，比SSD更准确，在少数数据集上比RCNN更快。我将讨论Yolo v2的工作原理和训练步骤。如果你想更深入地了解物体检测算法，你可以参考<a class="ae kl" href="http://cv-tricks.com/object-detection/faster-r-cnn-yolo-ssd/" rel="noopener ugc nofollow" target="_blank">这里</a>和<a class="ae kl" href="https://github.com/Nikasa1889/HistoryObjectRecognition/blob/master/HistoryOfObjectRecognition.png" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="ddd5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇文章假设你对<a class="ae kl" href="https://www.youtube.com/embed/Oqm9vsf_hvU?start=265&amp;end=396" rel="noopener ugc nofollow" target="_blank">卷积层</a>，最大池，<a class="ae kl" href="https://www.coursera.org/learn/deep-neural-network/lecture/81oTm/why-does-batch-norm-work" rel="noopener ugc nofollow" target="_blank">批处理</a>有基本的了解。如果没有，我建议你在附加的链接中得到一个关于主题的简要想法。</p><h1 id="12db" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">Yolo v2:你只看一次</h1><p id="a561" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">在下图中，我们需要识别人、电视监视器和自行车的边界框。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/eec990b797d586e0d412ac6e4e120fce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*DZjj8iKObSIMsPbswVVBeg.jpeg"/></div></figure><p id="4764" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">按照Yolo算法，我们将输入图像分成N×N(这里是13x13)个正方形。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/0c3d1e6ebab6f6bc27ba1923e6f1bb73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/1*3F2qll5kRP0QngXCglPVPQ.jpeg"/></div></figure><p id="e3df" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在每个方块中，Yolo网络(下面讨论)预测5个具有不同纵横比的边界框。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/c97e2a9ff4a201a7ce86eafd77b78aa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*w59evteI87u913_P8zQG0g.jpeg"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">An example of 5 boxes is shown for a square positioned at (7, 9) from top left.</figcaption></figure><p id="0da0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于每个边界框，Yolo网络预测其在正方形内的中心位置、框的宽度、高度、图像宽度、高度和在该框中具有任何对象的置信度得分，以及属于M个类别中的每一个的概率。</p><p id="901b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，不是每个边界框都有一个对象。给定这些预测，为了找到最终的边界框，我们需要执行以下两个步骤:</p><ol class=""><li id="9931" class="md me iq jp b jq jr ju jv jy mf kc mg kg mh kk mi mj mk ml bi translated">移除没有对象的边界框。移除预测置信度得分小于阈值0.24的边界框</li><li id="dcf0" class="md me iq jp b jq mm ju mn jy mo kc mp kg mq kk mi mj mk ml bi translated">在声称有对象的边界框中，使用<a class="ae kl" href="https://www.coursera.org/learn/convolutional-neural-networks/lecture/dvrjH/non-max-suppression" rel="noopener ugc nofollow" target="_blank">非最大抑制</a>和<a class="ae kl" href="https://www.coursera.org/learn/convolutional-neural-networks/lecture/p9gxz/intersection-over-union" rel="noopener ugc nofollow" target="_blank">并集上的交集</a>去除了识别相同对象的冗余。</li></ol><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi mr"><img src="../Images/540c10355b566486b6fd5521329f52eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P6rigs_SxTcTIbPTEljD6w.jpeg"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Predicted bounding boxes</figcaption></figure><h1 id="f650" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">YOLOv2网络:</h1><p id="e973" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">以上步骤是图像通过Yolo网络后得到最终包围盒所需的后处理步骤。然而，我们还没有讨论Yolo网络如何产生这种输出。在这里，我要讨论一下Yolo网络。</p><p id="0a50" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">YOLOv2的架构可以在这里看到<a class="ae kl" href="http://ethereon.github.io/netscope/#/gist/d08a41711e48cf111e330827b1279c31" rel="noopener ugc nofollow" target="_blank">。将鼠标悬停在块上可以看到可视化中每个块的详细信息。除了最后一个卷积块之外，每个卷积块都有BatchNorm归一化和泄漏Relu激活。</a></p><p id="74d7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Conv13_512之后的重组层(参见<a class="ae kl" href="http://ethereon.github.io/netscope/#/gist/d08a41711e48cf111e330827b1279c31" rel="noopener ugc nofollow" target="_blank">可视化</a>)是一个重组层。如果输入图像的尺寸为3x416x416(通道x高度x宽度— CHW)，则Conv13_512的输出尺寸为512x26x26 (CHW)。重组层将每一个交替的像素放入不同的通道。让我们以一个4x4像素的单通道为例，如下所示。重组层将大小减少一半，并创建4个通道，相邻像素位于不同的通道中。因此，来自Conv13_512的Reorg层的输出将是2048x13x13。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi mw"><img src="../Images/d821423e0a68b93baab9ba5fdf88b364.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8sCeKUWswwL-OFmi."/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Reorg layer in YOLO v2</figcaption></figure><p id="103f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">concat层接受Reorg层的输出(大小:2048x13x13)和Conv20_1024的输出(大小:1024x13x13)，并生成大小为3072x13x13的连接层。</p><h1 id="6d4f" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">损失函数:</h1><p id="94a2" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">目标函数是多部分函数，如</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi mw"><img src="../Images/8d48090d43b8177ae8d555a04136bcd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*O4WQJCUqgywq19Cw."/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">YOLO v2 Loss function</figcaption></figure><p id="414c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上述函数定义了迭代t的损失函数。如果边界框没有任何对象，则需要降低其对象置信度，并将其表示为第一损失项。因为边界框坐标预测需要与我们的先验信息对齐，所以为少数迭代(t &lt; 12800)添加了减少先验和预测之间的差异的损失项。如果边界框k负责真值框，那么预测需要与表示为第三损失项的真值对齐。𝞴值是每个损失项的预定义权重。</p><h1 id="7bba" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">训练YOLOv2:</h1><p id="f8a5" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">在训练YOLOv2之前，作者定义了一个架构，称为Darknet-19，用于在ImageNet数据集上训练。Darknet-19具有与YOLOv2网络相同的前19层(直到Conv18_1024)，然后附加了1024个滤波器的1x1卷积，之后是全局AvgPool和Softmax层。Darknet-19在ImageNet上训练，达到91.2%的top-5精度，并且训练的权重直到层Conv18_1024稍后在训练YOLOv2网络时使用。</p><p id="040a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我已经用SGD和Adam做了几次实验。我已经尝试过使用动量，如论文中提到的重量衰减。我不能在使用SGD的测试中得到65.7以上的地图。然而，亚当能够比SGD达到68.2地图表现更好。</p><p id="6c2d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">后来，我尝试了在精彩的<a class="ae kl" href="https://www.youtube.com/embed/JNxcznsrRb8?start=1155&amp;end=3447" rel="noopener ugc nofollow" target="_blank">快速人工智能</a>讲座中解释的重启循环学习率。这是一个非常有趣的技术，因为我发现在使用lr_find()找到的学习率开始训练后，测试精度在短短4个时期内就开始从以前的结果提高。我遵循的策略是:</p><ol class=""><li id="c950" class="md me iq jp b jq jr ju jv jy mf kc mg kg mh kk mi mj mk ml bi translated">使用lr_find技术发现学习率为0.00025，我使用PyTorch重新实现了该技术</li><li id="1174" class="md me iq jp b jq mm ju mn jy mo kc mp kg mq kk mi mj mk ml bi translated">用n _ epochs训练最后的层5个周期，每个周期加倍，得到31个epoch。我在PyTorch中使用CosineAnnealingLR方法实现了循环学习率。</li><li id="be99" class="md me iq jp b jq mm ju mn jy mo kc mp kg mq kk mi mj mk ml bi translated">以不同的学习速率训练所有层3个周期，每个周期的时期加倍。</li></ol><p id="dcf5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用上述策略，我可以在测试中获得71.8的地图，这比论文中提到的策略要好，我也可以在更短的时间内获得。但离论文中提到的精度(76.8图)还是有相当大的差距。我相信我还需要进一步尝试一些东西，以接近论文中提到的精度。</p><ol class=""><li id="b00f" class="md me iq jp b jq jr ju jv jy mf kc mg kg mh kk mi mj mk ml bi translated">多尺度训练，因为我无法在PyTorch中定期重复多尺度训练</li><li id="6fad" class="md me iq jp b jq mm ju mn jy mo kc mp kg mq kk mi mj mk ml bi translated">为更多的时代而训练。</li><li id="075b" class="md me iq jp b jq mm ju mn jy mo kc mp kg mq kk mi mj mk ml bi translated">处理困难样品(包围盒的宽度或高度【https://github.com/santoshgsk/yolov2-pytorch T2】</li></ol><p id="e7b7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi">I will be adding the code soon. Hit the clap if you like the post and please do let me know your thoughts about this finding.</p><p id="d7ff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi">I would like to thank Jeremy Howard and Rachel Thomas for their incredible effort of sharing useful tips on training neural networks.</p><p id="40f2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi">Please find the code here: <a class="ae kl" href="https://github.com/santoshgsk/yolov2-pytorch" rel="noopener ugc nofollow" target="_blank">https://github.com/santoshgsk/yolov2-pytorch</a></p></div></div>    
</body>
</html>