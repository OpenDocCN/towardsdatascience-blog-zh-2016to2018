<html>
<head>
<title>Convolution Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convolution-neural-network-e9b864ac1e6c?source=collection_archive---------4-----------------------#2017-07-10">https://towardsdatascience.com/convolution-neural-network-e9b864ac1e6c?source=collection_archive---------4-----------------------#2017-07-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="bc4d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">对于初学者</h2></div><h1 id="ed86" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">介绍</h1><p id="f5e1" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">卷积层用于从输入训练样本中提取特征。每个卷积图层都有一组有助于要素提取的过滤器。一般来说，随着CNN模型的深度增加，通过卷积层学习的特征的复杂性增加。例如，第一个卷积层捕获简单特征，而最后一个卷积层捕获训练样本的复杂特征。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/12d4f54ad07889d12291c4bde2475c3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*EmeyDkdMr63IT99egW5VFg.png"/></div></figure><p id="f11e" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi translated">通过考虑数据样本部分的卷积来提取特征。过滤器每次遍历的数据部分的数量与步长和填充值成比例。数据样本在卷积之前可以/可以不进行零填充。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/b4eeed70a559079f9e2ad09ba7c5736f.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*2YnAJCmJqemiBz2ibNlANA.png"/></div></figure><p id="3e2b" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi translated">卷积输出然后通过一个称为ReLU(整流线性单元)的激活单元。这个单元将数据转换成非线性形式。只有当卷积输出为负时，ReLU的输出才会被削波为零。</p><p id="a490" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi translated">由于消失梯度问题，Sigmoid单元不是优选的激活单元。如果CNN的深度很大，那么当在输入层发现的梯度穿过输出层时，它的值会大大减小。这导致网络的总输出变化很小。这反过来导致收敛缓慢/没有收敛。为了避免这种情况，最好使用ReLU。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/231ea0fae3411766523ad9411bd60711.png" data-original-src="https://miro.medium.com/v2/resize:fit:326/format:webp/1*wSOiHozERIRQg2WyTE38Bw.png"/></div></figure><p id="8576" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi translated">ReLU的输出然后通过一个池层。合并图层移除卷积过程中捕获的任何冗余要素。因此，这一层减少了数据样本的大小。池化背后的原理是它假设图像像素的相邻值几乎相同。使用四个相邻像素值的平均值/最小值/最大值来进行合并。一般来说，在2*2过滤器的帮助下，输入图像的大小减少了一半。输入数据在汇集之前可能会/可能不会进行零填充。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/87a46f8f0ff05c7b9583080068b1722f.png" data-original-src="https://miro.medium.com/v2/resize:fit:486/format:webp/1*7CZEuK9P9-6AOQ9O41Nkxw.png"/></div></figure><p id="4e5e" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi translated">按照CNN模型的设计，重复这种连续通过卷积和汇集层传递数据的过程。出于学习目的，这个过程重复2-4次。来自连续卷积和汇集层的输出然后通过多层神经网络。这里，每个神经元单元充当携带关于单元的信息的特征图。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/bbec227cb3be7e620b5740e782775d12.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*uX6P-9GC9jTLPM-AkQaG7g.png"/></div></figure><p id="71ff" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi translated">丢弃层用于通过使CNN模型对噪声鲁棒来减少过拟合。这些层通常被引入两个完全连接的神经网络层之间。它们暂时切断两个完全连接的层之间的部分数据流。这相当于让模型在存在噪声的情况下学习准确分类。因此，减少了由于过拟合而导致的模型分类不准确的机会。</p><p id="d7a8" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi translated">使用SoftMax函数计算CNN模型的输出。SoftMax是首选，因为它给出了不同类别的输出概率，而不是在sigmoid输出的情况下&gt; = 0.5。使用SoftMax函数根据类的最高概率查找输出结果可提高输出的准确性。</p><p id="f51d" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi translated">交叉熵用于衡量系统的性能。它们是在SoftMax函数的帮助下计算出来的。这里的优点是SoftMax输出是对应于我们知道输出所属的类的元素的踪迹。这通常节省了计算时间。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/9d39f208c825c0c709f797cef3cdcd81.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*7ubMex4upzuFLBoZXPu8XA.png"/></div></figure><h1 id="fd79" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">CNN层概述</h1><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/40356b328fc11157f66705f775c067e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*b4SYp0O8aA-wgk9j1jcMag.png"/></div></figure><p id="e35e" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi"></p><h1 id="df0b" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">特征提取— MNIST</h1><p id="e69c" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">本节让读者直观地了解如何将图像与核进行卷积，从而从输入图像中提取特征。我们考虑一个数字为2的图像，在每个示例中，该图像与翻转了90度的相同3*3滤波器进行卷积。</p><p id="d0b1" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi translated">在我们的实验中，我们假设滤波器的阈值为+2。黑色像素表示为0，白色像素表示为1。卷积的结果如下所示。</p><p id="3cf3" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi">1.</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/a52d0cda908ee48c7f4358ffcec9875f.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*MyM8xPw7o3VKaWMDYiEpBQ.png"/></div></figure><p id="0fc4" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi translated">卷积的输出表明该滤波器善于检测内部边缘。这通过沿着对角线的图像中的明显边缘来显示。使用的3*3滤波器值为[[2，-1，-1]，[-1，2，-1]，[-1，-1，2]]。因此，当卷积输出大于定义的阈值2时，我们认为该卷积的输出为1，否则为0。</p><p id="f93b" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi">2.</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/5ebcf0eeb2124ec099fc72987a6c8bd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*JzO4O2iQUSyeYsZWmoc7XQ.png"/></div></figure><p id="c168" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi translated">卷积的输出表明滤波器在对角线边缘是坏的。这通过沿着对角线的图像中的明显边缘来显示。使用的3*3滤波器值为[[-1，-1，2]，[-1，2，-1]，[2，-1，-1]]。因此，当卷积输出大于定义的阈值2时，我们认为该卷积的输出为1，否则为0。</p><p id="6a2e" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi">3.</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/99e6cab6a34686e2edf303d0e30a527c.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*lJDdN-nRLnzh-JfXXKxSvw.png"/></div></figure><p id="0937" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi translated">卷积的输出表明该滤波器擅长检测水平边缘。这通过沿着水平面的图像中的明显边缘来显示。使用的3*3滤波器值为[[-1，2，-1]，[-1，2，-1]，[-1，2，-1]]。因此，当卷积输出大于定义的阈值2时，我们认为该卷积的输出为1，否则为0。</p><p id="122a" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi">4.</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/3d21d355466296a96093b062b204c40d.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*Tv17kSHAHH0wzMy_lD3vyA.png"/></div></figure><p id="8981" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi translated">卷积的输出表示滤波器擅长检测垂直边缘。这通过沿着垂直平面的图像中的明显边缘来显示。使用的3*3滤波器值为[[-1，2，-1]，[-1，2，-1]，[-1，2，-1]]。因此，当卷积输出大于定义的阈值2时，我们认为该卷积的输出为1，否则为0。</p><p id="8756" class="pw-post-body-paragraph kx ky iq kz b la mb jr lc ld mc ju lf lg md li lj lk me lm ln lo mf lq lr ls ij bi translated">源代码</p><div class="mq mr gp gr ms mt"><a href="https://github.com/shree6791/Deep-Learning/blob/master/CNN/MNIST/keras/src/Feature%20Extraction.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="mu ab fo"><div class="mv ab mw cl cj mx"><h2 class="bd ir gy z fp my fr fs mz fu fw ip bi translated">shree 6791/深度学习</h2><div class="na l"><h3 class="bd b gy z fp my fr fs mz fu fw dk translated">深度学习——这个知识库由Shreenidhi Sudhakar实施的深度学习项目组成。</h3></div><div class="nb l"><p class="bd b dl z fp my fr fs mz fu fw dk translated">github.com</p></div></div><div class="nc l"><div class="nd l ne nf ng nc nh lz mt"/></div></div></a></div></div></div>    
</body>
</html>