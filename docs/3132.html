<html>
<head>
<title>Real-time and video processing object detection using Tensorflow, OpenCV and Docker.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Tensorflow，OpenCV和Docker的实时和视频处理对象检测。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/real-time-and-video-processing-object-detection-using-tensorflow-opencv-and-docker-2be1694726e5?source=collection_archive---------0-----------------------#2018-04-12">https://towardsdatascience.com/real-time-and-video-processing-object-detection-using-tensorflow-opencv-and-docker-2be1694726e5?source=collection_archive---------0-----------------------#2018-04-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="186a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我将介绍如何在Docker容器中使用Tensorflow对象检测API来执行实时(网络摄像头)和视频后处理。我使用OpenCV和python3多处理和多线程库。</p><p id="066e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我将把重点放在我遇到的障碍，以及我找到了什么解决方案(或者没有！).完整的代码在我的Github上。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi km"><img src="../Images/4bd1ba7e87d817fc2f2b1122aae919fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*N6mE8UCzVSmG_VkMjVtzhw.gif"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Video processing test with Youtube video</figcaption></figure><h1 id="d71c" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">动机</h1><p id="ca34" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">我从<a class="ae kl" rel="noopener" target="_blank" href="/building-a-real-time-object-recognition-app-with-tensorflow-and-opencv-b7a2b4ebdc32">这篇优秀的Dat Tran文章</a>开始探索实时对象检测的挑战，引导我用<a class="ae kl" href="https://www.pyimagesearch.com/2015/12/21/increasing-webcam-fps-with-python-and-opencv/" rel="noopener ugc nofollow" target="_blank"> Adrian Rosebrock的网站</a>研究python多处理库来增加FPS。为了进一步增强可移植性，我想将我的项目集成到Docker容器中。这里的主要困难是处理进入和来自容器的视频流。</p><p id="c162" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，我在我的项目中添加了一个视频后处理功能，也使用了多处理来减少处理时间(当使用原始Tensorflow对象检测API时，处理时间可能会非常非常长)。</p><p id="c3de" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我的个人笔记本电脑上，仅使用8GB CPU，实时和视频处理都可以高性能运行。</p><h1 id="a749" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">数据科学码头工人</h1><p id="3396" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">我不会花时间描述Tensorflow对象检测API实现，因为关于这个主题的文章很多。相反，我将展示如何在我作为数据科学家的日常工作中使用Docker。请注意，我使用了Tensorflow的经典<a class="ae kl" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank"> ssd_mobilenet_v2_coco </a>模型，以获得速度性能。我复制了这个模型。pb文件)和相应的本地标签映射(在模型/目录中)以保持以后使用个人模型的可能性。</p><p id="7e00" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我相信今天使用Docker已经成为数据科学家的一项基本技能。在数据科学和机器学习领域，每周都会发布许多新的算法、工具和程序，将它们安装到您的计算机上进行测试是让您的操作系统崩溃的最佳方式(有经验的！).为了防止这种情况，我现在使用Docker容器来创建我的数据科学工作区。</p><p id="7b95" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可以在我的知识库中找到我正在为这个项目工作的docker文件。下面是我如何安装Tensorflow对象检测(遵循<a class="ae kl" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank">官方安装指南</a>):</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="35b5" class="mg kz iq mc b gy mh mi l mj mk"># Install tensorFlow<br/>RUN pip install -U tensorflow</span><span id="6ef4" class="mg kz iq mc b gy ml mi l mj mk"># Install tensorflow models object detection<br/>RUN git clone <a class="ae kl" href="https://github.com/tensorflow/models" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/models</a> /usr/local/lib/python3.5/dist-packages/tensorflow/models<br/>RUN apt-get install -y protobuf-compiler python-pil python-lxml python-tk</span><span id="514d" class="mg kz iq mc b gy ml mi l mj mk">#Set TF object detection available<br/>ENV PYTHONPATH "$PYTHONPATH:/usr/local/lib/python3.5/dist-packages/tensorflow/models/research:/usr/local/lib/python3.5/dist-packages/tensorflow/models/research/slim"<br/>RUN cd /usr/local/lib/python3.5/dist-packages/tensorflow/models/research &amp;&amp; protoc object_detection/protos/*.proto --python_out=.</span></pre><p id="9823" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">同样，我安装了OpenCV:</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="63a6" class="mg kz iq mc b gy mh mi l mj mk"># Install OpenCV<br/>RUN git clone <a class="ae kl" href="https://github.com/opencv/opencv.git" rel="noopener ugc nofollow" target="_blank">https://github.com/opencv/opencv.git</a> /usr/local/src/opencv<br/>RUN cd /usr/local/src/opencv/ &amp;&amp; mkdir build<br/>RUN cd /usr/local/src/opencv/build &amp;&amp; cmake -D CMAKE_INSTALL_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local/ .. &amp;&amp; make -j4 &amp;&amp; make install</span></pre><p id="9e5d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">图像构建有点长，需要几分钟时间。然后，使用它是快速和容易的。</p><h1 id="49a3" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">实时目标检测</h1><p id="2a12" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">我首先尝试应用对象检测到我的网络摄像头流。这项工作的主要部分在<a class="ae kl" rel="noopener" target="_blank" href="/building-a-real-time-object-recognition-app-with-tensorflow-and-opencv-b7a2b4ebdc32"> Dat Tran的文章</a>中有完整的描述。困难在于将网络摄像头流发送到docker容器中，并使用X11服务器恢复输出流以显示它。</p><h2 id="913f" class="mg kz iq bd la mm mn dn le mo mp dp li jy mq mr lm kc ms mt lq kg mu mv lu mw bi translated">将视频流发送到容器中</h2><p id="05be" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">在Linux中，设备位于/dev/目录中，可以作为文件进行操作。通常，您的笔记本电脑网络摄像头是“0”设备。要将其流发送到docker容器中，在运行docker映像时使用<em class="mx">设备</em>参数:</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="4c66" class="mg kz iq mc b gy mh mi l mj mk">docker run --device=/dev/video0</span></pre><p id="fc65" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于Mac和Windows用户来说，将网络摄像头流发送到容器中的方式不像Linux那样简单(尽管Mac是基于Unix的)。我没有深入研究这个问题，但是Windows用户的解决方案是使用虚拟盒子来启动docker容器。</p><h2 id="d161" class="mg kz iq bd la mm mn dn le mo mp dp li jy mq mr lm kc ms mt lq kg mu mv lu mw bi translated">从容器中恢复视频流</h2><p id="9168" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">这是我花了一些时间解决的问题(解决方案不令人满意)。我在Docker <a class="ae kl" href="http://wiki.ros.org/docker/Tutorials/GUI" rel="noopener ugc nofollow" target="_blank">这里</a>找到了关于使用图形用户界面的有用信息，特别是将容器连接到主机的X服务器进行显示。</p><p id="5ba3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，您必须公开您的xhost，这样容器就可以通过X11 unix套接字读写来正确显示。首先设置X服务器主机的权限(这不是最安全的方法)让docker访问它:</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="6fdc" class="mg kz iq mc b gy mh mi l mj mk">xhost +local:docker</span></pre><p id="f72c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，当您使用完项目后，将访问控制恢复为默认值:</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="9cde" class="mg kz iq mc b gy mh mi l mj mk">xhost -local:docker</span></pre><p id="0964" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，创建两个环境变量XSOCK和XAUTH:</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="b3b2" class="mg kz iq mc b gy mh mi l mj mk">XSOCK=/tmp/.X11-unix<br/>XAUTH=/tmp/.docker.xauth</span></pre><p id="3308" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第一个引用X11 Unix套接字，第二个引用我们现在创建的具有适当权限的X身份验证文件:</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="9a51" class="mg kz iq mc b gy mh mi l mj mk">xauth nlist $DISPLAY | sed -e 's/^..../ffff/' | xauth -f $XAUTH nmerge -</span></pre><p id="62ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们只需更新docker运行行命令。我们转发我们的DISPLAY环境变量，为X11 Unix套接字和X身份验证文件挂载一个卷，该文件带有一个名为XAUTHORITY的环境变量，它链接到:</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="21f7" class="mg kz iq mc b gy mh mi l mj mk">docker run -it --rm --device=/dev/video0 -e DISPLAY=$DISPLAY -v $XSOCK:$XSOCK -v $XAUTH:$XAUTH -e XAUTHORITY=$XAUTH</span></pre><p id="8e48" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们可以运行docker容器了，它已经完成了:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi my"><img src="../Images/9bd3efdf39f236d1796e61859fb4669f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*cMR5W-JeOc8l-n1pLXRVnw.gif"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Me with common objects at work (I’m a shy person).</figcaption></figure><p id="27f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">尽管主机的X服务器配置，我不能完全删除我的代码中似乎是一个错误。OpenCV需要通过使用<em class="mx"> cv2.imshow </em>函数调用python脚本(<em class="mx"> init-openCV.py </em>)进行“初始化”。我得到以下错误消息:</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="f387" class="mg kz iq mc b gy mh mi l mj mk">The program 'frame' received an X Window System error.</span></pre><p id="3ea8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，可以调用主python脚本(<em class="mx"> my-object-detection.py </em>)并且视频流被很好地发送到主机显示器。我对使用第一个python脚本来初始化X11系统的解决方案不是很满意，但是到目前为止我还没有找到任何解决这个问题的方法。</p><p id="4fce" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">编辑:我终于(而且不小心！)通过使用OpenCV (3.4.1)的稳定版本，而不是在本地克隆git repo，找到了这个问题的解决方案。因此，现在不需要在主python脚本之前调用<em class="mx"> init-openCV.py </em>。</p><h1 id="1b9b" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">视频处理</h1><p id="6226" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">为了设法用我的网络摄像头实时运行对象检测API，我使用了<em class="mx">线程</em>和<em class="mx">多处理</em> python库。一个线程被用来读取网络摄像头流。帧被放入队列中，由一组工作线程(Tensorflow对象检测在其中运行)进行处理。</p><p id="403c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">出于视频处理的目的，不可能使用线程，因为在工人能够对放入输入队列的第一个帧应用对象检测之前，所有视频的帧都被读取。输入队列已满时读取的帧会丢失。也许使用大量工作人员和庞大的队列可以解决这个问题(计算成本高得令人望而却步)。</p><p id="be3e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">简单队列的另一个问题是，由于不断变化的分析时间，帧在输出队列中的发布顺序不同于在输入队列中的顺序。</p><p id="4c04" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了增加我的视频处理功能，我移除了读取帧的线程。相反，我使用下面几行代码来读取帧:</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="170f" class="mg kz iq mc b gy mh mi l mj mk">while True:<br/>  # Check input queue is not full<br/>  if not input_q.full():<br/>     # Read frame and store in input queue<br/>     ret, frame = vs.read()<br/>      if ret:            <br/>        input_q.put((int(vs.get(cv2.CAP_PROP_POS_FRAMES)),frame))</span></pre><p id="7386" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果输入队列未满，则从视频流中读取下一帧并放入队列。否则，当帧没有从输入队列中获取时，什么也不做。</p><p id="a41c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了解决帧顺序的问题，我使用了一个优先级队列作为第二个输出队列:</p><ol class=""><li id="384a" class="mz na iq jp b jq jr ju jv jy nb kc nc kg nd kk ne nf ng nh bi translated">读取帧并将其与相应的帧编号一起放入输入队列(实际上，一个python列表对象被放入队列)。</li><li id="3daa" class="mz na iq jp b jq ni ju nj jy nk kc nl kg nm kk ne nf ng nh bi translated">然后，工人从输入队列中取出帧，对它们进行处理，并将其放入第一个输出队列中(仍然使用它们的相对帧号)。</li></ol><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="e2f2" class="mg kz iq mc b gy mh mi l mj mk">while True:<br/>  frame = input_q.get()</span><span id="96f2" class="mg kz iq mc b gy ml mi l mj mk">frame_rgb = cv2.cvtColor(frame[1], cv2.COLOR_BGR2RGB)<br/>  output_q.put((frame[0], detect_objects(frame_rgb, sess, detection_graph)))</span></pre><p id="275f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3.如果输出队列不为空，则帧被提取并放入优先级队列，其对应的帧号作为优先级号。优先级队列的大小被任意设置为其它队列大小的三倍。</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="7660" class="mg kz iq mc b gy mh mi l mj mk"># Check output queue is not empty<br/>if not output_q.empty():<br/>  # Recover treated frame in output queue and feed priority queue<br/>  output_pq.put(output_q.get())</span></pre><p id="08f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">4.最后，如果输出优先级队列不为空，则采用优先级最高的帧(优先级最小的帧)(这是标准优先级队列)。如果先前对应于预期的帧号，则该帧被添加到输出视频流(并且如果需要的话写入)，否则该帧被放回到优先级队列中。</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="1eca" class="mg kz iq mc b gy mh mi l mj mk"># Check output priority queue is not empty<br/>  if not output_pq.empty():<br/>    prior, output_frame = output_pq.get()<br/>    if prior &gt; countWriteFrame:<br/>      output_pq.put((prior, output_frame))<br/>    else: <br/>      countWriteFrame = countWriteFrame + 1    <br/>      # Do something with your frame</span></pre><p id="5d97" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了停止这个过程，我检查了所有的队列都是空的，并且所有的帧都已经从视频流中提取出来:</p><pre class="kn ko kp kq gt mb mc md me aw mf bi"><span id="a6d4" class="mg kz iq mc b gy mh mi l mj mk">if((not ret) &amp; input_q.empty() &amp; <br/>    output_q.empty() &amp; output_pq.empty()):<br/>  break</span></pre><h1 id="e86c" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">结论</h1><p id="08bc" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">在本文中，我将介绍如何使用docker通过Tensorflow实现一个实时对象检测项目。如上所述，docker是测试新数据科学工具以及打包我们向客户交付的解决方案的最安全方式。我还向您展示了我是如何改编Dat Tran的原始python脚本来执行多处理视频处理的。</p><p id="b6f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你从头到尾看完这篇文章，谢谢你！正如你所看到的，这个项目有很多可能的改进。不要犹豫给我一些反馈，我总是渴望得到建议或意见。</p></div></div>    
</body>
</html>