<html>
<head>
<title>How to get started in NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何开始学习 NLP</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-get-started-in-nlp-6a62aa4eaeff?source=collection_archive---------0-----------------------#2017-05-01">https://towardsdatascience.com/how-to-get-started-in-nlp-6a62aa4eaeff?source=collection_archive---------0-----------------------#2017-05-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/64a7ff96b36bc5b22cc6769f59f99391.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ciOJ1mKZF6qZeXqKupvFwg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Dependency parse tree visualized by <a class="ae kc" href="https://explosion.ai/demos/displacy" rel="noopener ugc nofollow" target="_blank">displaCy</a></figcaption></figure><p id="1602" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我在某处读到过，如果你不得不回答同一个问题两次，把它变成一篇博客文章可能是个好主意。为了遵守这条规则，也为了给未来的自己节省一些时间，我现在给出了这个问题的标准答案:“我的背景是科学，我对学习 NLP 感兴趣。我从哪里开始？”</p><p id="87d9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在您开始之前，请注意下面的列表实际上只是一个非常一般的起点(并且很可能是不完整的)。为了帮助浏览大量的信息，我在括号中添加了简短的描述和难度估计。建议掌握基本编程技能(例如 Python)。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h2 id="1003" class="li lj iq bd lk ll lm dn ln lo lp dp lq ko lr ls lt ks lu lv lw kw lx ly lz ma bi translated">在线课程</h2><ul class=""><li id="b39a" class="mb mc iq kf b kg md kk me ko mf ks mg kw mh la mi mj mk ml bi translated">丹·茹拉夫斯基&amp;克里斯·曼宁:自然语言处理【很棒的入门视频系列】</li><li id="c33a" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="http://cs224d.stanford.edu/syllabus.html" rel="noopener ugc nofollow" target="_blank"> Stanford CS224d:面向自然语言处理的深度学习</a>【面向 NLP 的更高级的 ML 算法、深度学习和 NN 架构】</li><li id="6d33" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="https://www.youtube.com/playlist?list=PLLssT5z_DsK8BdawOVCCaTCO99Ya58ryR" rel="noopener ugc nofollow" target="_blank"> Coursera:自然语言处理简介</a>【密歇根大学提供的自然语言处理简介课程】</li></ul><h2 id="bb4d" class="li lj iq bd lk ll lm dn ln lo lp dp lq ko lr ls lt ks lu lv lw kw lx ly lz ma bi translated">图书馆和开源</h2><ul class=""><li id="8513" class="mb mc iq kf b kg md kk me ko mf ks mg kw mh la mi mj mk ml bi translated"><strong class="kf ir"> spaCy </strong> ( <a class="ae kc" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank">网站</a>，<a class="ae kc" href="https://explosion.ai/blog/" rel="noopener ugc nofollow" target="_blank">博客</a>)【Python；新兴开源库，包含<a class="ae kc" href="https://spacy.io/usage/spacy-101" rel="noopener ugc nofollow" target="_blank">奇妙的使用示例</a>、API 文档和<a class="ae kc" href="https://spacy.io/docs/usage/showcase" rel="noopener ugc nofollow" target="_blank">演示应用</a></li><li id="91cd" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><strong class="kf ir">自然语言工具包(NLTK) </strong> ( <a class="ae kc" href="http://www.nltk.org/" rel="noopener ugc nofollow" target="_blank">网站</a>，<a class="ae kc" href="http://www.nltk.org/book/" rel="noopener ugc nofollow" target="_blank">书籍</a>)【Python；NLP 编程实用入门，主要用于教学]</li><li id="4b58" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><strong class="kf ir">斯坦福 CoreNLP </strong> ( <a class="ae kc" href="https://stanfordnlp.github.io/CoreNLP/" rel="noopener ugc nofollow" target="_blank">网站</a>)【Java；高质量的分析工具包]</li><li id="1a77" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><strong class="kf ir"> AllenNLP </strong> ( <a class="ae kc" href="https://allennlp.org/" rel="noopener ugc nofollow" target="_blank">网站</a>)【Python；NLP 研究库建立在<a class="ae kc" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>之上</li><li id="2f45" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><strong class="kf ir"> fastText </strong> ( <a class="ae kc" href="https://fasttext.cc/" rel="noopener ugc nofollow" target="_blank">网站</a>)[c++；用于文本分类和表示学习的高效库]</li></ul><h2 id="5566" class="li lj iq bd lk ll lm dn ln lo lp dp lq ko lr ls lt ks lu lv lw kw lx ly lz ma bi translated">活跃的博客</h2><ul class=""><li id="8220" class="mb mc iq kf b kg md kk me ko mf ks mg kw mh la mi mj mk ml bi translated"><a class="ae kc" href="https://nlpers.blogspot.com/" rel="noopener ugc nofollow" target="_blank">自然语言处理博客</a> (Hal Daumé III)</li><li id="d36f" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="http://languagelog.ldc.upenn.edu/nll/" rel="noopener ugc nofollow" target="_blank">语言日志</a>(马克·利伯曼)</li><li id="a736" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="https://research.googleblog.com/" rel="noopener ugc nofollow" target="_blank">谷歌研究博客</a></li><li id="45f6" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="https://explosion.ai/blog/" rel="noopener ugc nofollow" target="_blank">爆炸 AI 博客</a></li><li id="45f9" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="https://medium.com/huggingface" rel="noopener">抱脸</a></li><li id="31eb" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="http://ruder.io/#open" rel="noopener ugc nofollow" target="_blank">塞巴斯蒂安·鲁德博客</a></li></ul><h2 id="90fd" class="li lj iq bd lk ll lm dn ln lo lp dp lq ko lr ls lt ks lu lv lw kw lx ly lz ma bi translated">书</h2><ul class=""><li id="34ed" class="mb mc iq kf b kg md kk me ko mf ks mg kw mh la mi mj mk ml bi translated"><a class="ae kc" href="https://web.stanford.edu/~jurafsky/slp3/" rel="noopener ugc nofollow" target="_blank">语音和语言处理</a> (Jurafsky 和 Martin)[涵盖所有基础知识的经典 NLP 教科书，第 3 版即将出版]</li><li id="6687" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="https://nlp.stanford.edu/fsnlp/" rel="noopener ugc nofollow" target="_blank">统计自然语言处理基础</a>(Manning and schütze)[更高级的统计 NLP 方法]</li><li id="255c" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="https://nlp.stanford.edu/IR-book/" rel="noopener ugc nofollow" target="_blank">信息检索导论</a> (Manning，Raghavan，schütze)[排名/搜索优秀参考]</li><li id="3edc" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="https://www.morganclaypool.com/doi/abs/10.2200/S00762ED1V01Y201703HLT037" rel="noopener ugc nofollow" target="_blank">自然语言处理中的神经网络方法</a>(gold Berg)[NN 方法深度介绍 NLP，此处<a class="ae kc" href="http://u.cs.biu.ac.il/~yogo/nnlp.pdf" rel="noopener ugc nofollow" target="_blank">引子</a> ]</li><li id="4e88" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="http://www.morganclaypool.com/doi/abs/10.2200/S00493ED1V01Y201303HLT020" rel="noopener ugc nofollow" target="_blank">自然语言处理的语言基础</a>(Bender)[更成功的自然语言处理的形态学和句法基础]</li><li id="7cba" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="http://www.deeplearningbook.org/" rel="noopener ugc nofollow" target="_blank">深度学习</a>(古德费勒、库维尔和本吉奥)[深度学习最佳入门]</li></ul><h2 id="06a5" class="li lj iq bd lk ll lm dn ln lo lp dp lq ko lr ls lt ks lu lv lw kw lx ly lz ma bi translated">多方面的</h2><ul class=""><li id="64b2" class="mb mc iq kf b kg md kk me ko mf ks mg kw mh la mi mj mk ml bi translated"><a class="ae kc" href="https://www.tensorflow.org/versions/master/tutorials/word2vec/index.html" rel="noopener ugc nofollow" target="_blank">如何在 TensorFlow 中构建 word2vec 模型</a>【教程】</li><li id="08e4" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="https://github.com/andrewt3000/dl4nlp" rel="noopener ugc nofollow" target="_blank">针对自然语言处理资源的深度学习</a>【针对深度学习的最先进资源概述，按主题组织】</li><li id="432c" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated">最后一句话:计算语言学和深度学习——看看自然语言处理的重要性。(配员)【文章】</li><li id="ce77" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="https://github.com/nyu-dl/NLP_DL_Lecture_Note/blob/master/lecture_note.pdf" rel="noopener ugc nofollow" target="_blank">分布式表示的自然语言理解</a> (Cho)【关于 NLU 的 ML/NN 方法的独立讲稿】</li><li id="ab66" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="http://www.isi.edu/natural-language/people/bayes-with-tears.pdf" rel="noopener ugc nofollow" target="_blank">贝叶斯含泪推断</a>(骑士)【教程练习册】</li><li id="96fa" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated">计算语言学协会</li><li id="4668" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="https://www.quora.com/How-do-I-learn-Natural-Language-Processing" rel="noopener ugc nofollow" target="_blank"> Quora:我如何学习自然语言处理？</a></li><li id="01da" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="https://docs.google.com/document/d/1mkB6KA7KuzNeoc9jW3mfOthv_6Uberxs8l2H7BmJdzg/edit" rel="noopener ugc nofollow" target="_blank">自然语言理解和计算语义学</a> (Bowman)【带综合幻灯片的开源课程大纲】</li><li id="f6fb" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated"><a class="ae kc" href="http://www.fast.ai/" rel="noopener ugc nofollow" target="_blank"> fast.ai </a> [“让神经网络再次变得不酷”]</li></ul><h2 id="5a2d" class="li lj iq bd lk ll lm dn ln lo lp dp lq ko lr ls lt ks lu lv lw kw lx ly lz ma bi translated"><strong class="ak"> DIY 项目和数据集</strong></h2><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/408a30cba4ca5ce9eda3ce088cc6f038.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*ItVQqIU6CfdPq33b6roCdw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Source: <a class="ae kc" href="http://gunshowcomic.com/comics/20120227-robotthatscreams.png" rel="noopener ugc nofollow" target="_blank">http://gunshowcomic.com/</a></figcaption></figure><p id="569d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Nicolas Iderhoff 已经创建了一个公开可用的 NLP 数据集的完整列表。除此之外，我还可以向任何想要尝试的 NLP 新手推荐一些项目:</p><ul class=""><li id="931b" class="mb mc iq kf b kg kh kk kl ko mw ks mx kw my la mi mj mk ml bi translated">基于<a class="ae kc" href="https://en.wikipedia.org/wiki/Hidden_Markov_model" rel="noopener ugc nofollow" target="_blank">隐马尔可夫模型</a> (HMM)实现<a class="ae kc" href="https://en.wikipedia.org/wiki/Part-of-speech_tagging" rel="noopener ugc nofollow" target="_blank">词性标注器</a></li><li id="21b0" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated">实现<a class="ae kc" href="https://en.wikipedia.org/wiki/CYK_algorithm" rel="noopener ugc nofollow" target="_blank"> CYK 算法</a>来解析<a class="ae kc" href="https://en.wikipedia.org/wiki/Context-free_grammar" rel="noopener ugc nofollow" target="_blank">上下文无关文法</a></li><li id="14c2" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated">实现文本集合中两个给定单词之间的<a class="ae kc" href="https://en.wikipedia.org/wiki/Semantic_similarity" rel="noopener ugc nofollow" target="_blank">语义相似度</a>，例如<a class="ae kc" href="https://en.wikipedia.org/wiki/Pointwise_mutual_information" rel="noopener ugc nofollow" target="_blank">点态互信息</a> (PMI)</li><li id="87ad" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated">实现一个<a class="ae kc" href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier" rel="noopener ugc nofollow" target="_blank">朴素贝叶斯分类器</a>来<a class="ae kc" href="https://en.wikipedia.org/wiki/Naive_Bayes_spam_filtering" rel="noopener ugc nofollow" target="_blank">过滤垃圾邮件</a></li><li id="37cf" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated">基于单词间的编辑距离实现一个<a class="ae kc" href="https://en.wikipedia.org/wiki/Spell_checker" rel="noopener ugc nofollow" target="_blank">拼写检查器</a></li><li id="6b88" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated">实现一个<a class="ae kc" href="https://en.wikipedia.org/wiki/Markov_chain" rel="noopener ugc nofollow" target="_blank">马尔可夫链</a>文本生成器</li><li id="e371" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated">使用<a class="ae kc" href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" rel="noopener ugc nofollow" target="_blank">潜在狄利克雷分配</a> (LDA)实现一个<a class="ae kc" href="https://en.wikipedia.org/wiki/Topic_model" rel="noopener ugc nofollow" target="_blank">主题模型</a></li><li id="43a0" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated">使用<a class="ae kc" href="https://code.google.com/archive/p/word2vec/" rel="noopener ugc nofollow" target="_blank"> word2vec </a>从大型文本语料库中生成单词嵌入，例如<a class="ae kc" href="https://en.wikipedia.org/wiki/Wikipedia:Database_download" rel="noopener ugc nofollow" target="_blank">维基百科</a></li><li id="e31e" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated">使用<a class="ae kc" href="https://en.wikipedia.org/wiki/K-means_clustering" rel="noopener ugc nofollow" target="_blank"> k-means </a>聚类<a class="ae kc" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank"> tf-idf </a>文本向量，例如新闻文章</li><li id="7b30" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated">实现一个<a class="ae kc" href="https://en.wikipedia.org/wiki/Named-entity_recognition" rel="noopener ugc nofollow" target="_blank">命名实体识别器</a> (NER)(也称为名称标记器)，例如遵循<a class="ae kc" href="https://www.clips.uantwerpen.be/conll2003/ner/" rel="noopener ugc nofollow" target="_blank"> CoNLL-2003 共享任务</a></li></ul><h2 id="712c" class="li lj iq bd lk ll lm dn ln lo lp dp lq ko lr ls lt ks lu lv lw kw lx ly lz ma bi translated">社交媒体上的 NLP</h2><ul class=""><li id="af1c" class="mb mc iq kf b kg md kk me ko mf ks mg kw mh la mi mj mk ml bi translated">推特:<a class="ae kc" href="https://twitter.com/hashtag/nlproc" rel="noopener ugc nofollow" target="_blank"> #nlproc </a>，<a class="ae kc" href="https://twitter.com/jasonbaldridge/lists/nlpers" rel="noopener ugc nofollow" target="_blank">nl pers 名单</a>(作者杰森·鲍德里奇)</li><li id="7d64" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated">Reddit:<a class="ae kc" href="https://www.reddit.com/r/LanguageTechnology" rel="noopener ugc nofollow" target="_blank">/r/language technology</a></li><li id="835c" class="mb mc iq kf b kg mm kk mn ko mo ks mp kw mq la mi mj mk ml bi translated">中:<a class="ae kc" href="https://medium.com/tag/nlp" rel="noopener"> Nlp </a></li></ul></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="21bd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mz">在推特上联系我</em><strong class="kf ir"><em class="mz">@ melto mene</em></strong></p></div></div>    
</body>
</html>