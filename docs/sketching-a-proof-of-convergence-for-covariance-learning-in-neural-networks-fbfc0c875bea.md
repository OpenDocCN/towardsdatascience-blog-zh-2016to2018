# 神经网络协方差学习收敛性的一个证明

> 原文：<https://towardsdatascience.com/sketching-a-proof-of-convergence-for-covariance-learning-in-neural-networks-fbfc0c875bea?source=collection_archive---------5----------------------->

*(我提供了一个冗长的、有点技术性的解释，详细阐述了我的著作*[](https://medium.com/@oaklandthinktank/overcoming-the-vanishing-gradient-problem-9569191df342)**[*协方差*](https://medium.com/towards-data-science/more-about-the-gradient-bf97e4d9c1c5) *作为一个* [*全网络成本函数*](https://aboveintelligent.com/details-on-reinforcement-by-covariance-75df1d9f4725) *，它允许网络* [*训练新插入的神经元*](https://medium.com/towards-data-science/mixture-of-experts-with-covariance-6d4a167743ad) *，特别是对于专家神经网络的混合。这项工作旨在促进* ***机器智能的发展，使其能够在新的经验发生时学习*** *。)***

****先来点背景:****

***神经网络功能强大。***

**神经网络正在诊断癌症，并在数百种语言之间进行翻译。使用深度神经网络，复杂的分类任务现在成为可能。随着我们依赖神经网络进行日益复杂的活动，我们可以预计这些网络将扩展到令人难以置信的深度。这些网络具有巨大的潜在价值。然而，训练非常深的神经网络会带来一些挑战…**

**过度拟合是一个问题。**

**当一个神经网络被训练来分类数据时，它最终学会了完美地排序——但是，它只会完美地排序你的训练数据，因为它*记住了整个集合*。当给定*新数据*时，这些过度拟合模型表现不佳。从一个**随机网络**(执行*随机*分类)移动到一个**记忆数据网络**(执行*精确*分类，即它是“过拟合”)是一个*大飞跃*，而**良好泛化网络**(对*新数据*表现良好)位于附近的点*。当给定新数据时，一旦分类器开始恶化，研究人员就停止他们的训练。这是一个难题，要解决的事实是*最小化‘损失函数’并不是我们真正想要的*。我们实际上想要一个好的概括！***

*培训——时间就是金钱。*

*更深层次的神经网络需要更长的训练时间，并且通常需要更大的数据集才能很好地学习。你可以使用 GPU(或 TPU)来减少时间和成本，但**那只是一次性的改进**。从根本上来说，**随着关系网越来越深，培训成本将大幅上升。** *摩尔定律已死*，因此*“计算机硬件的改进将继续使深度神经网络更便宜”*的说法不攻自破。*

**而且，学习需要无处不在。**

*神经网络在网络的深度上存储学习:简单的局部特征(如边缘的位置)通常在较低层被区分，而较高层对更抽象的特征(如“动物”、“工具”、“建筑物”)进行分类。不幸的是，神经网络是使用来自*输出层* — **的反向传播来训练的，它们自上而下**地学习。因此，必须在*低层*学习的特性只能通过**向下扩散通过多层**的信号来教授。这被称为“消失梯度”问题。残差和跳过连接是时髦的解决方法，但是它们没有消除自上而下学习的问题。(残差本质上*放大了梯度*，而跳跃连接*有效地拉平了网络的深度*；**两个**还是从最上面一层学起，往下。)*

***协方差是治愈的方法***

*具体来说，*负*协方差(以及它的表亲，**负相关**)就是解。当两个信号趋向于以相反方向出现*时，就会出现负协方差:如果一个信号为“开”，另一个信号为“关”，反之亦然。对于神经网络，如果神经元在正确分类数据时是“开”的，而在错误分类数据时是“关”的，则记录负协方差。(此外，负协方差也记录在逆条件中:正确分类数据时为“关”，错误分类数据时为“开”。)记录负协方差的神经元本质上是**错误检测器**。他们告诉我们:‘如果这个神经元在放电，那么我们就有可能得到错误的答案。我们应该倾听这些神经元，找出哪些教训没有被吸取。**

**协方差消除了自上而下的学习**

*今天的神经网络都受到自上而下学习的困扰——它们的“损失函数”或“成本函数”是在输出层发现的*误差。(损失函数问:“神经网络得到正确的*答案*了吗？”)同时，**协方差** **可以在任意层**发现错误，而不仅仅是最顶层的输出层！负协方差是一个**错误检测器**，专门指向对错误“负责”的神经元。**

*换句话说:如果神经网络是企业，那么“损失函数”就是一份备忘录，在到达员工之前，它会经过许多管理层。“损失函数”得出的结果是“我们的企业赔钱了！”并告诉上层管理人员“做一些不同的事情”。然后，这些经理向所有中层经理传达一个信息，坚持要求他们“做一些不同的事情”。当这个消息传到所有员工手中时，他们应该改变什么还不清楚。这份备忘录一开始就含糊不清，随着它在层级中的传递，变得越来越淡化。*

*继续商业隐喻:负协方差就像一份有针对性的备忘录，在个人绩效评估之后。协方差询问每个神经元/员工:“是这个员工*做了导致我们产品失败的工作吗？”*整个网络*正在审核中，消息“做一些不同的事情”仅*发送给需要做一些不同事情的神经元/员工！***

*因此，当*损失函数仅在输出层*定义时，协方差在**在网络**中的每个神经元定义。有了协方差，学习就发生在任何需要的地方，与层无关。*

**协方差节省时间和金钱**

*训练一个非常深的神经网络会增加时间，因为“业务备忘录”在通过额外的层时会变得稀释。相比之下，协方差以它的“备忘录”为目标，可以给每个神经元发出禁令，**而不管深度**。有了协方差，*额外的层不会冲淡信息*，因此，它们不会延长训练时间。*

*协方差节省了*重新训练*的时间。传统的训练创造了一个**静态**的神经网络；如果新数据被包括在网络的训练中，它通常从零开始被重新训练*。假设新数据需要对一些底层特性进行更改？在较低层发生有意义的变化之前，网络需要向下发送大量的“备忘录”。负协方差避免了这个问题，通过**立即识别对错误**、*负责的特定神经元，而*不需要向下移动层级。**

*随着神经网络变得更加深入，它们无法使用自上而下的学习快速进行重新训练。深度网络的频繁更新变得极其昂贵，而且**新数据可能在他们完成对旧数据的训练时到达**！负协方差消除了重新训练的滞后和成本，允许难以置信的深度神经网络随着每一批新数据更新*。对于许多应用程序来说，这种能力是玩具模型和可用产品之间的区别。**

***协方差将特征检测推到最低层，以延迟过拟合***

**这一点需要一点努力:通过在呈现负协方差的神经元上应用反向传播，网络被向下“推”,检测尽可能最低层的特征。当特征在早期被识别出来，网络就更难陷入记忆。收敛的证明要求最终达到完美的精度，但是当网络依赖于早期特征检测时，这种精度不太可能来自记忆。**

**为了展示这一切是如何发生的:**

**想象一个神经网络，其中最后一层仅仅是它下面一层的复制；电线正在全力连接单个神经元。这两层的反应是一样的。因此，最后一层实际上是不相关的，所有真正的计算都发生在较低层。我们可以说，分类问题已经被“推下”到更低的层。**

**如果我们制造一个神经网络，其层数比**所需的**多，我们希望训练会导致特征检测的‘下推’，消除**额外的**层。这是因为**额外的**层允许网络以*更大的特异性*进行分类——我们需要**足够的**层来指定我们的分类，但是*太多的*特异性会让网络*记住*(“过拟合”)训练数据。**

**因此，如果分类任务被我们的训练算法“下推”，那么网络仍然能够获得所有训练数据的准确性(这是“它需要的层”的定义)。然而，**没有必要的深度**来*完美地记忆数据*；它只有足够的层数来学习有效的分类。这种特性可以扩展到应用于所有层的所有特征检测:如果网络在可能的最低层捕获那些特征，那么只有足够的深度来允许分类，而没有足够的深度来允许完美的记忆。一个将特征检测“推”到最低可能层的网络将*延迟过拟合*——这就是我认为协方差所实现的。**

**那么，负协方差如何“下推”特征检测呢？**

**如果一个神经元记录了负协方差，它就是在说“当网络出错时，我就开火”。为了能够识别错误，该神经元必须*接收关于正在发生的错误的信息数据*。也就是说:**到达那个神经元的信息是*参与了*的错误。**(如果不是这样，神经元将*无法检测错误*，因此，它将不会记录负协方差——该陈述是同义反复的！)通过从该神经元反向传播，其下的神经元被抑制，这是*对导致错误的信息的抑制*。任何在错误期间活动的特征*将被阻止，结果，分类开始**依赖于正确的特征，**因为它们是唯一没有被阻止的特征**。*****

****这种“沮丧”适用于每一层；反向传播不鼓励在较低层检测到的任何导致较高层出现负协方差的特征。(这正是“损失函数”在输出层所做的；“损失函数”实际上只是限制在最顶层的负协方差。通过推广这一活动，负协方差让我们在所有层都这样做。)对*进行正确分类的更高层神经元*可能会阻止其一些输入，因为这些输入**也会**传播到具有负协方差的神经元。这意味着更高层的神经元，在这种沮丧的情况下，开始更密切地倾听输入神经元，而这些神经元是*自己*正确分类的。在极端情况下，*输入*神经元将执行正确的分类，并将其传输到更高层。在最上层，这种情况相当于当其下层输入是单个正确分类的神经元时，输出神经元触发。这就是我们**将**定义为‘下推’的特征检测！****

****因此，使用共变神经元的反向传播训练的网络将倾向于抑制任何层的神经元的活动，这些神经元涉及错误。*保持活跃*的神经元是那些*已经正确分类特征*的神经元。那些正确分类器之上的层是**有效冗余的**。这样做的影响是:正确的分类被“下推到”较低层，而仅仅是复制到较高层(除非较低层不能自己完全分类，在这种情况下，较高层神经元从较低层接收一些活动*组合*——这是“需要更多层”的一个例子)。****

******收敛证明的草图:******

****没有收敛性的证明，训练算法*可能*跳跃，而不会在训练数据上达到完美的精度。(它**可以**达到完美的精确度，但是我们没有数学上的保证！)我将介绍几个技巧，来解决负协方差的收敛问题:****

*****半学习*****

****在通过我们的神经网络运行所有训练数据之后，我们将正确分类的输入从错误分类的输入中分离出来，并针对每个神经元测量这两组之间的负协方差。然后，我们根据负协方差的程度，通过反向传播在每个神经元上应用梯度下降。假设，在应用梯度下降的“学习”之后，我们发现*错误分类的数量增加了*！在这种情况下，将“学习”的速度减半，然后再试一次。继续将学习率减半，**直到错误数量不再增加**。现在你有相同或更少的错误分类，你再次测量负协方差…我将这个过程称为将学习率减半的网络“半学习”。它保证*错误率不会增加*。****

*****半学习的停止点*****

****半学半会什么时候停？即使是最轻微的学习率也会导致错误数量的增加。当错误数为正时，会发生这种情况吗？回答这个问题需要仔细观察:****

****当仍然存在误差时，一些神经元表现出负协方差。也就是说，它们在错误分类时倾向于“开”，在正确分类时倾向于“关”，反之亦然。如果唯一具有负协方差的神经元是输出神经元之一(错误触发的神经元，导致错误分类)，那么这种情况相当于在输出层具有错误分类的传统“损失函数”。这在现有文献中已经被证明是一致的。****

****现在，假设有一个错误分类(它必然包括一个输出神经元上的负协方差)，即*也在更深的层中的另一个神经元上显示负协方差。如果“半学习”可以找到消除误差的共变神经元的小变化*，而不产生新的误差*，那么网络仍然收敛。*****

***存在一个“半学习”率，它消除了现有的误差*，而没有产生新的误差*。这是因为输出层上的错误分类器必须依赖错误神经元及其输入**多于正确分类器**。(如果正确分类器比错误分类器更依赖错误神经元*，那么它们必然**也会**错误分类输入。正确-根据定义，输出层上的分类器必须利用**主要正确的**输入！)因为输出层*上的错误分类神经元比其他输出神经元更依赖于下层错误神经元***，所以错误神经元的变化对错误分类器的影响*将大于对正确神经元的影响* …可以使用一些小的“半学习”率来消除错误分类，而无需过多地改变正确神经元！******

*****因此，我们已经证明了在输出层的单个神经元具有负协方差的情况下的收敛性(这只是传统的“损失函数”，现有文献中已经证明了收敛性)，以及在某个较低层的*附加*神经元呈现负协方差的情况下的收敛性(上一段中的“错误神经元”)。通过归纳，我提出**任何层上呈现负协方差的额外神经元同样受到约束**，并且**同样收敛**，结果。与正确分类的神经元相比，每个错误神经元在输出层与错误分类的关联 *必然*更强* ***，因此，这些错误神经元的微小变化对错误分类器**的影响比对正确分类器**的影响更大。这保证了误差不会增加，并且可以减少到零。*********

***就这些吗？***

***我并不打算暗示协方差允许网络总是比现有方法收敛得更快。相反，协方差能够训练*插入的神经元簇，提供更快的* ***再训练*** *倍*。你可以在现有网络内的任何地方培养一个新的神经元集群，并根据新数据对其进行训练，而网络的其余权重则被“冻结”。我建议在专家混合神经网络中的错误检测神经元上植入这些簇。每个集群本质上充当一个“专业专家”，从错误检测器中提取特征，帮助纠正错误！网络适应新的数据，而不会忘记旧的教训(健忘是重新训练深度网络的祸根！)…我希望负协方差将促进*异常深层网络*的发展，这些网络快速成长并适应新信息**，*而不会失去他们在过去学到的核心洞察力*。*****