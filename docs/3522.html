<html>
<head>
<title>[ ICLR 2015 ] Striving for Simplicity: The All Convolutional Net with Interactive Code [ Manual Back Prop with TF ]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">【ICLR 2015】力求简单:带交互码的全卷积网【带 TF 的手动背道具】</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/iclr-2015-striving-for-simplicity-the-all-convolutional-net-with-interactive-code-manual-b4976e206760?source=collection_archive---------7-----------------------#2018-05-20">https://towardsdatascience.com/iclr-2015-striving-for-simplicity-the-all-convolutional-net-with-interactive-code-manual-b4976e206760?source=collection_archive---------7-----------------------#2018-05-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/ba1b8a8b4a66a49d5fa5c122d2ebae07.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/1*ZSydmDd6rH6X-LvPUm0nrQ.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">GIF from this <a class="ae jy" href="https://giphy.com/gifs/beauty-HPfyB1Uc0oS3K" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="3e26" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我已经假设很多人已经知道这篇文章，“力求简单:所有卷积网络 ”它非常有名，目前它是第二个对 CIFAR 10 数据集分类最准确的网络<a class="ae jy" href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130" rel="noopener ugc nofollow" target="_blank"/>。</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi ky"><img src="../Images/bbc53e92f884d2bd78fe767a4a5b2026.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AKXAKC1DyEn9a53RBbZCMA.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image from this <a class="ae jy" href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="a3e3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">从上面，我们可以看到全卷积网络是多么有效。在这篇文章中，我们将实现两种不同类型的网络架构，像往常一样，让我们看看所有不同的优化方法进行比较。</p><p id="efc2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><em class="kx">案例 a)具有自动微分动量的 conv pool-CNN<br/>案例 b)具有自动微分动量的 conv pool-CNN<br/>案例 c)具有手动回推</em><a class="ae jy" href="https://medium.com/@SeoJaeDuk/implementation-of-optimization-for-deep-learning-highlights-in-2017-feat-sebastian-ruder-61e2cbe9b7cb" rel="noopener"><em class="kx">AMSGrad</em></a><em class="kx"><br/>案例 d)具有手动回推</em><a class="ae jy" href="https://medium.com/@SeoJaeDuk/implementation-of-optimization-for-deep-learning-highlights-in-2017-feat-sebastian-ruder-61e2cbe9b7cb" rel="noopener"><em class="kx">AMSGrad</em></a><em class="kx">(</em><a class="ae jy" rel="noopener" target="_blank" href="/outperforming-tensorflows-default-auto-differentiation-optimizers-with-interactive-code-manual-e587a82d340e"><em class="kx">扩张</em></a></p><p id="1028" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><em class="kx">情况 e)全 CNN 带自动分化动量<br/>情况 f)全 CNN 带自动分化亚当<br/>情况 g)全 CNN 带手动回推</em><a class="ae jy" href="https://medium.com/@SeoJaeDuk/implementation-of-optimization-for-deep-learning-highlights-in-2017-feat-sebastian-ruder-61e2cbe9b7cb" rel="noopener"><em class="kx">AMSGrad</em></a><em class="kx"><br/>情况 h)全 CNN 带手动回推</em><a class="ae jy" href="https://medium.com/@SeoJaeDuk/implementation-of-optimization-for-deep-learning-highlights-in-2017-feat-sebastian-ruder-61e2cbe9b7cb" rel="noopener"><em class="kx">AMSGrad</em></a><em class="kx">(</em><a class="ae jy" rel="noopener" target="_blank" href="/outperforming-tensorflows-default-auto-differentiation-optimizers-with-interactive-code-manual-e587a82d340e"><em class="kx">扩张</em> </a> <em class="kx"/></p></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><figure class="kz la lb lc gt jr"><div class="bz fp l di"><div class="lo lp l"/></div></figure></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><p id="3200" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">网络架构</strong></p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi lq"><img src="../Images/de16b5cbc1bf3d4249b3a5df98fc5e2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EGuklCK_C76MYFy_D3iNlw.png"/></div></div></figure><p id="be18" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">从上图中，我们可以看到本文提出的总体架构，因为今天我将只关注 ConvPool-CNN 模型和 All-CNN 模型。值得注意的一个有趣事实是，在最终卷积运算之后会发生什么，如下所示，我们将执行全局平均池运算。</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi lr"><img src="../Images/c4eeab2cf862b616de3a317940bdfb63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gJdzKxNwfP6YTR4LwD5etg.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image of General Base Model Presented in the Paper</figcaption></figure><p id="36d7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">蓝线</strong> →全局平均池操作</p><p id="6f0f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在继续阅读之前，请注意两件事。<br/> a)我将使用均值池而不是最大池<br/> b)我将执行<a class="ae jy" href="https://github.com/aleju/imgaug" rel="noopener ugc nofollow" target="_blank">数据扩充</a>和<a class="ae jy" rel="noopener" target="_blank" href="/understanding-batch-normalization-with-examples-in-numpy-and-tensorflow-with-interactive-code-7f59bb126642">标准均值归一化</a>。</p><p id="9eb6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在，让我们更深入地了解一下这个全局平均池操作是什么。</p></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><p id="829a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">全球平均池</strong></p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi ls"><img src="../Images/4d745687391b7b08f60996a3673dc8fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*q5tfLfIChA0YiExe.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image from this <a class="ae jy" href="https://alexisbcook.github.io/2017/global-average-pooling-layers-for-object-localization/" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="7876" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，我们可以观察到全局平均池操作减少了给定输入的维度。所以我们可以怀疑这个操作是平均池操作的极端版本。现在让我们看看如何在 Tensorflow 中实现它。</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi lt"><img src="../Images/4b438256e10664202f682e335eb0d8df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fsmF7GK1I4NXXgF2dWRPBA.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image from this <a class="ae jy" href="https://stackoverflow.com/questions/42054451/how-do-i-do-global-average-pooling-in-tensorflow" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="89a3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">从上图中，我们可以看到如何在 Tensorflow 中实现这个操作。现在让我们看看这个操作做了什么。</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi lu"><img src="../Images/211b2a9049ca7f887892c0d44b1fec24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fgPqus2bXzY7yCxZBWNZ1w.png"/></div></div></figure><p id="4c9f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，我们可以观察到全局平均池操作与取矩阵的平均值相同。(因此，通过适当的信道维数，我们可以将矩阵简化为向量。)此外，如果有人感兴趣，请查看这篇<a class="ae jy" href="https://alexisbcook.github.io/2017/global-average-pooling-layers-for-object-localization/" rel="noopener ugc nofollow" target="_blank">博客文章了解更多信息</a>。(<a class="ae jy" href="https://alexisbcook.github.io/" rel="noopener ugc nofollow" target="_blank">亚历克西斯·库克</a>也做了一项了不起的工作，解释了全球平均汇集[差距]。)此外<a class="ae jy" href="https://github.com/AndersonJo" rel="noopener ugc nofollow" target="_blank"> AndersonJo </a>做了一项令人惊叹的工作，解释 GAP 请点击此处或<a class="ae jy" href="https://github.com/AndersonJo/global-average-pooling/blob/master/global-average-pooling.ipynb" rel="noopener ugc nofollow" target="_blank">此处</a>。(注一是韩语)。</p></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><p id="0368" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="kx">结果:案例 a)具有自动微分动量的 conv pool-CNN</em></strong></p><div class="kz la lb lc gt ab cb"><figure class="lv jr lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><img src="../Images/17d68b4c556a06fc4080d488db158e7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*khTScQx_dCfOEk3_dZgeVQ.png"/></div></figure><figure class="lv jr lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><img src="../Images/6f4f12fe24c09b8104dbf598bd78b537.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Zu7eJuzFJk5HQFndrR9tQg.png"/></div></figure></div><p id="02e1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →随时间训练精度/随时间成本<br/> <strong class="kb ir">右图</strong> →随时间测试精度/随时间成本</p><p id="bf3d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，我们可以看到，只有在 20 个历元之后，我们才能达到 88%的准确度。考虑到训练图像上的准确率仍然是 96 %,有 4%的机会增加，有可能达到 90%的准确率。</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi mb"><img src="../Images/f1efa00f0bc2e753fbeff859217b5df9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3hHQVEEp5ofpOkahJowJcA.png"/></div></div></figure></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><p id="9bbc" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果:<em class="kx">病例 b)具有自动微分的 ConvPool-CNN 亚当</em>T3】</strong></p><div class="kz la lb lc gt ab cb"><figure class="lv jr lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><img src="../Images/c8ba2b5a69e7698b2096f69dffd01e70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*reKbTi1A2HPQPdjg1U0gMA.png"/></div></figure><figure class="lv jr lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><img src="../Images/9d695e3a353cbcea84fcdd37a49094de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*SMwpHoh27IMhWTp3bucNwA.png"/></div></figure></div><p id="2192" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →随时间训练精度/随时间成本<br/> <strong class="kb ir">右图</strong> →随时间测试精度/随时间成本</p><p id="1e26" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于 Adam，我们可以在测试图像上观察到 88%的相似准确性，当与动量比较时，看到结果如此相似是非常有趣的。(我认为它会非常合适)</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi mc"><img src="../Images/1f865eed4e23730bfceb5dd72d8fd8d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vyalbBpLr0xvSXXG207_6g.png"/></div></div></figure></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><p id="a9f6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果:<em class="kx">案例 c) ConvPool-CNN 带手动回柱</em></strong><a class="ae jy" href="https://medium.com/@SeoJaeDuk/implementation-of-optimization-for-deep-learning-highlights-in-2017-feat-sebastian-ruder-61e2cbe9b7cb" rel="noopener"><strong class="kb ir"><em class="kx">AMSGrad</em></strong></a></p><div class="kz la lb lc gt ab cb"><figure class="lv jr lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><img src="../Images/6619b732042c6411854d3da6b2472a44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*TRoS2QQW15Ue3aOyB8rrhg.png"/></div></figure><figure class="lv jr lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><img src="../Images/2139ec70e4a16c1f5aa970d792de34e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*20vitrHuihLa64wd44cwuQ.png"/></div></figure></div><p id="168c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →随时间训练精度/随时间成本<br/> <strong class="kb ir">右图</strong> →随时间测试精度/随时间成本</p><p id="c637" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">与传统的 ADAM 相比，AMS Grad 被认为在正规化方面做得更好，然而对于这个实验来说，情况并非如此。如下所示，该模型能够达到 88%的准确率，同时在训练图像上具有 96%的准确率。</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi md"><img src="../Images/f3da0dd133a410570c2d41dcdbe8ed1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ghBaEXg0yuYutvB2e3VtXg.png"/></div></div></figure><p id="3f14" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">蓝线</strong> →第 19 个历元的准确率为 88%。</p></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><p id="08d2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果:<em class="kx">案例 d) ConvPool-CNN 带手动回柱</em></strong><a class="ae jy" href="https://medium.com/@SeoJaeDuk/implementation-of-optimization-for-deep-learning-highlights-in-2017-feat-sebastian-ruder-61e2cbe9b7cb" rel="noopener"><strong class="kb ir"><em class="kx">AMSGrad</em></strong></a><strong class="kb ir"><em class="kx">(</em></strong><a class="ae jy" rel="noopener" target="_blank" href="/outperforming-tensorflows-default-auto-differentiation-optimizers-with-interactive-code-manual-e587a82d340e"><strong class="kb ir"><em class="kx">散瞳</em></strong></a><strong class="kb ir"><em class="kx">)</em></strong></p><div class="kz la lb lc gt ab cb"><figure class="lv jr lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><img src="../Images/75ea749fbc2f02e4af2affa8be469ff6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*9r1g3MjxyJBCQBQwg88OqQ.png"/></div></figure><figure class="lv jr lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><img src="../Images/d45d3c17924f95c32dd2111f566b3ef5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*wCVlMFaYmFOXWxd5vnmzrw.png"/></div></figure></div><p id="557c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →随时间训练精度/随时间成本<br/> <strong class="kb ir">右图</strong> →随时间测试精度/随时间成本</p><p id="4c59" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于前馈操作和反向传播的简单膨胀，结果没有显著改善。然而，它能够在第 12 个历元达到 89%的准确率，如下所示。</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div class="gh gi me"><img src="../Images/98ea7df74947dab58de4a4c8bafb8280.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*GPCdmnvY6bPAvr4XXzTjXA.png"/></div></figure></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><p id="9a95" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果:<em class="kx">情况 e)具有自动微分动量的全 CNN</em></strong></p><div class="kz la lb lc gt ab cb"><figure class="lv jr lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><img src="../Images/411106ab064ce14fe5ee96247ae1bf6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*zhx74KqCfu006owUdfoxzQ.png"/></div></figure><figure class="lv jr lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><img src="../Images/fb8111d2055c2392a215e085286e5543.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Lh4UUjtxT84iK9CWs-st9Q.png"/></div></figure></div><p id="05d7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →训练随时间的准确性/随时间的成本<br/> <strong class="kb ir">右图</strong> →测试随时间的准确性/随时间的成本</p><p id="6ffc" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">当我们用步长为 2 的卷积层替换所有池操作时，我们可以看到精度下降了 3%。(在测试图像上)。</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi lr"><img src="../Images/43ddd49ceeb0fe17b2f608313624a355.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ayWK3KBenkPbGnMfB6QAcw.png"/></div></div></figure></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><p id="e6d8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果:<em class="kx">情况 f)具有自动微分的全 CNN Adam</em></strong></p><div class="kz la lb lc gt ab cb"><figure class="lv jr lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><img src="../Images/6d33aebef8b81520e516ad9e3fa07f17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*4-fqUNXbwBlmvvT3-5t27A.png"/></div></figure><figure class="lv jr lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><img src="../Images/96f156405749ca94a39a9f444d92a9c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*OLt9m7R6_uMSlZBHGfewhw.png"/></div></figure></div><p id="62de" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →列车随时间的准确性/随时间的成本<br/> <strong class="kb ir">右图</strong> →测试随时间的准确性/随时间的成本</p><p id="2649" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">即使使用 Adam optimizer，我们也可以观察到，在相同的 epoch 数量下，测试图像的准确性下降了 1 ~ 2%。</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi mf"><img src="../Images/8a8e79a95bb3811ca5a5dd98a941d882.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T9kLzbaWGBy_WutHTf3V1A.png"/></div></div></figure></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><p id="997d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果:<em class="kx">案例 g) All-CNN 带手动回柱</em></strong><a class="ae jy" href="https://medium.com/@SeoJaeDuk/implementation-of-optimization-for-deep-learning-highlights-in-2017-feat-sebastian-ruder-61e2cbe9b7cb" rel="noopener"><strong class="kb ir"><em class="kx">AMSGrad</em></strong></a></p><div class="kz la lb lc gt ab cb"><figure class="lv jr lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><img src="../Images/c0a5b468313959d2adc89e3c3babdf0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*1uDqn45mFHbTzWcKbPuicg.png"/></div></figure><figure class="lv jr lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><img src="../Images/fc89e165d9c8f699411f2a8c8219d905.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*H8xkuHg7kPph0MDN6n7h5Q.png"/></div></figure></div><p id="6ce4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →一段时间内的训练精度/一段时间内的成本<br/> <strong class="kb ir">右图</strong> →一段时间内的测试精度/一段时间内的成本</p><p id="759c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">AMS Grad 的最高准确率约为 85%。在训练图像上具有相似的精度。</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi mg"><img src="../Images/4f4eb244c91d819bba71583ba6dd700c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Z7UnJ4ULK_eeSBMvi0s_A.png"/></div></div></figure></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><p id="8eef" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果:<em class="kx">案例 h) All-CNN 带手动背道具</em></strong><a class="ae jy" href="https://medium.com/@SeoJaeDuk/implementation-of-optimization-for-deep-learning-highlights-in-2017-feat-sebastian-ruder-61e2cbe9b7cb" rel="noopener"><strong class="kb ir"><em class="kx">AMSGrad</em></strong></a><strong class="kb ir"><em class="kx">(</em></strong><a class="ae jy" rel="noopener" target="_blank" href="/outperforming-tensorflows-default-auto-differentiation-optimizers-with-interactive-code-manual-e587a82d340e"><strong class="kb ir"><em class="kx">散瞳</em></strong></a><strong class="kb ir"><em class="kx">)</em></strong></p><div class="kz la lb lc gt ab cb"><figure class="lv jr lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><img src="../Images/5830613ee649f8c0a6f3ae1308d24c44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*kGkBG-qeMDf4ErE4weXb2g.png"/></div></figure><figure class="lv jr lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><img src="../Images/6f7af38f7f1daed8d687a377e34f3cad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*pT17s20S6nFL2rT-pfMoIA.png"/></div></figure></div><p id="ffb1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →随时间训练精度/随时间成本<br/> <strong class="kb ir">右图</strong> →随时间测试精度/随时间成本</p><p id="5a1b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最后，对于扩张反向传播的 AMS Grad，它比任何其他方法都差，只能达到 84%的准确性。</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi mc"><img src="../Images/bbc0bee32ec8f44364de3d9f63b2111b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*St6pqjcz2tuEzzwFOBqp_A.png"/></div></div></figure></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><p id="87a5" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">交互式代码/透明度</strong></p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/acc8d76278e1d23e6d1168e05c2a449f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*yHStxxU4qWdcfgqmIP6K2w.png"/></div></figure><p id="9091" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于谷歌 Colab，你需要一个谷歌帐户来查看代码，而且你不能在谷歌 Colab 中运行只读脚本，所以在你的操场上做一个副本。最后，我永远不会请求允许访问你在 Google Drive 上的文件，仅供参考。编码快乐！同样为了透明，我在训练期间上传了所有的日志。</p><p id="ca54" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">要访问全球平均池<a class="ae jy" href="https://colab.research.google.com/drive/1hL8NTJZfvh0k_UgTKEvOSykxMQ4zOO4r" rel="noopener ugc nofollow" target="_blank">的代码，请单击此处。</a></p><p id="88a1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">要访问<a class="ae jy" href="https://colab.research.google.com/drive/1pHLEKcr6DOCFLoE-04gXGqnDLu_rAkkc" rel="noopener ugc nofollow" target="_blank">案例 a 的代码，请点击此处</a>，要访问<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/AllConvolution/cases/a/casea.txt" rel="noopener ugc nofollow" target="_blank">日志，请点击此处。</a> <br/>访问<a class="ae jy" href="https://colab.research.google.com/drive/1WvrTEXqet7p5vtbQX_9jlDIDPy3hqelP" rel="noopener ugc nofollow" target="_blank">案例 b 的代码请点击此处</a>，访问<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/AllConvolution/cases/b/caseb.txt" rel="noopener ugc nofollow" target="_blank">日志请点击此处。</a> <br/>要访问<a class="ae jy" href="https://colab.research.google.com/drive/1iF5dKDTR2QvZj89PMicu_ww5eeHCnZMs" rel="noopener ugc nofollow" target="_blank">案例 c 的代码，请点击此处</a>，要访问<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/AllConvolution/cases/c/casec.txt" rel="noopener ugc nofollow" target="_blank">日志，请点击此处。</a> <br/>要访问<a class="ae jy" href="https://colab.research.google.com/drive/1kEOVStpGuKNHtzC8XXoDmj2BLrsh1Wac" rel="noopener ugc nofollow" target="_blank">案例 d 的代码，请点击此处</a>，要访问<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/AllConvolution/cases/d/cased.txt" rel="noopener ugc nofollow" target="_blank">日志，请点击此处。</a></p><p id="f210" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">要访问案件 e 的<a class="ae jy" href="https://colab.research.google.com/drive/1qPoKOmN4-pxJx_ukeLmOqF528jFMxpcO" rel="noopener ugc nofollow" target="_blank">代码，请点击这里</a>，要访问<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/AllConvolution/cases/e/casee.txt" rel="noopener ugc nofollow" target="_blank">日志，请点击这里。</a> <br/>访问<a class="ae jy" href="https://colab.research.google.com/drive/10DQkEp4S1ZEA0kBrxVkgmzOlRRHN3lGO" rel="noopener ugc nofollow" target="_blank">案例 f 的代码请点击此处</a>，访问<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/AllConvolution/cases/f/casef.txt" rel="noopener ugc nofollow" target="_blank">日志请点击此处。</a> <br/>要访问<a class="ae jy" href="https://colab.research.google.com/drive/1qPERnFIRH7jO2JS-NuEWBGuUUNc5JUQE" rel="noopener ugc nofollow" target="_blank">案例 g 的代码，请点击此处</a>，要访问<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/AllConvolution/cases/g/caseg.txt" rel="noopener ugc nofollow" target="_blank">日志，请点击此处。</a> <br/>要访问<a class="ae jy" href="https://colab.research.google.com/drive/1hKTZc2lTMnAlIz11IsP-UEW-5dPYWEcB" rel="noopener ugc nofollow" target="_blank">案例 h 的代码，请点击此处</a>，要访问<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/AllConvolution/cases/h/caseh.txt" rel="noopener ugc nofollow" target="_blank">日志，请点击此处。</a></p></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><p id="72a3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">最后的话</strong></p><p id="7b7e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">另外，如果你希望看到这个网络的 keras 实现，请查看这个<a class="ae jy" href="https://medium.com/@matelabs_ai/how-these-researchers-tried-something-unconventional-to-came-out-with-a-smaller-yet-better-image-544327f30e72" rel="noopener">博客帖子。Mate Labs 在解释这个话题方面做得非常出色！)</a></p><p id="a0b7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 给我，如果你想看我所有的写作清单，请在这里查看我的网站。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的 twitter 上关注我<a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>，访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或者我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。我还实现了<a class="ae jy" href="https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec" rel="noopener">广残网，请点击这里查看博文</a> t。</p></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><p id="1e5e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="786f" class="mi mj iq kb b kc kd kg kh kk mk ko ml ks mm kw mn mo mp mq bi translated">斯普林根贝格，j .，多索维茨基，a .，布罗克斯，t .，&amp;里德米勒，M. (2014)。追求简单:全卷积网。Arxiv.org。检索于 2018 年 5 月 11 日，来自<a class="ae jy" href="https://arxiv.org/abs/1412.6806" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1412.6806</a></li><li id="5cdd" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">cy donia 999/all _ 卷积 _net。(2018).GitHub。检索于 2018 年 5 月 11 日，来自<a class="ae jy" href="https://github.com/cydonia999/all_convolutional_net" rel="noopener ugc nofollow" target="_blank">https://github.com/cydonia999/all_convolutional_net</a></li><li id="4bda" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">示例:基础— imgaug 0.2.5 文档。(2018).img aug . readthe docs . io . 2018 年 5 月 11 日检索，来自<a class="ae jy" href="http://imgaug.readthedocs.io/en/latest/source/examples_basics.html" rel="noopener ugc nofollow" target="_blank">http://img aug . readthe docs . io/en/latest/source/examples _ basics . html</a></li><li id="cf76" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">NumPy . ndarray . dtype—NumPy 1.14 版手册。(2018).Docs.scipy.org。检索于 2018 年 5 月 11 日，来自<a class="ae jy" href="https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.ndarray.dtype.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/numpy-1 . 14 . 0/reference/generated/numpy . ndarray . dtype . html</a></li><li id="f734" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">(2018).[在线]可在:<a class="ae jy" href="https://www.quora.com/What-is-global-average-pooling" rel="noopener ugc nofollow" target="_blank">https://www.quora.com/What-is-global-average-pooling</a>[2018 年 5 月 11 日访问]。</li><li id="5f43" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">池层 Keras 文档。(2018).keras . io . 2018 年 5 月 11 日检索，来自<a class="ae jy" href="https://keras.io/layers/pooling/" rel="noopener ugc nofollow" target="_blank">https://keras.io/layers/pooling/</a></li><li id="9934" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">这些研究人员是如何尝试一些非传统的东西来得到一个更小但更好的图像…(2017).中等。检索于 2018 年 5 月 11 日，来自<a class="ae jy" href="https://medium.com/@matelabs_ai/how-these-researchers-tried-something-unconventional-to-came-out-with-a-smaller-yet-better-image-544327f30e72" rel="noopener">https://medium . com/@ mate labs _ ai/how-these-researchers-trying-something-outstanding-to-out-a-small-better-image-544327 f30e 72</a></li><li id="04d9" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">优化器— Keras 文档。(2018).keras . io . 2018 年 5 月 11 日检索，来自<a class="ae jy" href="https://keras.io/optimizers/" rel="noopener ugc nofollow" target="_blank">https://keras.io/optimizers/</a></li><li id="7983" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">库克，A. (2017)。用于对象本地化的全局平均池层。alexisbcook . github . io . 2018 年 5 月 11 日检索，来自<a class="ae jy" href="https://alexisbcook.github.io/2017/global-average-pooling-layers-for-object-localization/" rel="noopener ugc nofollow" target="_blank">https://alexisbcook . github . io/2017/global-average-pooling-layers-for-object-localization/</a></li><li id="8cbd" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">TensorFlow？，H. (2018)。如何在 TensorFlow 中进行全球平均池化？。堆栈溢出。检索于 2018 年 5 月 11 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/42054451/how-do-i-do-global-average-pooling-in-tensorflow" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/42054451/how-do-I-do-global-average-pooling-in-tensor flow</a></li><li id="7b3f" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">Anderson jo/全球平均池。(2018).GitHub。检索于 2018 年 5 月 11 日，来自<a class="ae jy" href="https://github.com/AndersonJo/global-average-pooling/blob/master/global-average-pooling.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/Anderson jo/global-average-pooling/blob/master/global-average-pooling . ipynb</a></li><li id="f722" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">Anderson jo/全球平均池。(2018).GitHub。检索于 2018 年 5 月 11 日，来自<a class="ae jy" href="https://github.com/AndersonJo/global-average-pooling" rel="noopener ugc nofollow" target="_blank">https://github.com/AndersonJo/global-average-pooling</a></li><li id="9962" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">贝嫩森河(2018)。分类数据集结果。rodrigob . github . io . 2018 年 5 月 13 日检索，来自<a class="ae jy" href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130" rel="noopener ugc nofollow" target="_blank">http://rodrigob . github . io/are _ we _ there _ yet/build/classification _ datasets _ results . html # 43494641522d 3130</a></li><li id="1587" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">误差，A. (2018)。避免 tensorflow 打印在标准错误上。堆栈溢出。检索于 2018 年 5 月 19 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/35869137/avoid-tensorflow-print-on-standard-error" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/35869137/avoid-tensor flow-print-on-standard-error</a></li><li id="8b76" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">2017 年深度学习优化实现亮点(feat。塞巴斯蒂安·鲁德)。(2018).中等。检索于 2018 年 5 月 19 日，来自<a class="ae jy" href="https://medium.com/@SeoJaeDuk/implementation-of-optimization-for-deep-learning-highlights-in-2017-feat-sebastian-ruder-61e2cbe9b7cb" rel="noopener">https://medium . com/@ SeoJaeDuk/implementation-of-optimization-for-deep-learning-highlights-in-2017-feat-sebastian-ruder-61e 2 CBE 9 b 7 CB</a></li><li id="7d99" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">超越 Tensorflow 的默认自动微分优化器，具有交互式代码[手动…(2018).走向数据科学。检索于 2018 年 5 月 19 日，来自<a class="ae jy" rel="noopener" target="_blank" href="/outperforming-tensorflows-default-auto-differentiation-optimizers-with-interactive-code-manual-e587a82d340e">https://towards data science . com/outpering-tensor flows-default-auto-difference-optimizer-with-interactive-code-manual-e 587 a82d 340 e</a></li><li id="936e" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">aleju/imgaug。(2018).GitHub。检索于 2018 年 5 月 19 日，来自<a class="ae jy" href="https://github.com/aleju/imgaug" rel="noopener ugc nofollow" target="_blank">https://github.com/aleju/imgaug</a></li><li id="e898" class="mi mj iq kb b kc mr kg ms kk mt ko mu ks mv kw mn mo mp mq bi translated">通过 Numpy 和 Tensorflow 中的示例和交互式代码理解批处理规范化。(2018).走向数据科学。检索于 2018 年 5 月 19 日，来自<a class="ae jy" rel="noopener" target="_blank" href="/understanding-batch-normalization-with-examples-in-numpy-and-tensorflow-with-interactive-code-7f59bb126642">https://towards data science . com/understanding-batch-normalization-with-examples-in-numpy-and-tensor flow-with-interactive-code-7f 59 bb 126642</a></li></ol></div></div>    
</body>
</html>