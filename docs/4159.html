<html>
<head>
<title>What Does A Face Detection Neural Network Look Like?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人脸检测神经网络是什么样子的？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/face-detection-neural-network-structure-257b8f6f85d1?source=collection_archive---------2-----------------------#2018-07-24">https://towardsdatascience.com/face-detection-neural-network-structure-257b8f6f85d1?source=collection_archive---------2-----------------------#2018-07-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="9124" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我的<a class="ae kl" href="https://medium.com/@reina.wang/mtcnn-face-detection-cdcb20448ce0" rel="noopener">上一篇文章</a>中，我探索了多任务级联卷积网络(MTCNN)模型，用它来通过我的网络摄像头检测人脸。在这篇文章中，我将研究神经网络的结构。</p><p id="8175" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">MTCNN 模型由 3 个独立的网络组成:P 网、R 网和 O 网:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/ae3696553b66625025bac3a3bb7a5fb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ICM3jnRB1unY6G5ZRGorfg.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Image 1: MTCNN Structure // <a class="ae kl" href="https://arxiv.org/ftp/arxiv/papers/1604/1604.02878.pdf" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="e8aa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于我们传入的每个图像，网络都会创建一个图像金字塔:也就是说，它会创建该图像的多个不同大小的副本。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lc"><img src="../Images/31e84f0ce9b6c4f6f683d175c6d6ca98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JH-L5EmTqj_fHEcXnzZT5Q.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Image 2: Image Pyramid // <a class="ae kl" href="https://arxiv.org/ftp/arxiv/papers/1604/1604.02878.pdf" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="3727" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在 P-Net 中，对于每个缩放的图像，一个 12×12 的内核在图像中运行，以搜索人脸。在下图中，红色方块代表内核，它缓慢地在图像中上下移动，搜索人脸。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/fc8b3fe0e78d8d0d4199acc6a3da7f57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*r3aAaOV2CWYBJav3uWRP5A.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Image 3: 12x12 kernel in the top right corner. After scanning this corner, it shifts sideways (or downwards) by 1 pixel, and continues doing that until it has gone through the entire image.</figcaption></figure><p id="a8b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这些 12x12 内核的每一个中，3 个卷积与 3x3 内核一起运行(如果你不知道卷积是什么，请查看<a class="ae kl" href="https://medium.com/@reina.wang.tw/what-is-a-neural-network-6010edabde2b" rel="noopener">我的另一篇文章</a>或<a class="ae kl" href="http://setosa.io/ev/image-kernels/" rel="noopener ugc nofollow" target="_blank">本网站</a>)。在每一个卷积层之后，一个预层被执行(当你把每一个负像素乘以一个特定的数字‘alpha’。“α”将通过训练来确定)。此外，maxpool 层放在第一个 prelu 层之后(maxpool 每隔一个像素取出一个像素，只留下附近最大的像素)。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi le"><img src="../Images/51dd02a42f2102e2f65c5f7e47809454.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w49KKbft4Iq3xLsoNy-l-Q.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Image 4: Max-pool // <a class="ae kl" href="https://youtu.be/gbceqO8PpBg" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="b626" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在第三卷积层之后，网络分裂成两层。来自第三层的激活被传递到两个单独的卷积层，以及其中一个卷积层之后的 softmax 层(softmax 为每个结果分配十进制概率，并且概率总计为 1。在这种情况下，它输出两个概率:在该区域中有<strong class="jp ir">是</strong>人脸的概率和有<strong class="jp ir">不是</strong>人脸的概率)。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lf"><img src="../Images/feb58659d64024175dcaf0f84b1cabc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*Ey4E1ZreYY8F_GiXLVCD_Q.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Image 5: P-Net</figcaption></figure><p id="1534" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">卷积 4–1 输出一个面在每个边界框中的概率，卷积 4–2 输出边界框的坐标。</p><p id="67e5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">看一看 mtcnn.py 会给你展示 P-Net 的结构:</p><pre class="kn ko kp kq gt lg lh li lj aw lk bi"><span id="0bd7" class="ll lm iq lh b gy ln lo l lp lq">class PNet(Network):</span><span id="48f2" class="ll lm iq lh b gy lr lo l lp lq">def _config(self):</span><span id="d467" class="ll lm iq lh b gy lr lo l lp lq">layer_factory = LayerFactory(self)</span><span id="284a" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_feed(name='data', layer_shape=(None, None, None, 3))</span><span id="fca4" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_conv(name='conv1', kernel_size=(3, 3), channels_output=10, stride_size=(1, 1),</span><span id="261f" class="ll lm iq lh b gy lr lo l lp lq">padding='VALID', relu=False)</span><span id="5b1e" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_prelu(name='prelu1')</span><span id="2950" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_max_pool(name='pool1', kernel_size=(2, 2), stride_size=(2, 2))</span><span id="3b12" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_conv(name='conv2', kernel_size=(3, 3), channels_output=16, stride_size=(1, 1),</span><span id="d6fe" class="ll lm iq lh b gy lr lo l lp lq">padding='VALID', relu=False)</span><span id="02e3" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_prelu(name='prelu2')</span><span id="5e45" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_conv(name='conv3', kernel_size=(3, 3), channels_output=32, stride_size=(1, 1),</span><span id="63c4" class="ll lm iq lh b gy lr lo l lp lq">padding='VALID', relu=False)</span><span id="19fb" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_prelu(name='prelu3')</span><span id="53e1" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_conv(name='conv4-1', kernel_size=(1, 1), channels_output=2, stride_size=(1, 1), relu=False)</span><span id="8dcc" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_softmax(name='prob1', axis=3)</span><span id="279b" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_conv(name='conv4-2', kernel_size=(1, 1), channels_output=4, stride_size=(1, 1),</span><span id="62bc" class="ll lm iq lh b gy lr lo l lp lq">input_layer_name='prelu3', relu=False)</span></pre><p id="60d8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">R-Net 具有类似的结构，但是具有更多的层。它以 P-网包围盒作为其输入，并改进其坐标。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/636a9498c67d7718689ca3107f766c39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*5KNvVDQHpsquv5yinnTDWw.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Image 6: R-Net</figcaption></figure><p id="9dda" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">类似地，R-Net 最终分成两层，给出两个输出:新边界框的坐标和机器对每个边界框的置信度。同样，mtcnn.py 包括 R-Net 的结构:</p><pre class="kn ko kp kq gt lg lh li lj aw lk bi"><span id="9757" class="ll lm iq lh b gy ln lo l lp lq">class RNet(Network):</span><span id="f1e5" class="ll lm iq lh b gy lr lo l lp lq">def _config(self):</span><span id="8bca" class="ll lm iq lh b gy lr lo l lp lq">layer_factory = LayerFactory(self)</span><span id="8b94" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_feed(name='data', layer_shape=(None, 24, 24, 3))</span><span id="226d" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_conv(name='conv1', kernel_size=(3, 3), channels_output=28, stride_size=(1, 1),</span><span id="25c6" class="ll lm iq lh b gy lr lo l lp lq">padding='VALID', relu=False)</span><span id="db12" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_prelu(name='prelu1')</span><span id="86e4" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_max_pool(name='pool1', kernel_size=(3, 3), stride_size=(2, 2))</span><span id="051a" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_conv(name='conv2', kernel_size=(3, 3), channels_output=48, stride_size=(1, 1),</span><span id="ae55" class="ll lm iq lh b gy lr lo l lp lq">padding='VALID', relu=False)</span><span id="3891" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_prelu(name='prelu2')</span><span id="f011" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_max_pool(name='pool2', kernel_size=(3, 3), stride_size=(2, 2), padding='VALID')</span><span id="72f8" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_conv(name='conv3', kernel_size=(2, 2), channels_output=64, stride_size=(1, 1),</span><span id="6c03" class="ll lm iq lh b gy lr lo l lp lq">padding='VALID', relu=False)</span><span id="1eba" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_prelu(name='prelu3')</span><span id="d6e9" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_fully_connected(name='fc1', output_count=128, relu=False)  </span><span id="8df0" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_prelu(name='prelu4')</span><span id="b36d" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_fully_connected(name='fc2-1', output_count=2, relu=False)  </span><span id="19b7" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_softmax(name='prob1', axis=1)</span><span id="0b9c" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_fully_connected(name='fc2-2', output_count=4, relu=False, input_layer_name='prelu4')</span></pre><p id="95c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，O-Net 将 R-Net 包围盒作为输入，并记下面部标志的坐标。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/062e2c8885a5a055c8a16a2082eb4070.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*BT6XlTxVjqaNSj87iDFjcg.png"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/5d4c5ad28f1ce6c150be3ee53974348b.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*eBiydaqk2HU36P0LcUbGzA.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Image 7: O-Net</figcaption></figure><p id="7348" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">O-Net 最终分成 3 层，给出 3 种不同的输出:人脸在框中的概率、边界框的坐标和面部标志的坐标(眼睛、鼻子和嘴的位置)。以下是 O-Net 的代码:</p><pre class="kn ko kp kq gt lg lh li lj aw lk bi"><span id="8ad6" class="ll lm iq lh b gy ln lo l lp lq">class ONet(Network):</span><span id="62ea" class="ll lm iq lh b gy lr lo l lp lq">def _config(self):</span><span id="4665" class="ll lm iq lh b gy lr lo l lp lq">layer_factory = LayerFactory(self)</span><span id="0fa0" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_feed(name='data', layer_shape=(None, 48, 48, 3))</span><span id="239e" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_conv(name='conv1', kernel_size=(3, 3), channels_output=32, stride_size=(1, 1),</span><span id="546c" class="ll lm iq lh b gy lr lo l lp lq">padding='VALID', relu=False)</span><span id="c56f" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_prelu(name='prelu1')</span><span id="57c2" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_max_pool(name='pool1', kernel_size=(3, 3), stride_size=(2, 2))</span><span id="fa37" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_conv(name='conv2', kernel_size=(3, 3), channels_output=64, stride_size=(1, 1),</span><span id="71a8" class="ll lm iq lh b gy lr lo l lp lq">padding='VALID', relu=False)</span><span id="8760" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_prelu(name='prelu2')</span><span id="d40f" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_max_pool(name='pool2', kernel_size=(3, 3), stride_size=(2, 2), padding='VALID')</span><span id="99b1" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_conv(name='conv3', kernel_size=(3, 3), channels_output=64, stride_size=(1, 1),</span><span id="6c62" class="ll lm iq lh b gy lr lo l lp lq">padding='VALID', relu=False)</span><span id="4728" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_prelu(name='prelu3')</span><span id="486d" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_max_pool(name='pool3', kernel_size=(2, 2), stride_size=(2, 2))</span><span id="fea8" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_conv(name='conv4', kernel_size=(2, 2), channels_output=128, stride_size=(1, 1),</span><span id="756a" class="ll lm iq lh b gy lr lo l lp lq">padding='VALID', relu=False)</span><span id="c9be" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_prelu(name='prelu4')</span><span id="4072" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_fully_connected(name='fc1', output_count=256, relu=False)</span><span id="d8d0" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_prelu(name='prelu5')</span><span id="af98" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_fully_connected(name='fc2-1', output_count=2, relu=False)</span><span id="36e2" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_softmax(name='prob1', axis=1)</span><span id="01a9" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_fully_connected(name='fc2-2', output_count=4, relu=False, input_layer_name='prelu5')</span><span id="6c3e" class="ll lm iq lh b gy lr lo l lp lq">layer_factory.new_fully_connected(name='fc2-3', output_count=10, relu=False, input_layer_name='prelu5')</span></pre><p id="a0d5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意，P-Net、R-Net 和 O-Net 的所有代码都导入了一个名为“LayerFactory”的类。本质上，LayerFactory 是一个类，由该模型的制作者创建，用于生成具有特定设置的层。有关更多信息，您可以查看 layer_factory.py。</p></div><div class="ab cl lv lw hu lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="ij ik il im in"><p id="aaee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">点击<a class="ae kl" href="https://medium.com/@reina.wang/mtcnn-face-detection-cdcb20448ce0" rel="noopener">此处</a>阅读实现 MTCNN 模型！</p><p id="cbf4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">点击<a class="ae kl" href="https://medium.com/@reina.wang/how-does-a-face-detection-program-work-using-neural-networks-17896df8e6ff" rel="noopener">此处</a>阅读 MTCNN 模式如何运作！</p></div><div class="ab cl lv lw hu lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="ij ik il im in"><p id="6af6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">点击此处下载 MTCNN 论文和资源:</p><p id="3ae2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Github 下载:【https://github.com/ipazc/mtcnn T4】</p><p id="34ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">研究文章:<a class="ae kl" href="http://arxiv.org/abs/1604.02878" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/1604.02878</a></p></div></div>    
</body>
</html>