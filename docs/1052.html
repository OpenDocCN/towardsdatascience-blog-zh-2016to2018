<html>
<head>
<title>ConvNets Series. Image Processing: Tools of the Trade</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ConvNets 系列。图像处理:行业工具</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convnets-series-image-processing-tools-of-the-trade-36e168836f0c?source=collection_archive---------2-----------------------#2017-07-24">https://towardsdatascience.com/convnets-series-image-processing-tools-of-the-trade-36e168836f0c?source=collection_archive---------2-----------------------#2017-07-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="265a" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">简介和系列发布</h1><p id="4f0b" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我越是研究<a class="ae lj" href="https://www.udacity.com/drive" rel="noopener ugc nofollow" target="_blank"> Udacity 的自动驾驶汽车项目</a>，卷积神经网络(ConvNets)这个话题对我来说似乎就越重要。原因很简单:在过去的几年里，在计算机视觉和机器人领域，convnets 已经变得无处不在。测绘，图像分类，分割，无人机和自动驾驶汽车的运动规划——许多处理图像(或图像序列)的问题都可以通过 convnets 高效解决。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lk"><img src="../Images/bae8fd7feda2a5af20b86870cd3a1cef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CktNrxlduNAHYBAbdWcE2Q.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">MultiNet as an example of a convolutional network (three in one, actually). We are going to use it in one of next posts. Source: <a class="ae lj" href="https://arxiv.org/pdf/1612.07695.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1612.07695.pdf</a></figcaption></figure><p id="cb86" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">我想，你对神经网络的工作原理有很强的直觉。有大量关于这个主题的博客文章、课程和书籍，所以我不想重复:</p><ul class=""><li id="4f9a" class="mf mg iq kn b ko ma ks mb kw mh la mi le mj li mk ml mm mn bi translated"><a class="ae lj" href="http://www.deeplearningbook.org/contents/mlp.html" rel="noopener ugc nofollow" target="_blank">第六章:深度前馈网络</a>——摘自 I.Goodfellow，Y.Bengio，A.Courville 所著的《深度学习》一书，强烈推荐。</li><li id="e82f" class="mf mg iq kn b ko mo ks mp kw mq la mr le ms li mk ml mm mn bi translated"><a class="ae lj" href="http://cs231n.github.io/" rel="noopener ugc nofollow" target="_blank">用于视觉识别的 CS231n 卷积神经网络</a> —费-李非和安德烈·卡帕西教授的著名斯坦福课程。动手和面向工程。卓越的课程材料质量。</li><li id="2574" class="mf mg iq kn b ko mo ks mp kw mq la mr le ms li mk ml mm mn bi translated"><a class="ae lj" href="https://youtu.be/PlhFWT7vAEw" rel="noopener ugc nofollow" target="_blank">深度学习</a>——南多·德·弗雷塔斯的牛津课程。</li><li id="f730" class="mf mg iq kn b ko mo ks mp kw mq la mr le ms li mk ml mm mn bi translated"><a class="ae lj" href="https://www.udacity.com/course/intro-to-machine-learning--ud120" rel="noopener ugc nofollow" target="_blank">机器学习简介</a>—uda city 的免费课程。一个非常温和和广泛的介绍 ML 的初学者。</li></ul><p id="e204" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">只有一个建议:为了确保你理解了神经网络的基础知识，<a class="ae lj" href="http://playground.tensorflow.org/" rel="noopener ugc nofollow" target="_blank">用它们</a>和<a class="ae lj" href="http://cs231n.github.io/neural-networks-case-study/" rel="noopener ugc nofollow" target="_blank">构建一个</a>！</p><p id="1fb5" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">本系列没有重复基础知识，而是专注于<strong class="kn ir">特定的神经网络架构</strong> : STN(空间转换器网络)、IDSIA(用于交通标志分类的卷积网络)、NVIDIA 用于端到端自动驾驶的网络、用于道路和交通标志检测和分类的 MultiNet。我们开始吧！</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><p id="3530" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated"><strong class="kn ir">本帖的主题是图像预处理</strong>。Convnets 不能被提供“任何”手边的数据，也不能被视为“自动”提取有用特征的黑匣子。预处理不好或没有预处理会使即使是顶尖的卷积网络也无法收敛或得分很低。因此，强烈建议所有网络进行图像预处理和增强(如果有的话)。在这篇文章中，我们为以后在神经网络中使用和重用打下了基础。</p><h1 id="2e65" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">工具 1。通过可视化进行数据发现</h1><p id="cc52" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在这篇和下一篇文章中，我们将使用 gt SRB——一个<a class="ae lj" href="http://benchmark.ini.rub.de/?section=gtsrb&amp;subsection=dataset" rel="noopener ugc nofollow" target="_blank">德国交通标志识别基准数据集</a>。我们的任务是使用来自 GTSRB 数据集的标记数据来训练交通标志分类器。一般来说，当你有一个数据集时，最好的习惯方法是从中抽取数据样本，并建立一个训练、验证和/或测试集的数据分布直方图。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi na"><img src="../Images/3192c6b556b0d28f10215908e58a984b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*MzNNAtRFWSQ68lr3VeJFSw.gif"/></div></div></figure><p id="856c" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">GTSRB 数据集的基本统计如下:</p><pre class="ll lm ln lo gt nb nc nd ne aw nf bi"><span id="74eb" class="ng jo iq nc b gy nh ni l nj nk">Number of training examples = 34799</span><span id="4e53" class="ng jo iq nc b gy nl ni l nj nk">Number of validation examples = 4410</span><span id="d832" class="ng jo iq nc b gy nl ni l nj nk">Number of testing examples = 12630</span><span id="1a55" class="ng jo iq nc b gy nl ni l nj nk">Image data shape = (32, 32, 3)</span><span id="40da" class="ng jo iq nc b gy nl ni l nj nk">Number of classes = 43</span></pre><p id="c777" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">在这个阶段，<code class="fe nm nn no nc b">matplotlib</code>是你最好的朋友。虽然你可以单独用<code class="fe nm nn no nc b">pyplot</code>构建良好的可视化效果，但是你可以用<code class="fe nm nn no nc b">matplotlib.gridspec.</code>将几个图表合并成一个</p><p id="355c" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">例如，您可以用这种方式初始化一个包含三个子图的空图表:</p><pre class="ll lm ln lo gt nb nc nd ne aw nf bi"><span id="7f05" class="ng jo iq nc b gy nh ni l nj nk">gs = gridspec.GridSpec(1, 3, wspace=0.25, hspace=0.1)<br/>fig = plt.figure(figsize=(12,2))<br/>ax1, ax2, ax3 = [plt.subplot(gs[:, i]) for i in range(3)]</span></pre><p id="5c1d" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">Gridspec 是高度可定制的。例如，你可以像我在图表中所做的那样，为每个子情节设置不同的宽度。gridspec 中的轴可以被视为独立的图表，允许您创建非常复杂的绘图。</p><p id="f4d0" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">然后，一个单独的图表可以说明你的数据。这里有三个任务可以通过良好的绘图来解决:</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi na"><img src="../Images/ce4493d303b20ae832ddccde5d2d8df3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iVECqG2rYsaAZaY6PFJnpA.png"/></div></div></figure><ul class=""><li id="bd4e" class="mf mg iq kn b ko ma ks mb kw mh la mi le mj li mk ml mm mn bi translated"><strong class="kn ir">样本图像可视化</strong>:我们马上会看到很多太暗或太亮的图像。光照变化应该(也将会)得到解决:这是一种数据标准化。</li><li id="498a" class="mf mg iq kn b ko mo ks mp kw mq la mr le ms li mk ml mm mn bi translated"><strong class="kn ir">检查类别不平衡</strong>:如果类别极度不平衡，您可能需要在批处理生成器中使用<a class="ae lj" href="http://www.chioka.in/class-imbalance-problem/" rel="noopener ugc nofollow" target="_blank">过采样或欠采样方法</a>。</li><li id="78ee" class="mf mg iq kn b ko mo ks mp kw mq la mr le ms li mk ml mm mn bi translated">比较训练、验证和测试组上的<strong class="kn ir">数据分布是相似的。这可以通过查看上面的直方图来验证，但是您也可以使用<a class="ae lj" href="https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient" rel="noopener ugc nofollow" target="_blank"> Spearman 等级相关性</a>(通过<code class="fe nm nn no nc b">scipy</code>)。</strong></li></ul><h1 id="c5be" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">工具 2。scikit-image 的 IPython 并行</h1><p id="e804" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了帮助网络融合，我们需要均衡图像的亮度，并(如<a class="ae lj" href="http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf" rel="noopener ugc nofollow" target="_blank"> LeCun 关于交通标志识别的论文</a>中所建议的)将它们转换成灰度。这可以使用 OpenCV 来完成，但是 Python 的工具箱包含了一个很棒的<a class="ae lj" href="http://scikit-image.org/" rel="noopener ugc nofollow" target="_blank"> scikit-image </a> ( <code class="fe nm nn no nc b">skimage</code>)库，可以通过 pip 轻松安装(与自己编译 OpenCV 形成对比)。关键的见解是使用基于内核的<a class="ae lj" href="https://en.wikipedia.org/wiki/Adaptive_histogram_equalization#Contrast_Limited_AHE" rel="noopener ugc nofollow" target="_blank"> CLAHE </a>(对比度受限的自适应直方图归一化)方法来归一化图像的直方图:<code class="fe nm nn no nc b">skimage.exposure.equalize_adapthist</code>。</p><p id="49ba" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated"><code class="fe nm nn no nc b">skimage</code>逐个处理图像并利用单个 cpu 核心，这显然是低效的。为了并行化图像预处理，我们使用了<a class="ae lj" href="https://ipyparallel.readthedocs.io/en/latest/intro.html" rel="noopener ugc nofollow" target="_blank"> IPython 并行</a> ( <code class="fe nm nn no nc b">ipyparallel</code>)包。<code class="fe nm nn no nc b">ipyparallel</code>的好处之一是它的简单性:并行运行 CLAHE 只需要几行代码。首先，从您的 shell 启动一个控制器和引擎(假设您已经安装了<code class="fe nm nn no nc b">ipyparallel</code>):</p><pre class="ll lm ln lo gt nb nc nd ne aw nf bi"><span id="c5d4" class="ng jo iq nc b gy nh ni l nj nk">$ ipcluster start</span></pre><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi np"><img src="../Images/d1deb4f69b8e92b31931f0791cb60976.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ffglwIq-HBmMjxwRHXfKow.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">One of the benefits of ipyparallel is its client interface which abstracts communication with engines, task scheduling, etc. Running parallel map is just trivial.</figcaption></figure><p id="3272" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">我们的并行化方法是最简单的:我们将数据集分成几批，并独立处理每一批。当所有的批次被处理后，我们将它们合并成一个单独的数据集。我的 CLAHE 批处理例程如下:</p><figure class="ll lm ln lo gt lp"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="d668" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">现在，转换函数已经准备好了，我们可以实现一段代码，将该函数应用于批量数据:</p><figure class="ll lm ln lo gt lp"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="ee24" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">现在我们可以运行它了:</p><pre class="ll lm ln lo gt nb nc nd ne aw nf bi"><span id="5645" class="ng jo iq nc b gy nh ni l nj nk"># X_train: numpy array of (34799, 32, 32, 3) shape<br/># y_train: a list of (34799,) shape</span><span id="28e7" class="ng jo iq nc b gy nl ni l nj nk">X_tr, y_tr = preprocess_equalize(X_train, y_train, bins=128)</span></pre><p id="d906" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">现在，我们确实利用了系统的所有 cpu 内核(在我的例子中是 32 个),并获得了显著的性能提升。以下是预处理的示例结果:</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi ns"><img src="../Images/77d8a6ef1d01e3ba54ea26fae17700c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NOcFhbrvnTDxiQAt9pR3yw.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Grayscale and equalize the histogram</figcaption></figure><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi ns"><img src="../Images/1d5b9d3e05ede531bf06bacf75e1c957.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l09OLCxqBGGXlKn4bAHhJg.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Histogram equalization for RGB image (I used a different function for rc[:].map)</figcaption></figure><p id="820e" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">由于整个预处理管道现在只需要几十秒钟就可以运行，我们可以测试不同的<code class="fe nm nn no nc b">num_bins</code>值来了解这个论点:</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nt"><img src="../Images/86f43f32d93e8e4dcb7f7b077e652975.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O1EKABXcbJFoyL-NQhbugA.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">num_bins: 8, 32, 128, 256, 512</figcaption></figure><p id="240c" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">较大的<code class="fe nm nn no nc b">num_bins</code>值确实增加了图像的对比度，但也过度突出了背景，增加了图像的噪声。不同的箱也可以用于<strong class="kn ir">对比度增强</strong>，因为我们需要防止对背景特征的过度拟合。</p><p id="ba11" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">最后，我们可以利用 IPython 的<code class="fe nm nn no nc b">%store</code> <a class="ae lj" href="https://ipython.org/ipython-doc/3/config/extensions/storemagic.html" rel="noopener ugc nofollow" target="_blank">魔法</a>来快速序列化我们的数据集以供进一步使用:</p><pre class="ll lm ln lo gt nb nc nd ne aw nf bi"><span id="c307" class="ng jo iq nc b gy nh ni l nj nk"># Same images, multiple bins (contrast augmentation)<br/>%store X_tr_8<br/>%store y_tr_8<br/># ...<br/>%store X_tr_512<br/>%store y_tr_512</span></pre><h1 id="27e0" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">工具 3。在线数据扩充</h1><p id="a582" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">众所周知，增加更多的数据可以提高神经网络的泛化能力。在我们的例子中，我们可以通过使用旋转、翻转和仿射变换来变换我们所拥有的(数据扩充)来构建人工图像。虽然我们可以对整个数据集运行一次这个过程，保存结果并在以后使用它，但更好的方法是动态(在线)构建新图像，以便能够快速修改和迭代数据扩充的参数。</p><p id="4ac8" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">首先，让我们列出我们的转换。我们用<code class="fe nm nn no nc b">numpy</code>和<code class="fe nm nn no nc b">skimage</code>:</p><figure class="ll lm ln lo gt lp"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="6a3e" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">仿射变换增加数据集，同时保持图像标签不变。相反，旋转和翻转可以将一个交通标志转换成另一个。为了处理这个问题，我们可以为每个交通标志和它将被转换成的类别列出一个可用的转换列表:</p><figure class="ll lm ln lo gt lp"><div class="bz fp l di"><div class="nq nr l"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">A part of <a class="ae lj" href="https://gist.github.com/dnkirill/8aab1c5dbe0471795cdf93729a572d49" rel="noopener ugc nofollow" target="_blank">the whole transformation table</a>. Values are class numbers (as in label_class) an image will take after transformation. Empty cell means that transformation is not available for that label.</figcaption></figure><p id="32e9" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">请注意，上表中的转换名称与我们之前介绍的函数名称相匹配。这样做是为了动态添加更多的转换:</p><figure class="ll lm ln lo gt lp"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="f269" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">接下来，我们构建一个管道，将<code class="fe nm nn no nc b">augmentation_table.csv</code>中列出的所有可用函数应用于所有类:</p><figure class="ll lm ln lo gt lp"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="81c1" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">很好。现在我们有两个数据集扩充例程:</p><ul class=""><li id="8336" class="mf mg iq kn b ko ma ks mb kw mh la mi le mj li mk ml mm mn bi translated"><code class="fe nm nn no nc b">affine_transform</code>:没有旋转组件的可定制的剪切和缩放变换(不是很一致，因为旋转是仿射变换的一部分)。</li><li id="5ef3" class="mf mg iq kn b ko mo ks mp kw mq la mr le ms li mk ml mm mn bi translated"><code class="fe nm nn no nc b">flips_rotations_augmentation</code>:基于随机旋转和增强 _table.csv 的图像变换，可以改变图像标签。</li></ul><p id="662e" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">最后一步是将它们合并到一个增强的批处理生成器中:</p><figure class="ll lm ln lo gt lp"><div class="bz fp l di"><div class="nq nr l"/></div></figure><p id="e0f9" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">当我们从这个批处理生成器采样时，我们得到了我们所需要的，对比度和位置数据增强:</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nu"><img src="../Images/2c19689a6c0432b1132541f4f7c70df9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*FgwxrEmn6iWZLsr832WtLA.gif"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Generated images via augmented_batch_generator</figcaption></figure><p id="df4c" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated"><strong class="kn ir">注:</strong>强化只在训练时需要。我们做预处理，但不增加验证或测试集。</p><p id="2d4b" class="pw-post-body-paragraph kl km iq kn b ko ma kq kr ks mb ku kv kw mc ky kz la md lc ld le me lg lh li ij bi translated">之后，一个好主意可能是检查该批处理生成器中批处理的数据分布是否仍然合理(要么与原始数据相似，要么是专门针对过采样设计的)。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nv"><img src="../Images/6abd6a30e69bacb8b9b6f20b407f028d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*7J9ZKX3RfsYTbuf-A6ULig.gif"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Left: data distribution from augmented batch generator. Right: original train. As we see, values differ, but distributions are similar.</figcaption></figure><h1 id="3a2b" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">向神经网络迈进</h1><p id="edc5" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在完成数据预处理、批处理生成器设置和数据集分析后，我们可以继续训练。我们将使用双卷积网络:STN(空间转换器网络)获取一批图像，专注于交通标志，去除背景，IDSIA 网络从 STN 提供的图像中识别交通标志。下一篇文章将专门讨论这些网络、培训、性能分析和演示。敬请期待，下期帖子再见！</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi nw"><img src="../Images/8f89a578469ee9ffc84a88a12ee2590a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZDCTd01flVoxQnMuJ8kMGg.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Left: original preprocessed image. Right: STN-transformed image which is fed to IDSIA network for classification.</figcaption></figure></div></div>    
</body>
</html>