<html>
<head>
<title>Training MXNet — part 4: distributed training</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">培训MXNet第4部分:分布式培训</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-mxnet-part-4-distributed-training-91def5ea3bb7?source=collection_archive---------6-----------------------#2017-05-05">https://towardsdatascience.com/training-mxnet-part-4-distributed-training-91def5ea3bb7?source=collection_archive---------6-----------------------#2017-05-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="1a5f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<a class="ae kl" href="https://medium.com/@julsimon/training-mxnet-part-3-cifar-10-redux-ecab17346aa0" rel="noopener">第3部分</a>中，我们使用了<a class="ae kl" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR-10 </a>数据集，并学习了如何调整优化参数。我们最终使用一个<a class="ae kl" href="https://aws.amazon.com/blogs/aws/new-g2-instance-type-with-4x-more-gpu-power/" rel="noopener ugc nofollow" target="_blank"> g2.8xlarge </a>实例的所有4个GPU训练了一个110层的ResNext模型……这花了大约12个小时。</p><p id="dd69" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我将向您展示如何使用多个实例来显著加快训练速度。系好安全带。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/ae0444b2fd5fa2c5d6dddd840eecfc67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d5beAIGIAj-xco2_E1jq8Q.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Training CIFAR-10 on 4 instances and 32 GPUs. Read on!</figcaption></figure><h2 id="372f" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">创建主节点</h2><p id="522f" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">我们将使用运行<strong class="jp ir">深度学习AMI </strong>、<a class="ae kl" href="https://aws.amazon.com/about-aws/whats-new/2017/04/deep-learning-ami-for-ubuntu-v-1-3-apr-2017-now-supports-caffe2/" rel="noopener ugc nofollow" target="_blank"> Ubuntu edition </a>的<a class="ae kl" href="https://aws.amazon.com/blogs/aws/new-p2-instance-type-for-amazon-ec2-up-to-16-gpus/" rel="noopener ugc nofollow" target="_blank"> p2.8xlarge </a>实例。然而，您可以很容易地用任何类型的EC2实例或者甚至在您办公桌下运行的一堆PC上复制这一点:)</p><p id="98da" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们开始吧。我们将按照我们喜欢的方式配置主节点，然后我们将<strong class="jp ir">克隆</strong>它以向我们的MXNet集群添加更多实例。第一步是转到EC2控制台的市场部分，找到深度学习AMI。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ma"><img src="../Images/970a0042bb4ce6fc4977821037fcc0ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uJwv3Lm9f2S2-xiMsn0A5A.png"/></div></div></figure><p id="11b8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，选择您想要使用的实例类型。请注意实例成本:一个p2.8xlarge每小时的成本是7.20美元。不要担心，您实际上可以使用任何实例类型，因为MXNet能够使用实例的CPU或GPU。很明显，GPU实例会比t2.micros快很多:)</p><p id="eb72" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">再点击几下就完成了。只需确保<strong class="jp ir"> SSH端口</strong>是打开的，并且您已经为实例创建了一个新的<strong class="jp ir">密钥对</strong>(姑且称之为<em class="mb"> ec2 </em>)。几分钟后，您可以使用<em class="mb"> ubuntu </em>用户(不是<em class="mb"> ec2-user </em>)进入主节点。</p><h2 id="dbff" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">在MXNET中启用分布式培训</h2><p id="4dde" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">默认情况下，在源代码发行版中没有启用分布式培训，这意味着我们可能必须从源代码中重新构建MXNet。如果您的构建已经包括分布式培训，您可以跳过这一部分。</p><p id="f41d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">深度学习AMI包括MXNet源代码:我们只需将它们变成我们自己的，并刷新到最新的稳定版本(<strong class="jp ir"> 0.9.5 </strong>在撰写本文时)。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="3bc7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我们需要配置我们的<strong class="jp ir">构建选项</strong>。最后一个实际上实现了分布式训练。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="f129" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们可以构建和安装库了。不需要添加依赖项，因为它们已经包含在AMI中了。我在32个内核上运行并行make，因为这是p2.8xlarge所拥有的。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="fc44" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦安装了这个库，运行一个快速的Python检查是一个好主意。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi me"><img src="../Images/f41f570d6307b59a831ba9fc44b87c30.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*X5pp1OEKVYcIjV678m6mkg.png"/></div></figure><p id="c53b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好的，这个看起来不错。我们继续吧。</p><h2 id="26e8" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">为分布式培训打开端口</h2><p id="2c26" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">主节点和工作节点需要相互通信以共享<strong class="jp ir">数据集</strong>以及<strong class="jp ir">训练结果</strong>。因此，我们需要改变我们的安全组的配置来允许这样做。</p><p id="8e0a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">做到这一点最简单的方法是允许MXNet集群实例之间的<strong class="jp ir">所有TCP </strong>通信，即使用<strong class="jp ir">相同安全组</strong>的实例。</p><p id="e624" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为此，请转到EC2控制台，编辑主节点的安全组的入站规则。添加一条规则，允许<strong class="jp ir">所有TCP流量</strong>，并使用安全组的实际名称<strong class="jp ir">限制</strong>源流量。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi mf"><img src="../Images/7ea683cda09a0a357ec7ad78dcc577b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T3qQeoMpVSTBP4Z0gAXlgQ.png"/></div></div></figure><p id="f55c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的实例现在已经准备好了。让我们创建工作节点。</p><h2 id="e817" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">创建工作节点</h2><p id="bcd9" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">我们将基于主节点创建一个<strong class="jp ir">新AMI </strong>。然后，我们用它来发动工人。在EC2控制台中找到您的实例并创建一个映像。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi mg"><img src="../Images/4d8628dd50d86c95847573a258d2d685.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tgE58qRXMUAab-Jzypl5_w.png"/></div></div></figure><p id="65a2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">几分钟后，您将在EC2控制台的“Images”部分看到新的AMI。您现在可以使用它来启动您的工作节点。</p><p id="b440" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里没有什么复杂的:选择您想要启动的<strong class="jp ir">实例类型</strong>、实例的<strong class="jp ir">数量</strong>(在我的例子中是3个)和与主节点相同的安全组<strong class="jp ir">。</strong></p><p id="848b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">再过几分钟，您的实例就准备好了。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi mh"><img src="../Images/c766819c5ec753fc1fd4af7c4201d7f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gisH2Q96WSZKOdbmnC5kHA.png"/></div></div></figure><p id="dc4d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">很可爱。记下每个实例的私有IP地址，我们马上会用到它们。</p><h2 id="1568" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">配置集群</h2><p id="cdde" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">让我们登录到主节点，移动到<em class="mb">工具</em>目录并查看启动器。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/1d3a0e5db5232d80d61143eb36147467.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*d7cgot72NFlDKhGtGcqXlA.png"/></div></figure><p id="1386" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是我们将用来在所有节点(包括主节点)上开始训练的工具。它做两件事:</p><ul class=""><li id="4415" class="mj mk iq jp b jq jr ju jv jy ml kc mm kg mn kk mo mp mq mr bi translated">使用rsync，<strong class="jp ir">在每个节点上复制<em class="mb"> /tmp/mxnet </em>中的数据集</strong>。或者，我们可以通过与自制的NFS或亚马逊EFS共享节点上的数据集来避免这种情况。</li><li id="7318" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated">使用ssh，<strong class="jp ir">运行开始训练的python脚本</strong>。如您所见，其他协议也是可用的，但我们今天不讨论它们。</li></ul><h2 id="e50b" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">创建主机文件</h2><p id="e440" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated"><em class="mb"> launch.py </em>需要在一个文件中声明所有节点(包括主节点)的私有IP地址。它应该看起来像这样。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/3358ef0f5b00852e9d7d33a04d638f99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*Z-QWGfoYwkBEc-aiIcRZ9w.png"/></div></figure><h2 id="25c8" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">配置SSH</h2><p id="9860" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">我们需要主节点和工作节点之间的无密码ssh访问。如果您已经准备好了，可以跳过这一部分。</p><p id="d3e2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了简单起见，我们将在本地计算机上创建一个新的密钥对，并在集群中分发它。</p><blockquote class="my mz na"><p id="1bc1" class="jn jo mb jp b jq jr js jt ju jv jw jx nb jz ka kb nc kd ke kf nd kh ki kj kk ij bi translated"><strong class="jp ir">请</strong>不要重复使用<em class="iq"> ec2 </em>密钥对，这是不好的做法。另外，有些人可能想在AMI中烘焙密钥对，以避免将它分发给所有实例，但是我建议不要这样做，因为这意味着将私钥存储在所有节点上，而不仅仅是主节点上。还有<a class="ae kl" href="https://heipei.github.io/2015/02/26/SSH-Agent-Forwarding-considered-harmful/" rel="noopener ugc nofollow" target="_blank">宋承宪代理转发也不好</a>。</p></blockquote><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="4383" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，还是从我们的本地计算机，我们将把<strong class="jp ir">公钥</strong>复制到所有节点(包括主节点),只把<strong class="jp ir">私钥</strong>复制到主节点。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="46a3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，在主节点上，我们将启动<em class="mb"> ssh-agent </em>并添加<em class="mb"> mxnet </em>身份。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="03ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，您应该能够从主节点登录到每个工作节点(包括主节点本身)。在继续之前，请确保此功能正常工作。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="8f38" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果是的话，你已经准备好训练了，伙计:)</p><h2 id="7a67" class="lc ld iq bd le lf lg dn lh li lj dp lk jy ll lm ln kc lo lp lq kg lr ls lt lu bi translated">开展分布式培训</h2><p id="034f" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">下面是这个神奇的命令:<em class="mb"> hosts </em>文件中列出的4个节点将通过<em class="mb"> rsync </em>接收一份<em class="mb"> /tmp/mxnet </em>中数据集的副本。然后，主节点将在每个节点上运行<em class="mb"> train_cifar10.py </em>脚本，在所有8个GPU上训练一个110层的ResNext模型。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mc md l"/></div></figure><blockquote class="my mz na"><p id="cdf1" class="jn jo mb jp b jq jr js jt ju jv jw jx nb jz ka kb nc kd ke kf nd kh ki kj kk ij bi translated">如果您运行在CPU实例上，只需删除GPU参数。</p></blockquote><p id="b200" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">PS_VERBOSE变量将输出额外的信息。万一出了问题，非常有用；)</p><p id="ac07" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以通过登录不同的节点并运行'<em class="mb"> nvidia-smi -l </em>'命令来检查进度。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/ae0444b2fd5fa2c5d6dddd840eecfc67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d5beAIGIAj-xco2_E1jq8Q.png"/></div></div></figure><p id="dd61" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">那么这有多快呢？正如我之前提到的，在一个g2.8xlarge实例的4个GPU上运行300个epochs需要大约12个小时。4个p2.8xlarge实例的32个GPU加起来用了<strong class="jp ir"> 91分钟！</strong></p><p id="a1f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一个<strong class="jp ir">8倍的加速</strong>，这是有道理的，因为我们有<strong class="jp ir">8倍多的GPU</strong>。我曾经读到过，现在我亲眼看到了:<strong class="jp ir">确实是线性缩放</strong>！这让我想把它推到256个GPU:毕竟它只需要16个p 2.16大:D</p><p id="6c8d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后但同样重要的是，我的同事Naveen Swamy和Joseph Spisak写了一篇非常有趣的<a class="ae kl" href="https://aws.amazon.com/blogs/compute/distributed-deep-learning-made-easy/" rel="noopener ugc nofollow" target="_blank">博文</a>，讲述了如何使用AWS CloudFormation自动完成大部分工作。如果你在AWS中运行所有的东西，这绝对值得一读。</p><p id="30ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">今天到此为止。非常感谢你的阅读和最近给我的友好支持。这对我意义重大！</p></div><div class="ab cl ne nf hu ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="ij ik il im in"><p id="5a81" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来:</p><p id="dad0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://medium.com/@julsimon/training-mxnet-part-5-distributed-training-efs-edition-1c2a13cd5460" rel="noopener">第5部分——分布式培训，EFS版</a></p></div></div>    
</body>
</html>