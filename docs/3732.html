<html>
<head>
<title>Zig-Zag // Dual-Stream Recurrent Neural Network, Twin Neural Network with Interactive Code. [ Manual Back Prop with TF ]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Zig-Zag //双流递归神经网络，具有交互式代码的双神经网络。[带 TF 的手动后撑]</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/zig-zag-dual-stream-recurrent-neural-network-twin-neural-network-with-interactive-code-b5c0a58b7f92?source=collection_archive---------9-----------------------#2018-06-12">https://towardsdatascience.com/zig-zag-dual-stream-recurrent-neural-network-twin-neural-network-with-interactive-code-b5c0a58b7f92?source=collection_archive---------9-----------------------#2018-06-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/36f3a4f910ca4ea83df120246c2de7ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*JBxmO_LQtcQMXDe6EDsVmQ.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">GIF from this <a class="ae jy" href="https://giphy.com/gifs/motionaddicts-inspiration-idea-spark-26BkNrGhy4DKnbD9u" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="ff9e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我从来没有双胞胎兄弟，但如果我有一个，这将是非常酷的。我们会有不同的想法，但彼此非常相似。这让我思考，这个概念是否也可以应用于神经网络？我想弄清楚。和往常一样，下面是我想为这篇文章实现的不同架构的列表。</p><p id="b5cb" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><em class="kx">案例 a:双流递归神经网络<br/>案例 b:双流之字形递归神经网络<br/>案例 c:双流混合递归神经网络<br/>案例 d:非孪生(标准)神经网络<br/>案例 e:孪生神经网络</em></p><blockquote class="ky kz la"><p id="d381" class="jz ka kx kb b kc kd ke kf kg kh ki kj lb kl km kn lc kp kq kr ld kt ku kv kw ij bi translated"><strong class="kb ir">请注意，这篇帖子只是为了娱乐，也是为了表达我的创意。因此不是面向结果的。</strong></p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="080d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">多流递归神经网络</strong></p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/76d453e61f0335684a3b8a81c99fc447.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*VDbUsAkprpevRiFHnusGRA.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image from this <a class="ae jy" href="https://arxiv.org/abs/1704.01194" rel="noopener ugc nofollow" target="_blank">paper</a></figcaption></figure><p id="647d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在写这篇文章时，我找到了几篇关于多流递归神经网络架构的论文。我想总的想法是，我们可以有两个(或三个)网络，而不是一个<a class="ae jy" href="https://en.wikipedia.org/wiki/Long_short-term_memory" rel="noopener ugc nofollow" target="_blank">长短期记忆</a> (LSTM)或<a class="ae jy" href="https://en.wikipedia.org/wiki/Recurrent_neural_network" rel="noopener ugc nofollow" target="_blank">循环神经网络</a> (RNN)。下面是我在写这篇文章时发现的论文列表。</p><ol class=""><li id="150e" class="lq lr iq kb b kc kd kg kh kk ls ko lt ks lu kw lv lw lx ly bi translated"><a class="ae jy" href="https://arxiv.org/abs/1704.01194" rel="noopener ugc nofollow" target="_blank">双流 LSTM:人体动作识别的深度融合框架</a></li><li id="5bbf" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated"><a class="ae jy" href="https://arxiv.org/abs/1702.03402" rel="noopener ugc nofollow" target="_blank">用于多流分类的并行长短期记忆</a></li><li id="91a5" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated"><a class="ae jy" href="https://www.isca-speech.org/archive/interspeech_2015/papers/i15_1413.pdf" rel="noopener ugc nofollow" target="_blank">多流长短期记忆神经网络语言模型</a></li></ol><p id="0b37" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在我想介绍一下我们将在本帖中使用的基础网络架构。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi me"><img src="../Images/44984d27f063183f2ff941a8b2b9e956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k1YW92V7rP9qceRpa_fSCg.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Case a: Dual RNN</figcaption></figure><p id="9865" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">红色方块，黑色方块</strong> →流 1 RNN，流 2 RNN <br/> <strong class="kb ir">粉色箭头</strong> →隐藏状态，每个时间戳都被保留<br/> <strong class="kb ir">绿色、粉色、黑色、蓝色箭头</strong> →输入时间戳 0，1，2，3 <br/> <strong class="kb ir">蓝色矩形，箭头</strong> →最终串接输出每个 RNN <br/> <strong class="kb ir">黑色矩形</strong> →卷积层(基于<a class="ae jy" rel="noopener" target="_blank" href="/iclr-2015-striving-for-simplicity-the-all-convolutional-net-with-interactive-code-manual-b4976e206760"> <em class="kx">所有卷积)</em></a></p><p id="c357" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我真的希望三维图形有助于每个人的理解。(挺烂的 lol)。但主要思想是在卷积神经网络之前有某种多流 RNN，基本上就是这样。最后，我想提一下，对于不同的时间戳，我们要么向网络提供原始图像，要么提供增强图像。(我们将使用<a class="ae jy" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR 10 </a>数据集)</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="05f9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">之字形递归神经网络</strong></p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi mj"><img src="../Images/9ee220f4536a4830eb2378da15d97bfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aBNLjdZSuZyd8s5bS9QhvA.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Case b: Dual Zig Zag RNN</figcaption></figure><p id="3033" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">白色、灰色箭头</strong> →改变隐藏状态的方向</p><p id="db0b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在让我们引入一些不同的东西，就像上面看到的，而不是使用来自同一个流的前一个时间戳的隐藏状态。我们将改变所使用的隐藏状态的方向。(因此得名 zig zag。).与两个独立的 RNN 电视网相比，我希望每个电视网都能学会如何相互合作，以获得更好的性能。</p><p id="63bb" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最后，让我们看一下网络结构，其中我们结合了之字形结构以及直线前馈操作。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi mk"><img src="../Images/5843580cd41375dd498ae046de0cbaef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eDU87LzP_k-iIWdm0FjJDQ.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Case c: Dual Mix RNN</figcaption></figure><p id="a184" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，这一次我们将结合 zig zag 结构以及原始的递归神经网络结构。(在从 2 时间戳到 3 时间戳的转换期间，我们将让网络使用它们自己的隐藏状态。)</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="82e4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果:案例 a:双流递归神经网络</strong></p><div class="lm ln lo lp gt ab cb"><figure class="ml jr mm mn mo mp mq paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><img src="../Images/8bd72e10a8cac54de7e514bd3874e26d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*I2SK9y-Vwv-gXn-WQHvx-w.png"/></div></figure><figure class="ml jr mm mn mo mp mq paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><img src="../Images/b8abd61bca1ddde2f2a70fc9f5b8c4af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*eK0Y6nvk07s6xiRBXC2DaA.png"/></div></figure></div><p id="7053" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →测试集精度/时间成本<br/> <strong class="kb ir">右图</strong> →训练集精度/时间成本</p><p id="7799" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">马上，我们可以注意到，这种类型的架构不适合图像分类任务。在训练结束时，我们只能达到 71%的训练图像准确率，而 64%的测试图像准确率。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi mr"><img src="../Images/5f730805563457551f0135c8ae0e04e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WN4KrArUPHN3dFtn6uUQlQ.png"/></div></div></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="5e30" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果:案例 b:双流之字形递归神经网络</strong></p><div class="lm ln lo lp gt ab cb"><figure class="ml jr mm mn mo mp mq paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><img src="../Images/7073c86b6dd5f0213a73b8b4263fc180.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*fb1rUUR9kq1eh4zM4k-UdA.png"/></div></figure><figure class="ml jr mm mn mo mp mq paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><img src="../Images/041d1844bc1af8391d96016bad267c0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*cf1-DnskVipBIv1OnnHe8g.png"/></div></figure></div><p id="bda0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →测试集精度/时间成本<br/> <strong class="kb ir">右图</strong> →训练集精度/时间成本</p><p id="61ea" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我真的不知道对这个网络有什么期望，但它似乎与原来的网络没有明显的区别。以相似的(在测试图像上更差)准确度完成训练。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi ms"><img src="../Images/20e51367c2ccae08abd0f23913635558.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gMWWup2Pqa7KT3c8gimvMg.png"/></div></div></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="6840" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果:案例 c:双流混合递归神经网络</strong></p><div class="lm ln lo lp gt ab cb"><figure class="ml jr mm mn mo mp mq paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><img src="../Images/009a12f027567ddb3bf0a25309e8b908.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*tg5SeWtzGfe-LfMbXCLTKg.png"/></div></figure><figure class="ml jr mm mn mo mp mq paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><img src="../Images/f84bac4b30e0db5cc8270151044eea39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*hxJbxGN5Khb2c1_hC4EfaQ.png"/></div></figure></div><p id="d455" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →测试集精度/时间成本<br/> <strong class="kb ir">右图</strong> →训练集精度/时间成本</p><p id="6ba8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最终类型的网络给出了相似的结果。然而，它能够胜过原来的网络以及 zig zag 网络。(按 0.003)。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi mt"><img src="../Images/60e745bce056f44e3b5c4a2467832bc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fTLhVXRPKMRJBdsAWngh3g.png"/></div></div></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="cef3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">孪生神经网络</strong></p><div class="lm ln lo lp gt ab cb"><figure class="ml jr mu mn mo mp mq paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><img src="../Images/b4252ede3cd5dcad84fb4208bd844420.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*2z_9lMgPtHgUk1CUuFeOSw.png"/></div></figure><figure class="ml jr mv mn mo mp mq paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><img src="../Images/8f1f01f8aa949b866b73046cc1b2e085.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*-UJeJJuh68RpL_A8OTsPTw.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk mw di mx my">Case d: Non Twin network</figcaption></figure></div><p id="ac5c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">黑框</strong> →卷积层<br/> <strong class="kb ir">粉色箭头</strong> →前馈运算<br/> <strong class="kb ir">黄色框</strong> →全局平均池和 Softmax</p><p id="d50c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在看一下 Twin 网络之前，让我们先看看我们的基本网络。如上所述，我们的基本网络只是从<a class="ae jy" rel="noopener" target="_blank" href="/iclr-2015-striving-for-simplicity-the-all-convolutional-net-with-interactive-code-manual-b4976e206760">全卷积网络</a>的扩展，在末端增加了一个卷积层。(使总层数为 10。)现在让我们来看看 Twin Network 的架构。</p><div class="lm ln lo lp gt ab cb"><figure class="ml jr mz mn mo mp mq paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><img src="../Images/cc8ffe82f48216ee230b2f330cb1e9cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*41Xbl7AhjdjCF8-2TN7Hyw.png"/></div></figure><figure class="ml jr na mn mo mp mq paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><img src="../Images/6005039f0af6e3a7c7a9da5531d1113f.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*thLVS1vG60pHRbbWj3iTRw.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk nb di nc my">Case e: Twin Network</figcaption></figure></div><p id="aacd" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">黑盒</strong> →孪生 1 的卷积层<br/> <strong class="kb ir">红盒→ </strong>孪生 2 的卷积层<br/> <strong class="kb ir">粉色箭头</strong> →前馈操作<br/>→绿色箭头 →级联和前馈操作<br/> <strong class="kb ir">弯曲箭头</strong> →前馈操作<br/> <strong class="kb ir">黄色框</strong> →全局平均池和 Softmax</p><p id="7a81" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，与原始网络没有太大区别，但我们可以观察到的主要区别是，现在不是用一个 10 层网络来完成所有工作。我们有两个相互交织的较小的网络。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="c335" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果:案例 d:非孪生(标准)神经网络</strong></p><div class="lm ln lo lp gt ab cb"><figure class="ml jr mm mn mo mp mq paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><img src="../Images/8143d9fa04fe2aa70369da95b209f785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*6_KYMQX8p3KifopIRdIPpw.png"/></div></figure><figure class="ml jr mm mn mo mp mq paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><img src="../Images/2bcc2f84d6eedaf4ae515c37d6682c5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*jQu9YHyFGZHJuyIArk5DVw.png"/></div></figure></div><p id="fa55" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →测试集精度/时间成本<br/> <strong class="kb ir">右图</strong> →训练集精度/时间成本</p><p id="aec7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">很明显，网络正遭受过度拟合，我们可以通过测试集精度以及训练集精度来观察这一点。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nd"><img src="../Images/6a11ab22249cc738f663916e8ef84a0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qEBDbpuNGcte-1U2XYX-xw.png"/></div></div></figure><p id="e036" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，我们能够在测试集图像上实现 82%的准确率，但我们需要考虑到训练图像的准确率已经超过 95%的事实。(96%)</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="d464" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果:案例 e:双神经网络</strong></p><div class="lm ln lo lp gt ab cb"><figure class="ml jr mm mn mo mp mq paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><img src="../Images/2aae476f62395e0b1b386f12024ab2c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*tBZ-UBAjHl-Z1ix1WuIwIw.png"/></div></figure><figure class="ml jr mm mn mo mp mq paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><img src="../Images/c5a9d4d84cccc69e6627308ffd7986a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*-lQF_JLchzEWpSG4kiDnlw.png"/></div></figure></div><p id="ad6d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →测试集精度/时间成本<br/> <strong class="kb ir">右图</strong> →训练集精度/时间成本</p><p id="0d46" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">与标准的 10 层神经网络相比，这是一个明显的优势。然而，该模型仍然存在过度拟合的问题。有了更好的正则化技术，就有可能克服这个问题。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi ne"><img src="../Images/1336d12fcb3035e30e74167d4b252211.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*za9C_B4bJGxcig_QwcBFYg.png"/></div></div></figure><p id="613a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，我们能够在测试图像上实现相同的准确性，同时在训练图像上实现 89%的准确性。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="ed8f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">互动代码</strong></p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nf"><img src="../Images/f3923fb57853de5626b50599170bfb0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1yYYViKxFKberVBE1l3B2w.png"/></div></div></figure><p id="d8fc" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><em class="kx">对于谷歌 Colab，你需要一个谷歌帐户来查看代码，而且你不能在谷歌 Colab 中运行只读脚本，所以在你的操场上做一个副本。最后，我永远不会请求允许访问你在 Google Drive 上的文件，仅供参考。编码快乐！同样为了透明，我在 github 上上传了所有的训练日志。</em></p><p id="88a1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">要访问案例<a class="ae jy" href="https://colab.research.google.com/drive/1_LtQihIqYN0LTo9sFi0vMPUKFWi16pHI" rel="noopener ugc nofollow" target="_blank">的代码，请点击此处</a>，要查看<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/ZigZag_Twin/a/a.txt" rel="noopener ugc nofollow" target="_blank">日志，请点击此处。</a> <br/>访问案例<a class="ae jy" href="https://colab.research.google.com/drive/1RpSE8qdiUZVyYhSmKVV96Xnk7G8yVB3F" rel="noopener ugc nofollow" target="_blank"> b 的代码点击此处</a>，查看<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/ZigZag_Twin/b/b.txt" rel="noopener ugc nofollow" target="_blank">日志点击此处。<br/> </a>要访问案例<a class="ae jy" href="https://colab.research.google.com/drive/1riDsWP_z3Kz3S0VLITf4cmG3zApYTIkK" rel="noopener ugc nofollow" target="_blank"> c 的代码，单击此处</a>，要查看<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/ZigZag_Twin/c/c.txt" rel="noopener ugc nofollow" target="_blank">日志，单击此处。</a> <br/>要访问案例<a class="ae jy" href="https://colab.research.google.com/drive/1-p8BIloIjBTFjBX8qFeInYVthdJLOfcQ" rel="noopener ugc nofollow" target="_blank"> d 的代码，请单击她的</a> e，要查看<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/ZigZag_Twin/d/c.txt" rel="noopener ugc nofollow" target="_blank">日志，请单击此处。</a> <br/>要访问案例<a class="ae jy" href="https://colab.research.google.com/drive/1ItODQ1vVL0vaY6q7YfKXOdi2s9Sgegdg" rel="noopener ugc nofollow" target="_blank"> e 的代码，请点击此处</a>，要查看<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/ZigZag_Twin/e/e.txt" rel="noopener ugc nofollow" target="_blank">日志，请点击此处。</a></p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="744f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">最后的话</strong></p><p id="bb42" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我更喜欢不同网络相互协作的想法。在发这个帖子的时候，我反复地听“<a class="ae jy" href="https://www.youtube.com/watch?v=3hK6IgvZ0CY" rel="noopener ugc nofollow" target="_blank"> <em class="kx">我的火焰——鲍比·考德威尔</em> </a>”。我只是想推荐给大家。</p><figure class="lm ln lo lp gt jr"><div class="bz fp l di"><div class="ng nh l"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Video from <a class="ae jy" href="https://www.youtube.com/channel/UCn_Td6IQrkcsfhC0ehBgFQQ" rel="noopener ugc nofollow" target="_blank">RUMnWINE</a></figcaption></figure><p id="3cda" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 给我，如果你想看我所有写作的列表，请在这里查看我的网站。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的 twitter 上关注我<a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>，访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或者我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。我还实现了<a class="ae jy" href="https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec" rel="noopener">广残网，请点击这里查看博文</a> t。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="1caa" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="79d2" class="lq lr iq kb b kc kd kg kh kk ls ko lt ks lu kw lv lw lx ly bi translated">Matplotlib 样式库。(2018).tonysyu . github . io . 2018 年 6 月 11 日检索，来自<a class="ae jy" href="https://tonysyu.github.io/raw_content/matplotlib-style-gallery/gallery.html" rel="noopener ugc nofollow" target="_blank">https://tonysyu . github . io/raw _ content/matplotlib-style-gallery/gallery . html</a></li><li id="fb4f" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated">Matplotlib:有格调的美好剧情。(2016).Futurile.net。检索于 2018 年 6 月 11 日，来自<a class="ae jy" href="http://www.futurile.net/2016/02/27/matplotlib-beautiful-plots-with-style/" rel="noopener ugc nofollow" target="_blank">http://www . futurile . net/2016/02/27/matplotlib-beautiful-plots-with-style/</a></li><li id="b594" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated">我的爱人——鲍比·考德威尔。(2018).YouTube。检索于 2018 年 6 月 11 日，来自<a class="ae jy" href="https://www.youtube.com/watch?v=3hK6IgvZ0CY" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=3hK6IgvZ0CY</a></li><li id="03e5" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated">NumPy . dtype—NumPy 1.14 版手册。(2018).Docs.scipy.org。检索于 2018 年 6 月 11 日，来自<a class="ae jy" href="https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.dtype.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/numpy-1 . 14 . 0/reference/generated/numpy . dtype . html</a></li><li id="af6e" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated">为什么 range(开始，e. (2018)。为什么 range(start，end)不包括 end？。堆栈溢出。检索于 2018 年 6 月 11 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/4504662/why-does-rangestart-end-not-include-end" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/4504662/why-does-rangestart-end-not-include-end</a></li><li id="4888" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated">数组，I. (2018)。将元素插入 numpy 数组。堆栈溢出。检索于 2018 年 6 月 11 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/21761256/insert-element-into-numpy-array" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/21761256/insert-element-into-numpy-array</a></li><li id="b9b4" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated">NumPy . insert—NumPy 1.14 版手册。(2018).Docs.scipy.org。检索于 2018 年 6 月 11 日，来自<a class="ae jy" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.insert.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/numpy/reference/generated/numpy . insert . html</a></li><li id="7e08" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated">[副本]，第(2018)页。阻止 TensorFlow 访问 GPU？。堆栈溢出。检索于 2018 年 6 月 11 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/44552585/prevent-tensorflow-from-accessing-the-gpu" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/44552585/prevent-tensor flow-from-access-the-GPU</a></li><li id="6378" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated">Gammulle，h .，Denman，s .，Sridharan，s .，&amp; Fookes，C. (2017 年)。双流 LSTM:人体动作识别的深度融合框架。Arxiv.org。检索于 2018 年 6 月 11 日，来自 https://arxiv.org/abs/1704.01194<a class="ae jy" href="https://arxiv.org/abs/1704.01194" rel="noopener ugc nofollow" target="_blank"/></li><li id="67cd" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated">长短期记忆。(2018).En.wikipedia.org。检索于 2018 年 6 月 11 日，来自 https://en.wikipedia.org/wiki/Long_short-term_memory<a class="ae jy" href="https://en.wikipedia.org/wiki/Long_short-term_memory" rel="noopener ugc nofollow" target="_blank"/></li><li id="b6ac" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated">递归神经网络。(2018).En.wikipedia.org。检索于 2018 年 6 月 11 日，来自<a class="ae jy" href="https://en.wikipedia.org/wiki/Recurrent_neural_network" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Recurrent_neural_network</a></li><li id="ea7f" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated">[ ICLR 2015 ]追求简单:具有交互码的全卷积网。(2018).走向数据科学。检索于 2018 年 6 月 11 日，来自<a class="ae jy" rel="noopener" target="_blank" href="/iclr-2015-striving-for-simplicity-the-all-convolutional-net-with-interactive-code-manual-b4976e206760">https://towardsdatascience . com/iclr-2015-努力简化-所有卷积网-交互式代码-手册-b4976e206760 </a></li><li id="79b9" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated">(2018).Isca-speech.org。检索于 2018 年 6 月 11 日，来自<a class="ae jy" href="https://www.isca-speech.org/archive/interspeech_2015/papers/i15_1413.pdf" rel="noopener ugc nofollow" target="_blank">https://www . isca-speech . org/archive/inter seech _ 2015/papers/i15 _ 1413 . pdf</a></li><li id="fc87" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated">m .布阿齐兹、m .莫奇德、r .杜福尔、利纳尔：s，g .，&amp; De Mori，R. (2017 年)。用于多流分类的并行长短期记忆。Arxiv.org。检索于 2018 年 6 月 11 日，来自<a class="ae jy" href="https://arxiv.org/abs/1702.03402" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1702.03402</a></li><li id="4115" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated">CIFAR-10 和 CIFAR-100 数据集。(2018).Cs.toronto.edu。检索于 2018 年 6 月 12 日，来自<a class="ae jy" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank">https://www.cs.toronto.edu/~kriz/cifar.html</a></li><li id="e9a4" class="lq lr iq kb b kc lz kg ma kk mb ko mc ks md kw lv lw lx ly bi translated">dmlc/xgboost。(2018).GitHub。检索于 2018 年 6 月 12 日，来自<a class="ae jy" href="https://github.com/dmlc/xgboost" rel="noopener ugc nofollow" target="_blank">https://github.com/dmlc/xgboost</a></li></ol></div></div>    
</body>
</html>