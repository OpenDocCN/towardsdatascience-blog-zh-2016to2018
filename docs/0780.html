<html>
<head>
<title>Generative Adversarial Networks- History and Overview</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成性对抗网络——历史与综述</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generative-adversarial-networks-history-and-overview-7effbb713545?source=collection_archive---------1-----------------------#2017-06-21">https://towardsdatascience.com/generative-adversarial-networks-history-and-overview-7effbb713545?source=collection_archive---------1-----------------------#2017-06-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="98e5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最近，生成模型越来越受欢迎。特别是，由Ian Goodfellow等人引入的一个相对较新的模型，称为生成对抗网络或GANs，显示出产生现实样本的前景。这篇博文分为两部分。第1部分包括对GANs的介绍，它背后的历史，以及它的各种应用。第2部分包括生成图像样本的GANs实现(带代码)。</p><h1 id="e769" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">第1部分-了解GANs</h1><h2 id="a2dd" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated">生成建模</h2><p id="adaa" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">让我们先来看看什么是生成模型，以及它与判别模型有什么不同。假设你有输入数据<em class="ma"> x </em>，以及相应的输出标签<em class="ma"> y </em>。判别模型试图直接学习条件概率分布<em class="ma"> P(y|x) </em>。另一方面，生成模型试图学习联合概率分布<em class="ma"> P(x，y) </em>。这可以用贝叶斯法则转化为<em class="ma"> P(y|x) </em>。然而，另外，与判别模型相反，生成模型可以使用联合分布<em class="ma"> P(x，y) </em>来生成可能的<em class="ma"> (x，y) </em>样本。</p><h2 id="d592" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated">炒作都是为了什么？</h2><p id="76f5" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">那么，为什么有人想要研究生成模型呢？有人可能想知道简单地生成更多数据有什么大不了的，尤其是因为已经有如此丰富的数据可用。但实际上，这可以有多种用途。例如，可以将一些以特定笔迹书写的文本输入到生成模型中，以生成更多相同笔迹的文本。生成模型，尤其是GANs，也可以用于强化学习的探索中，其中它们可以用于生成人工环境。其他应用包括草图到图像的转换、图像去噪、低分辨率图像到高分辨率的转换、艺术的生成以及卫星图像到地图的转换等等。除了广泛的应用之外，当大部分标签缺失时，生成模型特别有用，因为它们能够执行半监督学习。</p><h2 id="6db9" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated">多年来的生成模型</h2><p id="5270" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">既然我们已经奠定了什么是生成式建模以及它们为什么有用的基础，那么让我们来看看生成式建模中的各种方法。出于比较模型的目的，它们都可以被描述为执行最大似然。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/2bc271ea71ed6ff6696d8b6c1a302b2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*otb47mG5KQWNh91prmyxzg.png"/></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">Taxonomy of Generative Models (from Ian Goodfellow’s NIPS tutorial, 2016)</figcaption></figure><p id="ed42" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上图描绘了Ian Goodfellow在他的NIPS教程中描述的各种族的生成模型。现在让我们来看看上面提到的模型家族中一些流行方法的优缺点。</p><h2 id="d387" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated">完全可见的信念网络</h2><p id="b761" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">他们使用概率链规则将向量上的概率分布分解成向量中每个成员的乘积。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/55a90255979e2bac6dc09f4353bfe5c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*EEOWOQSAOams58A4gMfjkQ.png"/></div></figure><p id="b784" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这家最受欢迎的型号是PixelCNN。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mo"><img src="../Images/f9be036dff0bfacef08e022907907123.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vioNjVcI6vpplIuvTLWyQg.jpeg"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">Images generated by PixelCNN (van den Ord et al 2016)</figcaption></figure><p id="ff04" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">FVBNs最大的缺点是生成样本的速度非常慢。每次您想要生成新的样本时，您都必须再次运行该模型。这不能同时进行。</p><h2 id="f722" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated">基于变量变化的模型(非线性ICA)</h2><p id="0f7b" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">这种模型从简单的高斯分布开始，并使用非线性函数将分布转换到另一个空间。这样做的主要缺点是转换需要被设计成可逆的，并且潜在变量必须与数据具有相同的维数。所以如果你想生成5000个像素，你需要有5000个潜变量。</p><h2 id="15a1" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated">变分自动编码器</h2><p id="1d2f" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">变分自动编码器的工作方式是从密度函数<em class="ma"> log p(x) </em>中边缘化随机变量<em class="ma"> z </em>。由于这是难以处理的，它使用了变分近似。该模型希望最大化数据对数似然的下限。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/e780a6aa2b96cb7b796a791da656e890.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*Eg_zDuOlOvpS5yuOtFcC4Q.jpeg"/></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">Images of celebrity-like faces generated by a VAE (By Alec Radford)</figcaption></figure><p id="ff47" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里的主要缺点是，如果分布<em class="ma"> q </em>是完美的，那么模型是渐近一致的。否则，数据的下限和实际密度之间会有差距。另一个缺点是生成的样本质量相对较低。</p><h2 id="7772" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated">玻尔兹曼机器</h2><p id="3550" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">玻尔兹曼机可以由一个能量函数来定义，而一个特定状态的概率，正比于每个能量的值。为了将其转换为实际的概率分布，通过将总和除以不同的状态来进行重正化。这个总和是难以处理的，这需要使用蒙特卡罗方法进行近似。缺点是这些方法，尤其是马尔可夫链蒙特卡罗方法，在高维空间表现不好。因此，尽管它们可能在像<a class="ae mu" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST </a>这样的图像上表现良好，但你不会在来自<a class="ae mu" href="http://image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>的图像上获得类似的性能。</p><h2 id="dfdb" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated">生成对抗网络</h2><p id="ba11" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">既然我们已经讨论了其他流行的生成模型，我们可以看看GANs，以及它们与其他模型的比较。</p><p id="88db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">gan旨在克服上述模型中陈述的许多缺点。与完全可见的信念网络相反，GANs使用潜在的代码，并且可以并行生成样本。与变分自动编码器不同，gan是渐近一致的。此外，GANs不需要马尔可夫链，这是相对于玻尔兹曼机器的一个优势。最后，GANs通常被高度评价为产生最好的样本，尽管这是非常主观的，并且目前是一个争论的话题，有像PixelCNN这样的模型与之竞争。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/6236c66b318b4f5cdc3d8e89976fde08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*_d22i5gAB8UWL68EnjXQwA.png"/></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">Images generated by GAN using the Toronto Face Database (Ian Goodfellow et al 2014)</figcaption></figure><h2 id="fd3a" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated">GANs如何工作</h2><p id="2255" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">既然我们已经确定了为什么gan值得研究，让我们更深入地研究它们到底是如何工作的。</p><p id="c6ca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">GANs背后的主要思想可以解释为两个玩家之间的博弈——生成器和鉴别器。生成器尝试生成与训练数据遵循相同基础分布的样本。鉴别器试图区分由生成器生成的样本(假数据)和来自训练集的实际数据。生成器的目标是通过近似基本分布来欺骗鉴别器，以便生成与实际数据无法区分的样本。另一方面，鉴别器的目标是从真实数据中识别假数据。鉴别器的任务只是一个二进制分类问题，它决定数据是真是假。这个游戏的一个常见类比是伪造者和警察。伪造者就像发电机一样，试图伪造货币，并尽可能使其看起来合法，以便愚弄警察。警察就像鉴别者，其目标是能够识别出被伪造的货币。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mw"><img src="../Images/e68287644bce9ad131005440ec7c0173.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KF-XzsW2F44sCxlgdDy_9w.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">GAN overview</figcaption></figure><p id="5dd3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">生成器是一个可微分函数<em class="ma"> G </em>，它具有可以通过梯度下降学习的参数。对<em class="ma"> G </em>的输入是通过对潜在变量的一些先验分布中的潜在向量<em class="ma"> z </em>进行采样而获得的。所以本质上，<em class="ma"> z </em>是非结构化噪声的矢量。<em class="ma"> G </em>应用于z，以从模型中获得样本<em class="ma"> x </em>，该样本在理想情况下应类似于来自列车组的实际数据。像发生器一样，鉴别器也是一个可微分函数<em class="ma"> D </em>，它具有可以通过梯度下降学习的参数。函数<em class="ma"> D </em>在应用于从<em class="ma"> G(z) </em>获得的样本<em class="ma"> x </em>时，理想情况下应该输出一个接近于零的值，表示该样本是假的。当数据中的一个实际样本被输入到<em class="ma"> D </em>时，它应该输出一个接近1的值。</p><p id="2bd2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">说𝞱 <em class="ma"> (D) </em>和𝞱 <em class="ma"> (G) </em>分别是<em class="ma"> D </em>和<em class="ma"> G </em>的参数。鉴别器想要最小化它的成本<em class="ma">j(d)(</em>𝞱<em class="ma">(d)</em>,𝞱<em class="ma">(g)</em>，但是对𝞱 <em class="ma"> (G) </em>没有控制，而生成器想要最小化<em class="ma">j(g)(</em>𝞱<em class="ma">(d)</em>𝞱<em class="ma">(g)</em>而对𝞱 <em class="ma"> (D) </em>没有控制。所以我们想要找到<em class="ma">(</em>𝞱<em class="ma">(d)</em>,𝞱<em class="ma">(g)</em>的纳什均衡值，使得<em class="ma"> J(D) </em>相对于𝞱 <em class="ma"> (D) </em>最小，<em class="ma"> J(G) </em>相对于𝞱 <em class="ma"> (G) </em>最小。</p><p id="70ea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">那么训练实际上是如何进行的呢？训练程序是<br/>选择一个优化算法，比如Adam，并将其同时应用于两个小批数据，一个来自实际训练数据，另一个来自<em class="ma"> G </em>生成的样本。此外，你可以更新一个球员比其他球员更频繁。</p><h2 id="afa2" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated">发电机和鉴别器成本</h2><p id="a999" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">算法进行的方式取决于每个玩家的成本。指定成本的最简单方法是使用最小最大博弈，其中发生器成本是鉴别器成本的负数。那么鉴别器想要最大化，而生成器想要最小化的成本到底是多少呢？它只是鉴别器输出和实际标签(真/假)之间的标准交叉熵函数。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mx"><img src="../Images/b702c932244200d362f91823b38b2b9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fqbu2D0jvv5es9lx98iF7A.png"/></div></div></figure><p id="8153" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">J(D)中的第一项表示将实际数据提供给鉴别器，鉴别器希望最大化预测的对数概率，表明数据是真实的。第二项表示g生成的样本。在这里，鉴别器会希望最大化预测零的对数概率，这表明数据是假的。另一方面，生成器试图最小化鉴别器正确的对数概率。这个问题的解是博弈的一个均衡点，这个均衡点是鉴别器损失的一个鞍点。</p><p id="ba2b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个极大极小游戏的主要问题是，当鉴别器变得越来越聪明时，生成器的梯度就消失了。解决这个问题的一个方法是翻转交叉熵函数中参数的顺序，而不是简单地翻转鉴别器成本的符号。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi my"><img src="../Images/bddaeddc391a6aee3660d5ff0cc1109c.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*BmABwFGxU70CITe909PmjA.png"/></div></figure><p id="d3d9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">生成器现在想要最大化鉴别器出错的对数概率。现在，这种均衡不能用一个单一的价值函数来描述，这种特殊成本的动机更具启发性。</p><h2 id="bb46" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated">结垢甘斯</h2><p id="5ca8" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">最初的GANs本身并不能很好地扩展到大型应用程序。为了克服这一点，Radfort等人引入了深度卷积GAN架构。虽然最初，GANs已经是深度和卷积的，但DCGANs强调有更多的卷积层，并额外使用诸如批量标准化的技术。除了生成器的最后一层之外，对每一层都应用批量标准化，以便使学习过程更加稳定。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mz"><img src="../Images/efc66c0b8596f9e4641e69169d07a933.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wm4IDdMOigfTEXNXjFKuBw.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">DCGAN Architecture (Radford et al 2015)</figcaption></figure><h2 id="56fd" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated">更多应用</h2><p id="7c99" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">GANs在人工智能世界掀起了一场风暴，这不是神话，他们确实会留下来。在结束本节之前，我们先来看看GANs今天的一些迷人应用。</p><p id="4e7a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一个流行的应用是使用超分辨率技术从低分辨率图像生成高分辨率图像。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi na"><img src="../Images/6cd8144c4bb52025c09d063ae94cfdde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rkSvwXsWcJ2Aqu6gAMskTA.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">SRGAN used to obtain high resolution images. The original HR image is first downsampled to make a low-resolution image, and different methods are used to recover the original HR image (Christian Ledig et all 2016)</figcaption></figure><p id="b843" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Scott Reed等人在2016年取得了另一项最新进展，其中GANs被用于从文本中合成逼真的图像。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nb"><img src="../Images/605d38171b9648f7c35bc548c22e01d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h9ziqVloZE2nLmOQH-LDug.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">Generative Adversarial Text to Image Synthesis (Scott Reed et al 2016)</figcaption></figure><p id="1f1a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如前所述，gan在强化学习中也有许多应用。仅举几个例子，它们还被应用于图像去噪和艺术生成。</p><h1 id="d87f" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">第2部分—实施GANs</h1><p id="1bff" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">现在你已经了解了什么是GANs以及它们具体是如何工作的，你已经正式进入了博客的激动人心的部分。是时候开始写点代码了！</p><p id="d09f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为GANs最突出的应用是图像生成，所以熟悉用GANs编写图像生成器是有意义的。代码应该将一组图像作为输入，并生成一组相似的图像作为输出。大多数人通常从MNIST这样的图像开始，并尝试使用GANs生成更多的手绘数字。这里，我们将使用来自ImageNet的图像作为我们的输入。由于这些图像是非常高维的，我们将使用DCGANs来生成图像。</p><p id="83ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于输入，使用来自ImageNet的“植物”数据集的图像。调整每个图像的大小以获得128×128的图像。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/7f01d3f9f14f8d9af49100939faebce3.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*a-g7_k_bUO2WG90pAiMjLw.png"/></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">Plant data from ImageNet</figcaption></figure><p id="b1cf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下DCGAN实现在TensorFlow中。这个实现的关键包含在一个名为DCGAN的Python类中，我们将在其中定义用于定义模型和训练模型的方法。</p><p id="4004" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">生成器的定义如下。它由一个线性层和四个卷积层组成。linear和conv2dTranspose方法是用于获取图层的辅助函数。除了最后一个图层之外，批规范化应用于每一个图层。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nd"><img src="../Images/42d10183f0702b3f4998b815acc1334c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E9AXCJIID9BjrFWImgrfBg.png"/></div></div></figure><p id="acf9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们定义鉴别器。我们定义它有四个卷积层，后面是一个线性层。我们使用辅助函数lrelu来定义一个自定义激活函数(Leaky ReLU)。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi ne"><img src="../Images/0881c1d81b17956f32f9e74480ee264e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LnipgrZJIiRooKKIKZySJg.png"/></div></div></figure><p id="caf4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们可以创建生成器和鉴别器模型了。我们定义了两个共享相同参数的鉴别器。一个被馈送来自训练数据的实际图像的小批量，而另一个被馈送由生成器生成的图像的小批量。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nf"><img src="../Images/6b394c09d3121cbb041d81836f2ae790.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rB7mdryw6NAuhhk4PNfAGg.png"/></div></div></figure><p id="33b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们必须定义发生器和鉴别器的损失函数。如博客第1部分所述，我们在鉴别器的输出和实际标签(真/假)之间使用交叉熵函数。这里，标签“真实”对应于1。标签“假”对应于0。因此，鉴别器应该针对真实图像输出接近1的值，针对生成器产生的图像输出接近0的值。使用第1部分中规定的试探法计算发电机损耗。它是根据鉴别器出错的概率计算的，即生成器希望鉴别器为其生成的图像输出接近1的值。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi ng"><img src="../Images/a98bdce10cf434e329018c1e349c4386.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k6uqvQTU1MzDp3k7toq0TA.png"/></div></div></figure><p id="1d59" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们开始训练之前，我们需要首先定义一个优化函数来最小化上述损失。这里我们使用Adam优化器，学习率= 0.0002，用于生成器和鉴别器。这里d_theta表示鉴别器的所有参数，g_theta表示发生器的所有参数。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nh"><img src="../Images/285149bd99bb23583a876410d2393004.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QuP9i-AegqxfPkxjym5t0w.png"/></div></div></figure><p id="46f5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后一步是实际开始训练数据和生成图像。对于每个历元，生成两个微批次对，一个来自训练图像，另一个来自采样z。此外，为了防止鉴频器损耗变为零，每次更新鉴频器时，发生器都会更新两次。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi ni"><img src="../Images/d6384ec37b3f633a18baa9adb91ae827.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_5f2iX0_0k9pEArHKg-v7w.png"/></div></div></figure><h2 id="cc8c" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated">结果</h2><p id="c91d" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">以下是在运行DCGAN时获得的输出，其中来自ImageNet的工厂数据作为输入(大小调整为128x128)，历元数设置为250。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/868343d063be209df6dd1d5bea84292e.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*5kIiFpkG_lRhCg7bZ8g44Q.png"/></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">Output images generated by DCGAN</figcaption></figure><p id="a4ec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这四种损失分别标绘如下。</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nj"><img src="../Images/57cf022026397d5e70ec8be8f192293f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VfN3VnmmgJrX5m6i4bWyWw.png"/></div></div></figure><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nk"><img src="../Images/1b691112b9d6fd1fc33ceb472c185ad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ELTnivYLwXMxq87RukjasA.png"/></div></div></figure><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nl"><img src="../Images/960e0a49941ebb25cece30fe6b395a0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qDYvcNaUhwH6srw_DljbwQ.png"/></div></div></figure><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi nm"><img src="../Images/0cc2d2c7f777bbb077af98f58bea4acf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4MNlXBYoZZsad-YBksuW0Q.png"/></div></div></figure><h2 id="cbc8" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated">结论和未来工作</h2><p id="5783" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">对于大多数时期，发电机损耗低于鉴频器损耗。这可能是因为每次更新鉴别器时，生成器都会更新两次。</p><p id="5330" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">虽然并不完美，但许多生成的图像确实类似于植物/花朵，而不仅仅是一些随机像素的分布。因此，可以得出结论，DCGAN能够智能地构建自己的图像。然而，仍有很大的改进余地。这种实现的主要限制之一是缺乏计算资源。图像生成本身是一项计算密集型任务。在这个特定的例子中，与其他更原始的图像数据集如MNIST相比，图像具有相对更高的分辨率。此外，图像是彩色的。因此，使用GPU将在运行时产生巨大的差异，使运行更多的时代成为可能。</p><p id="6da2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，简单地增加历元可能不能保证产生更好的图像，并且如果学习率太低，鉴别器将开始获胜，并且图像的质量将开始恶化。改进模型的一个显而易见的方法是给生成器添加更多的层。我一开始只有一层，添加更多层后，结果有了显著的改善。人们还可以试验不同类型的激活函数以及优化函数。我在这里用过AdamOptimizer，因为它是Ian Goodfellow自己推荐的。</p><p id="b23f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">虽然上面生成植物图像的例子可能不是特别有用，但是相同的底层模型可以用于生成其他图像，例如小猫和小狗的图像。这也为使用GANs开发更复杂的应用程序奠定了基础，例如art的生成。</p><h2 id="28d2" class="lj km iq bd kn lk ll dn kr lm ln dp kv jy lo lp kz kc lq lr ld kg ls lt lh lu bi translated"><em class="nn">参考文献:</em></h2><figure class="mc md me mf gt mg"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="a82e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae mu" href="https://github.com/carpedm20/DCGAN-tensorflow" rel="noopener ugc nofollow" target="_blank">T3【https://github.com/carpedm20/DCGAN-tensorflow】T5</a></p></div></div>    
</body>
</html>