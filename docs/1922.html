<html>
<head>
<title>What is Transfer Learning?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是迁移学习？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-is-transfer-learning-8b1a0fa42b4?source=collection_archive---------1-----------------------#2017-11-17">https://towardsdatascience.com/what-is-transfer-learning-8b1a0fa42b4?source=collection_archive---------1-----------------------#2017-11-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="7ae4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">迁移学习</strong>利用在解决一个问题时获得的知识，并将其应用于另一个不同但相关的问题。</p><p id="2318" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，在学习识别汽车时获得的知识可以在一定程度上用于识别卡车。</p><h2 id="b748" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated">预培训</h2><p id="4b94" class="pw-post-body-paragraph jn jo iq jp b jq le js jt ju lf jw jx jy lg ka kb kc lh ke kf kg li ki kj kk ij bi translated">当我们在<strong class="jp ir">大型数据集(例如:ImageNet) </strong>上训练网络时，我们训练神经网络的所有参数，因此模型被学习。在你的GPU上可能要花几个小时。</p><h2 id="9fcf" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated"><strong class="ak">微调</strong></h2><p id="8d60" class="pw-post-body-paragraph jn jo iq jp b jq le js jt ju lf jw jx jy lg ka kb kc lh ke kf kg li ki kj kk ij bi translated">我们可以给出新的数据集来微调预训练的CNN。考虑新数据集几乎类似于用于预训练的原始数据集。由于新数据集是相似的，因此可以使用相同的权重从新数据集提取要素。</p><ol class=""><li id="a370" class="lj lk iq jp b jq jr ju jv jy ll kc lm kg ln kk lo lp lq lr bi translated">如果新数据集非常小，最好只训练网络的最后几层，以避免过度拟合，同时保持所有其他层不变。所以去掉预训练网络的最后几层。添加新层。仅重新训练新层。</li><li id="3507" class="lj lk iq jp b jq ls ju lt jy lu kc lv kg lw kk lo lp lq lr bi translated"><strong class="jp ir">如果新数据集非常大，使用预训练模型的初始权重重新训练整个网络</strong>。</li></ol><h2 id="556b" class="kl km iq bd kn ko kp dn kq kr ks dp kt jy ku kv kw kc kx ky kz kg la lb lc ld bi translated"><strong class="ak">如果新数据集与原始数据集差别很大，如何进行微调？</strong></h2><p id="8fca" class="pw-post-body-paragraph jn jo iq jp b jq le js jt ju lf jw jx jy lg ka kb kc lh ke kf kg li ki kj kk ij bi translated">ConvNet的早期特征包含更多的<strong class="jp ir">通用特征(如边缘检测器或彩色斑点检测器)</strong>，但ConvNet的后期层逐渐变得更加具体到原始数据集中包含的<strong class="jp ir">类的细节。</strong></p><p id="a2f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">较早的图层有助于提取新数据的特征。因此，如果你只得到少量的数据，修复早期的层并重新训练其余的层将会很好。</p><p id="a247" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您有大量的数据，您可以使用从预训练网络初始化的权重来重新训练整个网络。</p></div></div>    
</body>
</html>