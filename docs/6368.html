<html>
<head>
<title>Physics-guided Neural Networks (PGNNs)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">物理引导的神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/physics-guided-neural-networks-pgnns-8fe9dbad9414?source=collection_archive---------5-----------------------#2018-12-10">https://towardsdatascience.com/physics-guided-neural-networks-pgnns-8fe9dbad9414?source=collection_archive---------5-----------------------#2018-12-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/601aaec49570d34dbef44a90da5374e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*swK9AIYEdDIxtnTNHp46QA.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Talking some sense into gradient descent.</figcaption></figure><div class=""/><div class=""><h2 id="6068" class="pw-subtitle-paragraph kf jh ji bd b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw dk translated">基于物理的模型是当今科技的核心。近年来，数据驱动模型开始提供一种替代方法，并在许多任务中胜过物理驱动模型。即便如此，他们也渴望数据，他们的推论可能很难解释，归纳仍然是一个挑战。结合数据和物理可以揭示两个世界的精华。</h2></div><p id="35c8" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">当机器学习算法在<em class="lt">学习</em>时，它们实际上是在你选择的算法、架构和配置所定义的假设空间中搜索解决方案。即使对于相当简单的算法，假设空间也可能相当大。数据是我们在这个巨大的空间中寻找解决方案的唯一指南。如果我们可以利用我们对世界的了解——例如，物理学——以及数据来指导这种搜索，会怎么样呢？</p><p id="46de" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">这就是 Karpatne 等人在他们的论文<a class="ae lu" href="https://arxiv.org/abs/1710.11431" rel="noopener ugc nofollow" target="_blank">中解释的物理引导神经网络(PGNN):在湖泊温度建模</a> <em class="lt">中的应用。</em>在这篇文章中，我将解释为什么这个想法至关重要，我还将通过总结这篇文章来描述他们是如何做到的。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="32f5" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">想象一下你把你的外星人👽朋友(优化算法)到一家超市(假设空间)去买你喜欢的奶酪(解)。她唯一的线索就是你给她的奶酪的照片(数据)。由于她缺乏我们对超市的先入之见，她将很难找到奶酪。她可能会在到达食品区之前逛逛化妆品和清洁用品。</p><figure class="md me mf mg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mc"><img src="../Images/807a62b1fdda47960078584d5f81ae7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*45uOn1-tl6CQ9zYD0dJUWw.jpeg"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Finally reached the food section (courtesy of <a class="ae lu" href="https://www.instagram.com/dom_l_garcia_/" rel="noopener ugc nofollow" target="_blank"><strong class="bd mh">Dominic L. Garcia</strong></a>).</figcaption></figure><p id="d8b1" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">这类似于梯度下降等机器学习优化算法寻找假设的方式。数据是唯一的指南。理想情况下，这应该工作得很好，但大多数时候数据是嘈杂的或不够的。将我们的知识整合到优化算法中——在食品区搜索奶酪，甚至不要看化妆品——可以缓解这些挑战。接下来让我们看看，我们实际上是如何做到这一点的。</p><h2 id="dbeb" class="mi mj ji bd mk ml mm dn mn mo mp dp mq lg mr ms mt lk mu mv mw lo mx my mz na bi translated">如何用物理学指导一个 ML 算法</h2><p id="5c8e" class="pw-post-body-paragraph kx ky ji kz b la nb kj lc ld nc km lf lg nd li lj lk ne lm ln lo nf lq lr ls im bi translated">现在，让我总结一下作者如何利用物理学来指导机器学习模型。他们为此提出了两种方法:(1)使用物理理论，他们计算额外的特征(特征工程)以与测量值一起输入到模型中，以及(2)他们将物理不一致项添加到损失函数中，以便惩罚物理不一致的预测。</p><figure class="md me mf mg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ng"><img src="../Images/c76010528981130bf5751d7cd38bf1a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1jjbnRIaEXd0W-o64HGHAQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">(1) Feature engineering using a physics-based model</figcaption></figure><figure class="md me mf mg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nh"><img src="../Images/e9155baadb82603a795a7721ab6e8d5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uM2Qh4PFQLWLLI_KHbgaVw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">(2) Data + Physics driven loss function</figcaption></figure><p id="6d2f" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">第一种方法是特征工程，广泛用于机器学习。然而，第二种方法令人信服。非常类似于添加一个正则项来惩罚过度拟合，他们在损失函数中添加了一个物理不一致性项。因此，有了这个新术语，优化算法还应该注意最小化物理上不一致的结果。</p><p id="0302" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">在论文中，Karpatne 等人将这两种方法与神经网络相结合，并展示了一种他们称为物理导向神经网络(PGNN)的算法。PGNNs 可以提供两个主要优势:</p><ul class=""><li id="d29c" class="ni nj ji kz b la lb ld le lg nk lk nl lo nm ls nn no np nq bi translated"><a class="ae lu" href="https://developers.google.com/machine-learning/crash-course/generalization/video-lecture" rel="noopener ugc nofollow" target="_blank"> <strong class="kz jj">实现泛化</strong> </a>是机器学习中的一个根本性挑战。由于物理模型大多不依赖于数据，它们可能在看不见的数据上表现良好，即使来自不同的分布。</li><li id="6e95" class="ni nj ji kz b la nr ld ns lg nt lk nu lo nv ls nn no np nq bi translated">机器学习模型有时被称为黑盒模型，因为并不总是清楚模型如何达成特定决策。有相当多的工作进入<a class="ae lu" href="https://en.wikipedia.org/wiki/Explainable_Artificial_Intelligence" rel="noopener ugc nofollow" target="_blank"> <strong class="kz jj">可解释的 AI (XAI) </strong> </a>来提高模型的可解释性。PGNNs 可以为 XAI 提供一个基础，因为它们提供了物理上一致和可解释的结果。</li></ul><h2 id="ba01" class="mi mj ji bd mk ml mm dn mn mo mp dp mq lg mr ms mt lk mu mv mw lo mx my mz na bi translated">应用示例:湖泊温度建模</h2><p id="b455" class="pw-post-body-paragraph kx ky ji kz b la nb kj lc ld nc km lf lg nd li lj lk ne lm ln lo nf lq lr ls im bi translated">文中以湖泊温度建模为例，验证了 PGNN 的有效性。水温控制着湖中生物物种的生长、存活和繁殖。因此，对温度的准确观察和预测对于理解社区中发生的变化是至关重要的。任务是开发一个模型，可以预测给定湖泊的水温，作为深度和时间的函数。现在让我们看看他们是如何应用(1)特征工程和(2)损失函数修正来解决这个问题的。</p><p id="7889" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">(1)对于特征工程，他们使用了一种称为<a class="ae lu" href="http://aed.see.uwa.edu.au/research/models/GLM/" rel="noopener ugc nofollow" target="_blank"> <em class="lt">通用湖模型(GLM) </em> </a>的模型来生成新的特征并将它们输入到神经网络中。这是一个基于物理学的模型，它捕捉了湖泊温度动态的控制过程(太阳加热、蒸发等。).</p><p id="9d44" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">(2)现在让我们看看他们是如何定义这个物理不一致性术语的。众所周知，密度较大的水下沉。水温与其密度之间的关系也是已知的。因此，预测应该遵循这样的事实:点越深，预测的密度越高。如果对于一对点，模型预测离表面越近的点密度越高，这是物理上不一致的预测。</p><figure class="md me mf mg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nw"><img src="../Images/5a121d772e189e1d4b38f366ae8b8966.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dhsElli6-7gLivCvTF2FYQ.png"/></div></div></figure><p id="68f4" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">现在有可能将这一想法纳入损失函数。如果ρA&gt; ρB，我们就惩罚它，否则什么也不做。而且，对于较大的不一致，处罚力度应该更高。这可以很容易地通过将函数<em class="lt"> max( ρA- ρB，0) </em>的值加到损失函数上来实现。如果ρA &gt; ρB(即不一致)，该函数将给出一个正值，该正值将增加损失函数(我们试图最小化的函数)的值，否则将给出零，保持损失函数不变。</p><p id="f4a5" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">此时，为了正确使用该函数，需要对其进行两处修改。重要的是所有对的平均不一致性，而不是一个对。因此，可以对所有点的<em class="lt"> max( ρA- ρB，0) </em>求和，然后除以点数。此外，控制最小化物理不一致性的相对重要性也很关键。这可以通过将平均物理不一致性乘以超参数(类似于正则化参数)来实现。</p><figure class="md me mf mg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nx"><img src="../Images/d8c42bb701f96458ecc17c6d78aee2c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h9uzkmhpPV-H8JWRfcF0fw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Physical inconsistency term of the loss function</figcaption></figure><h2 id="7ae6" class="mi mj ji bd mk ml mm dn mn mo mp dp mq lg mr ms mt lk mu mv mw lo mx my mz na bi translated">结果</h2><p id="a91b" class="pw-post-body-paragraph kx ky ji kz b la nb kj lc ld nc km lf lg nd li lj lk ne lm ln lo nf lq lr ls im bi translated">以下是 4 个模型的结果。它们是:</p><ul class=""><li id="286a" class="ni nj ji kz b la lb ld le lg nk lk nl lo nm ls nn no np nq bi translated"><strong class="kz jj"> PHY: </strong>将军湖模型(GLM)。</li><li id="3708" class="ni nj ji kz b la nr ld ns lg nt lk nu lo nv ls nn no np nq bi translated"><strong class="kz jj"> NN: </strong>一个神经网络。</li><li id="dbe2" class="ni nj ji kz b la nr ld ns lg nt lk nu lo nv ls nn no np nq bi translated"><strong class="kz jj"> PGNN0: </strong>具有特征工程的神经网络。GLM 的结果作为附加特征输入到神经网络中。</li><li id="f1ad" class="ni nj ji kz b la nr ld ns lg nt lk nu lo nv ls nn no np nq bi translated"><strong class="kz jj"> PGNN: </strong>具有特征工程和修改的损失函数的 NN。</li></ul><p id="7396" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">和两个评估指标:</p><ul class=""><li id="dd3c" class="ni nj ji kz b la lb ld le lg nk lk nl lo nm ls nn no np nq bi translated"><strong class="kz jj"> RMSE: </strong>均方根误差。</li><li id="7b2f" class="ni nj ji kz b la nr ld ns lg nt lk nu lo nv ls nn no np nq bi translated"><strong class="kz jj">物理不一致:</strong>模型做出物理不一致预测的时间步长的分数。</li></ul><figure class="md me mf mg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ny"><img src="../Images/e8e2047b676d7ebbde84e837b9adc71e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*13A4nRsBQALP8xGZeNf1_Q.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Results on Lake Mille Lacs</figcaption></figure><figure class="md me mf mg gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nz"><img src="../Images/7345f61fbbe42eb984cd246a3fc0ea27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rab3FwDxRQjPwcsABYsMUw.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Results on Lake Mendota</figcaption></figure><p id="34fc" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">将神经网络与 PHY 进行比较，我们可以得出结论，神经网络以物理上不一致的结果为代价给出了更精确的预测。比较 PGNN0 和 PGNN，我们可以看到，由于修改的损失函数，物理不一致性被消除。精度的提高主要是由于特征工程以及损失函数的一些贡献。</p></div><div class="ab cl lv lw hx lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="im in io ip iq"><p id="3c36" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><strong class="kz jj">总而言之</strong>，这些初步结果向我们表明，这种新型算法 PGNN 非常有希望提供准确且物理上一致的结果。此外，将我们对世界的知识结合到损失函数中提供了一种改善机器学习模型的泛化性能的优雅方式。这个看似简单的想法有可能从根本上改善我们进行机器学习和科学研究的方式。</p><p id="21c7" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated">你可以在推特上找到我<a class="ae lu" href="https://twitter.com/malicannoyan" rel="noopener ugc nofollow" target="_blank"> @malicannoyan </a>。</p><p id="874c" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><strong class="kz jj">延伸阅读</strong> <br/> <a class="ae lu" href="https://arxiv.org/abs/1612.08544" rel="noopener ugc nofollow" target="_blank">理论指导下的数据科学:从数据中进行科学发现的新范式</a></p><p id="abe6" class="pw-post-body-paragraph kx ky ji kz b la lb kj lc ld le km lf lg lh li lj lk ll lm ln lo lp lq lr ls im bi translated"><a class="ae lu" href="https://arxiv.org/abs/1711.10561" rel="noopener ugc nofollow" target="_blank">物理学通知深度学习(上):非线性偏微分方程的数据驱动解</a></p></div></div>    
</body>
</html>