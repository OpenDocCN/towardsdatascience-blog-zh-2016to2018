<html>
<head>
<title>Finding Driving Lane Line live with OpenCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 OpenCV 实时查找车道线</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/finding-driving-lane-line-live-with-opencv-f17c266f15db?source=collection_archive---------2-----------------------#2018-07-14">https://towardsdatascience.com/finding-driving-lane-line-live-with-opencv-f17c266f15db?source=collection_archive---------2-----------------------#2018-07-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/be947f829f2242f75beab4e7c8d92f7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*-A8PsXp0sc0vA7s3KCjEnA.jpeg"/></div></figure><p id="f3d0" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">你好，在这个项目中，我将尝试从仪表板摄像头视频饲料找到车道线。一旦我们检测到车道线，我们将在原始视频帧上标记它们并回放。所有这些都将使用 OpenCV 函数在线完成，没有任何延迟。</p><p id="47a1" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们的方法是开发一系列功能来检测车道线。在编写这个函数时，我们将使用一个“样本”图像，一旦我们能够成功地检测到几个“样本”图像上的车道线，我们将把完整的程序合并到一个函数中，该函数可以接受实时馈送图像并返回相同的图像帧，其中车道线高亮显示。所以没有太多的延迟，让我们开始吧。</p><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi ks"><img src="../Images/1e71a57bc285727616adf25784c862e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*1ZKxoLsIlyyVpM5sug0pKg.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Sample Image</figcaption></figure><p id="5fb9" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">首先，我们输入样本图像帧。这一行将在最终代码中进行注释，其中“图像”将是由视频捕获发送的帧。</p><pre class="kt ku kv kw gt lb lc ld le aw lf bi"><span id="8ac2" class="lg lh iq lc b gy li lj l lk ll">image = cv2.imread('test_images/whiteCarLaneSwitch.jpg')</span></pre><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi ks"><img src="../Images/39f0167726c3c46228623ada3929d260.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*bB_kIG3dkoQY6mgiLwTNWg.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Greyed Image</figcaption></figure><p id="14db" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">为了减轻我们处理器的负担(这在嵌入式系统中是非常稀缺的资源)，我们将以图像的“灰度”版本而不是原始的彩色版本来进行所有的图像处理。这有助于用更少的资源更快地执行我们的程序。以下函数将彩色图像转换为灰度图像</p><pre class="kt ku kv kw gt lb lc ld le aw lf bi"><span id="df17" class="lg lh iq lc b gy li lj l lk ll">grey_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)</span></pre><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi ks"><img src="../Images/c2fca460fd7c85bb6451217b51c6c803.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*BpfDBvICkmL4-Zhkaf7nJw.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Image Blurring (Image Smoothing)</figcaption></figure><p id="0cd2" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">接下来，我们将通过模糊图像来去除噪声。图像模糊是通过将图像与低通滤波器核进行卷积来实现的。这对于消除噪音很有用。它实际上删除了图像中的高频内容(例如:噪声、边缘)。所以在这个操作中边缘有点模糊。OpenCV 提供了 4 种不同类型的模糊技术，高斯模糊是最流行的一种。</p><p id="5038" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们可以选择不同的内核大小，其中结果滤波器将简单地取内核(内核大小的行×列矩阵)区域下所有像素的平均值，并用平均值替换中心元素。同样，5 是一个相当标准的值，并且对我有效。</p><pre class="kt ku kv kw gt lb lc ld le aw lf bi"><span id="abaf" class="lg lh iq lc b gy li lj l lk ll">kernel_size = 5</span><span id="5166" class="lg lh iq lc b gy lm lj l lk ll">blur_gray = cv2.GaussianBlur(grey_image,(kernel_size, kernel_size),0)</span></pre><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi ks"><img src="../Images/4422a60c44e75131b4a89f8c47aa3abb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*dqQfe7eRmFpnPK_h2KTK2A.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Canny Edge Detection</figcaption></figure><p id="f2a5" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">Canny 边缘检测是一种流行的边缘检测算法。事实上，Canny edge function 还实现了我们在前面步骤中使用的 5x5 核高斯滤波器，但在我接触的许多文献中，它总是建议在 Canny 边缘检测之前实现自己的模糊。边缘检测背后的基本理论是，只要有边缘，边缘两侧的像素在它们的强度之间就有很大的差异(也称为梯度)。首先，在水平和垂直方向上扫描输入图像，以找到每个像素的梯度。在获得梯度大小和方向后，对图像进行全扫描，以去除可能不构成边缘的任何不想要的像素。为此，在每个像素处，检查像素是否是其邻域中的局部最大值。</p><p id="bc46" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">low_threshold 和 high_threshold 决定检测到的边沿强度。如果梯度高于“high_threshold”，则梯度被视为边缘的一部分。但是一旦检测到边缘，即使下一个像素大于“low_threshold ”,它也会包含在边缘中。</p><pre class="kt ku kv kw gt lb lc ld le aw lf bi"><span id="50bd" class="lg lh iq lc b gy li lj l lk ll">low_threshold = 50</span><span id="be9e" class="lg lh iq lc b gy lm lj l lk ll">high_threshold = 150</span><span id="2a94" class="lg lh iq lc b gy lm lj l lk ll">edges = cv2.Canny(blur_gray, low_threshold, high_threshold)</span></pre><p id="7e8e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">参考我们的示例图像，很明显，在边缘条件下，尤其是车道线所在的位置，相邻像素之间存在巨大的对比度差异，车道线为白色，相邻道路像素为黑色。</p><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi ks"><img src="../Images/c0140f19a1efd6b61e30ad35527152fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*lIYOb3IT-OuUezVQTyOcMA.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Region of Interest</figcaption></figure><p id="cdc1" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">需要考虑的一点是，我们不想找到图像中的所有边缘。我们只是对找到图像中心区域周围的车道感兴趣。直观上，这是有意义的，因为图像的右上/左上部分的边缘极不可能是车道。查看样本图像，我们可以有把握地说，车道线应该在梯形区域内，图像底部的边缘较宽，图像顶部的边缘越来越窄。</p><p id="1050" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">以下四条线标记了我们的边缘检测图像中的感兴趣区域。首先，我们找出图像的大小，其次我们创建梯形的四个角(这一步，和许多其他步骤一样，是一个迭代过程，其中我们需要尝试不同的值来找出最佳情况)。第三，我们用上面的顶点创建梯形，最后我们做一个逐位运算，这样只有在感兴趣的区域内并且被分类为边缘的像素被标记为 1。</p><pre class="kt ku kv kw gt lb lc ld le aw lf bi"><span id="eff6" class="lg lh iq lc b gy li lj l lk ll">imshape = image.shape</span><span id="0ce1" class="lg lh iq lc b gy lm lj l lk ll">vertices = np.array([[(0,imshape[0]),(450, 320), (500, 320), (imshape[1],imshape[0])]], dtype=np.int32)</span><span id="0356" class="lg lh iq lc b gy lm lj l lk ll">cv2.fillPoly(mask, vertices, ignore_mask_color)</span><span id="fe1b" class="lg lh iq lc b gy lm lj l lk ll">masked_edges = cv2.bitwise_and(edges, mask)</span></pre><p id="76fa" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">接下来，我们执行霍夫线变换，以便从上述边缘检测图像中检测一条线。请记住，边也可以是圆形边，但我们在应用中感兴趣的边是车道的直线边。</p><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/0a99b9ac4ad7922a0696b87624673c67.png" data-original-src="https://miro.medium.com/v2/resize:fit:460/format:webp/1*Xu4f4C2qjG-HqngXLDRaaQ.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Hough Line Transform</figcaption></figure><p id="3a52" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">简而言之，霍夫变换法将一条直线从其传统的 y = mx + b 形式变换为ρ= x * cos(θ)+y * sin(θ)其中ρ是从原点到该直线的垂直距离，θ是该垂直线与水平轴形成的角度。</p><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/67564d41abb434e172f98bd10f2f1516.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*gG0Ve4C_ZfBbtCm-IiYd7Q.png"/></div></figure><p id="2b1a" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们知道一条线(y = mx + b)在 m vs b 图中表示时只是一个点，x，y 框架中的一个点在 m vs b 框架中表示为一条线。</p><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/6521043f61587539617d23fc63b3e968.png" data-original-src="https://miro.medium.com/v2/resize:fit:526/format:webp/1*EX9FPra8tA8I8khXmN2rLQ.png"/></div></figure><p id="6ae8" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">所以我们在图像空间中寻找直线的策略是在霍夫空间中寻找相交的直线。为此，我们将霍夫空间划分为一个网格，并将相交线定义为通过给定网格单元的所有线。在霍夫空间中许多直线相交的地方，我们宣布我们已经找到了描述图像空间中一条直线的点的集合。</p><p id="60f9" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们有一个问题，垂直线在 m 对 b 的表示中有无限的斜率，这就是ρ对θ参数化的需要。</p><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/f445f415783e5349a40aa9a2e06308aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*CUDYEsVYspCDEVJ3ZU0ePw.png"/></div></figure><p id="0bd8" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">现在图像空间中的每个点对应于霍夫空间中的正弦曲线(rho vs theta)。如果我们取一整行点，它就转化成霍夫空间中的一整串正弦曲线。您可以将霍夫空间中的正弦曲线视为相当于 m vs b 空间中的一条线，它表示图像空间中的一个点。同样，霍夫空间中这些正弦曲线的交点给出了直线的表示。回到我们的代码，我们首先定义霍夫变换的参数，然后调用函数本身。</p><pre class="kt ku kv kw gt lb lc ld le aw lf bi"><span id="8e48" class="lg lh iq lc b gy li lj l lk ll">rho = 2 # distance resolution in pixels of the Hough grid</span><span id="afa0" class="lg lh iq lc b gy lm lj l lk ll">theta = np.pi/180 # angular resolution in radians of the Hough grid</span><span id="8451" class="lg lh iq lc b gy lm lj l lk ll">threshold = 15     # minimum number of votes (intersections in Hough grid cell)</span><span id="181f" class="lg lh iq lc b gy lm lj l lk ll">min_line_length = 40 #minimum number of pixels making up a line</span><span id="2651" class="lg lh iq lc b gy lm lj l lk ll">max_line_gap = 30    # maximum gap in pixels between connectable line segments</span><span id="dcf9" class="lg lh iq lc b gy lm lj l lk ll">line_image = np.copy(image)*0 # creating a blank to draw lines on</span></pre><p id="b7cb" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">输出“线”是包含检测到的线段的端点的数组。</p><pre class="kt ku kv kw gt lb lc ld le aw lf bi"><span id="b359" class="lg lh iq lc b gy li lj l lk ll">lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]),min_line_length, max_line_gap)</span></pre><p id="63d6" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">迭代输出“线”并在空白图像上画线。</p><pre class="kt ku kv kw gt lb lc ld le aw lf bi"><span id="7669" class="lg lh iq lc b gy li lj l lk ll">for line in lines:<br/>        for x1,y1,x2,y2 in line:<br/>            cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),10)</span></pre><p id="1255" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在原图上画线，还回来。</p><pre class="kt ku kv kw gt lb lc ld le aw lf bi"><span id="71ee" class="lg lh iq lc b gy li lj l lk ll">lines_edges = cv2.addWeighted(image, 0.8, line_image, 1, 0)</span><span id="6fc0" class="lg lh iq lc b gy lm lj l lk ll">return lines_edges</span></pre><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi ks"><img src="../Images/967279b167a13ae66c5bffb9f7af0c83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*Lbyd0KhX8cNOKQWYq0z0ow.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Lane Lines on a single frame</figcaption></figure><p id="165a" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在样本图像上成功检测车道线之后，我们将视频作为输入，检测车道线并回放视频。请注意，这里我处理的是以前录制的视频，但这可以很容易地应用到使用相同 cv2 的现场视频。视频捕捉功能。</p><p id="d1a2" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">首先，我们使用 cv2 创建一个视频对象。视频捕获命令。当‘video _ capture’运行时，我们读取它。Read()函数将返回两个变量，其中第一个变量是布尔值，分别用 true 或 false 值指示读取操作的成功或失败，第二个对象是捕获的帧本身。因此，每当“ret”为真时，我们就获取帧，并简单地将其传递给我们刚刚在上面构建的 processImage 函数。从 processImage 接收的输出显示在捕获帧顶部的车道标记上。</p><pre class="kt ku kv kw gt lb lc ld le aw lf bi"><span id="32f4" class="lg lh iq lc b gy li lj l lk ll">video_capture = cv2.VideoCapture('test_videos/solidWhiteRight.mp4')</span><span id="1c31" class="lg lh iq lc b gy lm lj l lk ll">while (video_capture.isOpened()):<br/>    ret, frame = video_capture.read()<br/>    if ret:<br/>        output = processImage(frame)<br/>        cv2.imshow('frame',output)<br/>        if cv2.waitKey(1) &amp; 0xFF == ord('q'):<br/>            break<br/>    else:<br/>        break</span><span id="b22c" class="lg lh iq lc b gy lm lj l lk ll"># Release everything if job is finished<br/>video_capture.release()<br/>cv2.destroyAllWindows()</span></pre><p id="9705" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">仅此而已。希望这篇文章写得足够好，让你愉快地阅读，并希望学到一两件事。显然，在上述程序中可以实现更多的改进，例如，检查检测线的斜率，以检查检测线是否实际上与车道线一致，并移除异常值。等等。欢迎提出任何改进建议，也欢迎提出有助于我成长的建议。完整的代码与样本图像和视频可以找到<a class="ae lr" href="https://github.com/PercyJaiswal/Find_Lane_Line_Live_OpenCV" rel="noopener ugc nofollow" target="_blank">这里</a></p><p id="4902" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">如果你喜欢这篇文章，在 Twitter 或 Claps 上关注、转发它，在我继续我的博客世界之旅时，Medium 上的赞会鼓励我写新文章。</p><p id="2944" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">直到下一次…干杯！！</p></div></div>    
</body>
</html>