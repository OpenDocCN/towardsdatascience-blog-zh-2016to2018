# LDA 主题建模:一种解释

> 原文：<https://towardsdatascience.com/lda-topic-modeling-an-explanation-e184c90aadcd?source=collection_archive---------2----------------------->

![](img/f6c00ce037dc0a4298625ae118b9a60c.png)

Photo by [Patrick Tomasso](https://unsplash.com/@impatrickt?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

## 背景

主题建模是在一组文档中识别主题的过程。这对于搜索引擎、客户服务自动化以及任何其他了解文档主题很重要的情况都很有用。有多种方法可以做到这一点，但在这里我将解释一种:**潜在狄利克雷分配(LDA)。**

## 该算法

LDA 是一种无监督学习的形式，它将文档视为单词包(即顺序无关紧要)。LDA 的工作方式是首先做出一个关键的假设:生成文档的方式是挑选一组主题，然后为每个主题挑选一组单词。现在你可能会问“好吧，那么它是如何找到主题的？”答案很简单:它逆向工程这个过程。为此，它为每个文档 *m* 执行以下操作:

1.  假设所有文档中都有 *k* 个主题
2.  通过给每个单词分配一个主题，在文档 *m* 中分布这些 *k* 主题(这种分布称为α，可以是对称的，也可以是非对称的，稍后会详细介绍)。
3.  对于文档 *m* 中的每个单词 *w* ，假设其主题是错误的，但是每隔一个单词被分配正确的主题。
4.  基于以下两点从概率上给单词 *w* 分配一个主题:
    -文档 *m
    -* 有多少次单词 *w* 在所有文档中被分配了一个特定的主题(这种分布被称为 *β* ，稍后将详细介绍)
5.  对每个文档重复这个过程几次，你就完成了！

## 模型

![](img/10c9a13f74324ac5c7b6c500f007e38e.png)

Smoothed LDA from [https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)

上面是所谓的 LDA 模型的板块图，其中:
α是每个文档的主题分布，
β是每个主题的单词分布，
θ是文档 *m、* 的主题分布，φ是主题 *k、* z 是文档 *m* 中第 *n* 个单词的主题，以及的主题

## 调整模型

在上面的板模型图中，可以看到 w 是灰色的。这是因为它是系统中唯一可观察的变量，而其他变量是潜在的。正因为如此，要调整模型，有一些事情你可以弄乱，下面我重点介绍两个。

α是一个矩阵，其中每行是一个文档，每列代表一个主题。行 *i* 和列 *j* 中的值表示文档 *i* 包含主题 *j* 的可能性。对称分布意味着每个主题均匀地分布在整个文档中，而非对称分布则倾向于某些主题。这将影响模型的起点，当您大致了解主题如何分布以改善结果时，可以使用它。

β是一个矩阵，其中每行代表一个主题，每列代表一个单词。行 *i* 和列 *j* 中的值表示主题 *i* 包含单词 *j* 的可能性。通常每个单词在整个主题中均匀分布，这样就不会有主题偏向某些单词。这可以被利用，虽然为了偏向某些主题，以有利于某些词。例如，如果你知道你有一个关于苹果产品的主题，那么在其中一个主题中偏向“iphone”和“ipad”这样的词会有所帮助，以便推动模型找到那个特定的主题。

## 结论

本文并不打算成为一个成熟的 LDA 教程，而是给出 LDA 模型如何工作以及如何使用它们的概述。有许多实现方式，例如 [Gensim](https://radimrehurek.com/gensim/) 易于使用且非常有效。关于使用 Gensim 库进行 LDA 建模的很好的教程可以在[这里](/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24)找到。

有什么想法或发现我错过了什么？让我知道！

快乐话题造型！