<html>
<head>
<title>Deep Dive into Supervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深入研究监督学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-dive-into-supervised-learning-e7952c0692e9?source=collection_archive---------11-----------------------#2018-06-26">https://towardsdatascience.com/deep-dive-into-supervised-learning-e7952c0692e9?source=collection_archive---------11-----------------------#2018-06-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="2810" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当你在学校的时候，你被要求练习很多加减法题。最初，你必须检查你得出的答案是对还是错，但过了一段时间，你对自己的答案变得有信心，认为它是正确的。这基本上就是<strong class="jp ir">监督学习</strong>。</p><p id="c811" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在监督学习中，算法由示例输入和期望输出提供。算法的工作是建立输入和输出之间的映射。在足够数量的输入之后，该算法能够以一定的精度预测输出。</p><p id="f83f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是展示<strong class="jp ir"> Alvin 的视频，它是人工智能系统</strong>通过观察人的驾驶来学习。正如我所说，第一步是训练一个网络/算法来驾驶。在训练人类驾驶员时，转向角度被提供给 Alvin。阿尔文的工作是学习“如何驾驶”。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><p id="b524" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在上面的视频中，有一个图像如下所示。它表示实时算法的输入和输出。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ks"><img src="../Images/36014b798cece10fc353b1338a9591c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*YlDKmh61xzuA2q4Y71AK3w.png"/></div></figure><p id="12e5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们从监督学习开始，但在此之前，您应该熟悉一些符号:</p><ul class=""><li id="b9ec" class="kv kw iq jp b jq jr ju jv jy kx kc ky kg kz kk la lb lc ld bi translated">m:训练实例的数量</li><li id="0254" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated">x:输入变量/特征</li><li id="36bd" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated">y:输出变量/目标变量</li><li id="a25c" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated">(x，y):训练示例</li><li id="af20" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated">n:输入变量或特征的数量</li><li id="5e3e" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated">θ:参数或权重。算法的工作是选择合适的权重</li></ul><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi lj"><img src="../Images/c84ac48c4f7616102a765b696c3e37af.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*kPYa-chlLgVtK4_DXjHVwA.png"/></div></figure><p id="9ac9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">总之，我们提供学习算法的训练样本。它为我们提供了一个假设(h)。假设在提供一些输入时会给我们预期的输出。假设由下式给出</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/e4395d5246b296d769c2ea7271e10536.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*ne0miZo9bWOYwLLXsr2zLg.png"/></div></figure><p id="424f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我们想要训练“m”个样本时，上述等式可以表示为:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/cf307175894b68331c7ed347618d00a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/1*k2SQS2xeMR0P-ifLJ0MrHA.png"/></div></figure><p id="c766" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，θ表示为假设预测值的平方和减去“m”个训练样本的实际值。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi lm"><img src="../Images/e2bee7f216bcd97f86c367cd3a1a523b.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*QEdN8twDhTP98ZWccyF_iA.png"/></div></figure><p id="48f8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了最小化 J(θ)，我们使用了被称为<strong class="jp ir">梯度下降</strong>的算法。它可以解释如下:想象你站在一个山顶上，你想向最陡的下坡方向迈出一小步，这可以让你尽快下山。梯度下降也是如此。你从一个点开始应用梯度下降，在一个新的点结束，重复同样的动作，直到你到达最小点。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/c7d94b6a8e1129f3537b3673778bfdab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*70KmcEnY9WqCO1wiI6hYUA.png"/></div></figure><p id="8eb2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">假设只有一个训练样本，我们将进行梯度下降的推导</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/226f28a2d399b3b5e28d182323628583.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*V9GRfH5f0pVxz8Wu_gwl2g.png"/></div></figure><p id="c20c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在θ由下式给出</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lp"><img src="../Images/c2541c8af76b3dcf5060c890e6f72828.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*-9xcHLD7Bof0CYkzwTwtrQ.png"/></div></div></figure><p id="9e85" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注:上式中的α是学习率。这就像下山时你想走多大的步。如果你步子迈得太小，下山会花很长时间。如果你的步长太大，你可能会超过局部最小值。如果有“m”个训练样本，则广义方程由下式给出</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/d54f04e70dd233223963046e83c982ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/1*2bZGX_-c4qLtv247mOnfcg.png"/></div></figure><p id="7588" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我会给你一个图像，让你看到梯度下降是行动。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/19457327ba69fd0a2cdab8f2aff0bfed.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/1*ZmzSnV6xluGa42wtU7KYVA.gif"/></div></figure><p id="ed1c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上述梯度下降也被称为<strong class="jp ir">批量梯度下降</strong>。这意味着每次该算法将针对所有训练示例运行。梯度下降还有一种变化，称为<strong class="jp ir">随机梯度下降</strong>或<strong class="jp ir">递增下降</strong>。如下所示:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lw"><img src="../Images/0f0bbbdc2cb4f8e7603347f7d538e8f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MmgIAHA5IHhTTQHXfRMTDA.png"/></div></div></figure><p id="9c8f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">随机梯度下降法的优点</strong>是根据误差相对于单个训练样本的梯度来更新参数。已经观察到，对于大数据集，随机梯度下降更快。</p><p id="c9a6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你发现我的帖子有不一致的地方，欢迎在评论中指出。感谢阅读。</p></div></div>    
</body>
</html>