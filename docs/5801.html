<html>
<head>
<title>A Bayesian Approach to Time Series Forecasting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">时间序列预测的贝叶斯方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-bayesian-approach-to-time-series-forecasting-d97dd4168cb7?source=collection_archive---------2-----------------------#2018-11-10">https://towardsdatascience.com/a-bayesian-approach-to-time-series-forecasting-d97dd4168cb7?source=collection_archive---------2-----------------------#2018-11-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/6af87d5cca1b58a574015b6c9b1aed4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H4VQ3X5fyVTmNeuYWE3Rkw.jpeg"/></div></div></figure><div class=""/><p id="b63e" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">今天我们将从头开始在 R 中实现贝叶斯线性回归，并使用它来预测美国 GDP 增长。这篇文章基于英格兰银行关于应用贝叶斯计量经济学的非常翔实的手册。我已经把原始的 Matlab 代码翻译成 R，因为它是开源的，并广泛应用于数据分析/科学。我在这篇文章中的主要目标是试图让人们更好地理解贝叶斯统计，它的一些优点，以及一些你可能想使用它的场景。</p><p id="c795" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们花一点时间来思考一下，为什么我们首先要使用贝叶斯技术。这样做有几个好处，对于时间序列分析来说尤其有吸引力。使用时间序列模型时的一个问题是过度拟合，特别是在相对较短的时间段内估计具有大量参数的模型时。在这种特殊的情况下，这不是一个问题，但当考虑多个变量时，这肯定是一个问题，这在经济预测中很常见。过度拟合问题的一个解决方案是采用贝叶斯方法，该方法允许我们对变量施加某些先验。</p><p id="8038" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了理解为什么会这样，考虑一下岭回归(L2 惩罚)的例子。这是一种正则化技术，通过在参数值变大时惩罚我们来帮助我们减少过度拟合(对<a class="ae kz" href="https://www.quora.com/How-does-ridge-regression-work" rel="noopener ugc nofollow" target="_blank">岭回归</a>的良好解释)。相反，如果我们采用贝叶斯方法来解决回归问题，并使用正态先验，我们实际上是在做与岭回归完全相同的事情。<a class="ae kz" href="https://www.coursera.org/learn/bayesian-methods-in-machine-learning/lecture/p1FM9/linear-regression" rel="noopener ugc nofollow" target="_blank"> <strong class="kd jf">这里的</strong> </a>是经过推导证明他们相同的视频(真的好课程 BTW)。我们经常喜欢使用贝叶斯方法的另一个重要原因是，它允许我们将不确定性纳入我们的参数估计中，这在预测时特别有用。</p></div><div class="ab cl la lb hx lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="im in io ip iq"><h1 id="5a3f" class="lh li je bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">贝叶斯理论</h1><p id="f3c0" class="pw-post-body-paragraph kb kc je kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">在我们开始之前，让我们花点时间来讨论贝叶斯理论的基础以及它如何应用于回归。通常，如果有人想估计以下形式的线性回归:</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/0c169938e3725303d19b2875454d1e81.png" data-original-src="https://miro.medium.com/v2/resize:fit:340/format:webp/1*wMM6kEBFpYCDTBD7F37Neg.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Linear regression Matrix Form</figcaption></figure><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/785f60dbd560a4e00507e3968fb0cec2.png" data-original-src="https://miro.medium.com/v2/resize:fit:314/format:webp/1*WjJbvac02rI_0MJJU5xjeg.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Normally distributed error</figcaption></figure><p id="d240" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">他们将从收集每个变量的适当数据开始，并形成下面的可能性函数。然后，他们会试图找到使该函数最大化的 B 和σ:</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mu"><img src="../Images/778c7c6944db6d53cddcd0ed8a03bb65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zHKD3xUyBX4aZiJofOgEkQ.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Likelihood Function</figcaption></figure><p id="2df4" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这种情况下，通过取该函数的<strong class="kd jf">对数</strong>的<strong class="kd jf">导数</strong>，并在导数等于零的地方找到 B 的值，可以找到最佳参数。如果我们真的做了数学计算，我们会发现答案是下面的<strong class="kd jf"> OLS 估计量</strong>。我不会去推导，但<a class="ae kz" href="https://www.youtube.com/watch?v=fb1CNQT-3Pg" rel="noopener ugc nofollow" target="_blank">在这里</a>是一个非常好的视频推导 OLS 估计的细节。我们也可以把这个估计量想象成 X 和 Y 的<strong class="kd jf">协方差</strong>除以 X 的<strong class="kd jf">方差</strong>。</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/59ed3af7335748d7e377cbf897e44ef4.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*yX5DMKyeb1AjZzZjkaqYWQ.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">OLS estimator</figcaption></figure><p id="16a9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">方差的最佳值将等于</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/7950bfe2bdbea9324c059e301b0fa59b.png" data-original-src="https://miro.medium.com/v2/resize:fit:198/format:webp/1*k7mlz097D_peAGkxL31xGA.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">variance</figcaption></figure><p id="5ce6" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">其中 T 是数据集中的行数。经典频率主义方法和贝叶斯方法之间的主要区别在于，模型的参数仅基于数据中包含的信息，而贝叶斯方法允许我们通过使用<strong class="kd jf">先验</strong>来整合其他信息。下表总结了频率主义者和贝叶斯方法之间的主要区别。</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/be951e0febe415a6e10ef91be9e8fa3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*HOLFuOjPJvRmqHTpu2HhLg.png"/></div></figure><p id="25b9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">那么我们如何利用这些先验信息呢？这就是贝叶斯法则发挥作用的时候了。记住贝叶斯规则的公式是:</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi my"><img src="../Images/38664b11a8dd5f5c21e7182a5c8c6432.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/1*I_ud7sSEQ_LdsdYVAVUU0A.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Bayes Rule</figcaption></figure><p id="8f6d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae kz" href="https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/" rel="noopener ugc nofollow" target="_blank">这里的</a>是一个非常清晰的解释和使用贝叶斯规则的例子。它展示了我们如何将我们的先验知识与证据结合起来，用一个医学例子来形成后验概率。</p><p id="0550" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在，让我们将贝叶斯规则应用于我们的回归问题，看看我们会得到什么。下面是我们参数的后验分布。记住，这最终是我们要计算的。</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/bae5de1af76f96327ee5db0761c67961.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*gRSRiZYYQV4H2jYOLcyWEg.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Bayes Rule expressed using our model and data</figcaption></figure><p id="138d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们还可以更进一步，用更简洁的方式描述<strong class="kd jf"> <em class="na">后验分布</em> </strong>。</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/79cb9e7654d54c80371a870c49abaa76.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*vShnDg9WY2ziiQDYqLfU2w.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Posterior Distribution</figcaption></figure><p id="756c" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这个等式表明，以我们的数据为条件的我们的参数的后验分布与我们的<strong class="kd jf"> <em class="na">似然函数</em> </strong>(我们假设它是正态的)乘以我们的系数的<strong class="kd jf"> <em class="na">先验分布</em> </strong>(它也是正态的)成比例。分母中的边际密度或 F(Y )(相当于贝叶斯规则中的 P(B ))是一个归一化常数，以确保我们的分布积分为 1。还要注意，它不依赖于我们的参数，所以我们可以忽略它。</p><p id="b993" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了计算后验分布，我们需要分离出这个后验分布中与每个系数相关的部分。这涉及到计算边际分布，这在实践中通常很难通过分析来完成。这就是被称为<strong class="kd jf"> <em class="na">吉布斯采样</em> </strong>的数值方法派上用场的地方。Gibbs sampler 是<strong class="kd jf">Markov Chain Monte Carlo(MCMC)</strong>的一个例子，它让我们利用条件分布来近似联合边际分布。接下来是如何工作的快速概述。</p><h1 id="c957" class="lh li je bd lj lk nc lm ln lo nd lq lr ls ne lu lv lw nf ly lz ma ng mc md me bi translated">吉布斯采样</h1><p id="1cc1" class="pw-post-body-paragraph kb kc je kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">假设我们有 N 个变量的联合分布:</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nh"><img src="../Images/d7f59e7f637b50fbf979bc4904b59062.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*JunuDOO6xUPlermYPP8P0w.png"/></div></div></figure><p id="9c72" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们想找到每个变量的边际分布。然而，如果这些变量的形式未知，可能很难解析地计算出必要的积分(<em class="na">积分很难！！</em>)。在这种情况下，我们采取以下步骤来实现吉布斯算法。首先，我们需要初始化变量的初始值，</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/0dab0fa46e666d55bdd2cb995fce5078.png" data-original-src="https://miro.medium.com/v2/resize:fit:210/format:webp/1*tpzFEKKsRB7UUW00YT_I5A.png"/></div></figure><p id="4d08" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来，我们根据其他 N-1 个变量的当前值对第一个变量进行采样。即</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/6a791ea0ed9ec6bac21ce99ab0e9ab90.png" data-original-src="https://miro.medium.com/v2/resize:fit:394/format:webp/1*uTgqw-IrjDcNOOOorNOxpw.png"/></div></figure><p id="fe60" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">然后，我们对第二个变量进行抽样，条件是所有其他变量</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/c79489b08cca8b6462c893aab0bafd8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:474/format:webp/1*cFQa8I31CHRbZJY6rxht7g.png"/></div></figure><p id="6995" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">，重复这一过程，直到我们对每个变量进行了采样。这结束了吉布斯采样算法的一次迭代。当我们多次重复这些步骤时，来自条件分布的样本收敛到联合边际分布。一旦我们运行了 M 次吉布斯采样器，我们保留的样本的平均值可以被认为是后验分布平均值的近似值。下面是取样器在两个变量作用下的可视化。您可以看到，算法最初是如何从分布之外的点开始采样，但经过一些步骤后开始收敛到分布。</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/3b9cdb16da42000bf6595b07d3584e06.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/1*FcyHiaK7ms7WXveeRr5bAg.gif"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Source: Coursera: Bayesian Methods for Machine learning</figcaption></figure><p id="3689" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">既然我们已经讨论了理论，让我们看看它在实践中是如何工作的。下面是使用 Gibbs sampler 实现线性回归的代码。特别是，我将对美国季度国内生产总值(GDP)的同比增长进行 AR(2)模型估计。然后，我将使用这个模型，用贝叶斯框架来预测 GDP 增长。使用这种方法，我们可以使用来自后验密度的分位数，即来自我们算法的保留抽取的分位数，围绕我们的预测构建可信区间。</p><h1 id="a857" class="lh li je bd lj lk nc lm ln lo nd lq lr ls ne lu lv lw nf ly lz ma ng mc md me bi translated">模型</h1><p id="40b6" class="pw-post-body-paragraph kb kc je kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">我们的模型将具有以下形式:</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/af3a0b147fda72fe3be9758aa151de33.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*c1s3fJ0npUdV2EJuJJwyjg.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">AR(2) Model</figcaption></figure><p id="bfde" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们也可以通过定义下面的矩阵，用矩阵的形式来表达。</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/3e073040adebcc0e8792219ef2228008.png" data-original-src="https://miro.medium.com/v2/resize:fit:338/format:webp/1*C1oTbYBZa6Ehh6ZdzINkRQ.png"/></div></figure><p id="78cc" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">上面是一个系数向量，下面是数据矩阵 X。</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi no"><img src="../Images/7951330aafcdf63f0b35a88f49851d0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/1*F2QwsV40XtWtSiE5JVZugg.png"/></div></figure><p id="41db" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这给出了上面等式 1 中的形式。正如我已经说过的，我们的目标是近似我们系数的后验分布:</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi np"><img src="../Images/adb76ec70f055047c2c89b243444fd50.png" data-original-src="https://miro.medium.com/v2/resize:fit:274/format:webp/1*yXX8DoSSdvcKgeoVThFJiQ.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">coefficients</figcaption></figure><p id="d82b" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以通过计算吉布斯抽样框架内的条件分布来做到这一点。好了，现在这个理论已经过时了，让我们开始用 r 编写代码。</p></div><div class="ab cl la lb hx lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="im in io ip iq"><h1 id="5431" class="lh li je bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">密码</h1><p id="023d" class="pw-post-body-paragraph kb kc je kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">我们需要做的第一件事是载入数据。我从圣路易斯美联储的网站下载了美国的 GDP 增长。我选择<strong class="kd jf"> p=2 </strong>作为我想要使用的滞后数。这种选择是相当随意的，有正式的测试，如<strong class="kd jf"> AIC </strong>和<strong class="kd jf"> BIC </strong>我们可以用来选择最佳数量的滞后，但我没有使用它们进行分析。那句老话是什么？照我说的做，不要照我做的做。我认为这适用于这里。😄</p><pre class="ml mm mn mo gt nq nr ns nt aw nu bi"><span id="c781" class="nv li je nr b gy nw nx l ny nz">library(ggplot)</span><span id="b329" class="nv li je nr b gy oa nx l ny nz">Y.df &lt;- read.csv('USGDP.csv', header =TRUE)<br/>names &lt;- c('Date', 'GDP')<br/>Y &lt;- data.frame(Y.df[,2])</span><span id="402d" class="nv li je nr b gy oa nx l ny nz">p = 2<br/>T1 = nrow(Y)</span></pre><p id="48a5" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来，我们定义<strong class="kd jf"> regression_matrix </strong>函数来创建包含 p 滞后 GDP 变量和一个常数项的 X 矩阵。该函数接受三个参数，数据、滞后次数以及真或假，这取决于我们是否需要一个常量。我还在下面创建了另一个辅助函数，它将模型中的系数矩阵转换成一个伴随矩阵。这个函数，<strong class="kd jf"> ar_companion_matrix </strong>实质上转换一个系数矩阵，如下所示(注意不包括常数项):</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/270871f3d3cc57771aff18e8cab09673.png" data-original-src="https://miro.medium.com/v2/resize:fit:158/format:webp/1*IB5JPNI0JKMtKfn9E91l2Q.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">matrix of coefficients</figcaption></figure><p id="3d8a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">转换成一个<strong class="kd jf"> <em class="na"> n*n 矩阵</em> </strong>，其系数位于顶行，其下是一个(n-1)*(n-1)单位矩阵。以这种方式表达我们的矩阵允许我们计算我们的模型 的<strong class="kd jf"> <em class="na">稳定性，这将是我们的吉布斯采样器的重要部分。当我们看到相关的代码时，我会在后面的文章中详细讨论这个问题。</em></strong></p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/2e25f828ba1c421d1fbcad1a466156c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*fSxC6EUIlgCqjEN2IF26bA.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Companion form of matrix</figcaption></figure><pre class="ml mm mn mo gt nq nr ns nt aw nu bi"><span id="e547" class="nv li je nr b gy nw nx l ny nz">regression_matrix  &lt;- function(data,p,constant){<br/>    nrow &lt;- as.numeric(dim(data)[1])<br/>    nvar &lt;- as.numeric(dim(data)[2])<br/>    <br/>    Y1 &lt;- as.matrix(data, ncol = nvar)<br/>    X &lt;- embed(Y1, p+1)<br/>    X &lt;- X[,(nvar+1):ncol(X)]<br/>    if(constant == TRUE){<br/>        X &lt;-cbind(rep(1,(nrow-p)),X)<br/>    }<br/>    Y = matrix(Y1[(p+1):nrow(Y1),])<br/>    nvar2 = ncol(X)<br/>    return = list(Y=Y,X=X,nvar2=nvar2,nrow=nrow) <br/>}</span><span id="26c2" class="nv li je nr b gy oa nx l ny nz">################################################################</span><span id="27ae" class="nv li je nr b gy oa nx l ny nz">ar_companion_matrix &lt;- function(beta){<br/>    <strong class="nr jf">#check if beta is a matrix</strong><br/>    if (is.matrix(beta) == FALSE){<br/>        stop('error: beta needs to be a matrix')<br/>    }<br/>    <strong class="nr jf"># dont include constant</strong><br/>    k = nrow(beta) - 1<br/>    FF &lt;- matrix(0, nrow = k, ncol = k)<br/>    <br/>   <strong class="nr jf"> #insert identity matrix</strong><br/>    FF[2:k, 1:(k-1)] &lt;- diag(1, nrow = k-1, ncol = k-1)<br/>   <br/>    temp &lt;- t(beta[2:(k+1), 1:1])<br/>    <strong class="nr jf">#state space companion form<br/>    #Insert coeffcients along top row</strong><br/>    FF[1:1,1:k] &lt;- temp<br/>    return(FF)<br/>}</span></pre><p id="17ba" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们的下一段代码实现了我们的<strong class="kd jf">回归矩阵函数</strong>，并从结果列表中提取矩阵和行数。我们还建立了贝叶斯分析的先验。</p><pre class="ml mm mn mo gt nq nr ns nt aw nu bi"><span id="519b" class="nv li je nr b gy nw nx l ny nz">results = list()<br/>results &lt;- regression_matrix(Y, p, TRUE)</span><span id="1a4c" class="nv li je nr b gy oa nx l ny nz">X &lt;- results$X<br/>Y &lt;- results$Y<br/>nrow &lt;- results$nrow<br/>nvar &lt;- results$nvar</span><span id="5926" class="nv li je nr b gy oa nx l ny nz"><strong class="nr jf"># Initialise Priors</strong><br/>B &lt;- c(rep(0, nvar))<br/>B &lt;- as.matrix(B, nrow = 1, ncol = nvar)<br/>sigma0 &lt;- diag(1,nvar)</span><span id="467a" class="nv li je nr b gy oa nx l ny nz">T0 = 1 <strong class="nr jf"># prior degrees of freedom</strong><br/>D0 = 0.1 <strong class="nr jf"># prior scale (theta0)</strong></span><span id="7dfb" class="nv li je nr b gy oa nx l ny nz"><strong class="nr jf"># initial value for variance</strong><br/>sigma2 = 1 </span></pre><p id="e65b" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们在这里所做的基本上是为我们的<strong class="kd jf"> <em class="na">贝塔系数</em> </strong>设置一个正态先验，其均值= 0，方差= 1。对我们来说，我们有前科:</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi od"><img src="../Images/3044f00bab9df45c7d35903b9d6cf7ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:298/format:webp/1*TWBWYYR-mwOCpUjw5vM2uA.png"/></div></figure><p id="8b21" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对于我们的方差，我们有先验:</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/23b68aa494cf66a82788c89021bde369.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*OKyC2rlsgKbpch8AV8MLHg.png"/></div></figure><p id="5cd2" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对于<strong class="kd jf"> <em class="na">方差参数</em> </strong>，我们设置了一个<strong class="kd jf">逆伽玛先验(共轭先验)。</strong>这是用于方差的标准分布，因为它只为正数定义，这对于方差来说是理想的，因为它只能是正的。</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi of"><img src="../Images/1bc61942aa4999b9df7745a432f93d2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*rqj9e6PpcdM7RFIcwdOmDw.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Inverse Gamma Prior</figcaption></figure><p id="d8a7" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对于这个例子，我们任意选择 T0 = 1 和θ0 = 0.1(D0 是我们的代码)。如果我们想测试这些先验的选择，我们可以通过改变我们的初始先验来做稳健性测试，看看它是否显著改变后验概率。如果我们尝试想象改变θ0 的值会产生什么影响，我们会发现，较高的值会给我们一个更宽的分布，我们的系数更可能呈现较大的绝对值，类似于我们的β具有较大的先验方差。</p><pre class="ml mm mn mo gt nq nr ns nt aw nu bi"><span id="18c6" class="nv li je nr b gy nw nx l ny nz">reps = 15000<br/>burn = 4000<br/>horizon = 14<br/>out = matrix(0, nrow = reps, ncol = nvar + 1)<br/>colnames(out) &lt;- c(‘constant’, ‘beta1’,’beta2', ‘sigma’)<br/>out1 &lt;- matrix(0, nrow = reps, ncol = horizon)</span></pre><p id="d4d3" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">上面我们设置了我们的预测范围，并初始化了一些矩阵来存储我们的结果。我们创建了一个名为<strong class="kd jf"> out </strong>的矩阵来存储我们所有的抽奖。它需要的行数等于我们的采样器的抽取数，在本例中等于 15，000。我们还需要创建一个矩阵来存储我们的预测结果。因为我们通过迭代以下形式的方程来计算我们的预测:</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi og"><img src="../Images/018d6bf1cba9632e230beb18a7913e69.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*S9daeLVfiTn03bY-y0TDQA.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">AR(2) Model</figcaption></figure><p id="16e4" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将需要最后两个可观测期来计算预测。这意味着我们的第二个矩阵<strong class="kd jf"> out1 </strong>的列数将等于预测周期数加上滞后数，在本例中为 14。</p><h1 id="83a1" class="lh li je bd lj lk nc lm ln lo nd lq lr ls ne lu lv lw nf ly lz ma ng mc md me bi translated">吉布斯采样的实现</h1><p id="01f7" class="pw-post-body-paragraph kb kc je kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">好了，接下来是一段看起来很复杂的代码，但我会一步一步地看，希望之后会更清楚。</p><pre class="ml mm mn mo gt nq nr ns nt aw nu bi"><span id="336f" class="nv li je nr b gy nw nx l ny nz">gibbs_sampler &lt;- function(X,Y,B0,sigma0,sigma2,theta0,D0,reps,out,out1){</span><span id="3b0c" class="nv li je nr b gy oa nx l ny nz">for(i in 1:reps){<br/>    if (i %% 1000 == 0){<br/>    print(sprintf("Interation: %d", i))<br/>        }<br/>    M = solve(solve(sigma0) + as.numeric(1/sigma2) * t(X) %*% X) %*%<br/>        (solve(sigma0) %*% B0 + as.numeric(1/sigma2) * t(X) %*% Y)<br/>    <br/>    V = solve(solve(sigma0) + as.numeric(1/sigma2) * t(X) %*% X)<br/>    <br/>    chck = -1<br/>    while(chck &lt; 0){   # check for stability<br/>        <br/>        B &lt;- M + t(rnorm(p+1) %*% chol(V))<br/>        <br/>        <strong class="nr jf"># Check : not stationary for 3 lags</strong><br/>        b = ar_companion_matrix(B)<br/>        ee &lt;- max(sapply(eigen(b)$values,abs))<br/>        if( ee&lt;=1){<br/>            chck=1<br/>        }<br/>    }<br/>    <strong class="nr jf"># compute residuals</strong><br/>    resids &lt;- Y- X%*%B<br/>    T2 = T0 + T1<br/>    D1 = D0 + t(resids) %*% resids<br/>    <br/>    <strong class="nr jf"># keeps samples after burn period</strong><br/>    out[i,] &lt;- t(matrix(c(t(B),sigma2)))<br/>    <br/>    <br/>    <strong class="nr jf">#draw from Inverse Gamma</strong><br/>    z0 = rnorm(T1,1)<br/>    z0z0 = t(z0) %*% z0<br/>    sigma2 = D1/z0z0<br/>    <br/>    <strong class="nr jf"># keeps samples after burn period</strong><br/>    out[i,] &lt;- t(matrix(c(t(B),sigma2)))<br/>    <br/>    <strong class="nr jf"># compute 2 year forecasts</strong><br/>    yhat = rep(0,horizon)<br/>    end = as.numeric(length(Y))<br/>    yhat[1:2] = Y[(end-1):end,]<br/>    cfactor = sqrt(sigma2)<br/>    X_mat = c(1,rep(0,p))</span><span id="505d" class="nv li je nr b gy oa nx l ny nz">for(m in (p+1):horizon){<br/>            for (lag in 1:p){<br/>           <strong class="nr jf"> #create X matrix with p lags</strong><br/>                X_mat[(lag+1)] = yhat[m-lag]<br/>    }<br/>            <strong class="nr jf"># Use X matrix to forecast yhat</strong><br/>            yhat[m] = X_mat %*% B + rnorm(1) * cfactor<br/>    }<br/>    </span><span id="06d0" class="nv li je nr b gy oa nx l ny nz">out1[i,] &lt;- yhat<br/>}<br/>    return = list(out,out1)<br/>    }</span><span id="eca2" class="nv li je nr b gy oa nx l ny nz">results1 &lt;- gibbs_sampler(X,Y,B0,sigma0,sigma2,T0,D0,reps,out,out1)</span><span id="21ef" class="nv li je nr b gy oa nx l ny nz"><strong class="nr jf"># burn first 4000</strong><br/>coef &lt;- results1[[1]][(burn+1):reps,]<br/>forecasts &lt;- results1[[2]][(burn+1):reps,]</span></pre><p id="9c57" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">首先，我们的函数需要以下参数。我们的初始变量，在这种情况下，GDP 增长(Y)。我们的 X 矩阵，只是 Y 滞后了 2 个周期，并附加了一列 1。我们还需要我们之前定义的所有先验，迭代算法的次数(reps ),最后，我们的 2 个输出矩阵。</p><p id="a8ca" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">主循环是我们在这里最需要注意的。这是所有主要计算发生的地方。前两个方程<strong class="kd jf"> <em class="na"> M 和 V </em> </strong>描述了以 B 和σ为条件的正态分布的<strong class="kd jf"> <em class="na">后验均值和方差</em> </strong>。我不会在这里推导这些，但如果你感兴趣，它们可以在 Hamilton (1994)的时间序列分析或<strong class="kd jf"> <em class="na"> Bishop 模式识别和机器学习第 3 章</em> </strong>(尽管符号略有不同)中找到。明确地说，我们的后验参数β的平均值定义为:</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/598585eec836950d00d34eef1780d544.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*__kzQiDB1w1jU8l-tkzYUQ.png"/></div></figure><p id="b1b3" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们的后验参数β的方差定义为:</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/08aad49e05af5cda1fb1229a68d1f820.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*bMTroaR7G8WmnsfZ5eKNKQ.png"/></div></figure><p id="122d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果我们稍微考虑一下 M 中的第二项，我们可以用最大似然估计来代替 Y_t，这样我们就可以得到</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/667952bf500ac93183b9c807e82e6d71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*iep2wSEHJBh7hVIN1SasVQ.png"/></div></figure><p id="2e7f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">本质上，这个等式表明<strong class="kd jf"> <em class="na"> M 只是我们的先验均值和β的最大似然估计的加权平均值。我直觉地认为这很有意义，因为我们正试图结合我们先前的信息以及来自我们数据的证据。让我们考虑一下之前的方差，尝试改进我们对这个等式的解释。如果我们分配一个小的先验方差(sigma0)，本质上我们对我们的先验选择是有信心的，并认为我们的后验将接近它。在这种情况下，分布将会非常紧密。相反，如果我们在 Beta 参数上设置了一个高方差，情况正好相反。在这种情况下，βOLS 参数的权重将更大。</em></strong></p><p id="953d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">但是我们还没有完成。我们仍然需要从正确的分布中随机抽取，但我们可以使用一个简单的技巧来做到这一点。要从均值为 M、方差为 V 的正态分布中获取随机变量，我们可以从标准正态分布中抽取一个向量，并使用以下等式对其进行转换。</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/aaa4edddc29a592e6a32fd824086f92f.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*rkqx3EmgLqPSdYZQEgdjxg.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Draw of B from conditional posterior distribution</figcaption></figure><p id="b8eb" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">本质上，我们通过后验方差(标准差)的平方根来添加我们的条件后验均值和标度。这给了我们来自条件后验分布的样本 B。下一段代码也有一个检查，以确保系数矩阵是稳定的，即我们的变量是稳定的，确保我们的模型是动态稳定的。通过将我们的 AR(2)重铸为 AR(1)(伴式)，我们可以检查<strong class="kd jf"> <em class="na">特征值的绝对值是否小于 1(只需要检查最大的特征值是&lt; |1|) </em> </strong>。如果是的话，那就意味着我们的模型是动态稳定的。如果有人想更详细地了解这一点，我推荐《数理经济学的基本方法》第 17 章，或者阅读<a class="ae kz" href="https://davegiles.blogspot.com/2013/06/when-is-autoregressive-model.html?_sm_au_=iVVj7sWRNPW1PkqF" rel="noopener ugc nofollow" target="_blank">这篇</a>博客文章作为快速入门。</p><p id="f6e7" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在我们有了 B 的绘制，我们根据 B 从反向伽马分布中绘制 sigma。从具有自由度的反向伽马分布中采样一个随机变量</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/4b2931a9a001e5cb70caa34f1f9a650d.png" data-original-src="https://miro.medium.com/v2/resize:fit:36/format:webp/1*WHEzDtf6cfy361ZhTgn6EQ.png"/></div></figure><p id="8299" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">和规模</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi om"><img src="../Images/5c039f52d69717279e1b0f62221ac726.png" data-original-src="https://miro.medium.com/v2/resize:fit:26/format:webp/1*2Hn-8tQu99tkzFYlNssYqw.png"/></div></figure><p id="0cff" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以从标准正态分布 z0 ~ N(0，1)中抽取 T 个变量，然后进行如下调整</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi on"><img src="../Images/15be7ce85f5bbb1aab13e6f5333eb4b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:204/format:webp/1*UISeHxXI9WWi8-68t5MrEg.png"/></div></figure><p id="a749" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">z 现在是从正确的反向伽马分布中提取的。</p><p id="e1f8" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">下面的代码将我们提取的系数存储到 out 矩阵中。然后，我们使用这些绘图来创建我们的预测。该代码实际上创建了一个名为 yhat 的矩阵，用于存储我们对未来 12 个时期的预测(因为我们使用季度数据，所以是 3 年)。我们预测提前一步的等式可以写成</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/5b7a010da9fc7a4f5991ea2e6e48b369.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*xG6_WsAtmI-yu4V-04DWyQ.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Forecast equation</figcaption></figure><p id="2087" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">一般来说，我们需要一个大小为<strong class="kd jf"> <em class="na"> n+p </em> </strong>的矩阵，其中 n 是我们希望预测的周期数，p 是 AR 中使用的滞后数。预测只是一个 AR(2)模型，每个周期都有随机冲击，这是基于我们对 sigma 的提取。好了，这就是 Gibbs 抽样器代码。</p><p id="0442" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在我们可以开始看看算法产生了什么。下面的代码提取了我们需要的系数，这些系数对应于 coef 矩阵的列。每一行都给出了吉布斯采样器每次采样的参数值。<strong class="kd jf"> <em class="na">计算这些变量中每一个的平均值给我们提供了每个系数</em> </strong>分布的后验平均值的近似值。这种分布对于假设检验等其他统计技术非常有用，也是采用贝叶斯方法建模的另一个优势。下面我用 ggplot2 绘制了系数的后验分布。我们可以看到，它们非常类似于正态分布，这在我们定义了正态先验和似然函数的情况下是有意义的。我们参数的后验均值如下:</p><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div class="gh gi np"><img src="../Images/8d18a3f41720daaa025405a8bb7a3e4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:274/format:webp/1*oUkHAgiLfv9h3iWWmmGZUQ.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Posterior Means of Parameters</figcaption></figure><pre class="ml mm mn mo gt nq nr ns nt aw nu bi"><span id="9e20" class="nv li je nr b gy nw nx l ny nz">const &lt;- mean(coef[,1])<br/>beta1 &lt;- mean(coef[,2])<br/>beta2 &lt;- mean(coef[,3])<br/>sigma &lt;- mean(coef[,4])</span><span id="97b2" class="nv li je nr b gy oa nx l ny nz">qplot(coef[,1], geom = "histogram", bins = 45, main = 'Distribution of Constant',<br/>      colour="#FF9999")<br/>qplot(coef[,2], geom = "histogram", bins = 45,main = 'Distribution of Beta1',<br/>      colour="#FF9999")<br/>qplot(coef[,3], geom = "histogram", bins = 45,main = 'Distribution of Beta2',<br/>      colour="#FF9999")<br/>qplot(coef[,4], geom = "histogram", bins = 45,main = 'Distribution of Sigma',<br/>      colour="#FF9999")</span></pre><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi op"><img src="../Images/cb215b6d6dad243551fa138af3ef9ecf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RbXgO4yI_GMrlMa34Hy_lA.png"/></div></div></figure><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi op"><img src="../Images/037a46898e4f7cab45a054bec3e31a9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YPrcI0JJdWKa8U7-8v_HGg.png"/></div></div></figure><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi op"><img src="../Images/cb979eefd39fd05d5f2d2b8edcbaae08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MeF7p21HA4du-DkFqKlEqQ.png"/></div></div></figure><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi op"><img src="../Images/1491e93d7bcf4fe4939c529bacb05d3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HnznYVybaluNPNOF3LmqKQ.png"/></div></div></figure><p id="e0ad" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来我们要做的是使用这些参数来绘制我们的预测，并围绕这些预测构建我们的可信区间。</p></div><div class="ab cl la lb hx lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="im in io ip iq"><h1 id="26e9" class="lh li je bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">绘制我们的预测</h1><p id="d3f5" class="pw-post-body-paragraph kb kc je kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">以下是对 3 年 GDP 同比增长的预测。请注意，使用贝叶斯分析使我们能够创建具有可信区间的预测，这对于突出我们预测的不确定性非常有用。请注意，这不同于置信区间，其解释略有不同。如果我们采用频率主义的方法，例如运行一个实验 100 次，我们会期望我们的真实参数值在 100 个实验中有 95 个在这个范围内。相比之下，贝叶斯方法被解释为真正的参数值以 95%的概率包含在这个范围内。这种差异很微妙，但非常重要。</p><pre class="ml mm mn mo gt nq nr ns nt aw nu bi"><span id="1625" class="nv li je nr b gy nw nx l ny nz">library(matrixStats); library(ggplot2); library(reshape2)</span><span id="d4fb" class="nv li je nr b gy oa nx l ny nz"><strong class="nr jf">#uantiles for all data points, makes plotting easier<br/></strong>post_means &lt;- colMeans(coef)<br/>forecasts_m &lt;- as.matrix(colMeans(forecasts))</span><span id="5a1f" class="nv li je nr b gy oa nx l ny nz"><strong class="nr jf">#Creating error bands/credible intervals around our forecasts</strong><br/>error_bands &lt;- colQuantiles(forecasts,prob = c(0.16,0.84))<br/>Y_temp = cbind(Y,Y)</span><span id="5e5d" class="nv li je nr b gy oa nx l ny nz">error_bands &lt;- rbind(Y_temp, error_bands[3:dim(error_bands)[1],])<br/>all &lt;- as.matrix(c(Y[1:(length(Y)-2)],forecasts_m))</span><span id="9afa" class="nv li je nr b gy oa nx l ny nz">forecasts.mat &lt;- cbind.data.frame(error_bands[,1],all, error_bands[,2])<br/>names(forecasts.mat) &lt;- c('lower', 'mean', 'upper')</span><span id="672f" class="nv li je nr b gy oa nx l ny nz"><strong class="nr jf"># create date vector for plotting</strong><br/>Date &lt;- seq(as.Date('1948/07/01'), by = 'quarter', length.out = dim(forecasts.mat)[1])</span><span id="7b2a" class="nv li je nr b gy oa nx l ny nz">data.plot &lt;- cbind.data.frame(Date, forecasts.mat)<br/>data_subset &lt;- data.plot[214:292,]<br/>data_fore &lt;- data.plot[280:292,]</span><span id="c7e5" class="nv li je nr b gy oa nx l ny nz">ggplot(data_subset, aes(x = Date, y = mean)) + geom_line(colour = 'blue', lwd = 1.2) + geom_ribbon(data = data_fore,<br/>aes(ymin = lower, ymax = upper , colour = "bands", alpha = 0.2))</span></pre><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi oq"><img src="../Images/bfd9aaa1245ccb0d921ae7b733cd4b3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E8X4V30_QH_PaETuxhLwuQ.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">GDP Forecast</figcaption></figure><p id="1338" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">上面的代码计算了我们预测的 16 和 84 个百分点，用作可信区间。我们将这些列与我们的预测相结合，然后使用 ggplot 和 geom_ribbon 绘制数据子集，以绘制预测的间隔。上面的情节看起来相当不错，但我想让这个更漂亮一点。</p><p id="deda" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我发现了一个非常有用的<a class="ae kz" href="https://gjabel.wordpress.com/2013/04/24/bank-of-england-fan-charts-in-r/" rel="noopener ugc nofollow" target="_blank">博客</a>帖子，它创建了与英国央行通胀报告非常相似的粉丝图表。我使用的库叫做<strong class="kd jf">扇形图</strong>，它可以让你绘制出我们预测分布的不同百分位数，看起来比上一张图好一点。</p><pre class="ml mm mn mo gt nq nr ns nt aw nu bi"><span id="9438" class="nv li je nr b gy nw nx l ny nz">library(fanplot)<br/>forecasts_mean &lt;- as.matrix(colMeans(out2))<br/>forecast_sd &lt;- as.matrix(apply(out2,2,sd))<br/>tt &lt;- seq(2018.25, 2021, by = .25)<br/>y0 &lt;- 2018.25<br/>params &lt;- cbind(tt, forecasts_mean[-c(1,2)], forecast_sd[-c(1,2)])<br/>p &lt;- seq(0.10, 0.90, 0.05)</span><span id="1421" class="nv li je nr b gy oa nx l ny nz"><strong class="nr jf"># Calculate Percentiles</strong><br/>k = nrow(params)<br/>gdp &lt;- matrix(NA, nrow = length(p), ncol = k)<br/>for (i in 1:k) <br/>    gdp[, i] &lt;- qsplitnorm(p, mode = params[i,2], <br/>                           sd = params[i,3])</span><span id="517d" class="nv li je nr b gy oa nx l ny nz"><strong class="nr jf"># Plot past data</strong><br/>Y_ts &lt;- ts(data_subset$mean, frequency=4, start=c(2001,1))<br/>plot(Y_ts, type = "l", col = "tomato", lwd = 2.5, <br/>     xlim = c(y0 - 17, y0 + 3), ylim = c(-4, 6), <br/>     xaxt = "n", yaxt = "n", ylab="")</span><span id="a1be" class="nv li je nr b gy oa nx l ny nz"><strong class="nr jf"># background and fanchart</strong><br/>rect(y0-0.25, par("usr")[3] - 1, y0 + 3, par("usr")[4], <br/>     border = "gray90", col = "gray90")<br/>fan(data = gdp, data.type = "values", probs = p, <br/>    start = y0, frequency = 4, <br/>    anchor = Y_ts[time(Y_ts) == y0-.25], <br/>    fan.col = colorRampPalette(c("tomato", "gray90")), <br/>    ln = NULL, rlab = NULL)</span><span id="90a6" class="nv li je nr b gy oa nx l ny nz"><strong class="nr jf"># BOE aesthetics</strong><br/>axis(2, at = -2:5, las = 2, tcl = 0.5, labels = FALSE)<br/>axis(4, at = -2:5, las = 2, tcl = 0.5)<br/>axis(1, at = 2000:2021, tcl = 0.5)<br/>axis(1, at = seq(2000, 2021, 0.25), labels = FALSE, tcl = 0.2)<br/>abline(h = 0)<br/>abline(v = y0 + 1.75, lty = 2) #2 year line</span></pre><figure class="ml mm mn mo gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi op"><img src="../Images/6f2840b93308c41adeb82aec07b19e58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IUtkQsuSGZhtkPnh9OSt8w.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">GDP Forecasts</figcaption></figure><h1 id="8349" class="lh li je bd lj lk nc lm ln lo nd lq lr ls ne lu lv lw nf ly lz ma ng mc md me bi translated">结论</h1><p id="0719" class="pw-post-body-paragraph kb kc je kd b ke mf kg kh ki mg kk kl km mh ko kp kq mi ks kt ku mj kw kx ky im bi translated">我们的预测似乎相当乐观，平均预测到 2021 年，年增长率在 3%左右。似乎还有相当大的上行风险，95%的可信区间将升至近 5%。图表显示，在这段时间内出现负增长的可能性极小，这很有意思，从美国目前的扩张性经济政策来看，这可能是正确的。正如你所看到的，置信区间相当大，表明在预测期内 GDP 增长值的分布范围很广。我们可以使用许多其他类型的模型来代替，并可能获得更准确的预测，如贝叶斯 VAR 或使用许多其他经济变量的动态因素模型。虽然可能更准确，但这些模型更复杂，也更难编码。为了介绍贝叶斯回归并获得对这种方法的直观理解，AR 模型是完全合理的。</p><p id="c1b1" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我认为重要的是要说明为什么我选择从头开始做这种模型，而做这种类型的预测显然有更容易和更少痛苦的方法。我倾向于发现，对我来说，学习像这样复杂的东西的绝对最好的方法是尝试从头开始复制算法。这确实强化了我在理论上所学到的东西，并迫使我将它应用到实际环境中，如果我没有完全理解这个主题，这可能会非常困难。我还发现，这种方法让事情在我脑海中停留的时间更长。实际上，我可能不会使用这段代码，因为它很容易出错，而且很难调试(正如我已经发现的那样)，但我认为这是一种非常有效的学习方法。虽然这显然比仅仅找到一个 R 或 Python 的包要花更多的时间，但花时间一步一步地完成它的好处最终会更大，我会向任何试图学习或理解不同模型和算法如何工作的人推荐它。</p><p id="e137" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">好了，伙计们，这篇文章到此结束。我希望你们都喜欢它，并了解了一些贝叶斯统计以及我们如何在实践中使用它。如果您有任何问题，欢迎在下面发帖或通过 LinkedIn 与我联系。</p><p id="b10b" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">下面的课程很好地概述了机器学习中使用的贝叶斯方法，我推荐给任何想提高这方面知识的人。</p><p id="125c" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="na">推荐课程:</em> <a class="ae kz" href="https://click.linksynergy.com/link?id=z2stMJEP3T4&amp;offerid=759505.11503135374&amp;type=2&amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fbayesian-methods-in-machine-learning" rel="noopener ugc nofollow" target="_blank"> <em class="na">贝叶斯机器学习方法</em> </a></p><p id="85f6" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">链接到 Kaggle 内核:<a class="ae kz" href="https://www.kaggle.com/dfoly1/bayesian-regression-blog-post" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/dfoly1/bayesian-regression-blog-post</a></p><p id="66a8" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="na">注意:这篇文章中的一些链接是附属链接。</em></p></div></div>    
</body>
</html>