<html>
<head>
<title>Detecting vehicles using machine learning and computer vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习和计算机视觉检测车辆</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/detecting-vehicles-using-machine-learning-and-computer-vision-e319ee149e10?source=collection_archive---------2-----------------------#2017-04-25">https://towardsdatascience.com/detecting-vehicles-using-machine-learning-and-computer-vision-e319ee149e10?source=collection_archive---------2-----------------------#2017-04-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="ce48" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">来自<a class="ae kl" href="http://udacity.com/drive" rel="noopener ugc nofollow" target="_blank"> Udacity自动驾驶汽车课程</a>的最后一个项目是创建一个软件管道，它能够从汽车上的前置摄像头识别视频中的汽车。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/524dee71172da04c1bc3f7159245e31c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OoPk0KYO5UV3xai20euEnA.jpeg"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">A snapshot from the final output of the project</figcaption></figure><p id="ddd0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">课程材料建议使用有点过时的方法来检测车辆，这是我在项目中途通过阅读这篇关于自动驾驶汽车的最先进的计算机视觉的<a class="ae kl" href="https://t.co/VFxlrhQ70C" rel="noopener ugc nofollow" target="_blank">伟大论文</a>而发现的。报纸上一小段:</p><blockquote class="lc ld le"><p id="7dee" class="jn jo lf jp b jq jr js jt ju jv jw jx lg jz ka kb lh kd ke kf li kh ki kj kk ij bi translated">在Dalal &amp; Triggs (2005)的工作中，线性支持<br/>向量机(SVMs)与<br/>方向直方图(HOG)特征相结合，最大化来自线性决策边界的所有<br/>样本的余量，已经成为流行的<br/>分类工具。然而，所有以前的方法都依赖于难以设计的手工制作的特征。<strong class="jp ir">随着深度学习的复兴<br/>，卷积神经网络已经<br/>自动化了这项任务，同时显著提升了性能</strong>。</p></blockquote><p id="4173" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">事实证明，深度神经网络优于我使用的方法(线性支持向量机结合梯度方向直方图)。我一定会回到这个项目中，在这个问题上尝试这个列表中的一些最佳表现者:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lj"><img src="../Images/ebeb248cb9240a560295afd63b903f3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1NE59oU2jDTeNMNcgjdngg.jpeg"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Table taken from <a class="ae kl" href="https://arxiv.org/pdf/1704.05519.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1704.05519.pdf</a></figcaption></figure><p id="ada4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">检测道路上的车辆的过程可以总结为以下步骤:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/0491d4506ddb16135d7c162866b0a1cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:442/format:webp/1*IIJPLy-B_9PtgfNVGFX3sg.jpeg"/></div></figure><h1 id="1029" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">训练数据分析</h1><p id="641d" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">训练数据由Udacity提供，由不同角度的<a class="ae kl" href="https://s3.amazonaws.com/udacity-sdc/Vehicle_Tracking/vehicles.zip" rel="noopener ugc nofollow" target="_blank">汽车</a>(8792)和<a class="ae kl" href="https://s3.amazonaws.com/udacity-sdc/Vehicle_Tracking/non-vehicles.zip" rel="noopener ugc nofollow" target="_blank">非汽车</a> (8968)物体图像组成。这里有两个例子:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi mo"><img src="../Images/47cdb9d0f0ea8327285da02403373fbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ThfiUs-X94C0W4LiGlU5AA.jpeg"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Examples from the training data set</figcaption></figure><h1 id="3ab9" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">特征抽出</h1><p id="4345" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">为了检测图像上的汽车，我们需要识别唯一代表汽车的<strong class="jp ir">特征</strong>。我们可以尝试使用简单的模板匹配或依赖颜色特征，但这些方法在改变物体的视角和形状时不够健壮。</p><p id="6f5c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了拥有一个健壮的特征集并提高我们的准确率，我们将使用<a class="ae kl" href="https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients" rel="noopener ugc nofollow" target="_blank">梯度方向直方图</a> (HOG)。该特征描述符对流量的动态变化更有弹性。本质上，你应该<strong class="jp ir">把特征想象成你感兴趣的物体的指纹</strong>。</p><p id="d3cd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="http://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.hog" rel="noopener ugc nofollow" target="_blank"> Scikit-image </a> python库为我们提供了计算HOG特征所必需的API。我已经使用<a class="ae kl" href="https://en.wikipedia.org/wiki/YCbCr" rel="noopener ugc nofollow" target="_blank"> YCrCb </a>颜色空间及其所有通道作为猪特征提取的输入。我尝试过其他颜色空间，但YCrCb在训练我的预测模型时给了我最好的准确性。这里有一个车辆和非车辆图像的样本，具有与上述图像相同的HOG特征:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi mp"><img src="../Images/7ad55d9c66601a224dc5d500ea42bdc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IhHW2al_-2z188mS8rylBQ.jpeg"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Extracted HOG features from sample training data</figcaption></figure><p id="8738" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">HOG特征提取基于9个方向，每个单元8个像素，每个块2个单元。增加方向和每个像元的像素参数确实可以缩短预测时间，但模型的准确率会下降。</p><h1 id="c6f9" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">模特培训</h1><p id="91eb" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">为了根据我们的特征集检测汽车，我们需要一个预测模型。对于这种特殊情况，我们将使用<a class="ae kl" href="https://en.wikipedia.org/wiki/Support_vector_machine" rel="noopener ugc nofollow" target="_blank">线性支持向量机</a>(线性支持向量机)。这是一个监督学习模型，在我们训练它之后，它将能够分类某物是否是一辆汽车。</p><p id="1f6e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用<a class="ae kl" href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank">标准缩放器</a>将HOG特征缩放至零均值和单位方差。</p><p id="7726" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我将提供的数据集分为训练集(80%)和测试集(20%)。在训练开始之前，图片也进行了洗牌。最终提取的HOG特征在YCrCb颜色空间上的线性支持向量机模型达到了98.06%的准确率。</p><h1 id="56f9" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">推拉窗</h1><p id="2656" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">一旦我们有了预测模型，就该在测试图像上使用它了。预测模型将应用于一种称为滑动窗口的特殊技术。使用这种技术，我们将在图像的子区域上运行预测模型，该子区域被划分为一个网格。</p><p id="7694" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了提高这种方法的稳健性，我们将添加多个网格，预测模型将遍历这些网格。我们这样做是因为汽车可以根据其在道路上的位置以各种大小出现在图像上。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi mq"><img src="../Images/8ae2d23f9a69608a794b4266e0ba1150.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5VnOJago9j8TTaQ7HUTpPA.jpeg"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Multi-window appraoch for sliding window technique</figcaption></figure><p id="7e58" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是这个概念应用于我们的测试图像时的样子:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/146ae5a964bac1b0cacc468adb2d4d98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*6MxTVwcQW-4SGuYnAs_xTQ.jpeg"/></div></figure><p id="b12b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我使用了不同的窗口尺寸(从128x128的靠近汽车的区域到64x64的远离汽车的区域)。窗口重叠设置为65%。</p><h1 id="b367" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">消除误报</h1><p id="f309" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">为了提高最终输出的准确性，我们将尝试在相似区域找到感兴趣对象的多个匹配项。这种方法相当于创建一个热图。</p><p id="9f29" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下一步是引入阈值，为了将热图中的特定命中计数接受为检测到的汽车，需要满足该阈值。在我们的例子中，阈值的值为2。</p><p id="2002" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一个应用热图并将其阈值设定为特定值的示例。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ms"><img src="../Images/5a0205d5b293dc5d559fdc35e7087fea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HBdTVrzqGgN9eRPheyu7rw.jpeg"/></div></div></figure><h1 id="b510" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">最后结局</h1><p id="9afd" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">最终结果并不完美，但管道本身显示出良好的潜力。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mt mu l"/></div></figure><h1 id="0878" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">结论</h1><p id="da8f" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">如果我有机会重新做这个项目，我可能会选择深度神经网络方法。我花了相当多的时间寻找正确的色彩空间、HOG参数和窗口幻灯片的大小。</p><p id="97f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">管道的性能不是很大，可以改进。深度神经网络方法将具有更好的性能数字。</p><p id="743d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于这种汽车检测方法是基于摄像头的，这种传感器很容易遇到常见的挑战(能见度低、反光等)。).</p><p id="6039" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">项目可以在我的<a class="ae kl" href="https://github.com/bdjukic/CarND-Vehicle-Detection" rel="noopener ugc nofollow" target="_blank"> Github </a>个人资料中找到:</p><div class="mv mw gp gr mx my"><a href="https://github.com/bdjukic/CarND-Vehicle-Detection" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd ir gy z fp nd fr fs ne fu fw ip bi translated">bdjukic/CarND-车辆检测</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">CarND-Vehicle-Detection -车辆检测项目</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">github.com</p></div></div><div class="nh l"><div class="ni l nj nk nl nh nm kw my"/></div></div></a></div></div></div>    
</body>
</html>