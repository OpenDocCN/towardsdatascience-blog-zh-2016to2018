<html>
<head>
<title>Learning computer vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">学习计算机视觉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learning-computer-vision-41398ad9941f?source=collection_archive---------5-----------------------#2018-11-24">https://towardsdatascience.com/learning-computer-vision-41398ad9941f?source=collection_archive---------5-----------------------#2018-11-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="cd89" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最近我读了很多关于计算机视觉的书并做了很多实验，这里介绍了在这个领域中学习和使用什么是有趣的。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/82846accf910856ffd35b659fa278b3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*We8Aye1G6wLXOCqu.jpg"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Image segmentation for autonomous driving</figcaption></figure><p id="8474" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">近年来，计算机视觉取得了很大进步。这些是我将在此提及的主题:</p><p id="338c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">技术:</p><ul class=""><li id="278a" class="lb lc iq jp b jq jr ju jv jy ld kc le kg lf kk lg lh li lj bi translated">人脸检测:Haar，HOG，MTCNN，Mobilenet</li><li id="22f6" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">人脸识别:CNN，Facenet</li><li id="3873" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">物体识别:alexnet，inceptionnet，resnet</li><li id="cf80" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">迁移学习:在一个新的主题上用很少的资源重新训练大的神经网络</li><li id="ba5b" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">图像分割:rcnn</li><li id="58f0" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">开始</li><li id="de0e" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">计算机视觉硬件:选什么，GPU 重要</li><li id="7287" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">集成视觉的 UI 应用程序:ownphotos</li></ul><p id="ef69" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">应用:</p><ul class=""><li id="0f04" class="lb lc iq jp b jq jr ju jv jy ld kc le kg lf kk lg lh li lj bi translated">个人照片组织</li><li id="2561" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">自动驾驶汽车</li><li id="5a03" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">自主无人机</li><li id="963d" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">求解验证码/ OCR</li><li id="2d90" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">为基于图片的网站/应用程序过滤图片</li><li id="34ec" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">为应用程序自动标记图片</li><li id="1af6" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">从视频(电视节目、电影)中提取信息</li><li id="1a56" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">视觉问答</li><li id="6e82" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">艺术</li></ul><p id="aa24" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">关注的人:</p><ul class=""><li id="ace7" class="lb lc iq jp b jq jr ju jv jy ld kc le kg lf kk lg lh li lj bi translated">重要的深度学习创始人:andrew ng、yann lecun、bengio yoshua、hinton joffrey</li><li id="0e0c" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">亚当·盖特基<a class="ae lp" href="https://medium.com/@ageitgey" rel="noopener">https://medium.com/@ageitgey</a>有很多关于视觉的有趣文章，比如<a class="ae lp" href="https://medium.com/@ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-c3cffc121d78" rel="noopener">https://medium . com/@ ageitgey/machine-learning-is-fun-part-4-modern-face-recognition-with-deep-learning-C3 cffc 121d 78</a>有完整的人脸检测/对齐/识别管道</li></ul><p id="9c06" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">课程:</p><ul class=""><li id="55e2" class="lb lc iq jp b jq jr ju jv jy ld kc le kg lf kk lg lh li lj bi translated">深度学习@ coursera</li><li id="b052" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">机器学习@ coursera</li></ul><p id="7ad6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">相关字段:</p><ul class=""><li id="353b" class="lb lc iq jp b jq jr ju jv jy ld kc le kg lf kk lg lh li lj bi translated">深度强化学习:参见以 cnn 为输入层的 ppo 和 dqn</li><li id="10c5" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">与 nlp 的互动:lstm 2 cnn</li></ul><h1 id="91f5" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">人脸检测</h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/8241c9e387f50006704ad364eb0081bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*l_UUWLiaUymG9B62.jpg"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Face detection is about placing boxes around faces</figcaption></figure><p id="98dc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">人脸检测就是检测人脸的任务。有几种算法可以做到这一点。</p><p id="301f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">【https://github.com/nodefluxio/face-detector-benchmark】提供了这些方法的速度基准，并带有易于重用的实现代码。</p><h2 id="5f73" class="mp lr iq bd ls mq mr dn lw ms mt dp ma jy mu mv me kc mw mx mi kg my mz mm na bi translated">哈尔分类器</h2><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/3075e559b962148ef4104014704e7577.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/0*Cf5NPwJkNNNuUUMN.jpg"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">haar features</figcaption></figure><p id="9e61" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它们是自 2000 年以来出现在 opencv 中的旧的计算机视觉方法。本文介绍了<a class="ae lp" href="http://wearables.cc.gatech.edu/paper_of_week/viola01rapid.pdf" rel="noopener ugc nofollow" target="_blank">http://wearables . cc . gatech . edu/paper _ of _ week/viola 01 rapid . pdf</a>。</p><p id="5686" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它是一个机器学习模型，具有专门为对象检测选择的特征。Haar 分类器速度快，但准确率低。</p><p id="e530" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<a class="ae lp" href="https://docs.opencv.org/3.4.3/d7/d8b/tutorial_py_face_detection.html" rel="noopener ugc nofollow" target="_blank">https://docs . opencv . org/3 . 4 . 3/D7/d8b/tutorial _ py _ face _ detection . html</a>中查看更长的解释和如何使用它的示例</p><h2 id="0e59" class="mp lr iq bd ls mq mr dn lw ms mt dp ma jy mu mv me kc mw mx mi kg my mz mm na bi translated">HOG:方向梯度直方图</h2><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="ab gu cl nc"><img src="../Images/21c2e473e934e112112b322a469ab2ce.png" data-original-src="https://miro.medium.com/v2/format:webp/1*6xgev0r-qn4oR88FrW6fiA.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Histogram of oriented gradients</figcaption></figure><p id="1f71" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">HOG 是一种较新的生成目标检测特征的方法:从 2005 年开始使用。它是基于计算图像像素的梯度。这些特征然后被馈送到机器学习算法，例如 SVM。它比 haar 分类器有更好的精度。</p><p id="2127" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它的一个实现在 dlib 中。它在人脸识别(<a class="ae lp" href="https://github.com/ageitgey/face_recognition" rel="noopener ugc nofollow" target="_blank">https://github.com/ageitgey/face_recognition</a>)库中。</p><h2 id="4bf2" class="mp lr iq bd ls mq mr dn lw ms mt dp ma jy mu mv me kc mw mx mi kg my mz mm na bi translated">MTCNN</h2><p id="489e" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">一种利用细胞神经网络变异检测图像的新方法。精度更高，但速度稍慢。参见<a class="ae lp" href="https://kpzhang93.github.io/MTCNN_face_detection_alignment/index.html" rel="noopener ugc nofollow" target="_blank">https://KP Zhang 93 . github . io/mt CNN _ face _ detection _ alignment/index . html</a></p><h2 id="6545" class="mp lr iq bd ls mq mr dn lw ms mt dp ma jy mu mv me kc mw mx mi kg my mz mm na bi translated">MobileNet</h2><p id="603f" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">目前最好最快的人脸检测方法。基于通用移动网络架构。参见 https://arxiv.org/abs/1704.04861 的<a class="ae lp" href="https://arxiv.org/abs/1704.04861" rel="noopener ugc nofollow" target="_blank"/></p><h1 id="1403" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">目标检测</h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="ab gu cl nc"><img src="../Images/548a9d139ef382c872492beba9450302.png" data-original-src="https://miro.medium.com/v2/format:webp/1*SthhLuiCOtNAN7p8mwdhtQ.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Object detection on many kind of objects</figcaption></figure><p id="5e36" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">可以使用类似于面部检测的方法来实现对象检测。</p><p id="3b00" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里有两篇文章介绍了实现这一目标的最新方法。这些方法有时甚至还提供对象的类别(实现对象识别) :</p><ul class=""><li id="ceb6" class="lb lc iq jp b jq jr ju jv jy ld kc le kg lf kk lg lh li lj bi translated"><a class="ae lp" rel="noopener" target="_blank" href="/review-r-fcn-positive-sensitive-score-maps-object-detection-91cd2389345c">https://towards data science . com/review-r-fcn-positive-sensitive-score-maps-object-detection-91cd 2389345 c</a>r-fcn</li><li id="54e1" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated"><a class="ae lp" rel="noopener" target="_blank" href="/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e">https://towards data science . com/r-CNN-fast-r-CNN-faster-r-CNN-yolo-object-detection-algorithms-36d 53571365 e</a>r-CNN、fast r-cnn、faster r-cnn 和 yolo 的对比</li></ul><h1 id="cd7b" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">卷积神经网络</h1><p id="6431" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">深度学习的最新进展已经看到新的架构取得了很大的成功。</p><p id="40bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用许多卷积层的神经网络就是其中之一。卷积层利用图像的 2D 结构在神经网络的下一层中生成有用的信息。关于什么是卷积的详细解释，请参见<a class="ae lp" rel="noopener" target="_blank" href="/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1">https://towards data science . com/intuitive-understanding-convolutions-for-deep-learning-1 F6 f 42 faee 1</a>。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="ab gu cl nc"><img src="../Images/7ac396ba31646ccdb59fd0b7071ec09e.png" data-original-src="https://miro.medium.com/v2/1*Zx-ZMLKab7VOCQTxdZ1OAw.gif"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">A convolution layer</figcaption></figure><h1 id="a808" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">物体识别</h1><p id="c93d" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">物体识别是将物体分类的一般问题(如猫、狗等)</p><p id="22b9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基于卷积深度神经网络已经被用于在这个任务上获得很好的结果。</p><p id="1792" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">ILSVR 大会已经在 ImageNet(<a class="ae lp" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank">http://www.image-net.org/</a>上举办了比赛，ImageNet 是一个数据库，里面有许多带有诸如猫、狗、..)</p><p id="1c9c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">越成功的神经网络已经使用越来越多的层。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/81eaeb20fd0e51a993fb786e85f737aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/0*JIZJ0h7TFi8v1lew.png"/></div></figure><p id="95e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">ResNet 架构是迄今为止最好的对象分类架构。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="ab gu cl nc"><img src="../Images/55a42b0ee1c90a780be5f5ad24a0e80c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*2ns4ota94je5gSVjrpFq3A.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Resnet architecture</figcaption></figure><p id="b46c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要对它进行适当的训练，需要使用数百万张图像，即使使用几十块昂贵的 GPU 也要花费大量时间。</p><p id="a42c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就是为什么在如此大的数据集上不需要每次都重新训练的方法非常有用的原因。迁移学习和嵌入就是这样的方法。</p><p id="ae68" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">resnet 的预训练模型在<a class="ae lp" href="https://github.com/tensorflow/tensor2tensor#image-classification" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/tensor 2 tensor # image-class ification</a>中提供</p><h1 id="03c0" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">人脸识别</h1><p id="1ee8" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">人脸识别就是要弄清楚谁是 T2，谁是 T3。</p><h2 id="0df2" class="mp lr iq bd ls mq mr dn lw ms mt dp ma jy mu mv me kc mw mx mi kg my mz mm na bi translated">历史方法</h2><p id="c4fc" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">解决该任务的传统方法是应用标准机器学习(例如 svm)的特征工程，或者应用深度学习方法进行对象识别。</p><p id="9c9e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些方法的问题是它们需要每个人的大量数据。实际上，这些数据并不总是可用的。</p><h2 id="bd2f" class="mp lr iq bd ls mq mr dn lw ms mt dp ma jy mu mv me kc mw mx mi kg my mz mm na bi translated">Facenet</h2><p id="8d83" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">谷歌研究人员于 2015 年在 https://arxiv.org/abs/1503.03832<a class="ae lp" href="https://arxiv.org/abs/1503.03832" rel="noopener ugc nofollow" target="_blank">推出了 Facenet。提出了一种不需要为每个人准备大量人脸样本的人脸识别方法。</a></p><p id="2840" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它的工作方式是通过拍摄大量人脸的照片数据集(比如 http://vis-www.cs.umass.edu/lfw/的照片)。</p><p id="ed2a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后采用现有的计算机视觉架构，如 inception(或 resnet ),然后用计算人脸嵌入的层来替换对象识别 NN 的最后一层。</p><p id="e92e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于数据集中的每个人，(阴性样本、阳性样本、第二个阳性样本)选择(使用试探法)三个一组的面部，并馈送给神经网络。这产生了 3 个嵌入。在这 3 个嵌入中，计算三元组损失，这最小化正样本和任何其它正样本之间的距离，并且最大化位置样本和任何其它负样本之间的距离。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="ab gu cl nc"><img src="../Images/844f1a327c536f604aff8970ab80d4a3.png" data-original-src="https://miro.medium.com/v2/format:webp/0*AX2TSZNk19_gDgTN.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Triplet loss</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="ab gu cl nc"><img src="../Images/330c03688b5c481f3559659b6dc029f1.png" data-original-src="https://miro.medium.com/v2/format:webp/1*n1R8VMyDRw3RNO3JULYBpQ.png"/></div></figure><p id="b5a9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最终结果是，每个人脸(甚至是不存在于原始训练集中的人脸)现在都可以被表示为一个嵌入(128 个数的向量),它与其他人的人脸的嵌入有很大的距离。</p><p id="c38b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，这些嵌入可以用于任何机器学习模型(即使是像 knn 这样简单的模型)来识别人。</p><p id="75b3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">关于 facenet 和 face embeddings 非常有趣的一点是，使用它，你可以只通过一些人的照片，甚至是一张照片来识别他们。</p><p id="2728" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">查看实现它的库:<a class="ae lp" href="https://github.com/ageitgey/face_recognition" rel="noopener ugc nofollow" target="_blank">https://github.com/ageitgey/face_recognition</a></p><p id="bc69" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是它的张量流实现:<a class="ae lp" href="https://github.com/davidsandberg/facenet" rel="noopener ugc nofollow" target="_blank">https://github.com/davidsandberg/facenet</a></p><p id="3763" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是人脸识别管道背后的想法的一个很酷的应用，而不是识别熊的脸:<a class="ae lp" href="https://hypraptive.github.io/2017/01/21/facenet-for-bears.html" rel="noopener ugc nofollow" target="_blank">https://hypractive . github . io/2017/01/21/face net-for-bears . html</a></p><h1 id="21ce" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">迁移学习</h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/3d67d7bd2a6fa382cfd3b58e35d584a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/0*96VYf9IANbvTeAC4.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Retrain quickly an accurate neural network on a custom dataset</figcaption></figure><p id="7665" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">训练像 resnet 这样的非常深度的神经网络是非常耗费资源的，需要大量的数据。</p><p id="4ca5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">计算机视觉是高度计算密集型的(在多个 gpu 上进行数周的训练)，需要大量数据。为了解决这个问题，我们已经讨论过计算人脸的一般嵌入。另一种方法是利用现有网络，在另一个数据集上只重新训练它的几个 it 层。</p><p id="98f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是它的教程:<a class="ae lp" href="https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0" rel="noopener ugc nofollow" target="_blank"> codelab 教程</a>。它建议你重新训练一个初始模型来训练未知的花类。</p><p id="0a67" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae lp" href="https://medium.com/@14prakash/transfer-learning-using-keras-d804b2e04ef8" rel="noopener">https://medium . com/@ 14 Prakash/transfer-learning-using-keras-d 804 b 2e 04 ef 8</a>提出了在进行迁移学习时，应该重新训练哪一层的良好指南。</p><h1 id="3124" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">图象分割法</h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/5bd3af410a6b44e36f70cdb27b132487.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rq3Z4SZ0YXELDOvZ.jpg"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Image segmentation for autonomous driving</figcaption></figure><p id="c2a0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">图像分割是一个令人印象深刻的新任务，近年来已经成为可能。它包括识别图像的每个像素。</p><p id="8a24" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该任务与目标检测相关。实现它的一种算法是 mask r-cnn，更多详情参见本文<a class="ae lp" href="https://medium.com/@jonathan_hui/image-segmentation-with-mask-r-cnn-ebe6d793272" rel="noopener">https://medium . com/@ Jonathan _ hui/image-segmentation-with-mask-r-CNN-ebe6d 793272</a></p><h1 id="0ab9" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">开始</h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="ab gu cl nc"><img src="../Images/bd35fcb66892e036660f692e2815751f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Yw2KxjmIkj8yqS-ykLCQCQ.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk"><a class="ae lp" href="https://arxiv.org/abs/1809.11096" rel="noopener ugc nofollow" target="_blank">Large scale GAN</a></figcaption></figure><p id="d38d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由 ian goodfellow 介绍的生成式广告网络<a class="ae lp" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">是一个由两部分组成的神经网络体系结构:一个鉴别器和一个生成器。</a></p><ul class=""><li id="81b2" class="lb lc iq jp b jq jr ju jv jy ld kc le kg lf kk lg lh li lj bi translated">鉴别器检测一张图片是否是一个类，它通常已经在一个对象分类数据集上进行过预训练。</li><li id="e5b2" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">生成器为给定的类生成图像</li></ul><p id="0478" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">生成器的权重在学习期间被调整，以便产生鉴别器不能从该类的真实图像中区分的图像。</p><p id="272f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是迄今为止最大的氮化镓制作的图像的例子<a class="ae lp" href="https://arxiv.org/abs/1809.11096" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1809.11096</a></p><p id="920e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">参见<a class="ae lp" href="https://github.com/eriklindernoren/Keras-GAN" rel="noopener ugc nofollow" target="_blank">https://github.com/eriklindernoren/Keras-GAN</a>的 keras 中 GAN 的实现</p><h1 id="90ea" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">计算机视觉硬件</h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nk"><img src="../Images/5deeb3cf79f8eb13839b3a33c8f49157.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S4XP66xrxygXuzjl.jpg"/></div></div></figure><p id="2855" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">训练大模型，需要大量的资源。有两种方法可以实现这一点。首先是使用云服务，比如 google cloud 或者 aws。第二种方式是自己搭建一台带 GPU 的电脑。</p><p id="8f45" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">只要 1000 美元，就有可能建造一台像样的机器来训练深度学习模型。</p><p id="ea1a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<a class="ae lp" href="https://hypraptive.github.io/2017/02/13/dl-computer-build.html" rel="noopener ugc nofollow" target="_blank">https://hypractive . github . io/2017/02/13/dl-computer-build . html</a>中阅读更多详细信息</p><h1 id="b2c7" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">UI 中的视觉</h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nl"><img src="../Images/9bef4cb1b145dacb22dbb5fff07c58d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bKB1lnTgUrRfCrpl.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Face dashboard of ownphotos</figcaption></figure><p id="6e1c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae lp" href="https://github.com/hooram/ownphotos" rel="noopener ugc nofollow" target="_blank"> Ownphotos </a>是一个令人惊叹的用户界面，允许你导入照片，自动计算人脸嵌入，进行物体识别和人脸识别。</p><p id="57b1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它使用:</p><ul class=""><li id="79a3" class="lb lc iq jp b jq jr ju jv jy ld kc le kg lf kk lg lh li lj bi translated">人脸识别:<a class="ae lp" href="https://github.com/ageitgey/face_recognition" rel="noopener ugc nofollow" target="_blank">人脸识别</a></li><li id="0edf" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">物体检测:<a class="ae lp" href="https://github.com/jcjohnson/densecap" rel="noopener ugc nofollow" target="_blank"> densecap </a>，<a class="ae lp" href="http://places.csail.mit.edu/" rel="noopener ugc nofollow" target="_blank"> places365 </a></li></ul><h1 id="dd1f" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">应用程序</h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi nm"><img src="../Images/c8104adb753272d5650a49cf7ac3c132.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sT9nWAypwSttkNDC.jpg"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk"><a class="ae lp" href="http://www.visualqa.org/" rel="noopener ugc nofollow" target="_blank">Visual question answering</a></figcaption></figure><p id="d66e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">计算机视觉有许多应用:</p><ul class=""><li id="ee41" class="lb lc iq jp b jq jr ju jv jy ld kc le kg lf kk lg lh li lj bi translated">个人照片组织</li><li id="801a" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">自动驾驶汽车</li><li id="97aa" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">自主无人机</li><li id="2199" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">求解验证码/ OCR</li><li id="7d07" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">为基于图片的网站/应用程序过滤图片</li><li id="946b" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">为应用程序自动标记图片</li><li id="b258" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">从视频(电视节目、电影)中提取信息</li><li id="bba3" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">视觉问答:结合自然语言处理和计算机视觉</li><li id="96b9" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">艺术:甘</li></ul><h1 id="a1e5" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">结论</h1><p id="d070" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy nf ka kb kc ng ke kf kg nh ki kj kk ij bi translated">正如我们在这里看到的，有许多新的有趣的方法和应用的成功。</p><p id="3663" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我认为人工智能中最有趣的是学习可以重复使用的算法，能够将这些方法应用到越来越多的任务中，而不需要太多的处理能力和数据:</p><ul class=""><li id="bd48" class="lb lc iq jp b jq jr ju jv jy ld kc le kg lf kk lg lh li lj bi translated">迁移学习:它使得重新利用预先训练好的大型神经网络成为可能</li><li id="a79b" class="lb lc iq jp b jq lk ju ll jy lm kc ln kg lo kk lg lh li lj bi translated">嵌入(例如 facenet):无需对这些类进行训练就可以识别许多类</li></ul></div></div>    
</body>
</html>