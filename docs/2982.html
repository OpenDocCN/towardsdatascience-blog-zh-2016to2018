<html>
<head>
<title>Paper Repro: Deep Neuroevolution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文复制:深层神经进化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/paper-repro-deep-neuroevolution-756871e00a66?source=collection_archive---------2-----------------------#2018-03-27">https://towardsdatascience.com/paper-repro-deep-neuroevolution-756871e00a66?source=collection_archive---------2-----------------------#2018-03-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/f6b0c020dd21050200bd2013974eda22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*EwAEtp0IkWYxfkji.jpg"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Obligatory evolution picture. From <a class="ae jy" href="http://www.techcrates.com/evolution-of-computers-and-technology/" rel="noopener ugc nofollow" target="_blank">http://www.techcrates.com/evolution-of-computers-and-technology/</a></figcaption></figure><p id="4b5e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在这篇文章中，我们复制了最近的优步论文“<a class="ae jy" href="https://arxiv.org/abs/1712.06567" rel="noopener ugc nofollow" target="_blank">深度神经进化:遗传算法是训练深度神经网络进行强化学习的一种有竞争力的替代方法</a>”，该论文令人惊讶地表明，在诸如Atari游戏等经过充分研究的问题上，简单的遗传算法有时比表面上先进的强化学习算法表现得更好。</p><p id="95e7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在优步最终用这篇论文解决冻伤问题之前，我们自己将会在冻伤问题上达到艺术表现的状态，这是一个困扰强化学习算法多年的游戏。我们还将学习使用遗传算法训练神经网络的黑暗艺术。</p><p id="ca38" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在某种程度上，这可以被认为是我的深度强化学习的第3部分，但我认为这篇文章也可以独立存在。请注意，与之前的教程不同，这篇文章将使用PyTorch而不是Keras，主要是因为这是我个人选择的，但也因为PyTorch确实更适合这个特定的用例。对于第0至第2部分，请参见:</p><div class="kx ky gp gr kz la"><a href="https://becominghuman.ai/lets-build-an-atari-ai-part-0-intro-to-rl-9b2c5336e0ec" rel="noopener  ugc nofollow" target="_blank"><div class="lb ab fo"><div class="lc ab ld cl cj le"><h2 class="bd ir gy z fp lf fr fs lg fu fw ip bi translated">用深度强化学习打败雅达利！(第0部分:RL简介)</h2><div class="lh l"><h3 class="bd b gy z fp lf fr fs lg fu fw dk translated">2013年末，一家当时名不见经传的公司DeepMind在钢筋领域取得了突破…</h3></div><div class="li l"><p class="bd b dl z fp lf fr fs lg fu fw dk translated">becominghuman.ai</p></div></div><div class="lj l"><div class="lk l ll lm ln lj lo js la"/></div></div></a></div><h1 id="88b6" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">设置环境</h1><blockquote class="mn mo mp"><p id="5956" class="jz ka mq kb b kc kd ke kf kg kh ki kj mr kl km kn ms kp kq kr mt kt ku kv kw ij bi translated">以下内容与DQN (Mnih等人，2015年)相同:(1)数据预处理，(2)网络架构，以及(3)随机环境，以多达30个随机的初始无操作操作开始每一集。</p></blockquote><p id="951a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">很好，所以预处理和我们用DQNs做的一样！那非常方便。提醒一下，这需要做些什么:</p><ul class=""><li id="79e5" class="mu mv iq kb b kc kd kg kh kk mw ko mx ks my kw mz na nb nc bi translated">我们应该使用OpenAI gym的“确定性v4”环境，它们可以自动跳过4帧，这似乎是DQN论文中的标准。</li><li id="b9af" class="mu mv iq kb b kc nd kg ne kk nf ko ng ks nh kw mz na nb nc bi translated">我们应该使国家灰度，并调整其大小为64乘64。我们还应该确保像素值在0和1之间，而不是0和255之间。</li><li id="c7a9" class="mu mv iq kb b kc nd kg ne kk nf ko ng ks nh kw mz na nb nc bi translated">状态应该由我们看到的前4帧组成。</li></ul><p id="d4f5" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我使用OpenCV做了预处理，得到了:</p><figure class="ni nj nk nl gt jr"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="167b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">请注意，我后来意识到，这做了调整大小的双线性插值，而我认为最近邻可能是规范，不清楚这是否可能有很大的影响，但值得注意。</p><p id="d422" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">就效果而言，这是我们看到的转变:</p><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div class="gh gi no"><img src="../Images/740952c91db2e6553d0f139aa061d7f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:374/format:webp/1*3gRpWpQaaDIeltDyNOmpCw.png"/></div></figure><p id="2344" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">变成了:</p><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/3d84fdd3b6066471521378c673b1b7b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/format:webp/1*3zVstpXum2Xq1c-Mj_5NPg.png"/></div></figure><p id="fce9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">基本上就是这样，现在我们只需要堆叠4个这样的元素来得到我们的状态。</p><h1 id="2b6b" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">模型</h1><blockquote class="mn mo mp"><p id="8a68" class="jz ka mq kb b kc kd ke kf kg kh ki kj mr kl km kn ms kp kq kr mt kt ku kv kw ij bi translated">我们使用来自Mnih等人(2015)的更大的DQN架构，该架构包括3个具有32、64和64个信道的卷积层，后面是一个具有512个单元的隐藏层。卷积层使用8 × 8、4 × 4和3 × 3滤波器，步长分别为4、2和1。所有隐藏层之后是整流器非线性(ReLU)。该网络包含超过4M个参数。</p></blockquote><p id="836c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">没有我们以前没见过的，让我们把它写下来！</p><figure class="ni nj nk nl gt jr"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="fff6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">好了，现在我们可以开始有趣的事情了:</p><h1 id="0aa8" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">遗传算法的简单解释</h1><blockquote class="mn mo mp"><p id="c196" class="jz ka mq kb b kc kd ke kf kg kh ki kj mr kl km kn ms kp kq kr mt kt ku kv kw ij bi translated"><em class="iq">一种遗传算法(荷兰，1992；Eiben等人，2003)进化出N个个体的群体P(这里是神经网络参数向量θ，通常称为基因型)。在每一代，对每个θi进行评估，产生一个适合度分数(又名奖励)F(θi)。我们的GA变体执行截断选择，其中前T个个体成为下一代的父母。为了产生下一代，下面的过程重复N-1次:通过替换均匀地随机选择一个父代，并通过对参数向量应用加性高斯噪声来进行变异:θ’=θ+σε其中ε∾N(0，I)。对于每个实验，根据经验确定适当的σ值，如补充信息(SI)表3所述。第n个个体是上一代最佳个体的未修改副本，这种技术称为精英主义。</em></p></blockquote><p id="6cb5" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这对我来说似乎相当清楚，但我将尝试重新解释它:基本上，我们不是随机生成一个网络并使用梯度下降修改其权重，而是随机生成一组网络，构成一个“代”，然后评估它们。当然，他们中的一些人会表现得稍微好一点。我们挑选出表现最好的一个，留给下一代。然后在前几个网络中，我们通过多次复制它们并稍微修改每个副本的权重来创建新一代。因为每次只选择顶级网络，而且因为我们不断更换网络，所以我们的性能似乎应该不断提高，事实上也确实如此！</p><p id="1197" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在我们的例子中，因为我们关注Atari游戏，所以群体大小是5000，截断阈值是10，σ参数是0.005。他们提到的I参数，简单来说就是从一个单位方差的正态分布中抽样(I是单位矩阵)。</p><p id="1344" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">那么，你可能会问，我们什么时候停止世代？优步非常清楚，他们在10亿<strong class="kb ir">帧</strong>后停止，而不是在固定数量的代后，所以我们将确保跟踪我们看到的帧数，一旦超过10亿就停止。提醒一下，神经网络上的帧和前向传递是有区别的，因为每次前向传递运行4帧是标准的(即网络每4帧只选择一个动作)。如果你在OpenAI健身房用了一个<code class="fe nq nr ns nt b">Deterministic-v4</code>，这个4帧的跳帧是自动为你实现的，那么只需将你调用<code class="fe nq nr ns nt b">.step</code>的次数乘以4，当那个数达到十亿时就停止。</p><h1 id="439c" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">模型压缩</h1><p id="e2a5" class="pw-post-body-paragraph jz ka iq kb b kc nu ke kf kg nv ki kj kk nw km kn ko nx kq kr ks ny ku kv kw ij bi translated">优步在这篇论文中提供的一个有趣的创新是在神经网络压缩方面。</p><blockquote class="mn mo mp"><p id="412a" class="jz ka mq kb b kc kd ke kf kg kh ki kj mr kl km kn ms kp kq kr mt kt ku kv kw ij bi translated"><em class="iq">我们提出了一种新的方法，通过将每个参数向量表示为一个初始化种子加上产生应用于θ的一系列突变的随机种子的列表，来紧凑地存储大参数向量。这项创新对于使遗传算法能够在深度神经网络的规模上工作至关重要，因此我们称之为深度遗传算法。这种技术的好处还在于提供了一种最先进的压缩方法(第5节)。</em></p></blockquote><p id="7f2f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">正如上面的引用所暗示的，我们绝对需要<strong class="kb ir">来实现这种压缩，不是因为它很酷，而是因为我们需要在几台不同的机器上工作，相互传递神经网络，并且能够有效地序列化神经网络，以便它们可以快速地从一台机器转移到另一台机器，这是非常重要的。</strong></p><p id="3f5a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">幸运的是，实现这一点非常简单！正如论文中提到的，这只是关于记住我们每次生成随机数时使用的随机种子，即我们需要记住:</p><ul class=""><li id="fb8c" class="mu mv iq kb b kc kd kg kh kk mw ko mx ks my kw mz na nb nc bi translated">我们用来初始化网络的种子</li><li id="4c3a" class="mu mv iq kb b kc nd kg ne kk nf ko ng ks nh kw mz na nb nc bi translated">我们每次进化网络权重时使用的种子。</li></ul><p id="ff84" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">就是这样！每当我们传递网络时，我们只是发送种子而不是实际的网络，在正确设置每个种子后，通过重新运行初始化和进化很容易重新创建它。</p><p id="ac0f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">使用PyTorch设置随机种子的方法很简单<code class="fe nq nr ns nt b">torch.manual_seed</code>，您可以向其传递一个数字。为了确保随机种子总是不同的，我传入了一个由Python的<code class="fe nq nr ns nt b">random.randint</code>生成的数字，从0到2^31 - 1进行采样(你为什么问这个数字？我不确定哪些数字可以作为随机种子，但这确保了我传递的任何东西都适合32位有符号整数，我觉得这几乎肯定是可以接受的，而更大的数字可能就不行了)。</p><p id="fee2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">学习:使用随机种子，而不是随机状态。</strong></p><p id="e562" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">PyTorch还有一种方法可以使用<code class="fe nq nr ns nt b">torch.get_rng_state</code>获得其当前的随机<strong class="kb ir">状态</strong>，并使用<code class="fe nq nr ns nt b">torch.set_rng_state</code>设置它。起初我用这个是因为可能的随机状态比随机种子多得多，所以对我来说它看起来更“随机”。最大的问题是每个随机状态的大小已经是5kB左右了(相比之下，一个随机种子只有4个字节，或者少了1000倍)，这意味着我的系统由于涉及到大量的数据而变得非常慢。不要和我犯同样的错误！</p><p id="a2d6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">既然我们理解了模型压缩和模型演化，我们就可以完成模型代码来处理这两者。我选择创建一个名为CompressedModel的单独的类来表示压缩模型，并且可以在两者之间来回切换。这需要对模型进行一些更新，以便它支持一个接受种子并对其进行演化的<code class="fe nq nr ns nt b">evolve</code>函数，这样它就可以在初始化自己时接受种子。我们得到:</p><figure class="ni nj nk nl gt jr"><div class="bz fp l di"><div class="nm nn l"/></div></figure><h1 id="fb5c" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">分布式计算:作业队列和现场实例</h1><p id="3dc6" class="pw-post-body-paragraph jz ka iq kb b kc nu ke kf kg nv ki kj kk nw km kn ko nx kq kr ks ny ku kv kw ij bi translated"><strong class="kb ir">公平的警告</strong>:在这一部分，我假设你已经对AWS或其他一些云提供商有所了解，比如谷歌云或微软Azure。如果你不知道，至少看看一些使用AWS进行深度学习的教程可能是值得的(例如:<a class="ae jy" rel="noopener" target="_blank" href="/how-to-set-up-a-deep-learning-environment-on-aws-with-keras-theano-b0f39e3d861c)">https://towards data science . com/how-to-set-up-a-deep-learning-environment-on-AWS-with-keras-the ano-b 0f 39 e 3d 861 c)</a>，或者至少意识到你可能必须进行一些谷歌搜索，因为我将跳过一些重要的基本内容。</p><p id="a0bf" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">使用遗传算法训练神经网络在以下方面不同于使用梯度下降训练神经网络:使用梯度下降，我们需要在单个网络上进行大量的数学运算，而使用遗传算法，我们需要在许多网络上进行少得多的数学运算(只是向前传递，而不是向前和向后)。这使得我们可以在大量的CPU上训练我们的遗传神经网络，而不是在单个GPU上。</p><p id="3586" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们说的有多大？让我们看看优步对此有什么看法:</p><blockquote class="mn mo mp"><p id="f2c4" class="jz ka mq kb b kc kd ke kf kg kh ki kj mr kl km kn ms kp kq kr mt kt ku kv kw ij bi translated"><em class="iq">当大量分布式计算可用时，GA和ES都比Q-learning和策略梯度方法更快(这里，几十台机器上有720个CPU内核)。</em></p></blockquote><p id="56ac" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> 720 </strong>？哇哦。我倾向于认为我自己的硬件是相当高端和最新的，但即使在我的台式机和笔记本电脑之间，我总共有8个CPU核心…</p><p id="1449" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">那么这又是一篇使用了我们普通人完全无法获得的大量资源的论文吗？不是这样的！我们只是需要学习更多关于基础设施的知识。</p><h2 id="7995" class="nz lq iq bd lr oa ob dn lv oc od dp lz kk oe of md ko og oh mh ks oi oj ml ok bi translated">作业队列</h2><p id="41e8" class="pw-post-body-paragraph jz ka iq kb b kc nu ke kf kg nv ki kj kk nw km kn ko nx kq kr ks ny ku kv kw ij bi translated">问题是，我们绝对不可能在一台机器上获得720个CPU内核。更合理的是，我们可以得到64或更多。这意味着如果我们想像优步那样处理东西，我们将需要多台机器。</p><p id="33cd" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">为此，我们将使用任务队列的概念，有一个主人(或经理)和工人。主服务器将任务放到任务队列中，而工人将从队列中取出作业，运行它们，并将结果写回。这个过程可以在这个图表中看到。</p><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/21781f418975ef862b05cc0176bfb01b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/0*U59j_tZaSOmiYZHO.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Source: <a class="ae jy" href="https://www.alberton.info/batching_vs_latency_and_jobqueue_models.html" rel="noopener ugc nofollow" target="_blank">https://www.alberton.info/batching_vs_latency_and_jobqueue_models.html</a></figcaption></figure><p id="2722" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在我们的例子中，作业是评估当前一代中不同神经网络的性能，输出只是每个神经网络的分数，以及它们使用的帧数。这种体系结构的另一个优点是，它允许我们将主设备和工作设备放在不同的机器上，这有助于降低成本:我们可以将主设备放在功能不太强大但非常可靠的机器上，而将工作设备放在功能非常强大但不太可靠的机器上。这样我们可以保存我们的数据(因为所有东西都存储在主服务器上)，但是可以使用不可靠的廉价机器作为工人。</p><p id="a0e9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们将使用的任务队列库是<a class="ae jy" href="http://python-rq.org/" rel="noopener ugc nofollow" target="_blank"> RQ </a>，这是一个非常容易使用的任务队列库。它依赖于Redis数据库，您可以非常简单地将其安装在Amazon实例上。</p><p id="b0d2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">你所需要做的就是确保<em class="mq">所有</em>你的工人所需要的代码都在一个<code class="fe nq nr ns nt b">.py</code>文件中，而不是在一个笔记本中，因为RQ需要<code class="fe nq nr ns nt b">.py</code>文件来创建工人进程。然而，你的主人可以在笔记本上。你可以把你需要的<code class="fe nq nr ns nt b">.py</code>的任何部分导入到你的主笔记本中。</p><p id="b42a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">具体来说，以下内容应该在一个<code class="fe nq nr ns nt b">.py</code>文件中:</p><ul class=""><li id="dafc" class="mu mv iq kb b kc kd kg kh kk mw ko mx ks my kw mz na nb nc bi translated">神经网络模型的代码</li><li id="eb28" class="mu mv iq kb b kc nd kg ne kk nf ko ng ks nh kw mz na nb nc bi translated">神经网络压缩/解压缩代码</li><li id="acc1" class="mu mv iq kb b kc nd kg ne kk nf ko ng ks nh kw mz na nb nc bi translated">用于根据压缩模型和环境名称评估神经网络的函数，该函数至少返回分数和使用的帧数</li></ul><p id="3db4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">然后，您的主代码可以使用<code class="fe nq nr ns nt b">job = rq.enqueue(...)</code>将一个作业添加到队列中，该作业带有所讨论的函数和它应该采用的参数，并且它可以使用<code class="fe nq nr ns nt b">job.result</code>得到结果，如果函数还没有返回，结果将是None。您应该确保您的代码对于被丢弃的作业是健壮的:如果您长时间没有得到作业的结果，请确保它被重新排队。记得将<strong class="kb ir">压缩的</strong>神经网络作为参数传递给<code class="fe nq nr ns nt b">enqueue</code>，因为这些需要序列化并通过网络传输，所以它们要小，这一点很重要。把这些放在一起，这是我最后的主代码。</p><figure class="ni nj nk nl gt jr"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="f3ae" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">一旦你有了所有这些，你应该为你的主人创建一个AWS实例，一个小型的就足够了，我个人使用了t2.medium。你可以在上面安装任何你想要的Linux，我个人使用了非深度学习的Ubuntu 16.04 AMI。然后安装代理的所有依赖项，包括redis-server、rq、pytorch等。完成后，您应该做以下事情:</p><ul class=""><li id="3e4c" class="mu mv iq kb b kc kd kg kh kk mw ko mx ks my kw mz na nb nc bi translated">编辑刚刚创建的主机的安全组，以允许redis连接。为了确保不将redis服务器暴露给外界，您可以将流量限制为仅来自同一个安全组内部的流量。从现在开始，确保您创建的任何其他计算机都在同一个安全组中。理想情况下，您应该只启用redis流量，但是我懒得找出具体的方法，所以我启用了来自安全组的所有流量，如下所示:</li></ul><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="on oo di op bf oq"><div class="gh gi om"><img src="../Images/0dbda7f8732895214da034ddfa5bfc7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c3Jeg9BTrUQURyIKA462Nw.png"/></div></div></figure><ul class=""><li id="1aba" class="mu mv iq kb b kc kd kg kh kk mw ko mx ks my kw mz na nb nc bi translated">找出你的主机的私有IP(应该在EC2 web界面中)并创建以下两个文件:<br/>一个名为<code class="fe nq nr ns nt b">redis.conf</code>的文件包含<code class="fe nq nr ns nt b">bind &lt;YOUR PRIVATE IP&gt;<br/></code>一个名为<code class="fe nq nr ns nt b">settings.py</code>的文件包含<code class="fe nq nr ns nt b">REDIS_HOST = '&lt;YOUR PRIVATE IP'</code></li><li id="a6cc" class="mu mv iq kb b kc nd kg ne kk nf ko ng ks nh kw mz na nb nc bi translated">运行redis服务器:<code class="fe nq nr ns nt b">nohup redis-server redis.conf&amp;</code>。<code class="fe nq nr ns nt b">nohup</code>部分确保服务器将继续运行，即使您的连接中断，而最后的<code class="fe nq nr ns nt b">&amp;</code>确保它立即在后台运行，以便您可以做其他事情。</li><li id="c98f" class="mu mv iq kb b kc nd kg ne kk nf ko ng ks nh kw mz na nb nc bi translated">使用<code class="fe nq nr ns nt b">rq worker -c settings</code>运行一个RQ worker。</li><li id="aeb7" class="mu mv iq kb b kc nd kg ne kk nf ko ng ks nh kw mz na nb nc bi translated">现在<strong class="kb ir">通过运行您的主代码来测试</strong>这是否可行，并确保作业确实由工人处理。</li><li id="9f48" class="mu mv iq kb b kc nd kg ne kk nf ko ng ks nh kw mz na nb nc bi translated">杀死worker，回到AWS界面，点击你的实例，进入“Actions -&gt; Images -&gt; Create Image”，这将允许你创建一个包含你刚刚安装的所有包的AMI，这样就可以很容易地在其他机器上启动worker！</li></ul><p id="a70d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们现在可以继续创建实际的工人。</p><h2 id="656c" class="nz lq iq bd lr oa ob dn lv oc od dp lz kk oe of md ko og oh mh ks oi oj ml ok bi translated">AWS Spot实例</h2><p id="f818" class="pw-post-body-paragraph jz ka iq kb b kc nu ke kf kg nv ki kj kk nw km kn ko nx kq kr ks ny ku kv kw ij bi translated">事实证明，访问大量CPU是相当容易的:例如，AWS上的c5.18xlarge实例包含惊人的72个CPU，是我们所需的1/10！只要有10个这样的实例，我们就会拥有与优步使用的CPU数量完全相同的CPU。甚至有一个实例有96个CPU(m5.24xlarge)，但值得注意的是，它的CPU比c5.18xlarge略慢，而且它的每CPU成本略高，因为它也有更多的内存，这是我们并不真正需要的(c5.18xlarge有144 GB的内存，m 5.24 x large有384 GB，但我记得我从未在我使用的任何机器上使用过超过5 GB的内存……)。</p><p id="13f9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">好的，那么要花多少钱？嗯，在美国西部地区，单个c5.18xlarge每小时的成本为3.06美元(其他地区应该差不多)，优步声称，他们能够使用相当于10个c5.18xlarge在大约一小时内训练他们的网络，因此，假设一切顺利，训练单个网络应该花费30.60美元。这其实没那么糟糕！但是我们可以使用<strong class="kb ir">点实例</strong>做得更好。</p><p id="b562" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现货实例是亚马逊如何处理并非所有机器在任何给定时间都被预订的事实:他们为闲置机器的使用设立拍卖，出价最高的人可以获得这些机器。这使得价格更低，但有一个问题:如果有人超过你的最高出价，或者亚马逊必须满足全价要求，你正在使用的机器可能会被夺走。</p><p id="6bcd" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">此外，与常规的按需实例相比，您实际支付的价格更难预测:实例的现货价格会随着需求的增加和减少而波动，只要当前现货价格低于您的最高出价，您就总是支付当前现货价格。因此，如果一个实例以每小时1美元的价格交易，而你出价2美元，你可能一开始会支付1美元，但随着时间的推移，你可能会开始支付每小时1.5美元，或0.5美元等。幸运的是，实例市场现在足够稳定，这不是一个大问题:如果您只使用您的实例几个小时，最有可能您将支付您第一次创建spot实例时看到的价格的5%左右。</p><p id="68f5" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">不过总的来说，我们上面描述的设计对于spot实例来说是完美的，因为您可以让一个“主”服务器运行在一个小型的随需应变实例上，并使用您想要的任何数量的高CPU spot实例。如果您正确地编写了代码，它应该相对不会出现实例死亡:它只会重试作业，不会丢失数据。在撰写本文时，一个c 5.18 x大型spot实例的成本为1.08美元，比使用按需实例的成本低近3倍。这意味着，乐观地说，在一个游戏上训练应该花费大约11美元。然而，请注意，由于我训练了3个游戏(冻伤、突破和太空入侵者)以及我在这个过程中犯的许多错误，整个实验花费了我大约115美元，所以在开始做这个之前，请尽量格外小心或确保你愿意花费大约100美元。</p><p id="83e4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">那么，如何创建spot实例呢？让我们现在就做吧！作为一个提醒，请确保您对您的设置有足够的信心(即您已经创建了一个AMI，并且您已经确认您可以轻松地在另一台机器上运行该系统)。</p><p id="91d3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在EC2面板中，单击右侧的“Spot请求”,然后单击“请求Spot实例”按钮。您将被带到此页面:</p><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="on oo di op bf oq"><div class="gh gi or"><img src="../Images/93c015889c5754e14e29cbed1d88779d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8Cp6LnYBvlHZ3DUkbXuCLw.png"/></div></div></figure><p id="dbc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">许多参数可以保留为默认值，只需记住执行以下操作:</p><ul class=""><li id="7b65" class="mu mv iq kb b kc kd kg kh kk mw ko mx ks my kw mz na nb nc bi translated">选择你的总容量(10会给你优步所使用的，但我个人选择使用5个实例，并简单地等待2小时，而不是1小时。您必须使用ssh访问每台机器，因此较低的数量更易于管理)。</li><li id="9c64" class="mu mv iq kb b kc nd kg ne kk nf ko ng ks nh kw mz na nb nc bi translated">选择您刚刚创建的AMI。</li><li id="d196" class="mu mv iq kb b kc nd kg ne kk nf ko ng ks nh kw mz na nb nc bi translated">从实例类型列表中删除c3.large实例类型，并添加一个c5.18xlarge。“选择实例类型”窗口将实际显示所有可用的实例及其价格。<br/> <em class="mq">有可能在你看的时候另一个实例类型会对你更有利。我的建议是，在计算哪个实例是最好的时，只需将当前的现货价格除以CPU的数量，就可以得到每个CPU最便宜的实例。但是，请注意，名称以“c”开头的实例是计算优化的，这通常意味着它们的CPU比其他实例上的CPU更快，即使内核数量相同。</em></li><li id="5fbc" class="mu mv iq kb b kc nd kg ne kk nf ko ng ks nh kw mz na nb nc bi translated">选择与主服务器相同的可用性区域(可能没有必要)。</li><li id="36da" class="mu mv iq kb b kc nd kg ne kk nf ko ng ks nh kw mz na nb nc bi translated">选择您先前创建/编辑的安全组。</li></ul><p id="9b06" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">一些可选的事情是设置您的最高价格(默认情况下是按需出价，这也是我推荐的价格)，并且可能在固定的时间内保留您的spot实例(这样可以保证您的实例在接下来的3个小时内不会被抢占，但是您可能会比普通的spot实例支付更多的费用)。</p><p id="13e8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">一旦完成，您就可以登录到各种spot实例并在其上运行rq workers。这是我用来启动72个workerss并让每个worker将其日志写入不同文件的脚本:</p><pre class="ni nj nk nl gt os nt ot ou aw ov bi"><span id="71bb" class="nz lq iq nt b gy ow ox l oy oz">for i in {0..72}<br/>do<br/>nohup rq worker -c settings &gt; $i&amp;<br/>done</span></pre><p id="df78" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在，假设您正在主盒上运行您的主代码，您应该最终在您的训练中取得进展！</p><h2 id="52a3" class="nz lq iq bd lr oa ob dn lv oc od dp lz kk oe of md ko og oh mh ks oi oj ml ok bi translated">英特尔MKL的一个重要消息</h2><p id="587c" class="pw-post-body-paragraph jz ka iq kb b kc nu ke kf kg nv ki kj kk nw km kn ko nx kq kr ks ny ku kv kw ij bi translated">英特尔MKL公司是数值计算领域一个非常酷的新发展。这是一个由英特尔开发的速度极快的数学库，它利用最新的指令和多线程来非常快速地执行数值计算。PyTorch使用它进行CPU计算，并帮助减少神经网络的CPU和GPU性能之间的差异(尽管GPU仍然更快)。</p><p id="676f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">不幸的是，MKL会给我们带来麻烦！这是因为它将自动使用几个CPU核心来向前传递单个神经网络，但我们已经设置好了，以便每个神经网络使用一个CPU核心。我发现这似乎让事情变得更慢，这就是为什么我建议在MKL禁用多线程。这可以通过在python ( <code class="fe nq nr ns nt b">conda install mkl-service</code>)中安装mkl-service并在导入pytorch之前将以下代码行放在worker文件的顶部来实现:</p><pre class="ni nj nk nl gt os nt ot ou aw ov bi"><span id="23e6" class="nz lq iq nt b gy ow ox l oy oz">import mkl<br/>mkl.set_num_threads(1)</span></pre><h1 id="2509" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">我们来看结果！</h1><p id="001b" class="pw-post-body-paragraph jz ka iq kb b kc nu ke kf kg nv ki kj kk nw km kn ko nx kq kr ks ny ku kv kw ij bi translated">最后是一两个小时后，看你选择用多少台机器，我们有结果了！</p><p id="904c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">那么我们如何评价我们代理人的表现呢？优步对此有几点要说:</p><blockquote class="mn mo mp"><p id="a0f1" class="jz ka mq kb b kc kd ke kf kg kh ki kj mr kl km kn ms kp kq kr mt kt ku kv kw ij bi translated">将我们的结果与其他算法的结果进行公平的比较是极其困难的，因为这种比较本质上在许多不同的方面是风马牛不相及的。一个重要的考虑因素是，是否在随机开始(随机数量的无操作动作)上对代理进行评估，这是他们接受训练的制度，或者从人类游戏中随机采样的开始，这测试一般化(Nair等人，2015)。 <strong class="kb ir"> <em class="iq">由于我们没有从</em> </strong> <em class="iq">抽取人力开工数的数据库，我们的代理商是用随机开工数进行评估的。在可能的情况下，我们将我们的结果与其他算法的结果进行比较，这些算法的随机开始结果是可用的。这对DQN和ES来说是正确的，但对A3C来说就不正确了，在A3C中，我们必须包括人类起跑的结果。</em></p></blockquote><p id="11ea" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我强调缺乏一个人类起点的数据库:我认为这太糟糕了，事实上似乎没有这样的数据库，我认为建立一个会很棒。</p><p id="05d6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">无论如何，听起来我们应该评估我们的代理的方式是在开始之前简单地使用随机数量的无操作操作，这就是我们最初是如何进行培训的。这里没有指定无操作的数量，但是其他地方给出的数量在0到30之间，所以这就是我们要做的。因为存在这种随机性(更不用说在单个Atari游戏中产生随机数的可能性)，我决定运行游戏30次，并显示最好、最差和中间值结果。开始了。</p><h2 id="7e13" class="nz lq iq bd lr oa ob dn lv oc od dp lz kk oe of md ko og oh mh ks oi oj ml ok bi translated">冻伤</h2><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/4eee36add71ce74dd53663055e27a040.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*f9BAJO-J4941M9qvjKpUTw.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Best score for Frostbite</figcaption></figure><p id="9203" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们可以看到，我们得到了一个对冻伤表现非常好的代理:4570是它的最好成绩，接近优步的4801，据我所知，这是目前最先进的水平！非常刺激。</p><p id="4c97" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">不幸的是，这个代理甚至对随机启动都不够健壮！中位数只有170，最差160！我不清楚为什么优步没有报告这个问题:这是我的实现中的一个问题吗？一些发生在他们身上但他们没有报告的事情？实施过程中的问题？(例如，如果他们实现了糟糕的随机启动，这可能不可见)。</p><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/7aa1669cb79d386473ec26efcb7e2926.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*WxpyqVOxEGD8ixoVw3bZ7w.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Median performance of the best agent for Frostbite</figcaption></figure><p id="1641" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这似乎解释了当我经历几代人时，中值分数和最佳分数之间的巨大差异(优步的“中值”分数图没有使用这个定义，这就是为什么我不能将它们与我的发现进行比较:在优步的定义中，它是最佳代理在多次运行中的中值):这并不是说代理对其权重的微小变化非常敏感，而是他们对其起点的微小变化非常敏感！</p><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/7ddcd763c291d36429af1fdfcb88f426.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*OYU3G1MFVnZbj74pKqgNZw.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Performance of the best and median agent at each generation</figcaption></figure><p id="d584" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我真的很想在将来解决这个问题。在我看来，有两件事可以帮助解决这个问题:</p><ul class=""><li id="8260" class="mu mv iq kb b kc kd kg kh kk mw ko mx ks my kw mz na nb nc bi translated">不是在一次运行中而是在多次运行中评估每个神经网络，每次运行都以不同数量的不操作开始。</li><li id="e32e" class="mu mv iq kb b kc nd kg ne kk nf ko ng ks nh kw mz na nb nc bi translated">重温epsilon贪婪的遗传算法:这似乎很疯狂，因为它似乎不像GA“需要”一个探索策略，这就是为什么优步没有实施一个，但它可能是探索不仅有助于强化学习代理发现新的高回报状态，而且有助于变得强大，以发现自己在不可预见的情况下。现在看起来GA网络过度适应了游戏中一个非常特殊的动作序列。编辑:在重新考虑这个问题后，我认为，虽然包含ε-greedy可能有助于提高某些游戏的遗传算法的性能，但它可能会冻伤。这是因为在冻伤中，很容易通过一个单一的动作杀死自己(例如，在错误的时刻跳跃)，因此随机选择动作可能是危险的。相比之下，在像breakout这样的游戏中，通常很容易修复随机动作的效果(只需撤销上一个动作的移动)。这意味着我们需要一个更好的冻伤探索策略。</li></ul><h2 id="0b7b" class="nz lq iq bd lr oa ob dn lv oc od dp lz kk oe of md ko og oh mh ks oi oj ml ok bi translated">越狱</h2><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/92fb63a9d59f95b9fc05e39cb8121fac.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*7D08PQXP7_-aaiPbb-2vnQ.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Best (!) performance for Breakout</figcaption></figure><p id="efdb" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">哦，好家伙…煤气做<strong class="kb ir">可怕的</strong>在突破。为什么？</p><p id="d934" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我可以看到几个原因:</p><ul class=""><li id="563f" class="mu mv iq kb b kc kd kg kh kk mw ko mx ks my kw mz na nb nc bi translated">你需要运行一个特定的动作，否则突围不会开始(具体来说，突围有4个动作:什么都不做，开始游戏，向左移动和向右移动)。当遵循诸如ε-贪婪的随机探索策略时，这不是问题，因为行动将在某个点或其他点被选择，但是没有任何探索，这意味着大部分代理将永远简单地什么也不做。为了防止这种情况，我甚至在最初几代中减少了游戏的最大长度，并惩罚了那些一直无所事事的代理。然而，显然它并没有那么好。</li><li id="05c3" class="mu mv iq kb b kc nd kg ne kk nf ko ng ks nh kw mz na nb nc bi translated">突破中很少有像素改变，所以代理继续执行相同的动作。<br/> <em class="mq">在冻伤中，即使代理什么都不做，也保证有差不多50%的像素发生变化。在突破中，只有一个小球，桨，也许还有一两块砖会改变，而且只有当代理人实际做了一些事情。对于随机初始化的神经网络，这可能不足以让它决定执行不同的动作。</em></li></ul><p id="941d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同样，我认为有办法解决这个问题，包括在训练中加入贪婪探索。这值得进一步探索。</p><h1 id="684f" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">太空入侵者</h1><figure class="ni nj nk nl gt jr gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/f05f68be43a469c622b28e354ca697ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*Si8Udx1IHIe-DSkHHbktPw.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Best performance on Space Invaders</figcaption></figure><p id="b7c3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">代理在《太空入侵者》中表现相对较好，类似于我们在<a class="ae jy" href="https://becominghuman.ai/beat-atari-with-deep-reinforcement-learning-part-2-dqn-improvements-d3563f665a2c" rel="noopener ugc nofollow" target="_blank"> DQNs Part 2 </a>中训练的代理，虽然远非最先进，但仍然相当不错。此外，不管初始随机无操作，它实际上执行相同的操作。</p><p id="70a1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">然而，我对它的策略有点担心，至少在一开始，它只是简单地呆在左边并试图射击母舰:这看起来更像是一个怪异的局部最优，而不是代理已经获得的实际技能。我也很好奇是什么让它学到了看起来更像游戏中真正的技巧而不是懒惰的策略。</p><h1 id="1ba7" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">结论</h1><p id="2687" class="pw-post-body-paragraph jz ka iq kb b kc nu ke kf kg nv ki kj kk nw km kn ko nx kq kr ks ny ku kv kw ij bi translated">我对优步论文中的结果感到兴奋。事实上，它在冻伤方面做得如此之好是非常惊人的，我不清楚这是否意味着传统的RL算法特别弱，或者GA惊人地强。然而，我认为，遗传算法似乎有一些优步没有指出的重大问题，部分原因是他们无法使用人类启动的数据库来评估他们的算法(我认为这将显示各种代理的脆弱性)，尝试解决这些问题会很有趣。我计划在未来尝试包括ε贪婪探索，我认为这将有助于代理的鲁棒性，正如优步指出的，有大量关于遗传算法的文献，他们只尝试了最基本的可能。谁知道更先进的气体会把我们带到哪里。</p></div></div>    
</body>
</html>