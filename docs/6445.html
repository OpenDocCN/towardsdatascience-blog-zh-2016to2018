<html>
<head>
<title>Doodling with Deep Learning!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用深度学习涂鸦！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/doodling-with-deep-learning-1b0e11b858aa?source=collection_archive---------5-----------------------#2018-12-14">https://towardsdatascience.com/doodling-with-deep-learning-1b0e11b858aa?source=collection_archive---------5-----------------------#2018-12-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/63906783b60ac9e178c5360b472d20b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zMhUUzPiTtZO9BkzlbdFvQ.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="0bec" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated"><strong class="ak"> <em class="kq">我们的旅程与素描识别</em> </strong></h2></div><p id="2abd" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在这篇博文中，我们描述了我们对过程的理解，对模型的拟合，以及找到一个有趣的 Google Quick，Draw 应用程序！数据集。与我们一起走过这段旅程，看看我们是如何应对成功分类“可以说是世界上最可爱的研究数据集”这一挑战的</p><p id="c3f9" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">该项目由 Akhilesh Reddy、Vincent Kuo、Kirti、Tiffany Sung 和 Helena Shi 建造。要查看使用的完整代码，请找到我们的<a class="ae ln" href="https://github.com/QuickDraw-sketchRecognition/Sketch_Recognition/" rel="noopener ugc nofollow" target="_blank"> github </a>:</p><h1 id="96ef" class="lo lp jb bd lq lr ls lt lu lv lw lx ly kh lz ki ma kk mb kl mc kn md ko me mf bi translated"><strong class="ak">一、背景</strong></h1><p id="3ab4" class="pw-post-body-paragraph kr ks jb kt b ku mg kc kw kx mh kf kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">2016 年，谷歌发布了一款名为“快，画！”—这是一项人工智能实验，它在神经网络方面对公众进行了教育，并建立了超过 10 亿张图纸的庞大数据集。游戏本身很简单。它会提示玩家在某个类别中涂鸦一幅图像，当玩家在画画时，神经网络会在人机游戏的猜图游戏中猜测这幅图像描绘了什么。你可以在这里找到更多关于游戏<a class="ae ln" href="https://cloud.google.com/blog/products/gcp/drawings-in-the-cloud-introducing-the-quick-draw-dataset" rel="noopener ugc nofollow" target="_blank">的信息</a>或者自己玩<a class="ae ln" href="https://quickdraw.withgoogle.com/" rel="noopener ugc nofollow" target="_blank">游戏</a>！</p><p id="8635" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">自从在数据集中发布了 5000 万幅图画以来，ML 社区已经开始探索这些数据在改进手写识别、训练<a class="ae ln" href="https://ai.googleblog.com/2017/04/teaching-machines-to-draw.html" rel="noopener ugc nofollow" target="_blank">草图 RNN </a>模型来教机器画画等方面的应用。值得注意的是，它在 OCR(光学字符识别)、ASR(自动语音识别)&amp; NLP(自然语言处理)方面具有强大的潜力，并揭示了世界各地的人们如何<a class="ae ln" href="https://www.blog.google/technology/ai/quick-draw-one-billion-drawings-around-world/" rel="noopener ugc nofollow" target="_blank">不同，但却是相同的</a>。</p><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ml"><img src="../Images/e110904323788947f26dc7397c30ef88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Y4rwYwnMP0yGRfgkOgrGQA.gif"/></div></div></figure><h1 id="0ac1" class="lo lp jb bd lq lr ls lt lu lv lw lx ly kh lz ki ma kk mb kl mc kn md ko me mf bi translated"><strong class="ak">二。数据</strong></h1><p id="acfb" class="pw-post-body-paragraph kr ks jb kt b ku mg kc kw kx mh kf kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">我们的总数据量为 73GB，包含 340 个标签类别中的 5000 万张图纸。每张图纸都有特定的变量:</p><ul class=""><li id="0612" class="mq mr jb kt b ku kv kx ky la ms le mt li mu lm mv mw mx my bi translated">“<strong class="kt jc">字</strong>”—该图纸的类别标签</li><li id="1190" class="mq mr jb kt b ku mz kx na la nb le nc li nd lm mv mw mx my bi translated">"<strong class="kt jc">国家代码</strong> " —出票人的原产国</li><li id="f5fd" class="mq mr jb kt b ku mz kx na la nb le nc li nd lm mv mw mx my bi translated">“<strong class="kt jc">时间戳</strong>”—图纸的时间戳</li><li id="b73c" class="mq mr jb kt b ku mz kx na la nb le nc li nd lm mv mw mx my bi translated">“<strong class="kt jc">识别出</strong>”—表示 app 预测成功</li><li id="8793" class="mq mr jb kt b ku mz kx na la nb le nc li nd lm mv mw mx my bi translated"><strong class="kt jc">绘图</strong>——针对涂鸦图像的笔画基础数据；每幅画都由矩阵形式的多个笔画组成</li></ul><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ne"><img src="../Images/35af34646eb6b03077bf143fd1e78da9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Rh_7QVwsl52eUlqo"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">As seen here, each point in a stroke corresponds to an x-coordinate, y-coordinate, and time point</figcaption></figure><h1 id="1ea9" class="lo lp jb bd lq lr ls lt lu lv lw lx ly kh lz ki ma kk mb kl mc kn md ko me mf bi translated"><strong class="ak">三。接近</strong></h1><p id="07bc" class="pw-post-body-paragraph kr ks jb kt b ku mg kc kw kx mh kf kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">我们首先了解构成草图的数组的结构，并对数据进行预处理。然后，我们深入研究拟合一些简单的分类器和一个基本的卷积神经网络，或 CNN。从那里，我们处理 CNN 架构，如 ResNet 和 MobileNet。最后，我们通过参加<a class="ae ln" href="https://www.kaggle.com/c/quickdraw-doodle-recognition" rel="noopener ugc nofollow" target="_blank"> Kaggle 竞赛</a>与世界分享了我们的成果。</p><p id="828d" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">由于数据的巨大规模和对更高容量 GPU 的需求，我们在谷歌云平台上实现了 CNN 结构，该平台提供 300 美元的免费试用。要了解我们是如何做到的，请点击链接<a class="ae ln" href="https://medium.com/@alamhanz/jupyter-notebook-on-gcp-for-pythoners-18a8e7a73a56" rel="noopener">这里</a>和<a class="ae ln" href="https://medium.com/google-cloud/using-a-gpu-tensorflow-on-google-cloud-platform-1a2458f42b0" rel="noopener">这里。</a></p><h1 id="044b" class="lo lp jb bd lq lr ls lt lu lv lw lx ly kh lz ki ma kk mb kl mc kn md ko me mf bi translated"><strong class="ak">四。数据预处理</strong></h1><p id="0db6" class="pw-post-body-paragraph kr ks jb kt b ku mg kc kw kx mh kf kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">对于每个类别标签的图形，数据以单独的 CSV 文件格式存在。因此，我们首先改组 CSV，用来自所有类的数据创建 100 个新文件，以确保模型接收图像的随机样本作为输入，并消除偏差。</p><figure class="mm mn mo mp gt is"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="37bc" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">大多数人画涂鸦的方式都差不多。例如，如果我让你画一个太阳，你会从一个圆开始，然后以顺时针方向画出从圆心向外辐射的虚线。为了捕捉这些信息，我们使用灰度/颜色编码处理<strong class="kt jc"> </strong>来利用 RGB 通道，同时构建 CNN，以便模型可以识别每个笔画之间的差异。我们给涂鸦的每一个按时间顺序排列的笔画分配了一种颜色，这样模型就可以获得单个笔画的信息，而不仅仅是整幅图像。</p><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nl"><img src="../Images/fe5e531cd98bf76ddc3d52e963f92ee9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EpwcOTYXQlX2qvqT27J5CQ.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Violin (left) in black &amp; white; Mermaid (right) color-encoded</figcaption></figure><p id="2867" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们还通过随机翻转、旋转或阻挡部分来增加图像，以将噪声引入图像，并增加模型处理噪声的能力。在游戏过程中，一些玩家没有完成他们的涂鸦或以不同的角度画画。在这些情况下，增强可以为模型提供信息。</p><figure class="mm mn mo mp gt is"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="bd62" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">灰度/彩色编码和图像增强都使用了来自 keras <strong class="kt jc">、</strong>的 OpenCV 和 ImageGenerator，它们从 csv 文件中加载大量原始数据，并将其转换为图像。</p><h1 id="dab2" class="lo lp jb bd lq lr ls lt lu lv lw lx ly kh lz ki ma kk mb kl mc kn md ko me mf bi translated"><strong class="ak">五、建筑模型</strong></h1><p id="a5f5" class="pw-post-body-paragraph kr ks jb kt b ku mg kc kw kx mh kf kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">在完成所有的数据收集和预处理步骤之后，就该开始项目中最有趣的部分了——模型构建！</p><p id="b7a4" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在我们进入 CNN 之前，我们尝试了一些基本的分类器来比较不同的机器学习算法，并熟悉这些数据。我们从<a class="ae ln" href="https://console.cloud.google.com/storage/browser/quickdraw_dataset/full/numpy_bitmap//" rel="noopener ugc nofollow" target="_blank">谷歌云存储</a>中提取了数据的 numpy 文件。该数据已经过预处理，并在 numpy 中呈现为 28x28 灰度位图。npy 格式。由于整个数据集包括超过 345 个类别，我们最终选择了仅包含以下 5 个类别的子集:飞机、闹钟、救护车、天使和动物迁徙。</p><h2 id="89f7" class="nm lp jb bd lq nn no dn lu np nq dp ly la nr ns ma le nt nu mc li nv nw me nx bi translated"><strong class="ak">随机森林</strong></h2><p id="86dd" class="pw-post-body-paragraph kr ks jb kt b ku mg kc kw kx mh kf kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">我们首先从随机森林分类器开始。我们利用 GridSearchCV 交叉验证模型并优化参数。我们发现精确度在 100 棵树后趋于平稳，所以我们使用 n_estimators = 100 作为我们的最终模型，返回的精确度为 0.8291。</p><figure class="mm mn mo mp gt is"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h2 id="8862" class="nm lp jb bd lq nn no dn lu np nq dp ly la nr ns ma le nt nu mc li nv nw me nx bi translated"><strong class="ak"> KNN </strong></h2><p id="b977" class="pw-post-body-paragraph kr ks jb kt b ku mg kc kw kx mh kf kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">其次，我们尝试了 k-最近邻(kNN)分类器，这可以说是最简单、最容易理解的模型。它的算法通过在 k 个最接近的例子中找到最常见的类来对未知数据点进行分类。我们交叉验证了 n_neighbors，发现给出的最佳模型是 k = 5，这返回 0.8752 的准确度。</p><figure class="mm mn mo mp gt is"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h2 id="66fd" class="nm lp jb bd lq nn no dn lu np nq dp ly la nr ns ma le nt nu mc li nv nw me nx bi translated"><strong class="ak">多层感知器(MLP) </strong></h2><p id="cfaa" class="pw-post-body-paragraph kr ks jb kt b ku mg kc kw kx mh kf kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">最后，我们尝试了 scikit-learn 的多层感知器(MLP)。我们在不同的隐藏层大小和学习率上进行交叉验证，决定隐藏层大小为(784)，学习率α= 0.001，这给出了 0.8654 的准确度。</p><figure class="mm mn mo mp gt is"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h2 id="3b75" class="nm lp jb bd lq nn no dn lu np nq dp ly la nr ns ma le nt nu mc li nv nw me nx bi translated"><strong class="ak">卷积神经网络</strong></h2><p id="f191" class="pw-post-body-paragraph kr ks jb kt b ku mg kc kw kx mh kf kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">然后，我们转到一个简单的 CNN 模型，为模型性能设置一个较低的阈值，并理解模型的细微差别和执行时间。在这个模型中，我们使用数据中的绘图信息，通过 OpenCV 创建所需大小的图像。这里，我们尝试了一系列不同的参数，如下所示:</p><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ny"><img src="../Images/1f5016a547c42788776d1190a9738d6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JerL1vSPnC-21bFLWu9_Sw.png"/></div></div></figure><p id="9aac" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这是我们参数设置背后的一些直觉。首先，较大的批量将有助于解决由于错误标记的训练数据而产生的噪声。尺寸参数表示图像尺寸/分辨率，对精度有重要影响。例如，32x32 和 128x128 的比较表明，32x32 的大小过于像素化，无法实现精确的模型。</p><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nz"><img src="../Images/7a96d4ee7313a3ad16f847ce631e2b96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RWYJH28fDFahfnRIhJXryw.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">32x32 (left), 128x128 (right)</figcaption></figure><p id="4237" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">第一个模型使用两个卷积层，每个深度为 128。然而，这种图像尺寸的增加需要更大的感受野 conv 层或额外的 conv 层。因此，当用更大的图像尺寸训练时，我们包括了多一层。下面是我们创建的自定义 CNN 模型，在构建模型时，将卷积层数、密集层数、压差和大小作为参数。</p><figure class="mm mn mo mp gt is"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="11f8" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">由于我们仍在决定进一步进行分析的最佳模型，我们在初始步骤使用了有限的数据来减少执行时间。</p><h2 id="3de8" class="nm lp jb bd lq nn no dn lu np nq dp ly la nr ns ma le nt nu mc li nv nw me nx bi translated">选择优化器</h2><p id="3170" class="pw-post-body-paragraph kr ks jb kt b ku mg kc kw kx mh kf kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">继续培训之前的一个关键步骤是决定使用哪个优化器。在参考了文献并听取了各种 Kaggle 论坛上专家的建议后，我们决定比较 Adam 优化器和 SGD 优化器在我们的数据上的性能。在多次迭代之后，我们选择了 Adam 优化器，因为我们观察到它显示出比 SGD 稍好的结果并且收敛得更快。</p><p id="7c02" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在对每个班级的 25000 张图片运行该模型大约 3 小时后，我们在 Kaggle 的公共排行榜上获得了 0.76 的 MAP@3 分数——对于每个班级仅有 25000 张图片来说，这是一个不错的结果！客观地说，数据集中的平均类包含 150000 幅图像。然而，当我们增加模型的复杂性时，精确度略有下降，这就导致了我们的下一步:ResNet。</p><h2 id="c8ac" class="nm lp jb bd lq nn no dn lu np nq dp ly la nr ns ma le nt nu mc li nv nw me nx bi translated"><strong class="ak"> SE-ResNet-34，SE-ResNet-50: </strong></h2><p id="7c76" class="pw-post-body-paragraph kr ks jb kt b ku mg kc kw kx mh kf kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">当增加模型的深度时，可能会面临消失梯度和退化等问题；相比之下，更深的模型比更简单的模型表现更差。残差网络(ResNet)是一种神经网络架构，它通过使用深度残差学习，以最简单的方式解决消失梯度和退化问题。</p><p id="1d8f" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">简而言之，在反向传播过程中，当信号反向发送时，梯度总是要经过<em class="oa"> f(x) </em>(其中<em class="oa"> f(x) </em>是我们的卷积、矩阵乘法或批量归一化等)，这可能会由于涉及到的非线性而带来麻烦。</p><p id="f383" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">结尾的“<em class="oa"> + x </em>”是快捷键。它允许渐变直接向后传递。通过堆叠这些层，梯度理论上可以“跳过”所有中间层，并到达底部而不会减小。</p><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ob"><img src="../Images/5059ae343f0af6e75599d70c50883717.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LQihgrosKsSy_z0LMNLxMw.png"/></div></div></figure><p id="1a2f" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">可以参考<a class="ae ln" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank">原文</a>进一步了解 34 层平面网络和 34 层残差网络的比较。</p><p id="4230" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在该过程的这一步中，我们训练 SE-ResNet-34 和 50 作为简单 CNN 的进一步发展。术语 SE 指的是挤压和激发网；有了它，一个额外的块给不同的通道加权。通过给出权重，SE 模块被证明提供了额外的精度，而仅仅增加了总参数的不到 10%。关于挤压和激励网络的更多信息可在<a class="ae ln" href="https://arxiv.org/pdf/1709.01507.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="474a" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在训练 SE-ResNet-50 时，我们对 50 到 60 个时期尝试了如下不同的参数。</p><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oc"><img src="../Images/69e89dd000d5e360416343421fc8fd7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_xsWmk91oK9F6C5dBvXp3A.png"/></div></div></figure><p id="e678" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后，在所有组合中，批量大小为 512 和图像大小为 128x128 的组合对分数的改善最大，将分数提高到 0.9093。值得注意的是，更改批量大小和图像大小是基于我们使用的 GPU，这些是 Tesla k80 上我们数据的最大可能参数。</p><h2 id="155d" class="nm lp jb bd lq nn no dn lu np nq dp ly la nr ns ma le nt nu mc li nv nw me nx bi translated">MobileNet</h2><p id="5586" class="pw-post-body-paragraph kr ks jb kt b ku mg kc kw kx mh kf kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">在与 SE-ResNet 进行多次迭代后，随着竞赛截止日期的临近，我们决定探索 MobileNet，它提供了相当的准确性，但执行速度更快。</p><p id="91c2" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">MobileNet 由 Google 推出，旨在为客户随时随地提供最新的技术，如对象、徽标和文本识别，而不考虑互联网连接。MobileNets 基于一种流线型架构，使用深度方向可分离的卷积来构建轻量级深度神经网络。</p><p id="454e" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了正确理解这一点，标准卷积在所有输入通道上应用滤波器，并在一个步骤中组合这些值。相比之下，深度方向可分离卷积执行两个不同的步骤:</p><ol class=""><li id="79d4" class="mq mr jb kt b ku kv kx ky la ms le mt li mu lm od mw mx my bi translated"><em class="oa">深度方向卷积</em>将单个滤波器应用于每个输入通道</li><li id="dff4" class="mq mr jb kt b ku mz kx na la nb le nc li nd lm od mw mx my bi translated"><em class="oa">逐点卷积</em>，一个简单的 1×1 卷积，然后用于创建深度方向层输出的线性组合</li></ol><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oe"><img src="../Images/4fa5b5564eb01baec8b85d3d3e7b8fe6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RZQdgPu1yEtw-INA_G2XyQ.png"/></div></div></figure><p id="a86c" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这种因子分解大大减少了计算和模型大小，因为它打破了输出通道数量和内核大小之间的相互作用。根据 MobileNet 上的原始论文，MobileNet 显示计算成本减少了至少 9 倍。更详细的内容，可以参考 MobileNet 上的<a class="ae ln" href="https://arxiv.org/pdf/1704.04861.pdf" rel="noopener ugc nofollow" target="_blank">原创论文。</a></p><p id="41c3" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了简单起见，我们在 keras 中使用了简单的两行标准 MobileNet 模块。</p><figure class="mm mn mo mp gt is"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="3607" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在训练模式之前，我们确保使用所有 50 MM 图像来训练模型，并通过每个笔画的灰度梯度包括笔画信息的顺序。经过多次迭代，我们发现以下参数是最佳参数。</p><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi of"><img src="../Images/91e929b475d8f18f3d8faf827d5a58d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*msvVPuAbaX3VH_BgjkYWYw.png"/></div></div></figure><h1 id="333a" class="lo lp jb bd lq lr ls lt lu lv lw lx ly kh lz ki ma kk mb kl mc kn md ko me mf bi translated">不及物动词结果</h1><p id="ece9" class="pw-post-body-paragraph kr ks jb kt b ku mg kc kw kx mh kf kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">我们开始在谷歌云平台提供的特斯拉 P100 GPU 上用 50 毫米的图纸和 340 节课训练模型。经过 20 个小时的训练和 50 美元的 GCP 积分，我们最终在 Kaggle 排行榜上使用 MobileNet 获得了 0.9211 的分数，这帮助我们在 1316 支参赛队伍中获得了 268 名的排名！</p><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi og"><img src="../Images/25edf4d848785866412dfc6b270e4c39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*evWJa5_ePq89sil9"/></div></div></figure><p id="0571" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在这里，您可以看到我们模型参数和结果的总体总结:</p><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oh"><img src="../Images/3dd41591d8263e903fe2071039495557.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kn10jVBU_Gp81CapU-hzFA.png"/></div></div></figure><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oi"><img src="../Images/2deb2b666ee3bcdd71fc4a76f9686775.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GewRz58IEGF1jLcRrCNAgQ.png"/></div></div></figure><p id="0c9b" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">以下是我们预测的一些例子！</p><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oj"><img src="../Images/18063d44c7e256aa921601d9c77e1ca5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KrVPXIFWyS01fvdDZrkXCA.png"/></div></div></figure><h1 id="c82e" class="lo lp jb bd lq lr ls lt lu lv lw lx ly kh lz ki ma kk mb kl mc kn md ko me mf bi translated">有趣的奖励！</h1><p id="ec84" class="pw-post-body-paragraph kr ks jb kt b ku mg kc kw kx mh kf kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">如果你坚持读完并读到这一点，给你加分！作为一个有趣的治疗，我们决定也增加一点趣味，并创建了一个可以通过网络摄像头捕捉涂鸦的应用程序！该应用程序使用我们的模型进行实时预测。OpenCV 函数被用来从网络摄像头捕捉视频并提取所绘制的图像。</p><p id="85d9" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们使用第一个简单的 CNN 模型作为我们的后端，因为它是我们运行过的最轻的模型。该模型在 15 个类别(如下所列)上进行训练，并实现了 87%的正确率来检测所画的涂鸦。</p><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ok"><img src="../Images/05d6d7713f58d0db2cef57f7d0c415ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WJdHXy06O_XREZ864TS41Q.png"/></div></div></figure><figure class="mm mn mo mp gt is gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/6cb3cf51a29edbba58a78092aa49b14a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*Ys_EtaceCKyQw5TyiowcUQ.gif"/></div></figure><h1 id="5a02" class="lo lp jb bd lq lr ls lt lu lv lw lx ly kh lz ki ma kk mb kl mc kn md ko me mf bi translated">七。结论</h1><p id="8014" class="pw-post-body-paragraph kr ks jb kt b ku mg kc kw kx mh kf kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">最后，我们将总结一下这个曲折旅程中所采取的步骤:</p><ol class=""><li id="24e4" class="mq mr jb kt b ku kv kx ky la ms le mt li mu lm od mw mx my bi translated">绞尽脑汁理解涂鸦数据的独特结构，并想出如何连接谷歌云平台来运行模型</li><li id="fe0f" class="mq mr jb kt b ku mz kx na la nb le nc li nd lm od mw mx my bi translated">通过混洗 CSV 和用笔画信息扩充图像等执行数据清理和预处理</li><li id="b6a3" class="mq mr jb kt b ku mz kx na la nb le nc li nd lm od mw mx my bi translated">在我们的本地系统上的三个简单分类器上运行五个类的缩减数据集</li><li id="4f0e" class="mq mr jb kt b ku mz kx na la nb le nc li nd lm od mw mx my bi translated">实施深度学习模型，从简单的 CNN 到 ResNets 和 MobileNets</li><li id="41e8" class="mq mr jb kt b ku mz kx na la nb le nc li nd lm od mw mx my bi translated">向比赛提交了成果，给了我们自己一个大大的鼓励，并通过创建一个应用程序来庆祝项目的结束！</li></ol><p id="a16a" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">以下是在训练深度学习网络时学到的一些经验:</p><ul class=""><li id="9b20" class="mq mr jb kt b ku kv kx ky la ms le mt li mu lm mv mw mx my bi translated">获得该算法的一个基本实现，首先在一个较小的数据集上测试它，以节省执行时间</li><li id="04a3" class="mq mr jb kt b ku mz kx na la nb le nc li nd lm mv mw mx my bi translated">探索所有可用的 GPU 选项，并根据任务所需的计算强度在它们之间进行交替</li><li id="50f2" class="mq mr jb kt b ku mz kx na la nb le nc li nd lm mv mw mx my bi translated">随着时代的增加而降低学习率。我们有一个名为 ReduceLRonplateau 的内置函数来执行这个操作。这影响了模型在平台期的学习</li></ul><p id="d070" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">总的来说，这个项目非常值得！作为研究生，我们抓住了这两个机会(希望如此！)打动我们的教授，参加有声望的比赛。我们能够第一次通过处理图像分类来挑战自己，并且得出了非常令人满意的结果。</p><h1 id="164b" class="lo lp jb bd lq lr ls lt lu lv lw lx ly kh lz ki ma kk mb kl mc kn md ko me mf bi translated">参考</h1><p id="5f4d" class="pw-post-body-paragraph kr ks jb kt b ku mg kc kw kx mh kf kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">这些工作没有一项是我们自己能够完成的。查看以下参考资料，获取我们使用的所有重要资源:</p><p id="66b0" class="pw-post-body-paragraph kr ks jb kt b ku kv kc kw kx ky kf kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><a class="ae ln" href="https://cloud.google.com/blog/products/gcp/drawings-in-the-cloud-introducing-the-quick-draw-dataset" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/blog/products/GCP/drawings-in-the-cloud-introducing-the-quick-draw-dataset</a><br/>T3】https://ai . Google blog . com/2017/04/teaching-machines-to-draw . html<br/><a class="ae ln" href="https://www.kaggle.com/c/quickdraw-doodle-recognition" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/quickdraw-doodle-recognition</a><br/><a class="ae ln" href="https://www.blog.google/technology/ai/quick-draw-one-billion-drawings-around-world/" rel="noopener ugc nofollow" target="_blank">https://www . blog . Google/technology/ai/quick-draw-10 亿次绘图-环游世界/ </a> <br/>q = https://stats . stack exchange . com/questions/148139/rules-for-selecting-convolutionary-neural-network-hyperparameters&amp;sa = D&amp;ust = 1544740608219000&amp;usg = afqjcngwjl 5 gpzwwpkmpfclt 6 qinwqnha<br/><a class="ae ln" href="http://ruder.io/optimizing-gradient-descent/index.html#adam" rel="noopener ugc nofollow" target="_blank">http://ruder.io/optimizing-gradient-descent/index.html#adam</a><br/><a class="ae ln" href="http://cs231n.stanford.edu/reports/2016/pdfs/264_Report.pdf" rel="noopener ugc nofollow" target="_blank">http://cs231n.stanford.edu/reports/2016/pdfs/264_Report.pdf</a><br/></p></div></div>    
</body>
</html>