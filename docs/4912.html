<html>
<head>
<title>A Density-based algorithm for outlier detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一种基于密度的离群点检测算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/density-based-algorithm-for-outlier-detection-8f278d2f7983?source=collection_archive---------2-----------------------#2018-09-15">https://towardsdatascience.com/density-based-algorithm-for-outlier-detection-8f278d2f7983?source=collection_archive---------2-----------------------#2018-09-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="044a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">离群点检测(也称为异常检测)是发现行为与预期非常不同的数据对象的过程。这种对象被称为异常值或异常值。最有趣的物体是那些明显偏离正常物体的物体。离群值不是由与其余数据相同的机制生成的。<br/>异常值检测在许多应用中非常重要，例如:</p><ul class=""><li id="c1a1" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk kq kr ks kt bi translated">通信网络中的入侵</li><li id="9101" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">财务数据中的欺诈</li><li id="dad7" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">假新闻和错误信息</li><li id="591f" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">医疗保健分析</li><li id="263d" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">工业损伤检测</li><li id="a2c8" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">安全和监控</li><li id="3b8e" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">等等</li></ul><p id="0d73" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">离群点检测和聚类分析是两个高度相关的任务。聚类发现数据集中的大多数模式，并相应地组织数据，而异常值检测试图捕获那些与大多数模式有很大差异的异常情况。</p><p id="fed6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我将介绍离群点检测的基本方法，并重点介绍一类基于邻近度的方法。此外，我将提供一个 LOF 算法的代码实现。</p><figure class="la lb lc ld gt le gh gi paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="gh gi kz"><img src="../Images/761ce1a74dd8011abefc64d7d621e6ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sn_tPmQVusDZFccbAOVxAQ.jpeg"/></div></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk">Nassim taleb is an inventor of <a class="ae lp" href="https://en.wikipedia.org/wiki/Black_Swan_theory" rel="noopener ugc nofollow" target="_blank">Black Swan theory</a> — extreme impact of rare and unpredictable <a class="ae lp" href="https://en.wikipedia.org/wiki/Outlier" rel="noopener ugc nofollow" target="_blank">outlier</a> event and the human tendency to find simplistic explanations for these events, retrospectively.</figcaption></figure><h2 id="d58f" class="lq lr iq bd ls lt lu dn lv lw lx dp ly jy lz ma mb kc mc md me kg mf mg mh mi bi translated">离群值和噪声数据</h2><p id="88bc" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">首先，你需要从嘈杂的数据中分辨出离群值。</p><p id="7251" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在应用异常值检测时，应该去除噪声。它可能会扭曲正常对象，模糊正常对象和异常值之间的区别。这可能有助于隐藏异常值并降低异常值检测的有效性。例如，如果用户考虑购买比他以前通常购买的更贵的午餐，这种行为应该被视为“噪声交易”，如“随机误差”或“方差”。</p><h1 id="8e93" class="mo lr iq bd ls mp mq mr lv ms mt mu ly mv mw mx mb my mz na me nb nc nd mh ne bi translated">异常值的类型</h1><p id="47f8" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">一般来说，离群值可以分为三类，即全局离群值、上下文(或条件)离群值和集体离群值。</p><ul class=""><li id="f7b2" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk kq kr ks kt bi translated">全局异常值-对象明显偏离数据集的其余部分</li><li id="955f" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">上下文异常值—对象根据选定的上下文显著偏离。例如，28⁰C 是莫斯科冬天的异常值，但在另一种情况下不是异常值，28⁰C 不是莫斯科夏天的异常值。</li><li id="ea69" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">集体离群值—数据对象的子集集体显著偏离整个数据集，即使单个数据对象可能不是离群值。例如，一个小团体在短时间内大量交易同一只股票，可以被认为是操纵市场的证据。</li></ul><figure class="la lb lc ld gt le gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/4391ecc4a45f962770a89a4ef83b9711.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*kR2QCzuxEZDLuu0-pNV3sg.png"/></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk">Collective outlier.</figcaption></figure><p id="3302" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通常，一个数据集可能包含不同类型的异常值，同时可能属于不止一种异常值。</p><h1 id="8ef7" class="mo lr iq bd ls mp mq mr lv ms mt mu ly mv mw mx mb my mz na me nb nc nd mh ne bi translated">离群点检测方法</h1><p id="2699" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">在文献中有许多离群点检测方法，并在实践中使用。首先，离群点检测方法根据用于分析的数据样本是否具有领域专家提供的标签而不同，这些标签可用于建立离群点检测模型。第二，方法可以根据它们对正常对象和异常值的假设分成不同的组。</p><p id="5bec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果可以获得正常和/或异常对象的专家标记的示例，则它们可以用于建立异常检测模型。使用的方法可分为监督方法、半监督方法和非监督方法。</p><h2 id="1ac8" class="lq lr iq bd ls lt lu dn lv lw lx dp ly jy lz ma mb kc mc md me kg mf mg mh mi bi translated">监督方法</h2><p id="159b" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">我们将异常检测建模为一个分类问题。领域专家检查的样本用于培训和测试。</p><p id="a866" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">挑战:</p><ul class=""><li id="5112" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk kq kr ks kt bi translated">阶级不平衡。也就是说，异常值的总体通常比正常对象的总体小得多。可以使用处理不平衡类的方法，例如过采样。</li><li id="7b08" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">捕捉尽可能多的异常值，即召回比准确性更重要(即不要将正常对象误标为异常值)</li></ul><h2 id="e891" class="lq lr iq bd ls lt lu dn lv lw lx dp ly jy lz ma mb kc mc md me kg mf mg mh mi bi translated">无监督方法</h2><p id="7ee9" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">在某些应用场景中，标记为“正常”或“异常值”的对象不可用。因此，必须使用无监督的学习方法。无监督的离群点检测方法做出了一个隐含的假设:正常对象在某种程度上是“聚集的”换句话说，无监督离群点检测方法期望正常对象比离群点更频繁地遵循一种模式。</p><p id="dcdc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">挑战:</p><ul class=""><li id="a2ba" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk kq kr ks kt bi translated">正常对象可能不共享任何强模式，但是集体离群值可能在小区域中共享高相似性</li><li id="0649" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">如果正常活动是多样的并且不属于高质量的聚类，则无监督的方法可能具有高的假阳性率，并且可能让许多实际的异常值未被检测到。</li></ul><p id="3381" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最新的非监督方法开发了智能思想，直接处理离群值，而无需显式检测聚类。</p><h2 id="07b3" class="lq lr iq bd ls lt lu dn lv lw lx dp ly jy lz ma mb kc mc md me kg mf mg mh mi bi translated">半监督方法</h2><p id="21d1" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">在许多应用中，虽然获得一些标记的例子是可行的，但是这种标记的例子的数量通常很少。如果一些带标签的正常对象可用:</p><ul class=""><li id="8144" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk kq kr ks kt bi translated">使用已标记的示例和最接近的未标记对象来训练正常对象的模型</li><li id="7856" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">不符合正常对象模型的那些被检测为异常值</li></ul><p id="675d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果只有一些标记异常值可用，少量的标记异常值可能无法很好地覆盖可能的异常值。</p><h1 id="ed2d" class="mo lr iq bd ls mp mq mr lv ms mt mu ly mv mw mx mb my mz na me nb nc nd mh ne bi translated">统计方法</h1><p id="c455" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">统计方法(也称为基于模型的方法)假设正态数据遵循某种统计模型(随机模型)。其思想是学习适合给定数据集的生成模型，然后将模型的低概率区域中的对象识别为异常值。</p><h2 id="6498" class="lq lr iq bd ls lt lu dn lv lw lx dp ly jy lz ma mb kc mc md me kg mf mg mh mi bi translated">参数方法</h2><p id="e02b" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">参数方法假设正态数据对象是由具有参数𝜃.的参数分布生成的参数分布<em class="ng"> f(x，</em> 𝜃 <em class="ng"> ) </em>的概率密度函数给出了对象<em class="ng"> x </em>由该分布生成的概率。该值越小，<em class="ng"> x </em>越有可能是异常值。</p><p id="3c1a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于随机模型，正常对象出现在高概率区域，低概率区域的对象是异常值。</p><p id="09a3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">统计方法的有效性高度依赖于对分布的假设。</p><p id="4af0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，考虑具有正态分布的单变量数据。我们将使用最大似然法检测异常值。</p><figure class="la lb lc ld gt le gh gi paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="gh gi nh"><img src="../Images/444e00cbdbeba3b6bd60513816603da7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IamNCi6ihVMOV8fP7evZ4Q.png"/></div></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk">Maximum likelihood methods to estimate the parameter 𝜇 and 𝜎</figcaption></figure><p id="a939" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对𝜇和𝜎求导，并求解一阶条件的结果系统，得到以下最大似然估计</p><figure class="la lb lc ld gt le gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/4e47348f8ffebecbe5b783c73d597f1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*jtUKKdXvoOvWGUIAWHsK2g.png"/></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk">Maximum likelihood estimates of 𝜇 and 𝜎²</figcaption></figure><figure class="la lb lc ld gt le"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="d49f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">偏离值最大的是 24⁰，偏离平均值 4.61。我们知道𝜇 +/- 3𝜎地区包含了正态分布假设下的 97%的数据。因为 4.61/1.54 &gt; 3，我们认为 24⁰是一个异常值。</p><p id="08f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，我们可以使用另一种统计方法，称为格拉布斯检验，并计算 z 分数。</p><figure class="la lb lc ld gt le gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/25f03f1185e67a97f6052dacf3585c0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*bARaxg_biKQ_FD9k9eRUEQ.png"/></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk">s — standart deviation</figcaption></figure><figure class="la lb lc ld gt le gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/ab41c4ae110bb225ea2a78b4a0c23bbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*e5UN661ZKwZ11mmXnfajNg.png"/></div></figure><p id="957f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是我们很少处理只有一个属性的数据。涉及两个或多个属性的数据称为多元数据。这些方法的中心思想是将多元数据转化为单变量异常检测问题。<br/>一种流行的方法是𝜒 - <em class="ng">统计法。</em></p><figure class="la lb lc ld gt le gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/e99cbdb1ba810ae74cb2b0684cbd59af.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*u4I8OtXgCXVQ0RbbFbdvYw.png"/></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk">Oi — the value of O in i-th dimension. Ei — the mean of the i-th dimension among all objects, n — dimensionality.</figcaption></figure><p id="845b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果𝜒 -大，该对象是一个离群值。</p><p id="89d2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">参数模型的主要缺点是，在许多情况下，数据分布可能是未知的。</p><p id="08a1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，如果我们有两个大的集群，关于正态分布的假设就不适用。</p><figure class="la lb lc ld gt le gh gi paragraph-image"><div class="gh gi no"><img src="../Images/e34521b355e061174c7ff2964a05e37f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*EHU8DiQRdJJ-T9_fqfJ19Q.png"/></div></figure><p id="c17b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">相反，我们假设正态数据对象由多个正态分布𝛩 (𝜇1，𝜎1)和𝛩 (𝜇2，𝜎2)生成，并且对于数据集中的每个对象<strong class="jp ir"> o </strong>，我们计算由混合分布生成的概率。</p><p id="2a26" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="ng">pr(</em><strong class="jp ir"><em class="ng">o</em></strong><em class="ng">|𝛩1，𝛩2)= f𝛩1(</em><strong class="jp ir"><em class="ng">o</em></strong><em class="ng">)+f𝛩2(</em><strong class="jp ir"><em class="ng">o</em></strong><em class="ng">)</em></p><p id="c18f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中<em class="ng">f𝛩1(</em><strong class="jp ir"><em class="ng">o</em></strong><em class="ng">)——分别为</em> 𝛩1 和𝛩2 的概率密度函数。为了学习参数𝜇和𝜎，我们可以使用 EM 算法。EM 算法的一个例子可以在<a class="ae lp" href="https://github.com/zkid18/Machine-Learning-Algorithms/blob/master/EM-algorithm.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h2 id="b7bb" class="lq lr iq bd ls lt lu dn lv lw lx dp ly jy lz ma mb kc mc md me kg mf mg mh mi bi translated">非参数方法</h2><p id="63d1" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">在用于异常值检测的非参数方法中，从输入数据中学习“正常数据”的模型，而不是先验地假设一个模型。非参数方法通常对数据做较少的假设，因此可以适用于更多的情况。例如，我们可以使用直方图。</p><p id="ab44" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在最简单的方法中，如果对象在直方图仓之一中失败，则认为它是正常的。缺点是很难选择箱子的大小。</p><h1 id="4c45" class="mo lr iq bd ls mp mq mr lv ms mt mu ly mv mw mx mb my mz na me nb nc nd mh ne bi translated">基于邻近的算法</h1><p id="1406" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">给定特征空间中的一组对象，可以使用距离度量来量化对象之间的相似性。直观上，距离他人较远的对象可以视为离群值。基于邻近度的方法假设离群对象与其最近邻居的邻近度明显偏离该对象与数据集中大多数其他对象的邻近度。</p><p id="577b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基于邻近度的算法可以分为基于距离的方法(如果一个对象的邻域没有足够的点，则该对象是异常值)和基于密度的方法(如果一个对象的密度比其邻域的密度相对低得多，则该对象是异常值)</p><h2 id="846c" class="lq lr iq bd ls lt lu dn lv lw lx dp ly jy lz ma mb kc mc md me kg mf mg mh mi bi translated">基于密度</h2><p id="88ba" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">基于距离的离群点检测方法参考由给定半径定义的对象的邻域。如果一个对象的邻域没有足够多的其他点，则该对象被认为是异常值。</p><p id="ab39" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">距离阈值可以被定义为对象的合理邻域。对于每个对象，我们可以找到一个对象的合理数量的邻居。</p><p id="4346" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">形式上，设<em class="ng"> r(r &gt; 0) </em>为距离阈值，𝜋 <em class="ng"> (0 &lt; 𝜋 &lt; 1) </em>为分数阈值。的一个对象<strong class="jp ir"> o 是<em class="ng"> DB(r，</em> 𝜋 <em class="ng"> ) </em></strong></p><figure class="la lb lc ld gt le gh gi paragraph-image"><div class="gh gi np"><img src="../Images/295fa961fb6eae62b944154d23b45092.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*uUxtr3_XtbkMqVxaPYFqyQ.png"/></div></figure><p id="9f62" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="ng">距离</em> —距离测量。</p><p id="24d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">简单的方法需要 O(n)时间。</p><p id="ff9a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">挖掘基于距离的异常值的算法；</p><ul class=""><li id="5c98" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk kq kr ks kt bi translated">基于索引的算法</li><li id="a8fd" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">嵌套循环算法</li><li id="c6ac" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">基于单元的算法</li></ul><h2 id="2da9" class="lq lr iq bd ls lt lu dn lv lw lx dp ly jy lz ma mb kc mc md me kg mf mg mh mi bi translated">基于密度的方法</h2><p id="75da" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy ml ka kb kc mm ke kf kg mn ki kj kk ij bi translated">基于密度的离群点检测方法研究对象及其邻居的密度。这里，如果一个对象的密度比其邻居的密度相对低得多，则该对象被识别为异常值。</p><p id="2160" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">许多真实世界的数据集展示了更复杂的结构，其中对象可以被认为是关于它们的局部邻域的离群值，而不是关于全局数据分布的离群值。</p><figure class="la lb lc ld gt le gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/2202eb602cc127ee733798eff1a10ef5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*zHb0zMV1lD6VVBDY3tssZQ.png"/></div></figure><p id="46d7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">考虑上面的例子，基于距离的方法能够检测到 o3，但是对于 o1 和 o2 就不那么明显了。</p><p id="5063" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基于密度的思想是，我们需要将对象周围的密度与其局部邻居周围的密度进行比较。基于密度的异常检测方法的基本假设是，非异常对象周围的密度与其邻居周围的密度相似，而异常对象周围的密度与其邻居周围的密度显著不同。</p><p id="ac67" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="ng">dist _ k(o)</em>-是对象<strong class="jp ir"> o </strong>和 k 个最近邻之间的距离。o<strong class="jp ir">的 k 距离邻域包含所有到</strong>o<strong class="jp ir">的距离不大于<em class="ng">dist _ k(o)</em>o<strong class="jp ir">o</strong>的第 k 个距离的物体</strong></p><figure class="la lb lc ld gt le gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/ed6d672bec92eb481afa9975967c8d1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*pjq3Ldl6Yq2yQiriVsPlNw.png"/></div></figure><p id="65ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以用 Nk(o)中的物体到 o<strong class="jp ir">的平均距离作为<strong class="jp ir"> o </strong>局部密度的度量。如果<strong class="jp ir"> o </strong>具有非常接近的邻居<strong class="jp ir">o’</strong>使得<em class="ng"> dist(o，o’)</em>非常小，则距离测量的统计波动可能会不期望地高。为了克服这个问题，我们可以通过添加平滑效果来切换到下面的可达性距离度量。</strong></p><figure class="la lb lc ld gt le gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/91cd21050e5018bf2adbd4aa8bbb142b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*0a7x4i3PazXBi3StuO-Wxw.png"/></div></figure><p id="ba08" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="ng"> k </em>是用户指定的参数，控制平滑效果。本质上，<em class="ng"> k </em>指定了要检查的最小邻域，以确定对象的局部密度。可达性距离是不对称的。</p><p id="b9c0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一个对象<strong class="jp ir"> o </strong>的局部可达性密度为</p><figure class="la lb lc ld gt le gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/887aaf65d9997098cd7752c7507f18bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*yIiJoxYkq4kPDsqmwCYGgA.png"/></div></figure><p id="8bd8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们计算一个对象的局部可达性密度，并将其与其邻居的可达性密度进行比较，以量化该对象被视为离群值的程度。</p><figure class="la lb lc ld gt le gh gi paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="gh gi nu"><img src="../Images/4217b639fd698183b34b1e06598599fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nLw41FmHDdx7CyMCprc6Gg.png"/></div></div></figure><p id="a533" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">局部离群因子是<strong class="jp ir"> o </strong>的局部可达性密度与<strong class="jp ir"> o 的</strong> k 个最近邻的局部可达性密度之比的平均值。<strong class="jp ir"> o </strong>的局部可达性密度越低，o 的<em class="ng"> k </em>最近邻的局部可达性密度越高，则 LOF 值越高。这准确地捕获了局部离群值，其局部密度与其 k 个最近邻居的局部密度相比相对较低。</p><figure class="la lb lc ld gt le gh gi paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="gh gi nv"><img src="../Images/a7d9990ddfc70cdf114919dd8f84f9b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vyqUwFsjwnuF1vdMrzNikQ.png"/></div></div></figure><p id="b72d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">LOF 算法</p><p id="e112" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基于 data.csv 中的点击流事件频率模式，我们将应用 LOF 算法计算每个点的 LOF，初始设置如下:</p><ol class=""><li id="84dd" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk nw kr ks kt bi translated">k = 2 并使用曼哈顿距离。</li><li id="5fb0" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk nw kr ks kt bi translated">k = 3 并使用欧几里德距离。</li></ol><p id="e746" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">结果，我们将找到 5 个异常值和它们的<em class="ng"> LOF_k(o) </em></p><p id="1814" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">数据可以从 github <a class="ae lp" href="https://github.com/zkid18/Machine-Learning-Algorithms" rel="noopener ugc nofollow" target="_blank">库</a>下载</p><figure class="la lb lc ld gt le gh gi paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="gh gi nx"><img src="../Images/a27357c9d6e36ebd21b9aa1c90da88ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b3MeGxkJndROYlDDrsMC3g.png"/></div></div></figure><figure class="la lb lc ld gt le"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="2625" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">参考文献</strong></p><ul class=""><li id="27f9" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk kq kr ks kt bi translated"><a class="ae lp" href="http://www.kdnuggets.com/2017/01/3-methods-deal-outliers.html" rel="noopener ugc nofollow" target="_blank">http://www . kdnugges . com/2017/01/3-methods-deal-outliers . html</a></li><li id="a835" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated"><a class="ae lp" href="https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2016/01/guide-data-exploration/</a></li><li id="8224" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">韩佳玮，Micheline Kamber，JianPei 数据挖掘概念和技术-第 3 版-摩根-考夫曼-2011 <a class="ae lp" href="https://www.amazon.com/Data-Mining-Concepts-Techniques-Management/dp/0123814790" rel="noopener ugc nofollow" target="_blank">【亚马逊】</a></li><li id="21a5" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated"><a class="ae lp" rel="noopener" target="_blank" href="/a-brief-overview-of-outlier-detection-techniques-1e0b2c19e561">https://towards data science . com/a-brief-overview-of-outlier-detection-techniques-1e 0 b 2c 19 e 561</a></li></ul><p id="c323" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">MSBD 5002 HKUST 讲稿</p></div></div>    
</body>
</html>