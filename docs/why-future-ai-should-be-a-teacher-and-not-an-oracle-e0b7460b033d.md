# 为什么未来的人工智能应该是老师而不是先知

> 原文：<https://towardsdatascience.com/why-future-ai-should-be-a-teacher-and-not-an-oracle-e0b7460b033d?source=collection_archive---------3----------------------->

请少预测，多洞察。

![](img/67d2ef42737aa32fb9cb0c117b63b925.png)

Taken from [pexels](https://static.pexels.com/photos/301926/pexels-photo-301926.jpeg)

虽然现在开发算法是我的工作，但我仍然对深度学习和大部分机器学习持有健康的偏见。尽管它做出了强有力的预测，但我还没有看到它产生多少对社会有价值的直接见解。如果我们自己不能从算法中学习，那么学习算法有什么意义呢？

好吧，我承认，有时候我们通过观察向他们学习。例如，通过观察算法正在做什么，人类象棋和围棋选手正在变得更好。当然还有很多东西要学。但是，如果算法能立即告诉我们为什么，岂不是更有效率？

# 黑匣子的问题是

正如 Pentland 教授在最近的 Edge conversation 中描述的那样，问题是这些算法没有使用我们目前拥有的所有物理和因果知识。只是愚蠢的神经元拼凑出无限多的小近似值。它不能一概而论，因此仍然容易出错。

当算法无法理解的新数据到来时，它没有意识到这一点，只是变得疯狂。

最重要的是，它不知道训练数据中所有可能的偏差。

当它出错时，我们无法向客户和经理解释原因。当然也不会对法官和陪审团说，如果你发现自己因算法决策出错而被送上法庭。

彭特兰教授描述了在我们的人工智能中使用更多的物理功能。使用已知的因果结构。来制造洞察发生器，而不仅仅是做预测。这种方法比目前的暴力算法更吸引我。

# 为什么我们选择白盒

在我的工作中，数学家、领域专家(物理学家)和业务经理之间会就算法进行无休止的讨论。最终，我们希望[建造智能机器](https://www.asml.com/careers/working-at-asml/en/s32408?rid=42455)，在物理可能的边缘运行。

数学家和数据科学家提出了许多他们想使用的新奇算法。虽然在一个封闭的行业中仍然很难找到足够多的好数据，但它们有时确实有效。

物理学家谴责了其中的大部分，因为它们没有使用真实世界的信息。那么我们怎么能相信他们输出的东西呢？

业务经理想要业绩保证。他们想要控制和责任。我们怎么得到这个？

我们最终选择了更多的白盒方法。期望多项式或正弦函数的线性回归。也许是简单的决策树。如果需要，一些贝叶斯规则。用已知的物理约束来规范一切。通过正确的努力，结果通常表现得与任何神经网络方法一样好，但好处是知道为什么。

除此之外，我们还使用算法，利用我们对数据行为的了解来监控传入的数据。因为如果数据以意想不到的方式变化，我们就不能再相信我们的输出预测。

然后我们得到我们可以控制的算法，并解释它们何时出错。然而，他们不会自动更新他们的物理假设。同样地，它们也不会教我们任何我们不知道的世界。

# 支持黑盒

我仍然想为黑盒算法辩护。

## 1.他们工作

首先，它们可以工作得非常好！目前的深度神经网络非常棒，尤其是对于那些拥有所有数据的人来说。没有更好的方法来检测猫的图像，或者把它们画成梵高的风格。我们一直在尝试的一个很好的应用是使用这些黑盒算法作为基准来测试我们的白盒是否丢失了一些信息。

## 2.他们老了

支持黑盒算法的另一个理由非常简单。我们已经每天都信任他们。尽管心理学和神经科学取得了很大进步，但我们对自己的大脑却知之甚少，更不用说社交网络的运作了。

我们的大脑几乎是一个黑匣子。然而，我们信任他们，因为他们经常给我们口头陈述他们的内部推理。然而，我们也知道我们的头脑充满了偏见，经常会感知到与实际不同的世界。

## 3.它们可以被改进

也许我们可以通过创建输出一些冗长的基本原理的算法来使用这些知识。如果我们问它为什么做了某个预测，它会给自己一些合理的解释。DARPA 称之为人工智能的第三次浪潮。例如，如果 HR 算法拒绝了一个候选人，它会说它是根据人的肤色拒绝的。之后我们可以说:“不，不，那是不可接受的，请更新你的神经网络”。然后，它可能会相应地这样做，或者只是提出更好的理由。不利的一面是，我们可能不得不处理说谎算法的可能性。

# 洞察网络

我们有一个有影响力的同事喜欢贝叶斯网络。在这些方法中，您将大量观察结果和根本原因与它们的基本比率拼凑在一起，并使用贝叶斯规则作为连接。当新的观察结果出现时，所有的概率都会更新，并且可以确定一个可能的原因。后来你就知道推论是如何发生的了。

它不能教你新的观察，但是它对复杂环境中的根本原因分析很有帮助。我会说这是未来许多有趣的途径之一。

# 你想要什么样的老师？

看，你可以说 AI 已经在教我们了。你整天向搜索引擎提问，得到回答作为回报。如果你正确地训练它们，算法可以给你提供有价值的知识。在 Medium 上，我向世界各地的作家学习，通过 Medium 的人工智能来学习。

然而，你不能问它为什么给你那些答案和文章。好的教学是一个开放的双向过程。只要黑盒的表现优于白盒，创造赚钱神谕的人就没有动力改变他们的方式。这意味着要靠世界其他地方来培养我们未来的教师。我真的希望更多的人觉得这值得努力。