<html>
<head>
<title>Only Numpy: Implementing and Comparing Combination of Google Brain’s Decoupled Neural Interfaces (Synthetic Gradients) and Google Brain’s Gradient Noise with interactive code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Only Numpy:使用交互式代码实现和比较Google Brain的去耦神经接口(合成梯度)和Google Brain的梯度噪声的组合</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/only-numpy-implementing-and-comparing-combination-of-google-brains-decoupled-neural-interfaces-6712e758c1af?source=collection_archive---------5-----------------------#2018-01-22">https://towardsdatascience.com/only-numpy-implementing-and-comparing-combination-of-google-brains-decoupled-neural-interfaces-6712e758c1af?source=collection_archive---------5-----------------------#2018-01-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/b4801c11960d5c93228e51b31bf0d567.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*VpYiz-mEEyF5JiGm0LhcZw.gif"/></div></div></figure><p id="0aeb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">所以我在想，Google Brain发表了这篇论文“<a class="ae kw" href="https://arxiv.org/pdf/1608.05343.pdf" rel="noopener ugc nofollow" target="_blank">使用合成梯度去耦合神经接口</a>”，它可以同时训练每一层。当执行反向传播时，网络架构以每层不依赖于下一层梯度的方式构建。(算是吧)。</p><p id="5ebd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">而且他们还发表了这篇论文“<a class="ae kw" href="https://arxiv.org/abs/1511.06807" rel="noopener ugc nofollow" target="_blank">添加梯度噪声提高了对非常深的网络的学习</a> s”。几天前我写了一篇博文，关于将<a class="ae kw" href="https://becominghuman.ai/only-numpy-implementing-adding-gradient-noise-improves-learning-for-very-deep-networks-with-adf23067f9f1" rel="noopener ugc nofollow" target="_blank">高斯噪声添加到反向传播以使学习更快</a>，现在让我们将这两个想法结合起来。</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi kx"><img src="../Images/f104c1841c188349d031147bf24aa6ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YIMB1PcARtB6PaIk4qSNkg.jpeg"/></div></div></figure><p id="ed97" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">所以我们总共可以检查4个案例。</p><p id="22a7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">1 →纯神经网络<br/> 2 →解耦神经接口<br/> 3 →纯神经网络+高斯噪声<br/> 4 →解耦神经接口+高斯噪声</p><h1 id="2740" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">热门人工智能文章:</h1><blockquote class="ma"><p id="e153" class="mb mc iq bd md me mf mg mh mi mj kv dk translated"><a class="ae kw" href="https://becominghuman.ai/google-will-beat-apple-at-its-own-game-with-superior-ai-534ab3ada949" rel="noopener ugc nofollow" target="_blank"> 1。谷歌将凭借卓越的人工智能在自己的游戏中击败苹果</a></p><p id="85bc" class="mb mc iq bd md me mf mg mh mi mj kv dk translated"><a class="ae kw" href="https://becominghuman.ai/the-ai-job-wars-episode-i-c18e932ff225" rel="noopener ugc nofollow" target="_blank"> 2。人工智能职业战争:第一集</a></p><p id="ccd5" class="mb mc iq bd md me mf mg mh mi mj kv dk translated"><a class="ae kw" href="https://becominghuman.ai/introducing-open-mined-decentralised-ai-18017f634a3f" rel="noopener ugc nofollow" target="_blank"> 3。引入露天开采:分散人工智能</a></p></blockquote><p id="da77" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated"><strong class="ka ir">阅读前</strong></p><p id="ffe6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我假设你们所有人都已经非常熟悉去耦神经接口和高斯噪声。如果没有，请点击下面的链接。</p><p id="15be" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于解耦的<a class="ae kw" href="http://iamtrask.github.io/2017/03/21/synthetic-gradients/" rel="noopener ugc nofollow" target="_blank">神经接口，请阅读来自</a> Trask的这篇惊人的帖子。来自m  e LOL的这篇并不令人印象深刻的博文。</p><p id="d5d5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于高斯噪声，<a class="ae kw" href="https://becominghuman.ai/only-numpy-implementing-adding-gradient-noise-improves-learning-for-very-deep-networks-with-adf23067f9f1" rel="noopener ugc nofollow" target="_blank">请阅读本博客</a>。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="fee9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">免责声明</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mw"><img src="../Images/bdc4f3bd4adea9824f8385977dfa43a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nU38XnS45k6fyqDdsuMc7Q.png"/></div></div></figure><p id="035c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">上面是我在Trinket上运行代码时得到的结果，下面是我在桌面上运行代码时得到的结果。</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/388e586dab3c4ce9a1c7abc830f477da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*wKPDx_K3QOx_zoCtsfn7tw.png"/></div></figure><p id="12b3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如图所示，分类结果的颜色存在差异。尽管我使用了相同的np.random.seed()值，但结果还是略有不同。我不知道为什么会这样，但它确实存在，所以如果你知道为什么，请在下面评论。此外，我将使用我的笔记本电脑上的屏幕截图和东西的结果。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="1569" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">声明超参数和训练数据</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/beda143925f88c8dfd6f15aae6e463b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*qzd49tEMr82g4CVdM7Q8FQ.png"/></div></figure><p id="074c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如上所述，这是一个简单的分类任务，到处都有一些噪声。现在让我们创建权重变量并复制它们，以确保我们从相同的权重开始。</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi my"><img src="../Images/82a42b28c9e605cfe7358badb95bfe59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Oc-fLUN01yy1jx1BUDtwAg.png"/></div></div></figure><p id="8c7d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如上所示，总共有18个砝码。红框内的权重用于<em class="mz">情况2:解耦神经接口</em>，蓝框内的权重用于<em class="mz">情况4:解耦神经接口+高斯噪声。</em></p><p id="9f6c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，请注意，对于分离的神经接口，我们不仅需要合成梯度的权重，还需要每层的权重，因此我们需要绿色框内的权重。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="a401" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">DNI的网络架构</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi na"><img src="../Images/501052467a720ac58400520d756bcfd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7qoVJeKQEIhCriY_48w1Fw.jpeg"/></div></div></figure><p id="e64b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">上面是一个可怕的网络架构，来自我的媒体帖子，它并不代表我们将要实现的网络，但它确实得到了解耦神经接口的一般结构。再次为更多的信息，请阅读我已经包括的链接。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="61a4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">纯神经网络和DNI的前馈</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/a4abe3774e786bba78215edcd60d4976.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*4UC5TXXc4PC2fSczY7DaIQ.png"/></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk">Forward Feed For Pure NN</figcaption></figure><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ng"><img src="../Images/dc4ba83b332c5a6d88334d65e42cfd4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1rS07FNLMZ0FqkxrVZGZsw.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk">Partial View for Forward Feed for DNI</figcaption></figure><p id="02dc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">标准的神经网络前馈过程是容易和简单的，没有更多的添加。但是对于DNI来说，这就有点复杂了，因为我们可以在完成前馈过程后立即对重量进行反向传播。</p><p id="e4c7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">蓝框→更新层1的权重(W1_DN) <br/>红框→更新层1的合成权重(W1_sythn)</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="4656" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">带有高斯噪声的反向传播</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nh"><img src="../Images/04bf6bcec4e6a362c65808c0f178a019.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M3oUsbM5ajTVvC6OwYIIjA.png"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk">Back Propagation with Gaussian Noise</figcaption></figure><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ni"><img src="../Images/eb7250f5ee0f14878dbe4079a8e712c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fT-uuSXqSnOzyzCcHFK2Mw.png"/></div></div></figure><p id="3d91" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于纯神经网络，高斯噪声下的标准反向传播也没什么特别的。但是对于DNI，当更新正常权重(红框)和合成权重(蓝框)时，我添加了高斯噪声。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="4d97" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">结果</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/388e586dab3c4ce9a1c7abc830f477da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*wKPDx_K3QOx_zoCtsfn7tw.png"/></div></figure><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nj"><img src="../Images/125bd07cc2fe58f6e141fca6edf226e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*32E4aDklikBCJx_emFmCiw.png"/></div></div></figure><p id="faf8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，无噪声解耦神经接口的最终成本最小。至少在这个场景中。当我玩hyper parameters的时候，我意识到DNI对学习速率非常敏感，你自己试试看，如果学习速率太大，我们会有梯度爆炸。</p><p id="5672" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，这有点令人困惑，因为我期望看到案例3和案例4的损失成本最小。不知道为什么会这样…(也许我会在未来的帖子中详细探讨这个想法。)</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/beda143925f88c8dfd6f15aae6e463b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*qzd49tEMr82g4CVdM7Q8FQ.png"/></div></figure><figure class="ky kz la lb gt jr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/4d7964c490ab5fc2de1267e242d61d2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*ILKANkKmDsKubmZ6D3IBJg.png"/></div></figure><p id="e83b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但是，当直接与基本事实和最终的分类进行比较时，我们可以看到，仅从颜色上看，情况2最接近基本事实。除了红色方框区域。</p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="546e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">交互代码</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nk"><img src="../Images/9abd92f1e496aa786e117f05c7901103.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HeNDIBAeXMGlPxNArWZXmA.png"/></div></div></figure><p id="781d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="mz">更新:我搬到谷歌Colab的交互代码！所以你需要一个谷歌帐户来查看代码，你也不能在谷歌实验室运行只读脚本，所以在你的操场上做一个副本。最后，我永远不会请求允许访问你在Google Drive上的文件，仅供参考。编码快乐！</em></p><p id="e069" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">要访问<a class="ae kw" href="https://colab.research.google.com/notebook#fileId=1Wxx9Zu6IW-Z7mwktjwz00g0H3MPJPtuY" rel="noopener ugc nofollow" target="_blank">互动代码，请点击这里。</a></p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><h2 id="af05" class="nl ld iq bd le nm nn dn li no np dp lm kj nq nr lq kn ns nt lu kr nu nv ly nw bi translated">最后的话</h2><p id="660e" class="pw-post-body-paragraph jy jz iq ka b kb nx kd ke kf ny kh ki kj nz kl km kn oa kp kq kr ob kt ku kv ij bi translated">我仍然很困惑为什么结果会是这样，我认为找出为什么会这样是个好主意…</p><p id="a3f6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，我看到了我在DNI上的旧帖子，并意识到这是多么可怕，我将很快重新访问解耦神经接口。</p><p id="74f7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果发现任何错误，请发电子邮件到jae.duk.seo@gmail.com找我。</p><p id="ccc9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">同时，在我的推特<a class="ae kw" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，并访问<a class="ae kw" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或我的<a class="ae kw" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>了解更多内容。如果你感兴趣，我还在简单的RNN <a class="ae kw" href="https://medium.com/@SeoJaeDuk/only-numpy-vanilla-recurrent-neural-network-with-activation-deriving-back-propagation-through-time-4110964a9316" rel="noopener">上做了反向传播。</a></p></div><div class="ab cl mp mq hu mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ij ik il im in"><p id="55aa" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">参考文献</strong></p><ol class=""><li id="0dc5" class="oc od iq ka b kb kc kf kg kj oe kn of kr og kv oh oi oj ok bi translated">Seo，J. D. (2017年12月24日)。Only Numpy:推导合成梯度中的前馈和反向传播(解耦神经…2018年1月22日检索，来自<a class="ae kw" href="https://medium.com/@SeoJaeDuk/only-numpy-deriving-forward-feed-and-back-propagation-in-synthetic-gradient-decoupled-neural-ca4c99666bbf" rel="noopener">https://medium . com/@ SeoJaeDuk/only-Numpy-derivating-Forward-feed-and-Back-Propagation-in-Synthetic-Gradient-Decoupled-Neural-ca4c 99666 bbf</a></li><li id="c947" class="oc od iq ka b kb ol kf om kj on kn oo kr op kv oh oi oj ok bi translated">Seo，J. D. (2018年1月18日)。only Numpy:Implementing " ADDING GRADIENT NOISE IMPROVES-LEARNING FOR-VERY-DEEP-NETWORKS-with-ADF 23067 F9 f1 2018年1月22日检索自<a class="ae kw" href="https://becominghuman.ai/only-numpy-implementing-adding-gradient-noise-improves-learning-for-very-deep-networks-with-adf23067f9f1" rel="noopener ugc nofollow" target="_blank">https://becoming human . ai/only-Numpy-Implementing-ADDING-GRADIENT-NOISE-IMPROVES-LEARNING-FOR-VERY-DEEP-NETWORKS-with-ADF 23067 F9 f1</a></li><li id="12ce" class="oc od iq ka b kb ol kf om kj on kn oo kr op kv oh oi oj ok bi translated">没有反向传播的深度学习。(未注明)。检索于2018年1月22日，来自<a class="ae kw" href="https://iamtrask.github.io/2017/03/21/synthetic-gradients/" rel="noopener ugc nofollow" target="_blank">https://iamtrask.github.io/2017/03/21/synthetic-gradients/</a></li><li id="3cfa" class="oc od iq ka b kb ol kf om kj on kn oo kr op kv oh oi oj ok bi translated">贾德伯格，m .，Czarnecki，W. M .，奥辛德罗，s .，维尼亚尔斯，o .，格雷夫斯，a .，&amp; Kavukcuoglu，K. (2016)。使用合成梯度的去耦神经接口。<em class="mz"> arXiv预印本arXiv:1608.05343 </em>。</li><li id="8851" class="oc od iq ka b kb ol kf om kj on kn oo kr op kv oh oi oj ok bi translated">Neelakantan，a .，Vilnis，l .，Le，Q. V .，Sutskever，I .，Kaiser，l .，Kurach，k .，和Martens，J. (2015年)。添加梯度噪声改善了对非常深的网络的学习。<em class="mz"> arXiv预印本arXiv:1511.06807 </em>。</li></ol><figure class="ky kz la lb gt jr"><div class="bz fp l di"><div class="oq or l"/></div></figure><div class="ky kz la lb gt ab cb"><figure class="os jr ot ou ov ow ox paragraph-image"><a href="https://becominghuman.ai/artificial-intelligence-communities-c305f28e674c"><img src="../Images/20880898f038333e31843bbd07b0e4df.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*2f7OqE2AJK1KSrhkmD9ZMw.png"/></a></figure><figure class="os jr ot ou ov ow ox paragraph-image"><a href="https://upscri.be/8f5f8b"><img src="../Images/dd23357ef17960a7bfb82e7b277f50f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*v-PpfkSWHbvlWWamSVHHWg.png"/></a></figure><figure class="os jr ot ou ov ow ox paragraph-image"><a href="https://becominghuman.ai/write-for-us-48270209de63"><img src="../Images/91ecfb22295488bc2c6af3d2ac34d857.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*Wt2auqISiEAOZxJ-I7brDQ.png"/></a></figure></div></div></div>    
</body>
</html>