<html>
<head>
<title>Can Machine Learning predict Poverty?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习能预测贫困吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/can-machine-learning-predict-poverty-5b4847a2f6b4?source=collection_archive---------3-----------------------#2018-03-24">https://towardsdatascience.com/can-machine-learning-predict-poverty-5b4847a2f6b4?source=collection_archive---------3-----------------------#2018-03-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/e718ca2b5fe23fec78a833d255c87891.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fjjI0jvybyR3gMnecdmJww.jpeg"/></div></div></figure><p id="3e2e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">世界银行在竞赛主办网站drivendata.org主办了贫困预测竞赛。比赛的链接是<a class="ae kw" href="https://www.drivendata.org/competitions/50/worldbank-poverty-prediction/" rel="noopener ugc nofollow" target="_blank">这里</a>。我们决定在这个数据集上测试我们的机器学习技能。在<a class="ae kw" href="https://www.paralleldots.com/" rel="noopener ugc nofollow" target="_blank"> ParallelDots </a>的大多数常规工作都围绕三个主题:图像和视频的视觉分析、医疗保健人工智能和自然语言处理，这三个主题都是使用深度学习技术解决的。这个比赛是一个尝试新事物的机会，并建立我们的内部代码库来处理表格数据集，就像我们在比赛中一样。</p><p id="68d7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们希望从竞赛中获得的最终结果是:</p><ol class=""><li id="2eee" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv lc ld le lf bi translated">尝试多种可能解决问题的机器学习模型。</li><li id="df8e" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">尝试现有的AutoML方法。(AutoML方法只需要你自己进行特征工程并找出管道的其余部分)</li><li id="b5ef" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">创建一个最佳模型来解决问题，而不需要集合太多的模型来提高分数。由于AIaaS是我们的日常工作，优化一个好的模型对我们来说更重要，因为集成很难作为服务部署。</li><li id="0daf" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">建立一个代码库来解决未来的数据科学和机器学习问题。</li></ol><h1 id="cb31" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">分析数据集(不费吹灰之力)</h1><p id="7276" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">在任何机器学习项目中，第一项任务是分析数据集并查看其属性。通过查看数据集，我们可以获得一些正确的信息:</p><ol class=""><li id="9011" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv lc ld le lf bi translated">有三个不同国家的数据文件。</li><li id="5ba9" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">所有的字段都是匿名和编码的，所以你不知道这些字段是什么意思。这将特定领域特性工程的可能性降低到零。</li><li id="fd7a" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">这三个国家的数据完全不同，因此需要建立三个模型，每个国家一个。</li></ol><p id="b285" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">(快速)深入数据的一个方法是使用新的软件包Pandas-Profiling(可以从GitHub <a class="ae kw" href="https://github.com/pandas-profiling/pandas-profiling" rel="noopener ugc nofollow" target="_blank">这里</a>下载)。这个包做了大量的初步分析，并将它们保存为漂亮的HTML文件，人们可以在浏览器上查看。我们对所有三个国家的数据进行了Pandas-Profiling分析，以了解数据类型、频率、相关性等。</p><p id="d259" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在下图中可以看到其中一个国家的示例输出:</p><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mo"><img src="../Images/e8599ae5ed66b3ae249498b15e069c0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sQnCLL50KfggGWjHlxKFoQ.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk"><em class="mx">Pandas Profiling shows overview for the country C data</em></figcaption></figure><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi my"><img src="../Images/654a3204ddd30101beb4d43d5fde940f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*daKO1xmX4Z0EMh_5GzI3OA.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk"><em class="mx">Feature Level Statistics details created by Pandas Profiling</em></figcaption></figure><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/e31631c3830a24ea5f695ab15d8a8d83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KbsEhoW8YZSC_tlZcC-Svw.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk"><em class="mx">Correlations amongst different features</em></figcaption></figure><p id="14b9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们可以得出的更多结论是:</p><ol class=""><li id="8bc9" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv lc ld le lf bi translated">大多数分类字段似乎都有一个默认值，这是该字段最常见的值。(例如，在上图中，您可以看到字段AOSWkWKB有一个默认值，它需要80%以上的时间)</li><li id="5feb" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">数据集是高度不平衡的，我们需要在训练时注意这一事实。</li></ol><h1 id="0794" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">建立数据模型的两种方法</h1><p id="dec2" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">如果查看对象的数据类型，可以看到数据是分类值(可以从常量可枚举值中取一的属性)和数值(浮点数和整数)的混合。事实上，这就是世界银行提供的随机森林基准的建模方式，可在此处获得。然而，当你看数字量时，它们并不多，可能代表出生日期等数量。(如果你上过<a class="ae kw" href="https://www.coursera.org/learn/competitive-data-science" rel="noopener ugc nofollow" target="_blank">的Coursera课程</a>，Dmitry在处理匿名化数据集一节中谈到了类似的领域)。因此，我们想尝试的另一种方法是将所有字段视为分类属性。我们最终都尝试了。</p><h1 id="5649" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">数据不平衡</h1><p id="3bc6" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">数据集的另一个重要属性是+ve和-ve类之间的不平衡(非贫困人口远远超过贫困人口)。对于国家A，数据仍然是平衡的，但是对于B和C，数据具有非常偏斜的分布。为了在这种扭曲的数据上训练模型，我们使用Python中的<a class="ae kw" href="http://contrib.scikit-learn.org/imbalanced-learn/stable/" rel="noopener ugc nofollow" target="_blank">不平衡学习库</a>尝试了不同的方法:</p><ol class=""><li id="b812" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv lc ld le lf bi translated">在倾斜的数据集上进行训练(效果不错，不太好)</li><li id="22b0" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">在负类欠采样的数据集上训练(表现非常差，即使最好的机器学习模型也可以与该数据集的基线一样好地工作)</li><li id="33d8" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">对+ve类进行过采样(工作得相当好)</li><li id="780e" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">使用SMOTE算法的过采样(不如正常的过采样有效，主要是因为SMOTE算法不是真正为分类属性定义的)</li><li id="3e9e" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">使用ADASYN进行过采样(不如正常过采样有效)</li></ol><h1 id="1ae6" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">预处理</h1><p id="79c3" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">数据集预处理如下:</p><ol class=""><li id="eb0b" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv lc ld le lf bi translated">所有分类特征都被转换成二元特征。</li><li id="3567" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">数值被归一化。测试了最大-最小和平均-标准差归一化。</li><li id="a5b2" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">家庭一级和个人一级的数据被合并(个人一级的数据为所有家庭的每个成员提供单独的数据)。对于个人和家庭数据中常见的属性，只保留了家庭一级的数据。家庭中的所有数字特征都取平均值(这可能不是最好的方法)，并且所有分类值都聚合为家庭中最奇怪的值(例如，如果特征X在家庭中的值为1，1，1，0，我们会将家庭的组合值取为0)。原因是许多分类变量都有默认值，而我们期望奇数值有更多的信息。</li></ol><h1 id="f53e" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">我们尝试过的方法</h1><p id="6c72" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">我们现在讨论我们尝试过的多种方法。</p><ul class=""><li id="2156" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv na ld le lf bi translated"><strong class="ka ir">首先，我们来谈谈那些不起作用的事情:</strong></li></ul><ol class=""><li id="fd97" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv lc ld le lf bi translated">我们认为分类字段的默认属性可能对建模没有用处。为了检查这一点，我们训练了具有和不具有默认属性的机器学习模型。没有输入缺省属性的模型比输入缺省值的模型表现更差。</li><li id="73a1" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">SMOTE和ADASYN过采样并没有给出比正常过采样更好的结果。</li><li id="f9d8" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">两个阶段的机器学习，第一个阶段创建决策树以获得特征的重要性，另一个阶段训练最重要的特征。我们尝试这种技术没有任何收获。</li><li id="619a" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">尝试不同的方法来标准化数值数据并没有改变准确性。然而，非规范化数值属性的准确性较差。</li></ol><ul class=""><li id="d44a" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv na ld le lf bi translated"><strong class="ka ir">帮助我们提高分数的窍门:</strong></li></ul><ol class=""><li id="0941" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv lc ld le lf bi translated">数字和分类特征组合比所有分类属性更适合于训练算法。至少对决策树来说是这样。</li><li id="8e05" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">为缺失数据选择默认值有助于我们提高准确性。我们开始时将所有缺失的值设为0，但后来使用了更好的-999。</li><li id="510f" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">跨机器学习超参数的网格搜索让我们不费吹灰之力就在验证集上获得了2–4%的提升。</li><li id="8cfb" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">一个强大的AutoML基线可以帮助我们很好地开始。</li></ol><ul class=""><li id="d662" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv na ld le lf bi translated"><strong class="ka ir">我们想尝试但不能/没有/懒得编码的招数:</strong></li></ul><ol class=""><li id="7dea" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv lc ld le lf bi translated">通过获取非默认分类值的笛卡尔乘积，然后选择重要特征来训练模型的特征工程。</li><li id="6c10" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">通过以不同方式组合数字特征并对生成的特征进行特征选择的特征工程。</li><li id="7266" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">尝试多个模型的集合。我们之前设定的目标是得到一个好的模型，但最终还是训练了很多方法。我们可以把它们组合成一个整体，就像堆叠一样。</li></ol><h2 id="7aec" class="nb lm iq bd ln nc nd dn lr ne nf dp lv kj ng nh lz kn ni nj md kr nk nl mh nm bi translated">机器学习算法</h2><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/0205f0c327895b5446a49060a9a227c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*TKoox6gYbzKKne3w.jpg"/></div></figure><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/c34a10d2538ea14f33c9bf2efbef6f1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*RWv6kd0BTmecvc6w.jpg"/></div></figure><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/fc7a1dff52ddea1fd4e2d8a2296d78b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*3S7JqXMe2bUb4ci9.jpg"/></div></figure><p id="28a2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们使用的库:SKLearn、XGBOOST和TPOT</p><p id="c0bf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们现在将讨论我们尝试过的机器学习方法。按时间顺序谈论事情，如我们尝试方法的顺序。请注意，自从我们第一次尝试以来，所有对我们有用的技巧都不存在了，我们一个一个地把它们包括进来。请看每一次试验的要点，了解当时的管道是什么。除非另有说明，所有使用的机器学习模型均来自<a class="ae kw" href="http://scikit-learn.org/" rel="noopener ugc nofollow" target="_blank"> Scikit学习库</a>。</p><ul class=""><li id="0039" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv na ld le lf bi translated"><strong class="ka ir">带有默认参数的常见疑点</strong></li></ul><ol class=""><li id="0f97" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv lc ld le lf bi translated">我们开始用默认参数尝试常见的可疑情况。逻辑回归、SVM和随机森林。我们还尝试了一个名为CATBOOST的新库，但是我们找不到很多关于它的超参数的文档，也不能很好地适应数据，所以决定用更著名的XGBOOST替换它。我们还了解XGBOOST超参数调优(我们知道我们必须在后面的阶段进行)。</li><li id="344d" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">第一次尝试将所有列建模为分类数据和不平衡数据集。</li><li id="9d28" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">所有的模型都符合要求，并且在验证数据上给了我们比扔硬币更好的准确性。这告诉我们，数据提取管道是好的(没有明显的错误，但需要更多的微调)。</li><li id="da3b" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">像竞争提供商提供的基线一样，随机森林和带有默认超参数的XGBOOST显示了良好的结果。</li><li id="fe7e" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">LR和SVM可以很好地模拟数据(不如RF和XGBOOST，因为默认超参数的方差较小)。SVM (SKLearn SVC)也有很好的准确性，但它返回的概率在SKLearn中并不真正可用(我发现这是默认<a class="ae kw" href="https://github.com/scikit-learn/scikit-learn/issues/4800" rel="noopener ugc nofollow" target="_blank">超参数</a>的常见问题)，这使我们放弃了SVM，因为竞争是根据平均对数损失进行判断的，这需要额外的努力来确保概率数字是正确的。只是SVC收益的概率不完全是概率，而是某种分数。</li></ol><ul class=""><li id="f222" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv na ld le lf bi translated"><strong class="ka ir"> TPOT: AutoML做了一个很好的基线</strong></li></ul><ol class=""><li id="9944" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv lc ld le lf bi translated">仍然继续所有的特征都被认为是分类的，我们试图用一种叫做<a class="ae kw" href="https://automl.info/tpot/" rel="noopener ugc nofollow" target="_blank"> TPOT </a>的自动方法来拟合基线。</li><li id="d8e0" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">TPOT使用遗传算法为手头的问题找出一个好的机器学习管道，以及与之一起使用的超参数。</li><li id="8a58" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">这使我们在提交时在竞赛公共排行榜上名列前100。</li><li id="2664" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">TPOT需要时间来找出管道，并在几个小时内对整个数据集进行收敛。</li></ol><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi no"><img src="../Images/3c266d500c6ec76dea861b166a5e41aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eGc3NdhuiaBKoqUIMhJqYw.jpeg"/></div></div></figure><ul class=""><li id="5711" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv na ld le lf bi translated"><strong class="ka ir">神经网络可以用吗？有人知道神经网络吗？</strong></li></ul><p id="31fc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们对深度学习的热爱让我们跃跃欲试，试图用神经网络来解决这个问题。我们开始训练一个好的神经网络算法来解决这个问题。请注意，此时我们正在做实验，将所有列都视为分类。有很多分类变量，需要预测一个标签的问题是什么？文本分类。这是神经网络大放异彩的一个地方。然而，与文本不同，这个数据集没有序列的概念，所以我们决定使用文本分类中常见的神经网络，但不考虑顺序。那个算法就是<a class="ae kw" href="http://fasttext.cc/" rel="noopener ugc nofollow" target="_blank"> FastText </a>。我们编写了一个(深度)版本的快速文本，就像keras中的算法一样，在数据集上进行训练。我们训练神经网络的另一件事是过采样少数类，因为它不能很好地训练不平衡的数据。</p><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi np"><img src="../Images/c164f284838fa93e2975266055c4f716.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yW1zISQiyrmXWd9ShPbTvg.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk"><em class="mx">FFNN Used</em></figcaption></figure><p id="4dd0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们尝试使用最近提出的自归一化神经网络进行训练。这给了我们在验证集上的自由碰撞的准确性。</p><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nq"><img src="../Images/270b77b65060ad938686930c149b0692.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EgUxlP6B4qOrxisrRPnLIA.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk"><em class="mx">Self Normalized FFNN (SELU) we used</em></figcaption></figure><p id="6454" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">虽然当我们使用深度神经网络，特别是神经网络时，我们在验证集上获得了准确性。在B国，我们获得了最高的准确率(甚至比我们表现最好的模型还要好),这是因为我们使用了自标准化深度神经网络，结果并没有转化到排行榜上，我们一直得到低分(高对数损失)。</p><ul class=""><li id="476c" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv na ld le lf bi translated"><strong class="ka ir">改进AutoML基线并调整XGBOOST </strong></li></ul><p id="e694" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们创建的AutoML基线仍然盯着我们的脸，因为我们所有的手工方法仍然更差。因此，我们决定改用经过测试的XGBOOST模型来提高分数。我们编写了一个数据管道，用于尝试我们在该部分开始时提到的不同技巧(成功/不成功)，以及一个管道，用于在不同的超参数上进行网格搜索，并尝试5重交叉验证。</p><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mo"><img src="../Images/a2b67182e213d42f883156cb93ef6c48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DzRgiMF1SDGmkorw2ZGF9A.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk"><em class="mx">Grid Search Example for the single validation set</em></figcaption></figure><p id="cdc4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">上面的技巧与网格搜索相结合，极大地提高了我们的分数，我们可以击败0.2 logloss，然后也可以击败0.9 logloss。我们尝试了另一个TPOT AutoML，使用我们成功的技巧生成的数据集，但它只能占用排行榜上接近0.2 logloss的管道。所以最终XGBOOST模型被证明是最好的。当我们尝试对随机森林算法的参数进行网格搜索时，我们无法获得相同数量级的精度。</p><p id="d29e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">与公开比赛排行榜相比，我们在私人排行榜上的得分/排名略有下降。我们在90%左右结束了比赛。</p><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nr"><img src="../Images/c77c795bc3202d814648e8e464f541ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W6EDXJjJdDQsgsLuArg5_Q.jpeg"/></div></div></figure><p id="1275" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们希望你喜欢这篇文章。请<a class="ae kw" href="http://user.apis.paralleldots.com/signing-up?utm_source=blog&amp;utm_medium=chat&amp;utm_campaign=paralleldots_blog" rel="noopener ugc nofollow" target="_blank">注册</a>一个免费的<a class="ae kw" href="https://www.paralleldots.com" rel="noopener ugc nofollow" target="_blank">平行账号</a>开始你的AI之旅。你也可以在这里查看PrallelDots AI API<a class="ae kw" href="https://www.paralleldots.com/ai-apis" rel="noopener ugc nofollow" target="_blank">的演示。</a></p><p id="4fe9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">点击阅读原文<a class="ae kw" href="https://blog.paralleldots.com/product/competitive-analysis/can-machine-learning-predict-poverty/" rel="noopener ugc nofollow" target="_blank">。</a></p></div></div>    
</body>
</html>