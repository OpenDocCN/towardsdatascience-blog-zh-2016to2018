<html>
<head>
<title>Speeding up your Algorithms Part 4— Dask</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">加速您的算法第 4 部分— Dask</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/speeding-up-your-algorithms-part-4-dask-7c6ed79994ef?source=collection_archive---------4-----------------------#2018-11-27">https://towardsdatascience.com/speeding-up-your-algorithms-part-4-dask-7c6ed79994ef?source=collection_archive---------4-----------------------#2018-11-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c287" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">与 Dask 并行运行您的 Pandas/Numpy/Sklearn/Python 代码</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/9b454635fb54ff50110d09631efcb289.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bMrhEFGcM8tkp75N"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@rcoses?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Raul Cacho Oses</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="e4b0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是我写的系列文章中的第四篇。所有帖子都在这里:</p><ol class=""><li id="20d0" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/speed-up-your-algorithms-part-1-pytorch-56d8a4ae7051">加速你的算法第一部分— PyTorch </a></li><li id="b935" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">加速你的算法第二部分—数字</li><li id="3ca5" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/speed-up-your-algorithms-part-3-parallelization-4d95c0888748">加速您的算法第 3 部分—并行化</a></li><li id="0afc" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/speeding-up-your-algorithms-part-4-dask-7c6ed79994ef">加速您的算法第 4 部分— Dask </a></li></ol><p id="083c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">而这些与<strong class="ky ir"> <em class="mg"> Jupyter 笔记本</em> </strong>搭配在这里可以得到:</p><p id="c6ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[<a class="ae kv" href="https://github.com/PuneetGrov3r/MediumPosts/tree/master/SpeedUpYourAlgorithms" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">Github</strong>-speedupyourlightms</a>和<strong class="ky ir">[</strong><a class="ae kv" href="https://www.kaggle.com/puneetgrover/kernels" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">ka ggle</strong></a><strong class="ky ir">】</strong></p></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><p id="43dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> (Edit-1/2/2019) </strong> — <a class="ae kv" href="#c217" rel="noopener ugc nofollow">添加了 dask . distributed . local cluste</a>r 的更多信息/可能用法</p><h1 id="5133" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">索引</h1><ol class=""><li id="06b3" class="ls lt iq ky b kz ng lc nh lf ni lj nj ln nk lr lx ly lz ma bi translated"><a class="ae kv" href="#16a7" rel="noopener ugc nofollow">简介</a></li><li id="f605" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="#7b8c" rel="noopener ugc nofollow">数据类型</a></li><li id="c779" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="#c7cd" rel="noopener ugc nofollow">延迟</a></li><li id="8424" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="#59f3" rel="noopener ugc nofollow">分发</a></li><li id="97a6" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="#9f6a" rel="noopener ugc nofollow">机器学习</a></li><li id="3119" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="#7154" rel="noopener ugc nofollow">延伸阅读</a></li><li id="d64b" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="#df2c" rel="noopener ugc nofollow">参考文献</a></li></ol><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="e90e" class="nq mp iq nm b gy nr ns l nt nu"><strong class="nm ir"><em class="mg">NOTE:<br/></em></strong>This post goes with <strong class="nm ir"><em class="mg">Jupyter Notebook</em></strong> available in my Repo on <strong class="nm ir">Github</strong>:[<a class="ae kv" href="https://nbviewer.jupyter.org/github/PuneetGrov3r/MediumPosts/blob/master/SpeedUpYourAlgorithms/4%29%20Dask.ipynb" rel="noopener ugc nofollow" target="_blank">SpeedUpYourAlgorithms-Dask</a>]<br/>and on <strong class="nm ir">Kaggle:<br/></strong>[<a class="ae kv" href="https://www.kaggle.com/puneetgrover/speed-up-your-algorithms-dask" rel="noopener ugc nofollow" target="_blank">SpeedUpYourAlgorithms-Dask</a>]</span></pre><h1 id="16a7" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">1.简介<a class="ae kv" href="#5133" rel="noopener ugc nofollow"> ^ </a></h1><p id="08e0" class="pw-post-body-paragraph kw kx iq ky b kz ng jr lb lc nh ju le lf nv lh li lj nw ll lm ln nx lp lq lr ij bi translated">随着对机器学习算法并行化需求的增加，由于数据大小甚至模型大小的指数增长，如果我们有一个工具可以帮助我们并行处理<code class="fe ny nz oa nm b">Pandas</code>的数据帧，可以并行处理<code class="fe ny nz oa nm b">Numpy</code>的计算，甚至可以并行处理我们的机器学习算法(可能是来自<code class="fe ny nz oa nm b">sklearn</code>和<code class="fe ny nz oa nm b">tensorflow</code>的算法)，而没有太多麻烦，这将是非常有用的。</p><p id="c04a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但这样的库确实存在，它的名字叫<code class="fe ny nz oa nm b">Dask</code>。<code class="fe ny nz oa nm b">Dask</code>是一个并行计算库，它不仅帮助并行化现有的机器学习工具(<code class="fe ny nz oa nm b">Pandas</code>和<code class="fe ny nz oa nm b">Numpy</code> )[ <strong class="ky ir">，即使用高级集合</strong> ]，还帮助并行化低级任务/功能，并可以通过制作任务图来处理这些功能之间的复杂交互。[ <strong class="ky ir">即使用低级调度程序</strong> ]这类似于 Python 的线程或多处理模块。</p><p id="abcd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">他们还有一个独立的机器学习库<code class="fe ny nz oa nm b">dask-ml</code>，它与现有的库如<code class="fe ny nz oa nm b">sklearn</code>、<code class="fe ny nz oa nm b">xgboost</code>和<code class="fe ny nz oa nm b">tensorflow</code>集成在一起。</p><p id="2d11" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ny nz oa nm b">Dask </code>通过绘制任务之间的交互图，将分配给它的任务并行化。通过使用<code class="fe ny nz oa nm b">Dask</code>的<code class="fe ny nz oa nm b">.visualize()</code>方法来可视化您正在做的事情将会非常有帮助，该方法可用于它的所有数据类型和您计算的复杂任务链。该方法将输出您的任务的图表，如果您的任务在每一层都有许多节点(即您的任务链结构在许多层都有许多独立的任务，例如数据块上的可并行化任务)，那么<code class="fe ny nz oa nm b">Dask</code>将能够并行化它们。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/7e8529afb759bb938ac081923172d8c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*MXtMfGFLYzdcPZuY9z7UcQ.gif"/></div></div></figure><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="c1cc" class="nq mp iq nm b gy nr ns l nt nu"><strong class="nm ir">Note:</strong><br/>Dask is still a relatively new project. It has a long way to go. Still if you don't want to go through learning a completely new API (like in case of PySpark) Dask is your best option, which surely will get better and better in future. <br/>Still Spark/PySpark is ways ahead and will still keep on improving. It is a well established Apache project. I will publish a post on PySpark in coming months.(Today: April'19)<br/>If you want to start with PySpark, read this comment <a class="ae kv" href="https://medium.com/@grover.puneet1995/i-have-stated-in-third-section-4f8206c4f081" rel="noopener">here</a>.</span></pre><h1 id="7b8c" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">2.数据类型<a class="ae kv" href="#5133" rel="noopener ugc nofollow"> ^ </a></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/09b3f8043947a1443014daa460762c4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aPsiRYwyw2hNcIeZ"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@memoryonsounds?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Kai Oberhäuser</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="fd6b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ny nz oa nm b">Dask</code>中的每种数据类型都提供了现有数据类型的分布式版本，如<code class="fe ny nz oa nm b">Pandas</code>中的<code class="fe ny nz oa nm b">DataFrame</code>、<code class="fe ny nz oa nm b">numpy</code>中的<code class="fe ny nz oa nm b">ndarray</code>和<code class="fe ny nz oa nm b">Python</code>中的<code class="fe ny nz oa nm b">list</code>。这些数据类型可能比你的内存大，<code class="fe ny nz oa nm b">Dask</code>将以<code class="fe ny nz oa nm b">Blocked</code>的方式对你的数据并行(y)运行计算。<code class="fe ny nz oa nm b">Blocked</code>通过执行许多小计算来执行大计算，即以块为单位，块的数量是<code class="fe ny nz oa nm b">chunks</code>的总数。</p><p id="1c1b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> a)数组:</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi od"><img src="../Images/6bb548294d8072bf79c1390967060df2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*JfQnXJ5_R104bPyE8_XhwQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Many Numpy arrays in a grid as Dask Array</figcaption></figure><p id="9abe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Dask Array 通过将非常大的数组分成块并并行执行这些块来对它们进行操作。它有许多可用的 numpy 方法，你可以用它们来加速。但是其中的<a class="ae kv" href="http://docs.dask.org/en/latest/array.html#scope" rel="noopener ugc nofollow" target="_blank">部分</a>没有实现。</p><p id="980b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Dask 数组可以从任何类似数组的结构中读取，只要它支持类似 numpy 的切片，并且通过使用<code class="fe ny nz oa nm b">dask.array.from_array</code>方法具有<code class="fe ny nz oa nm b">.shape</code>属性。也可以从<code class="fe ny nz oa nm b">.npy</code>和<code class="fe ny nz oa nm b">.zarr</code>文件中读取。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="7876" class="nq mp iq nm b gy nr ns l nt nu">import dask.array as da<br/>import numpy as np</span><span id="e8c7" class="nq mp iq nm b gy oe ns l nt nu">arr = numpy.random.randint(1, 1000, (10000, 10000))</span><span id="2b19" class="nq mp iq nm b gy oe ns l nt nu">darr = da.from_array(arr, chunks=(1000, 1000))<br/># It will make chunks, each of size (1000, 1000)<br/>darr.npartitioins<br/># 100</span></pre><p id="f73b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当你的数组非常大的时候(也就是说，它们放不进内存)可以使用它，而<code class="fe ny nz oa nm b">numpy</code>对此无能为力。所以，<code class="fe ny nz oa nm b">Dask</code>把它们分成数组块，给你并行操作。</p><p id="8526" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，<code class="fe ny nz oa nm b">Dask</code>对每一个方法进行懒惰的评估。所以，要真正计算一个函数的值，你必须使用<code class="fe ny nz oa nm b">.compute()</code>方法。它将在块中并行计算结果，同时并行处理每个独立的任务。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="c88c" class="nq mp iq nm b gy nr ns l nt nu">result = darr.compute()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/32a4696c89b6e890ea47f36fb3488388.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UbmYpFbPiRv3j9fKBLJz4g.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">1) Numpy faster than Dask for smaller number of elements; 2) Dask taking over Numpy for around 1e7 elements; 3) Numpy not able to produce results for higher number of elements as it is not able to put them on memory.</figcaption></figure><p id="42c0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> b)数据帧:</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/81d0fe47edcd364adfcb2736f79c880d.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*74l3bfUubu_ygWMJlV8KKA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">5 Pandas’ DataFrames each providing monthly data (can be from diff files) in one Dask DataFrame</figcaption></figure><p id="be0e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与<code class="fe ny nz oa nm b">Dask Arrays</code>类似，<code class="fe ny nz oa nm b">Dask DataFrame</code>通过将文件划分为块，并对这些块并行地执行计算功能，来对无法容纳在内存中的非常大的数据文件进行并行计算。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="e681" class="nq mp iq nm b gy nr ns l nt nu">import dask.dataframe as dd<br/>df = dd.read_csv("BigFile(s).csv", blocksize=50e6)</span></pre><p id="bfad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，您可以应用/使用<code class="fe ny nz oa nm b">pandas</code>库中的大多数功能，并在此处应用。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="f9b6" class="nq mp iq nm b gy nr ns l nt nu">agg = df.groupby(["column"]).aggregate(["sum", "mean", "max", "min"])<br/>agg.columns = new_column_names # see in notebook<br/>df_new = df.merge(agg.reset_index(), on="column", how="left")<br/>df_new.compute().head()</span></pre><p id="3b0d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> c)袋子:</strong></p><p id="96fe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ny nz oa nm b">Dask</code> <code class="fe ny nz oa nm b">Bag</code> s 对包含多种数据类型元素的<code class="fe ny nz oa nm b">Python</code><code class="fe ny nz oa nm b">list</code>like 对象进行并行化计算。当您试图处理 JSON blobs 或日志文件之类的半结构化数据时，这很有用。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="8634" class="nq mp iq nm b gy nr ns l nt nu">import dask.bag as db<br/>b = db.from_txt("BigSemiStructuredData.txt")<br/>b.take(1)</span></pre><p id="b0ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ny nz oa nm b">Dask</code> bags 逐行读取，<code class="fe ny nz oa nm b">.take</code>方法输出指定行数的元组。</p><p id="f7f4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ny nz oa nm b">Dask</code> <code class="fe ny nz oa nm b">Bag</code>对这类 Python 对象集合执行<code class="fe ny nz oa nm b">map</code>、<code class="fe ny nz oa nm b">filter</code>、<code class="fe ny nz oa nm b">fold</code>、<code class="fe ny nz oa nm b">groupby</code>等操作。它使用 Python 迭代器以较小的内存占用并行完成这一任务。它类似于 PyToolz T21 的平行版本或者 PySpark RDD 的 Pythonic 版本。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="8303" class="nq mp iq nm b gy nr ns l nt nu">filtered = b.filter(lambda x: x["Name"]=="James")\<br/>                     .map(lambda x: x["Address"] = "New_Address")<br/>filtered.compute()</span></pre><h1 id="c7cd" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">3.延期<a class="ae kv" href="#5133" rel="noopener ugc nofollow"> ^ </a></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/1b8edb31001a1168e56a38c3e7ad231a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IAyysBPaMglCEGhD"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@andreacau?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Andrea Cau</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="974d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您的任务有点简单，并且您不能或不想使用这些高级集合来完成，那么您可以使用低级调度程序来帮助您使用<code class="fe ny nz oa nm b">dask.delayed</code>接口并行化您的代码/算法。<code class="fe ny nz oa nm b">dask.delayed</code>也做懒计算。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="4bd2" class="nq mp iq nm b gy nr ns l nt nu">import dask.delayed as delay</span><span id="f165" class="nq mp iq nm b gy oe ns l nt nu">@delay<br/>def sq(x):<br/>    return x**2<br/>@delay <br/>def add(x, y):<br/>    return x+y<br/>@delay <br/>def sum(arr):<br/>    sum=0<br/>    for i in range(len(arr)): sum+=arr[i]<br/>    return sum</span></pre><p id="5e71" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以根据需要在这些函数之间添加复杂的交互，使用前一个任务的结果作为下一个任务的参数。<code class="fe ny nz oa nm b">Dask</code>不会立即计算这些函数，而是会为您的任务制作一个图表，有效地整合您使用的函数之间的交互。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="581a" class="nq mp iq nm b gy nr ns l nt nu">inputs = list(np.arange(1, 11))#Will be addin' dask.delayed to list<br/>temp = []<br/>for i in range(len(inputs)):<br/>    temp.append(sq(inputs[i]))  # Compute sq of inputs and save <br/>                                # delayed in list<br/>inputs=temp; temp = []<br/>for i in range(0, len(inputs)-1, 2):<br/>    temp.append(add(inputs[i]+inputs[i+1])) # Add two consecutive<br/>                                            # results from prev step<br/>inputs = temp<br/>result = sum(inputs) # Sum all results from prev step<br/>results.compute()</span></pre><p id="7b32" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以用许多可能的小块为任何可并行化的代码增加延迟，并获得加速。它可以是你想要计算的许多函数，比如上面的例子，或者使用<code class="fe ny nz oa nm b">pandas.read_csv</code>并行读取许多文件。</p><h1 id="59f3" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">4.分发<a class="ae kv" href="#5133" rel="noopener ugc nofollow"> ^ </a></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/7bbb6434103f7208268868a81dbb0090.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bVhypr-RFdHafVU-"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@mero_dnt?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Chinh Le Duc</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="b8ce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，到目前为止，我们一直使用<code class="fe ny nz oa nm b">Dask</code>的默认调度程序来计算任务的结果。但是您可以根据自己的需要从<code class="fe ny nz oa nm b">Dask</code>的可用选项中进行更改。</p><p id="bf5c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ny nz oa nm b">Dask</code>附带四个可用的调度程序:</p><ul class=""><li id="0ea3" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr oi ly lz ma bi translated">"<code class="fe ny nz oa nm b">threaded</code>":由线程池支持的调度程序</li><li id="5efa" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr oi ly lz ma bi translated">"<code class="fe ny nz oa nm b">processes</code>":由进程池支持的调度程序</li><li id="d1da" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr oi ly lz ma bi translated">"<code class="fe ny nz oa nm b">single-threaded</code>"(又名"<code class="fe ny nz oa nm b">sync</code>"):一个同步调度器，适合调试</li><li id="6d91" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr oi ly lz ma bi translated"><code class="fe ny nz oa nm b">distributed</code>:用于在多台机器上执行图形的分布式调度程序</li></ul><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="c488" class="nq mp iq nm b gy nr ns l nt nu">result.compute(scheduler="single-threaded") # for debugging<br/># Or<br/>dask.config.set(scheduler="single-threaded")<br/>result.compute()</span><span id="d14f" class="nq mp iq nm b gy oe ns l nt nu"><strong class="nm ir">NOTE: (from official page </strong><a class="ae kv" href="https://render.githubusercontent.com/view/ipynb?commit=33efceb9ba76b16ce3bf51d6210546e257f0874b&amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6461736b2f6461736b2d7475746f7269616c2f333365666365623962613736623136636533626635316436323130353436653235376630383734622f30355f64697374726962757465642e6970796e62&amp;nwo=dask%2Fdask-tutorial&amp;path=05_distributed.ipynb&amp;repository_id=39199909&amp;repository_type=Repository#Some-Questions-to-Consider:" rel="noopener ugc nofollow" target="_blank"><strong class="nm ir">here</strong></a><strong class="nm ir">)</strong><br/>Threaded tasks will work well when the functions called release the <a class="ae kv" href="https://wiki.python.org/moin/GlobalInterpreterLock" rel="noopener ugc nofollow" target="_blank">GIL</a>, whereas multiprocessing will always have a slower start-up time and suffer where a lot of communication is required between tasks.</span><span id="46d0" class="nq mp iq nm b gy oe ns l nt nu"># And you can get the scheduler by the one of these commands:<br/>dask.threaded.get, dask.multiprocessing.get, dask.local.get_sync<br/># last one for "single-threaded"</span></pre><p id="d7a1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，<code class="fe ny nz oa nm b">Dask</code>多了一个调度器，<code class="fe ny nz oa nm b">dask.distributed</code>，出于以下原因，可以优先选择它:</p><ol class=""><li id="ffce" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">它提供对异步 API 的访问，特别是<a class="ae kv" href="http://docs.dask.org/en/latest/futures.html" rel="noopener ugc nofollow" target="_blank"> Futures </a>，</li><li id="1dbf" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">它提供了一个诊断控制面板，可以提供关于性能和进度的宝贵见解</li><li id="524c" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">它处理数据局部性更加复杂，因此在需要多个进程的工作负载上比多处理调度程序更有效。</li></ol><p id="35c1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以通过导入和创建一个<code class="fe ny nz oa nm b">Client</code>来创建<code class="fe ny nz oa nm b">Dask</code>的<code class="fe ny nz oa nm b">dask.distributed</code>调度程序。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="febb" class="nq mp iq nm b gy nr ns l nt nu">from dask.distributed import Client<br/>client = Client() # Set up a local cluster</span><span id="a125" class="nq mp iq nm b gy oe ns l nt nu"># You can navigate to <a class="ae kv" href="http://localhost:8787/status" rel="noopener ugc nofollow" target="_blank">http://localhost:8787/status</a> to see the <br/># diagnostic dashboard if you have Bokeh installed.</span></pre><p id="daf0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，您可以通过使用<code class="fe ny nz oa nm b">client.submit</code>方法将您的任务提交给这个集群，将函数和参数作为它的参数。然后我们可以通过使用<code class="fe ny nz oa nm b">client.gather</code>或<code class="fe ny nz oa nm b">.result</code>方法来收集我们的结果。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="2599" class="nq mp iq nm b gy nr ns l nt nu">sent = client.submit(sq, 4) # sq: square function<br/>result = client.gather(sent) # Or sent.result()</span></pre><p id="a9b8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您还可以通过使用<code class="fe ny nz oa nm b">dask.distributed.progress</code>来查看当前单元格中的任务进度。您还可以通过使用<code class="fe ny nz oa nm b">dask.distributed.wait</code>明确选择等待任务完成。</p><p id="3f6d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">更多信息请看<a class="ae kv" href="http://docs.dask.org/en/latest/futures.html" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="c217" class="nq mp iq nm b gy nr ns l nt nu"><strong class="nm ir">Note: (Local Cluster)<br/></strong>At times you will notice that <strong class="nm ir">Dask</strong> is exceeding memory use, even though it is dividing tasks. It could be happening to you because of the function you are trying to use on your <strong class="nm ir">dataset </strong>wants most of your data for processing, and multiprocessing can make things worse as all workers might try to copy <strong class="nm ir">dataset </strong>to memory. This can happen in aggregating cases.<br/>Or maybe you want to restrict Dask to use only specific amount of memory. </span><span id="557d" class="nq mp iq nm b gy oe ns l nt nu">In these cases you can use <strong class="nm ir">Dask.distributed.LocalCluster</strong> parameters and pass them to <strong class="nm ir">Client</strong>() to make a <strong class="nm ir">LocalCluster</strong> using cores of your Local machines.</span><span id="709d" class="nq mp iq nm b gy oe ns l nt nu"><strong class="nm ir">from</strong> dask.distributed <strong class="nm ir">import</strong> Client, LocalCluster<br/>client = <strong class="nm ir">Client</strong>(n_workers=1, threads_per_worker=1, processes=False,<br/>                memory_limit='25GB', scheduler_port=0, <br/>                silence_logs=True, diagnostics_port=0)<br/>client </span><span id="09d7" class="nq mp iq nm b gy oe ns l nt nu">'scheduler_port=0' and 'diagnostics_port=0' will choose random port number for this particular client. With 'processes=False' <strong class="nm ir">dask</strong>'s client won't copy dataset, which would have happened for every process you might have made.<br/>You can tune your client as per your needs or limitations, and for more info you can look into parameters of <strong class="nm ir">LocalCluster.<br/></strong>You can also use multiple clients on same machine at different ports.</span></pre><h1 id="9f6a" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">5.机器学习<a class="ae kv" href="#5133" rel="noopener ugc nofollow"> ^ </a></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/8fb8c345acbf5d5af33423cea93dd676.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HsxQfJDyKp0qa7YB"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@lamppidotco?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">James Pond</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="3d00" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ny nz oa nm b">Dask</code>也有帮助并行运行最流行的机器学习库的库，比如<code class="fe ny nz oa nm b">sklearn</code>、<code class="fe ny nz oa nm b">tensorflow</code>和<code class="fe ny nz oa nm b">xgboost</code>。</p><p id="4968" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在机器学习中，你可能会面临几个不同的缩放问题。扩展策略取决于您面临的问题:</p><ol class=""><li id="6b64" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">大型模型:数据适合 RAM，但训练时间太长。许多超参数组合、许多模型的大型集合等。</li><li id="4db8" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">大型数据集:数据比 RAM 大，采样是不可行的。</li></ol><p id="bde2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，您应该:</p><ul class=""><li id="7516" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr oi ly lz ma bi translated">对于内存适配问题，只需使用 scikit-learn(或者你最喜欢的 ML 库)；</li><li id="9788" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr oi ly lz ma bi translated">对于大型模型，使用<code class="fe ny nz oa nm b">dask_ml.joblib</code>和您最喜欢的 scikit-learn 估算器；和</li><li id="027e" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr oi ly lz ma bi translated">对于大型数据集，使用<code class="fe ny nz oa nm b">dask_ml</code>估算器。</li></ul><p id="b68a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> a)预处理:</strong></p><p id="fd58" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ny nz oa nm b">dask_ml.preprocessing</code>包含<code class="fe ny nz oa nm b">sklearn</code>中的一些功能，如<code class="fe ny nz oa nm b">RobustScalar</code>、<code class="fe ny nz oa nm b">StandardScalar</code>、<code class="fe ny nz oa nm b">LabelEncoder</code>、<code class="fe ny nz oa nm b">OneHotEncoder</code>、<code class="fe ny nz oa nm b">PolynomialFeatures</code>等。，还有一些自己的如<code class="fe ny nz oa nm b">Categorizer</code>、<code class="fe ny nz oa nm b">DummyEncoder</code>、<code class="fe ny nz oa nm b">OrdinalEncoder</code>等。</p><p id="1db0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以像使用<code class="fe ny nz oa nm b">Pandas</code>数据框一样使用它们。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="3573" class="nq mp iq nm b gy nr ns l nt nu">from dask_ml.preprocessing import RobustScalar</span><span id="8d91" class="nq mp iq nm b gy oe ns l nt nu">df = da.read_csv("BigFile.csv", chunks=50000)</span><span id="296e" class="nq mp iq nm b gy oe ns l nt nu">rsc = RobustScalar()<br/>df["column"] = rsc.fit_transform(df["column"])</span></pre><p id="1abc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以使用<code class="fe ny nz oa nm b">Dask</code>的<code class="fe ny nz oa nm b">DataFrame</code>上的<code class="fe ny nz oa nm b">Dask</code>的预处理方法，从<code class="fe ny nz oa nm b">sklearn</code>的<code class="fe ny nz oa nm b">make_pipeline</code>方法制作一个管道。</p><p id="cc74" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> b)超参数搜索:</strong></p><p id="8c47" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ny nz oa nm b">Dask</code>有来自<code class="fe ny nz oa nm b">sklearn</code>的用于超参数搜索的方法，如<code class="fe ny nz oa nm b">GridSearchCV</code>、<code class="fe ny nz oa nm b">RandomizedSearchCV</code>等。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="ea0b" class="nq mp iq nm b gy nr ns l nt nu">from dask_ml.datasets import make_regression<br/>from dask_ml.model_selection import train_test_split, GridSearchCV<br/>X, y = make_regression(chunks=50000)<br/>xtr, ytr, xval, yval = test_train_split(X, y)</span><span id="dbe7" class="nq mp iq nm b gy oe ns l nt nu">gsearch = GridSearchCV(estimator, param_grid, cv=10)<br/>gsearch.fit(xtr, ytr)</span></pre><p id="6451" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你使用<code class="fe ny nz oa nm b">partial_fit</code>和你的估算器，你可以使用<code class="fe ny nz oa nm b">dask-ml</code>的<code class="fe ny nz oa nm b">IncrementalSearchCV</code>。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="c5f0" class="nq mp iq nm b gy nr ns l nt nu"><strong class="nm ir">NOTE: (from Dask)</strong><br/>If you want to use post-fit tasks like scoring and prediction, then underlying estimators scoring method is used. If your estimator, possibly from <!-- -->sklearn<!-- --> is not able to handle large dataset, then wrap your estimator around "<!-- -->dask_ml.wrappers.ParallelPostFit"<!-- -->. It can parallelize methods like "predict", "predict_proba", "transform" etc.</span></pre><p id="92c8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> c)模型/估计器:</strong></p><p id="dcd4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ny nz oa nm b">Dask</code>有一些线性模型(<code class="fe ny nz oa nm b">LinearRegression</code>，<code class="fe ny nz oa nm b">LogisticRegression</code>等)。)、一些聚类模型(<code class="fe ny nz oa nm b">Kmeans</code>和<code class="fe ny nz oa nm b">SpectralClustering</code>)、一个用<code class="fe ny nz oa nm b">Tensorflow</code> <a class="ae kv" href="https://ml.dask.org/tensorflow.html" rel="noopener ugc nofollow" target="_blank">聚类</a>操作的方法、使用<code class="fe ny nz oa nm b">Dask</code>训练<code class="fe ny nz oa nm b">XGBoost</code> <a class="ae kv" href="https://ml.dask.org/xgboost.html" rel="noopener ugc nofollow" target="_blank">模型</a>的方法。</p><p id="1d99" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你的训练数据很少，你可以使用<code class="fe ny nz oa nm b">sklearn</code>的模型和<code class="fe ny nz oa nm b">Dask</code>，或者使用<code class="fe ny nz oa nm b">ParallelPostFit</code>的包装器(如果你的测试数据很多)。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="53e5" class="nq mp iq nm b gy nr ns l nt nu">from sklearn.linear_model import ElasticNet<br/>from <!-- -->dask_ml.wrappers import ParallelPostFit</span><span id="02c6" class="nq mp iq nm b gy oe ns l nt nu">el = <!-- -->ParallelPostFit(estimator=ElasticNet())</span><span id="12d8" class="nq mp iq nm b gy oe ns l nt nu">el.fit(Xtrain, ytrain)<br/>preds = el.predict(Xtest)</span></pre><p id="848a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你的数据集不大但是你的模型很大，那么你可以使用<code class="fe ny nz oa nm b">joblib</code>。许多<code class="fe ny nz oa nm b">sklearns</code>算法是为并行执行而编写的(您可能已经使用了<code class="fe ny nz oa nm b">n_jobs=-1</code>参数)，使用<code class="fe ny nz oa nm b">joblib</code>来利用线程和进程来并行化工作负载。要使用<code class="fe ny nz oa nm b">Dask</code>进行并行化，您可以创建一个<code class="fe ny nz oa nm b">Client</code>(您必须这样做)，然后将您的代码包装在<code class="fe ny nz oa nm b">with joblib.parallel_backend('dask'):</code>周围。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="4f68" class="nq mp iq nm b gy nr ns l nt nu">import dask_ml.joblib<br/>from sklearn.externals import joblib</span><span id="d8e0" class="nq mp iq nm b gy oe ns l nt nu">client = Client()</span><span id="6682" class="nq mp iq nm b gy oe ns l nt nu">with joblib.parallel_backend('dask'):<br/>    # your scikit-learn code</span><span id="8ede" class="nq mp iq nm b gy oe ns l nt nu"><strong class="nm ir">NOTE:<br/>  </strong>Note that the Dask joblib backend is useful for scaling out CPU-bound workloads; workloads with datasets that fit in RAM, but have many individual operations that can be done in parallel. To scale out to RAM-bound workloads (larger-than-memory datasets) you should use Dask's inbuilt models and methods.</span></pre><p id="d0a9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你的训练数据太大，无法放入内存，那么你应该使用<code class="fe ny nz oa nm b">Dask</code>的内置估算器来加速。您也可以使用<code class="fe ny nz oa nm b">Dask</code>的<code class="fe ny nz oa nm b">wrapper.Incremental</code>，它使用底层估计器的<code class="fe ny nz oa nm b">partial_fit</code>方法对整个数据集进行训练，但它本质上是顺序的。</p><p id="bd70" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ny nz oa nm b">Dask</code>的内置估算器通过各种优化算法(如<code class="fe ny nz oa nm b">admm</code>、<code class="fe ny nz oa nm b">lbfgs</code>、<code class="fe ny nz oa nm b">gradient_descent</code>等)很好地扩展了大型数据集。以及<code class="fe ny nz oa nm b">L1</code>、<code class="fe ny nz oa nm b">L2</code>、<code class="fe ny nz oa nm b">ElasticNet</code>等正则化子。</p><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="dd1c" class="nq mp iq nm b gy nr ns l nt nu">from dask_ml.linear_model import LogisticRegression</span><span id="93ba" class="nq mp iq nm b gy oe ns l nt nu">lr = LogisticRegression()<br/>lr.fit(X, y, solver="lbfgs")</span></pre><p id="be9e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">再举一个使用<code class="fe ny nz oa nm b">Dask</code>的例子，你可以在这里阅读我的帖子<a class="ae kv" rel="noopener" target="_blank" href="/how-to-learn-from-bigdata-files-on-low-memory-incremental-learning-d377282d38ff">中的<code class="fe ny nz oa nm b">Dask</code>部分。这是一个从探索到训练模型的完整过程。</a></p><h1 id="7154" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">6.延伸阅读<a class="ae kv" href="#5133" rel="noopener ugc nofollow"> ^ </a></h1><ol class=""><li id="c37c" class="ls lt iq ky b kz ng lc nh lf ni lj nj ln nk lr lx ly lz ma bi translated"><a class="ae kv" href="https://mybinder.org/v2/gh/dask/dask-examples/master?urlpath=lab" rel="noopener ugc nofollow" target="_blank">https://mybinder.org/v2/gh/dask/dask-examples/master?urlpath=lab </a></li><li id="b394" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/how-i-learned-to-love-parallelized-applies-with-python-pandas-dask-and-numba-f06b0b367138">https://towards data science . com/how-I-learn-to-love-parallelised-apply-with-python-pandas-dask-and-numba-f 06 b0b 367138</a></li><li id="5489" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://docs.dask.org/en/latest/" rel="noopener ugc nofollow" target="_blank">https://docs.dask.org/en/latest/</a></li><li id="433b" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://ml.dask.org" rel="noopener ugc nofollow" target="_blank">https://ml.dask.org</a></li></ol><h1 id="df2c" class="mo mp iq bd mq mr ms mt mu mv mw mx my jw mz jx na jz nb ka nc kc nd kd ne nf bi translated">7.参考文献<a class="ae kv" href="#5133" rel="noopener ugc nofollow"> ^ </a></h1><ol class=""><li id="b523" class="ls lt iq ky b kz ng lc nh lf ni lj nj ln nk lr lx ly lz ma bi translated"><a class="ae kv" href="https://ml.dask.org" rel="noopener ugc nofollow" target="_blank">https://ml.dask.org</a></li><li id="65c2" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://docs.dask.org/en/latest/" rel="noopener ugc nofollow" target="_blank">https://docs.dask.org/en/latest/</a></li></ol><pre class="kg kh ki kj gt nl nm nn no aw np bi"><span id="46b1" class="nq mp iq nm b gy nr ns l nt nu">Suggestions and reviews are welcome.<br/>Thank you for reading!</span></pre><p id="72bd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">签名:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oj"><img src="../Images/ca01c1d315400c09978fb5e62da01d87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*N7tbEUmEr0wEqsdlZNQ5iA.png"/></div></div></figure></div></div>    
</body>
</html>