<html>
<head>
<title>Why Your A.I is Biased &amp; How to Fix it</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么你的人工智能有偏见&amp;如何解决</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-your-a-i-is-biased-how-to-fix-it-c9ffb3de6ed2?source=collection_archive---------4-----------------------#2017-05-09">https://towardsdatascience.com/why-your-a-i-is-biased-how-to-fix-it-c9ffb3de6ed2?source=collection_archive---------4-----------------------#2017-05-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0b16" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">我们都应该问的问题</h2></div><p id="c0d5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">人工智能和机器学习领域的许多创新者面临着一个技术培训的问题。他们用来教授算法的数据仅限于来自网络或合理使用资源，这些资源容易受到偏见或不充分，因为没有包括各种各样的人。</p><p id="7422" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，这里有一些快速的谷歌图片搜索，有助于可视化包容性和代表性的差异。以下结果来自搜索“女人”、“男人”、“头发”和“美丽的微笑”</p><div class="lb lc ld le gt ab cb"><figure class="lf lg lh li lj lk ll paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><img src="../Images/4aaf601bb1c14cba337c25cf03b8d16e.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*iDGueqYwSfU7IbLA4tiwnQ.png"/></div></figure><figure class="lf lg ls li lj lk ll paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><img src="../Images/ff8f941838b0390d24eee9319e79d493.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*g1UqfaWIl5LbUxM4kaUT5Q.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk lx di ly lz">Representation of Women &amp; Men, According to the Internet.</figcaption></figure></div><div class="ab cb"><figure class="lf lg ma li lj lk ll paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><img src="../Images/598067f7b15924a146fda05df278fd8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*aXV_CggOerfh_c72KoYrnw.png"/></div></figure><figure class="lf lg mb li lj lk ll paragraph-image"><div role="button" tabindex="0" class="lm ln di lo bf lp"><img src="../Images/28a201dd0cd3c70591f18d3f10b56361.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*II9OXhkNZPP7unIhk5tA3Q.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk mc di md lz">What People With Hair &amp; Beautiful Smiles Look Like, According to the Internet.</figcaption></figure></div><p id="aa8d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当人工智能暴露在网络上已经培养了几十年的文化刻板印象、语义和系统偏见中时，问题就出现了。我们中的许多人已经无意识地习惯于接受这些偏见作为“规范”；《人工智能的编程》将这些偏见公之于众，而<strong class="kh ir"> </strong>将这些偏见的问题本质放入背景中——迫使我们变得更加公平和负责。许多人质疑人工智能是否天生就有偏见，因为它是由人类训练的，而人类本身并不完美。</p><h1 id="c714" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">这些问题</h1><p id="ba74" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">答案在于问两个关键问题:</p><p id="a0b1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">1)什么数据被用来训练人工智能，它来自哪里，是“全谱”数据吗？</p><p id="e59f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2)是否有意识地从头开始实施人工智能系统，以防止偏见的发生？</p><h1 id="cbb6" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">为什么我变得有偏见</h1><p id="849d" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">当做错时，通常会在通过来自互联网的数据进行训练的机器中看到种族主义和厌恶女性的特征，或者从一开始就没有认真努力解决偏见。</p><p id="f490" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面的例子快速突出了为什么使用互联网作为机器学习中建立数据集的媒介是有问题的&amp;扩散了预先存在的人类偏见。</p><p id="1395" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">1)微软和他们的twitter聊天机器人Tay在大约一天的时间里变成了一个亲希特勒的种族主义者，在Twitter上发布了如下声明:</p><p id="d2bb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">“布什制造了911事件，希特勒会比我们现在的猴子做得更好。唐纳德·特朗普是我们唯一的希望。”</p><figure class="lb lc ld le gt lg gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/19dd4928062cfa6cad84f2d1fb0fb4c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*ctfVVhzZ8j5RL0RdwDMPJQ.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Tay’s tweet</figcaption></figure><p id="1be6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Tay正在从人们在互联网上发布的推文中学习和提取数据。</p><p id="fea5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2) <a class="ae nc" href="http://science.sciencemag.org/content/356/6334/183" rel="noopener ugc nofollow" target="_blank">最近的研究表明</a>人工智能在网上的标准文本体上进行训练，结果是它将欧裔美国人的名字与令人愉快的词语如“礼物”或“快乐”联系起来，而将非裔美国人的名字与令人不快的词语联系起来。</p><p id="dcf9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">3)美。AI表演了一场由人工智能评判的选美比赛。上传了来自100个不同国家的6000张自拍。在44名获奖者中，少数是亚洲人。除一人外，其余都是白人。答:我并不是故意被教导说白皮肤的人更漂亮，但它确实是这样，不过假设它所输入的数据主要由白人组成。</p><p id="fc86" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">亚历克斯·扎沃龙科夫，美女。AI的首席科学官，<a class="ae nc" href="https://www.theguardian.com/technology/2016/sep/08/artificial-intelligence-beauty-contest-doesnt-like-black-people" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">在《卫报》上解释了多样化数据集的重要性:</strong> </a></p><p id="98f1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">“虽然算法偏向白人有很多原因，但主要问题是该项目用来建立吸引力标准的数据没有包括足够多的少数族裔……如果数据集中没有那么多有色人种，那么你实际上可能会得到有偏见的结果。”他当时说。</p><h1 id="c464" class="me mf iq bd mg mh mi mj mk ml mm mn mo jw mp jx mq jz mr ka ms kc mt kd mu mv bi translated">答案</h1><p id="94e9" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">以下是如何建立一个没有偏见的人工智能:</p><p id="66b4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">1)创建“全谱”数据集，这是一个从零开始构建的数据库，没有固有的偏见，具有包容性和多样性。</p><p id="0557" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2)建立人工智能，注意偏见&amp;全面实施防止偏见发生的系统。</p><p id="9e60" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">3)人情味对质量控制至关重要，以确定在向人工智能引入新数据时是否存在任何偏见。</p><p id="0b06" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，<a class="ae nc" href="https://www.knockri.com/" rel="noopener ugc nofollow" target="_blank"> Knockri </a>通过分析求职者的语言和非语言交流来筛选视频求职申请。我们建立了自己的专有数据集，强调包容性和多样性。此外，在量化候选人的能力时，该算法不会将个人的种族、性别、外貌或性偏好作为招聘意愿的衡量标准。</p><p id="ef51" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">A.我只和它的数据集一样好。当精心构建时，人工智能可以为企业提供可扩展的资源，可以持续帮助人们做出更客观的决策。</p></div></div>    
</body>
</html>