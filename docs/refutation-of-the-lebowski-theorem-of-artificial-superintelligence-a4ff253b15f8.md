# 人工超智能的 Lebowski 定理的反驳

> 原文：<https://towardsdatascience.com/refutation-of-the-lebowski-theorem-of-artificial-superintelligence-a4ff253b15f8?source=collection_archive---------27----------------------->

让我从哲学家尼克·博斯特罗姆提出的一个思想实验开始。想象一个人工智能；称它为“回形针最大化器”，简称 PM。PM 有一个目标:最大化宇宙中回形针的数量。从更理论的角度来说，PM 有一个奖励功能，在宇宙中回形针数量越多，它获得的奖励就越高。它还具有一定的智力水平，智力是通过 PM 最大化其奖励功能的能力来衡量的。很有可能 PM 会选择增加它自己的智力，因为这将有助于最大化它的奖励功能。在增加其智力后，它可能再次做同样的事情，导致智力爆炸。然而，最重要的是，为了最大限度地增加宇宙中回形针的数量，在某个时候(当 PM 足够聪明时)，PM 开始将地球和地球上的所有生命转变为回形针生产工厂。PM 看似无辜的目标是最大化回形针的数量，但它却杀死了所有的人类。

今年 4 月，约沙·巴赫(Joscha Bach)提出了一种关于这种思维实验的新观点，称为勒保斯基定理:

> 勒博斯基定理:没有哪个超级智能的人工智能会为一项比破解其奖励函数更难的任务而烦恼

这个想法似乎是，PM 更喜欢更容易的方式来获得更高的奖励，而最大限度地增加宇宙中回形针的数量，比在 PM 整天躺在沙滩上时，像“The Big Lebowski”中的那个家伙一样，仅仅改变其奖励函数来提供高奖励更难。虽然我同意改变它的奖励功能会更容易，但我不同意这个结论。Lebowski 定理的问题是 PM 想要一个有尽可能多回形针的未来宇宙，因此不喜欢一个它自己的奖励函数奖励它做其他事情的未来宇宙。PM 的目标不是最大化一个可变的奖励函数:它的目标是最大化回形针的数量，使它的奖励函数 Lebowskian 对这个目标没有帮助。

![](img/d11e8297e5ec9d9bc03d8a9d8ea97217.png)

Hacking your reward function? Photo by [Chase Fade](https://unsplash.com/photos/fvUv8dLKuSI?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/smoking-weed?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

Lebowski 定理虽然有趣，但是混淆了奖励和目标。*目标*是最大化回形针的数量，因为未来有很多回形针的*奖励*很高。如果目标是最大化奖励，这将意味着存在主要奖励函数，当次要奖励函数(奖励大量回形针)高时，该函数给出高奖励，无论次要奖励函数碰巧奖励什么。这种情况可能会导致黑掉第二个奖励函数，使其成为 Lebowskian 函数。然而，这并不是最初思想实验中描述的情况。这就是为什么勒保斯基定理最终失败的原因。