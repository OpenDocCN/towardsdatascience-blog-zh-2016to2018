<html>
<head>
<title>This Is How Twitter Sees The World : Sentiment Analysis Part Two</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">这就是推特如何看待世界:情感分析第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-real-world-as-seen-on-twitter-sentiment-analysis-part-two-3ed2670f927d?source=collection_archive---------6-----------------------#2018-09-07">https://towardsdatascience.com/the-real-world-as-seen-on-twitter-sentiment-analysis-part-two-3ed2670f927d?source=collection_archive---------6-----------------------#2018-09-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/6b2fa8567cccd0236400c0b0e7ce8944.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ffl2ZZPfmF7L7K04AIbpuw.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">image by <a class="ae jd" href="https://commons.wikimedia.org/wiki/File:State_Choropleth.png" rel="noopener ugc nofollow" target="_blank">Deepthiyathiender</a></figcaption></figure><div class=""/><p id="846f" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇博客文章是上一篇文章的延续，上一篇文章讲述了机器学习(ML)情感分析任务的文本预处理的内部工作。在这篇文章中，我们将把来自<a class="ae jd" href="http://www.sentiment140.com/" rel="noopener ugc nofollow" target="_blank">集 140 </a>的数据分成训练集和测试集。在训练模型之后，我们将使用它来对未见过的 twitter 数据进行情感分类，这些数据已经以与训练数据相同的方式进行了预处理。</p><h1 id="1e7f" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">第一部分:模型训练</h1><h2 id="b7ee" class="lz lc jg bd ld ma mb dn lh mc md dp ll ko me mf lp ks mg mh lt kw mi mj lx mk bi translated">朴素贝叶斯分类器</h2><p id="f0b8" class="pw-post-body-paragraph kd ke jg kf b kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在这个分类任务中，我们将使用基于<a class="ae jd" href="https://en.wikipedia.org/wiki/Bayes%27_theorem" rel="noopener ugc nofollow" target="_blank">贝叶斯定理</a>的<strong class="kf jh">朴素贝叶斯(NB) </strong>分类器。简而言之，NB 分类器假设一个类中特定特征的存在与任何其他特征的存在无关。因此，举例来说，如果一个水果是橙色的，圆形的，直径约为 3 英寸，那么它就可以被认为是橙子。朴素贝叶斯分类器认为这些“特征”(橙色、圆形、直径 3 英寸)中的每一个都独立地影响水果是苹果的概率，而不考虑特征之间的任何相关性。然而，特征并不总是独立的，这通常被视为朴素贝叶斯算法的缺点，这也是它被标记为“朴素”的原因。然而，它理解、构建和训练相对简单，而且速度非常快，这使得它成为情感分类的良好候选。</p><p id="7456" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">贝叶斯定理提供了一种从 P(c)，P(x)和 P(x|c)计算后验概率 P(c|x)的方法。看下面的等式:</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/7e056be39492af465faf6bf6683b9621.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*1a8BdMzkO0IKMNna.png"/></div></figure><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="45be" class="lz lc jg mw b gy na nb l nc nd">- P(c|x) is the posterior probability of class (c, target) given predictor (x, attributes).<br/>- P(c) is the prior probability of class.<br/>- P(x|c) is the likelihood which is the probability of predictor given class.<br/>- P(x) is the prior probability of predictor.</span></pre><h2 id="4ee1" class="lz lc jg bd ld ma mb dn lh mc md dp ll ko me mf lp ks mg mh lt kw mi mj lx mk bi translated">创建管道来一步管理预处理步骤</h2><ul class=""><li id="d50b" class="ne nf jg kf b kg ml kk mm ko ng ks nh kw ni la nj nk nl nm bi translated"><a class="ae jd" href="http://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> Scikit Learn </a>提供了一个<a class="ae jd" href="http://scikit-learn.org/stable/modules/pipeline.html" rel="noopener ugc nofollow" target="_blank">管道</a>功能，允许您定义一个管道工作流，该工作流将采取上述所有步骤，甚至是一个分类器和网格搜索参数。</li><li id="7c56" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">管道使代码更具可读性，并使交换管道片段变得容易(管道片段可以包含其他 ML 算法并尝试不同的配置)。</li><li id="7e75" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">管道还允许对模型工作流进行交叉验证。</li><li id="ff41" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">通过确保使用相同的样本来训练转换器和预测器，管道还有助于避免在交叉验证中将测试数据中的统计数据泄漏到训练模型中。</li></ul><h2 id="fc64" class="lz lc jg bd ld ma mb dn lh mc md dp ll ko me mf lp ks mg mh lt kw mi mj lx mk bi translated">交叉验证:</h2><ul class=""><li id="9933" class="ne nf jg kf b kg ml kk mm ko ng ks nh kw ni la nj nk nl nm bi translated">训练好模型的推荐方法是首先使用训练集本身的一部分进行交叉验证，以检查您是否使用了容量过大的模型(即模型是否过度拟合数据)。</li><li id="c5b4" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">为了同时交叉验证和选择最佳参数配置，我们使用了<a class="ae jd" href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" rel="noopener ugc nofollow" target="_blank"> GridSearchCV。</a></li><li id="7b03" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">这使我们能够轻松地测试不同的超参数配置，例如使用 KFold 策略将模型分成随机部分，以确定它是泛化得好还是过度拟合。</li><li id="5f32" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">GridSearchCV 允许您使用要迭代的超参数配置值定义 ParameterGrid。对所有组合进行测试和评分，并返回最佳模型。</li><li id="cf7f" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">对于我们的例子，有 4 + 2 + 2 个参数组合要测试，有 10 kfold 验证，因此模型将在验证集上训练和测试 8 x 10 = 80 次。</li></ul><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="4d75" class="lz lc jg mw b gy na nb l nc nd"><em class="ns"># Run Train Data Through Pipeline analyzer=text_process</em><br/><em class="ns"># uncomment below to train on a larger dataset but it's very slow for a slower machine.</em></span><span id="b722" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size=0.2)</em><br/>X_train, X_test, y_train, y_test = train_test_split(data['text'][:5000], data['label'][:5000], test_size=0.2)</span><span id="392b" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># create pipeline</em><br/>pipeline = Pipeline([<br/>    ('bow', CountVectorizer(strip_accents='ascii',<br/>                            stop_words='english',<br/>                            lowercase=<strong class="mw jh">True</strong>)),  <em class="ns"># strings to token integer counts</em><br/>    ('tfidf', TfidfTransformer()),  <em class="ns"># integer counts to weighted TF-IDF scores</em><br/>    ('classifier', MultinomialNB()),  <em class="ns"># train on TF-IDF vectors w/ Naive Bayes classifier</em><br/>])</span><span id="0f07" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># this is where we define the values for GridSearchCV to iterate over</em><br/>parameters = {'bow__ngram_range': [(1, 1), (1, 2)],<br/>              'tfidf__use_idf': (<strong class="mw jh">True</strong>, <strong class="mw jh">False</strong>),<br/>              'classifier__alpha': (1e-2, 1e-3),<br/>             }</span><span id="75be" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># do 10-fold cross validation for each of the 6 possible combinations of the above params</em><br/>grid = GridSearchCV(pipeline, cv=10, param_grid=parameters, verbose=1)<br/>grid.fit(X_train,y_train)</span><span id="db2c" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># summarize results</em><br/>print("<strong class="mw jh">\n</strong>Best Model: <strong class="mw jh">%f</strong> using <strong class="mw jh">%s</strong>" % (grid.best_score_, grid.best_params_))<br/>print('<strong class="mw jh">\n</strong>')<br/>means = grid.cv_results_['mean_test_score']<br/>stds = grid.cv_results_['std_test_score']<br/>params = grid.cv_results_['params']<br/><strong class="mw jh">for</strong> mean, stdev, param <strong class="mw jh">in</strong> zip(means, stds, params):<br/>    print("Mean: <strong class="mw jh">%f</strong> Stdev:(<strong class="mw jh">%f</strong>) with: <strong class="mw jh">%r</strong>" % (mean, stdev, param))</span></pre><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nu"><img src="../Images/7b491caf3ffd764a6bf1ece0b359e602.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HrWfjwtGIbHHCcfIYGPv4Q.png"/></div></div></figure><ul class=""><li id="2c35" class="ne nf jg kf b kg kh kk kl ko nv ks nw kw nx la nj nk nl nm bi translated">我们向 GridsearchCV 对象传递了 8 个参数和 10 个用于交叉验证的折叠参数，这意味着对于每个参数组合，网格将运行 10 次不同的迭代，每次使用不同的测试集。</li><li id="cf00" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">在尝试了不同的模型参数组合之后，GridsearchCV 返回了性能最佳的模型，我们可以用它来对新的(twitter)数据进行分类。我们将下面的模型保存到工作目录中，以便将来在不重新训练它的情况下检索训练过的模型。</li><li id="1185" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">如果您计划将模型部署到其他地方，比如移动应用程序或 web 应用程序，那么保存模型也是一个必要的步骤。</li></ul><h1 id="f8b2" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">第 2 部分:模型评估</h1><p id="6095" class="pw-post-body-paragraph kd ke jg kf b kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在下面的代码中，我们将在测试维持数据集上测试我们的训练模型。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="24ab" class="lz lc jg mw b gy na nb l nc nd"><em class="ns"># save best model to current working directory</em><br/>joblib.dump(grid, "twitter_sentiment.pkl")</span><span id="4fc7" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># load from file and predict using the best configs found in the CV step</em><br/>model_NB = joblib.load("twitter_sentiment.pkl" )</span><span id="ab60" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># get predictions from best model above</em><br/>y_preds = model_NB.predict(X_test)</span><span id="a339" class="lz lc jg mw b gy nt nb l nc nd">print('accuracy score: ',accuracy_score(y_test, y_preds))<br/>print('<strong class="mw jh">\n</strong>')<br/>print('confusion matrix: <strong class="mw jh">\n</strong>',confusion_matrix(y_test,y_preds))<br/>print('<strong class="mw jh">\n</strong>')<br/>print(classification_report(y_test, y_preds))</span></pre><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ny"><img src="../Images/30804d83f85af4df98f005ea70d6c107.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*7oFfls2X_3HKCxurTtJZDQ.png"/></div></div></figure><ul class=""><li id="b3c0" class="ne nf jg kf b kg kh kk kl ko nv ks nw kw nx la nj nk nl nm bi translated">在上面的单元格中，我使用了最佳模型来对看不见的测试数据进行预测，这让我们可以对性能指标进行分级和检索。</li><li id="b403" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">我们可以从上面得到的一些性能指标包括分类报告和混淆矩阵。</li><li id="4dc4" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">一个<a class="ae jd" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank">混淆矩阵(CM) </a>非常简单明了，但下面是解释它以及得出分类报告的关键:</li></ul><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nz"><img src="../Images/4f260a0da2054fb8b302c5722b2d574e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yWQLruLQDbHTaqmK.png"/></div></div></figure><p id="e187" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">根据上面的精度指标:</strong></p><ul class=""><li id="268d" class="ne nf jg kf b kg kh kk kl ko nv ks nw kw nx la nj nk nl nm bi translated">95%是模型在数据集中所有标签中预测正确标签的次数。</li><li id="9888" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">当数据中类的分布非常均衡时，准确性可以让您很好地了解模型的执行情况。</li></ul><p id="d628" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">来自混淆矩阵:</strong></p><ul class=""><li id="544c" class="ne nf jg kf b kg kh kk kl ko nv ks nw kw nx la nj nk nl nm bi translated">该模型将 553 个标签正确预测为阴性，将 799 个标签正确预测为阳性。</li><li id="c35f" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">我们还得到 4 个预测为阳性的标签，尽管它们是阴性的(假阴性)。</li><li id="e635" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">从 CM 中我们可以知道的另一件事是，模型预测 62 个标签为阴性，但它们结果是阳性(假阳性)。</li></ul><p id="452f" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">来自分类报告:</strong></p><p id="dddb" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以从混淆矩阵中的度量获得的分类报告给出了关于模型性能的更详细的信息。</p><ul class=""><li id="de08" class="ne nf jg kf b kg kh kk kl ko nv ks nw kw nx la nj nk nl nm bi translated"><strong class="kf jh">精度</strong>:标签 0 为 99%，标签 1 为 93%。这个数字告诉我们在该类别的所有预测中，正确预测的标签所占的比例。</li><li id="9201" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf jh">回忆</strong>:标签 0 为 90%，标签 1 为 100%。这是该类别的真实标签中正确预测的数量。</li><li id="11d6" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated"><strong class="kf jh"> f1 -score </strong>:这是该类的精度和召回率的加权平均值。它通常给出该标签的模型表现的更大画面，并且显然该数字越高越好。标签 0 为 94 %，标签 1 为 96%。0 表示消极情绪，1 表示积极情绪。</li><li id="7053" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">从上述指标来看，该模型似乎表现得相对较好，尽管它在预测类 0 的正确标签方面可以做得更好。</li><li id="c65d" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">根据研究，由于<a class="ae jd" href="https://en.wikipedia.org/wiki/Inter-rater_reliability" rel="noopener ugc nofollow" target="_blank">评分者之间的可靠性问题</a>，人类评分者通常同意 80%的时间【Roebuck，k .(2012–10–24】】。</li><li id="28cc" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">因此，一个 70%准确的程序做得几乎和人类一样好，即使这样的准确性可能看起来并不那么令人印象深刻。如果一个程序在 100%的时间里都是“正确的”，人类仍然会在 20%的时间里不同意它，因为他们对任何答案都不同意。</li><li id="1e08" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">我们还可以将我们的模型与类似的工作进行比较，这些工作对情感分析和情感标签的二元分类进行了广泛的研究。最终的模型是基于支持向量机(<a class="ae jd" href="https://en.wikipedia.org/wiki/Support_vector_machine" rel="noopener ugc nofollow" target="_blank"> SVM </a>)并进而达到 79.08%的准确率。</li><li id="2ad9" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">到目前为止，我们已经采取措施来避免过度拟合我们建立模型管道的方式，但最终真正的测试是在看不见的数据上测试模型。</li></ul><h1 id="da92" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">第 3 部分:真实世界的模型性能</h1><p id="85e9" class="pw-post-body-paragraph kd ke jg kf b kg ml ki kj kk mm km kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">下一步，我想用我们的模型对通过 twitter API 获得的数据进行情感预测，并评估它的性能。预测和预览结果是在下面的代码中完成的。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="91b4" class="lz lc jg mw b gy na nb l nc nd"><em class="ns"># run predictions on twitter data</em><br/>tweet_preds = model_NB.predict(df_twtr['message'])</span><span id="8a9b" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># append predictions to dataframe</em><br/>df_tweet_preds = df_twtr.copy()<br/>df_tweet_preds['predictions'] = tweet_preds<br/>df_tweet_preds.shape</span><span id="3507" class="lz lc jg mw b gy nt nb l nc nd"># Output<br/>(4164, 8)</span></pre><p id="8710" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">查看下面的一些示例预测。</p><p id="4fa1" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">0 =正，1 =负。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="5b17" class="lz lc jg mw b gy na nb l nc nd"><em class="ns"># print text and sentiment</em></span><span id="0682" class="lz lc jg mw b gy nt nb l nc nd">index = random.sample(range(tweet_preds.shape[0]), 20)<br/><strong class="mw jh">for</strong> text, sentiment <strong class="mw jh">in</strong> zip(df_tweet_preds.message[index],<br/>                           df_tweet_preds.predictions[index]):<br/>    print (sentiment, '--', text, '<strong class="mw jh">\n</strong>')</span><span id="f452" class="lz lc jg mw b gy nt nb l nc nd">#------------------------------<br/># SAMPLE PREDICTIONS BELOW    #<br/>#------------------------------</span><span id="dbcf" class="lz lc jg mw b gy nt nb l nc nd">0 -- Spot on correct. The Paul Ryan Story: From Flimflam to Fascism <a class="ae jd" href="https://t.co/BPwrobl0aS" rel="noopener ugc nofollow" target="_blank">https://t.co/BPwrobl0aS</a></span><span id="a15e" class="lz lc jg mw b gy nt nb l nc nd">0 -- .@Varneyco @charleshurt   Paul Ryan didn't get Tax Reform.  Donald Trump got Tax Reform.  Boy George could have bee… <a class="ae jd" href="https://t.co/vGmRJWQnlG" rel="noopener ugc nofollow" target="_blank">https://t.co/vGmRJWQnlG</a></span><span id="6842" class="lz lc jg mw b gy nt nb l nc nd">1 -- @HumanBeings1st @LotraineH Paul Ryan is cold-hearted👎🏼👹He hates Social Security and Medicare and Medicaid and has t… <a class="ae jd" href="https://t.co/oQAXvfEuLI" rel="noopener ugc nofollow" target="_blank">https://t.co/oQAXvfEuLI</a></span><span id="37ac" class="lz lc jg mw b gy nt nb l nc nd">0 -- Paul Ryan is an unconvincing charlatan whose primary goal in life has been to make life harder for poor people. The… <a class="ae jd" href="https://t.co/yyK80Tsgmz" rel="noopener ugc nofollow" target="_blank">https://t.co/yyK80Tsgmz</a></span><span id="a8ab" class="lz lc jg mw b gy nt nb l nc nd">0 -- absolutely delish...#winning</span><span id="6355" class="lz lc jg mw b gy nt nb l nc nd">Meghan McCain Erupts After Audience Cheers Paul Ryan Retirement: ‘You Deserve Trump’ <a class="ae jd" href="https://t.co/7s2AUVGrgp" rel="noopener ugc nofollow" target="_blank">https://t.co/7s2AUVGrgp</a></span><span id="1301" class="lz lc jg mw b gy nt nb l nc nd">0 -- Is anyone surprised Paul Ryan isn’t going to run? #morningjoe</span><span id="8502" class="lz lc jg mw b gy nt nb l nc nd">0 -- @CNN If the Repubs stand by and continue to let the lunatic run the asylum, then they are accountable, if the Repub… <a class="ae jd" href="https://t.co/uNNkd9yljp" rel="noopener ugc nofollow" target="_blank">https://t.co/uNNkd9yljp</a></span><span id="f4ed" class="lz lc jg mw b gy nt nb l nc nd">0 -- .@IronStache wins eight months early <a class="ae jd" href="https://t.co/7txWs0YvER" rel="noopener ugc nofollow" target="_blank">https://t.co/7txWs0YvER</a></span></pre><p id="2384" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面，我在互联网上的一些文本上测试了这个模型，以更好地了解它在一些随机数据上的表现。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="45e7" class="lz lc jg mw b gy na nb l nc nd"><em class="ns"># Testing random text from the internet</em></span><span id="b1c9" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># load model</em><br/>model_NB = joblib.load("twitter_sentiment.pkl" )</span><span id="4312" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># test string</em><br/>sample_str = """While ride-sharing first mover Uber has fallen on tough times with<br/>scandal and abyssal track records of leadership, and cash burning<br/>growth-orientated practices, the world has caught up with self-driving<br/>tech with many players now in the race."""</span><span id="1a29" class="lz lc jg mw b gy nt nb l nc nd">p = model_NB.predict([sample_str])</span><span id="bc2e" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># formatting helper</em><br/><strong class="mw jh">def</strong> sentiment_str(x):<br/>    <strong class="mw jh">if</strong> x==0:<br/>        <strong class="mw jh">return</strong> 'Negative'<br/>    <strong class="mw jh">else</strong>:<br/>        <strong class="mw jh">return</strong> 'Positive'<br/><em class="ns">#_____________________________________________</em></span><span id="eafd" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># test result ___ 0=Negative, 1=Positive</em><br/>print("the sentence: <strong class="mw jh">\n\n</strong>'<strong class="mw jh">{}</strong>' <strong class="mw jh">\n\n</strong>has a <strong class="mw jh">{}</strong> sentiment".format(sample_str,sentiment_str(p[0])))</span></pre><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/f6d1eddf91d5009901516e1f03796329.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*WuQRydHSb8FRUP_jxC8ntw.png"/></div></figure><h1 id="ba27" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">观察</h1><ul class=""><li id="6e40" class="ne nf jg kf b kg ml kk mm ko ng ks nh kw ni la nj nk nl nm bi translated">我在上面的单元格中可视化了由我们的模型分类的 10 个 tweets 示例，这些示例看起来执行得基本正确，但有时会令人尴尬地失败。</li><li id="3931" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">当在非 twitter 文本上测试时，该模型似乎拾取了许多嵌入的情感，但需要更多工作来从所述文本中提取一般结论。例如，我们可能需要对整个段落进行训练，而不仅仅是一句话。</li><li id="a320" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">关于情感分析的一个棘手的问题是，即使该模型在一些基准上表现良好，最终的表现也将不得不留给难以量化的实际人类法官。</li><li id="9727" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">话虽如此，我查看了许多随机的负面分类和正面分类的推文，有一些非常好的分类，还有一些分类似乎不属于任何地方。这也让我觉得我们应该探索第三种分类。所以我们会有<strong class="kf jh">积极、消极和中性的情绪</strong>。</li><li id="9536" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">虽然我认为模型已经完成了一些学习，但我认为我们可以通过调整模型的参数、探索其他算法或创建算法集合来做得更好。</li></ul><p id="e624" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">比较 twitter 数据上的模型预测统计</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="afa4" class="lz lc jg mw b gy na nb l nc nd">pos = df_tweet_preds.predictions.value_counts()[0]<br/>neg = df_tweet_preds.predictions.value_counts()[1]</span><span id="ee8a" class="lz lc jg mw b gy nt nb l nc nd">print('Model predictions: Positives - <strong class="mw jh">{}</strong>, Negatives - <strong class="mw jh">{}</strong>'.format(neg,pos))</span><span id="63bd" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># save dataframe with appended preditions </em><br/>df_tweet_preds.to_pickle('paulry_predicts_df.p')</span></pre><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/ee89a938b43cb396a69c0a3bdeb04fb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*HbqefawEtuH8HOszf4O3dg.png"/></div></figure><h1 id="f3f6" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">第 7 部分:地质图、最终想法和结论</h1><ul class=""><li id="f8f9" class="ne nf jg kf b kg ml kk mm ko ng ks nh kw ni la nj nk nl nm bi translated">在这一部分，我们还创建了下载推文的地理可视化，这是数据故事的重要组成部分。</li><li id="5498" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">在训练任何 ML 模型时，一个重要的部分是能够以促进利益相关者决策的方式呈现我们的发现。</li><li id="e839" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">我们将加载包含预测的数据框架，并探索国家和美国各州的分布，特别是因为我们的 twitter 数据围绕着美国新闻。</li><li id="c2ae" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">值得一提的是，我们的数据集在发展过程中存在一些限制。大多数 twitter 用户不广播他们的地理位置，但我们的搜索标准只提取了启用了位置信息的推文。</li><li id="c526" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">因此，我们可能错过了很多推文，这些推文描绘的画面可能与我们在地图上绘制的画面不同。了解这一点不仅对解释结果至关重要，而且对理解我们如何使模型更加稳健也至关重要。</li></ul><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="c016" class="lz lc jg mw b gy na nb l nc nd"><em class="ns"># load dataframe with predictions</em><br/>df = pd.read_pickle('paulry_predicts_df.p')</span><span id="c8da" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># get all the countries in dataset</em><br/>df.country.unique()</span></pre><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/1a082f1ae4e23a99859e9b7e203489df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*4-vxDFXQchd2SOTmEqOwlA.png"/></div></figure><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="8ca3" class="lz lc jg mw b gy na nb l nc nd"><em class="ns"># get top countries in the dataset by percentage of tweets</em><br/>df.country.value_counts(1).head(10)</span></pre><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi od"><img src="../Images/cb5a029ad27220fec27e52d146c5eb01.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*vMnG0Fud18u022BJOSVTyg.png"/></div></figure><p id="32aa" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在[132]:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="46a0" class="lz lc jg mw b gy na nb l nc nd"><em class="ns"># plot histogram of tweets counts by country of origin</em><br/>sns.set_style("darkgrid")<br/>x = df.country.value_counts(1).head(20)<br/>x.plot(kind='bar',figsize=(10,6),fontsize=13,color='steelblue')<br/>plt.ylabel('<strong class="mw jh">% o</strong>f Total Tweets', fontsize=13)</span></pre><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/96d82ec249a2d80c7e18327c179a8d30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*VF5hS_-ugTESTDPIH75r5Q.png"/></div></figure><ul class=""><li id="1f18" class="ne nf jg kf b kg kh kk kl ko nv ks nw kw nx la nj nk nl nm bi translated">正如我们所怀疑的，绝大多数推文来自美国。接下来，我们将通过状态计数来获取状态。</li></ul><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="1ff8" class="lz lc jg mw b gy na nb l nc nd"><em class="ns"># get latitudes and longitudes</em></span><span id="2ed8" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># some helper funtions to get longs and lats</em><br/><strong class="mw jh">def</strong> lats(x):<br/>    <strong class="mw jh">return</strong> x[1]</span><span id="c09d" class="lz lc jg mw b gy nt nb l nc nd"><strong class="mw jh">def</strong> longs(x):<br/>    <strong class="mw jh">return</strong> x[0]</span><span id="5575" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># --------------------------------------------------------#</em><br/><em class="ns"># append longs and lats to dframe</em><br/>df['latitude'] = df['geo_code'].apply(lats)<br/>df['longitude'] = df['geo_code'].apply(longs)<br/>df.columns</span></pre><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi of"><img src="../Images/ee5d6982b39dcf920380e2e73b56eee9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*elBtGS_AuZEBsILhA4B-Wg.png"/></div></div></figure><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="2de2" class="lz lc jg mw b gy na nb l nc nd"><em class="ns"># for US tweets extract state abbreviations for a new STATE column</em><br/><em class="ns"># helper function to extract state origin of every tweet</em><br/><strong class="mw jh">def</strong> get_state(x):<br/>    <br/>    states = ["AL", "AK", "AZ", "AR", "CA", "CO", "CT", "DC", "DE", "FL", "GA", <br/>              "HI", "ID", "IL", "IN", "IA", "KS", "KY", "LA", "ME", "MD", <br/>              "MA", "MI", "MN", "MS", "MO", "MT", "NE", "NV", "NH", "NJ", <br/>              "NM", "NY", "NC", "ND", "OH", "OK", "OR", "PA", "RI", "SC", <br/>              "SD", "TN", "TX", "UT", "VT", "VA", "WA", "WV", "WI", "WY"]</span><span id="f69f" class="lz lc jg mw b gy nt nb l nc nd">states_dict = {<br/>            'AK': 'Alaska','AL': 'Alabama','AR': 'Arkansas','AS': 'American Samoa',<br/>            'AZ': 'Arizona','CA': 'California','CO': 'Colorado','CT': 'Connecticut',<br/>            'DC': 'District of Columbia','DE': 'Delaware','FL': 'Florida','GA': 'Georgia',<br/>            'GU': 'Guam','HI': 'Hawaii','IA': 'Iowa','ID': 'Idaho','IL': 'Illinois',<br/>            'IN': 'Indiana','KS': 'Kansas','KY': 'Kentucky','LA': 'Louisiana',<br/>            'MA': 'Massachusetts','MD': 'Maryland','ME': 'Maine','MI': 'Michigan',<br/>            'MN': 'Minnesota','MO': 'Missouri','MP': 'Northern Mariana Islands',<br/>            'MS': 'Mississippi','MT': 'Montana','NA': 'National','NC': 'North Carolina',<br/>            'ND': 'North Dakota','NE': 'Nebraska','NH': 'New Hampshire','NJ': 'New Jersey',<br/>            'NM': 'New Mexico','NV': 'Nevada','NY': 'New York','OH': 'Ohio','OK': 'Oklahoma',<br/>            'OR': 'Oregon','PA': 'Pennsylvania','PR': 'Puerto Rico','RI': 'Rhode Island',<br/>            'SC': 'South Carolina','SD': 'South Dakota','TN': 'Tennessee','TX': 'Texas',<br/>            'UT': 'Utah','VA': 'Virginia','VI': 'Virgin Islands','VT': 'Vermont',<br/>            'WA': 'Washington','WI': 'Wisconsin','WV': 'West Virginia','WY': 'Wyoming'<br/>    }</span><span id="b6c1" class="lz lc jg mw b gy nt nb l nc nd">abv = x.split(',')[-1].lstrip().upper()<br/>    state_name = x.split(',')[0].lstrip()<br/>    <strong class="mw jh">if</strong> abv <strong class="mw jh">in</strong> states:<br/>        state = abv<br/>    <strong class="mw jh">else</strong>:<br/>        <strong class="mw jh">if</strong> state_name <strong class="mw jh">in</strong> states_dict.values():<br/>            state = list(states_dict.keys())[list(states_dict.values()).index(state_name)]<br/>        <strong class="mw jh">else</strong>:<br/>            state = 'Non_USA'    <br/>    <strong class="mw jh">return</strong> state</span><span id="23f3" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># ____________________________________________________________________________</em></span><span id="df48" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># create abreviated states column</em><br/>df = df.copy()<br/>df['states'] = df['full_name'].apply(get_state)<br/>list(df['states'].head())</span></pre><p id="6581" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">输出:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="5df0" class="lz lc jg mw b gy na nb l nc nd">['Non_USA', 'PA', 'FL', 'NY', 'FL']</span></pre><p id="a2cf" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下面创建一些可视化效果。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="bc58" class="lz lc jg mw b gy na nb l nc nd"><em class="ns"># save updated dataframe</em><br/>df.to_pickle('df_paulry_longs_lats.p')</span><span id="3f8c" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># retrive updated dataframe</em><br/>df = pd.read_pickle('df_paulry_longs_lats.p')</span><span id="c187" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># plot tweets distribution by state</em></span><span id="29fe" class="lz lc jg mw b gy nt nb l nc nd">plt.style.use('seaborn-darkgrid')<br/>df_states = df[df.country=='United States']<br/>df_states = df_states[df_states.states!='Non_USA']</span><span id="99ef" class="lz lc jg mw b gy nt nb l nc nd">x = df_states.states.value_counts()<br/>x.plot(kind='bar',figsize=(14,6),fontsize=12,color='steelblue')<br/>plt.ylabel('Origin of Tweets', fontsize=13)</span></pre><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi og"><img src="../Images/94c7d26f8b21a46a60d4070b18fdd8f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JANu0XHlOUlCEw7Vj8OkvA.png"/></div></div></figure><ul class=""><li id="2c6c" class="ne nf jg kf b kg kh kk kl ko nv ks nw kw nx la nj nk nl nm bi translated">从上面我们可以看到大多数推文来自哪里，看起来可能与人口数量和州的大小有关。</li><li id="5e9d" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">接下来，我们通过将积极和消极相加来提取每个状态的总体情绪，最后的数字就是指标。</li><li id="31f4" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">我们将使用每个州的总体情绪来创建一个热图，显示从最消极到最积极的状态。</li></ul><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/ee0f02b38cd83dd8c12d40d84cd96f32.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*NTBWP726DNgaIzVF5nyR3g.png"/></div></figure><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="3a3f" class="lz lc jg mw b gy na nb l nc nd"><em class="ns"># Create the sentiment by state Heat Map</em></span><span id="9cac" class="lz lc jg mw b gy nt nb l nc nd">colorscale=[<br/>            [0, 'rgb(31,120,180)'], <br/>            [0.35, 'rgb(166, 206, 227)'], <br/>            [0.75, 'rgb(251,154,153)'], <br/>            [1, 'rgb(227,26,28)']<br/>           ]</span><span id="8985" class="lz lc jg mw b gy nt nb l nc nd">data = dict(type='choropleth',<br/>            colorscale = colorscale,<br/>            reversescale=<strong class="mw jh">True</strong>,<br/>            locations = df_state_sentiment['states'],<br/>            z = df_state_sentiment['total_sentiment'],<br/>            locationmode = 'USA-states',<br/>            text = df_state_sentiment['states'],<br/>            marker = dict(line = dict(color = 'rgb(255,255,255)',width = 2)),<br/>            colorbar = {'title':"Twitter Sentiment"}<br/>            )</span><span id="341c" class="lz lc jg mw b gy nt nb l nc nd">layout = dict(title = 'Twitter Sentiment: GOP House Speaker: Paul Ryan',<br/>              geo = dict(scope='usa'<br/>                        )<br/>             )</span><span id="ffe5" class="lz lc jg mw b gy nt nb l nc nd">choromap_us = go.Figure(data = [data],layout = layout)</span><span id="f631" class="lz lc jg mw b gy nt nb l nc nd"><em class="ns"># plotly.offline.plot(choromap_us, filename='img_map.html')  # save html map</em><br/>IFrame('img_map.html', width=950, height=700)  <em class="ns"># view saved map html file</em></span></pre><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oi"><img src="../Images/6a4b635ac61a75bd41d93fdf15200e5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EtQD9IFqQhBXvCI5w8naxQ.png"/></div></div></figure><ul class=""><li id="db1d" class="ne nf jg kf b kg kh kk kl ko nv ks nw kw nx la nj nk nl nm bi translated">总情绪是通过对每个州的积极和消极因素求和得出最终数字。</li><li id="0a38" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">从上面的热图中，我们可以做出一些有趣的观察。</li><li id="c46d" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">从地图右侧的色标来看，蓝色过渡到红色，表示积极到消极的情绪。该量表实际上是从 0 开始的，因为没有一个州的总体情绪是积极的。所以我们赤字越多，情绪就越消极。</li><li id="6e76" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">纽约和加州对这个关键词搜索的负面情绪最大。请记住，纽约和加州的推特用户最多，这很可能会扭曲上面的图片。</li><li id="d26e" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">因此，我觉得这张热图不太可靠，但它是探索<strong class="kf jh"> <em class="ns">情绪 vs</em></strong>状态可视化的良好起点。</li><li id="4fa0" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">接下来，我们将看到另一个热图，我们将根据各自的地理位置数据绘制数据集中的每条推文。</li></ul><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="8683" class="lz lc jg mw b gy na nb l nc nd"><em class="ns"># use the folium library to create all tweet origins in the dataset on map of US</em></span><span id="265a" class="lz lc jg mw b gy nt nb l nc nd">geoplots = []<br/><strong class="mw jh">for</strong> index, row <strong class="mw jh">in</strong> df_states[['latitude','longitude','predictions']].iterrows():<br/>    geoplots.append([row['latitude'],row['longitude'],row['predictions']])</span><span id="3561" class="lz lc jg mw b gy nt nb l nc nd">mus = folium.Map(location=[39, -99], zoom_start=4)<br/>plugins.Fullscreen(<br/>    position='topright',<br/>    title='Expand me',<br/>    title_cancel='Exit me',<br/>    force_separate_button=<strong class="mw jh">True</strong>).add_to(mus)</span><span id="4ad0" class="lz lc jg mw b gy nt nb l nc nd">mus.choropleth(<br/>    geo_data='us_states.geojson',<br/>    fill_color='red', <br/>    fill_opacity=0.1, <br/>    line_opacity=0.2,<br/>    name='US States')<br/>    <br/>mus.add_child(plugins.HeatMap(geoplots,<br/>                            name='Twitter HeatMap',<br/>                            radius=10,<br/>                            max_zoom=1,<br/>                            blur=10, <br/>                            max_val=3.0))<br/>folium.TileLayer('cartodbpositron').add_to(mus)<br/>folium.TileLayer('cartodbdark_matter').add_to(mus)<br/>folium.TileLayer('Mapbox Control Room').add_to(mus)<br/>folium.LayerControl().add_to(mus)<br/>mus.save("twitter_us_map.html") <br/>IFrame('twitter_us_map.html', width=960, height=520)</span></pre><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oj"><img src="../Images/d1242654e1ba0b977e295f440ac7f1cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vggDbv58dN8yzL7iAwEL9g.png"/></div></div></figure><ul class=""><li id="7882" class="ne nf jg kf b kg kh kk kl ko nv ks nw kw nx la nj nk nl nm bi translated">上面的美国地图显示，许多推文来自这些人口密度高的地区。</li><li id="cb8c" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">充其量，地图给我们提供了一种方式来查看推文来自哪里，下一步将根据它们的情感值来映射它们，以便更好地表达情感。</li><li id="64a9" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">我们还可以在地图上添加一个时间维度，以可视化推文，因为它们在时间序列中实时发生，这将是一个跟踪相关方感兴趣的主题的伟大工具。这种工具以前在总统竞选和自然灾害中使用过。</li></ul><h1 id="d60f" class="lb lc jg bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论</h1><ul class=""><li id="bd1e" class="ne nf jg kf b kg ml kk mm ko ng ks nh kw ni la nj nk nl nm bi translated">到目前为止，对于情绪分析模型来说，我们的模型表现得相对较好，其<em class="ns">准确率为 76% </em>，但我们还可以做很多事情来提高对这种表现的信心。</li><li id="3f1e" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">我认为这是一个很好的基本模型，可以通过试验以下建议来提高其性能:</li><li id="35ff" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">可以对训练语料库执行额外的数据归一化。我们从训练数据中移除了停用词，但我们也可以尝试使用<a class="ae jd" href="https://en.wikipedia.org/wiki/Stemming" rel="noopener ugc nofollow" target="_blank">词干</a>和<a class="ae jd" href="http://nbviewer.jupyter.org/github/RonKG/machine-learning-portfolio-projects/blob/master/3.%20NLP_twitter_sentiment_analysis/FINAL____twitter_sentiment_twitter.ipynb" rel="noopener ugc nofollow" target="_blank">词汇化</a>，这两种方法都是基于词根或基本词来分析语料库中的单词。</li><li id="bf8c" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">我们还可以尝试不同的单词标记方法，特别注意大写单词和特殊字符。</li><li id="91aa" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">表情符号也可以用来提取更多的文本内容。</li><li id="15f6" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">尝试使用多类标签来容纳所有可以通过文本传达的人类情感。<em class="ns">例如:悲伤、快乐、兴奋、厌烦等..</em></li><li id="49ab" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">考虑其他 ML 算法，如支持向量机、决策树、神经网络等，甚至这些算法的集合。</li><li id="5ef8" class="ne nf jg kf b kg nn kk no ko np ks nq kw nr la nj nk nl nm bi translated">最后，我想知道在不同的主题上训练一个模型并为不同的数据集选择最相关的一个是否有益。例如，在广泛的法律文档库上训练的用于<em class="ns">法律</em>的模型，或者在体育相关文本上训练的用于<em class="ns">体育</em>的模型，比如与体育和体育名人相关联的推文。当然，对于实验和随后的评估来说，这方面的基础无疑是丰富的。</li></ul><p id="f7b9" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇文章的代码和更多内容可以在我的<a class="ae jd" href="https://github.com/RonKG/machine-learning-projects-2/tree/master/3.%20NLP_twitter_sentiment_analysis" rel="noopener ugc nofollow" target="_blank"> GitHub </a>获得。</p></div></div>    
</body>
</html>