<html>
<head>
<title>Quick review to leap into embedded models with proxies</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">快速回顾，进入具有代理的嵌入式模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/quick-review-to-leap-into-embedded-models-with-proxies-c6f39e24d06d?source=collection_archive---------16-----------------------#2018-09-12">https://towardsdatascience.com/quick-review-to-leap-into-embedded-models-with-proxies-c6f39e24d06d?source=collection_archive---------16-----------------------#2018-09-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="7e7e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为后续工作，我制作了一个 Jupyter 笔记本。这里收集的部分图片取自那里:【https://arxiv.org/pdf/1703.07464.pdf】https://github . com/rachuism/food-classifier-proxy-NCA/blob/master/visualization . ipynb 还有这里:<a class="ae km" href="https://arxiv.org/pdf/1703.07464.pdf" rel="noopener ugc nofollow" target="_blank">T5】</a></p><p id="0c98" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">顾名思义，嵌入是为了让东西变得更小。在深度学习的情况下，它包括将项目(例如，电影、文本等)映射到低维实向量，使相似的项目彼此靠近。</p><p id="3ef2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以让我们以一部电影的推荐系统为例。我们需要跟踪每个用户的口味来提取数据。但是，如果我们正在跟踪一组，例如，一百万部电影呢？对整个集合进行编码将如下所示:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi kn"><img src="../Images/891580a51a6b45850f0e0ac354c2bfad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t-gF4_uCJvLgQL2kBP-Ojg.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Taken from Google’s developers course</figcaption></figure><p id="c524" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这对于处理深度学习模型是非常低效的。相反，我们试图使用各种数学技术来减少这个空间的维数。下图显示了巨大的编码是如何“嵌入”网络的。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi ld"><img src="../Images/7151982af097444253cc3a9ceec24f92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*htb_BZXm3hjVfbf_MxKc8w.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Taken from Google’s developers course</figcaption></figure><p id="e6d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我的模型的训练期间，嵌入大小被选择为 64。这就是为什么当张量被打印出来时，有 64 个元素塑造了它:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi le"><img src="../Images/170a57851988d07ce6766612e0f61978.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tiu4-yiuUYowuD9hebQdXQ.png"/></div></div></figure><p id="3b63" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个项目的另一个关键词是“代理”,在这个例子中，它是作为模型参数的一部分学习的。它努力将一个数据集表示成一个点。根据经验，在代理上公式化的学习问题表现出比其他度量学习方法更快的收敛。</p><p id="9b4a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为一个帮助理解它的例子，让我们首先理解“三元组”的概念:有一个“锚”点<strong class="jp ir"> x </strong>，我们想减少到另一个相似点<strong class="jp ir"> y </strong>的距离，并增加到不同点<strong class="jp ir">z</strong>的距离。下图试图简化理解:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi lf"><img src="../Images/6153f201f2375522bb2e5679f5bae6dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/format:webp/1*w9lD35J9Rjr56jyuPC14Cg.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Taken from the aforementioned paper</figcaption></figure><p id="6e25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们想象我们的定位点是孤立的红色圆圈，它离其余的圆圈较近，离星星较远。这是总结代理意图的最佳实例。在下面的方案中，右图显示了一个大点如何表示一组点。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi lg"><img src="../Images/170cc3822fcfa1019d7173d728ef4f4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*MMs-MmvWc1uzeGbgA-B8rw.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Taken from the aforementioned paper</figcaption></figure><p id="43ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">可以看出，代理充当每个点集的上限表示。在这些距离上计算损耗，试图保持<strong class="jp ir"> x </strong>尽可能靠近<strong class="jp ir"> y </strong>并尽可能远离<strong class="jp ir">z</strong></p><h1 id="636f" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">资料组</h1><p id="c5f9" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">该数据集由 20 个食物类别和每个类别的 100 张图像组成。所选的种类有苹果派、面包布丁、牛肉片、甜菜沙拉、巧克力蛋糕、巧克力慕斯、甜甜圈、贝奈特饼、本尼迪克特蛋卷、法式面包卷、汤团、虾和玉米粉、烤三文鱼、猪排、千层面、馄饨、煎饼、法式吐司、意大利肉酱面、泰式炒面。</p><p id="59d2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">链接到数据集(UPMC-20 国集团):<a class="ae km" href="http://visiir.lip6.fr/" rel="noopener ugc nofollow" target="_blank">http://visiir.lip6.fr/</a></p><h1 id="a546" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">培训和评估</h1><p id="8125" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">下图解释了评估系统的工作流程。首先，将训练集提供给推荐算法，该算法产生可用于生成新预测的推荐模型。为了评估该模型，将保留的测试集提供给学习模型，其中为每个用户-项目对生成预测。<strong class="jp ir">具有已知标签的预测(真值)</strong>然后被用作评估算法的输入，以产生评估结果。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi mk"><img src="../Images/5058aec303024b742838fb8d049fb09c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZGVGrig1akAcyJdcYzwQGw.png"/></div></div></figure><p id="4ca0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为我只处理了 20 个类，所以我将其中的 50%用于训练集，50%用于评估</p><p id="3cf2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于远程度量学习来说，类的数量很少，因为与类内变化相比，类内变化很大。这就是后来 NMI 抛出低值的原因。</p><h1 id="3288" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated"><strong class="ak">预言。邻域成分分析</strong></h1><p id="3655" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">NCA 由一种监督学习方法组成，用于根据给定的数据距离度量将多元数据分类到不同的类中。(k 个最近邻居)。在“预测”步骤中，我使用:<strong class="jp ir">sk learn . metrics . pairwise . pairwise _ distances(X)</strong>来查找更接近我的查询的图像。</p><p id="a879" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这个例子中，我选择作为查询的图像是小菜一碟，经过一些转换(输入被调整为 256 × 256 像素，然后被随机裁剪为 227 × 227。像素的亮度已被缩放)看起来像这样:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/7946c1b85847c9c7c1c5e5a22fffc33a.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Wf0NW0HsiwbxaZMep-bWtw.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">UPMC20 dataset</figcaption></figure><p id="a807" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对该照片的检索是来自同一类(蛋糕)的图像:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/e6f8f048abe5093e713b0dec1e1c23a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*RwfS_ox8yUFa0RNY5ShbJg.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">UPMC20 dataset</figcaption></figure><h1 id="e6c1" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">理解日志</h1><p id="6463" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">纪元的数量已被设置为 20。有两个概念可以理解在“评估步骤”中损失是如何计算的</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/712039cf8bea6e9096de5614028aaf09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*FmHfQR4CWcPCrXNb-96FqA.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">.log file</figcaption></figure><p id="3f2c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">NMI:归一化互信息，定义为聚类和地面实况的互信息与其调和平均值的比值。它量化了通过其他随机变量获得的关于一个变量的信息量。</p><p id="12de" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">k 时回忆:<em class="kl">k 时回忆是前 k 项推荐中相关项目的比例。</em>所以在 R@1 的<em class="kl"> </em>的情况下，它意味着相关项目出现在第一个位置的概率为 40%，在 R@8 的情况下，它意味着相关项目出现在前 8 个位置的概率为 84%。这就是为什么参数“K”越大，其召回率越大的原因。数学上可以定义为:<strong class="jp ir">召回@k =(推荐项目数@k 相关)/(相关项目总数)。</strong></p><h1 id="1823" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated"><strong class="ak">参考</strong></h1><div class="mo mp gp gr mq mr"><a href="https://medium.com/@m_n_malaeb/recall-and-precision-at-k-for-recommender-systems-618483226c54" rel="noopener follow" target="_blank"><div class="ms ab fo"><div class="mt ab mu cl cj mv"><h2 class="bd ir gy z fp mw fr fs mx fu fw ip bi translated">推荐系统的召回率和 k 精度</h2><div class="my l"><h3 class="bd b gy z fp mw fr fs mx fu fw dk translated">附例详细说明</h3></div><div class="mz l"><p class="bd b dl z fp mw fr fs mx fu fw dk translated">medium.com</p></div></div><div class="na l"><div class="nb l nc nd ne na nf kx mr"/></div></div></a></div><p id="baea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">不要大惊小怪使用代理的距离度量学习</strong><a class="ae km" href="https://arxiv.org/pdf/1703.07464.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1703.07464.pdf</a></p></div></div>    
</body>
</html>