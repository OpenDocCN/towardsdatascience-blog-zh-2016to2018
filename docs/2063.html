<html>
<head>
<title>Artificial Intelligence is Probably Safe</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能很可能是安全的</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/artificial-intelligence-is-probably-safe-ce67f0abd759?source=collection_archive---------8-----------------------#2017-12-11">https://towardsdatascience.com/artificial-intelligence-is-probably-safe-ce67f0abd759?source=collection_archive---------8-----------------------#2017-12-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="cd5c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">尽管我们最终都会被宇宙<a class="ae kl" href="https://en.wikipedia.org/wiki/Googol" rel="noopener ugc nofollow" target="_blank">[10^100]</a>年后的<a class="ae kl" href="https://en.wikipedia.org/wiki/Heat_death_of_the_universe#Time_frame_for_heat_death" rel="noopener ugc nofollow" target="_blank"/>的<a class="ae kl" href="https://www.youtube.com/watch?v=4_aOIA-vyBo" rel="noopener ugc nofollow" target="_blank">热寂所杀死，但还有更多迫在眉睫的问题需要思考。还有太阳的</a><a class="ae kl" href="https://www.space.com/g00/23154-death-of-sun-will-destroy-earth-infographic.html?i10c.encReferrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNhLw%3D%3D" rel="noopener ugc nofollow" target="_blank">死亡</a>(从现在起 50 亿年<a class="ae kl" href="http://www.enchantedlearning.com/subjects/astronomy/sun/sundeath.shtml" rel="noopener ugc nofollow" target="_blank"/>)，以及行星的<a class="ae kl" href="https://www.nasa.gov/press-release/nasa-releases-detailed-global-climate-change-projections" rel="noopener ugc nofollow" target="_blank">加热</a>(参见模型中的 2100 年<a class="ae kl" href="https://www.livescience.com/1433-timeline-earth-precarious-future.html" rel="noopener ugc nofollow" target="_blank"/>)。这是一个好主意<a class="ae kl" href="https://nickbostrom.com/papers/future.html" rel="noopener ugc nofollow" target="_blank">优先考虑将杀死我们所有人的事情</a>，并避免所说的坏事情。我们不知道人工智能的威胁在时间线中的确切位置，但看起来人工智能更像是在 100 年或更短的时间内杀死我们所有人。肯定不会太快。不要在你的 2018 日历上标注 AI 末日。</p><p id="098f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我告诉你为什么我认为我们现在是安全的。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi km"><img src="../Images/23e53c4f3e9144ffa28bacd7e3cb0855.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/0*hmMaqK6wKkMnm6jm.jpg"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">I love <a class="ae kl" href="http://www.quickmeme.com/meme/3pty0g" rel="noopener ugc nofollow" target="_blank">Futurama</a>.</figcaption></figure><p id="efa8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">先说<a class="ae kl" href="https://books.google.ca/books?id=C-_8AwAAQBAJ&amp;lpg=PP1&amp;ots=UFS-LttOMq&amp;lr&amp;pg=PP1#v=onepage&amp;q&amp;f=false" rel="noopener ugc nofollow" target="_blank">AI 为什么危险</a>。超智能 AI 的默认状态是强优化。大多数强优化过程都是“杀死所有人类”的特例(例如<a class="ae kl" href="https://www.youtube.com/watch?v=tcdVC4e6EV4" rel="noopener ugc nofollow" target="_blank">集邮者</a>、<a class="ae kl" href="https://en.wikipedia.org/wiki/Instrumental_convergence" rel="noopener ugc nofollow" target="_blank">回形针机</a>)。这就是为什么 AI 安全是一个重要的问题，有时被称为<a class="ae kl" href="https://en.wikipedia.org/wiki/AI_control_problem" rel="noopener ugc nofollow" target="_blank">控制问题</a>。更多<a class="ae kl" href="https://www.youtube.com/results?search_query=computerphile+ai+safety" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><p id="ec6c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">超级智能也被称为“强人工智能”和人工通用智能(AGI)等。它开始是一个聪明的过程，变得越来越聪明，直到达到并超过人类水平的机器智能(HLMI)。这个点通常被称为奇点。这种人工智能不是通过已知的过程实现的。这是人类目前还没有实现的东西，我们也不知道如何制造我们给它贴上标签的东西。我们<a class="ae kl" href="https://www.youtube.com/watch?v=kfYZqBG1IDg" rel="noopener ugc nofollow" target="_blank">可以称暗物质和暗能量为“弗雷德和威尔玛”</a>，因为除了它们的名字，我们所知甚少。同样，除了知道它有多危险和强大，我们对 AGI 知之甚少。人工智能(不是 AGI)的力量在短期内是帮助人类的。当你读到这些文字的时候，这是一股自动化和效率的力量，它正迅速在经济和文化中荡漾。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi ky"><img src="../Images/facb88a19b4967934e511ea24c7ff873.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Yo75ycBRdKdfXwpc.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Fusion is hard. Really hard.</figcaption></figure><p id="560b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与来源不明的 AGI 相反，聚变是一个已知的过程。<a class="ae kl" href="https://www.youtube.com/watch?v=-MaASrJyqYg" rel="noopener ugc nofollow" target="_blank">核聚变对人类来说是令人敬畏的</a>，但也可能导致人类的终结(核聚变意味着每个人都拥有核武器，以及发动战争的无限能量)。所以，就大的上升空间和大的风险而言，这听起来类似于人工智能，但至少我们有了融合的蓝图。我们每天都看到太阳在进行核聚变，即使我们知道核聚变是如何在太阳中进行的，我们在地球上也没有运行的核聚变反应堆。是工程问题让核聚变遥不可及。很难在实验室里建造太阳(等离子体密封)。更容易制造太阳能电池板。</p><p id="5a53" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果融合很难，而且我们知道融合是如何工作的，那么<a class="ae kl" href="https://en.wikipedia.org/wiki/Argumentum_a_fortiori" rel="noopener ugc nofollow" target="_blank">做《AGI:危险的人工智能》就格外困难。我们不知道 AGI 是如何工作的，除了人类如何进化出我们的智慧之外，我们没有其他例子，我们也不知道产生 HLMI 或超级智慧有多难。因此，比起核聚变或全球变暖，不要更担心 AGI。</a></p><p id="7d18" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过理论上证明<a class="ae kl" href="https://youtu.be/sNhhvQGsMEc" rel="noopener ugc nofollow" target="_blank">大过滤器</a>在我们身后<a class="ae kl" href="https://www.youtube.com/watch?v=1fQkVqno-uI" rel="noopener ugc nofollow" target="_blank"/>，费米悖论正在被解答/解决。比如，也许线粒体+细胞=非常稀少。比起另一个选择，我更喜欢那个。我不相信 AGI 需要如此稀有的东西来生产，因为人工智能比生物生命需要更少的进化时间。但是……我们不要自欺欺人了。深度学习任重道远，融合也是如此。杀手机器人是真实的，但由强人工智能建造的机器人还很遥远。我认为这一领域的研究应该作为国家安全的重中之重来资助，就像核聚变一样，但是让我们正视威胁。全球气候变化，在我看来，比想要杀死所有人类的 AI 更有杀伤力，更立竿见影。我们知道气候正在变化。海平面上升=洪水=糟糕。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi ky"><img src="../Images/90949d7b4d53f7fc39a439faf2e16743.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uYbVLeEU6VMsTrXk.jpg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">The world after a 100 meter sea level rise, caused by melting 80% of the ice on the planet. This should bother you if you live bascially anywhere near open water.</figcaption></figure><p id="0182" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对人工智能来说，更直接的担忧应该是失业、假新闻和其他社会弊病。基本上，美国 30 万卡车司机中的 90%将被取代。所有的优步车手也是如此。如果我们现在就为这些影响做准备，这是一个好主意。也许用<a class="ae kl" href="https://youtu.be/kl39KHS07Xc" rel="noopener ugc nofollow" target="_blank">通用基本收入(UBI) </a>？一些其他的解决方案？</p><p id="bf76" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我在工作中制造人工智能系统，我并不害怕它。你不应该害怕。</p><p id="4c3d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">人工智能研究的进展速度令人印象深刻。我想说的是，就目前而言，人工智能可能是安全的，但应该继续研究人工智能的安全和控制问题。我怀疑我们能否将人类价值观灌输到超级智能中，但是值得一试去思考这些问题。</p><p id="0618" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我花了很多精力准备的上一篇文章之后，这是一篇非常有趣的高水平文章。如果你喜欢这篇关于人工智能安全的文章，请告诉我。在收到关于上一篇文章的一些不错的电子邮件反馈后，我确实计划写更多带有代码示例的研究内容。我也很高兴在评论中或通过电子邮件听到你对我的想法的反馈。你怎么想呢?</p><p id="ca0a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">试用<strong class="jp ir">拍手工具</strong>。轻点那个。跟着我们走。分享这篇文章的链接。去吧。</p><p id="77b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">编码快乐！</p><p id="e8c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">——丹尼尔<br/>T3】丹尼尔@lemay.ai  ←打个招呼。<br/><a class="ae kl" href="https://lemay.ai" rel="noopener ugc nofollow" target="_blank">LEMAY . AI</a><br/>1(855)LEMAY-AI</p><p id="8427" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可能喜欢的其他文章:</p><ul class=""><li id="167e" class="ld le iq jp b jq jr ju jv jy lf kc lg kg lh kk li lj lk ll bi translated"><a class="ae kl" rel="noopener" target="_blank" href="/artificial-intelligence-and-bad-data-fbf2564c541a">人工智能和不良数据</a></li><li id="d59c" class="ld le iq jp b jq lm ju ln jy lo kc lp kg lq kk li lj lk ll bi translated"><a class="ae kl" rel="noopener" target="_blank" href="/artificial-intelligence-hyperparameters-48fa29daa516">人工智能:超参数</a></li><li id="4172" class="ld le iq jp b jq lm ju ln jy lo kc lp kg lq kk li lj lk ll bi translated"><a class="ae kl" href="https://medium.com/towards-data-science/artificial-intelligence-get-your-users-to-label-your-data-b5fa7c0c9e00" rel="noopener">人工智能:让你的用户给你的数据贴标签</a></li></ul><p id="e806" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">附注:尼克·博斯特罗姆很棒:<a class="ae kl" href="https://www.fhi.ox.ac.uk/" rel="noopener ugc nofollow" target="_blank">https://www.fhi.ox.ac.uk/</a></p><p id="72ff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">花絮:甜甜圈来源于<a class="ae kl" href="https://www.youtube.com/watch?v=DePRyZE5sn4" rel="noopener ugc nofollow" target="_blank">面结</a>，切一个洞有助于它们煮得更均匀。</p></div></div>    
</body>
</html>