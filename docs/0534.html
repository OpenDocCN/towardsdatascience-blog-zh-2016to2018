<html>
<head>
<title>Train/Test Split and Cross Validation in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Python中训练/测试分割和交叉验证</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6?source=collection_archive---------0-----------------------#2017-05-17">https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6?source=collection_archive---------0-----------------------#2017-05-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="960b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">大家好！在我上一篇关于Python 中的<a class="ae ko" href="https://medium.com/towards-data-science/simple-and-multiple-linear-regression-in-python-c928425168f9" rel="noopener">线性回归的文章之后，我认为写一篇关于训练/测试分割和交叉验证的文章是很自然的。像往常一样，我将对这个主题做一个简短的概述，然后给出一个用Python实现它的例子。这是数据科学和数据分析中两个相当重要的概念，被用作防止(或至少最小化)</a><a class="ae ko" href="https://en.wikipedia.org/wiki/Overfitting" rel="noopener ugc nofollow" target="_blank">过度拟合</a>的工具。我将解释这是什么-当我们使用统计模型(例如线性回归)时，我们通常将模型拟合到训练集，以便对未经训练的数据(一般数据)进行预测。过度拟合意味着我们对模型的拟合过于依赖训练数据。很快就会明白的，我保证！</p><h1 id="edd3" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">什么是过度拟合/欠拟合模型？</h1><p id="7fe1" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">如上所述，在统计学和机器学习中，我们通常将数据分为两个子集:训练数据和测试数据(有时分为三个子集:训练、验证和测试)，并根据训练数据拟合我们的模型，以便对测试数据进行预测。当我们这样做时，可能会发生两种情况之一:我们使模型过拟合或者使模型欠拟合。我们不希望这些事情发生，因为它们会影响我们模型的可预测性——我们可能会使用一个准确性较低和/或不通用的模型(这意味着你不能根据其他数据概括你的预测)。让我们来看看欠拟合和过拟合的实际含义:</p><h2 id="7b33" class="ls kq it bd kr lt lu dn kv lv lw dp kz kb lx ly ld kf lz ma lh kj mb mc ll md bi translated">过度拟合</h2><p id="8708" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">过度拟合意味着我们训练的模型已经训练得“太好”,并且现在与训练数据集太接近了。这通常发生在模型过于复杂的时候(例如，与观察值相比，特征/变量太多)。该模型在训练数据上非常准确，但在未训练或新数据上可能非常不准确。这是因为这个模型不是一般化的(或者说不是一般化的)，这意味着你可以对结果进行一般化，而不能对其他数据进行任何推断，而这正是你最终想要做的。基本上，当这种情况发生时，模型学习或描述训练数据中的“噪声”,而不是数据中变量之间的实际关系。显然，这种噪声不是任何新数据集的一部分，也不能应用于它。</p><h2 id="28fb" class="ls kq it bd kr lt lu dn kv lv lw dp kz kb lx ly ld kf lz ma lh kj mb mc ll md bi translated">欠拟合</h2><p id="d5ed" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">与过度拟合相反，当模型拟合不足时，意味着模型不适合训练数据，因此错过了数据中的趋势。这也意味着该模型不能推广到新的数据。正如你可能猜到的(或者想出来的！)，这通常是一个非常简单的模型(没有足够的预测器/自变量)的结果。例如，当我们用线性模型(如<a class="ae ko" href="https://medium.com/towards-data-science/simple-and-multiple-linear-regression-in-python-c928425168f9" rel="noopener">线性回归</a>)拟合非线性数据时，也会发生这种情况。几乎不言而喻，这个模型的预测能力会很差(对训练数据，无法推广到其他数据)。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi me"><img src="../Images/a719c1679ed3d448edabb0ed7ef35492.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*tBErXYVvTw2jSUYK7thU2A.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">An example of overfitting, underfitting and a model that’s “just right!”</figcaption></figure><p id="8a3b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">值得注意的是，适配不足不像适配过度那样普遍。然而，我们希望在数据分析中避免这两个问题。你可能会说，我们正试图找到一个中间地带之间的不足和过度拟合我们的模型。正如您将看到的，训练/测试分割和交叉验证有助于避免过度拟合多于欠拟合。让我们深入了解这两个问题！</p><h1 id="a5ba" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">训练/测试分割</h1><p id="6a0b" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">我之前说过，我们使用的数据通常分为训练数据和测试数据。训练集包含一个已知的输出，模型学习这个数据，以便以后推广到其他数据。我们有测试数据集(或子集)来测试我们的模型对这个子集的预测。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi mq"><img src="../Images/190bb1d5442c8ba1854806a56eaf6204.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-8_kogvwmL1H6ooN1A1tsQ.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">Train/Test Split</figcaption></figure><p id="bf8a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们看看如何在Python中实现这一点。我们将使用<a class="ae ko" href="http://scikit-learn.org/stable/index.html" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn库</a>，特别是<a class="ae ko" href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank"> train_test_split方法</a>来完成这项工作。我们将从导入必要的库开始:</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="3c12" class="ls kq it mw b gy na nb l nc nd">import pandas as pd<br/>from sklearn import datasets, linear_model<br/>from sklearn.model_selection import train_test_split<br/>from matplotlib import pyplot as plt</span></pre><p id="2a74" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们快速浏览一下我导入的库:</p><ul class=""><li id="4253" class="ne nf it js b jt ju jx jy kb ng kf nh kj ni kn nj nk nl nm bi translated"><strong class="js iu"> Pandas </strong> —加载数据文件作为Pandas数据框并分析数据。如果你想了解更多关于熊猫的信息，请随时查看我的帖子！</li><li id="5f55" class="ne nf it js b jt nn jx no kb np kf nq kj nr kn nj nk nl nm bi translated">从<strong class="js iu"> Sklearn </strong>中，我已经导入了<em class="ns">数据集</em>模块，因此我可以加载一个样本数据集，以及<em class="ns"> linear_model </em>，因此我可以运行一个线性回归</li><li id="bca9" class="ne nf it js b jt nn jx no kb np kf nq kj nr kn nj nk nl nm bi translated">从<strong class="js iu"> Sklearn，</strong>子库<strong class="js iu"> model_selection </strong>，我已经导入了<em class="ns"> train_test_split </em>，这样我就可以，嗯，拆分到训练集和测试集</li><li id="8d86" class="ne nf it js b jt nn jx no kb np kf nq kj nr kn nj nk nl nm bi translated">从<strong class="js iu"> Matplotlib </strong>中，我导入了<em class="ns"> pyplot </em>来绘制数据的图形</li></ul><p id="c9ab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">好了，都准备好了！让我们加载<a class="ae ko" href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html" rel="noopener ugc nofollow" target="_blank">糖尿病数据集</a>，将其转换为数据框并定义列名:</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="97ce" class="ls kq it mw b gy na nb l nc nd"># Load the Diabetes dataset<br/>columns = “age sex bmi map tc ldl hdl tch ltg glu”.split() # Declare the columns names<br/>diabetes = datasets.load_diabetes() # Call the diabetes dataset from sklearn<br/>df = pd.DataFrame(diabetes.data, columns=columns) # load the dataset as a pandas data frame<br/>y = diabetes.target # define the target variable (dependent variable) as y</span></pre><p id="d0f5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们可以使用train_test_split函数来进行拆分。函数中的<em class="ns"> test_size=0.2 </em>表示应该保留下来进行测试的数据的百分比。一般是80/20或者70/30左右。</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="653b" class="ls kq it mw b gy na nb l nc nd"># create training and testing vars<br/>X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2)<br/>print X_train.shape, y_train.shape<br/>print X_test.shape, y_test.shape</span><span id="a443" class="ls kq it mw b gy nt nb l nc nd">(353, 10) (353,)<br/>(89, 10) (89,)</span></pre><p id="49d9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，我们将根据训练数据拟合模型:</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="baf8" class="ls kq it mw b gy na nb l nc nd"># fit a model<br/>lm = linear_model.LinearRegression()</span><span id="9dca" class="ls kq it mw b gy nt nb l nc nd">model = lm.fit(X_train, y_train)<br/>predictions = lm.predict(X_test)</span></pre><p id="c9fb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如您所见，我们正在根据训练数据拟合模型，并尝试预测测试数据。让我们看看有哪些预测:</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="0f1b" class="ls kq it mw b gy na nb l nc nd">predictions[0:5]<br/>array([ 205.68012533,   64.58785513,  175.12880278,  169.95993301,<br/>        128.92035866])</span></pre><p id="1844" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">注意:因为我在预测后使用了[0:5],所以它只显示了前五个预测值。删除[0:5]会使它打印出我们的模型创建的所有预测值。</p><p id="707b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们绘制模型:</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="99da" class="ls kq it mw b gy na nb l nc nd">## The line / model<br/>plt.scatter(y_test, predictions)<br/>plt.xlabel(“True Values”)<br/>plt.ylabel(“Predictions”)</span></pre><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/f97f0e204aac3d9d22c242ce9aadab98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*2f6x7rNuN0_zbW3_O5vOEA.png"/></div></figure><p id="0105" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">并打印准确度分数:</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="ae35" class="ls kq it mw b gy na nb l nc nd">print “Score:”, model.score(X_test, y_test)</span><span id="fd38" class="ls kq it mw b gy nt nb l nc nd">Score: 0.485829586737</span></pre><p id="7d1c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这就对了。以下是我所做工作的总结:我加载了数据，将其分为训练集和测试集，对训练数据拟合了回归模型，基于这些数据进行了预测，并对测试数据的预测进行了测试。看起来不错，对吧？但是训练/测试分割确实有它的危险——如果我们做的分割不是随机的呢？如果我们数据的一个子集只有某个州的人，有某个收入水平的员工，而没有其他收入水平的，只有女性或只有某个年龄的人，会怎么样？(想象一个由这些文件之一排序的文件)。这将导致过度拟合，即使我们试图避免它！这就是交叉验证的用武之地。</p><h1 id="7a51" class="kp kq it bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">交互效度分析</h1><p id="5280" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">在前一段中，我提到了训练/测试分割方法中的注意事项。为了避免这种情况，我们可以执行一种叫做<a class="ae ko" href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)" rel="noopener ugc nofollow" target="_blank">的交叉验证</a>。它非常类似于训练/测试分割，但是它适用于更多的子集。也就是说，我们将数据分成k个子集，并在其中的k-1个子集上进行训练。我们要做的是保留最后一个子集进行测试。我们可以对每个子集都这样做。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi nv"><img src="../Images/c4f319132a30447e1b2d96deed906e5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4G__SV580CxFj78o9yUXuQ.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">Visual Representation of Train/Test Split and Cross Validation. H/t to my <a class="ae ko" href="https://generalassemb.ly/education/data-science-immersive" rel="noopener ugc nofollow" target="_blank">DSI</a> instructor, <a class="nw nx ep" href="https://medium.com/u/690e8d667b35?source=post_page-----80b61beca4b6--------------------------------" rel="noopener" target="_blank">Joseph Nelson</a>!</figcaption></figure><p id="6af2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">有很多交叉验证方法，我将介绍其中的两种:第一种是<strong class="js iu"> K重交叉验证</strong>第二种是<strong class="js iu">留一交叉验证</strong> (LOOCV)</p><h2 id="5bb4" class="ls kq it bd kr lt lu dn kv lv lw dp kz kb lx ly ld kf lz ma lh kj mb mc ll md bi translated">k重交叉验证</h2><p id="e6fc" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">在K折叠交叉验证中，我们将数据分成K个不同的子集(或折叠)。我们使用k-1个子集来训练我们的数据，并将最后一个子集(或最后一个折叠)作为测试数据。然后，我们根据每个褶皱对模型进行平均，然后最终确定我们的模型。之后，我们用测试集来测试它。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ny"><img src="../Images/8ad7c5dd68efd72f4806cc631dcae787.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J2B_bcbd1-s1kpWOu_FZrg.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">Visual representation of K-Folds. Again, H/t to <a class="nw nx ep" href="https://medium.com/u/690e8d667b35?source=post_page-----80b61beca4b6--------------------------------" rel="noopener" target="_blank">Joseph Nelson</a>!</figcaption></figure><p id="0b46" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里有一个来自K折叠的<a class="ae ko" href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn-model-selection-kfold" rel="noopener ugc nofollow" target="_blank"> Sklearn文档</a>的非常简单的例子:</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="523c" class="ls kq it mw b gy na nb l nc nd">from sklearn.model_selection import KFold # import KFold<br/>X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]]) # create an array<br/>y = np.array([1, 2, 3, 4]) # Create another array<br/>kf = KFold(n_splits=2) # Define the split - into 2 folds <br/>kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator</span><span id="637f" class="ls kq it mw b gy nt nb l nc nd">print(kf) </span><span id="0b89" class="ls kq it mw b gy nt nb l nc nd">KFold(n_splits=2, random_state=None, shuffle=False)</span></pre><p id="cfb9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们看看结果——褶皱:</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="b6f3" class="ls kq it mw b gy na nb l nc nd">for train_index, test_index in kf.split(X):<br/> print(“TRAIN:”, train_index, “TEST:”, test_index)<br/> X_train, X_test = X[train_index], X[test_index]<br/> y_train, y_test = y[train_index], y[test_index]</span><span id="d82c" class="ls kq it mw b gy nt nb l nc nd">('TRAIN:', array([2, 3]), 'TEST:', array([0, 1]))<br/>('TRAIN:', array([0, 1]), 'TEST:', array([2, 3]))</span></pre><p id="9ab3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如您所见，该函数将原始数据分割成不同的数据子集。再次，非常简单的例子，但我认为它很好地解释了这个概念。</p><h2 id="03b1" class="ls kq it bd kr lt lu dn kv lv lw dp kz kb lx ly ld kf lz ma lh kj mb mc ll md bi translated">遗漏一项交叉验证(LOOCV)</h2><p id="8111" class="pw-post-body-paragraph jq jr it js b jt ln jv jw jx lo jz ka kb lp kd ke kf lq kh ki kj lr kl km kn im bi translated">这是另一种交叉验证的方法，<a class="ae ko" href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut" rel="noopener ugc nofollow" target="_blank">省去一个交叉验证</a>(顺便说一下，这些方法不是唯一的两种，还有一堆其他的交叉验证的方法。在<a class="ae ko" href="http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection" rel="noopener ugc nofollow" target="_blank"> Sklearn网站</a>查看。在这种类型的交叉验证中，折叠(子集)的数量等于我们在数据集中的观察数量。然后，我们对所有这些折叠进行平均，并用平均值构建我们的模型。然后，我们根据最后一次折叠测试模型。因为我们会得到大量的训练集(等于样本数)，这种方法计算量很大，应该在小数据集上使用。如果数据集很大，最好使用不同的方法，比如kfold。</p><p id="f2c7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们看看Sklearn的另一个例子:</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="58fe" class="ls kq it mw b gy na nb l nc nd"><strong class="mw iu">from</strong> <strong class="mw iu">sklearn.model_selection</strong> <strong class="mw iu">import</strong> LeaveOneOut <br/>X = np.array([[1, 2], [3, 4]])<br/>y = np.array([1, 2])<br/>loo = LeaveOneOut()<br/>loo.get_n_splits(X)<br/><br/><br/><strong class="mw iu">for</strong> train_index, test_index <strong class="mw iu">in</strong> loo.split(X):<br/>   print("TRAIN:", train_index, "TEST:", test_index)<br/>   X_train, X_test = X[train_index], X[test_index]<br/>   y_train, y_test = y[train_index], y[test_index]<br/>   print(X_train, X_test, y_train, y_test)</span></pre><p id="9703" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是输出结果:</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="56e3" class="ls kq it mw b gy na nb l nc nd">('TRAIN:', array([1]), 'TEST:', array([0]))<br/>(array([[3, 4]]), array([[1, 2]]), array([2]), array([1]))<br/>('TRAIN:', array([0]), 'TEST:', array([1]))<br/>(array([[1, 2]]), array([[3, 4]]), array([1]), array([2]))</span></pre><p id="355d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">再次，简单的例子，但我真的认为它有助于理解这个方法的基本概念。</p><p id="b0f5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">那么，我们应该用什么方法呢？多少折？我们有越多的折叠，我们将减少由于偏差引起的误差，但是增加由于方差引起的误差；显然，计算成本也会上升——折叠次数越多，计算时间就越长，并且需要更多内存。随着折叠次数的减少，我们减少了方差引起的误差，但偏差引起的误差会更大。这也将在计算上更便宜。因此，在大数据集中，通常建议k=3。在较小的数据集中，正如我之前提到的，最好使用LOOCV。</p></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><p id="0a02" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们看看我之前使用的例子，这次是使用交叉验证。我将使用<em class="ns"> cross_val_predict </em>函数返回测试切片中每个数据点的预测值。</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="52d3" class="ls kq it mw b gy na nb l nc nd"># Necessary imports: <br/>from sklearn.model_selection import cross_val_score, cross_val_predict<br/>from sklearn import metrics</span></pre><p id="6135" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如您所知，之前我已经为糖尿病数据集创建了训练/测试分割，并拟合了一个模型。我们来看看交叉验证后的分数是多少:</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="aacf" class="ls kq it mw b gy na nb l nc nd"># Perform 6-fold cross validation<br/>scores = cross_val_score(model, df, y, cv=6)<br/>print “Cross-validated scores:”, scores</span><span id="0ae5" class="ls kq it mw b gy nt nb l nc nd">Cross-validated scores: [ 0.4554861   0.46138572  0.40094084  0.55220736  0.43942775  0.56923406]</span></pre><p id="c77c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如你所见，最后一次折叠提高了原始模型的分数——从0.485提高到0.569。不是一个惊人的结果，但嘿，我们会采取我们能得到的:)</p><p id="ad4f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，让我们在执行交叉验证后，绘制新的预测:</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="74fa" class="ls kq it mw b gy na nb l nc nd"># Make cross validated predictions<br/>predictions = cross_val_predict(model, df, y, cv=6)<br/>plt.scatter(y, predictions)</span></pre><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi og"><img src="../Images/7524afbacbfa4871387ee97d336ef5d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*iHQeqD1jkhi1ihuxX_30lg.png"/></div></figure><p id="fa8e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你可以看到它与早期的原始情节有很大的不同。因为我用了cv=6，所以是原图的6倍多。</p><p id="1b02" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后，让我们检查模型的R得分(R是一个“表示从自变量可预测的因变量中方差的比例的数字)”。基本上，我们的模型有多精确):</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="5689" class="ls kq it mw b gy na nb l nc nd">accuracy = metrics.r2_score(y, predictions)<br/>print “Cross-Predicted Accuracy:”, accuracy</span><span id="8953" class="ls kq it mw b gy nt nb l nc nd">Cross-Predicted Accuracy: 0.490806583864</span></pre></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><p id="5d0f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这次到此为止！我希望你喜欢这篇文章。一如既往，我欢迎大家就您想阅读的主题提出问题、笔记、评论和请求。下次见！</p></div></div>    
</body>
</html>