<html>
<head>
<title>Building a Chat Bot With Object Detection and OCR</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用对象检测和 OCR 构建聊天机器人</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-chat-bot-with-image-recognition-and-ocr-721ee7b2a70b?source=collection_archive---------9-----------------------#2018-12-28">https://towardsdatascience.com/building-a-chat-bot-with-image-recognition-and-ocr-721ee7b2a70b?source=collection_archive---------9-----------------------#2018-12-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="dc6d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本系列的第 1 部分中，我们让我们的机器人能够从文本中检测情绪并做出相应的响应。但这是它能做的全部，而且不可否认相当无聊。</p><p id="2169" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当然，在真实的聊天中，我们经常发送各种媒体:从文本、图像、视频、gif 到任何其他东西。所以在这里，我们旅程的下一步，让我们给机器人一个愿景。本教程的目标是让我们的机器人接收图像，回复它们，并最终给我们一个关于图像中主要物体的粗略描述。</p><p id="ebfd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们开始吧！</p><p id="c5e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您还没有跟进，您可以在这里找到最新的代码:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><p id="d894" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以我们要修改的代码在我们的事件响应循环方法中，这里:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><p id="a62b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的机器人已经对图像做出反应，但它不知道它们是什么，并且以一种相当温和的方式做出反应。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi ks"><img src="../Images/f2fe42715cb1484c53fca409280e6480.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/1*-iZjBlCs6KSvIT_Hxs6rQA.gif"/></div></figure><p id="dae0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以试一试，自己看看。让我们启动我们的服务器(和 ngrok)，并向我们的机器人发送一个图像。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi kv"><img src="../Images/f82d87a2ae0c5be0b427b0bf87c60e88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0QL5R3cq03ndDufJbVAqbw.png"/></div></div></figure><p id="876f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">到目前为止一切顺利。我们的机器人至少知道它何时接收到图像。</p><p id="6e2e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这个系列中，我们一直使用 google cloud APIs，所以对于我们的图像检测，我们将使用 Google Cloud Vision。按照这里的快速入门来设置您的项目:<a class="ae la" href="https://cloud.google.com/vision/docs/quickstart-client-libraries" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/vision/docs/quick start-client-libraries</a>。记得使用我们在第 1 部分中设置的同一个项目。</p><p id="ab77" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦你完成了这些，现在是时候回到编码上来了。让我们将以下内容添加到我们的 Gemfile 中，并运行 bundle install:</p><pre class="kl km kn ko gt lb lc ld le aw lf bi"><span id="9839" class="lg lh iq lc b gy li lj l lk ll">gem 'google-cloud-vision'</span></pre><p id="0d30" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们在<strong class="jp ir"> main.rb </strong>中添加以下内容:</p><pre class="kl km kn ko gt lb lc ld le aw lf bi"><span id="8fe7" class="lg lh iq lc b gy li lj l lk ll">require ‘google/cloud/vision’</span></pre><p id="ebc3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们想要创建云语言 API 的一个实例:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">You can find your project ID in your google cloud console.</figcaption></figure><p id="2533" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们要使用的 vision API 特性叫做<a class="ae la" href="https://googleapis.github.io/google-cloud-ruby/docs/google-cloud-vision/latest/Google/Cloud/Vision/Annotation.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">注释</strong> </a>。给定一个<strong class="jp ir">文件路径</strong>到本地机器上的一个图像，它将尝试基于我们传递给方法调用的值来识别图像。</p><p id="1fb7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在下面的例子中(来自 Google 的文档):</p><pre class="kl km kn ko gt lb lc ld le aw lf bi"><span id="7f91" class="lg lh iq lc b gy li lj l lk ll">vision = <a class="ae la" href="https://googleapis.github.io/google-cloud-ruby/docs/google-cloud-vision/latest/Google.html" rel="noopener ugc nofollow" target="_blank"><strong class="lc ir">Google</strong></a>::<a class="ae la" href="https://googleapis.github.io/google-cloud-ruby/docs/google-cloud-vision/latest/Google/Cloud.html" rel="noopener ugc nofollow" target="_blank"><strong class="lc ir">Cloud</strong></a>::<a class="ae la" href="https://googleapis.github.io/google-cloud-ruby/docs/google-cloud-vision/latest/Google/Cloud/Vision.html" rel="noopener ugc nofollow" target="_blank"><strong class="lc ir">Vision</strong></a>.<a class="ae la" href="https://googleapis.github.io/google-cloud-ruby/docs/google-cloud-vision/latest/Google/Cloud/Vision.html#new-class_method" rel="noopener ugc nofollow" target="_blank">new</a><br/>image = vision.image "path/to/face.jpg"<br/><br/>annotation = vision.annotate image, faces: <strong class="lc ir">true</strong>, labels: <strong class="lc ir">true</strong><br/>annotation.faces.count <em class="lq">#=&gt; 1<br/></em>annotation.labels.count <em class="lq">#=&gt; 4<br/></em>annotation.text <em class="lq">#=&gt; nil</em></span></pre><p id="b653" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们告诉 vision API 尝试识别人脸和标签。“标签”本质上是 API 确定它已经识别的对象。如果给我们一张狗的照片，我们可能会被贴上以下标签:</p><pre class="kl km kn ko gt lb lc ld le aw lf bi"><span id="7644" class="lg lh iq lc b gy li lj l lk ll">{<br/>  "responses": [<br/>    {<br/>      "labelAnnotations": [<br/>        {<br/>          "mid": "/m/0bt9lr",<br/>          "description": "dog",<br/>          "score": 0.97346616<br/>        },<br/>        {<br/>          "mid": "/m/09686",<br/>          "description": "vertebrate",<br/>          "score": 0.85700572<br/>        },<br/>        {<br/>          "mid": "/m/01pm38",<br/>          "description": "clumber spaniel",<br/>          "score": 0.84881884<br/>        },<br/>        {<br/>          "mid": "/m/04rky",<br/>          "description": "mammal",<br/>          "score": 0.847575<br/>        },<br/>        {<br/>          "mid": "/m/02wbgd",<br/>          "description": "english cocker spaniel",<br/>          "score": 0.75829375<br/>        }<br/>      ]<br/>    }<br/>  ]<br/>}</span></pre><p id="80e6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们创建以下方法来利用这一功能:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><p id="c20e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面的方法(不可否认是幼稚的)基于 Google cloud vision 的 API 的结果，获取一个文件路径并返回一个字符串。在<strong class="jp ir"> annotate </strong>方法中，我们传递了一些参数，这些参数告诉 API 我们想要检测什么。</p><p id="7231" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个方法的返回(响应)是一个级联的短路流，首先检查著名的地标、任何文本，最后检查它检测到的任何对象(标签)。出于本教程的目的，这个流程纯粹是任意的和简化的(即，不要给我发电子邮件告诉我如何改进它)。</p><p id="3799" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面这张图我们来试试吧:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/51d4e87876e304deb8b7e1445d199a12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1170/format:webp/1*gYAKcwU81_4SmzwHZDIe8A.jpeg"/></div></figure><p id="7998" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">和结果(截断):</p><pre class="kl km kn ko gt lb lc ld le aw lf bi"><span id="573b" class="lg lh iq lc b gy li lj l lk ll">description: "cuisine", score: 0.9247923493385315, confidence: 0.0, topicality: 0.9247923493385315, bounds: 0, locations: 0, properties: {}<br/>description: "sushi", score: 0.9149415493011475, confidence: 0.0, topicality: 0.9149415493011475, bounds: 0, locations: 0, properties: {}<br/>description: "food", score: 0.899940550327301, confidence: 0.0, topicality: 0.899940550327301, bounds: 0, locations: 0, properties: {}<br/>description: "japanese cuisine", score: 0.8769422769546509, confidence: 0.0, topicality: 0.8769422769546509, bounds: 0, locations: 0, properties: {}</span></pre><p id="139c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于没有地标或文本，我们收到了 API 能够检测到的标签。在这种情况下，我们看到它已被确定为“寿司”根据我对标签检测结果的经验，第二个标签(具有第二高的话题性)倾向于普通人如何识别该图片。</p><p id="8326" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们在下面再试一次:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi ls"><img src="../Images/3906285cdcc9d887f4084b7cd53f849e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X43sWKcN7KaP9xNebEfHWQ.jpeg"/></div></div></figure><p id="6d5b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">输出(再次被截断):</p><pre class="kl km kn ko gt lb lc ld le aw lf bi"><span id="ff56" class="lg lh iq lc b gy li lj l lk ll">description: "wildlife", score: 0.9749518036842346, confidence: 0.0, topicality: 0.9749518036842346, bounds: 0, locations: 0, properties: {}<br/>description: "lion", score: 0.9627781510353088, confidence: 0.0, topicality: 0.9627781510353088, bounds: 0, locations: 0, properties: {}<br/>description: "terrestrial animal", score: 0.9247941970825195, confidence: 0.0, topicality: 0.9247941970825195, bounds: 0, locations: 0, properties: {}</span></pre><p id="84a8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们看到了，《狮子》是第二部热播剧。</p><p id="8dd8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好的，另一个好的衡量标准，让我们尝试一些文本提取:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi lt"><img src="../Images/57ed2407411b6c710693d2120854be3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hACGuAihwfxJaPzRYAswCw.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Just a screenshot of my text editor</figcaption></figure><p id="17ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们看看我们得到了什么:</p><pre class="kl km kn ko gt lb lc ld le aw lf bi"><span id="a868" class="lg lh iq lc b gy li lj l lk ll">2.4.2 :022 &gt; puts analyze_image("major_general.png")<br/>I am the very model of a modern Major-General,<br/>I've information vegetable, animal, and mineral,<br/>I know the kings of England, and I quote the fights historical<br/>From Marathon to Waterloo, in order categorical;<br/>I'm very well acquainted, too, with matters mathematical,<br/>I understand equations, both the simple and quadratical,<br/>About binomial theorem I'm teeming with a lot o' news, (bothered for a rhyme)<br/>With many cheerful facts about the square of the hypotenuse.<br/> =&gt; nil<br/>2.4.2 :023 &gt;</span></pre><p id="8ddf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">还不错。</p><p id="e1e9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好吧，为了完整起见，最后一个。让我们尝试一个地标:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi lu"><img src="../Images/c3ed259d7c1dec26d317abb3ff869cfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OMPb_rz_MIs8RPpEl0JNIw.jpeg"/></div></div></figure><p id="111d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的方法给了我们:</p><pre class="kl km kn ko gt lb lc ld le aw lf bi"><span id="9abd" class="lg lh iq lc b gy li lj l lk ll">2.4.2 :030 &gt; puts analyze_image(“statue_of_liberty.jpg”)<br/>Statue of Liberty</span></pre><p id="bc71" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好了，我们的方法正在按预期工作，现在让我们实际使用我们的聊天机器人。</p><p id="eb1e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我们通过我们的客户端(Line)向我们的聊天机器人发送一个图像时，客户端将响应体中的图像数据(以及其他相关信息)返回给我们的回调。因为我们的图像识别方法需要一个文件路径，所以我们必须将上述图像数据保存到我们的本地机器上。</p><p id="25f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们修改我们的方法来做到这一点。将回调方法的相关部分更改为以下内容:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><p id="04cf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里有点不对劲。首先，我们创建一个新的<a class="ae la" href="https://ruby-doc.org/stdlib-1.9.3/libdoc/tempfile/rdoc/Tempfile.html" rel="noopener ugc nofollow" target="_blank"> Tempfile </a>，并使用响应主体(图像数据)作为其内容。然后，我们将临时文件的路径传递给刚刚在控制台中测试过的<strong class="jp ir">分析图像</strong>方法。让我们用我们的机器人试一试，作为一个理智检查。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi lv"><img src="../Images/e312a2067f47aeb634c427e362e0e3fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nQo4WdSfMrn0oAYDNZjXdA.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Such a nice bot…</figcaption></figure><p id="ccf3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它成功地为我们识别出了一个地标。</p><p id="df02" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的机器人现在只是作为一个美化的控制台打印行工作，这不是很健谈。我们希望这个东西听起来更自然，让我们稍微清理一下我们的方法，让它听起来更“人性化”。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/3178d2ae4c7eaf3a2bc5f85d56ebd051.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/1*ZN1KndpvpwzpynGmVBUq7g.gif"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">In fact, it is.</figcaption></figure><p id="57d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们对代码进行必要的修改。我们将修改一个现有的方法<strong class="jp ir"> analyze_image </strong>并创建一个新方法<strong class="jp ir">get _ analyze _ image _ response</strong>。下面是:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure><p id="09ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">同样，这不是一个关于 Ruby 的教程，而是概念；然而，让我们回顾一下我们刚刚做的事情。在<strong class="jp ir"> analyze_image </strong>中，我们简单地删除了字符串 reply，并用我们的新方法<strong class="jp ir"> get_analyze_image_response 替换它。</strong>该方法采用一个注释对象，并基于图像中识别的对象类型，使用注释对象的描述值构建一个句子(字符串)。</p><p id="c0c1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们来试试吧！</p><p id="b4ce" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">经典:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi lx"><img src="../Images/98df80eb67a8bb45ecfb4871a1a34ec7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4rRcUtJ2fET8WcRsi1KiOA.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">It’s a bacon cheeseburger, but I’ll give you that one.</figcaption></figure><p id="0955" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在是一个里程碑:</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi ly"><img src="../Images/5a7a39c1a34470e600c451ab4fc20a3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LBsmC3PGn1LobLk9W2woPQ.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">It indeed is!</figcaption></figure><p id="6f4b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">就是这样！我们的机器人现在使用光学字符识别从图像中提取文本，并给我们提供它在我们发送的任何图像中找到的对象的基本描述。</p><p id="8722" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">目前，我们的机器人只能回复一次性消息。但是如果它有“记忆”，并且能够进行真正的对话呢？我们将在第 3 部分讨论多步沟通。</p><p id="de84" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是我们到目前为止的所有代码:</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div></figure></div></div>    
</body>
</html>