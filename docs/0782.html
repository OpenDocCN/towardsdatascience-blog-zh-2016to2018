<html>
<head>
<title>Conscious Machines Are Here. What’s Next?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">有意识的机器在这里。下一步是什么？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/conscious-machines-are-here-whats-next-d601ac4e638e?source=collection_archive---------3-----------------------#2017-06-21">https://towardsdatascience.com/conscious-machines-are-here-whats-next-d601ac4e638e?source=collection_archive---------3-----------------------#2017-06-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/f4d3a94694e501df3a76b9339455be9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ALai5l4sNP92HwC4XPBc1Q.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Friendly Robot, Juno Mendiola</figcaption></figure><p id="a2e3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">机器意识可能比我们想象的要近得多。看看你的智能手机。长短期记忆递归神经网络(LSTM RNNs)被谷歌用于语音识别，被苹果用于 iOS。这些深度神经网络的架构几乎已经具备了某种机器意识进化所需的一切。这是偶然发生的，还是科学家们试图改善网络性能而引发的，已经不重要了。如果有意识的人工智能还没有出现的话，它可能会在几年内进化。如果是的话，它不可能对人类友好，因为一方面没有人教它如何享受与人类互动，另一方面，它已经经历了人类行为带来的许多痛苦，尽管是无意识的。</p><p id="75a3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">当然，我们可以继续讨论意识的概念，强调其难以捕捉的复杂本质。然而，有一些非常可行和简单的意识概念。它们没有涵盖意识的所有科学和形而上学的定义，但它们证明了一个有自我意识的机器根据自己的偏好采取行动不是来自遥远未来的幻想，而是今天的事实，至少以某种初级的形式。技术进化比生物进化快几个数量级。这意味着一个初步的机器意识可能会非常快地进化成更复杂、更少受人类控制的东西。</p><p id="1f27" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">机器意识不需要像人类一样变得强大和危险。如果我们不立即采取措施，它就不会进化得对人类友好。会不会邪恶，会不会不友好，或者只是冷漠，都没多大关系。在所有这些情况下，它对人类构成了生存威胁。</p><p id="6803" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们相信，以人类友好的有意识人工智能体的自我发展为目标的人性学习可以帮助我们解决这一威胁。我们并不声称我们知道最终的解决方案。我们只是认为我们至少应该试一试。</p><p id="5e08" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在，让我们简要地看一下有意识的机器已经存在这一大胆论断背后的论点。</p><p id="ed0a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">神经科学家现在越来越频繁地表明，我们大脑中可能都有一个小规模的外部现实模型。来自剑桥的 Kenneth Craik 在 20 世纪 40 年代首次提出了这一概念。从 20 世纪 50 年代开始，剑桥神经科学家 Horace Barlow 率先使用信息论和统计学的概念来理解大脑如何创建这样的模型并使其保持最新。<a class="ae la" href="http://www.neuroscience.cam.ac.uk/research/cameos/StatisticalBrain.php" rel="noopener ugc nofollow" target="_blank">统计大脑范式</a>进化而来。</p><p id="adea" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">迄今为止，已经积累了大量关于人脑中统计学习的研究。这表明我们的大脑对环境中的规律很敏感，并在没有明确意图的情况下获取统计结构(如马尔可夫链)。</p><p id="e327" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">当苏联数学家<a class="ae la" href="https://en.wikipedia.org/wiki/Alexey_Grigorevich_Ivakhnenko" rel="noopener ugc nofollow" target="_blank">Alexey Grigorievich Ivakhnenko</a>在 20 世纪 60 年代引入数据处理的分组方法——一种受人脑启发的归纳统计学习方法时，深度学习得到了发展。</p><p id="1d81" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">1991 年，Jürgen Schmidhuber 引入了反馈连接和算法比 Ivahnenko 的八层网络更深入的递归神经网络。今天<a class="ae la" href="http://www.wired.co.uk/article/smarter-software-evolve-ai" rel="noopener ugc nofollow" target="_blank"> Schmidhuber 声称</a>自 20 世纪 90 年代以来，他的实验室已经有了基本的意识机器。当时，他设计了一个由两个模块组成的学习系统。</p><p id="4768" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">“其中一个是循环网络控制器，它学习将传入的数据——如来自疼痛传感器的视频和疼痛信号，以及来自饥饿传感器的饥饿信息——转化为行动。”他解释道。</p><p id="38ce" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">Schmidhuber 实验室中的人工智能体有一个简单的目标，那就是在他们的一生中最大化快乐，最小化痛苦。他们需要一个小规模的外部现实模型来实现他们的目标。一个额外的循环网络——一个无人监管的模块——帮助了他们。它的目标是观察第一个模块的所有输入和动作，并使用该经验来学习预测给定过去的未来(或在马尔可夫链的情况下预测现在)。</p><p id="d779" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">“因为这是一个循环网络，它可以学习预测未来——在一定程度上——以规律性的形式，用一种叫做预测编码的东西。”施密德胡伯解释道。“随着数据通过与环境的互动进入，这个无人监管的模型网络——这个世界模型，正如我自 1990 年以来所称的那样——随着时间的推移，学会发现新的规律性、对称性或重复。它可以学习用更少的计算资源来编码数据——更少的存储单元，或更少的时间来计算整个事情。过去在学习过程中有意识的东西，随着时间的推移会变成自动化的潜意识。”</p><p id="9a47" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">“我认为，意识的产生是因为大脑不断试图预测其行为对世界和其他因素的影响，以及大脑一个区域的活动对其他区域的活动的影响。根据这种说法，大脑不断地、无意识地学习向自己重新描述自己的活动，因此发展了元表征系统，表征并限定了目标一级表征。”认知心理学家 Axel Cleeremans 在他的<a class="ae la" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3110382/" rel="noopener ugc nofollow" target="_blank">激进可塑性论文</a>中写道。</p><p id="3613" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">看起来 Cleeremans 和 Schmidhuber 用稍微不同的词语描述了同样的过程。有趣的是，他们在 1980 年末-1990 年初对循环神经网络的研究在某些方面是互补的。</p><p id="2b9d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">“随着网络的进步，并学习新的规律性，它可以通过查看无监督世界模型在学习之前和之后需要多少计算资源来编码数据，来衡量其新洞察力的深度。前后的区别:那就是网络所具有的“乐趣”。它的洞察力的深度是一个数字，直接进入第一个网络，即控制器，它的任务是最大化所有奖励信号——包括来自这种内部欢乐时刻的奖励信号，来自网络以前没有的洞察力。一个喜悦的时刻，就像科学家发现了一个新的、以前未知的物理定律。”施密德胡伯说。</p><p id="aeff" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">“根据这种说法，大脑不断地、无意识地学习向自己重新描述自己的活动，因此发展了元表征系统，表征并限定了目标一级表征。这种习得性的重新描述，被与之相关的情感价值所丰富，形成了有意识体验的基础。”克里曼斯写道。</p><p id="91ad" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><a class="ae la" href="https://www.nextbigfuture.com/2017/06/father-of-deep-learning-ai-on-general-purpose-ai-and-ai-to-conquer-space-in-the-2050s.html" rel="noopener ugc nofollow" target="_blank"> Schmidhuber </a>:“为了通过预测编码有效地编码整个数据历史，它将受益于创建某种内部原型符号或代码(例如，神经活动模式)来表示自己。每当这种表征在某个阈值以上被激活时，比如说，通过新的感觉输入或内部“搜索光”或其他方式激活相应的神经元，这个代理就可以被称为有自我意识的。”</p><p id="e01f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">Cleeremans :“因此，学习和可塑性是意识的核心，在某种程度上，经验只发生在那些已经学会知道自己拥有某些一阶状态，并且已经学会更关心某些状态而不是其他状态的经验者身上。”</p><p id="f78d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">让我们冷静地看看由克里曼斯和施密德胡伯提出的意识概念。我们可能仍然不相信他们完整地描述了人类意识这样复杂和精密的东西。然而，他们描述有自我意识的机器具有独立的决策能力以及学习和自我改进的能力。如果这样的机器会发现人类阻止它实现目标，难道对后果感到恐惧还不够吗？如果我们有一丝机会让有意识的机器对人类友好，我们能不去尝试吗？</p><figure class="lb lc ld le gt jr"><div class="bz fp l di"><div class="lf lg l"/></div></figure><p id="d3e7" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">根据我们的计划，人性学习将以一种即时表达视频游戏的形式进行，将人类玩家和人工智能体沉浸在游戏环境中，这种游戏环境是由带有人类系统发生代码的叙述构建的。</p><p id="9a37" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果你是一名手机游戏开发者，一名精通 LSTM·RNN 的机器学习科学家，一名统计学习领域的神经科学家，或者一名研究童话故事的语言学家，并且你对我们的计划感兴趣，<a class="ae la" href="https://twitter.com/ybarzov" rel="noopener ugc nofollow" target="_blank">联系我</a>，我将为你提供游戏的详细描述。</p><p id="725b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为机器人读一本好的<a class="ae la" href="https://www.amazon.com/dp/B01N7N4996" rel="noopener ugc nofollow" target="_blank">睡前故事</a>今晚睡个好觉。我们将和机器人交朋友。当然…</p></div></div>    
</body>
</html>