<html>
<head>
<title>Multi-label image classification with Inception net</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于初始网的多标签图像分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multi-label-image-classification-with-inception-net-cbb2ee538e30?source=collection_archive---------0-----------------------#2017-04-02">https://towardsdatascience.com/multi-label-image-classification-with-inception-net-cbb2ee538e30?source=collection_archive---------0-----------------------#2017-04-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/b5cae2d9ad2b50e926552c100f0f7073.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uXfC5fcbDsL0TJG4T8PsVw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Inception v3 architecture. (<a class="ae kc" href="https://github.com/tensorflow/models/tree/master/inception" rel="noopener ugc nofollow" target="_blank">source</a>)</figcaption></figure><p id="dc1b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">更新:</strong>本文已更新，修复了<a class="lb lc ep" href="https://medium.com/u/abf9181453af?source=post_page-----cbb2ee538e30--------------------------------" rel="noopener" target="_blank">特里萨·巴顿</a>指出的精度计算可能存在的问题。<a class="ae kc" href="https://github.com/BartyzalRadek/Multi-label-Inception-net" rel="noopener ugc nofollow" target="_blank"> git 回购</a>也已经更新，你可以在那里找到所有的变化。</p></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><p id="f0fc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://github.com/tensorflow/models/tree/master/inception" rel="noopener ugc nofollow" target="_blank"> Inception v3 </a>是一个深度卷积神经网络，在<a class="ae kc" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>数据集上训练用于单标签图像分类。TensorFlow 团队已经准备了一个<a class="ae kc" href="https://codelabs.developers.google.com/codelabs/tensorflow-for-poets" rel="noopener ugc nofollow" target="_blank">教程</a>来重新训练它，根据我们自己的例子来区分一些类。我们将修改教程<strong class="kf ir"> </strong>中的再训练脚本<strong class="kf ir"> retrain.py </strong>，将网络改为多标签分类器。</p><p id="b29a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你只是想跳转到结果代码，这里的<a class="ae kc" href="https://github.com/BartyzalRadek/Multi-label-Inception-net" rel="noopener ugc nofollow" target="_blank">是</a>所有必要的文件和信息，需要让它工作。从现在开始，我将假设您已经克隆了提到的存储库并引用了它的文件。</p><p id="69ec" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那么需要做些什么呢？首先，我们必须以某种方式告诉网络哪一个是每个图像的正确标签。然后，我们必须修改正在重新训练的最后一层和评估生成的预测的方法，以便实际上能够针对每个图像的多个可能的正确类别来训练它。</p><h1 id="b6fd" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">要求</h1><ul class=""><li id="3d93" class="mi mj iq kf b kg mk kk ml ko mm ks mn kw mo la mp mq mr ms bi translated"><a class="ae kc" href="https://github.com/tensorflow/tensorflow/releases/tag/0.12.0-rc1" rel="noopener ugc nofollow" target="_blank">张量流 0.12.0-rc1 </a></li><li id="6c61" class="mi mj iq kf b kg mt kk mu ko mv ks mw kw mx la mp mq mr ms bi translated">JPEG 格式的训练图像</li><li id="859d" class="mi mj iq kf b kg mt kk mu ko mv ks mw kw mx la mp mq mr ms bi translated"><a class="ae kc" href="https://github.com/BartyzalRadek/Multi-label-Inception-net" rel="noopener ugc nofollow" target="_blank">修改后的源代码与示例</a></li></ul><h1 id="4eb6" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">数据预处理</h1><h2 id="4972" class="my ll iq bd lm mz na dn lq nb nc dp lu ko nd ne ly ks nf ng mc kw nh ni mg nj bi translated">准备训练图像</h2><ol class=""><li id="fb77" class="mi mj iq kf b kg mk kk ml ko mm ks mn kw mo la nk mq mr ms bi translated">将所有训练图像放入<strong class="kf ir">图像</strong>目录下的一个文件夹中。<br/>尽量去掉所有重复的图像，它们可能会人为地夸大测试<em class="nl"> </em>和验证的准确性。文件夹的名称并不重要。我用的是<strong class="kf ir">多标</strong>。</li></ol><h2 id="e8de" class="my ll iq bd lm mz na dn lq nb nc dp lu ko nd ne ly ks nf ng mc kw nh ni mg nj bi translated">为每个训练图像准备标签</h2><p id="7bd5" class="pw-post-body-paragraph kd ke iq kf b kg mk ki kj kk ml km kn ko nm kq kr ks nn ku kv kw no ky kz la ij bi translated">我们需要为每个图像准备带有正确标签的文件。将文件命名为<strong class="kf ir">&lt;image _ file _ name . jpg&gt;。txt </strong> =如果你有一张图片【car.jpg.txt】，附带的文件应该命名为<strong class="kf ir"> car.jpg.txt </strong>。</p><p id="a557" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将每个标签放在文件中的一个新行上，不要做其他事情。</p><p id="da55" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在将所有创建的文件复制到项目根目录下的<strong class="kf ir"> image_labels_dir </strong>目录中。您可以通过编辑<strong class="kf ir"> retrain.py </strong>中的全局变量 IMAGE_LABELS_DIR 来更改该文件夹的路径。</p><h2 id="6b12" class="my ll iq bd lm mz na dn lq nb nc dp lu ko nd ne ly ks nf ng mc kw nh ni mg nj bi translated">创建包含所有标签的文件</h2><p id="320c" class="pw-post-body-paragraph kd ke iq kf b kg mk ki kj kk ml km kn ko nm kq kr ks nn ku kv kw no ky kz la ij bi translated">最初的 Inception net 使用一个文件夹结构来导出类的列表。在我们的例子中，所有的训练图像都在一个文件夹中，因此我们需要在一个外部文件中列出这些类。</p><p id="4a49" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在项目根目录下创建文件<strong class="kf ir"> labels.txt </strong>，并用所有可能的标签填充它。每个标签在一个新的行上，没有别的。就像所有可能的类中的图像的<strong class="kf ir"> image_label </strong>文件一样。</p><h1 id="871d" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">修改总管</h1><p id="29e2" class="pw-post-body-paragraph kd ke iq kf b kg mk ki kj kk ml km kn ko nm kq kr ks nn ku kv kw no ky kz la ij bi translated">main()方法最初将包含每个标签的图像的目录结构加载到单独的文件夹中，并通过以下方式为每个类创建了<em class="nl">验证</em>、<em class="nl">测试</em>和<em class="nl">训练</em>集合:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="d0a0" class="my ll iq nu b gy ny nz l oa ob">image_lists = create_image_lists(FLAGS.image_dir, FLAGS.testing_percentage,cFLAGS.validation_percentage)</span></pre><p id="3c9e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在在一个目录中有所有的图像，因此<strong class="kf ir"> image_lists.keys() </strong>只包含一个元素，那就是我们所有图像的文件夹(例如多标签)。所有的训练图像被分成<em class="nl">验证</em>、<em class="nl">测试</em>和<em class="nl">训练</em>组，通过该键可以进入。</p><p id="486c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们已经正确地分割了数据，我们只需要加载标签列表并计算类计数:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="6810" class="my ll iq nu b gy ny nz l oa ob"><strong class="nu ir">with </strong>open(ALL_LABELS_FILE) <strong class="nu ir">as </strong>f:<br/>    labels = f.read().splitlines()<br/>class_count = len(labels)</span></pre><h1 id="18f7" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">创建地面真实向量</h1><ol class=""><li id="fe3a" class="mi mj iq kf b kg mk kk ml ko mm ks mn kw mo la nk mq mr ms bi translated">添加<strong class="kf ir">get _ image _ labels _ path()</strong>方法，该方法只是稍微编辑了一下<strong class="kf ir"> get_image_path() </strong>方法返回包含正确图像标签的文件的路径=例如<strong class="kf ir">image _ labels _ dir/car . jpg . txt</strong>对于<strong class="kf ir">car.jpg</strong>。</li><li id="fa82" class="mi mj iq kf b kg mt kk mu ko mv ks mw kw mx la nk mq mr ms bi translated">编辑<strong class="kf ir">get _ random _ cached _ 瓶颈()</strong>方法:</li></ol><p id="d2a3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该方法创建包含每个返回图像的正确标签的 ground_truth 向量。最初它只是创建了一个零向量:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="fbd3" class="my ll iq nu b gy ny nz l oa ob">ground_truth = np.zeros(class_count, dtype=np.float32)</span></pre><p id="0b34" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后在正确的标签位置放一个 1.0，这是我们知道的，因为这是我们从中获取图像的文件夹的名称:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="1feb" class="my ll iq nu b gy ny nz l oa ob">ground_truth[label_index] = 1.0</span></pre><p id="68dc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">多标签分类没那么简单。我们需要从 image_label_file 中为给定的图像加载所有正确的标签。</p><p id="c8bb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">获取带有正确标签的文件路径:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="85f8" class="my ll iq nu b gy ny nz l oa ob">labels_file = get_image_labels_path(image_lists,label_name,image_index, IMAGE_LABELS_DIR, category)</span></pre><p id="f832" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从文件中读取所有行=标签，并保存到数组<strong class="kf ir"> true_labels </strong>:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="3203" class="my ll iq nu b gy ny nz l oa ob"><strong class="nu ir">with </strong>open(labels_file) <strong class="nu ir">as </strong>f:<br/>   true_labels = f.read().splitlines()</span></pre><p id="75cc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">用零初始化 ground_truth 向量:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="1420" class="my ll iq nu b gy ny nz l oa ob">ground_truth = np.zeros(class_count, dtype=np.float32)</span></pre><p id="7794" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">用 1.0 表示 ground_truth 向量中的正确标签:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="f9d9" class="my ll iq nu b gy ny nz l oa ob">idx = 0<br/><strong class="nu ir">for </strong>label <strong class="nu ir">in </strong>labels:<br/>   <strong class="nu ir">if </strong>label <strong class="nu ir">in </strong>true_labels:<br/>      ground_truth[idx] = 1.0<br/>   idx += 1</span></pre><p id="a6e5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">标签</strong>列表是添加到<strong class="kf ir">get _ random _ cached _ bottoms()</strong>方法的参数，包含所有可能的类的名称。</p><p id="67e9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就是这样！我们可以通过缓存创建的<em class="nl">地面真相</em>来改进这个解决方案。这防止了每次我们为相同的图像请求时创建<em class="nl">地面真实</em>向量，如果我们为多个时期训练，这是必然发生的。这就是全局字典 CACHED_GROUND_TRUTH_VECTORS 的用途。</p><h1 id="6b38" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">修改培训</h1><p id="f3f8" class="pw-post-body-paragraph kd ke iq kf b kg mk ki kj kk ml km kn ko nm kq kr ks nn ku kv kw no ky kz la ij bi translated"><strong class="kf ir"> add_final_training_ops() </strong>方法最初添加了一个新的 softmax 和全连接层用于训练。我们只需要用一个不同的函数替换 softmax 函数。</p><p id="5056" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为什么？</p><p id="3199" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">softmax 函数将向量的所有值压缩到[0，1]范围内，总和为 1。这正是我们在单一标签分类中想要的。但是对于我们的多标签情况，我们希望我们得到的类别概率能够表示汽车的图像属于类别<strong class="kf ir">汽车</strong>的概率为 90%,属于类别<strong class="kf ir">事故</strong>的概率为 30%,等等。</p><p id="c358" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将通过使用例如<a class="ae kc" href="https://en.wikipedia.org/wiki/Sigmoid_function" rel="noopener ugc nofollow" target="_blank"> sigmoid </a>函数来实现这一点。</p><p id="e430" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">具体来说，我们将替换:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="96a5" class="my ll iq nu b gy ny nz l oa ob">final_tensor = tf.nn.softmax(logits, name=final_tensor_name)</span></pre><p id="82ad" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="8ae2" class="my ll iq nu b gy ny nz l oa ob">final_tensor = tf.nn.sigmoid(logits, name=final_tensor_name)</span></pre><p id="5694" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还必须更新交叉熵的计算方法，以正确训练我们的网络:</p><p id="23a9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">同样，只需将 softmax 替换为 sigmoid:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="c194" class="my ll iq nu b gy ny nz l oa ob">cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits,ground_truth_input)</span></pre><h1 id="dbba" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">修改评估</h1><p id="e4b0" class="pw-post-body-paragraph kd ke iq kf b kg mk ki kj kk ml km kn ko nm kq kr ks nn ku kv kw no ky kz la ij bi translated">方法<strong class="kf ir"> add_evaluation_step() </strong>插入我们需要评估预测标签准确性的操作。最初看起来是这样的:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="8291" class="my ll iq nu b gy ny nz l oa ob">correct_prediction = tf.equal(tf.argmax(result_tensor, 1), tf.argmax(ground_truth_tensor, 1))</span></pre><p id="8c4f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好吧，这是怎么回事？</p><p id="bb3e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> result_tensor </strong>和<strong class="kf ir"> ground_truth_tensor </strong>都可以想象成 2D 数组:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="33f3" class="my ll iq nu b gy ny nz l oa ob">|        | label1  | label2 | label3  |<br/>| image1 |    0    |    1   |    0    |<br/>| image2 |    1    |    0   |    0    |</span></pre><p id="c49a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此这一行:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="f9ea" class="my ll iq nu b gy ny nz l oa ob">tf.argmax(result_tensor, 1)</span></pre><p id="e810" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">返回每个<strong class="kf ir">行</strong>中最大值的索引。每一行因为(axis = <strong class="kf ir"> 1 </strong>参数。</p><p id="6548" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将获得具有最高值的索引并比较它们，同时知道因为只有一个标签是正确的，所以<strong class="kf ir">地面 _ 真相 _ 张量</strong>在每行中只包含一个<strong class="kf ir"> 1 </strong>。</p><p id="7c8e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了使这种方法适应我们的多标签情况，我们简单地用<em class="nl"> round() </em>替换<em class="nl"> argmax() </em>，这将概率变成 0 和 1。然后，我们将<strong class="kf ir">结果张量</strong>与已经只包含 0 和 1 的<strong class="kf ir">基础张量</strong>进行比较:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="efdf" class="my ll iq nu b gy ny nz l oa ob">correct_prediction = tf.equal(tf.round(result_tensor), ground_truth_tensor)</span></pre><p id="eb61" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是我们为正确分类带有多个标签的图像所需要做的所有更改。</p><h1 id="1ace" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">运行再培训</h1><p id="6380" class="pw-post-body-paragraph kd ke iq kf b kg mk ki kj kk ml km kn ko nm kq kr ks nn ku kv kw no ky kz la ij bi translated">只需从项目根目录运行以下命令:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="5851" class="my ll iq nu b gy ny nz l oa ob">python retrain.py \<br/>--bottleneck_dir=bottlenecks \<br/>--how_many_training_steps 500 \<br/>--model_dir=model_dir \<br/>--output_graph=retrained_graph.pb \<br/>--output_labels=retrained_labels.txt \<br/>--summaries_dir=retrain_logs \<br/>--image_dir=images</span></pre><p id="7994" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我建议调整训练步骤的数量，以防止过度适应你的模型。</p><h1 id="66b0" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">测试重新训练的模型</h1><figure class="np nq nr ns gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oc"><img src="../Images/fa72f7c4c8fac17fb340163015b7a1c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IiRd7SGT9oYpuZVBmDZk5w.jpeg"/></div></div></figure><p id="6f80" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">运行:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="4bb1" class="my ll iq nu b gy ny nz l oa ob">python label_image.py &lt;image_name&gt;</span></pre><p id="ac99" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我稍微修改了一下<strong class="kf ir"> label_image.py </strong>，将得到的类百分比写入<strong class="kf ir"> results.txt </strong>。</p><h1 id="7e05" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">可视化培训</h1><figure class="np nq nr ns gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi od"><img src="../Images/22966c158996966ab99298b0699afdac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RLfT672o3aTbsMReQffupQ.jpeg"/></div></div></figure><p id="0093" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">重新训练完成后，您可以通过运行以下命令来查看日志:</p><pre class="np nq nr ns gt nt nu nv nw aw nx bi"><span id="0133" class="my ll iq nu b gy ny nz l oa ob">tensorboard --logdir retrain_logs</span></pre><p id="91ba" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">并在浏览器中导航至<a class="ae kc" href="http://127.0.0.1:6006/" rel="noopener ugc nofollow" target="_blank"> http://127.0.0.1:6006/ </a>。</p><h1 id="0bca" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">结束了</h1><p id="3baf" class="pw-post-body-paragraph kd ke iq kf b kg mk ki kj kk ml km kn ko nm kq kr ks nn ku kv kw no ky kz la ij bi translated">我希望我尽可能清楚地解释了所有的变化及其背后的原因，希望你今天学到了一些新东西:)</p><p id="6a86" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你有进一步的问题，你可以在<a class="ae kc" href="https://www.linkedin.com/in/radek-bartyzal-7408b4121/" rel="noopener ugc nofollow" target="_blank"> linkedin </a>上找到我或者<a class="ae kc" href="mailto:rbartyzal1@gmail.com" rel="noopener ugc nofollow" target="_blank">直接发邮件给我</a>。</p></div></div>    
</body>
</html>