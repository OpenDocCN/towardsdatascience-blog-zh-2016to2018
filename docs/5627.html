<html>
<head>
<title>Visualizing YouTube videos using Seaborn and WordCloud in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Python 中的 Seaborn 和 WordCloud 可视化 YouTube 视频</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/visualizing-youtube-videos-using-seaborn-and-wordcloud-in-python-b24247f70228?source=collection_archive---------11-----------------------#2018-10-30">https://towardsdatascience.com/visualizing-youtube-videos-using-seaborn-and-wordcloud-in-python-b24247f70228?source=collection_archive---------11-----------------------#2018-10-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/d8964d019c601a4d28918ca65525f785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mb9gRK6Y70TF2hbT00bHXw.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Courtesy: Pexels.com</figcaption></figure><p id="e7b8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我是一个狂热的 Youtube 用户，喜欢在空闲时间用它看视频。我决定对在美国播放的 youtube 视频做一些探索性的数据分析。我在这个链接上找到了 Kaggle 上的数据集</p><div class="la lb gp gr lc ld"><a href="https://www.kaggle.com/datasnaek/youtube-new" rel="noopener  ugc nofollow" target="_blank"><div class="le ab fo"><div class="lf ab lg cl cj lh"><h2 class="bd ir gy z fp li fr fs lj fu fw ip bi translated">趋势 YouTube 视频统计</h2><div class="lk l"><h3 class="bd b gy z fp li fr fs lj fu fw dk translated">热门 YouTube 视频的每日统计数据</h3></div><div class="ll l"><p class="bd b dl z fp li fr fs lj fu fw dk translated">www.kaggle.com</p></div></div><div class="lm l"><div class="ln l lo lp lq lm lr jw ld"/></div></div></a></div><p id="0042" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我下载了所有可用的地理数据集的 csv 文件“USvidoes.csv”和 json 文件“US_category_id.json”。我用 Jupyter 笔记本进行了分析。</p><h1 id="542b" class="ls lt iq bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">我们开始吧！</h1><p id="bdf4" class="pw-post-body-paragraph kc kd iq ke b kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv mu kx ky kz ij bi translated">加载必要的库</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="44c4" class="ne lt iq na b gy nf ng l nh ni"><strong class="na ir">import</strong> <strong class="na ir">pandas</strong> <strong class="na ir">as</strong> <strong class="na ir">pd</strong><br/><strong class="na ir">import</strong> <strong class="na ir">numpy</strong> <strong class="na ir">as</strong> <strong class="na ir">np</strong><br/><strong class="na ir">import</strong> <strong class="na ir">seaborn</strong> <strong class="na ir">as</strong> <strong class="na ir">sns</strong><br/><strong class="na ir">import</strong> <strong class="na ir">matplotlib.pyplot</strong> <strong class="na ir">as</strong> <strong class="na ir">plt</strong><br/><strong class="na ir">import</strong> <strong class="na ir">os</strong><br/><strong class="na ir">from</strong> <strong class="na ir">subprocess</strong> <strong class="na ir">import</strong> check_output<br/><strong class="na ir">from</strong> <strong class="na ir">wordcloud</strong> <strong class="na ir">import</strong> WordCloud, STOPWORDS<br/><strong class="na ir">import</strong> <strong class="na ir">string</strong><br/><strong class="na ir">import</strong> <strong class="na ir">re</strong> <br/><strong class="na ir">import</strong> <strong class="na ir">nltk</strong><br/><strong class="na ir">from</strong> <strong class="na ir">nltk.corpus</strong> <strong class="na ir">import</strong> stopwords<br/><strong class="na ir">from</strong> <strong class="na ir">nltk</strong> <strong class="na ir">import</strong> pos_tag<br/><strong class="na ir">from</strong> <strong class="na ir">nltk.stem.wordnet</strong> <strong class="na ir">import</strong> WordNetLemmatizer <br/><strong class="na ir">from</strong> <strong class="na ir">nltk.tokenize</strong> <strong class="na ir">import</strong> word_tokenize<br/><strong class="na ir">from</strong> <strong class="na ir">nltk.tokenize</strong> <strong class="na ir">import</strong> TweetTokenizer</span></pre><p id="68b4" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我创建了一个名为“df_you”的数据帧，它将在整个分析过程中使用。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="a04a" class="ne lt iq na b gy nf ng l nh ni">df_you = pd.read_csv(r"...\Projects\US Youtube - Python\USvideos.csv")</span></pre><p id="b065" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">最重要的一步是了解数据的长度、宽度和带宽。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="4812" class="ne lt iq na b gy nf ng l nh ni">print(df_you.shape)<br/>print(df_you.nunique())</span></pre><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/88772da51a4588bedb73ec02bd4b9ebc.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*Y_vzMYGoalrd9H11rLCdGw.png"/></div></figure><p id="c605" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">数据集中似乎有大约 40949 个观察值和 16 个变量。如果有必要，下一步将是清除数据。我检查了是否有需要删除或操作的空值。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="eed6" class="ne lt iq na b gy nf ng l nh ni">df_you.info()</span></pre><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/8b2b007e9a1a3b1c6e34ba1c1b0c2159.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*ZP3Rs_OykkeVNDmTAS7ygQ.png"/></div></figure><p id="012a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们看到总共有 16 列没有空值。对我们有好处:)现在让我们通过查看最上面的几行来了解一下数据。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="3c15" class="ne lt iq na b gy nf ng l nh ni">df_you.head(n=5)</span></pre><p id="54d8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在是可视化令人兴奋的部分！为了可视化变量中的数据，如“喜欢”、“不喜欢”、“视图”和“评论数”，我首先使用对数分布对数据进行归一化。数据的标准化对于确保这些变量被适当地缩放而不让一个主导变量扭曲最终结果是必不可少的。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="9a95" class="ne lt iq na b gy nf ng l nh ni">df_you['likes_log'] = np.log(df_you['likes']+1)<br/>df_you['views_log'] = np.log(df_you['views'] +1)<br/>df_you['dislikes_log'] = np.log(df_you['dislikes'] +1)<br/>df_you['comment_count_log'] = np.log(df_you['comment_count']+1)</span></pre><p id="1d61" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">让我们现在绘制这些！</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="efa5" class="ne lt iq na b gy nf ng l nh ni">plt.figure(figsize = (12,6))<br/>plt.subplot(221)<br/>g1 = sns.distplot(df_you['likes_log'], color = 'green')<br/>g1.set_title("LIKES LOG DISTRIBUTION", fontsize = 16)<br/><br/>plt.subplot(222)<br/>g2 = sns.distplot(df_you['views_log'])<br/>g2.set_title("VIEWS LOG DISTRIBUTION", fontsize = 16)<br/><br/>plt.subplot(223)<br/>g3 = sns.distplot(df_you['dislikes_log'], color = 'r')<br/>g3.set_title("DISLIKES LOG DISTRIBUTION", fontsize=16)<br/><br/>plt.subplot(224)<br/>g4 = sns.distplot(df_you['comment_count_log'])<br/>g4.set_title("COMMENT COUNT LOG DISTRIBUTION", fontsize=16)<br/><br/>plt.subplots_adjust(wspace = 0.2, hspace = 0.4, top = 0.9)<br/><br/>plt.show()</span></pre><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nl"><img src="../Images/d90d5222e1df539201dad9a2a4489222.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CwhQVyiA7RIrFOF2oeakcw.png"/></div></div></figure><p id="be5a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在让我们找出数据集中存在的唯一类别 id，以便在数据帧中分配适当的类别名称。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="d622" class="ne lt iq na b gy nf ng l nh ni">np.unique(df_you["category_id"])</span></pre><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nm"><img src="../Images/7d74eda53f9a6385a2d7292ac9ce853a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dbw8CBUj1Lap1l9iFC-Fqw.png"/></div></div></figure><p id="c3f8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们看到有 16 个独特的类别。让我们使用之前下载的 json 文件‘US _ category _ id . JSON’中的信息为这些类别命名。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="40ca" class="ne lt iq na b gy nf ng l nh ni">df_you['category_name'] = np.nan<br/><br/>df_you.loc[(df_you["category_id"]== 1),"category_name"] = 'Film and Animation'<br/>df_you.loc[(df_you["category_id"] == 2), "category_name"] = 'Cars and Vehicles'<br/>df_you.loc[(df_you["category_id"] == 10), "category_name"] = 'Music'<br/>df_you.loc[(df_you["category_id"] == 15), "category_name"] = 'Pet and Animals'<br/>df_you.loc[(df_you["category_id"] == 17), "category_name"] = 'Sports'<br/>df_you.loc[(df_you["category_id"] == 19), "category_name"] = 'Travel and Events'<br/>df_you.loc[(df_you["category_id"] == 20), "category_name"] = 'Gaming'<br/>df_you.loc[(df_you["category_id"] == 22), "category_name"] = 'People and Blogs'<br/>df_you.loc[(df_you["category_id"] == 23), "category_name"] = 'Comedy'<br/>df_you.loc[(df_you["category_id"] == 24), "category_name"] = 'Entertainment'<br/>df_you.loc[(df_you["category_id"] == 25), "category_name"] = 'News and Politics'<br/>df_you.loc[(df_you["category_id"] == 26), "category_name"] = 'How to and Style'<br/>df_you.loc[(df_you["category_id"] == 27), "category_name"] = 'Education'<br/>df_you.loc[(df_you["category_id"] == 28), "category_name"] = 'Science and Technology'<br/>df_you.loc[(df_you["category_id"] == 29), "category_name"] = 'Non-profits and Activism'<br/>df_you.loc[(df_you["category_id"] == 43), "category_name"] = 'Shows'</span></pre><p id="40ea" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在让我们画出这些来识别流行的视频类别！</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="b07f" class="ne lt iq na b gy nf ng l nh ni">plt.figure(figsize = (14,10))<br/>g = sns.countplot('category_name', data = df_you, palette="Set1", order = df_you['category_name'].value_counts().index)<br/>g.set_xticklabels(g.get_xticklabels(),rotation=45, ha="right")<br/>g.set_title("Count of the Video Categories", fontsize=15)<br/>g.set_xlabel("", fontsize=12)<br/>g.set_ylabel("Count", fontsize=12)<br/>plt.subplots_adjust(wspace = 0.9, hspace = 0.9, top = 0.9)<br/>plt.show()</span></pre><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nn"><img src="../Images/2694f50f44e652cd21507ae218f08a84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OwA3Wy2pA3ExsPqzoopJXQ.png"/></div></div></figure><p id="b847" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们看到前 5 个被浏览的类别是“娱乐”、“音乐”、“如何和风格”、“喜剧”和“人物和博客”。因此，如果你正在考虑开办自己的 youtube 频道，你最好先考虑这些类别！</p><p id="7e23" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在让我们用箱线图来看看不同类别的观点、喜欢、不喜欢和评论的情况。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="fb5d" class="ne lt iq na b gy nf ng l nh ni">plt.figure(figsize = (14,10))<br/>g = sns.boxplot(x = 'category_name', y = 'views_log', data = df_you, palette="winter_r")<br/>g.set_xticklabels(g.get_xticklabels(),rotation=45, ha="right")<br/>g.set_title("Views across different categories", fontsize=15)<br/>g.set_xlabel("", fontsize=12)<br/>g.set_ylabel("Views(log)", fontsize=12)<br/>plt.subplots_adjust(wspace = 0.9, hspace = 0.9, top = 0.9)<br/>plt.show()</span></pre><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi no"><img src="../Images/963587ee3cc8813ddf628a4a4d6bc53a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5alM2iRd5JYwDpme1UgKaw.png"/></div></div></figure><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="94f0" class="ne lt iq na b gy nf ng l nh ni">plt.figure(figsize = (14,10))<br/>g = sns.boxplot(x = 'category_name', y = 'likes_log', data = df_you, palette="spring_r")<br/>g.set_xticklabels(g.get_xticklabels(),rotation=45, ha="right")<br/>g.set_title("Likes across different categories", fontsize=15)<br/>g.set_xlabel("", fontsize=12)<br/>g.set_ylabel("Likes(log)", fontsize=12)<br/>plt.subplots_adjust(wspace = 0.9, hspace = 0.9, top = 0.9)<br/>plt.show()</span></pre><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi np"><img src="../Images/01ec3d88aa384e5a8f0742b564b882df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jMjg_6kYEvYSgtIQxNWJ4A.png"/></div></div></figure><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="6529" class="ne lt iq na b gy nf ng l nh ni">plt.figure(figsize = (14,10))<br/>g = sns.boxplot(x = 'category_name', y = 'dislikes_log', data = df_you, palette="summer_r")<br/>g.set_xticklabels(g.get_xticklabels(),rotation=45, ha="right")<br/>g.set_title("Dislikes across different categories", fontsize=15)<br/>g.set_xlabel("", fontsize=12)<br/>g.set_ylabel("Dislikes(log)", fontsize=12)<br/>plt.subplots_adjust(wspace = 0.9, hspace = 0.9, top = 0.9)<br/>plt.show()</span></pre><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nq"><img src="../Images/1acd519885837d9bde9db96568d35e8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*No2Jia07yK2KlBGqhhORqw.png"/></div></div></figure><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="a02c" class="ne lt iq na b gy nf ng l nh ni">plt.figure(figsize = (14,10))<br/>g = sns.boxplot(x = 'category_name', y = 'comment_count_log', data = df_you, palette="plasma")<br/>g.set_xticklabels(g.get_xticklabels(),rotation=45, ha="right")<br/>g.set_title("Comments count across different categories", fontsize=15)<br/>g.set_xlabel("", fontsize=12)<br/>g.set_ylabel("Comment_count(log)", fontsize=12)<br/>plt.subplots_adjust(wspace = 0.9, hspace = 0.9, top = 0.9)<br/>plt.show()</span></pre><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nr"><img src="../Images/1d548e6a535fb82c7ff047eb6d7abd35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CTB4yuGttqo3QQTUINku7Q.png"/></div></div></figure><p id="c7ff" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">接下来，我计算了参与度指标，如喜欢率、不喜欢率和评论率。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="d27e" class="ne lt iq na b gy nf ng l nh ni">df_you['like_rate'] = df_you['likes']/df_you['views']<br/>df_you['dislike_rate'] = df_you['dislikes']/df_you['views']<br/>df_you['comment_rate'] = df_you['comment_count']/df_you['views']</span></pre><p id="9dec" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">使用参与度热图构建关联矩阵。</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="b060" class="ne lt iq na b gy nf ng l nh ni">plt.figure(figsize = (10,8))<br/>sns.heatmap(df_you[['like_rate', 'dislike_rate', 'comment_rate']].corr(), annot=<strong class="na ir">True</strong>)<br/>plt.show()</span></pre><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/8bb7045f9660d1d98ddb9925d2d51fc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*_2vWQd4zOmlqM-5S3PFuyA.png"/></div></figure><p id="836f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">从上面的热图可以看出，如果观众喜欢某个视频，他/她有 43%的机会对其进行评论，而如果观众不喜欢该视频，则有 28%的机会进行评论。这是一个很好的见解，这意味着如果观众喜欢任何视频，他们更有可能对它们进行评论，以显示他们的欣赏/反馈。</p><p id="b91a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">接下来，我试着分析“标题”和“标签”栏中的<strong class="ke ir">字数</strong>、<strong class="ke ir">唯一字数、标点数和单词的平均长度</strong></p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="1d60" class="ne lt iq na b gy nf ng l nh ni"><em class="nt">#Word count </em><br/>df_you['count_word']=df_you['title'].apply(<strong class="na ir">lambda</strong> x: len(str(x).split()))<br/>df_you['count_word_tags']=df_you['tags'].apply(<strong class="na ir">lambda</strong> x: len(str(x).split()))<br/><br/><em class="nt">#Unique word count</em><br/>df_you['count_unique_word'] = df_you['title'].apply(<strong class="na ir">lambda</strong> x: len(set(str(x).split())))<br/>df_you['count_unique_word_tags'] = df_you['tags'].apply(<strong class="na ir">lambda</strong> x: len(set(str(x).split())))<br/><br/><em class="nt">#Punctutation count</em><br/>df_you['count_punctuation'] = df_you['title'].apply(<strong class="na ir">lambda</strong> x: len([c <strong class="na ir">for</strong> c <strong class="na ir">in</strong> str(x) <strong class="na ir">if</strong> c <strong class="na ir">in</strong> string.punctuation]))<br/>df_you['count_punctuation_tags'] = df_you['tags'].apply(<strong class="na ir">lambda</strong> x: len([c <strong class="na ir">for</strong> c <strong class="na ir">in</strong> str(x) <strong class="na ir">if</strong> c <strong class="na ir">in</strong> string.punctuation]))<br/><br/><em class="nt">#Average length of the words</em><br/>df_you['mean_word_len'] = df_you['title'].apply(<strong class="na ir">lambda</strong> x : np.mean([len(x) <strong class="na ir">for</strong> x <strong class="na ir">in</strong> str(x).split()]))<br/>df_you['mean_word_len_tags'] = df_you['tags'].apply(<strong class="na ir">lambda</strong> x: np.mean([len(x) <strong class="na ir">for</strong> x <strong class="na ir">in</strong> str(x).split()]))</span></pre><p id="1445" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">绘制这些…</p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="0496" class="ne lt iq na b gy nf ng l nh ni">plt.figure(figsize = (12,18))<br/><br/>plt.subplot(421)<br/>g1 = sns.distplot(df_you['count_word'],<br/>                 hist = <strong class="na ir">False</strong>, label = 'Text')<br/>g1 = sns.distplot(df_you['count_word_tags'],<br/>                 hist = <strong class="na ir">False</strong>, label = 'Tags')<br/>g1.set_title('Word count distribution', fontsize = 14)<br/>g1.set(xlabel='Word Count')<br/><br/>plt.subplot(422)<br/>g2 = sns.distplot(df_you['count_unique_word'],<br/>                 hist = <strong class="na ir">False</strong>, label = 'Text')<br/>g2 = sns.distplot(df_you['count_unique_word_tags'],<br/>                 hist = <strong class="na ir">False</strong>, label = 'Tags')<br/>g2.set_title('Unique word count distribution', fontsize = 14)<br/>g2.set(xlabel='Unique Word Count')<br/><br/>plt.subplot(423)<br/>g3 = sns.distplot(df_you['count_punctuation'],<br/>                 hist = <strong class="na ir">False</strong>, label = 'Text')<br/>g3 = sns.distplot(df_you['count_punctuation_tags'],<br/>                 hist = <strong class="na ir">False</strong>, label = 'Tags')<br/>g3.set_title('Punctuation count distribution', fontsize =14)<br/>g3.set(xlabel='Punctuation Count')<br/><br/>plt.subplot(424)<br/>g4 = sns.distplot(df_you['mean_word_len'],<br/>                 hist = <strong class="na ir">False</strong>, label = 'Text')<br/>g4 = sns.distplot(df_you['mean_word_len_tags'],<br/>                 hist = <strong class="na ir">False</strong>, label = 'Tags')<br/>g4.set_title('Average word length distribution', fontsize = 14)<br/>g4.set(xlabel = 'Average Word Length')<br/><br/>plt.subplots_adjust(wspace = 0.2, hspace = 0.4, top = 0.9)<br/>plt.legend()<br/>plt.show()</span></pre><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nu"><img src="../Images/63778cc54bd9dc5dfb3b94bfcae128e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bfYCMYkerMUtdV9Z5ZCoug.png"/></div></div></figure><p id="efc2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在，让我们将视频标题、视频描述和视频标签的单词 cloud 可视化。这样我们就能发现标题、描述和标签中哪些词比较流行。创建一个词云是在博客世界中寻找热门词的一种流行方式。</p><ol class=""><li id="07d5" class="nv nw iq ke b kf kg kj kk kn nx kr ny kv nz kz oa ob oc od bi translated"><strong class="ke ir">视频标题的文字云</strong></li></ol><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="898d" class="ne lt iq na b gy nf ng l nh ni">plt.figure(figsize = (20,20))<br/>stopwords = set(STOPWORDS)<br/>wordcloud = WordCloud(<br/>                      background_color = 'black',<br/>                      stopwords=stopwords,<br/>                      max_words = 1000,<br/>                      max_font_size = 120,<br/>                      random_state = 42<br/>                    ).generate(str(df_you['title']))<br/><br/><em class="nt">#Plotting the word cloud</em><br/>plt.imshow(wordcloud)<br/>plt.title("WORD CLOUD for Titles", fontsize = 20)<br/>plt.axis('off')<br/>plt.show()</span></pre><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oe"><img src="../Images/cd11eec11ea6e4d89234aed33233b1d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mmtJ2prPSsP8nSwjGHwH9w.png"/></div></div></figure><p id="d7fd" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">从上面的词云可以明显看出，最常用的标题词是“官方”、“视频”、“谈话”、“SNL”、“VS”和“星期”等等。</p><p id="b486" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> 2。标题描述的文字云</strong></p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="ee4c" class="ne lt iq na b gy nf ng l nh ni">plt.figure(figsize = (20,20))<br/><br/>stopwords = set(STOPWORDS)<br/><br/>wordcloud = WordCloud(<br/>                      background_color = 'black',<br/>                      stopwords = stopwords,<br/>                      max_words = 1000,<br/>                      max_font_size = 120,<br/>                      random_state = 42<br/>                    ).generate(str(df_you['description']))<br/><br/>plt.imshow(wordcloud)<br/>plt.title('WORD CLOUD for Title Description', fontsize = 20)<br/>plt.axis('off')<br/>plt.show()</span></pre><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/d86d9e1b2d93f61b6a6d88ea6116323c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s-y5xCOjo-1UND5NYMD2gw.png"/></div></div></figure><p id="8cc0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我发现描述视频最流行的词是“https”、“video”、“new”、“watch”等等。</p><p id="7109" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> 3。标签的文字云</strong></p><pre class="mv mw mx my gt mz na nb nc aw nd bi"><span id="5e1e" class="ne lt iq na b gy nf ng l nh ni">plt.figure(figsize = (20,20))<br/><br/>stopwords = set(STOPWORDS)<br/><br/>wordcloud = WordCloud(<br/>                      background_color = 'black',<br/>                      stopwords = stopwords,<br/>                      max_words = 1000,<br/>                      max_font_size = 120,<br/>                      random_state = 42<br/>                    ).generate(str(df_you['tags']))<br/><br/>plt.imshow(wordcloud)<br/>plt.title('WORD CLOUD for Tags', fontsize = 20)<br/>plt.axis('off')<br/>plt.show()</span></pre><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi og"><img src="../Images/d0176b313aae6a1cd89c8eef66065e53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rUhU3uiPYEXw06lXT757-Q.png"/></div></div></figure><p id="be33" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">热门标签似乎是' SNL '，' TED '，' new '，' Season '，' week '，' Cream '，' youtube '从词云分析来看，看起来 youtube 上有很多周六夜现场的粉丝！</p><p id="8cca" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我第一次使用 word cloud library，它产生了漂亮而有用的视觉效果！如果你有兴趣了解更多关于这个库以及如何使用它，那么你一定要看看这个</p><div class="la lb gp gr lc ld"><a href="https://www.datacamp.com/community/tutorials/wordcloud-python" rel="noopener  ugc nofollow" target="_blank"><div class="le ab fo"><div class="lf ab lg cl cj lh"><h2 class="bd ir gy z fp li fr fs lj fu fw ip bi translated">用 Python 生成单词云</h2><div class="lk l"><h3 class="bd b gy z fp li fr fs lj fu fw dk translated">很多时候，你可能会看到一朵云，里面充满了不同大小的单词，它们代表频率或…</h3></div><div class="ll l"><p class="bd b dl z fp li fr fs lj fu fw dk translated">www.datacamp.com</p></div></div><div class="lm l"><div class="oh l lo lp lq lm lr jw ld"/></div></div></a></div><p id="3fe9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这个分析在我的 Github 页面上。</p><div class="la lb gp gr lc ld"><a href="https://github.com/tanmayeewaghmare/Exploratory-Data-Analysis/blob/master/Youtube%20videos%20analysis_%20US%20Market.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="le ab fo"><div class="lf ab lg cl cj lh"><h2 class="bd ir gy z fp li fr fs lj fu fw ip bi translated">探索性数据分析</h2><div class="lk l"><h3 class="bd b gy z fp li fr fs lj fu fw dk translated">通过在 GitHub 上创建帐户，为 tanmayeewaghmare/探索性数据分析开发做出贡献。</h3></div><div class="ll l"><p class="bd b dl z fp li fr fs lj fu fw dk translated">github.com</p></div></div><div class="lm l"><div class="oi l lo lp lq lm lr jw ld"/></div></div></a></div><p id="aac9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">感谢阅读！</p></div></div>    
</body>
</html>