<html>
<head>
<title>Image Captioning with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Keras 的图像字幕</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8?source=collection_archive---------0-----------------------#2018-11-04">https://towardsdatascience.com/image-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8?source=collection_archive---------0-----------------------#2018-11-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="19e1" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">教计算机描述图片</h2></div><h1 id="2007" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">目录:</h1><ol class=""><li id="90ba" class="kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo bi translated">介绍</li><li id="6839" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">动机</li><li id="7599" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">先决条件</li><li id="27b7" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">数据收集</li><li id="e0df" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">理解数据</li><li id="9e39" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">数据清理</li><li id="ac62" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">加载训练集</li><li id="a21b" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">数据预处理—图像</li><li id="eaf7" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">数据预处理—标题</li><li id="602b" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">使用生成器功能准备数据</li><li id="0b27" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">单词嵌入</li><li id="487b" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">模型架构</li><li id="d8c4" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">推理</li><li id="0d73" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">估价</li><li id="1a3b" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">结论和未来工作</li><li id="3238" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated">参考</li></ol><h1 id="4400" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated"><strong class="ak"> 1。简介</strong></h1><p id="2132" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">在下图中你看到了什么？</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mh"><img src="../Images/46bc2d74f8e289bfcf3950c4c3b6a75f.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*AtxxyM5bg2WEGh0rySAMXQ.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Can you write a caption?</figcaption></figure><p id="925f" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">有些人可能会说“<strong class="kz ir">草地上的白狗</strong>”，有些人可能会说“<strong class="kz ir">带褐色斑点的白狗</strong>”，还有一些人可能会说“<strong class="kz ir">草地上的狗和一些粉红色的花</strong>”。</p><p id="d0d9" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">毫无疑问，所有这些说明都与这张图片相关，可能还有其他一些说明。但是我想说的是。对我们人类来说，只是看一眼图片，然后用合适的语言描述它是如此容易。即使是一个 5 岁的孩子也能轻而易举地做到。</p><p id="71e6" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">但是，你能编写一个将图像作为输入并产生相关标题作为输出的计算机程序吗？</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nc"><img src="../Images/f589b9cd4d5da4fc8b07c1b58f1378e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Su2F41rq7sZ3CVNwjRChrg.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">The Problem</figcaption></figure><p id="aca3" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">就在深度神经网络最近发展之前，这个问题甚至是计算机视觉领域最先进的研究人员都无法想象的。但是随着深度学习的出现，如果我们有了所需的数据集，这个问题就可以很容易地解决。</p><p id="87ab" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">Andrej Karapathy  在斯坦福大学[1]的博士论文中很好地研究了这个问题，他现在也是特斯拉的 AI 总监。</p><p id="d0a4" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">这篇博客文章的目的是解释(用尽可能简单的话)如何使用深度学习来解决为给定图像生成字幕的问题，因此得名<strong class="kz ir">图像字幕。</strong></p><p id="1255" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">为了更好地了解这个问题，我强烈建议使用这个由微软创建的最先进的系统，名为<a class="ae nd" href="https://www.captionbot.ai/" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir">字幕机器人</strong> </a>。只需转到此链接，尝试上传您想要的任何图片；这个系统会为它生成一个标题。</p><h1 id="e4f9" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">2.动机</h1><p id="2566" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">我们必须首先理解这个问题对现实世界的场景有多重要。让我们看看这个问题的解决方案非常有用的几个应用。</p><ul class=""><li id="f7cf" class="kx ky iq kz b la mx lc my le ne lg nf li ng lk nh lm ln lo bi translated">自动驾驶汽车——自动驾驶是最大的挑战之一，如果我们能够适当地描述汽车周围的场景，它可以促进自动驾驶系统的发展。</li><li id="3f93" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk nh lm ln lo bi translated">帮助盲人——我们可以为盲人创造一种产品，引导他们在没有他人帮助的情况下上路。我们可以先将场景转换成文本，然后将文本转换成声音。两者现在都是深度学习的著名应用。参考这个<a class="ae nd" href="https://www.youtube.com/watch?v=rLyF4XQLwr0" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir">链接</strong> </a>，它展示了 Nvidia research 如何试图创造这样一个产品。</li><li id="a37b" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk nh lm ln lo bi translated">今天，闭路电视摄像头无处不在，但随着观看世界，如果我们也可以生成相关的字幕，那么我们就可以在某个地方发生恶意活动时发出警报。这可能有助于减少一些犯罪和/或事故。</li><li id="c7b9" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk nh lm ln lo bi translated">自动字幕可以帮助，使谷歌图片搜索像谷歌搜索一样好，因为然后每个图像可以首先转换成标题，然后可以根据标题进行搜索。</li></ul><h1 id="8c46" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated"><strong class="ak"> 3。</strong>先决条件</h1><p id="d6c1" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">这篇文章假设读者熟悉基本的深度学习概念，如多层感知器、卷积神经网络、递归神经网络、迁移学习、梯度下降、反向传播、过拟合、概率、文本处理、Python 语法和数据结构、Keras 库等。</p><h1 id="b5f3" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">4.数据收集</h1><p id="1302" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">这个问题有很多开源数据集可用，像 Flickr 8k(包含 8k 张图片)、Flickr 30k(包含 30k 张图片)、MS COCO(包含 180k 张图片)等。</p><p id="49aa" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">但是出于这个案例研究的目的，我使用了 Flickr 8k 数据集，您可以通过填写伊利诺伊大学香槟分校提供的这个<a class="ae nd" href="https://forms.illinois.edu/sec/1713398" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir">表格</strong> </a> <strong class="kz ir"> </strong>来下载该数据集。此外，用大量图像训练模型在不是非常高端的 PC/膝上型电脑的系统上可能是不可行的。</p><p id="6d28" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">这个数据集包含 8000 个图像，每个图像有 5 个标题(正如我们在简介部分已经看到的，一个图像可以有多个标题，所有标题同时相关)。</p><p id="e8ac" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">这些图像分为以下两部分:</p><ul class=""><li id="fda9" class="kx ky iq kz b la mx lc my le ne lg nf li ng lk nh lm ln lo bi translated">训练集— 6000 幅图像</li><li id="df22" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk nh lm ln lo bi translated">开发集— 1000 个图像</li><li id="129a" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk nh lm ln lo bi translated">测试集— 1000 幅图像</li></ul><h1 id="7a19" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">5.理解数据</h1><p id="d068" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">如果您已经从我提供的链接下载了数据，那么，除了图像之外，您还将获得一些与图像相关的文本文件。其中一个文件是“Flickr8k.token.txt ”,它包含每张图片的名称及其 5 个标题。我们可以这样阅读这个文件:</p><pre class="mi mj mk ml gt ni nj nk nl aw nm bi"><span id="110c" class="nn kg iq nj b gy no np l nq nr"># Below is the path for the file "Flickr8k.token.txt" on your disk<br/>filename = "/dataset/TextFiles/Flickr8k.token.txt"<br/>file = open(filename, 'r')<br/>doc = file.read()</span></pre><p id="d0b6" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">该文本文件如下所示:</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="ns nt l"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Sample Text File</figcaption></figure><p id="5d52" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">因此每行包含<image name=""> #i <caption>，其中 0≤i≤4</caption></image></p><p id="0eee" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">即图像的名称、标题号(0 到 4)和实际标题。</p><p id="5ea6" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">现在，我们创建一个名为“descriptions”的字典，它包含图像的名称(没有。jpg 扩展名)作为键，对应图像的 5 个标题的列表作为值。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="ns nt l"/></div></figure><p id="c0a0" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">例如，参考上面的屏幕截图，字典将如下所示:</p><pre class="mi mj mk ml gt ni nj nk nl aw nm bi"><span id="172e" class="nn kg iq nj b gy no np l nq nr">descriptions['101654506_8eb26cfb60'] = ['A brown and white dog is running through the snow .', 'A dog is running in the snow', 'A dog running through snow .', 'a white and brown dog is running through a snow covered field .', 'The white and brown dog is running over the surface of the snow .']</span></pre><h1 id="b681" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">6.数据清理</h1><p id="fdcf" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">当我们处理文本时，我们通常会执行一些基本的清理，如将所有单词小写(否则“hello”和“Hello”将被视为两个独立的单词)，删除特殊标记(如“%”、“$”、“#”等)。)，删除包含数字的单词(如“hey199”等)。).</p><p id="4247" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">以下代码执行这些基本的清理步骤:</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="ns nt l"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Code to perform Data Cleaning</figcaption></figure><p id="2a04" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">创建在数据集中所有 8000*5(即 40000)个图像标题(<strong class="kz ir">语料库</strong>)中出现的所有唯一单词的词汇表；</p><pre class="mi mj mk ml gt ni nj nk nl aw nm bi"><span id="c1aa" class="nn kg iq nj b gy no np l nq nr">vocabulary = set()<br/>for key in descriptions.keys():<br/>    [vocabulary.update(d.split()) for d in descriptions[key]]<br/>print('Original Vocabulary Size: %d' % len(vocabulary))<br/>Original Vocabulary Size: 8763</span></pre><p id="6ff3" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">这意味着在所有 40000 个图片说明中，我们有 8763 个独特的单词。我们将所有这些说明连同它们的图像名称一起写入一个新文件，即“<em class="nu">descriptions . txt”</em>，并将其保存在磁盘上。</p><p id="1d17" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">然而，如果我们仔细想想，这些词中有许多会出现很少次，比如说 1 次、2 次或 3 次。由于我们正在创建一个预测模型，我们不希望所有的单词都出现在我们的词汇表中，而是更有可能出现或更常见的单词。这有助于模型变得对异常值更加<strong class="kz ir">稳健</strong>，并减少错误。</p><p id="5daa" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">因此，我们只考虑那些在整个语料库中至少出现 10 次的单词。这方面的代码如下:</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="ns nt l"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Code to retain only those words which occur at least 10 times in the corpus</figcaption></figure><p id="82b9" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">所以现在我们的词汇中只有 1651 个独特的单词。然而，我们将附加 0(零填充将在后面解释)，因此总字数= 1651+1 =<strong class="kz ir">1652</strong>(0 的一个索引)。</p><h1 id="fd12" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">7.加载训练集</h1><p id="04e5" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">文本文件“Flickr_8k.trainImages.txt”包含属于训练集的图像的名称。所以我们把这些名字加载到一个列表“train”中。</p><pre class="mi mj mk ml gt ni nj nk nl aw nm bi"><span id="ba9f" class="nn kg iq nj b gy no np l nq nr">filename = 'dataset/TextFiles/Flickr_8k.trainImages.txt'<br/>doc = load_doc(filename)<br/>train = list()<br/>for line in doc.split('\n'):<br/>    identifier = line.split('.')[0]<br/>    train.append(identifier)<br/>print('Dataset: %d' % len(train))<br/>Dataset: 6000</span></pre><p id="d842" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">因此，我们在名为“train”的列表中分离了 6000 个训练图像。</p><p id="c680" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">现在，我们从 Python 字典“train_descriptions”中的“descriptions.txt”(保存在硬盘上)加载这些图像的描述。</p><p id="6357" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">然而，当我们加载它们时，我们将在每个标题中添加两个标记，如下所示(重要性稍后解释):</p><p id="9d92" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir"> startseq </strong> ' - &gt;这是一个开始序列标记，将被添加到每个字幕的开头。</p><p id="7659" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir"> endseq </strong> ' - &gt;这是一个结束序列标记，将被添加到每个标题的末尾。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="ns nt l"/></div></figure><h1 id="0a00" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">8.数据预处理—图像</h1><p id="929d" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">图像只是我们模型的输入(X)。您可能已经知道，模型的任何输入都必须以向量的形式给出。</p><p id="36dc" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">我们需要将每张图像转换成固定大小的向量，然后将其作为神经网络的输入。为此，我们通过使用 Google Research 创建的 InceptionV3 模型(卷积神经网络)选择了<strong class="kz ir">迁移学习</strong>。</p><p id="39c0" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">该模型在 Imagenet 数据集上进行训练，以对 1000 个不同类别的图像执行图像分类。然而，我们在这里的目的不是对图像进行分类，而是获得每幅图像的固定长度的信息向量。这个过程被称为<strong class="kz ir">自动特征工程。</strong></p><p id="a525" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">因此，我们只是从模型中移除最后一个 softmax 层，并为每个图像提取 2048 长度向量(<strong class="kz ir">瓶颈特征</strong>)，如下所示:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi nv"><img src="../Images/d8779488ad23fc64ce99dfaeabd1da1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9VoYufkvd-hBxK3p2NEWmw.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Feature Vector Extraction (Feature Engineering) from InceptionV3</figcaption></figure><p id="e077" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">这方面的代码如下:</p><pre class="mi mj mk ml gt ni nj nk nl aw nm bi"><span id="16b3" class="nn kg iq nj b gy no np l nq nr"># Get the InceptionV3 model trained on imagenet data<br/>model = InceptionV3(weights='imagenet')<br/># Remove the last layer (output softmax layer) from the inception v3<br/>model_new = Model(model.input, model.layers[-2].output)</span></pre><p id="3d78" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">现在，我们将每个图像传递给该模型，以获得相应的 2048 长度的特征向量，如下所示:</p><pre class="mi mj mk ml gt ni nj nk nl aw nm bi"><span id="b1d8" class="nn kg iq nj b gy no np l nq nr"># Convert all the images to size 299x299 as expected by the<br/># inception v3 model<br/>img = image.load_img(image_path, target_size=(299, 299))<br/># Convert PIL image to numpy array of 3-dimensions<br/>x = image.img_to_array(img)<br/># Add one more dimension<br/>x = np.expand_dims(x, axis=0)<br/># preprocess images using preprocess_input() from inception module<br/>x = preprocess_input(x)<br/># reshape from (1, 2048) to (2048, )<br/>x = np.reshape(x, x.shape[1])</span></pre><p id="19f9" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">我们将所有的瓶颈训练特征保存在一个 Python 字典中，并使用 Pickle 文件保存在磁盘上，即“<strong class="kz ir"> encoded_train_images.pkl </strong>”，其关键字是图像名，值是对应的 2048 长度特征向量。</p><p id="ec6c" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir">注意:</strong>如果您没有高端 PC/笔记本电脑，这个过程可能需要一两个小时。</p><p id="0459" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">类似地，我们对所有的测试图像进行编码，并将它们保存在文件“<strong class="kz ir"> encoded_test_images.pkl </strong>”中。</p><h1 id="8e39" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">9.数据预处理—标题</h1><p id="fce1" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">我们必须注意，字幕是我们想要预测的东西。因此在训练期间，字幕将是模型正在学习预测的目标变量(Y)。</p><p id="f7e0" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">但是对给定图像的整个字幕的预测不会立即发生。我们将逐字预测字幕<strong class="kz ir"/>。因此，我们需要将每个单词编码成一个固定大小的向量。然而，这一部分将在我们稍后查看模型设计时看到，但现在我们将创建两个 Python 字典，即“wordtoix”(发音—单词到索引)和“ixtoword”(发音—单词到索引)。</p><p id="90d9" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">简单地说，我们将用一个整数(索引)来表示词汇表中的每个唯一的单词。如上所述，我们在语料库中有 1652 个唯一的单词，因此每个单词将由 1 到 1652 之间的整数索引来表示。</p><p id="7318" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">这两个 Python 字典的用法如下:</p><p id="4fdf" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">wordtoix[' abc ']--&gt;返回单词' ABC '的索引</p><p id="fecc" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">ixtoword[k] -&gt;返回索引为“k”的单词</p><p id="78cb" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">使用的代码如下:</p><pre class="mi mj mk ml gt ni nj nk nl aw nm bi"><span id="0e6d" class="nn kg iq nj b gy no np l nq nr">ixtoword = {}<br/>wordtoix = {}</span><span id="37ec" class="nn kg iq nj b gy nw np l nq nr">ix = 1<br/>for w in vocab:<br/>    wordtoix[w] = ix<br/>    ixtoword[ix] = w<br/>    ix += 1</span></pre><p id="2b71" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">我们还需要计算一个参数，即字幕的最大长度，我们的计算如下:</p><pre class="mi mj mk ml gt ni nj nk nl aw nm bi"><span id="e7cb" class="nn kg iq nj b gy no np l nq nr"># convert a dictionary of clean descriptions to a list of descriptions<br/>def to_lines(descriptions):<br/> all_desc = list()<br/> for key in descriptions.keys():<br/>  [all_desc.append(d) for d in descriptions[key]]<br/> return all_desc</span><span id="7f65" class="nn kg iq nj b gy nw np l nq nr"># calculate the length of the description with the most words<br/>def max_length(descriptions):<br/> lines = to_lines(descriptions)<br/> return max(len(d.split()) for d in lines)</span><span id="f985" class="nn kg iq nj b gy nw np l nq nr"># determine the maximum sequence length<br/>max_length = max_length(train_descriptions)<br/>print('Max Description Length: %d' % max_length)<br/>Max Description Length: 34</span></pre><p id="21bc" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">所以任何标题的最大长度是 34。</p><h1 id="8afb" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated"><strong class="ak"> 10。</strong>使用生成器功能准备数据</h1><p id="867a" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">这是本案例研究中最重要的步骤之一。在这里，我们将了解如何以一种方便的方式准备数据，以作为深度学习模型的输入。</p><p id="7fba" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">在下文中，我将尝试通过以下示例来解释剩余的步骤:</p><p id="f16c" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">假设我们有 3 张图片和 3 个相应的标题，如下所示:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/4f1777aed0bdeefb0c0cf20c482a9d99.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*tVETPw5HjXoNM9Ne5DSZWA.jpeg"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">(Train image 1) Caption -&gt; The black cat sat on grass</figcaption></figure><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/4cb1c013b4ff4a1128037e0068e35811.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*2fTSz1aB0JimPSBH9vsB5Q.jpeg"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">(Train image 2) Caption -&gt; The white cat is walking on road</figcaption></figure><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/f61d260e894c5da8a762125e18e48089.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*hUsFhuZJNXaLqzQJsCHGKg.jpeg"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">(Test image) Caption -&gt; The black cat is walking on grass</figcaption></figure><p id="2199" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">现在，假设我们使用<strong class="kz ir">前两幅图像</strong>和它们的标题<strong class="kz ir">来训练</strong>模型，使用<strong class="kz ir">第三幅图像</strong>来<strong class="kz ir">测试</strong>我们的模型。</p><p id="b6ce" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">现在将要回答的问题是:我们如何将这一问题框定为监督学习问题？，数据矩阵是什么样子的？我们有多少数据点？等。</p><p id="ba69" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">首先，我们需要将两个图像转换成它们相应的 2048 长度的特征向量，如上所述。设“<strong class="kz ir">图像 _1 </strong>”和“<strong class="kz ir">图像 _2 </strong>”分别为前两幅图像的特征向量</p><p id="5b15" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">其次，让我们为前两个(train)标题构建词汇表，在这两个标题中添加两个标记“startseq”和“endseq”:(假设我们已经执行了基本的清理步骤)</p><p id="e4d8" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">caption _ 1--&gt; "黑猫坐在草地上"</p><p id="f433" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">caption _ 2--&gt; " start seq 白猫走在路上 endseq "</p><p id="4372" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">vocab = {black，cat，endseq，grass，is，on，road，sat，startseq，the，walking，white}</p><p id="eba7" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">让我们给词汇表中的每个单词编个索引:</p><p id="d400" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">黑色-1，猫-2，结束序列-3，草-4，是-5，on -6，道路-7，sat -8，开始序列-9，the -10，步行-11，白色-12</p><p id="e6d6" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">现在让我们试着把它框定为一个<strong class="kz ir">监督学习问题</strong>其中我们有一组数据点 D = {Xi，易}，其中 Xi 是数据点‘我’的特征向量，易是相应的目标变量。</p><p id="eace" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">让我们取第一个图像向量<strong class="kz ir"> Image_1 </strong>和它对应的标题“<strong class="kz ir"> startseq the 黑猫坐在草地上 endseq </strong>”。回想一下，图像向量是输入，标题是我们需要预测的。但是我们预测标题的方式如下:</p><p id="1209" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">第一次，我们提供图像向量和第一个单词作为输入，并尝试预测第二个单词，即:</p><p id="a5f7" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">input = Image _ 1+' start seq '；Output = 'the '</p><p id="ed7a" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">然后，我们提供图像向量和前两个单词作为输入，并尝试预测第三个单词，即:</p><p id="ad18" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">input = Image _ 1+' start seq the '；输出= '猫'</p><p id="cda7" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">诸如此类…</p><p id="1374" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">因此，我们可以将一幅图像的数据矩阵及其相应的标题总结如下:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/3f34eb8d23bb94b208bae4b3f7fe24a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*0ixJXDqGxFYR6XZQc5Bh5w.jpeg"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Data points corresponding to one image and its caption</figcaption></figure><p id="ea42" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">必须注意，一个图像+字幕<strong class="kz ir">不是单个数据点</strong>，而是取决于字幕长度的多个数据点。</p><p id="a359" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">类似地，如果我们考虑图像及其标题，我们的数据矩阵将如下所示:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oa"><img src="../Images/7a8389fa7940c2161cad377a90bab9b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ME49hZnlJDtkA4cWtZjKNg.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Data Matrix for both the images and captions</figcaption></figure><p id="3c98" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">我们现在必须明白，在每一个数据点中，不仅仅是图像作为系统的输入，还有部分标题帮助<strong class="kz ir">预测序列中的下一个单词。</strong></p><p id="16f2" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">由于我们正在处理<strong class="kz ir">序列</strong>，我们将使用<strong class="kz ir">递归神经网络</strong>来读取这些部分字幕(稍后将详细介绍)。</p><p id="c698" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">然而，我们已经讨论过，我们不会传递标题的实际英文文本，而是传递索引序列，其中每个索引代表一个唯一的单词。</p><p id="4ec7" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">因为我们已经为每个单词创建了一个索引，现在让我们用它们的索引来替换单词，并理解数据矩阵将会是什么样子:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/2bfd58a7f50e499b076f05c321409e3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*6G1eDpwq11eRY4rhD0yXPg.jpeg"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Data matrix after replacing the words by their indices</figcaption></figure><p id="68da" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">由于我们将进行<strong class="kz ir">批处理</strong>(稍后解释)，我们需要确保每个序列的<strong class="kz ir">长度</strong>相等。因此，我们需要<strong class="kz ir">在每个序列的末尾添加 0 的</strong>(零填充)。但是<strong class="kz ir">我们应该在每个序列中添加多少个</strong>零呢？</p><p id="fd48" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">这就是我们计算标题最大长度的原因，它是 34(如果你记得的话)。因此，我们将添加这些数量的零，这将导致每个序列的长度为 34。</p><p id="b280" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">数据矩阵将如下所示:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/e1ee303f91ce97b9e4e64222afee3bd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*gefPePe1I2-9pryw3axP1A.jpeg"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Appending zeros to each sequence to make them all of same length 34</figcaption></figure><p id="8e21" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir">需要数据生成器:</strong></p><p id="8165" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">我希望这能给你一个好的感觉，关于我们如何为这个问题准备数据集。然而，这里面有一个很大的陷阱。</p><p id="5aaa" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">在上面的例子中，我只考虑了导致 15 个数据点的 2 个图像和标题。</p><p id="4d8f" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">然而，在我们实际的训练数据集中，我们有 6000 张图片，每张图片有 5 个标题。这使得总共有<strong class="kz ir"> 30000 </strong>张图片和说明文字。</p><p id="bb67" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">即使我们假设每个字幕平均只有 7 个单词长，也将导致总共 30000*7，即<strong class="kz ir"> 210000 </strong>个数据点。</p><p id="42f3" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir">计算数据矩阵的大小:</strong></p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/1509921c956a2a9e5bbc5a3aad4530ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*xWXhUrwzgRc5KLTT58-u6w.jpeg"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Data Matrix</figcaption></figure><p id="f2ef" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">数据矩阵的大小= n*m</p><p id="82a6" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">其中 n-&gt;数据点的数量(假设为 210000)</p><p id="9846" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">和 m-&gt;每个数据点的长度</p><p id="8bf4" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">显然 m=图像向量的长度(2048) +部分字幕的长度(x)。</p><p id="9b09" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">m = 2048 + x</p><p id="d4c2" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">但是 x 的值是多少呢？</p><p id="4e43" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">你可能认为是 34，但是不对，等等，这是错的。</p><p id="8f18" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">每个单词(或索引)将通过一种单词嵌入技术被映射(嵌入)到更高维度的空间。</p><p id="3667" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">稍后，在模型构建阶段，我们将看到使用预训练的手套单词嵌入模型将每个单词/索引映射到 200 长的向量。</p><p id="766e" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">现在每个序列包含 34 个索引，其中每个索引是长度为 200 的向量。因此 x = 34*200 = 6800</p><p id="62a7" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">因此，m = 2048 + 6800 = 8848。</p><p id="4e7a" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">最后，数据矩阵的大小= 210000 * 8848= 1858080000 块。</p><p id="d047" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">现在，即使我们假设一个块占用 2 个字节，那么，为了存储这个数据矩阵，我们将需要超过 3 GB 的主存储器。</p><p id="fc0a" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">这是一个相当大的需求，即使我们能够将这么多数据加载到 RAM 中，也会使系统非常慢。</p><p id="a5e4" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">由于这个原因，我们在深度学习中大量使用数据生成器。数据生成器是一种在 Python 中本地实现的功能。Keras API 提供的 ImageDataGenerator 类只不过是 Python 中生成器函数的一个实现。</p><p id="0d84" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir">那么使用生成器函数如何解决这个问题呢？</strong></p><p id="1679" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">如果你知道深度学习的基础，那么你必须知道，为了在特定的数据集上训练模型，我们使用一些版本的随机梯度下降(SGD)，如 Adam，Rmsprop，Adagrad 等。</p><p id="c474" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">使用<strong class="kz ir"> SGD </strong>，我们不用计算整个数据集的损失来更新梯度。相反，在每次迭代中，我们计算一批<strong class="kz ir">数据点(通常是 64、128、256 等)的损失。)来更新梯度。</strong></p><p id="9203" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">这意味着我们不需要一次将整个数据集存储在内存中。即使我们在内存中有当前的一批点，它也足以满足我们的目的。</p><p id="52f0" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">Python 中的生成器函数正好用于此目的。它就像一个迭代器，从上次被调用的地方恢复功能。</p><p id="cddc" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">想了解更多关于发电机的知识，请在这里阅读<a class="ae nd" href="https://wiki.python.org/moin/Generators" rel="noopener ugc nofollow" target="_blank"><strong class="kz ir"/></a>。</p><p id="ef26" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">数据生成器的代码如下:</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="ns nt l"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Code to load data in batches</figcaption></figure><h1 id="2be1" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated"><strong class="ak"> 11。单词嵌入</strong></h1><p id="9e13" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">如上所述，我们将把每个单词(索引)映射到 200 长的向量，为此，我们将使用预先训练的手套模型:</p><pre class="mi mj mk ml gt ni nj nk nl aw nm bi"><span id="84ab" class="nn kg iq nj b gy no np l nq nr"># Load Glove vectors<br/>glove_dir = 'dataset/glove'<br/>embeddings_index = {} # empty dictionary<br/>f = open(os.path.join(glove_dir, 'glove.6B.200d.txt'), encoding="utf-8")</span><span id="6840" class="nn kg iq nj b gy nw np l nq nr">for line in f:<br/>    values = line.split()<br/>    word = values[0]<br/>    coefs = np.asarray(values[1:], dtype='float32')<br/>    embeddings_index[word] = coefs<br/>f.close()</span></pre><p id="9ffb" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">现在，对于我们词汇表中的所有 1652 个唯一单词，我们创建一个嵌入矩阵，该矩阵将在训练之前加载到模型中。</p><pre class="mi mj mk ml gt ni nj nk nl aw nm bi"><span id="ca1c" class="nn kg iq nj b gy no np l nq nr">embedding_dim = 200</span><span id="74a1" class="nn kg iq nj b gy nw np l nq nr"># Get 200-dim dense vector for each of the 10000 words in out vocabulary<br/>embedding_matrix = np.zeros((vocab_size, embedding_dim))</span><span id="272c" class="nn kg iq nj b gy nw np l nq nr">for word, i in wordtoix.items():<br/>    #if i &lt; max_words:<br/>    embedding_vector = embeddings_index.get(word)<br/>    if embedding_vector is not None:<br/>        # Words not found in the embedding index will be all zeros<br/>        embedding_matrix[i] = embedding_vector</span></pre><p id="db07" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">要了解更多关于单词嵌入的信息，请参考此<a class="ae nd" href="https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir">链接</strong> </a></p><h1 id="338a" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">12.模型架构</h1><p id="0a73" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">由于输入由两部分组成，一个图像向量和一个部分标题，我们不能使用 Keras 库提供的顺序 API。出于这个原因，我们使用函数式 API 来创建合并模型。</p><p id="abd7" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">首先，让我们看看包含高级子模块的简要架构:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi od"><img src="../Images/1fe26a9d430c3ed2026e4c0769a45a0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rfYN2EELhLvp2Van3Jo-Yw.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">High level architecture</figcaption></figure><p id="6276" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">我们将模型定义如下:</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="ns nt l"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Code to define the Model</figcaption></figure><p id="6321" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">让我们来看看模型总结:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi oe"><img src="../Images/1982e0d2870c1c1b8c6027fd47458b15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FO8xZThMxW55enOuHhK_Xg.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Summary of the parameters in the model</figcaption></figure><p id="249c" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">下图有助于形象化网络结构，并更好地理解两个输入流:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi of"><img src="../Images/6c080d4628a8d44ae58f310560cc1632.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VGzSnYhyhpAAmGkSyOfeig.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Flowchart of the architecture</figcaption></figure><p id="236a" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">右侧的红色文本是为您提供的注释，用于将您对数据准备的理解映射到模型架构。</p><p id="6f36" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir"> LSTM(长短期记忆)</strong>层只不过是一个专门的递归神经网络来处理序列输入(在我们的例子中是部分字幕)。要了解更多关于 LSTM 的信息，点击<a class="ae nd" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir">这里</strong> </a>。</p><p id="f3e5" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">如果您已经阅读了前面的部分，我认为阅读这些评论应该有助于您以一种直接的方式理解模型架构。</p><p id="686d" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">回想一下，我们已经从预训练的手套模型中创建了一个嵌入矩阵，我们需要在开始训练之前将它包含在模型中:</p><pre class="mi mj mk ml gt ni nj nk nl aw nm bi"><span id="f9d8" class="nn kg iq nj b gy no np l nq nr">model.layers[2].set_weights([embedding_matrix])<br/>model.layers[2].trainable = False</span></pre><p id="9dff" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">请注意，由于我们使用的是预训练的嵌入层，所以在训练模型之前，我们需要<strong class="kz ir">冻结</strong>它(可训练=假)，这样它就不会在反向传播过程中更新。</p><p id="ff89" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">最后，我们使用 adam 优化器编译模型</p><pre class="mi mj mk ml gt ni nj nk nl aw nm bi"><span id="eb10" class="nn kg iq nj b gy no np l nq nr">model.compile(loss=’categorical_crossentropy’, optimizer=’adam’)</span></pre><p id="2cda" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">最后，通过反向传播算法更新模型的权重，并且给定图像特征向量和部分字幕，模型将学习输出单词。总而言之，我们有:</p><p id="b337" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">Input_1 -&gt;部分字幕</p><p id="f4cd" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">Input_2 -&gt;图像特征向量</p><p id="3f5a" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">Output -&gt;一个适当的单词，在 input_1 中提供的部分字幕序列中的下一个(或者用概率术语我们说<strong class="kz ir">以图像向量和部分字幕为条件</strong>)</p><p id="938f" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir">训练期间的高参数:</strong></p><p id="87ac" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">然后用 0.001 的初始学习率和每批 3 张图片(批量大小)训练该模型 30 个时期。然而，在 20 个时期之后，学习率降低到 0.0001，并且每批在 6 张图片上训练模型。</p><p id="0c7b" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir">这通常是有意义的，因为在训练的后期阶段，由于模型正在走向收敛，我们必须降低学习率，以便我们朝着最小值迈出更小的步伐。此外，随着时间的推移增加批量大小有助于您的渐变更新更加强大。</strong></p><p id="864b" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir">耗时:</strong>我在<a class="ae nd" href="http://www.paperspace.com" rel="noopener ugc nofollow" target="_blank">www.paperspace.com</a>上使用了 GPU+ Gradient 笔记本，因此我花了大约一个小时来训练模型。然而，如果你在没有 GPU 的 PC 上训练它，它可能需要 8 到 16 个小时，这取决于你的系统配置。</p><h1 id="2ee4" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">13.推理</h1><p id="5e40" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">到目前为止，我们已经了解了如何准备数据和构建模型。在本系列的最后一步，我们将了解如何通过传入新图像来测试(推断)我们的模型，也就是说，我们如何为新的测试图像生成标题。</p><p id="b1a8" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">回想一下，在我们看到如何准备数据的例子中，我们只使用了前两个图像及其标题。现在，让我们使用第三个图像，并尝试理解我们希望标题如何生成。</p><p id="ee3b" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">第三个图像向量和标题如下:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/f61d260e894c5da8a762125e18e48089.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*hUsFhuZJNXaLqzQJsCHGKg.jpeg"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Test image</figcaption></figure><p id="22c7" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">描述-&gt;黑猫在草地上行走</p><p id="7917" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">示例中的词汇还有:</p><p id="48e5" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">vocab = {black，cat，endseq，grass，is，on，road，sat，startseq，the，walking，white}</p><p id="cb3a" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">我们将迭代生成标题，一次一个单词，如下所示:</p><p id="7875" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir">迭代 1: </strong></p><p id="8699" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">输入:图像向量+“startseq”(作为部分字幕)</p><p id="15f9" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">预期输出字:“the”</p><p id="0768" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">(现在您应该理解标记“startseq”的重要性，它在推断过程中用作任何图像的初始部分标题)。</p><p id="84b3" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">但是等等，模型生成了一个 12 长的向量(在示例中是 1652 长的向量，而在原始示例中是 1652 长的向量)，这是词汇表中所有单词的概率分布。由于这个原因，我们<strong class="kz ir">贪婪地</strong>选择具有最大概率的单词，给定特征向量和部分标题。</p><p id="2333" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">如果模型训练良好，我们必须期望单词“the”的概率最大:</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi og"><img src="../Images/a943d2e079cd185637fc3784534ef3ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*isNHnFwkJQFcX3yEy2iTDg.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Iteration 1</figcaption></figure><p id="4106" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">这被称为<strong class="kz ir">最大似然估计(MLE) </strong>，即我们根据给定输入的模型选择最有可能的单词。有时这种方法也被称为<strong class="kz ir">贪婪搜索</strong>，因为我们贪婪地选择具有最大概率的单词。</p><p id="33c8" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir">迭代 2: </strong></p><p id="6cb4" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">输入:图像向量+ "startseq the "</p><p id="39db" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">预期输出字:“黑色”</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi og"><img src="../Images/369e9c9f8b237f68bad2daafc3c6a233.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-4GJpKamCP4TJit5zrK5ZQ.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Iteration 2</figcaption></figure><p id="21db" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir">迭代 3: </strong></p><p id="04a6" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">输入:图像向量+ "startseq the black "</p><p id="557a" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">预期输出字:“猫”</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi og"><img src="../Images/d672001ccd15f788419c498d400e0dd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WXS-BIlzvUrokdFHz71bpw.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Iteration 3</figcaption></figure><p id="e9f5" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir">迭代 4: </strong></p><p id="af11" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">输入:图像向量+ "startseq the black cat "</p><p id="97cb" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">预期的输出字:“是”</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi og"><img src="../Images/096feaedee402a035eae08e360885dfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*67sBzjYHmfWzSS3Q9lAodw.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Iteration 4</figcaption></figure><p id="76eb" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir">迭代 5: </strong></p><p id="81f0" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">输入:图像向量+ "startseq 黑猫是"</p><p id="85c6" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">预期输出字:“行走”</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi og"><img src="../Images/c2521f8f5a1b8934c62fd4d885c52fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8UQ_mnowODycDBMrhW5eGg.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Iteration 5</figcaption></figure><p id="e27b" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir">迭代 6: </strong></p><p id="6d40" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">输入:图像向量+ "startseq 黑猫在走"</p><p id="2ab0" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">预期输出字:“开”</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi og"><img src="../Images/4aa37661803c2966b40fc41e31e7c755.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wrSn21PEj9ahfeia0N07Gw.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Iteration 6</figcaption></figure><p id="556d" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir">迭代 7: </strong></p><p id="321d" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">输入:图像向量+“黑猫正在行走的起始序列”</p><p id="f1d8" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">预期输出字:“草”</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi og"><img src="../Images/ad539c667b34842fd6b77f336b321eb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-F-zUo2VulxfuMfoJLJ_9Q.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Iteration 7</figcaption></figure><p id="275e" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir">迭代 8: </strong></p><p id="f092" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">输入:图像向量+“startseq 黑猫在草地上走”</p><p id="e662" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">预期输出字:“endseq”</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi og"><img src="../Images/5c3f6de2a42715e1233c6ef28109d455.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ikzIYNA5_1PPjvMqrvQ7ww.jpeg"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Iteration 8</figcaption></figure><p id="9e65" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">这是我们停止迭代的地方。</p><p id="e638" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">因此，当满足以下两个条件之一时，我们停止:</p><ul class=""><li id="9b22" class="kx ky iq kz b la mx lc my le ne lg nf li ng lk nh lm ln lo bi translated">我们遇到了一个“<strong class="kz ir"> endseq </strong>”标记，这意味着模型认为这是标题的结尾。(您现在应该明白' endseq '标记的重要性了)</li><li id="a852" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk nh lm ln lo bi translated">我们达到由模型生成的单词数量的最大阈值<strong class="kz ir"/>。</li></ul><p id="9a85" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">如果满足以上任何一个条件，我们就中断循环，并将生成的标题报告为给定图像的模型输出。用于推理的代码如下:</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="ns nt l"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Inference with greedy search</figcaption></figure><h1 id="9130" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">14.估价</h1><p id="a175" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">为了了解模型有多好，让我们尝试在测试数据集的图像上生成标题(即模型在训练期间没有看到的图像)。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/7d3f2b45e1fc6451f815e4e0726ca533.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*slRQIAs7Z8TCQPKvzPHkHg.png"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Output — 1</figcaption></figure><p id="353a" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">注意:我们必须理解模型是如何精确地识别颜色的。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/ff3dd29c3d33fdb85a343a5f2f0f98c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*ZmmJQ-FsazXfcjl_WHmKvA.png"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Output — 2</figcaption></figure><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/5f8626ce4b3e34a1295f2bb7a68f7203.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*J9MqpfygNjD1lvpvT-Ezmg.png"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Output — 3</figcaption></figure><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/455fa5ef6124ed5479a4ec6f5ca3b79c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*3_q3nU0FdvsP-QBuiw89Tg.png"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Output — 4</figcaption></figure><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/bc6f4819b600121deb5a3e89a6db9820.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*kUJj5j57Xo2Dwa4-dZNzLg.png"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Output — 5</figcaption></figure><p id="d914" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">当然，如果我只给你看适当的说明，我是在欺骗你。世界上没有一个模型是完美的，这个模型也会犯错误。让我们来看一些例子，这些例子中的标题不是很相关，有时甚至是不相关的。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi om"><img src="../Images/a6ecf9b65f4936822ed95b47d0e83e73.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*AIlPFhnRkwNX0JBj3ZAz-g.png"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Output — 6</figcaption></figure><p id="85ce" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">可能衬衫的颜色和背景色混在一起了</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi on"><img src="../Images/7f1b244c13502c5a84d84f37936375b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*ajYqHTHXYTjWC-QcEz2dog.png"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Output — 7</figcaption></figure><p id="585b" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">为什么模型把著名的拉菲尔·纳达尔归为女性:-)？大概是因为长发的缘故吧。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/ca42688f6a1dab603c17b842f2b643a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*R962xS1Y_jc4AXfRWt8Q2w.png"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Output — 7</figcaption></figure><p id="a014" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">这次模型得到的语法不正确</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi op"><img src="../Images/f6d34d4ac277f22491b03bb77d308d22.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*3UXw9_WOOtm4SBySg1Yxeg.png"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Output — 9</figcaption></figure><p id="73e2" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">很明显，这个模型尽了最大努力去理解这个场景，但是标题仍然不太好。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/22da39c8ae49c0a02c2155e5c2ed3eda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*er8PsZFsNpePUvSMB0v0ag.png"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Output — 10</figcaption></figure><p id="97c8" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">这又是一个模型失败，标题不相关的例子。</p><p id="e497" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">所以总而言之，我必须说，我天真的第一次切割模型，没有任何严格的超参数调整，在生成图像字幕方面做得很好。</p><p id="7922" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir">重点:</strong></p><p id="6f87" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">我们必须理解，用于测试的图像必须与用于训练模型的图像在语义上相关。例如，如果我们在猫、狗等的图像上训练我们的模型。我们不能在飞机、瀑布等图像上测试它。这是一个训练集和测试集的分布将非常不同的例子，在这种情况下，世界上没有机器学习模型会提供良好的性能。</p><h1 id="fa6f" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">15.结论和未来工作</h1><p id="8d84" class="pw-post-body-paragraph lu lv iq kz b la lb jr lw lc ld ju lx le ly lz ma lg mb mc md li me mf mg lk ij bi translated">如果你已经到达这里，非常感谢。这是我第一次尝试写博客，所以我希望读者能慷慨一点，忽略我可能犯的小错误。</p><p id="c594" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">请参考我的 GitHub 链接<a class="ae nd" href="https://github.com/hlamba28/Automatic-Image-Captioning.git" rel="noopener ugc nofollow" target="_blank"> <strong class="kz ir">这里</strong> </a>访问 Jupyter 笔记本上写的完整代码。</p><p id="fdc5" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">请注意，由于模型的随机性，您生成的标题(如果您试图复制代码)可能与我的案例中生成的标题不完全相似。</p><p id="fd25" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated">当然，这只是一个初步的解决方案，可以进行许多修改来改进该解决方案，例如:</p><ul class=""><li id="7fc4" class="kx ky iq kz b la mx lc my le ne lg nf li ng lk nh lm ln lo bi translated">使用一个<strong class="kz ir">更大的</strong>数据集。</li><li id="c3e1" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk nh lm ln lo bi translated">改变模型架构，例如包括<strong class="kz ir">注意</strong>模块。</li><li id="a343" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk nh lm ln lo bi translated">做更多<strong class="kz ir">超参数调整</strong>(学习率、批量大小、层数、单位数、辍学率、批量标准化等。).</li><li id="764d" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk nh lm ln lo bi translated">使用交叉验证集了解<strong class="kz ir">过拟合</strong>。</li><li id="33d2" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk nh lm ln lo bi translated">推断时使用<strong class="kz ir">波束搜索</strong>代替贪婪搜索。</li><li id="9b0f" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk nh lm ln lo bi translated">使用<strong class="kz ir"> BLEU Score </strong>评估和测量模型的性能。</li><li id="f18b" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk nh lm ln lo bi translated">以适当的面向对象的方式编写代码，以便其他人更容易复制:-)</li></ul><h1 id="e7db" class="kf kg iq bd kh ki kj kk kl km kn ko kp jw kq jx kr jz ks ka kt kc ku kd kv kw bi translated">16.参考</h1><ol class=""><li id="8e6c" class="kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo bi translated"><a class="ae nd" href="https://cs.stanford.edu/people/karpathy/cvpr2015.pdf" rel="noopener ugc nofollow" target="_blank">https://cs.stanford.edu/people/karpathy/cvpr2015.pdf</a></li><li id="f99d" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated"><a class="ae nd" href="https://arxiv.org/abs/1411.4555" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1411.4555</a></li><li id="d4ed" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated"><a class="ae nd" href="https://arxiv.org/abs/1703.09137" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1703.09137</a></li><li id="2bde" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated"><a class="ae nd" href="https://arxiv.org/abs/1708.02043" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1708.02043</a></li><li id="1b39" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated"><a class="ae nd" href="https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/develop-a-deep-learning-caption-generation-model-in-python/</a></li><li id="03c7" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated"><a class="ae nd" href="https://www.youtube.com/watch?v=yk6XDFm3J2c" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=yk6XDFm3J2c</a></li><li id="b414" class="kx ky iq kz b la lp lc lq le lr lg ls li lt lk ll lm ln lo bi translated"><a class="ae nd" href="https://www.appliedaicourse.com/" rel="noopener ugc nofollow" target="_blank">https://www.appliedaicourse.com/</a></li></ol><p id="ca45" class="pw-post-body-paragraph lu lv iq kz b la mx jr lw lc my ju lx le mz lz ma lg na mc md li nb mf mg lk ij bi translated"><strong class="kz ir"> PS: </strong>如果你认为他们可以改进这个博客，请随时提供意见/批评，我一定会努力做出必要的修改。</p></div></div>    
</body>
</html>