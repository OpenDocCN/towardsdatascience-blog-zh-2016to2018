<html>
<head>
<title>Image-to-Recipe Translation with Deep Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用深度卷积神经网络进行图像到食谱的翻译</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/this-ai-is-hungry-b2a8655528be?source=collection_archive---------0-----------------------#2018-09-09">https://towardsdatascience.com/this-ai-is-hungry-b2a8655528be?source=collection_archive---------0-----------------------#2018-09-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/e6d1ab567775bd0ed5188c263d2d6f6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BzCVKWDSzdR-hiJEr9Ck7g.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><a class="ae kc" href="https://github.com/Murgio/Food-Recipe-CNN" rel="noopener ugc nofollow" target="_blank">https://github.com/Murgio/Food-Recipe-CNN</a></figcaption></figure><h1 id="d52a" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">介绍</h1><p id="1009" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在这篇文章中，我们将看看如何训练一个<strong class="ld ir">深度卷积神经网络</strong>，它能够<em class="lz">将图像分类为食物类别</em>和<em class="lz">输出匹配的食谱</em>。到目前为止，我们强调选择目标领域的困难有两个方面。首先，烹饪菜肴的单个成分的分类或对象识别的进展很少。问题是，实际上没有公共处理过的数据集可用于此。第二，到目前为止，烹饪菜肴表现出内在的高度类间相似性，这使得即使对于最复杂的系统来说，推断菜肴类别也是一个困难的问题。为了应对这些挑战，我们从欧洲最受欢迎的烹饪食谱平台 chefkoch.de 中收集了一个新的数据集，其中包含&gt; 800，000 张食物图像和&gt; 300，000 份食谱，并在数据集上实证比较了当代机器学习模型(卷积神经网络)和更传统方法(最近邻搜索)的有效性。</p><h1 id="61e3" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">前言</h1><p id="4de6" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi ma translated">其他任何领域对人类健康的影响都不亚于营养。每天，用户在社交网络上发布不计其数的食物图片；从第一个自制的蛋糕到顶级的米其林菜肴，如果人们成功地做了一道菜，他们很乐意与世界分享他们的喜悦。事实上，无论一个人与另一个人有多么不同，好的食物几乎都会受到每个人的高度赞赏。</p><p id="077b" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">单个烹饪原料的分类进展很少。问题是几乎没有公开编辑过的记录。这项工作处理的问题是<strong class="ld ir">自动识别</strong>拍摄的烹饪菜肴，并随后输出适当的食谱。所选问题的难度与之前的监督分类问题之间的区别在于，食物菜肴中有很大的重叠(又名<strong class="ld ir">高类间相似度</strong>)，因为不同类别的菜肴可能仅在图像信息方面看起来非常相似(见图 1)。</p><div class="mo mp mq mr gt ab cb"><figure class="ms jr mt mu mv mw mx paragraph-image"><img src="../Images/4ff03402c5f73c018ccce3829e0698ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*hM0kc2J9etdjJNPjF2kE_Q.jpeg"/></figure><figure class="ms jr my mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/1f687ca39b00d0b4b8e5398d3b37f830.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*jR2AVpT1AtP-3q5s_Jvk1w.jpeg"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk mz di na nb">Figure 1: Images of distant categories may look similar (be it by similar cooking methods (e.g. grill marks) or an overlap of characterizations, inter alia), but sure enough, don’t taste similar!</figcaption></figure></div><p id="6c6a" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">根据座右铭<em class="lz">分而治之</em>，教程被细分为<strong class="ld ir">个更小的部分</strong>:</p><p id="995f" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">根据目前的状态，超过 300，000 个食谱的最大德语数据集将被搜集和分析。我们假设使用机器学习可能会克服更传统的所谓查询方法的障碍:我们使用卷积神经网络(简称 CNN)将对象识别或烹饪法庭识别与在超过 80 万张图像的记录中搜索最近邻居(下一个邻居分类)相结合。这种组合可以帮助找到更有可能<strong class="ld ir"> </strong>的食谱，并且将分类引导到更有成效的方向，因为 CNN 的前 k 个类别与具有排序相关性的下一个相邻类别相比较。诸如<a class="ae kc" href="https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir"> Kendall Tau </strong> </a>的基于等级相关性的方法本质上测量两个项目在两个分级列表中处于相同顺序的概率。数学上，肯德尔τ计算如下</p><figure class="mo mp mq mr gt jr gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/cb9738d08cd634572cbf946745746249.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*4tAfykueT2XHPdeF6y-vMg.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">notation: Rithesh Agrawal</figcaption></figure><p id="63e3" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">在哪里</p><ul class=""><li id="c960" class="nd ne iq ld b le mj li mk lm nf lq ng lu nh ly ni nj nk nl bi translated">N =总对数</li><li id="1e1d" class="nd ne iq ld b le nm li nn lm no lq np lu nq ly ni nj nk nl bi translated">C =一致对的数量</li><li id="959a" class="nd ne iq ld b le nm li nn lm no lq np lu nq ly ni nj nk nl bi translated">D =不一致对的数量</li></ul><h1 id="362c" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">方法学</h1><p id="e988" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">管道由以下步骤描述:</p><ol class=""><li id="5bda" class="nd ne iq ld b le mj li mk lm nf lq ng lu nh ly nr nj nk nl bi translated">每个配方<strong class="ld ir"> R </strong>由<strong class="ld ir"> K </strong>张图片组成。对于这些图像中的每一个，从预训练的卷积神经网络中提取特征向量<strong class="ld ir"> w ∈ W </strong>(其已经在 ILSVRC 2014 图像识别竞赛中使用 1000 个类别上的数百万个图像进行了预训练)。不严格地说，特征向量在最后一个完全连接的层中形成图像的内部表示，就在 1000 类别的 Softmax 层之前。</li><li id="ea1f" class="nd ne iq ld b le nm li nn lm no lq np lu nq ly nr nj nk nl bi translated">这些特征向量<strong class="ld ir"> W </strong>然后通过 PCA(主成分分析)从一个<strong class="ld ir">N×4096</strong>矩阵减少到一个<strong class="ld ir">N×512</strong>矩阵。结果，选择与输入图像具有最小欧几里德距离的前 k 个图像。由于计算某种成对距离度量是计算密集型的，并且不能很好地扩展，我们将注意力转向变体 ANN(近似最近邻)。</li><li id="4366" class="nd ne iq ld b le nm li nn lm no lq np lu nq ly nr nj nk nl bi translated">此外，美国有线电视新闻网是用类别<strong class="ld ir"> C </strong>和<strong class="ld ir"> R </strong>食谱的图片来训练的。<strong class="ld ir"> C </strong>是使用一种流行的主题建模技术动态确定的，该技术被称为非负矩阵工厂化(NNMF)和配方名称的语义分析。结果，我们为配方中的每个图像获得了类别上的概率分布。</li><li id="e980" class="nd ne iq ld b le nm li nn lm no lq np lu nq ly nr nj nk nl bi translated">美国有线电视新闻网(CNN)的前 k 类(2。)与来自前 k 个光学相似图像(1。)与肯德尔τ相关。</li></ol><p id="76ce" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">图 2 概述了一般方法:</p><figure class="mo mp mq mr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ns"><img src="../Images/7cf1f203832188fcc833b96ad935fe50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9IFTICi0OoOEpOHX_gcK9w.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 2: (a) Each image <strong class="bd nt">k ∈ K </strong>is transformed into the image embedding <strong class="bd nt">w </strong>and pairwise euclidean distances (L2 Norm) are calculated to the image query <strong class="bd nt">q</strong>. (b) The query image <strong class="bd nt">q </strong>is classified with the fine-tuned VGG-16 and the probability distribution is compared to the euclidean distances.</figcaption></figure><p id="d981" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">1│── <strong class="ld ir">数据准备</strong> <br/> │ └──清算数据<br/> │ └──数据扩充</p><p id="c3fe" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">2)───<strong class="ld ir">数据分析和可视化，拆分数据(训练、有效、测试)</strong></p><p id="0b2f" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">3│── <strong class="ld ir">主题建模</strong> <br/> │ └──潜在狄利克雷分配(LDA) <br/> │ └──非负矩阵分解</p><p id="7c29" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">4│── <strong class="ld ir">特征提取</strong> <br/> │ └── k 近邻<br/> │ └── t-SNE 可视化</p><p id="c3ca" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">5│── <strong class="ld ir">迁移学习:训练预先训练好的 CNN(卷积神经网络)</strong> <br/> │ └── AlexNet、VGG、ResNet、GoogLeNet</p><p id="3e6c" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">6└── <strong class="ld ir">用烧瓶展开</strong></p><p id="60ba" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">每个部分都包含 Jupyter 笔记本，您可以在<a class="ae kc" href="https://github.com/Murgio/Food-Recipe-CNN" rel="noopener ugc nofollow" target="_blank"> Github 页面</a>上查看。</p></div><div class="ab cl nu nv hu nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="ij ik il im in"><h1 id="0603" class="kd ke iq bd kf kg ob ki kj kk oc km kn ko od kq kr ks oe ku kv kw of ky kz la bi translated">收集和准备数据</h1><p id="bb2e" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">为了能够训练模型，人们需要足够数量的数据(所谓的数据扩充和预训练模型的微调提供了一种补救措施)。只有通过这样的数据量，训练集的泛化能力才能不断提高到一定程度，测试集中的高精度才能实现。本教程的第一部分处理特征及其关系的数据采集、分析和可视化。</p><blockquote class="og oh oi"><p id="669f" class="lb lc lz ld b le mj lg lh li mk lk ll oj ml lo lp ok mm ls lt ol mn lw lx ly ij bi translated">无耻之徒:我正在开发一个 python 代码编辑器，它简化了数据分析和数据绘图。更多信息请访问:<a class="ae kc" href="https://muriz.me/products/möbius" rel="noopener ugc nofollow" target="_blank">莫比乌斯代码编辑器</a></p></blockquote><p id="fceb" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">谷歌研究总监彼得·诺维格在 2011 年的一次采访中透露</p><blockquote class="og oh oi"><p id="6752" class="lb lc lz ld b le mj lg lh li mk lk ll oj ml lo lp ok mm ls lt ol mn lw lx ly ij bi translated">我们没有更好的算法。我们只是有更多的数据。</p></blockquote><p id="68ad" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">无一例外，数据集的质量和数量都不容忽视。这就是为什么欧洲最大的烹饪平台会被刮:每个食谱，最后是 316'756 个食谱(截至 2017 年 12 月)，总共下载了 879'620 张图片。重要的是，下载时不要进行得太快，并保护有太多查询的服务器，因为否则禁止自己的 IP 地址会使数据收集更加困难。</p><p id="704f" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">更多的数据导致更多的维度，但更多的维度并不一定导致更好的模型及其表示。干扰学习的数据集中的偏离模式可能会被更多维度无意地放大，数据记录的概括和学习对于神经网络来说是不利的，信噪比降低。</p><p id="98d0" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">所有 30 万份食谱按日期排序:<a class="ae kc" href="http://www.chefkoch.de/rs/s30o3/Rezepte.html" rel="noopener ugc nofollow" target="_blank">http://www.chefkoch.de/rs/s30o3/Rezepte.html</a></p><p id="ff76" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">做网站报废的时候，尊重 robots.txt 文件很重要。一些管理员不希望机器人访问特定的目录。<a class="ae kc" href="https://www.chefkoch.de/robots.txt" rel="noopener ugc nofollow" target="_blank">https://www.chefkoch.de/robots.txt</a>提供:</p><pre class="mo mp mq mr gt om on oo op aw oq bi"><span id="8c41" class="or ke iq on b gy os ot l ou ov">User-agent: * # directed to all spiders, not just scooters<br/>Disallow: / cgi-bin<br/>Disallow: / stats<br/>Disallow: / pictures / photo albums /<br/>Disallow: / forumuploads /<br/>Disallow: / pictures / user /<br/>Disallow: / user /<br/>Disallow: / avatar /<br/>Disallow: / cms /<br/>Disallow: / products /<br/>Disallow: / how2videos /</span></pre><p id="cb47" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">列出了我们不感兴趣的目录，因此您可以放心地继续。尽管如此，我们还是建议采取一些措施，比如随机标题和在不同请求之间留出足够长的停顿时间，以避免网站被封禁。</p><pre class="mo mp mq mr gt om on oo op aw oq bi"><span id="88ab" class="or ke iq on b gy os ot l ou ov"><em class="lz"># Chefkoch.de Website</em><br/>CHEFKOCH_URL  = 'http://www.chefkoch.de'<br/>START_URL     = 'http://www.chefkoch.de/rs/s'<br/>CATEGORY      = '/Rezepte.html'</span><span id="6098" class="or ke iq on b gy ow ot l ou ov">category_url = START_URL + '0o3' + CATEGORY<br/><br/><strong class="on ir">def</strong> _get_html(url):<br/>    page = ''<br/>    <strong class="on ir">while</strong> page == '':<br/>        <strong class="on ir">try</strong>:<br/>            page = requests.get(url, headers=random_headers())<br/>        <strong class="on ir">except</strong>:<br/>            print('Connection refused')<br/>            time.sleep(10)<br/>            <strong class="on ir">continue</strong><br/>    <strong class="on ir">return</strong> page.text<br/><br/><strong class="on ir">def</strong> _get_total_pages(html):<br/>    soup = BeautifulSoup(html, 'lxml')<br/>    total_pages = soup.find('div', class_='ck-pagination qa-pagination').find('a', class_='qa-pagination-pagelink-last').text<br/>    <strong class="on ir">return</strong> int(total_pages)<br/><br/>html_text_total_pages = _get_html(category_url)<br/>total_pages = _get_total_pages(html_text_total_pages)<br/>print('Total pages: ', total_pages)</span><span id="6077" class="or ke iq on b gy ow ot l ou ov">Total pages:  10560</span></pre><p id="f23d" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">下一个重要步骤是选择不利于不重要数据的特征。为神经网络准备原始数据在实践中很常见。在第一遍中，下载配方名称、配方的平均应用、评级数量、难度级别、准备时间和发布日期。在第二遍中，然后是配料列表、配方文本、所有图像和配方打印的次数。有了这些功能，可以很好地描述数据记录，并帮助获得对数据集的深刻理解，这对选择算法很重要。</p><p id="9733" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">诸如配方名称、等级、上传配方的日期等数据。存储在 csv 文件中。如果配方有图像，缩略图会放在 search_thumbnails 文件夹中。我们将利用多重处理来确保更短的下载时间。更多信息请访问<a class="ae kc" href="https://docs.python.org/3.4/library/multiprocessing.html?highlight=process" rel="noopener ugc nofollow" target="_blank"> Python 的文档</a></p><pre class="mo mp mq mr gt om on oo op aw oq bi"><span id="3308" class="or ke iq on b gy os ot l ou ov"><strong class="on ir">def</strong> scrap_main(url):<br/>    print('Current url: ', url)<br/>    html = _get_html(url)<br/>    _get_front_page(html)<br/>    <em class="lz">#sleep(randint(1, 2))</em></span><span id="196d" class="or ke iq on b gy ow ot l ou ov">start_time = time()<br/><strong class="on ir">with</strong> Pool(15) <strong class="on ir">as</strong> p:<br/>    p.map(scrap_main, url_list)<br/>print("--- <strong class="on ir">%s</strong> seconds ---" % (time() - start_time))</span></pre><blockquote class="og oh oi"><p id="5baa" class="lb lc lz ld b le mj lg lh li mk lk ll oj ml lo lp ok mm ls lt ol mn lw lx ly ij bi translated">请注意，给定的代码已被缩短。完整的代码请访问<a class="ae kc" href="https://github.com/Murgio/Food-Recipe-CNN/blob/master/01_rezepte_download.ipynb" rel="noopener ugc nofollow" target="_blank">相应的 Jupyter 笔记本</a>。</p></blockquote><p id="f20c" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">接下来，我们需要刮成分列表，准备，标签和每个食谱的所有图像。</p><pre class="mo mp mq mr gt om on oo op aw oq bi"><span id="b87c" class="or ke iq on b gy os ot l ou ov"><strong class="on ir">def</strong> write_recipe_details(data):<br/>    dpath = DATAST_FOLDER + DFILE_NAME<br/>    <strong class="on ir">with</strong> open(dpath, 'a', newline='') <strong class="on ir">as</strong> f:<br/>        writer = csv.writer(f)<br/>        <strong class="on ir">try</strong>:<br/>            writer.writerow((data['link'],<br/>                             data['ingredients'],<br/>                             data['zubereitung'],<br/>                             data['tags'],<br/>                             data['gedruckt:'],<br/>                             data['n_pics']<br/>                             <em class="lz">#data['reviews'],</em><br/>                             <em class="lz">#data['gespeichert:'],</em><br/>                             <em class="lz">#data['Freischaltung:'],</em><br/>                             <em class="lz">#data['author_registration_date'],</em><br/>                             <em class="lz">#data['author_reviews']</em><br/>                            ))<br/>        <strong class="on ir">except</strong>:<br/>            writer.writerow('')</span></pre><p id="af0f" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">如果下载一切顺利，我们的数据如下所示:</p><ul class=""><li id="50ce" class="nd ne iq ld b le mj li mk lm nf lq ng lu nh ly ni nj nk nl bi translated">总共 879，620 张图片(35 GB)</li><li id="0547" class="nd ne iq ld b le nm li nn lm no lq np lu nq ly ni nj nk nl bi translated">316，756 个配方<br/>——其中 189，969 个包含一个或多个图片<br/> — —其中 107，052 个配方包含两个以上的图片<br/>——126，787 个不包含图片</li></ul></div><div class="ab cl nu nv hu nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="ij ik il im in"><h1 id="f4b1" class="kd ke iq bd kf kg ob ki kj kk oc km kn ko od kq kr ks oe ku kv kw of ky kz la bi translated"><strong class="ak">数据分析和可视化</strong></h1><h2 id="4a42" class="or ke iq bd kf ox oy dn kj oz pa dp kn lm pb pc kr lq pd pe kv lu pf pg kz ph bi translated">统计数字</h2><p id="6de5" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">为了获得第一印象，我们通常绘制一个热图，以获得对哪些可能的特征感兴趣的初步见解。</p><figure class="mo mp mq mr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pi"><img src="../Images/5d6db5d6b958174886528a4002751b46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5MHpY-ztxpZbUmP0AB4oEw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 3: The heatmap gives us insight which values correlate with other values.</figcaption></figure><p id="23ac" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">相关度最高的有<em class="lz">票</em>和<em class="lz">平均 _ 评分</em>。图 2 显示了第一列第二行的配对图，很明显，评分数越高，配方的评分越好。同样有趣的是准备时间和收视率数量的对比。大多数评论都是基于准备时间短的食谱。ChefKoch 社区似乎更喜欢简单的食谱。另一个想法是比较每年新上传食谱的数量。</p><figure class="mo mp mq mr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pj"><img src="../Images/17779bf7113ae2ab8fbc6d38e21bba83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KqNsBQNKt88_PIFnuGs7gA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 4: In the years 2008 to 2009, it has noticeably the most uploads per year. A quick search search on the internet shows that in 2008 the food price crisis had prevailed.</figcaption></figure><p id="622c" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">曲线对比(下图)显示，全球价格上涨和食谱供应之间存在虚假的相关性。我的假设是，对食谱的需求上升是因为一个人呆在家里为自己和家人做饭，以节省预算并尽可能使收支平衡。</p><figure class="mo mp mq mr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pk"><img src="../Images/e37d06eb0abee12436061b1ad1d19c49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dG0shK7kLKmYiGxfnIp28Q.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 5: On the left the <a class="ae kc" href="https://de.wikipedia.org/wiki/FAO_Food_Price_Index" rel="noopener ugc nofollow" target="_blank">index</a> and on the right the number of uploaded recipes per year.</figcaption></figure><h2 id="8e66" class="or ke iq bd kf ox oy dn kj oz pa dp kn lm pb pc kr lq pd pe kv lu pf pg kz ph bi translated">佐料</h2><p id="716a" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">一共<em class="lz"> 316'755 份食谱</em>分享<em class="lz"> 3'248'846 份配料</em>。如果去掉所有出现不止一次的成分，就有<em class="lz">63’588 种独特成分</em>。对于成分的关联分析，使用了 APRIORI 算法。这提供了什么成分与其他成分组合出现的频率。</p><figure class="mo mp mq mr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pl"><img src="../Images/cf2f092bda2f347499204388f16bfebf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cRXpudMOLIwwqcwbAq45RQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Table 1: On the left are the top 8 and on the right the top 9–16 ingredients with the highest incidence.</figcaption></figure><p id="d995" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">在所有的食谱中，盐占了 60%。在第三个位置，你可以看到第一个元组，两种成分的组合，即胡椒和盐，仅超过 40%，它们是迄今为止最常见的一对。最常见的三胞胎、四胞胎甚至五胞胎都可以在<a class="ae kc" href="https://github.com/Murgio/Food-Recipe-CNN/blob/master/03_02_zutaten_analysis_cloud.ipynb" rel="noopener ugc nofollow" target="_blank">对应的 Jupyter 笔记本</a>中找到。</p><p id="9b9f" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated"><em class="lz">更多图形详见</em> <a class="ae kc" href="https://github.com/Murgio/Food-Recipe-CNN/blob/master/03_01_rezepte_analysis_cloud.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="lz">本笔记本</em> </a> <em class="lz">。</em></p></div><div class="ab cl nu nv hu nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="ij ik il im in"><h1 id="99ad" class="kd ke iq bd kf kg ob ki kj kk oc km kn ko od kq kr ks oe ku kv kw of ky kz la bi translated">主题建模</h1><p id="b753" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">该程序的目标是<strong class="ld ir">将所有配方名称分为 n 类</strong>。对于监督分类问题，我们必须为神经网络提供带标签的图像。有了这些标签，学习才成为可能。问题是<strong class="ld ir"> Chefkoch.de 没有对他们的图片进行分类</strong>。分割 316’755 配方名称的可能程序如下所示。</p><p id="1445" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">到目前为止，考虑下面的例子，其中给出了四个配方名称:</p><ul class=""><li id="81ed" class="nd ne iq ld b le mj li mk lm nf lq ng lu nh ly ni nj nk nl bi translated">蘑菇披萨</li><li id="755d" class="nd ne iq ld b le nm li nn lm no lq np lu nq ly ni nj nk nl bi translated">青椒配豌豆和金枪鱼</li><li id="9b41" class="nd ne iq ld b le nm li nn lm no lq np lu nq ly ni nj nk nl bi translated">海鲜披萨</li><li id="a9e4" class="nd ne iq ld b le nm li nn lm no lq np lu nq ly ni nj nk nl bi translated">豌豆辣椒粉</li></ul><p id="dc2d" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">以上四个配方名称必须分为 n 类。一般来说，第一个和第三个食谱需要放在同一个类别中，可能叫做比萨饼。由于豌豆的原因，第二和第四食谱也可以被放入新的类别。但是，如何正确地对 300，000 多个食谱名称进行分类呢？</p><h2 id="b694" class="or ke iq bd kf ox oy dn kj oz pa dp kn lm pb pc kr lq pd pe kv lu pf pg kz ph bi translated">潜在狄利克雷分配</h2><p id="e9b0" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">概率主题建模(LDA，[Blei 等人，2003])和向量空间模型(LSA，[Deerwester 等人，1990])通过将文档建模为潜在主题集上的有限混合物或通过奇异值分解(SVD)来近似单词的含义。自从 Blei 等人[2003]的开创性工作以来，已经提出了类似的方法[Jagarlamudi 等人，2012]，通过在每个主题中提供种子词来指导模型学习期望的主题。也就是说，题目是提前知道的。</p><p id="1782" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">一般来说，在大多数 NLP 任务中，名称体必须被清理，即停用词被移除，词被减少到它们的根。干净的词汇作为输入。</p><pre class="mo mp mq mr gt om on oo op aw oq bi"><span id="7e09" class="or ke iq on b gy os ot l ou ov">de_stop = get_stop_words('german')<br/>s_stemmer = SnowballStemmer('german')<br/>tokenizer = RegexpTokenizer(r'\w+')<br/>final_names = []<br/><br/><strong class="on ir">for</strong> recipe_name <strong class="on ir">in</strong> twentyeigth_iter:<br/>    raw = recipe_name.lower()<br/>    tokens = tokenizer.tokenize(raw)<br/>    stop_t = [recipe_name <strong class="on ir">for</strong> recipe_name <strong class="on ir">in</strong> tokens <strong class="on ir">if</strong> <strong class="on ir">not</strong> recipe_name <strong class="on ir">in</strong> de_stop <strong class="on ir">and</strong> <strong class="on ir">not</strong> recipe_name <strong class="on ir">in</strong> filter_words_]<br/>    stem_t = [i <strong class="on ir">for</strong> i <strong class="on ir">in</strong> stop_t <strong class="on ir">if</strong> len(i)&gt;1]<br/>    <strong class="on ir">if</strong> len(stem_t)==0: final_names.append(['error'])<br/>    <strong class="on ir">else</strong>: final_names.append(stem_t)<br/><br/>print('20 Cleaned Recipe names example: <strong class="on ir">\n</strong> &gt;&gt;&gt;')<br/>pprint(final_names[:20])</span><span id="f0bb" class="or ke iq on b gy ow ot l ou ov">20 Cleaned Recipe names example: <br/> &gt;&gt;&gt;<br/>[['bratapfel', 'rotkohl'],<br/> ['frühstückswolke'],<br/> ['deichgrafensalat'],<br/> ['geschichteter', 'kohl'],<br/> ['rinderlendenragout'],<br/> ['blaukraut'],<br/> ['sauerbraten'],<br/> ['punschtorte'],<br/> ['oberländer'],<br/> ['mcmoes', 'pasta'],<br/> ['geschnetzeltes'],<br/> ['ahorn', 'bacon', 'butter'],<br/> ['endiviensalat'],<br/> ['rote', 'linsen', 'gemüse'],<br/> ['kotelett', 'gratin'],<br/> ['rotkohl'],<br/> ['remouladensauce'],<br/> ['nudeln'],<br/> ['kohlsuppe'],<br/> ['gemüse', 'hackfleischauflauf']]</span></pre><figure class="mo mp mq mr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pm"><img src="../Images/76984c85cd7f854539b2db095fd0717f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JIqd3yZP6yQNG5bl4RlRsQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 6: 300 topics were set as condition. The model for Topic 89 provides good results: drinks are detected and summarized.</figcaption></figure><p id="affc" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">为了简单起见，不讨论精确的数学定义。因此，我们有一个概率列表，可以确定模型符合主题的程度。例如:' 0.363 * '干贝'+ 0.165 * '麻辣'+ 0.124 * '夏日'+ 0.006 * "塔布莱"+ 0.004 * "燕麦饼干"。</p><p id="655c" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">在 Github Repo 的<a class="ae kc" href="https://github.com/Murgio/Food-Recipe-CNN/blob/master/04_01_topic_modeling.ipynb" rel="noopener ugc nofollow" target="_blank"> 04_01_topic_modeling.ipynb 中可以找到一个交互式图表来浏览 300 个主题中的每一个。</a></p><h2 id="649d" class="or ke iq bd kf ox oy dn kj oz pa dp kn lm pb pc kr lq pd pe kv lu pf pg kz ph bi translated">非负矩阵分解</h2><p id="ae72" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">第一步是计算 tf-idf(词频-逆文档频)。考虑到在整个文本语料库中的重要性，这仅仅代表了菜谱名称中的一个单词的<strong class="ld ir">重要性。最重要的四个词是:</strong></p><p id="03ea" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">1.【T4 沙拉(2935.18)】2。意大利面(2429.36) <br/> 3。托泰(2196.21) <br/> 4。蛋糕(1970.08)</p><p id="12bc" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">NMF 算法将 tf-idf 作为输入，并且<strong class="ld ir">同时执行降维和聚类</strong>。这一努力为前 4 个主题提供了出色的结果，如下所示:</p><p id="7b4e" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated"><strong class="ld ir">话题#0: </strong> <br/> <em class="lz">意面 carbonara alla olio aglio al sabo puttanesca di mare</em><br/><strong class="ld ir">话题#1: </strong> <br/> <em class="lz">沙拉什锦玉米瓜菊苣 bulgur 萝卜芹菜 q </em> uinoa 不冷不热<br/> <strong class="ld ir">话题#2: </strong> <br/> <em class="lz">面条中国亚洲米氏亚洲炒锅乌冬面罗勒黑光</em> <br/> <strong class="ld ir">话题#3: 【T28</strong></p><p id="81a0" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">因为我们不是疯子，所以我们从 0 开始索引。</p><p id="0f9b" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">使用 t-SNE 可以将结果可视化。重要的是，具有几个维度的记录被简化为 2D，这允许为每个配方名称找到一个坐标。</p><figure class="mo mp mq mr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/240a03ed3a5e9f02ef357645b8e170d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pOMs6vwmuBxHjMyjvHnNYg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 7: For further information visit the <a class="ae kc" href="https://github.com/Murgio/Food-Recipe-CNN/blob/master/04_02_topic_modeling_tsne_cloud.ipynb" rel="noopener ugc nofollow" target="_blank">corresponding Jupyter Notebook</a>.</figcaption></figure></div><div class="ab cl nu nv hu nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="ij ik il im in"><h1 id="72a7" class="kd ke iq bd kf kg ob ki kj kk oc km kn ko od kq kr ks oe ku kv kw of ky kz la bi translated"><strong class="ak">特征提取</strong></h1><p id="0b4a" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">对于 CNN，首先对图像信息进行汇总，以减少参数的数量。我们假设 CNN 中的第一层识别图片中的粗略结构。越深入到最后一个 Softmax 层，学习到的特征就越精细。我们可以利用这一点，采用预先训练的 CNN，这些 CNN 已经用数百万张图片进行了训练，并删除最后几层，用我们自己的数据来训练它们。这为我们节省了数百万个参数，从而减少了计算时间。这里选择的 CNN 是 VGG-16，它在 2014 年的分类比赛中接受了 1000 个类别的训练。</p><p id="39dd" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">如果去掉最后一层，我们就得到倒数第二层的特征提取器。这形成了 n×4096 矩阵，其中 n 是输入图片的数量。</p><pre class="mo mp mq mr gt om on oo op aw oq bi"><span id="0a7d" class="or ke iq on b gy os ot l ou ov">features = []<br/><strong class="on ir">for</strong> image_path <strong class="on ir">in</strong> tqdm(images):<br/>    img, x = get_image(image_path);<br/>    feat = feat_extractor.predict(x)[0]<br/>    features.append(feat)</span></pre><p id="1849" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">我们让 VGG-16 计算我们所有图像的向量。这个向量可以说是图片的指纹<strong class="ld ir"> : </strong>神经网络构建的内部表示。</p><div class="mo mp mq mr gt ab cb"><figure class="ms jr pn mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/786162846fed7833e29c46fd342e5784.png" data-original-src="https://miro.medium.com/v2/resize:fit:1540/format:webp/1*7ef7Dfupq4oFbG4q5V2NyA.png"/></div></figure><figure class="ms jr po mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/110b3f3096d3fb3cc63f4c987f0cb08d.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*OEB5rJ2toAhCrvfDzBHZ5w.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk pp di pq nb">Figure 8: (a) Left-side is plot the 4096 vector calculated from the cake on the right (b).</figcaption></figure></div><p id="2eae" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">现在，我们所要做的就是将每个新的给定输入图像通过 VGG-16，获得指纹向量，并使用近似最近邻搜索计算最近邻。我将为此使用的库是<a class="ae kc" href="https://github.com/FALCONN-LIB/FALCONN" rel="noopener ugc nofollow" target="_blank">法尔康</a>。FALCONN 是一个带有最近邻搜索算法的库。<strong class="ld ir">FALCONN 中的算法基于</strong> <a class="ae kc" href="https://en.wikipedia.org/wiki/Locality-sensitive_hashing" rel="noopener ugc nofollow" target="_blank"> <strong class="ld ir">局部敏感哈希</strong></a><strong class="ld ir">【LSH】</strong>，这是一类流行的高维空间最近邻搜索方法。FALCONN 的目标是为基于 LSH 的数据结构提供非常高效且经过充分测试的实现。</p><p id="f2b2" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">目前，FALCONN 支持两个 LSH 家族的余弦相似性:超平面 LSH 和十字多面体 LSH。这两个散列族都是用多探针 LSH 实现的，以便最大限度地减少内存使用。此外，FALCONN 针对密集和稀疏数据进行了优化。尽管 FALCONN 是为余弦相似性而设计的，但它通常可用于欧氏距离下的最近邻搜索或最大内积搜索。</p><p id="cf43" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">为了测试 choosen ANN 方法，我们传递了左边的布朗尼图像(图 9)，并如预期的那样收到了看起来相似的菜肴。</p><div class="mo mp mq mr gt ab cb"><figure class="ms jr pr mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/c707db857eb74552d6743140297450b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*OR4p3eF0oxCENHAlahHu0w.jpeg"/></div></figure><figure class="ms jr ps mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/5ad36eb812c4ede941299d845e3d09e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*sTcqGkTWrXBLK6Y98vBlfQ.png"/></div></figure></div><p id="a907" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">我们甚至可以创建一个图像网格来查看神经网络的解释。下图只是整个图像的一小部分。你可以看到有相似特征的烹饪菜肴靠得更近。整个网格可以在这里找到<a class="ae kc" href="https://github.com/Murgio/Food-Recipe-CNN/blob/master/output/tsne/20000-tSNE-grid-recipes.jpg" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="mo mp mq mr gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pt"><img src="../Images/8d75ddfe20e73d9847e2f9c79c72195f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z7GF7kDWLJMwHlH2_RDaFQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 10: Similar cooking dishes are closer to each other.</figcaption></figure></div><div class="ab cl nu nv hu nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="ij ik il im in"><h1 id="a066" class="kd ke iq bd kf kg ob ki kj kk oc km kn ko od kq kr ks oe ku kv kw of ky kz la bi translated">结论</h1><p id="0ee6" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们引入了一个新的数据集，将烹饪图像和相应的食谱结合在一起。我们强调了选择的食物领域和预先存在的图像分类任务之间的差异，并通过实验研究了卷积神经网络和近似最近邻方法的有效性。</p><p id="2839" class="pw-post-body-paragraph lb lc iq ld b le mj lg lh li mk lk ll lm ml lo lp lq mm ls lt lu mn lw lx ly ij bi translated">如何在没有预训练的情况下从头开始训练自己的神经网络，并使用 Flask 将我们的系统变成 web 应用程序(第五部分和第六部分)，将在下一篇教程中讨论。</p></div></div>    
</body>
</html>