<html>
<head>
<title>Journey to Understand Bayes’ Theorem Visually</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">直观理解贝叶斯定理之旅</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/journey-to-understand-bayes-theorem-visually-80b9fbf9f4f5?source=collection_archive---------10-----------------------#2018-12-15">https://towardsdatascience.com/journey-to-understand-bayes-theorem-visually-80b9fbf9f4f5?source=collection_archive---------10-----------------------#2018-12-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/f09fbb6295338dcaf26d1294c970b4dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*D7KNDgqRKjWC7JqW"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo by <a class="ae kc" href="https://unsplash.com/@rihok?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Riho Kroll</a> on <a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="9f1c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于机器学习工程师或数据科学专业人员来说，理解概率的概念是必须的。许多数据科学挑战性问题的解决方案本质上往往是概率性的。因此，更好地理解概率将有助于你更有效地理解和实现这些算法。</p><p id="d1d9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每当我阅读任何概率书籍或研究论文时，大多数时候我都发现这些书籍中的文献过于理论化。根据<a class="ae kc" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=587201" rel="noopener ugc nofollow" target="_blank">社会科学研究网</a>的数据，65%的人是视觉学习者。用图解法理解定理和证明是可视化信息和数据的有效方法，不仅如此，这种以可视化方式呈现数据的方法在很长一段时间内都被证明是有效的。所以通过这个博客，我想以一种视觉的方式展示概率的概念。</p><h1 id="7409" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">目录</h1><ol class=""><li id="2d40" class="lz ma iq kf b kg mb kk mc ko md ks me kw mf la mg mh mi mj bi translated">什么是条件概率？</li><li id="00df" class="lz ma iq kf b kg mk kk ml ko mm ks mn kw mo la mg mh mi mj bi translated">全概率定律</li><li id="11d3" class="lz ma iq kf b kg mk kk ml ko mm ks mn kw mo la mg mh mi mj bi translated">贝叶斯定理</li><li id="73d3" class="lz ma iq kf b kg mk kk ml ko mm ks mn kw mo la mg mh mi mj bi translated">贝叶斯定理的应用</li></ol><p id="172e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先让我们详细了解条件概率。</p><h1 id="5942" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">什么是条件概率？</h1><p id="453f" class="pw-post-body-paragraph kd ke iq kf b kg mb ki kj kk mc km kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">根据<a class="ae kc" href="https://en.wikipedia.org/wiki/Conditional_probability" rel="noopener ugc nofollow" target="_blank">维基百科</a> <strong class="kf ir">的说法，条件概率</strong>是在假设(通过假设、推测、断言或证据)另一事件已经发生的情况下，对一个事件(一些特定情况发生)的概率的度量。如果感兴趣的事件是<em class="ms"> A </em>且事件<em class="ms"> B </em>已知或假设已经发生，“给定<em class="ms"> B </em>的情况下<em class="ms"> A </em>的条件概率”，或“条件<em class="ms"> B </em>下<em class="ms"> A </em>的概率”，通常写成<em class="ms">P</em>(<em class="ms">A</em>|<em class="ms">B</em>，有时也写成<em class="ms">P<em class="ms"/></em></p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/8270ab1d04e7fe8d02849197de15b8fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/1*hut8AJBbpfpYsOC8fHx0hg.gif"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Source: <a class="ae kc" href="https://giphy.com" rel="noopener ugc nofollow" target="_blank">giphy.com</a></figcaption></figure><p id="8763" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这和我第一次读这本书时的反应是一样的。你们中的一些人一定已经通过<a class="ae kc" href="https://oscarbonilla.com/2009/05/visualizing-bayes-theorem/" rel="noopener ugc nofollow" target="_blank">维恩图方法</a>理解了它。所以现在让我们尝试用一种新的方法来直观地解释它。</p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div class="gh gi my"><img src="../Images/18536e26cdf7334757676d6dcc9cf949.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*QlBtIWvM8mHj7XywWYorQA.jpeg"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Conditional Probability Diagram</figcaption></figure><p id="e77d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设我们在从<strong class="kf ir">开始</strong>的时间线内开始观察。在我们开始观察时间线之后，事件 A 有可能发生。在 A 之后还有另一个事件 B 发生的可能性，其概率用<strong class="kf ir"> P(B|A) </strong>表示。</p><p id="e70d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于两个事件相继发生，整个时间线发生的概率(即<a class="ae kc" href="https://brilliant.org/wiki/rule-of-product/" rel="noopener ugc nofollow" target="_blank"> A 和 B 都发生</a>并且 B 发生在 A 之后)为</p><blockquote class="mz na nb"><p id="e60f" class="kd ke ms kf b kg kh ki kj kk kl km kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated">P(A)⋅港口</p></blockquote><p id="dae3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于我们考虑 A 和 B 都发生的概率，它也可以解释为<strong class="kf ir"> P(A ∩ B) </strong></p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/14bff4056c4d6f91c8ec4c07bc6b9e90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*TMRSEOTDvjsqVSHWZ_z-lw.jpeg"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Intersection Rule (A <strong class="bd ng">∩</strong> B)</figcaption></figure><p id="32ae" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，</p><blockquote class="mz na nb"><p id="8266" class="kd ke ms kf b kg kh ki kj kk kl km kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated">P(A <strong class="kf ir"> ∩ </strong> B) = P(A)⋅ P(B|A)</p></blockquote><p id="5f65" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里 P(B|A)被称为<strong class="kf ir">条件概率</strong>，因此可以简化为</p><blockquote class="mz na nb"><p id="60f0" class="kd ke ms kf b kg kh ki kj kk kl km kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated">P(B|A) = P(A <strong class="kf ir"> ∩ </strong> B)/P(A)，假设 P(A) ≠ 0</p></blockquote><blockquote class="nh"><p id="3d52" class="ni nj iq bd nk nl nm nn no np nq la dk translated">请注意，只有当事件相继发生并且相互依赖时，上述情况才有效。也有可能 A 不影响 B，如果是这样，那么这些事件是相互独立的，称为独立事件</p></blockquote><figure class="ns nt nu nv nw jr gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/b69ee14c0c14edd393a7c20b1e97ba24.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*URepolKaelntLV7ZiT-KHg.jpeg"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Independent Events</figcaption></figure><p id="aada" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，在独立事件的情况下，A 发生的几率不会影响 B 发生的几率。</p><blockquote class="mz na nb"><p id="6a19" class="kd ke ms kf b kg kh ki kj kk kl km kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated">P(B|A) = P(B)</p></blockquote><h1 id="52bd" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">全概率定律</h1><p id="649e" class="pw-post-body-paragraph kd ke iq kf b kg mb ki kj kk mc km kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">全概率法则将计算分成不同的部分。它用于确定一个事件的概率，该事件与前一个事件之前发生的两个或多个事件相关。</p><p id="9058" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">太抽象？让我们试试视觉方法</p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/333ee9c0f0af7daebab2dbdf698514c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*XeyItIOuDnd4rUuneWQYsQ.jpeg"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Total Probability Diagram</figcaption></figure><p id="b7c9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">设 B 是一个事件，它可以发生在任何“<strong class="kf ir"> n </strong>”事件(A1，A2，A3，…)之后..安)。如上定义<strong class="kf ir"> P(Ai ∩ B) = P(Ai)⋅P(B|Ai) ∀ i ∈[1，n] </strong></p><p id="86c8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">自从事件 A1，A2，A3，…an 是互斥的，不能同时出现，我们可以通过 A1 或 A2 或 A3 或……或 An 到达 B。因此,<a class="ae kc" href="https://brilliant.org/wiki/rule-of-sum/" rel="noopener ugc nofollow" target="_blank">求和规则</a>规定</p><blockquote class="mz na nb"><p id="62e7" class="kd ke ms kf b kg kh ki kj kk kl km kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated"><strong class="kf ir">P(B)= P(A1∩B)+P(A2∩B)+P(A3∩B)+…..+ P(An ∩ B) </strong></p><p id="d756" class="kd ke ms kf b kg kh ki kj kk kl km kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated">P(A1)⋅ P(B|A1) + P(A2)⋅ P(B|A2) + …..+ P(An)⋅ P(B|An)</p></blockquote><p id="58f0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上述表达式称为<strong class="kf ir">全概率法则</strong>或<strong class="kf ir">全概率法则</strong>。这也可以用<a class="ae kc" href="https://www.probabilitycourse.com/chapter1/1_4_2_total_probability.php" rel="noopener ugc nofollow" target="_blank">文氏图</a>来解释。</p><h1 id="7bdc" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">贝叶斯定理</h1><p id="c6f9" class="pw-post-body-paragraph kd ke iq kf b kg mb ki kj kk mc km kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">贝叶斯定理是一种基于某些概率的先验知识来预测起源或来源的方法</p><p id="9d1c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们已经知道<strong class="kf ir"> P(B|A) = P(A ∩ B)/P(A) </strong>，假设两个相互依存的事件 P(A) ≠ 0。有没有想过什么<strong class="kf ir"> P(A|B) =？</strong>，语义上没有任何意义，因为 B 发生在 A 之后，并且时间线不能反转(即我们不能从<strong class="kf ir"> B </strong>向上移动到<strong class="kf ir">开始</strong></p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/599235c4b65de727109dcc878ea12cc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*DbvGUwGskK0NvveghrVK9w.jpeg"/></div></figure><p id="2f3f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据条件概率，数学上我们知道</p><blockquote class="mz na nb"><p id="5982" class="kd ke ms kf b kg kh ki kj kk kl km kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated"><strong class="kf ir"> P(A|B) = P(B ∩ A)/P(B)，假设 P(B) ≠ 0 </strong></p><p id="4345" class="kd ke ms kf b kg kh ki kj kk kl km kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated"><strong class="kf ir"> P(A|B) = P(A ∩ B)/P(B)，as P(A ∩ B) = P(B ∩ A) </strong></p></blockquote><p id="d258" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们知道这一点</p><blockquote class="mz na nb"><p id="35bf" class="kd ke ms kf b kg kh ki kj kk kl km kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated"><strong class="kf ir"> P(A ∩ B) = P(B|A)⋅ P(A) </strong></p></blockquote><p id="a4ea" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">替换我们得到的值</p><blockquote class="mz na nb"><p id="17c4" class="kd ke ms kf b kg kh ki kj kk kl km kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated"><strong class="kf ir">p(a | b)=p(b|a)⋅p(a)/p(b)</strong></p></blockquote><p id="c96c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是贝叶斯定理的最简单形式。</p><p id="947b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，假设<strong class="kf ir"> B </strong>相互依赖于在它之前发生的多个事件。将<strong class="kf ir">全概率规则</strong>应用于上述表达式，我们得到</p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/68dfa80a70335563fc0e5df922ec5da4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*pthHVPTki-IQks6uZOQO0A.jpeg"/></div></figure><blockquote class="mz na nb"><p id="68c1" class="kd ke ms kf b kg kh ki kj kk kl km kn nc kp kq kr nd kt ku kv ne kx ky kz la ij bi translated">p(ai | b)=p(b|ai)⋅p(ai)/(p(a1)⋅p(b | a1)+…..+ P(An)⋅ P(B|An)) </p></blockquote><p id="0cb7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是我们通常在各种现实世界应用中使用的贝叶斯定理的形式。</p><h1 id="135f" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">贝叶斯定理的应用</h1><p id="cdd4" class="pw-post-body-paragraph kd ke iq kf b kg mb ki kj kk mc km kn ko mp kq kr ks mq ku kv kw mr ky kz la ij bi translated">由于它的预测性质，我们使用贝叶斯定理来推导朴素贝叶斯，这是一个流行的机器学习分类器</p><p id="83c1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如您所知，贝叶斯定理基于可能与事件相关的因素的先验知识来定义事件的概率。</p><p id="d681" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，基本上对于一个数据点 xi，我们必须预测当前输出 Y 属于哪一类。假设总共有“j”个类用于输出。<br/>然后，<br/>P(y = c1 | x = xi)——&gt;告诉我们，对于给定的输入 Xi，y 是 C1 的概率是多少。<br/>P(y = c2 | x = xi)——&gt;告诉我们，对于给定的输入 Xi，y 是 C2 的概率是多少。<br/>以此类推直到 cj。</p><p id="cc5d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在所有这些概率计算中，y 属于具有最大概率的特定类别。</p><p id="f88a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用贝叶斯定理来做这些概率计算。</p><p id="7b05" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这为我们提供了数据点(xi)的当前值的输出属于第 j 类的概率。<br/>因为对于所有的类 1，2，…，j，分母将具有相同的值，所以我们在进行比较时可以忽略这一点。因此，我们得到了计算概率的公式。</p><p id="7193" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">为什么叫幼稚？还是天真的假设</strong></p><p id="ed57" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们之所以称之为幼稚，是因为我们做了一个简单的假设，即一个类中特定特性的存在与任何其他特性的存在无关，这意味着每个特性都是相互独立的。</p><p id="ae91" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">概率 P(y=cj)的估计可以直接从训练点的数量来完成。<br/>假设有 100 个训练点和 3 个输出类别，10 个属于类别 c1，40 个属于类别 C2，剩余的 50 个属于类别 C3。<br/>类别概率的估计值将为:<br/>P(y = C1)= 10/100 = 0.1<br/>P(y = C2)= 40/100 = 0.4<br/>P(y = C3)= 50/100 = 0.5</p><p id="1550" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了对 P(x=xi|y=cj)进行概率估计，朴素贝叶斯分类算法假设<strong class="kf ir">所有特征都是独立的</strong>。因此，对于第 j 个类的输出，我们可以通过分别乘以所有这些特征获得的概率(假设特征是独立的)来计算这一点。</p><p id="70dc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">P(x = Xi | y = CJ)= P(x = Xi(1)| y = CJ)P(x = Xi(2)| y = CJ)…。P(x=xi(n)|y=cj)</p><p id="fad9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，xi(1)表示第 I 个数据点的第 1 特征的值，x=xi(n)表示第 I 个数据点的第 n 特征的值。</p><p id="fc29" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在接受了天真的假设后，我们可以很容易地计算出个体的概率，然后简单地将结果相乘，计算出最终的概率 P’。</p><p id="6b1d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用上面的公式，对于给定的第 I 个数据点，我们可以计算输出 y 属于第 j 类的概率。</p><p id="0595" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是贝叶斯定理在现实世界中的一个主要应用</p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/3ca008139bd14910edaaa527d895d7e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:352/1*w3rZLtt11wcJVQ3xH4WQlw.gif"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Source: <a class="ae kc" href="https://giphy.com" rel="noopener ugc nofollow" target="_blank">giphy.com</a></figcaption></figure></div></div>    
</body>
</html>