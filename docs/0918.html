<html>
<head>
<title>A word cloud of words used in Abstract</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">摘要中使用的单词云</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-word-cloud-of-words-used-in-abstract-1d07613770f?source=collection_archive---------9-----------------------#2017-07-09">https://towardsdatascience.com/a-word-cloud-of-words-used-in-abstract-1d07613770f?source=collection_archive---------9-----------------------#2017-07-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="ff26" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我真的很喜欢《抽象》——网飞的系列设计纪录片。这是那种让你不想被动消费和创造的内容。</p><p id="1de1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我一直在R中玩文本分析，并决定应用我最近接触到的一些技术，创建一个包含节目中使用的所有单词的单词云。像所有数据科学项目一样，这个项目始于数据采集。网飞提供多种语言的字幕。每次你打开字幕或者改变语言，它都会下载。花了几分钟时间在Chrome中找到请求:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/b9026b98ea7fba1adf02cdab5415585c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2f8It-EIBBEMLZMFnFU7aw.png"/></div></div></figure><p id="6c02" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于这部电视剧只有8集，我没有尝试自动下载每集的英文字幕，而是手动下载。</p><p id="aeff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">字幕以TTML格式提供。对于创建单词云，我只对文件中的文本内容感兴趣，对时间或字体数据不太感兴趣。因此，我没有尝试寻找一个专门的TTML处理库，而是编写了一个快速的Python脚本，将每个文件简单地视为另一个XML文件，并将每集的文本转储到一个制表符分隔的文件中:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="kx ky l"/></div></figure><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="8dd9" class="le lf iq la b gy lg lh l li lj">episode script<br/>1 [director] Part of this is I’m trying to figure out some of the...<br/>2 [sea birds calling] [Tinker] I probably think about feet a lot ...<br/>3 [Es] Over the last two decades of working, one of the things I'...<br/>.<br/>.<br/>.</span></pre><p id="3e9f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下一步是在r中读取这个文件。我使用了通用的<code class="fe lk ll lm la b">read.csv</code>,但它没有像预期的那样工作。</p><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="f09a" class="le lf iq la b gy lg lh l li lj">&gt; d &lt;- read.csv('~/proj/abstract.tsv', sep="\t")<br/>&gt; str(d)<br/>'data.frame': 3 obs. of  2 variables:<br/> $ <strong class="la ir">episode: int  6 7 8</strong><br/> $ script : Factor w/ 3 levels "[Ilse] Some people think interior design is a look. In fact, It must be really fun buying furniture is somethin"| __truncated__,..: 2 3 1</span></pre><p id="342e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">数据框只有3行。它清楚地读取了整个文件，因为它从标题(剧集，剧本)中选择了列名，并得到了最后3行，但我很困惑为什么<code class="fe lk ll lm la b">read.csv</code>会跳过第1-5行。我试图将<code class="fe lk ll lm la b">as.is=T</code>参数传递给<code class="fe lk ll lm la b">read.csv</code>以防止它将字符串解释为因子，但这并不能阻止它跳过第1–5行。</p><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="745f" class="le lf iq la b gy lg lh l li lj">'data.frame': 3 obs. of  2 variables:<br/> $ <strong class="la ir">episode: int  6 7 8</strong><br/> $ script : chr  "[Paula] I walk outside and I see typography everywhere. New York City is a city of signs. Sometimes things writ"| __truncated__ "[Platon] I'm not really a photographer at all. The camera is nothing more than a tool. Communication, simplicit"| __truncated__ "[Ilse] Some people think interior design is a look. In fact, It must be really fun buying furniture is somethin"| __truncated__</span></pre><p id="b6f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最终，我从<code class="fe lk ll lm la b">data.table</code>套餐中选择了<code class="fe lk ll lm la b">fread</code>,它非常管用:</p><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="fea2" class="le lf iq la b gy lg lh l li lj">&gt; library(data.table)<br/>&gt; d &lt;- fread('~/proj/abstract.tsv')<br/>&gt; str(d)<br/>Classes ‘data.table’ and 'data.frame': 8 obs. of  2 variables:<br/> $ <strong class="la ir">episode: int  1 2 3 4 5 6 7 8</strong><br/> $ script : chr  "[director] Part of this is I'm trying to figure out some of the big picture things. How aesthetically to tell y"| __truncated__ "[sea birds calling] [Tinker] I probably think about feet a lot more than the average person. As a shoe designer"| __truncated__ "[Es] Over the last two decades of working, one of the things I've discovered is often things are made to fill v"| __truncated__ "[director] Is this going to be a slapstick comedy? Is it an action film? You know, let's have fun with it. -Yea"| __truncated__ ...<br/> - attr(*, ".internal.selfref")=&lt;externalptr&gt; </span></pre><p id="0c99" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下一步是将脚本分解成单词。<code class="fe lk ll lm la b">tidytext</code>包帮助我们做到了这一点(甚至更多):</p><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="c4bf" class="le lf iq la b gy lg lh l li lj">&gt; library(tidytext)<br/>&gt; words &lt;- unnest_tokens(d, word, script)<br/>&gt; head(words)<br/>   episode     word<br/>1:       1 director<br/>2:       1     part<br/>3:       1       of<br/>4:       1     this<br/>5:       1       is<br/>6:       1      i'm</span></pre><p id="e863" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们来数一数每个单词:</p><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="0772" class="le lf iq la b gy lg lh l li lj">&gt; library(dplyr)<br/>&gt; words %&gt;% group_by(word) %&gt;% summarise(count=n()) %&gt;% arrange(desc(count))<br/># A tibble: 5,047 x 2<br/>    word count<br/>   &lt;chr&gt; &lt;int&gt;<br/> 1   the  1863<br/> 2   and  1262<br/> 3     a  1217<br/> 4    to  1170<br/> 5     i  1135<br/> 6    of   985<br/> 7  that   878<br/> 8    it   796<br/> 9    in   681<br/>10   you   681<br/># ... with 5,037 more rows</span></pre><p id="ba67" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，正如您所料，我们在脚本中最常用的词大多是停用词。移除它们实际上非常简单:</p><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="b40d" class="le lf iq la b gy lg lh l li lj">&gt; words &lt;- words %&gt;% <strong class="la ir">anti_join(stop_words)</strong><br/>&gt; words %&gt;% group_by(word) %&gt;% summarise(count=n()) %&gt;% arrange(desc(count))<br/># A tibble: 4,496 x 2<br/>      word count<br/>     &lt;chr&gt; &lt;int&gt;<br/> 1  people   157<br/> 2  design   123<br/> 3    time   110<br/> 4   music   107<br/> 5 playing    97<br/> 6     car    66<br/> 7    yeah    66<br/> 8    feel    56<br/> 9    idea    50<br/>10   world    50<br/># ... with 4,486 more rows</span></pre><p id="9cdd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在引起我注意的是“音乐”这个词是第四个最常用的词。据我回忆，除了第三集有Ev Devlin，这个系列没有太多关于音乐的内容。当我在文本编辑器中打开由TTML文件生成的标签限定的文件，并搜索“音乐”时，这个词出现频率如此之高的原因对我来说变得很清楚。字幕中提到了很多背景音乐，例如，我仅在第一集就发现了以下短语:</p><p id="85ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[电子音乐继续播放]，[电子音乐结束]，[不祥的音乐播放]，[平静的音乐播放]，[乐观的钢琴音乐播放]，[爵士音乐播放]，[电子音乐播放]，[电子音乐继续]，[编钟音乐播放]，[平静的音乐播放]，[平静的音乐继续]，[编钟音乐播放]，[乐观的音乐播放]，[器乐播放]</p><p id="a863" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我使用正则表达式从脚本中删除这些短语，并重复上面的步骤来获得单词及其计数:</p><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="5758" class="le lf iq la b gy lg lh l li lj">&gt; d$script &lt;- gsub('\\[(?:\\w+\\s){0,3}music(?:\\s\\w+){0,3}\\]', "", d$script, perl=T)<br/>&gt; words &lt;- unnest_tokens(d, word, script)<br/>&gt; words &lt;- words %&gt;% anti_join(stop_words)<br/>&gt; words %&gt;% group_by(word) %&gt;% summarise(count=n()) %&gt;% arrange(desc(count))<br/>&gt; words<br/># A tibble: 4,485 x 2<br/>     word count<br/>    &lt;chr&gt; &lt;int&gt;<br/> 1 people   157<br/> 2 design   123<br/> 3   time   110<br/> 4    car    66<br/> 5   yeah    66<br/> 6   feel    56<br/> 7   idea    50<br/> 8  world    50<br/> 9  ralph    49<br/>10   love    48<br/># ... with 4,475 more rows</span></pre><p id="4f4e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好多了。一旦我们有了单词和它们的数量，制作单词云就很容易了:</p><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="2bfd" class="le lf iq la b gy lg lh l li lj">&gt; library(wordcloud)<br/>&gt; words %&gt;% count(word) %&gt;% with(wordcloud(word, n, max.words=50, min.freq=5, color='purple4', random.order=F))</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ln"><img src="../Images/a7baad7064dc97a18bb533888ffdac6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Iey4-tsRxdqmiVCm3isXRQ.png"/></div></div></figure><p id="5c27" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">每集制作一个单词云同样简单:</p><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="2f7a" class="le lf iq la b gy lg lh l li lj">&gt; par(mfrow=c(2,4))<br/>&gt; colors &lt;- c("blue","green4","green","gold","orange","orange3","red","red3")<br/>&gt; for (i in 1:8) {<br/>    words %&gt;% filter(episode == i) %&gt;% count(word) %&gt;% with(wordcloud(word, n, max.words=50, min.freq=5,color=colors[i],random.order=F))<br/>}</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi lo"><img src="../Images/52324ecf47d4e8768ff4af2fc46992ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X0rTMTuS6i6AIQi75yUfVA.png"/></div></div></figure><p id="b040" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里还可以做更多的事情——例如，请注意，在廷克·哈特菲尔德的单词cloud中，单词shoe和shoes重复出现——我们可以在绘制单词cloud之前通过单数化这些单词来解决这个问题。</p><p id="0d67" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你对用R分析文本感兴趣，我强烈推荐<a class="ae lp" href="http://tidytextmining.com" rel="noopener ugc nofollow" target="_blank">用R进行文本挖掘:一种整洁的方法</a>这本书。</p><p id="d3ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">更新:</strong>我发现了为什么<code class="fe lk ll lm la b">read.csv</code>跳过了前五行——文件中的大量引号与其默认的引用行为产生了不良影响。因此，如果您更愿意使用<code class="fe lk ll lm la b">read.csv</code>而不是<code class="fe lk ll lm la b">fread</code>，请将<code class="fe lk ll lm la b">quote</code>参数设置为空字符串:</p><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="e21f" class="le lf iq la b gy lg lh l li lj">d &lt;- read.csv("~/proj/abstract.tsv", sep="\t", <strong class="la ir">quote=""</strong>, as.is=T)</span></pre></div></div>    
</body>
</html>