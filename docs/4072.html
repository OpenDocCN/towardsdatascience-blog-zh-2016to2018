<html>
<head>
<title>Clustering on mixed type data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">混合类型数据的聚类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/clustering-on-mixed-type-data-8bbd0a2569c3?source=collection_archive---------0-----------------------#2018-07-16">https://towardsdatascience.com/clustering-on-mixed-type-data-8bbd0a2569c3?source=collection_archive---------0-----------------------#2018-07-16</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><figure class="it iu gq gs iv iw gi gj paragraph-image"><div role="button" tabindex="0" class="ix iy di iz bf ja"><div class="gi gj is"><img src="../Images/9b4d59f5a8552c7d52dc6297a3a48542.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B93nsMh-BbomYbRTm5p4Dg.jpeg"/></div></div><figcaption class="jd je gk gi gj jf jg bd b be z dk">Which methodology to group individuals based on their common patterns and similarities when expressed in multiple data types?</figcaption></figure><div class=""/><div class=""><h2 id="8ca6" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">一种使用 R</h2></div><h2 id="9e09" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">关于；在…各处 ；大约</h2><p id="d9da" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm in bi translated"><strong class="lw jk">聚类</strong> <a class="ae mn" href="https://en.wikipedia.org/wiki/Unsupervised_learning" rel="noopener ugc nofollow" target="_blank"> <strong class="lw jk">无监督数据</strong> </a> <strong class="lw jk">并不是一件容易的事情</strong>。事实上，在这种情况下，数据处理和探索通常是由领域知识驱动的，如果不是纯粹的直觉，并且由于没有方法来测量所得分割的准确性(与监督学习相反)，因此变得很困难。</p><p id="d2a0" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated">此外，<strong class="lw jk">无监督学习的入门课程相当经常地讨论理想的用例</strong>，比如 k-means 教程，它只适用于数字特征。</p><p id="c43f" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated">然而，<strong class="lw jk">真实的业务情况往往会偏离这些理想的用例</strong>，需要分析由<strong class="lw jk">混合类型数据</strong>、<strong class="lw jk">构成的数据集，其中数值</strong>(两个值的差是有意义的)<strong class="lw jk">、名义</strong>(分类的，不排序的)或<strong class="lw jk">序数</strong>(分类的，排序的)<strong class="lw jk">特征共存</strong>。</p><p id="f1cd" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated">在这篇文章中，我将关注这种情况，在使用 R 的无监督分类练习<strong class="lw jk">的背景下。</strong></p><ul class=""><li id="be6a" class="mt mu jj lw b lx mo ma mp lh mv ll mw lp mx mm my mz na nb bi translated">第一部分包括<strong class="lw jk">方法论</strong>:我正在讨论<strong class="lw jk">使用距离的数学概念来衡量个体之间的相似性</strong>的问题。然后，我将介绍 PAM <strong class="lw jk">聚类算法</strong>(围绕 medoids 进行划分)以及一种选择最佳聚类数(轮廓系数)的方法<strong class="lw jk">。我最后用一句话来结束对<strong class="lw jk">的解读</strong>。</strong></li><li id="c39a" class="mt mu jj lw b lx nc ma nd lh ne ll nf lp ng mm my mz na nb bi translated">在第二部分中，我将使用 uci 的<a class="ae mn" href="https://archive.ics.uci.edu/ml/datasets/Bank+Marketing" rel="noopener ugc nofollow" target="_blank">机器学习库</a>上的银行营销数据集以及来自<code class="fe nh ni nj nk b">cluster</code>和<code class="fe nh ni nj nk b">Rtsne</code>包的一些有用的函数来说明方法<strong class="lw jk">。该数据集与葡萄牙银行机构的直接营销活动(电话)相关，传统上用于监督学习讨论(分类目标是预测客户是否会认购定期存款)。但是，它包含一些关于<strong class="lw jk">银行客户的信息，我们将尝试对这些信息进行“先验”聚类</strong>。</strong></li></ul><p id="ad77" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated">我们开始吧！</p></div><div class="ab cl nl nm hy nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="in io ip iq ir"><h1 id="5391" class="ns kz jj bd la nt nu nv ld nw nx ny lg kp nz kq lk ks oa kt lo kv ob kw ls oc bi translated">第一部分:方法</h1><h2 id="82d0" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">如何度量相似度</h2><figure class="oe of og oh gu iw gi gj paragraph-image"><div role="button" tabindex="0" class="ix iy di iz bf ja"><div class="gi gj od"><img src="../Images/df7e60213466986494def3dbfb460e0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R-1jRqX1jT2x5ciVYq02og.png"/></div></div><figcaption class="jd je gk gi gj jf jg bd b be z dk">Data Scientists aiming at clustering ‘unknown’ data, sometimes without business knowledge, use distance to avoid subjectivity and ensure consistent approach to all features</figcaption></figure><p id="e20e" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated"><strong class="lw jk">距离</strong>是个体之间距离的数值度量，即用于测量个体之间的接近度或相似度的度量。存在许多距离度量，其中一个实际上对破解我们的案例非常有用，那就是<strong class="lw jk">高尔距离</strong> (1971)。</p><p id="34fc" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated">高尔距离被计算为个体间部分差异的平均值。每个部分不相似性(以及高尔距离)在[0±1]范围内。</p><figure class="oe of og oh gu iw gi gj paragraph-image"><div class="gi gj oi"><img src="../Images/0ae45bfc9e69f4a8e7afcc6cc258cbc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*0k6YFgMc-SF8qLlJlzTJHg.png"/></div><figcaption class="jd je gk gi gj jf jg bd b be z dk">Gower distance’s formula</figcaption></figure><p id="6c19" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated"><strong class="lw jk">部分相异</strong> ( <code class="fe nh ni nj nk b">d_ij^f</code> ) <strong class="lw jk">计算取决于被评估变量的类型</strong>。这意味着将对每个特征应用特定的标准化，并且两个个体之间的距离是所有特征特定距离的平均值。</p><ul class=""><li id="3352" class="mt mu jj lw b lx mo ma mp lh mv ll mw lp mx mm my mz na nb bi translated">对于一个<strong class="lw jk">数字特征</strong> <code class="fe nh ni nj nk b"><strong class="lw jk">f</strong></code>，偏相异度是 1)观察值<code class="fe nh ni nj nk b">x_i</code>和<code class="fe nh ni nj nk b">x_j</code>的绝对差值与 2)从所有个体观察到的最大范围:<code class="fe nh ni nj nk b">d_ij^f = |x_i — x_j| / |(max_N(x) — min_N(x))|</code>，N 是数据集中个体的数量。</li></ul><figure class="oe of og oh gu iw gi gj paragraph-image"><div class="gi gj oj"><img src="../Images/d4987607fcf6dd28036b6a44f5bb048f.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*mEVeRxXK9jn25q2zthdzbA.png"/></div><figcaption class="jd je gk gi gj jf jg bd b be z dk">Partial dissimilarity computation for numerical features (R_f = maximal range observed)</figcaption></figure><ul class=""><li id="622d" class="mt mu jj lw b lx mo ma mp lh mv ll mw lp mx mm my mz na nb bi translated">对于一个<strong class="lw jk">定性的</strong>特征<code class="fe nh ni nj nk b">f</code>，只有当观测值<code class="fe nh ni nj nk b">y_i</code>和<code class="fe nh ni nj nk b">y_j</code>具有不同的值时，偏相异度才等于 1。否则为零。</li></ul><p id="a1f4" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated"><strong class="lw jk">注</strong>:使用<code class="fe nh ni nj nk b">cluster </code>包中的<code class="fe nh ni nj nk b">daisy()</code>功能，可在<strong class="lw jk"> R </strong>中获得更高的距离。特征首先自动<strong class="lw jk">标准化</strong>(即重新调整至[0 1]范围内)。</p><h2 id="0af4" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">聚类算法:<strong class="ak">MEDOIDS 周围划分(PAM) </strong></h2><p id="3b13" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm in bi translated">高尔距离非常符合<a class="ae mn" href="https://en.wikipedia.org/wiki/K-medoids" rel="noopener ugc nofollow" target="_blank"> k-medoids 算法</a>。k-medoid 是一种经典的聚类划分技术，它将 n 个对象的数据集聚类成 k 个先验已知的聚类<strong class="lw jk"/>。</p><p id="c429" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated">与<a class="ae mn" href="https://en.wikipedia.org/wiki/K-means_clustering" rel="noopener ugc nofollow" target="_blank"> k-means 算法</a>非常相似，PAM 具有以下特征:</p><ul class=""><li id="90ec" class="mt mu jj lw b lx mo ma mp lh mv ll mw lp mx mm my mz na nb bi translated"><strong class="lw jk">优点</strong>:与 k-means 相比，它直观、对噪声和异常值更鲁棒(由于所使用的距离属性)，并且它为每个聚类产生一个“典型个体”(对解释有用)。</li><li id="81d8" class="mt mu jj lw b lx nc ma nd lh ne ll nf lp ng mm my mz na nb bi translated"><strong class="lw jk">缺点</strong>:耗时耗机(运行时间和内存是二次的)。</li></ul><h2 id="253e" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">评估数据集群内的一致性</h2><p id="c71f" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm in bi translated">除非你有一个很好的先验原理来强制一个特定的<strong class="lw jk">数量的簇 k </strong>，否则你可能会对<strong class="lw jk">向</strong>计算机<strong class="lw jk">询问一个基于统计的推荐</strong>感兴趣。<a class="ae mn" href="https://en.wikipedia.org/wiki/Cluster_analysis#Evaluation_and_assessment" rel="noopener ugc nofollow" target="_blank">存在几种方法</a>来限定所选数量的聚类的相关性。在第二部分中，我们使用<strong class="lw jk">轮廓系数</strong>。</p><p id="56bf" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated"><a class="ae mn" href="https://en.wikipedia.org/wiki/Silhouette_(clustering)" rel="noopener ugc nofollow" target="_blank">轮廓系数</a>将到同一簇中元素的平均距离与到其他簇中元素的平均距离进行对比。具有高轮廓值的对象被认为是良好聚类的，具有低值的对象可能是异常值。<strong class="lw jk">该指标</strong>适用于 k-medoids 聚类，并且<strong class="lw jk">也</strong>用于确定最优聚类数。请阅读维基百科页面，了解关于计算和解释的更多细节。</p><h2 id="c1d2" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">解释</h2><p id="7a5f" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm in bi translated">基本上有两种方法来研究这种聚类工作的结果，以便得出一些与业务相关的解释。</p><ul class=""><li id="c9ca" class="mt mu jj lw b lx mo ma mp lh mv ll mw lp mx mm my mz na nb bi translated">1.<strong class="lw jk">每簇</strong>的汇总，使用 r 中的<code class="fe nh ni nj nk b">summary()</code>函数</li><li id="5dd2" class="mt mu jj lw b lx nc ma nd lh ne ll nf lp ng mm my mz na nb bi translated">2.<strong class="lw jk">低维空间中的可视化</strong>，使用<a class="ae mn" href="https://lvdmaaten.github.io/tsne/" rel="noopener ugc nofollow" target="_blank"> t-SNE </a>，使用 r . t-分布式随机邻居嵌入(t-SNE)中的<code class="fe nh ni nj nk b">Rtsne()</code>函数是一种降维技术，特别适合于高维数据集的可视化。</li></ul><p id="5394" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated">我们在用例(第二部分)中涵盖了这两种情况。理论够了，来应用和举例说明吧！</p></div><div class="ab cl nl nm hy nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="in io ip iq ir"><h1 id="4c97" class="ns kz jj bd la nt nu nv ld nw nx ny lg kp nz kq lk ks oa kt lo kv ob kw ls oc bi translated">第二部分:用例</h1><p id="2107" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm in bi translated">在这个用例中，我们将尝试根据以下特征对银行客户进行聚类:</p><ul class=""><li id="6eb5" class="mt mu jj lw b lx mo ma mp lh mv ll mw lp mx mm my mz na nb bi translated"><strong class="lw jk">年龄</strong>(数字)</li><li id="bc69" class="mt mu jj lw b lx nc ma nd lh ne ll nf lp ng mm my mz na nb bi translated"><strong class="lw jk">工作类型</strong>(分类):‘行政’、'蓝领'、'企业家'、'女佣'、'管理'、'退休'、'个体户'、'服务'、'学生'、'技术员'、'失业'、'未知'</li><li id="eb3b" class="mt mu jj lw b lx nc ma nd lh ne ll nf lp ng mm my mz na nb bi translated"><strong class="lw jk">婚姻状况</strong>(分类):“离婚”、“已婚”、“单身”、“未知”</li><li id="8ab5" class="mt mu jj lw b lx nc ma nd lh ne ll nf lp ng mm my mz na nb bi translated"><strong class="lw jk">教育</strong>(分类):“初级”、“中级”、“高级”、“未知”</li><li id="8fc8" class="mt mu jj lw b lx nc ma nd lh ne ll nf lp ng mm my mz na nb bi translated"><strong class="lw jk">违约</strong>:有信用违约？(分类):“否”、“是”、“未知”</li><li id="89d0" class="mt mu jj lw b lx nc ma nd lh ne ll nf lp ng mm my mz na nb bi translated"><strong class="lw jk">余额</strong>(数字):年平均余额，单位为欧元</li><li id="cb06" class="mt mu jj lw b lx nc ma nd lh ne ll nf lp ng mm my mz na nb bi translated"><strong class="lw jk">住房</strong>:有住房贷款？(分类):“否”、“是”、“未知”</li></ul><pre class="oe of og oh gu ok nk ol om aw on bi"><span id="a355" class="ky kz jj nk b gz oo op l oq or">#' Load useful packages<br/>library(cluster)<br/>library(dplyr)<br/>library(ggplot2)<br/>library(readr)<br/>library(Rtsne)</span><span id="c498" class="ky kz jj nk b gz os op l oq or">#' Load data<br/>df &lt;- read_csv2("../data/001_unsupervised_mixed_types_data/bank.csv")</span></pre><p id="5e00" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated">根据高尔距离，最相似和最不相似的客户:</p><pre class="oe of og oh gu ok nk ol om aw on bi"><span id="3b1c" class="ky kz jj nk b gz oo op l oq or">#' Compute Gower distance<br/>gower_dist &lt;- daisy(df, metric = "gower")</span><span id="ade2" class="ky kz jj nk b gz os op l oq or">gower_mat &lt;- as.matrix(gower_dist)</span><span id="0d1b" class="ky kz jj nk b gz os op l oq or">#' Print most similar clients<br/>df[which(gower_mat == min(gower_mat[gower_mat != min(gower_mat)]), arr.ind = TRUE)[1, ], ]</span><span id="50b6" class="ky kz jj nk b gz os op l oq or"># A tibble: 2 x 7<br/>    age job        marital education default balance housing<br/>  &lt;int&gt; &lt;fct&gt;      &lt;fct&gt;   &lt;fct&gt;     &lt;fct&gt;     &lt;int&gt; &lt;fct&gt;  <br/>1    <strong class="nk jk">52 technician married secondary no          196 yes </strong>   <br/>2   <strong class="nk jk"> 52 technician married secondary no          195 yes</strong></span><span id="24da" class="ky kz jj nk b gz os op l oq or">#' Print most dissimilar clients<br/>df[which(gower_mat == max(gower_mat[gower_mat != max(gower_mat)]), arr.ind = TRUE)[1, ], ]</span><span id="ac1a" class="ky kz jj nk b gz os op l oq or"># A tibble: 2 x 7<br/>    age job     marital  education default balance housing<br/>  &lt;int&gt; &lt;fct&gt;   &lt;fct&gt;    &lt;fct&gt;     &lt;fct&gt;     &lt;int&gt; &lt;fct&gt;  <br/>1   <strong class="nk jk"> 60 retired married  primary   no        71188 no   </strong>  <br/>2    <strong class="nk jk">26 admin.  divorced secondary yes          -3 yes</strong></span></pre><p id="9748" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated">在商业环境中，我们通常寻找一些既有意义又容易记忆的聚类，例如最多 2 到 8 个。轮廓图有助于我们确定最佳选择。</p><pre class="oe of og oh gu ok nk ol om aw on bi"><span id="6476" class="ky kz jj nk b gz oo op l oq or">sil_width &lt;- c(NA)<br/>for(i in 2:8){  <br/>  pam_fit &lt;- pam(gower_dist, diss = TRUE, k = i)  <br/>  sil_width[i] &lt;- pam_fit$silinfo$avg.width  <br/>}</span><span id="247c" class="ky kz jj nk b gz os op l oq or">plot(1:8, sil_width,<br/>     xlab = "Number of clusters",<br/>     ylab = "Silhouette Width")<br/>lines(1:8, sil_width)</span></pre><figure class="oe of og oh gu iw gi gj paragraph-image"><div class="gi gj ot"><img src="../Images/6686f49d1a4042e6c83a2f805965f74a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MyuoKxU6HGSuLt0zwQhgjw.png"/></div><figcaption class="jd je gk gi gj jf jg bd b be z dk">7 clusters has the highest silhouette width. 5 is simpler and almost as good. Let’s pick k = 5</figcaption></figure><p id="01ee" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated"><strong class="lw jk">解读</strong></p><ul class=""><li id="1eb3" class="mt mu jj lw b lx mo ma mp lh mv ll mw lp mx mm my mz na nb bi translated">每个集群的摘要</li></ul><pre class="oe of og oh gu ok nk ol om aw on bi"><span id="e0af" class="ky kz jj nk b gz oo op l oq or">k &lt;- 5<br/>pam_fit &lt;- pam(gower_dist, diss = TRUE, k)<br/>pam_results &lt;- df %&gt;%<br/>  mutate(cluster = pam_fit$clustering) %&gt;%<br/>  group_by(cluster) %&gt;%<br/>  do(the_summary = summary(.))<br/>pam_results$the_summary</span></pre><figure class="oe of og oh gu iw gi gj paragraph-image"><div role="button" tabindex="0" class="ix iy di iz bf ja"><div class="gi gj ou"><img src="../Images/dfce71756d29c2ebdf17901e1f340d76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y-wuli_WBfFLBdWHYM6hbw.png"/></div></div><figcaption class="jd je gk gi gj jf jg bd b be z dk">Clusters’ scorcard</figcaption></figure><p id="3456" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated">在这里，我们可以尝试为集群中的客户端导出一些通用模式。例如，集群 1 由<strong class="lw jk">“管理 x 三级 x 无违约 x 无住房”</strong>客户组成，集群 2 由<strong class="lw jk">“蓝领 x 二级 x 无违约 x 住房”</strong>客户组成，等等。</p><ul class=""><li id="3130" class="mt mu jj lw b lx mo ma mp lh mv ll mw lp mx mm my mz na nb bi translated"><strong class="lw jk">低维空间中的可视化</strong></li></ul><pre class="oe of og oh gu ok nk ol om aw on bi"><span id="c8c2" class="ky kz jj nk b gz oo op l oq or">tsne_obj &lt;- Rtsne(gower_dist, is_distance = TRUE)</span><span id="a50d" class="ky kz jj nk b gz os op l oq or">tsne_data &lt;- tsne_obj$Y %&gt;%<br/>  data.frame() %&gt;%<br/>  setNames(c("X", "Y")) %&gt;%<br/>  mutate(cluster = factor(pam_fit$clustering))</span><span id="e8b5" class="ky kz jj nk b gz os op l oq or">ggplot(aes(x = X, y = Y), data = tsne_data) +<br/>  geom_point(aes(color = cluster))</span></pre><figure class="oe of og oh gu iw gi gj paragraph-image"><div class="gi gj ot"><img src="../Images/46adcc48e4be8a5b04d1e78a0445d84c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rXC82ido8CZLoeR9ZHJ3eA.png"/></div><figcaption class="jd je gk gi gj jf jg bd b be z dk">Clients observed in a lower dimensional space</figcaption></figure><p id="2da0" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated">虽然不完美(尤其是聚类 3)，但颜色大多位于相似的区域，这证实了分割的相关性。</p></div><div class="ab cl nl nm hy nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="in io ip iq ir"><h2 id="c98b" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">结论</h2><p id="eacf" class="pw-post-body-paragraph lu lv jj lw b lx ly kk lz ma mb kn mc lh md me mf ll mg mh mi lp mj mk ml mm in bi translated">这篇文章是我在尝试对混合类型的无监督数据集进行聚类练习时的想法的总结。我认为这可能对其他数据科学家有附加价值，因此分享。</p><p id="2748" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated"><strong class="lw jk">然而，仍存在一些挑战</strong>，包括:</p><ul class=""><li id="d72b" class="mt mu jj lw b lx mo ma mp lh mv ll mw lp mx mm my mz na nb bi translated">如何处理海量数据集(cf 内存密集)？</li><li id="eb0c" class="mt mu jj lw b lx nc ma nd lh ne ll nf lp ng mm my mz na nb bi translated">一种热编码可能是一种解决方案；这两种方法的优缺点是什么？</li></ul><p id="b237" class="pw-post-body-paragraph lu lv jj lw b lx mo kk lz ma mp kn mc lh mq me mf ll mr mh mi lp ms mk ml mm in bi translated">请不吝评论并分享您对如何应对这一挑战和改进这一拟议方法的看法。</p></div><div class="ab cl nl nm hy nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="in io ip iq ir"><h2 id="49ae" class="ky kz jj bd la lb lc dn ld le lf dp lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">来源</h2><ul class=""><li id="6af5" class="mt mu jj lw b lx ly ma mb lh ov ll ow lp ox mm my mz na nb bi translated"><a class="ae mn" href="https://dpmartin42.github.io/posts/r/cluster-mixed-types" rel="noopener ugc nofollow" target="_blank">R 中混合数据类型的聚类</a> | Daniel P. Martin | 2016</li><li id="d674" class="mt mu jj lw b lx nc ma nd lh ne ll nf lp ng mm my mz na nb bi translated"><a class="ae mn" href="https://stats.stackexchange.com/questions/55798/what-is-the-optimal-distance-function-for-individuals-when-attributes-are-nomina/55802#55802" rel="noopener ugc nofollow" target="_blank">当属性为名义属性时，个体的最优距离函数是什么？</a>|<a class="ae mn" href="https://stats.stackexchange.com/users/3277/ttnphns" rel="noopener ugc nofollow" target="_blank">ttnphns</a>| stats.stackexchange.com</li><li id="f9a4" class="mt mu jj lw b lx nc ma nd lh ne ll nf lp ng mm my mz na nb bi translated"><a class="ae mn" href="http://larmarange.github.io/analyse-R/classification-ascendante-hierarchique.html" rel="noopener ugc nofollow" target="_blank">分类上升等级</a>|约瑟夫·拉玛兰吉| 2018(法语)</li></ul></div></div>    
</body>
</html>