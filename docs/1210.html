<html>
<head>
<title>Data Science</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/data-science-43c246d4eebc?source=collection_archive---------5-----------------------#2017-08-10">https://towardsdatascience.com/data-science-43c246d4eebc?source=collection_archive---------5-----------------------#2017-08-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a633" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Minder建议引擎:</h2></div><p id="351f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是如何使用随机森林进行数据分类的详细说明。</p><p id="b20d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们分析了由一个类似Tinder的配对网站产生的数据，<em class="lb"> Minder </em>面向一个特定的社区。其工作方式是，当您登录时，Minder的引擎会根据您保存的偏好向您推荐配置文件。你可以向右滑动，即<em class="lb">喜欢</em>的个人资料，或者你可以向左滑动<em class="lb">丢弃</em>。任何显示过一次的个人资料，在任何情况下都不会再向您显示。因此，如果两个人互相喜欢对方，他们的详细资料会透露给对方。</p><p id="9366" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了增加匹配的可能性，我们显然需要了解人们的刷卡行为。我们收集了一百万条最新的刷卡数据，并决定使用由<strong class="kh ir"> Python </strong>提供的流行生态系统来分析这些数据。我们用这一百万个数据点来训练我们的引擎。然后，我们的引擎预测一个人喜欢另一个人的可能性。</p><p id="49dc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于两种性别之间的性别行为非常不同(如下图所示)，我们最终决定为男性和女性用户使用单独的预测分类器。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/0ac407c4e4f10ff573e686112297de34.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*sGPnGqI7sEc869tGn-4RTg.png"/></div></figure><p id="a661" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图表中的<em class="lb">真</em>和<em class="lb">假</em>值是候选人<em class="lb">喜欢另一个</em>还是<em class="lb">不喜欢</em>。我们可以看到，男性喜欢展示给他们的58.65%的简介，而女性只喜欢5.7%。这与男性相比甚至不到十分之一。</p><p id="6782" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最终，我们实现了正确预测一个人是否会喜欢某个个人资料的结果，女性用户的准确率大约为94%，男性用户的准确率为83%。</p><p id="32eb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">详细信息分为以下三个部分:</p><h2 id="21a5" class="lk ll iq bd lm ln lo dn lp lq lr dp ls ko lt lu lv ks lw lx ly kw lz ma mb mc bi translated">I:使用机器学习的数据分类</h2><p id="8c9d" class="pw-post-body-paragraph kf kg iq kh b ki md jr kk kl me ju kn ko mf kq kr ks mg ku kv kw mh ky kz la ij bi translated">首先，我们将大类分开，并确定根据性别和T21行为来分离数据可能是个好主意。我们决定使用由<strong class="kh ir"> Python </strong>提供的流行生态系统来分析刷卡数据。我们的最终目标是创建一个web服务(RESTful ),通过提供两个用户的个人资料作为输入，提供一个人喜欢另一个人的大概情况。</p><p id="8871" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">导入库</strong></p><p id="5e47" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用由<a class="ae mi" href="http://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank"> Pandas </a>库提供的数据帧来加载和操作数据。然后我们将使用<a class="ae mi" href="http://matplotlib.org/" rel="noopener ugc nofollow" target="_blank"> Matplotlib </a>(及其衍生<a class="ae mi" href="http://seaborn.pydata.org/" rel="noopener ugc nofollow" target="_blank"> Seaborn </a>)库来可视化数据的不同方面。数字操作通常用<a class="ae mi" href="http://www.numpy.org/" rel="noopener ugc nofollow" target="_blank"> Numpy </a>数组完成，对于机器学习，我们使用<a class="ae mi" href="http://scikit-learn.org/" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn </a>。使用<em class="lb"> pip </em>或任何其他合适的Python包管理器可以很容易地安装这些库。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="2d3b" class="lk ll iq mk b gy mo mp l mq mr">import os<br/>import datetime<br/>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>from sklearn import tree<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import classification_report,confusion_matrix<br/>from sklearn.externals import joblib</span></pre><p id="4248" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">读取数据</strong></p><p id="1b1c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们已经对数据库中的所有数据进行了反规范化，并将其转储到一个平面CSV文件中。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="f76d" class="lk ll iq mk b gy mo mp l mq mr">data=pd.read_csv('1M.csv')<br/>print data.shape data.head(2)</span><span id="991a" class="lk ll iq mk b gy ms mp l mq mr">----output----<br/>(1000000, 27)<br/> "p1_liked","p2_liked","confirmed","unmatched","answeredFromTelegram","p1_id","p1_country","p1_gender","p1_education","p1_flavor","p1_age","p1_timezone","p1_ethnicity","p1_languages","p1_religiosity","p1_premium","p2_id","p2_country","p2_gender","p2_education","p2_flavor","p2_age","p2_timezone","p2_ethnicity","p2_languages","p2_religiosity","p2_premium"<br/> FALSE,,FALSE,,,151606,"US","male","graduate_degree","sunni",26,"-5","{""South Asian""}","{Bengali}","3.0661764705882355",FALSE,181761,"US","female","graduate_degree","sunni",26,"-4","{""South Asian""}","{Bengali,English,Hindi,Urdu}","2.9233774038461537",FALSE<br/> FALSE,,FALSE,,,266475,"US","female","graduate_degree","sunni",26,"-4","{""South Asian""}","{Bengali}","1.5865208360015366",FALSE,213638,"US","male","graduate_degree",,,"-6",,,,FALSE</span></pre><p id="c792" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">删除无用的列</strong></p><p id="2391" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我们决定提取数据时，我们从数据库中收集了(几乎)所有可能用到的信息。后来我们决定删除几列，因为这些不是用户决策(刷卡)过程中使用的信息的一部分。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="9c12" class="lk ll iq mk b gy mo mp l mq mr">useless_columns = ['answeredFromTelegram', 'confirmed', 'p1_timezone', 'p2_timezone', 'unmatched'] </span><span id="9e66" class="lk ll iq mk b gy ms mp l mq mr">data.drop(useless_columns, axis=1, inplace=True)</span></pre><p id="457d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">附:这些文章中使用的“风味”一词是指一个特定的宗教派别。</p><p id="f976" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">进一步反规格化数据</strong></p><p id="7df6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">刷卡数据的结构是这样的，每个刷卡行都有一个名为[p1_liked]的字段，该字段包含第一个人(p1)的刷卡结果(<em class="lb"> true </em>表示<em class="lb"> like </em>),第一个人(p1)被展示给另一个人(p2的)的简档。当(且如果)p2显示p1的配置文件时，使用相同的行，数据存储在名为[p2_liked]的字段中。如果两个字段都有<em class="lb">真值</em>，那么字段【确认】被设置为<em class="lb">真值</em>。请注意，我们之前已经删除了[确认]数据。</p><p id="8c66" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为这些行(其中[p2_liked]不为空)包含两组数据，所以让我们复制它们，然后在切换[p1_…]和[p2_…]数据后将它们与主数据重新合并。这将使[p2_liked]无用，我们将删除它。</p><p id="b42f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一步是复制[p2_liked]不为空T27的行，即不是T28真T29就是T30假T31。接下来，我们将交换其列的名称，以便交换<em class="lb"> p1 </em>和<em class="lb"> p2 </em>的角色。这对我们来说是一个新的数据点。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="4699" class="lk ll iq mk b gy mo mp l mq mr">datap2=data[data.p2_liked&gt;=0]<br/>print datap2.shape</span><span id="f5ee" class="lk ll iq mk b gy ms mp l mq mr">p2_cols={'p1_age' : 'p2_age' , 'p1_country' : 'p2_country' ,<br/> 'p1_education' : 'p2_education' , 'p1_ethnicity' : 'p2_ethnicity' ,<br/> 'p1_flavor' : 'p2_flavor' , 'p1_gender' : 'p2_gender' ,<br/> 'p1_id' : 'p2_id' , 'p1_languages' : 'p2_languages' ,<br/> 'p1_liked' : 'p2_liked' , 'p1_premium' : 'p2_premium' ,<br/> 'p1_religiosity' : 'p2_religiosity' , 'p2_age' : 'p1_age' ,<br/> 'p2_country' : 'p1_country' , 'p2_education' : 'p1_education' ,<br/> 'p2_ethnicity' : 'p1_ethnicity' , 'p2_flavor' : 'p1_flavor' ,<br/> 'p2_gender' : 'p1_gender' , 'p2_id' : 'p1_id' ,<br/> 'p2_languages' : 'p1_languages' , 'p2_liked' : 'p1_liked' ,<br/> 'p2_premium' : 'p1_premium' , 'p2_religiosity' : 'p1_religiosity' }<br/>datap2n= datap2.rename(columns=p2_cols)</span><span id="d653" class="lk ll iq mk b gy ms mp l mq mr">data2 = pd.concat([data, datap2n], axis=0);<br/>print data2.shape<br/>data2= data2.rename(columns={'p1_liked':'liked'})</span><span id="9801" class="lk ll iq mk b gy ms mp l mq mr">----output----<br/>(43089, 22)<br/>(1043089, 22)</span></pre><p id="b8ff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们看到数据中有43089行，其中两个人都刷了对方的个人资料。最后，我们将新数据帧与主数据合并，并将新数据帧称为<strong class="kh ir"> data2。</strong>我们也把[p1_liked]重命名为[liked]。[liked]列有True/False值，这些值就是我们的分类器将分类到的类。</p><p id="3528" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">根据性别分割数据</strong></p><p id="1722" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们在[p1_gender]的基础上分割数据。我们将很快证明我们的选择。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="d50c" class="lk ll iq mk b gy mo mp l mq mr">dataf = data2[(data2.p1_gender=='female') &amp; (data2.p2_gender=='male')]<br/>datam = data2[(data2.p1_gender=='male') &amp;      (data2.p2_gender=='female')]<br/>print dataf.shape<br/>print datam.shape</span><span id="4fc0" class="lk ll iq mk b gy ms mp l mq mr">----output----<br/>(344951, 22)<br/>(695762, 22)</span></pre><p id="6ec3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们删除更多无用的列。记住我们不需要用户<em class="lb">id’</em>s和性别值作为分类器。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="e81e" class="lk ll iq mk b gy mo mp l mq mr">useless_columns=['p1_gender','p2_gender','p2_liked','p1_id','p2_id']<br/>datam.drop(useless_columns, axis=1, inplace=True)<br/>dataf.drop(useless_columns, axis=1, inplace=True)</span><span id="fda5" class="lk ll iq mk b gy ms mp l mq mr">----output----<br/>count     1043089<br/>unique          2<br/>top         False<br/>freq       614942<br/>Name: liked, dtype: object</span></pre><p id="67bf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">行为分析</strong></p><p id="e910" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里有一个根据性别分离数据集的基本原理。他们的行为完全不同。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="7e20" class="lk ll iq mk b gy mo mp l mq mr">dmvc = datam.liked.value_counts()<br/>dfvc = dataf.liked.value_counts()<br/>df = pd.DataFrame([dmvc,dfvc])<br/>df.index = ['Males','Females']<br/>df.plot(kind='bar', stacked=True);</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/0ac407c4e4f10ff573e686112297de34.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*sGPnGqI7sEc869tGn-4RTg.png"/></div></figure><p id="843e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">男性喜欢向他们展示的58.65%的简介，而女性只喜欢5.7%。甚至不到<em class="lb">十分之一</em>相比男性。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="fccb" class="lk ll iq mk b gy mo mp l mq mr">dmm = datam.liked.mean()<br/>dfm = dataf.liked.mean()<br/>df = pd.DataFrame([dmm,dfm])<br/>df.index = ['Males','Females']<br/>df.plot(kind='bar', stacked=True);</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/b154463681f47d88a2c1191d752b339c.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*Ws8qq0i6tVeLxcDWBAd5DQ.png"/></div></figure><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="f66e" class="lk ll iq mk b gy mo mp l mq mr">print " True liked values - Males- {} ({:.2%})".format(datam.liked.sum(), datam.liked.mean())<br/>print " True liked values - Females- {} ({:.2%})".format(dataf.liked.sum(), dataf.liked.mean())</span><span id="a0cc" class="lk ll iq mk b gy ms mp l mq mr">----output----<br/>True  liked values - Males-  408099 (58.65%)<br/>True  liked values - Females-  19791 (5.74%)</span></pre><p id="0f9e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">现在保存</strong>，让分析在单独的数据集上继续进行。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="ae64" class="lk ll iq mk b gy mo mp l mq mr">datam.to_csv("1M-datam.csv", index=False)<br/>dataf.to_csv("1M-dataf.csv", index=False)</span></pre><p id="0569" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来:我们将分析女性用户的行为。</p><h2 id="f59d" class="lk ll iq bd lm ln lo dn lp lq lr dp ls ko lt lu lv ks lw lx ly kw lz ma mb mc bi translated">二:数据分析</h2><p id="9bd2" class="pw-post-body-paragraph kf kg iq kh b ki md jr kk kl me ju kn ko mf kq kr ks mg ku kv kw mh ky kz la ij bi translated">让我们从加载<em class="lb"> 1M-dataf.csv </em>开始，这个文件包含了女性用户的滑动行为。我们假设已经加载了适当的库(<em class="lb"> Pandas、Matplotlib、Seaborn、Numpy、Scikit-Learn </em>)。</p><p id="0738" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">加载数据</strong></p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="1f03" class="lk ll iq mk b gy mo mp l mq mr">datafile='1M-dataf.csv'<br/>data=pd.read_csv(datafile)<br/>print data.shape<br/>print list(data)<br/>print data.liked.mean()<br/>print data.liked.describe()</span><span id="84de" class="lk ll iq mk b gy ms mp l mq mr">----output----<br/>(344951, 17)<br/>['p1_age', 'p1_country', 'p1_education', 'p1_ethnicity', 'p1_sect', 'p1_languages', 'liked', 'p1_premium', 'p1_religiosity', 'p2_age', 'p2_country', 'p2_education', 'p2_ethnicity', 'p2_sect', 'p2_languages', 'p2_premium', 'p2_religiosity']<br/>0.0573733660723<br/><br/>count     344951<br/>unique         2<br/>top        False<br/>freq      325160<br/>Name: liked, dtype: object</span></pre><p id="5d45" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我们从上一篇文章中所记得的，在[喜欢的]列中几乎94.7%的值(355160/244951)都是<em class="lb">错误的。</em></p><p id="19f5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们向我们的数据框架添加一个新列[same_country]。如果国家相同或不同，添加信息，减少了我们的交叉类别很多。对于宗教派别来说也是如此。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="fea3" class="lk ll iq mk b gy mo mp l mq mr">data['same_country']=(data['p1_country']==data['p2_country'])<br/>data['same_religion']=(data['p1_flavor']==data['p2_flavor'])</span></pre><p id="38b9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">处理数字数据和相关的N/A</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="49e3" class="lk ll iq mk b gy mo mp l mq mr">print data.shape<br/>data.describe().loc['count',:]</span><span id="128f" class="lk ll iq mk b gy ms mp l mq mr">----output----<br/>(344951, 19)<br/> p1_age 332184<br/> p1_religiosity 257957<br/> p2_age 328447<br/> p2_religiosity 233237</span></pre><p id="1796" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">计数值的差异是缺失值，或NaN。我们将用中间值填充缺失的[年龄]值，用平均值填充缺失的[宗教信仰]值。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="ab5e" class="lk ll iq mk b gy mo mp l mq mr">print (data.p1_religiosity.mean(), data.p1_religiosity.median(), data.p2_religiosity.mean(), <br/>   data.p2_religiosity.median())<br/>print (data.p1_age.mean(), data.p1_age.median(), <br/>   data.p2_age.mean(), data.p2_age.median())<br/><br/>data.p1_age.fillna(data.p1_age.median(), inplace=True)<br/>data.p2_age.fillna(data.p2_age.median(), inplace=True)<br/>data.p1_religiosity.fillna(data.p1_religiosity.mean(), <br/>   inplace=True)<br/>data.p2_religiosity.fillna(data.p2_religiosity.mean(),<br/>   inplace=True)</span><span id="7dd9" class="lk ll iq mk b gy ms mp l mq mr">----output----<br/>(3.07051616485, 3.03669724771, 2.79660425283, 2.96941896024)<br/>(26.1033403174, 25.0, 28.1010147756, 28.0)</span></pre><h2 id="28b4" class="lk ll iq bd lm ln lo dn lp lq lr dp ls ko lt lu lv ks lw lx ly kw lz ma mb mc bi translated"><strong class="ak">分析开始</strong></h2><p id="287d" class="pw-post-body-paragraph kf kg iq kh b ki md jr kk kl me ju kn ko mf kq kr ks mg ku kv kw mh ky kz la ij bi translated">Seaborn库提供了更简单的API来创建更好的可视化。</p><p id="13d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 1。国家智慧</strong></p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="5af8" class="lk ll iq mk b gy mo mp l mq mr">sns.countplot(x="p1_country", hue='liked', data=data);</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/45bd0f588aaa44310c365f50a9d79602.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*Aron1O5ABqkjcphYRKV4Kg.png"/></div></figure><p id="d4bb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看一下标准化的数据，以便理解。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="5c9a" class="lk ll iq mk b gy mo mp l mq mr">sns.barplot(x="p1_country", y='liked', hue='same_country', <br/>    data=data, ci=None);</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/1602b415c16a93897397e41b84ad8020.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*fsDk_diIlVQpnKNTgah6Hw.png"/></div></figure><p id="5526" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">按国家查看喜欢的个人资料。</strong></p><p id="6620" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为就频率而言有三个不同的组:</p><ol class=""><li id="e18b" class="mw mx iq kh b ki kj kl km ko my ks mz kw na la nb nc nd ne bi translated">美国</li><li id="5e93" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nb nc nd ne bi translated">CA/GB</li><li id="892f" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nb nc nd ne bi translated">世界其他地方</li></ol><p id="847d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们分别来看。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="1c92" class="lk ll iq mk b gy mo mp l mq mr">fig, ax =plt.subplots(nrows=1, ncols=3, figsize=(15,5))<br/>sns.countplot(x="p1_country", hue='same_country', <br/>     data=data[(data.liked) &amp; (data.p1_country=='US')], <br/>     ax=ax[0]);<br/>sns.countplot(x="p1_country", hue='same_country', <br/>     data=data[(data.like) &amp; ((data.p1_country=='CA')|<br/>     (data.p1_country=='GB'))], ax=ax[1]);<br/>sns.countplot(x="p1_country", hue='same_country', <br/>     data=data[(data.liked) &amp; (data.p1_country!='US')<br/>         &amp;(data.p1_country!='CA') &amp; (data.p1_country!='GB')],<br/>     ax=ax[2]);<br/>fig.show()</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nk"><img src="../Images/e77dc9873c3ede345e2aa451f6c509a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UC_qqEKos9CNRohnZinh7Q.png"/></div></div></figure><p id="1297" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以国家分为四类</p><ol class=""><li id="4cc2" class="mw mx iq kh b ki kj kl km ko my ks mz kw na la nb nc nd ne bi translated">美国</li><li id="ad9c" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nb nc nd ne bi translated">加拿大</li><li id="9a1f" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nb nc nd ne bi translated">千兆字节</li><li id="cade" class="mw mx iq kh b ki nf kl ng ko nh ks ni kw nj la nb nc nd ne bi translated">其他人</li></ol><p id="a94e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">同样，我们将删除[p2_country]数据，保留[same_country],因为来自其他国家的数据点非常少，所以我们将它们分组在一起。我们将[p1_country]重命名为[country]，并删除[p2_country]。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="cfb6" class="lk ll iq mk b gy mo mp l mq mr">data.p1_country[(data.p1_country!='US') &amp; (data.p1_country!='CA')<br/>         &amp; (data.p1_country!='GB')]='XX'<br/>data.rename(columns={"p1_country":"country"}, inplace=True)<br/>data.drop("p2_country", inplace=True, axis=1)</span></pre><p id="2eba" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">绘制上面的图表表明，数据看起来仍然有意义。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="6592" class="lk ll iq mk b gy mo mp l mq mr">fig, ax =plt.subplots(nrows=2, ncols=3, figsize=(15,10))<br/>sns.countplot(x="country", hue='liked', data=data, ax=ax[0,0]);<br/>sns.barplot(x="country", y='liked', hue='same_country', data=data, ci=None, ax=ax[0,1]);<br/>sns.countplot(x="country", hue='same_country', data=data[(data.liked) &amp; (data.country=='US')], ax=ax[1, 0]);<br/>sns.countplot(x="country", hue='same_country', data=data[(data.liked) &amp; ((data.country=='CA')|(data.country=='GB'))], ax=ax[1, 1]);<br/>sns.countplot(x="country", hue='same_country', data=data[(data.liked) &amp; (data.country!='US') &amp; (data.country!='CA') &amp; (data.country!='GB')], ax=ax[1,2]);<br/>fig.show()</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi np"><img src="../Images/390a60d4e08c5eed454ee64bf1b1fab8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Olydgq0UIii_CV2M8178Jw.png"/></div></div></figure><p id="3bee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 2。宗教</strong></p><p id="d12e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">宗教和教派信息无疑是目标群体中的一个关键因素。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="27eb" class="lk ll iq mk b gy mo mp l mq mr">fig, ax =plt.subplots(nrows=1, ncols=3, figsize=(15,5))<br/>sns.countplot(x="p1_flavor", hue='liked', data=data, ax=ax[0]);<br/>sns.barplot(x="p1_flavor", y='liked', data=data, ci=None, ax=ax[1]);<br/>sns.barplot(x="p1_flavor", y='liked', hue='p2_flavor', data=data, ci=None, ax=ax[2]);<br/>fig.show()</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nq"><img src="../Images/a8b54e6e2867d066dcec21c187d5c5cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4y1y1DOImqjY4NnDsfDVhg.png"/></div></div></figure><p id="5a48" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">“其他人”很少，让我们把他们和“仅仅是穆斯林”合并起来，然后重复。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="d420" class="lk ll iq mk b gy mo mp l mq mr">data.p1_flavor[(data.p1_flavor=='other')]='just_muslim'<br/>data.p2_flavor[(data.p2_flavor=='other')]='just_muslim'<br/>fig, ax =plt.subplots(nrows=1, ncols=3, figsize=(15,5))<br/>sns.countplot(x="p1_flavor", hue='liked', data=data, ax=ax[0]);<br/>sns.barplot(x="p1_flavor", y='liked', data=data, ci=None, ax=ax[1]);<br/>sns.barplot(x="p1_flavor", y='liked', hue='p2_flavor', data=data, ci=None, ax=ax[2]);<br/>fig.show()</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nq"><img src="../Images/46e4837342bd616b60cdc2060338d193.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0UD7vPjQEiZUWu49jkzKJQ.png"/></div></div></figure><p id="dcf9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 2.1宗教狂热</strong></p><p id="1db4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">宗教狂热呢？这是每个用户给出的关于他/她自己的信息，他/她有多虔诚，等级为1-5。让我们先把数据转换成最接近的整数，然后画出来。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="e696" class="lk ll iq mk b gy mo mp l mq mr">data=data.round({'p1_religiosity': 0, 'p2_religiosity': 0})<br/>data.p1_religiosity=data.p1_religiosity.astype(int)<br/>data.p2_religiosity=data.p2_religiosity.astype(int)<br/>fig, ax =plt.subplots(nrows=1, ncols=2, figsize=(15,5))<br/>sns.barplot(x="p1_religiosity", y='liked', data=data, ci=None, ax=ax[0]);<br/>sns.barplot(x="p1_religiosity", y='liked', hue='p2_religiosity', data=data, ci=None, ax=ax[1]);<br/>fig.show()</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nr"><img src="../Images/d0c174c2b51be741d9a7559eae082cea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S34-Rcw1EYQDGKATCtT-ww.png"/></div></div></figure><p id="c841" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以看起来宗教相关性仍然比宗教告诉我们更多，但是宗教图表中的微小差异也可能帮助我们。两个都留着吧。</p><p id="a65a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 3。高级用户</strong></p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="c98b" class="lk ll iq mk b gy mo mp l mq mr">fig, ax =plt.subplots(nrows=1, ncols=2, figsize=(15,5))<br/>sns.barplot(x='p1_premium', y='liked', hue='p2_premium',<br/>    data=data, ci=None, ax=ax[0]);<br/>sns.barplot(x='p2_premium', y='liked', hue='p1_premium',<br/>    data=data, ci=None, ax=ax[1]);<br/>fig.show()</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nr"><img src="../Images/3fc6c50d4210c5d7c3375f1bfbeac8b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nKXjwl-vEenWd4FXDm7oUw.png"/></div></div></figure><p id="5caf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">高级用户更有可能被<em class="lb">喜欢</em> <strong class="kh ir">。</strong>但这一点受到了怀疑，因为高级用户的个人资料更经常被展示。因此，让我们保留<em class="lb"> p2 </em>的保费数据，并在我们的培训中使用它来提高他们的概率，以便实际上不需要在最后计算保费。</p><p id="0e2e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">p1 的先决条件也并非完全无关紧要。高级用户选择了更多的选择(右图)。但是这个事实并没有改善我们的预测。</p><p id="41d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 4。教育</strong></p><p id="3ea5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们有一种预感，教育可能是一个关键因素。让我们验证一下直觉。但首先让我们打印我们的数据库中给出的独特的教育资格。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="d75f" class="lk ll iq mk b gy mo mp l mq mr">print data.p1_education.unique()</span><span id="5891" class="lk ll iq mk b gy ms mp l mq mr">array(['graduate_degree', 'college_degree', 'undergraduate', 'other',<br/>       'high_school', nan], dtype=object)</span><span id="e73c" class="lk ll iq mk b gy ms mp l mq mr">fig, ax =plt.subplots(nrows=1, ncols=2, figsize=(15,5))<br/>edu_o=['graduate_degree', 'undergraduate', 'college_degree', 'other', 'high_school']<br/>sns.countplot(x="p1_education", data=data, order=edu_o, ax=ax[0]);<br/>sns.barplot(x="p1_education", y='liked', hue='p2_education', data=data, ci=None, order=edu_o, hue_order=edu_o, ax=ax[1]);<br/>fig.show()</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nq"><img src="../Images/0f8406b01a0b7f7da9763be089542553.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7AM9bFpY_gUvK3IHxA3MOA.png"/></div></div></figure><p id="c563" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以教育似乎是影响决策的一个因素。既然反对这些的用户行为是相似的，让我们合并本科生，大学和其他。它们似乎同等重要。让我们称之为BS。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="051a" class="lk ll iq mk b gy mo mp l mq mr">data.p1_education[(data.p1_education=='college_degree')|(data.p1_education=='undergraduate')|(data.p1_education=='other')]='BS'<br/>data.p2_education[(data.p2_education=='college_degree')|(data.p2_education=='undergraduate')|(data.p2_education=='other')]='BS'</span></pre><p id="383c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了确保万无一失，让我们绘制图表。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="e162" class="lk ll iq mk b gy mo mp l mq mr">fig, ax =plt.subplots(nrows=1, ncols=3, figsize=(15,5))<br/>sns.countplot(x="p1_education", data=data, ax=ax[0]);<br/>sns.countplot(x="p1_education", data=data[data.liked], ax=ax[1]);<br/>sns.barplot(x="p1_education", y='liked', hue='p2_education', data=data, ci=None, ax=ax[2]);<br/>fig.show()</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nq"><img src="../Images/c83458c87201dc10ac09f453d09b4191.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-zB0kT07_Y6q6JuA67OgKQ.png"/></div></div></figure><p id="c196" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">既然我们已经处理完了数据，是时候继续了。</p><p id="a76b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">处理列</strong></p><p id="13ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">关于我们将要使用的分类器(<a class="ae mi" href="http://en.wikipedia.org/wiki/Random_forest" rel="noopener ugc nofollow" target="_blank">随机森林</a>)的一点是，它可以很好地处理数字数据或虚拟分类数据(也称为<a class="ae mi" href="http://en.wikipedia.org/wiki/Dummy_variable_(statistics)" rel="noopener ugc nofollow" target="_blank">指示变量</a>)。现在我们有了所有的列(除了多值数组:[种族]和[语言])，让我们对它们进行适当的虚拟化和类型转换。</p><p id="d060" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为我们已经清理了数字字段(适当地填充了NaN值)，所以让我们为训练/测试创建一个新的数据副本，称为<em class="lb"> dt </em>。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="5893" class="lk ll iq mk b gy mo mp l mq mr">dt = data[['p1_age','p2_age','p1_religiosity','p2_religiosity']].copy()</span></pre><p id="5a67" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在让我们为每个分类字段创建虚拟变量:[国家、教育、宗教(风味)、溢价]。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="d879" class="lk ll iq mk b gy mo mp l mq mr">datac = pd.get_dummies(data.country, prefix="ct")<br/>dt = pd.concat([dt,datac],axis=1)<br/>dt = pd.concat([dt,data.same_country.astype(int)],axis=1)</span><span id="4beb" class="lk ll iq mk b gy ms mp l mq mr">datae1 = pd.get_dummies(data.p1_education, prefix="edu1")<br/>dt = pd.concat([dt,datae1],axis=1)<br/>datae2 = pd.get_dummies(data.p2_education, prefix="edu2")<br/>dt = pd.concat([dt,datae2],axis=1)</span><span id="75a6" class="lk ll iq mk b gy ms mp l mq mr">datar = pd.get_dummies(data.p1_flavor, prefix="rel")<br/>dt = pd.concat([dt,datar],axis=1)<br/>dt = pd.concat([dt,data.same_religion.astype(int)],axis=1)</span><span id="fc10" class="lk ll iq mk b gy ms mp l mq mr">dt = pd.concat([dt,data.p2_premium.astype(int)],axis=1)</span></pre><p id="6061" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们已经完成了标准数据。有两个多值字段[种族、语言]。这些多值数据需要处理，因为我们将它们表示为JSON数组。我们将简单地使用我们对实际实现的理解来获得语言和种族列表。我们将遍历所有语言/种族，并进行子字符串比较，以查看我们的语言/种族是否在字段数据中。让我们创建一个新的数据框，并在那里进行一些分析。</p><p id="e40a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先针对<em class="lb">语言:</em></p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="1c09" class="lk ll iq mk b gy mo mp l mq mr">langs=["Arabic", "Urdu", "Turkish", "Spanish", "Russian", "Pashtu", "Malaysian", "Italian", "Indonesian", "Hindi", "German", "French", "Filipino", "Farsi", "English", "Dutch", "Chinese", "Bengali"]</span><span id="68b0" class="lk ll iq mk b gy ms mp l mq mr">dfl = pd.DataFrame()<br/>dl1=data.p1_languages<br/>dl2=data.p2_languages</span><span id="ab98" class="lk ll iq mk b gy ms mp l mq mr">dfl["liked"]=data.liked.astype(int)<br/>dfl["same_language"]=0<br/>for l in langs:<br/>ln1="lang1_"+l<br/>ln2="lang2_"+l<br/>dfl[ln1]=(dl1.str.contains(l)==True)<br/>dfl[ln2]=(dl2.str.contains(l)==True)</span><span id="1c9e" class="lk ll iq mk b gy ms mp l mq mr">dfl["same_language"]=dfl["same_language"]+((dfl[ln1])*(dfl[ln1]==dfl[ln2]))</span><span id="dfdb" class="lk ll iq mk b gy ms mp l mq mr">fig, ax =plt.subplots(nrows=1, ncols=3, figsize=(15,5))<br/>sns.countplot(x="same_language", data=dfl, ax=ax[0]);<br/>sns.countplot(x="same_language", data=dfl[dfl.liked==1], ax=ax[1]);<br/>sns.barplot(x="same_language", y='liked', data=dfl, ci=None, ax=ax[2]);<br/>fig.show()</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nq"><img src="../Images/8e35218c84ef78cee533957dca2d0435.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nLpUQuJOMo0InmG6t2rT3Q.png"/></div></div></figure><p id="2960" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，我们还为[same_language]创建了字段，这有望使分析变得更加简单。下一站【种族】。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="c774" class="lk ll iq mk b gy mo mp l mq mr">dfe = pd.DataFrame()<br/>de1=data.p2_ethnicity<br/>de2=data.p2_ethnicity</span><span id="85fd" class="lk ll iq mk b gy ms mp l mq mr">dfe["liked"]=data.liked.astype(int)<br/>dfe["same_ethnicity"]=0<br/>    <br/>ethnics=["Afghan", "African American", "Arab (Khaleej)", "Arab (Levant)", "Arab (North Africa)", "Caucasian", "East African", "East Asian", "Hispanic", "Kurdish", "Persian", "South Asian", "Sub-Sahara African", "Turkish", "West African", "Other"]<br/>for e in ethnics:<br/>    et1="ethn1_"+e<br/>    et2="ethn2_"+e<br/>    dfe[et1]=(de1.str.contains(e)==True)<br/>    dfe[et2]=(de2.str.contains(e)==True)<br/>    dfe["same_ethnicity"]=dfe["same_ethnicity"]+((dfe[et1])*(dfe[et1]==dfe[et2]))</span><span id="76b4" class="lk ll iq mk b gy ms mp l mq mr">fig, ax =plt.subplots(nrows=1, ncols=3, figsize=(15,5))<br/>sns.countplot(x="same_ethnicity", data=dfe, ax=ax[0]);<br/>sns.countplot(x="same_ethnicity", data=dfe[dfe.liked==1], ax=ax[1]);<br/>sns.barplot(x="same_ethnicity", y='liked', data=dfe, ci=None, ax=ax[2]);<br/>fig.show()</span></pre><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="nl nm di nn bf no"><div class="gh gi nq"><img src="../Images/50250dd7a4ac2393c56a1f5fedb41589.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iJCyuXEGsAovVLpsWpYrEw.png"/></div></div></figure><p id="3e31" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，图表显示了<em class="lb">喜欢的</em>简介的匹配语言/声明种族的频率。让我们最后把这个数据加到<em class="lb"> dt </em>上。我们还需要将目标列<em class="lb"> liked、</em>添加到dt中，然后将数据帧保存到一个文件中。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="c545" class="lk ll iq mk b gy mo mp l mq mr">dt = pd.concat([dt,dfl.same_language.astype(int)],axis=1)<br/>dt = pd.concat([dt,dfe.same_ethnicity.astype(int)],axis=1)<br/>dt = pd.concat([dt,data.liked.astype(int)],axis=1)<br/>print dt.shape<br/>dt.to_csv("dataf-categorical.csv", index=False)</span><span id="b817" class="lk ll iq mk b gy ms mp l mq mr">----output----<br/>(344951, 23)</span></pre><p id="4cce" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在填充缺失值、创建虚拟(指示)变量和减少字段数量(维度缩减)之后，我们可以看到我们的数据由23个属性组成。在下一步中，我们将训练我们的分类器，看看我们的进展如何。</p><h2 id="d6f2" class="lk ll iq bd lm ln lo dn lp lq lr dp ls ko lt lu lv ks lw lx ly kw lz ma mb mc bi translated">三:培训/储蓄和测试</h2><p id="9229" class="pw-post-body-paragraph kf kg iq kh b ki md jr kk kl me ju kn ko mf kq kr ks mg ku kv kw mh ky kz la ij bi translated">我们将使用<a class="ae mi" href="http://en.wikipedia.org/wiki/Random_forest" rel="noopener ugc nofollow" target="_blank">随机森林</a>分类器，众所周知它在这类问题中工作得很好。同样，我们假设已经加载了适当的库(<em class="lb"> Pandas、Matplotlib、Seaborn、Numpy、Scikit-Learn </em>)。</p><p id="11a7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们加载数据，并提醒自己所涉及的维度。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="f73d" class="lk ll iq mk b gy mo mp l mq mr">datafile="1M-dataf-categorical"<br/>data=pd.read_csv(datafile+".csv")<br/>print data.shape<br/>print ("Percentage of likes: {:.2%}".format(data.liked.mean()))</span><span id="58e5" class="lk ll iq mk b gy ms mp l mq mr">----output----<br/>(344951, 23)<br/>Percentage of likes: 5.74%</span></pre><p id="6353" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们有345K的<em class="lb">刷</em>记录，只有5.74%的<em class="lb">喜欢</em>，其余都是<em class="lb">不喜欢</em>。</p><p id="e033" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">创建训练和测试数据集</strong></p><p id="ff54" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们将数据分为训练数据和测试数据。我们将在每个集合中随机放置一半数量的行。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="5918" class="lk ll iq mk b gy mo mp l mq mr">num_test = 0.5<br/>train, test, train_target, test_target =<br/>        train_test_split(data.drop(['liked'], axis=1), <br/>        data.liked, test_size=num_test, random_state=23)<br/>train_features = train.values<br/>test_features = test.values</span><span id="8b98" class="lk ll iq mk b gy ms mp l mq mr">print "Training Data (rows, columns): {}".format(str(train_features.shape))<br/>print "Testing Data (rows, columns): {}".format(str(test_features.shape))</span><span id="39c8" class="lk ll iq mk b gy ms mp l mq mr">----output----<br/>Training Data (rows, columns): (172475, 22)<br/>Testing Data (rows, columns): (172476, 22)</span></pre><p id="cc76" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">字段[liked]已从特征数据中分离出来，并将用作训练和测试的<em class="lb">目标</em>类数据。</p><h2 id="8ff6" class="lk ll iq bd lm ln lo dn lp lq lr dp ls ko lt lu lv ks lw lx ly kw lz ma mb mc bi translated">训练并保存随机森林模型</h2><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="b49c" class="lk ll iq mk b gy mo mp l mq mr">clfr = RandomForestClassifier(max_depth = 35, min_samples_split=2, n_estimators = 20, random_state = 2)</span><span id="6ba9" class="lk ll iq mk b gy ms mp l mq mr">start = time.time()<br/>model = clfr.fit(train_features,train_target)<br/>end = time.time()</span><span id="2256" class="lk ll iq mk b gy ms mp l mq mr">print("Training Time: {:.2f} seconds.".format(end - start))<br/>print("Classifier Score: {:.2%}".format(model.score(train_features,train_target)))<br/>joblib.dump(model, datafile+'-RFclf.pkl');</span></pre><p id="d7bf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">注意:</strong> <em class="lb"> clfr </em>是我们用一些适当的参数初始化的主classier对象。<em class="lb"> fit </em>函数是核心训练函数，所以我们对它进行计时，以便对在我的core-i3 linux机器上训练大数据所需的时间进行估计。我们将分类器的准确性打印在训练数据上。记住极高的训练效率最有可能导致<a class="ae mi" href="http://en.wikipedia.org/wiki/Overfitting" rel="noopener ugc nofollow" target="_blank">过拟合</a>的问题。我们的模型使用SK-Learm中的<em class="lb"> joblib </em>模块保存在<em class="lb"> pkl </em>文件中，并且可以重复使用。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="2efe" class="lk ll iq mk b gy mo mp l mq mr">----output----<br/>Training Time: 6.31 seconds.<br/>Classifier Score: 97.31%</span></pre><p id="2903" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这似乎令人印象深刻。所以现在我们当然可以原样使用<em class="lb">模型</em>，但是仅仅为了好玩，我们将<em class="lb"> </em>重新加载模型。</p><p id="df10" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">重新加载模型并根据测试数据预测结果</strong></p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="ff46" class="lk ll iq mk b gy mo mp l mq mr">clf = joblib.load(datafile+'-RFclf.pkl')<br/>pred = clf.predict(test_features)<br/>print("Accuracy: {:.2%}".format((test_target.values==pred).mean())</span><span id="6ace" class="lk ll iq mk b gy ms mp l mq mr">----output----<br/>Accuracy: 93.34%</span></pre><p id="cbe1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，我们可能使用了</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="36ca" class="lk ll iq mk b gy mo mp l mq mr">clf.score(test_features,test_target)</span></pre><p id="edb7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是由<em class="lb"> sk-learn </em>提供的功能，但是为了准确起见，我们使用了简单的比较计数。结果会是一样的。</p><p id="c66d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以现在这是一个很好的结果，但是通过预测每一个配置文件匹配为<em class="lb">假</em>，它可能很容易方便地(但显然是无用地)增加，因为它们中的95 %应该是假的，我们将获得95%的准确性，没有假阴性。但是输出对我们没有任何帮助。对于95%的简档，我们可以通过随机预测<em class="lb">不喜欢的</em>达到90%以上的准确率。对于“有用”的结果，我们需要通过使用所谓的<em class="lb">混淆矩阵</em>来分析行为。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="759f" class="lk ll iq mk b gy mo mp l mq mr">confusion_matrix(test_target,pred)</span><span id="e16d" class="lk ll iq mk b gy ms mp l mq mr">----output----<br/>array([[160001,   2554],<br/>       [  8929,    992]])</span></pre><p id="61b9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但这并没有给我们太多的洞察力，相反，让我们自己重新计算这些值，以了解发生了什么。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="adad" class="lk ll iq mk b gy mo mp l mq mr">aq1=(test_target.values==pred) &amp; (test_target.values==0)<br/>aq2=(test_target.values!=pred) &amp; (test_target.values==0)<br/>aq3=(test_target.values!=pred) &amp; (test_target.values==1)<br/>aq4=(test_target.values==pred) &amp; (test_target.values==1)<br/>print " True Negative {} ({:.2%})".format(aq1.sum(), aq1.mean())<br/>print "False Positive {} ({:.2%})".format(aq2.sum(), aq2.mean())<br/>print "False Negative {} ({:.2%})".format(aq3.sum(), aq3.mean())<br/>print " True Positive {} ({:.2%})".format(aq4.sum(), aq4.mean())</span><span id="804a" class="lk ll iq mk b gy ms mp l mq mr">----output----<br/> True Negative 160001 (92.77%)<br/>False Positive 2554 (1.48%)<br/>False Negative 8929 (5.18%)<br/> True Positive 992 (0.58%)</span></pre><p id="a0b6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是首次尝试。接下来，我们当然可以玩我们削减的参数(在<a class="ae mi" href="http://numan.space/2017/07/30/minder-suggestion-engine-2/" rel="noopener ugc nofollow" target="_blank">第二部分</a>)以及<a class="ae mi" href="http://en.wikipedia.org/wiki/Feature_engineering" rel="noopener ugc nofollow" target="_blank">设计新功能</a>。由于<em class="lb">喜欢</em>的比例已经很低，我们可能得不到足够的匹配。为了理解这一点，考虑一下<em class="lb">预测</em>函数是如何工作的。分类器给出一个数据点(输入行)属于某一类的可能性(概率)。如果<em class="lb">喜欢</em>(比如0.6)的概率高于<em class="lb">不喜欢</em> (0.4)，那么预测将为<em class="lb">真，</em>否则为<em class="lb">假。</em>因此，即使我们的分类器预测到<em class="lb">不像</em>，它也可能是100%到0%的决定，而不是51%到49%的决定。对于后一种情况，最好将其作为可能的候选返回，因为<em class="lb">可能的</em>简档的数量已经非常少了。</p><p id="92ac" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">幸运的是，预测结果可以作为类别概率而不是类别值来检索(在我们的例子中是<em class="lb">真/假</em>)。</p><pre class="ld le lf lg gt mj mk ml mm aw mn bi"><span id="4fe0" class="lk ll iq mk b gy mo mp l mq mr">print clf.predict_proba(test_features)</span><span id="9827" class="lk ll iq mk b gy ms mp l mq mr">----output----<br/>array([[ 1.  ,  0.  ],<br/>       [ 1.  ,  0.  ],<br/>       [ 0.44,  0.56],<br/>       ..., <br/>       [ 1.  ,  0.  ],<br/>       [ 0.98,  0.02],<br/>       [ 1.  ,  0.  ]])</span></pre><p id="1860" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">返回的数组维数为172476✕2.针对每一行，我们得到两个概率值，分别针对<em class="lb">不像</em>和<em class="lb">像</em>。我们可以对这个数组进行排序，并使用最好的几个结果来建议候选项。</p><p id="dee1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对男性用户的数据进行同样的处理，最终达到83%的准确率。</p></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><p id="b3cc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">原载@ </em> <a class="ae mi" href="https://numan.space/ds/" rel="noopener ugc nofollow" target="_blank"> <em class="lb">努曼的博客</em></a><em class="lb">2017年7月31日</em></p></div></div>    
</body>
</html>