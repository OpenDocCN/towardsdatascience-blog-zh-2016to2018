<html>
<head>
<title>Building a Question-Answering System from Scratch— Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始构建问答系统—第 1 部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-question-answering-system-part-1-9388aadff507?source=collection_archive---------0-----------------------#2018-05-23">https://towardsdatascience.com/building-a-question-answering-system-part-1-9388aadff507?source=collection_archive---------0-----------------------#2018-05-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="c009" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">系列文章的第一部分着重于脸书嵌入句</em></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/dc7db79f2d93de7d7af23fc9842f9b66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m78yhkykUzQWG0qDCWY2Aw.jpeg"/></div></div></figure><p id="ed49" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">随着我的硕士学位即将结束，我想从事一个有趣的 NLP 项目，在那里我可以使用我在<a class="ae ky" href="https://www.usfca.edu/arts-sciences/graduate-programs/data-science" rel="noopener ugc nofollow" target="_blank"> USF </a>学到的所有技术(不完全是)。在我的教授的帮助下，通过与同学们的讨论，我决定从头开始建立一个问答模型。我使用的是<a class="ae ky" href="https://rajpurkar.github.io/SQuAD-explorer/" rel="noopener ugc nofollow" target="_blank">斯坦福问答数据集(SQuAD) </a>。这个问题非常有名，所有的大公司都试图在排行榜上跳起来，并使用先进的技术，如基于注意力的 RNN 模型，以获得最佳的准确性。我发现的其他人做的与 SQuAD 相关的所有 GitHub 库也都使用了 RNNs。</p><p id="fba2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，我的目标并不是达到最先进的准确性，而是学习不同的 NLP 概念，实现它们并探索更多的解决方案。我一直相信从基本模型开始了解基线，这也是我的方法。这一部分将重点介绍<strong class="jp ir">脸书语句嵌入</strong>以及如何将其用于构建问答系统。在未来的部分，我们将尝试实现深度学习技术，特别是针对这个问题的序列建模。所有代码都可以在这个<a class="ae ky" href="https://github.com/aswalin/SQuAD" rel="noopener ugc nofollow" target="_blank"> Github 库</a>上找到。</p><p id="7125" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是我们先来了解一下问题。我先简单概述一下，不过，对问题的详细了解可以在这里<a class="ae ky" href="https://rajpurkar.github.io/mlx/qa-and-squad/" rel="noopener ugc nofollow" target="_blank">找到</a>。</p><h2 id="8aa0" class="kz la iq bd lb lc ld dn le lf lg dp lh jy li lj lk kc ll lm ln kg lo lp lq lr bi translated"><strong class="ak">小队数据集</strong></h2><p id="6e06" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">S<strong class="jp ir">S</strong>tanford<strong class="jp ir">Qu</strong>estion<strong class="jp ir">A</strong>nswering<strong class="jp ir">D</strong>ataset(SQuAD)是一个新的阅读理解数据集，由一组维基百科文章上的众包工作者提出的问题组成，其中每个问题的答案都是相应阅读文章中的一段文字，或<em class="kl"> span </em>。SQuAD 拥有 500+篇文章上的 100，000+问答对，比以前的阅读理解数据集大得多。</p><h2 id="bec1" class="kz la iq bd lb lc ld dn le lf lg dp lh jy li lj lk kc ll lm ln kg lo lp lq lr bi translated">问题</h2><p id="8b83" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">对于训练集中的每个观察，我们都有一个<strong class="jp ir">上下文、问题和文本。</strong>这样一个观察的例子——</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lx"><img src="../Images/94d3fa045c5ebbc70918ee6fe158e957.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0KDRs1_tYlqIs6_FYiaNBQ.png"/></div></div></figure><p id="af6b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">目标是为任何新问题和提供的上下文找到文本。这是一个封闭的数据集，意味着问题的答案总是上下文的一部分，也是上下文的一个连续跨度。我现在把这个问题分成两部分-</p><ul class=""><li id="1c88" class="ly lz iq jp b jq jr ju jv jy ma kc mb kg mc kk md me mf mg bi translated">获得有正确答案的句子(突出显示黄色)</li><li id="e8a3" class="ly lz iq jp b jq mh ju mi jy mj kc mk kg ml kk md me mf mg bi translated">一旦句子最终确定，从句子中获得正确答案(突出显示为绿色)</li></ul><h1 id="9e11" class="mm la iq bd lb mn mo mp le mq mr ms lh mt mu mv lk mw mx my ln mz na nb lq nc bi translated">引入阴差阳错，脸书句嵌入</h1><p id="a06b" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">这些天我们有各种类型的嵌入<a class="ae ky" href="https://deeplearning4j.org/word2vec.html" rel="noopener ugc nofollow" target="_blank"> word2vec </a>、<a class="ae ky" href="https://medium.com/scaleabout/a-gentle-introduction-to-doc2vec-db3e8c0cce5e" rel="noopener"> doc2vec </a>、<a class="ae ky" href="https://jaan.io/food2vec-augmented-cooking-machine-intelligence/" rel="noopener ugc nofollow" target="_blank"> food2vec </a>、<a class="ae ky" href="https://docs.google.com/presentation/d/1L-633fYUokbYqTC8R5FUfhlmWnpCO5ey6JMZ_kAnJlM/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank"> node2vec </a>，那么为什么没有 sentence2vec 呢？所有这些嵌入背后的基本思想是使用各种维度的向量来用数字表示实体，这使得计算机更容易理解它们以用于各种下游任务。解释这些概念的文章被链接以便你理解。</p><p id="30c1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">传统上，我们习惯于平均一个句子中所有单词的向量，称为单词袋方法。每个句子被标记为单词，这些单词的向量可以使用手套嵌入来找到，然后取所有这些向量的平均值。这种技术表现不错，但是这不是一种非常准确的方法，因为它没有考虑单词的顺序。</p><p id="40f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是<a class="ae ky" href="https://github.com/facebookresearch/InferSent" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">推断</strong> </a>，它是一个<em class="kl">句子嵌入</em>方法，提供语义句子表示。它在自然语言推理数据上进行训练，并很好地推广到许多不同的任务。</p><p id="95eb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个过程是这样的-</p><blockquote class="nd ne nf"><p id="a91a" class="jn jo kl jp b jq jr js jt ju jv jw jx ng jz ka kb nh kd ke kf ni kh ki kj kk ij bi translated">从训练数据创建词汇表，并使用该词汇表训练推理模型。一旦模型被训练，提供句子作为编码器函数的输入，该函数将返回 4096 维向量，而不管句子中的单词数。[ <a class="ae ky" href="https://github.com/facebookresearch/InferSent/blob/master/encoder/demo.ipynb" rel="noopener ugc nofollow" target="_blank">演示</a></p></blockquote><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="nj nk l"/></div></figure><p id="bb26" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些嵌入可以用于各种下游任务，如寻找两个句子之间的相似性。我已经为 Quora-问题对 kaggle 竞赛实现了同样的功能。你可以点击查看<a class="ae ky" href="https://github.com/aswalin/Kaggle/blob/master/Quora.ipynb" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="e59c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">说到团队问题，下面是我尝试使用句子嵌入来解决前一部分问题的第一部分的方法</p><ul class=""><li id="3dde" class="ly lz iq jp b jq jr ju jv jy ma kc mb kg mc kk md me mf mg bi translated">将段落/上下文分成多个句子。我知道的处理文本数据的两个包是-<a class="ae ky" href="https://spacy.io/usage/spacy-101" rel="noopener ugc nofollow" target="_blank">Spacy</a>&amp;<a class="ae ky" href="http://textblob.readthedocs.io/en/dev/" rel="noopener ugc nofollow" target="_blank">text blob</a>。我也使用了包 TextBlob。它进行智能拆分，不像 spacy 的句子检测可以根据周期给你随机的句子。下面提供了一个例子:</li></ul><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nl"><img src="../Images/dbe27c116a7b28af00fcdb69553dd529.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JT9pWkq28tEaGOEqrY-PqQ.png"/></div></div><figcaption class="nm nn gj gh gi no np bd b be z dk"><strong class="bd nq">Example: Paragraph</strong></figcaption></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nr"><img src="../Images/8d70cb8c460720c85891d14d5c0145b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GKE0z4wiXe5b30VYzn0QWg.png"/></div></div><figcaption class="nm nn gj gh gi no np bd b be z dk"><strong class="bd nq">TextBlob is splitting it into 7 sentences which makes sense</strong></figcaption></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ns"><img src="../Images/f3c0257dea01e2c9570c75058ac8ec89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o2k0eR1WahjQHVN1scSnkQ.png"/></div></div><figcaption class="nm nn gj gh gi no np bd b be z dk"><strong class="bd nq">Spacy is splitting it into 12 sentences</strong></figcaption></figure><ul class=""><li id="3c79" class="ly lz iq jp b jq jr ju jv jy ma kc mb kg mc kk md me mf mg bi translated">使用推理模型获得每个句子和问题的向量表示</li><li id="acdd" class="ly lz iq jp b jq mh ju mi jy mj kc mk kg ml kk md me mf mg bi translated">根据每个句子-问题对的余弦相似度和欧几里德距离，创建距离等特征</li></ul><h1 id="7b4b" class="mm la iq bd lb mn mo mp le mq mr ms lh mt mu mv lk mw mx my ln mz na nb lq nc bi translated">模型</h1><p id="b260" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">我用两种主要方法进一步解决了这个问题-</p><ul class=""><li id="bde6" class="ly lz iq jp b jq jr ju jv jy ma kc mb kg mc kk md me mf mg bi translated">不使用目标变量的无监督学习。这里，我从与给定问题距离最小的段落中返回句子</li><li id="37ea" class="ly lz iq jp b jq mh ju mi jy mj kc mk kg ml kk md me mf mg bi translated">监督学习-训练集的创建对于这一部分来说非常棘手，原因是每个部分没有固定数量的句子，答案可以从一个单词到多个单词不等。我能找到的唯一一篇实现了逻辑回归的论文是由发起这个竞赛&amp;数据集的斯坦福团队发表的。他们使用了这篇<a class="ae ky" href="https://arxiv.org/pdf/1606.05250.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中解释的多项式逻辑回归，并创建了<strong class="jp ir">1.8 亿个特征(该模型的句子检测准确率为 79%) </strong>，但不清楚他们是如何定义目标变量的。如果任何人有任何想法，请在评论中澄清。稍后我会解释我的解决方案。</li></ul><h2 id="ddf1" class="kz la iq bd lb lc ld dn le lf lg dp lh jy li lj lk kc ll lm ln kg lo lp lq lr bi translated">无监督学习模型</h2><p id="9050" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">在这里，我首先尝试使用欧几里德距离来检测与问题距离最小的句子。这个模型的精确度大约为 45%。然后，我切换到余弦相似度，准确率从<strong class="jp ir"> 45%提高到 63% </strong>。这是有意义的，因为欧几里德距离不关心向量之间的对齐或角度，而余弦则负责这一点。在矢量表示的情况下，方向很重要。</p><p id="62d9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是这种方法没有利用提供给我们的带有目标标签的丰富数据。然而，考虑到解决方案的简单性质，这仍然是一个没有任何培训的好结果。我认为体面的表现归功于脸书句子嵌入。</p><h2 id="e7b6" class="kz la iq bd lb lc ld dn le lf lg dp lh jy li lj lk kc ll lm ln kg lo lp lq lr bi translated">监督学习模型</h2><p id="0f0e" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">这里，我已经将目标变量从文本转换为包含该文本的句子索引。为了简单起见，我把我的段落长度限制在 10 句以内(大约 98%的段落只有 10 句或更少)。因此，在这个问题中，我有 10 个标签要预测。</p><p id="2914" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于每个句子，我都建立了一个基于余弦距离的特征。如果一个段落的句子数量较少，那么我将把它的特征值替换为 1(最大可能余弦距离),这样总共有 10 个句子。用一个例子来解释这个过程会比较容易。</p><p id="7ad5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们来看看训练集的第一个观察/行。有答案的句子在上下文中被加粗。：</p><p id="9a83" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">问题——“1858 年在法国卢尔德，圣母玛利亚据说是向谁显现的？”<br/> <strong class="jp ir">背景</strong>——“从建筑上来说，这所学校具有天主教的特征。在主楼的金色圆顶上是一座金色的圣母玛利亚雕像。在主建筑的正前方，正对着它的是一尊铜制的基督雕像，双臂高举，上面写着“Venite Ad Me Omnes”的字样。主楼旁边是圣心大教堂。长方形会堂的后面是一个洞穴，一个祈祷和沉思的地方。这是一个法国卢尔德石窟的复制品，据说圣母玛利亚于 1858 年在这里出现在圣贝尔纳黛特·索比罗斯面前。在主车道的尽头(在一条直线上，连接着三座雕像和金色穹顶)，是一座简单、现代的玛丽石像。<br/> <strong class="jp ir">正文</strong>——《圣贝尔纳黛特·索比罗斯》</p><p id="9057" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这种情况下，目标变量将变成 5，因为这是粗体句子的索引。我们将有 10 个特征，每个特征对应于段落中的一个句子。column_cos_7、column_cos_8 和 column_cos_9 的缺失值用 1 填充，因为这些句子在段落中不存在</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nt"><img src="../Images/415d16706598d00ccf2630dad378c39a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AUCFeZNB6It0QxTkTQ5UJw.png"/></div></div></figure><p id="64ca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">依赖解析<br/> </strong>我为这个问题使用的另一个特性是<strong class="jp ir">“依赖解析树”</strong>。这将模型的精确度略微提高了 5%。这里，我使用了空间树解析，因为它有丰富的 API 来导航树。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nu"><img src="../Images/e7f67d36b10b771ebcea43e9a560e9af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NX7lNUowzXw4kTWS_myEPA.png"/></div></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nv"><img src="../Images/63b708f8c3d4b398b03329431c66e188.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Iz2nqSA2ysrFDBtqoIaYlw.png"/></div></div><figcaption class="nm nn gj gh gi no np bd b be z dk">For more details: Please check out <a class="ae ky" href="https://web.stanford.edu/~jurafsky/slp3/14.pdf" rel="noopener ugc nofollow" target="_blank">Stanford Lecture</a></figcaption></figure><blockquote class="nw"><p id="fe7b" class="nx ny iq bd nz oa ob oc od oe of kk dk translated">单词之间的关系在句子上方用有向的、有标记的弧线从首字母到从属字母来表示。我们称之为类型依赖结构，因为标签是从固定的语法关系清单中提取的。它还包括一个根节点，该节点显式地标记了树的根，即整个结构的头部。</p></blockquote><p id="0632" class="pw-post-body-paragraph jn jo iq jp b jq og js jt ju oh jw jx jy oi ka kb kc oj ke kf kg ok ki kj kk ij bi translated">让我们使用空间树解析来可视化我们的数据。我使用的是上一节中提供的同一个例子。</p><p id="87fd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">问题—“</strong>1858 年在法国卢尔德，圣母玛利亚据称是向谁显现的？”</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ol"><img src="../Images/9279e223e377886d9a4c87d9f804d92e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r8TvJomfxPhzGlFKUMW8Kg.png"/></div></div></figure><p id="0904" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">有答案的句子— </strong>“这是一个法国卢尔德石窟的复制品，据说圣母玛利亚于 1858 年在那里出现在圣贝尔纳黛特·索比罗斯面前”</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi om"><img src="../Images/ed675c43a695c2cc38380b8f04081a27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qZGjrGF4Vl_PtBDHt0Txqw.png"/></div></div></figure><p id="c926" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">段落中所有句子的词根</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi on"><img src="../Images/a1d543b060b0c4408e3fb39039da24d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7bvfpzWzLyWe_Ruwkm8naw.png"/></div></div></figure><p id="59a6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">想法是将问题的词根匹配到句子的所有词根/子词根。由于一个句子中有多个动词，所以我们可以得到多个词根。如果问题的词根包含在句子的词根中，那么这个问题被那个句子回答的可能性就更大。考虑到这一点，我为每个值为 1 或 0 的句子创建了一个特征。这里，1 表示问句的词根包含在句根中，否则为 0。</p><blockquote class="nd ne nf"><p id="78d1" class="jn jo kl jp b jq jr js jt ju jv jw jx ng jz ka kb nh kd ke kf ni kh ki kj kk ij bi translated">注意:在比较句子的词根和问题词根之前，做词干分析是很重要的。在前面的例子中，问句的词根是<strong class="jp ir">出现</strong>，而句子中的词根是<strong class="jp ir">出现</strong>。如果不把<strong class="jp ir">出现的</strong> &amp; <strong class="jp ir">出现的</strong>归结为一个共同术语，它们就不可能匹配。</p></blockquote><p id="2f08" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面的示例是转置的数据，带有来自已处理训练数据的 2 个观察值。因此，对于段落中的 10 个句子，结合余弦距离和根匹配，我们总共有 20 个特征。目标变量的范围从 0 到 9。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi oo"><img src="../Images/a67a5c1145a090baa19c6221f9afcb7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*0aP3istBpXTn4ovLptS4cg.png"/></div></div></figure><blockquote class="nd ne nf"><p id="394c" class="jn jo kl jp b jq jr js jt ju jv jw jx ng jz ka kb nh kd ke kf ni kh ki kj kk ij bi translated">注意:对于逻辑回归，标准化数据中的所有列是非常重要的。</p></blockquote><p id="6054" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦创建了训练数据，我就使用了<strong class="jp ir">多项式逻辑回归、随机森林&amp;梯度推进技术</strong>。</p><p id="1065" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">多项逻辑回归</strong>对验证集的准确率为<strong class="jp ir"> 65% </strong>。考虑到原始模型有很多特征，准确率为<strong class="jp ir"> 79% </strong>，这个模型非常简单。<strong class="jp ir">随机森林</strong>给出了<strong class="jp ir"> 67% </strong>的准确率，最后<strong class="jp ir"> XGBoost </strong>在验证集上表现最好，准确率为<strong class="jp ir"> 69% </strong>。</p><p id="3c8d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我将增加更多的功能(NLP 相关)来改善这些模型。</p><p id="9f95" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">非常欢迎与功能工程或其他改进相关的想法。这里提供了与上述概念相关的所有代码<a class="ae ky" href="https://github.com/aswalin/SQuAD" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="faf8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在下一部分中，我们将重点关注从这一部分中入围的句子中提取文本(正确跨度)。同时，看看我的其他博客<a class="ae ky" href="https://medium.com/@aswalin" rel="noopener">这里</a>！</p></div><div class="ab cl op oq hu or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="ij ik il im in"><p id="d369" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">关于我:<a class="ae ky" href="https://alviraswalin.wixsite.com/alvira" rel="noopener ugc nofollow" target="_blank">https://alviraswalin.wixsite.com/alvira</a>。有兴趣与跨职能部门合作，从数据中获得见解，并应用机器学习知识来解决复杂的数据科学问题。<br/> <strong class="jp ir">领英:</strong><a class="ae ky" href="http://www.linkedin.com/in/alvira-swalin" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">www.linkedin.com/in/alvira-swalin</strong></a></p><h1 id="41d0" class="mm la iq bd lb mn mo mp le mq mr ms lh mt mu mv lk mw mx my ln mz na nb lq nc bi translated">参考</h1><ol class=""><li id="e9a1" class="ly lz iq jp b jq ls ju lt jy ow kc ox kg oy kk oz me mf mg bi translated"><a class="ae ky" href="https://github.com/aswalin/SQuAD" rel="noopener ugc nofollow" target="_blank">带有代码的 Github 库</a></li><li id="bfc7" class="ly lz iq jp b jq mh ju mi jy mj kc mk kg ml kk oz me mf mg bi translated"><a class="ae ky" href="https://github.com/facebookresearch/InferSent" rel="noopener ugc nofollow" target="_blank">脸书回购延期</a></li><li id="f244" class="ly lz iq jp b jq mh ju mi jy mj kc mk kg ml kk oz me mf mg bi translated"><a class="ae ky" href="https://arxiv.org/pdf/1606.05250.pdf" rel="noopener ugc nofollow" target="_blank">解释逻辑回归的最佳资源论文</a></li><li id="7892" class="ly lz iq jp b jq mh ju mi jy mj kc mk kg ml kk oz me mf mg bi translated"><a class="ae ky" href="https://rajpurkar.github.io/mlx/qa-and-squad/" rel="noopener ugc nofollow" target="_blank">博客解释问题</a></li><li id="4bf5" class="ly lz iq jp b jq mh ju mi jy mj kc mk kg ml kk oz me mf mg bi translated"><a class="ae ky" href="https://rajpurkar.github.io/SQuAD-explorer/" rel="noopener ugc nofollow" target="_blank">排行榜&amp;数据集</a></li></ol></div></div>    
</body>
</html>