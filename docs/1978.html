<html>
<head>
<title>Fun with small image data-sets (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">小图像数据集的乐趣(第2部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fun-with-small-image-data-sets-part-2-54d683ca8c96?source=collection_archive---------4-----------------------#2017-11-27">https://towardsdatascience.com/fun-with-small-image-data-sets-part-2-54d683ca8c96?source=collection_archive---------4-----------------------#2017-11-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="4e9c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kl">人类是戴眼镜的吗？</em> </strong>第一部<a class="ae km" href="https://medium.com/@nikhil.b.k_13958/fun-with-small-image-data-sets-8c83d95d0159" rel="noopener">看这里</a>。</p><p id="0ea1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这篇博客中，我们将看到如何训练一个分类器来识别人是否戴着眼镜。我们从一个预先训练好的模型和从Google图片搜索下载的260张训练图片开始。像第一部分中的<a class="ae km" href="https://medium.com/@nikhil.b.k_13958/fun-with-small-image-data-sets-8c83d95d0159" rel="noopener">一样，我们将使用</a><a class="ae km" href="http://www.fast.ai/" rel="noopener ugc nofollow" target="_blank"> Fastai课程的第一课Jupyter </a><a class="ae km" href="https://github.com/fastai/fastai/tree/master/courses/dl1" rel="noopener ugc nofollow" target="_blank">笔记本</a>的修改版本。</p><p id="91f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">早先玩10张图片很有趣，但随着我们进入更严肃的乐趣，我们想处理100张甚至1000张图片。为此，我使用了Hardikvasa的一个漂亮的小脚本。这是一个Python程序，可以在谷歌图片上搜索关键字/关键词，并可以选择下载所有图片。</p><p id="316e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我首先为“戴眼镜”和“不戴眼镜”两种情况下载了200个演员(男/女)的图像。我手动扫描图像以删除有缺陷的图像(jpg文件损坏、错误的图像等),然后将图像分为135幅训练图像和20幅验证图像——包括“戴眼镜”和“不戴眼镜”的情况。</p><p id="2feb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">训练图像数量:135 x 2(带眼镜和不带眼镜)</strong></p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi kn"><img src="../Images/c5e305c335b244be543dbac3dfeda487.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vLYOU3WGHAWtsIJvrddS5Q.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">Sample Training data-set (with glasses)</strong></figcaption></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi le"><img src="../Images/6ec315819e67118b681a79108902720f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7SpNQdwV7x8831TNl8bclg.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">Sample training data-set (with no glasses)</strong></figcaption></figure><p id="3316" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用学习率为0.01的普通resnet模型，我能够获得合理的准确度<strong class="jp ir"> 77.5 % </strong> (31/40的测试图像被正确分类)</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi lf"><img src="../Images/6cc7c70e17040c55de138b40f46caa1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*fElwwGgDi0733aIHf6RtNw.png"/></div></figure><p id="183d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了提高我们的模型的准确性，我们可以尝试几种技术，如增强、优化最佳学习速率、对不同层使用不同的学习速率以及测试时间增强等。我们将在这里介绍两种技术:</p><p id="272c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> (1)增强</strong>是一种将神经网络暴露于我们从现有数据集创建的更多数据的方法。这是通过以不影响图像解释的方式随机改变图像来实现的，例如水平翻转、缩放和旋转。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi lg"><img src="../Images/5e541764b5bee6c1f044b28985075c9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*l2dlFGQ3En8z8PH83fbGFw.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">Applying augmentation transforms to a sample image (flipping, zooming in etc)</strong></figcaption></figure><p id="691b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">增强主要是为了减少过度拟合(这意味着我们的模型正在学习识别训练集中的特定图像，但没有足够好地概括，因此我们在验证集上获得了良好的结果)。使用训练数据集的增强，我能够获得更好的准确性— <strong class="jp ir"> 87.5 % </strong> (35/40的图像被正确分类)</p><p id="7a80" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> (2)不同的学习速率和解冻层:</strong>我们在这里使用的resnet模型由几层组成。通常，早期的层识别基本特征，如线条、渐变等。每一层都逐步建立在前一层的基础上，因此，随着我们进入后面的层，所识别的“特征”的复杂性会增加。因此，我们预计后面的层对于新的数据集需要较少的微调。这里，我们将对不同的层使用不同的学习速率:前几层将处于1e-4，中间层处于1e-3，而我们的FC层将像以前一样处于1e-2。如下图所示，使用增强和差异学习率的组合足以给我们的数据集带来100%的准确率！重复实验几次，我注意到准确率大部分时间都徘徊在97.5到100 %以上。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi lh"><img src="../Images/4ab7bb67ff168252b618426a8b3c829f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dmbodSp6-pgc0l_i3xTXFg.png"/></div></div></figure><p id="109c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">结论:</strong>我们的模型能够准确预测人是否戴眼镜。尽管训练图像数量如此之少，但看到这种深度学习模型的功效令人兴奋。在数据收集阶段，我不知道会发生什么，但我对结果感到惊喜。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi lh"><img src="../Images/b3b6610e99525a7359b08ef3546e0363.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cXkCeMEq2GEYpfmi5NtEaQ.png"/></div></div></figure></div></div>    
</body>
</html>