<html>
<head>
<title>A new kind of deep neural networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一种新的深度神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-new-kind-of-deep-neural-networks-749bcde19108?source=collection_archive---------2-----------------------#2017-05-05">https://towardsdatascience.com/a-new-kind-of-deep-neural-networks-749bcde19108?source=collection_archive---------2-----------------------#2017-05-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="5b69" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">作者阿尔弗雷多·坎齐阿尼、阿比舍克·乔拉西亚和</em><a class="ae km" href="https://medium.com/@culurciello" rel="noopener">T3】尤金尼奥·库勒西略T5】</a></p><p id="d504" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">又有<strong class="jp ir">新一波深度神经网络</strong>来了。它们是前馈模型的演变，我们之前详细分析过<a class="ae km" href="https://medium.com/towards-data-science/neural-network-architectures-156e5bad51ba" rel="noopener"/>。</p><p id="fb3e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种新型神经网络是最初的前馈模型<a class="ae km" href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" rel="noopener ugc nofollow" target="_blank">lenet 5</a>/<a class="ae km" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank">Alex net</a>及其衍生模型的进化，包括比<a class="ae km" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">ResNet</a>/<a class="ae km" href="http://arxiv.org/abs/1602.07261" rel="noopener ugc nofollow" target="_blank">Inception</a>更复杂的旁路方案。这些前馈神经网络也被称为<em class="kl">编码器、</em>，因为它们将图像压缩和编码成更小的表示向量。</p><p id="fdea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">新一波神经网络有两个重要的新特征:</p><ul class=""><li id="d4b9" class="kn ko iq jp b jq jr ju jv jy kp kc kq kg kr kk ks kt ku kv bi translated"><strong class="jp ir">生成分支</strong>:也称为<em class="kl">解码器</em>，因为它们将一个表示向量投射回输入空间</li><li id="cba6" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated"><strong class="jp ir">重现层</strong>:将先前时间步的表示与当前时间步的输入和表示相结合</li></ul><h1 id="c9bb" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">太好了！但是这种增加的复杂性能为我们做什么呢？</h1><p id="a5a5" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">原来传统的前馈神经网络有很多局限性:</p><p id="a640" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1- <strong class="jp ir">无法精确定位</strong>:由于较高层中的下采样和空间分辨率损失，特征/对象/类别的定位受损</p><p id="658b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2- <strong class="jp ir">无法对场景</strong>进行推理:因为他们将图像压缩成一个简短的表示代码，他们丢失了关于图像如何构成以及图像或场景的部分如何在空间上排列的信息</p><p id="84a8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2-具有<strong class="jp ir">时间不稳定性</strong>:由于他们是在静止图像上接受训练的，他们没有学会物体在空间中运动的平滑时空变换。它们可以识别某些图像中的物体类别，但不能识别其他图像，并且对<a class="ae km" href="https://arxiv.org/abs/1511.06306" rel="noopener ugc nofollow" target="_blank">敌对噪声</a>和<a class="ae km" href="https://arxiv.org/abs/1412.1897" rel="noopener ugc nofollow" target="_blank">扰动</a>非常敏感</p><p id="2c7a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3- <strong class="jp ir">无法预测</strong>:由于不使用时间信息，前馈神经网络仅基于当前输入在每一帧提供新的表示代码，但无法预测接下来几帧会发生什么(注意:除了<a class="ae km" href="https://arxiv.org/abs/1504.08023" rel="noopener ugc nofollow" target="_blank">例外</a>，未在视频上训练)</p><p id="eef5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了<strong class="jp ir">超越这些限制</strong>，我们需要一种新的网络，它可以将学习到的表达投射回输入图像空间，并且可以对时间上连贯的图像序列进行训练:<strong class="jp ir">我们需要对视频进行训练</strong>。</p><p id="d816" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是这些新网络可以提供的<strong class="jp ir">高级功能</strong>列表:</p><ul class=""><li id="dcdb" class="kn ko iq jp b jq jr ju jv jy kp kc kq kg kr kk ks kt ku kv bi translated"><strong class="jp ir">无监督学习</strong>:它们可以在视频上进行预训练，以预测未来的帧或表示，从而需要少得多的标记数据(在视频上很昂贵！)来训练执行一些任务</li><li id="81d9" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated"><strong class="jp ir">分割</strong> : <a class="ae km" href="https://arxiv.org/abs/1511.00561" rel="noopener ugc nofollow" target="_blank">分割图像中的不同对象</a></li><li id="02d3" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated"><strong class="jp ir">场景解析</strong>:如果数据集具有逐像素对象标签，则遵循分割，用于<a class="ae km" href="https://codeac29.github.io/projects/linknet/index.html" rel="noopener ugc nofollow" target="_blank">自动驾驶</a>和增强现实</li><li id="528e" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated"><strong class="jp ir">定位</strong>:遵循分割和完美的对象边界，所有的场景解析和分割网络都可以做到这一点！</li><li id="1ee0" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated"><strong class="jp ir">时空表示</strong>:使用视频进行训练，而不仅仅是静止图像，了解时间概念和时间关系</li><li id="48d2" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated"><strong class="jp ir">视频预测</strong>:一些网络被设计成<a class="ae km" href="https://arxiv.org/abs/1605.08104" rel="noopener ugc nofollow" target="_blank">预测视频中未来帧</a></li><li id="8463" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated"><strong class="jp ir">表示预测</strong>:某网络可以<a class="ae km" href="https://arxiv.org/abs/1703.07684" rel="noopener ugc nofollow" target="_blank">预测视频中未来帧的表示</a></li><li id="f273" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">通过监控预测和实际未来帧或表示之间的误差信号来执行<strong class="jp ir">在线学习</strong>的能力</li></ul><p id="60ed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在让我们检查这些新网络的细节和实现，如下所示。</p><h1 id="0465" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">生成梯形网络</h1><p id="3ba9" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">这些模型使用编码器和解码器对来将图像分割成部分和对象。例子有:<a class="ae km" href="https://arxiv.org/abs/1606.02147" rel="noopener ugc nofollow" target="_blank"> ENet </a>，<a class="ae km" href="https://arxiv.org/abs/1511.00561" rel="noopener ugc nofollow" target="_blank"> SegNet </a>，<a class="ae km" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> Unet </a>，<a class="ae km" href="https://arxiv.org/abs/1611.09326" rel="noopener ugc nofollow" target="_blank"> DenseNets </a>，<a class="ae km" href="https://arxiv.org/abs/1507.02672" rel="noopener ugc nofollow" target="_blank">梯形网络</a>等等。</p><p id="b79a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是一个典型的三层模型:</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi me"><img src="../Images/3209a593eeb3a5bee544bcd6e449237e.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*PqSlgTefUx6gogJQLppLaA.png"/></div></figure><p id="8b1b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl"> D模块</em>是标准的前馈层。<em class="kl"> G模块</em>是生成模块，类似于标准前馈层，但具有去卷积和上采样功能。它们还使用类似残差的连接<em class="kl">“RES”</em>将每个编码器层的表示连接到其中一个解码器层。这迫使生成层的表示由前馈表示来调制，从而具有更强的将场景定位和解析为对象和部分的能力。<em class="kl">【x】</em>是输入图像，<em class="kl">【y】</em>是输出分割的同时步。</p><p id="b669" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些网络可以执行分割、场景解析和精确定位，但是不在时间域中操作，并且没有过去帧的记忆。</p><p id="4d76" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最近，每层的编码器到解码器旁路帮助这些网络实现了最先进的性能。</p><h1 id="3319" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">递归和生成梯形网络</h1><p id="2ef7" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">最新的深度神经网络架构之一将递归添加到生成梯形网络中。这些是递归和生成式梯形网络(REGEL，我们称之为<a class="ae km" href="https://engineering.purdue.edu/elab/CortexNet/" rel="noopener ugc nofollow" target="_blank"> CortexNet </a>模型)，它们是迄今为止最复杂的深度神经网络模型之一，至少对于图像分析来说是如此。</p><p id="4b34" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是我们目前使用的一个网络的三层模型:</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/1c06ebbf5f69b3861c19bfcf37a45535.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*n0mQ16Mp7vhhvDSXPn55hg.png"/></div></figure><p id="f9ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl"> D </em>和<em class="kl"> G </em>模块实际上与上述生成梯形网络中的模块相同。这些网络增加了从每个<em class="kl"> G </em>模块到同一层中相应的<em class="kl"> D </em>模块的循环路径<em class="kl">“t-1”</em>。</p><p id="dbd6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些网络将视频中的一系列帧作为输入<em class="kl"> x[t] </em>，并在每个时间步预测视频中的下一帧<em class="kl"> y[t+1] </em>，如果预测准确的话，该帧接近<em class="kl"> x[t+1] </em>。</p><p id="9974" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于该网络可以测量预测和实际下一帧之间的误差，它知道何时能够预测输入或不能够预测输入。如果没有，它可以激活增量学习，这是前馈网络所不能做到的。因此，它能够执行固有的<strong class="jp ir">在线学习</strong>。</p><p id="3ddd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们认为这是机器学习的一个非常重要的特征，是预测神经网络的特权。没有这个特征，网络就不能提供真正的预测置信度信号，也不能进行有效的增量学习。</p><p id="61fe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些网络仍在研究中。我们的建议是:保持警惕！</p><h1 id="f488" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">预测编码网络—第1部分</h1><p id="2959" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">递归生成网络是一种可能的预测模型。或者，<strong class="jp ir">预测编码</strong>计算神经科学模型可以提供预测能力，并被安排为分层深度神经网络。</p><p id="c448" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是一个两层模型的示例:</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mn"><img src="../Images/0e66e87547d03bd1547c4a4eea919a55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HyTr686aB6p8P6fxYQFQNw.png"/></div></div></figure><p id="177b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae km" href="http://www.nature.com/neuro/journal/v2/n1/abs/nn0199_79.html" rel="noopener ugc nofollow" target="_blank"> Rao和Ballard </a>模型和<a class="ae km" href="https://www.ncbi.nlm.nih.gov/pubmed/23177956" rel="noopener ugc nofollow" target="_blank"> Friston实现</a>计算<em class="kl">“A”</em>模块(类似于梯形网络上的<em class="kl"> D </em>模块)和<em class="kl">R/Ay】</em>模块(类似于梯形网络上的<em class="kl"> G </em>模块)之间每一层的误差<em class="kl">“e”</em>。这个误差<em class="kl">“e”</em>表示在每一层，网络预测表示的能力。错误<em class="kl">“e”</em>然后作为输入被转发到下一层。<em class="kl">“R”</em>是卷积RNN/LST模块，<em class="kl">“Ay”</em>类似于<em class="kl">“A”</em>模块。<em class="kl">【R】</em>和<em class="kl">【Ay】</em>也可以组合成一个单独的循环模块。在第一层<em class="kl"> "x" </em>是输入帧。</p><p id="e0a6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个模型的问题是，这个网络与标准的前馈神经网络非常不同。它不在创建较低层特征组合的较高层创建分层表示，而是这些预测网络计算先前层的<em class="kl">残差</em>的表示。</p><p id="e53d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，它们有点让人想起残差前馈网络，但在实践中，迫使这些网络转发错误并不会导致它们在更高层学习有效的分层表示。因此，它们不能有效地执行基于上层表示的其他任务，例如分类、分割、动作识别。需要更多的实验来证明这些局限性。</p><p id="4bd6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个模型已经由Bill Lotter和David Cox在<a class="ae km" href="https://coxlab.github.io/prednet/" rel="noopener ugc nofollow" target="_blank"> PredNet </a>中实现。类似的型号也来自<a class="ae km" href="https://arxiv.org/abs/1607.06854" rel="noopener ugc nofollow" target="_blank">大脑公司</a>。</p><h1 id="ca11" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">预测编码网络—第二部分</h1><p id="7659" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated"><a class="ae km" href="https://nms.kcl.ac.uk/michael.spratling/Doc/visres08.pdf" rel="noopener ugc nofollow" target="_blank"> Spratling </a>预测编码模型将表示<em class="kl"> y </em>投射到上层，而不是误差<em class="kl">“e”</em>，如在上面的Friston模型中所执行的。这使得该网络模型与分层前馈深度神经网络更兼容，并避免了上层中的学习误差时刻。</p><p id="1125" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是一个两层模型的示例:</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mn"><img src="../Images/b5763e4952ac943fefdcc4f5f87b0b67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yWMu0j3w9a6frhspbhBKtw.png"/></div></div></figure><p id="3758" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个模型可以基本上重写并简化为我们上面看到的递归生成阶梯模型。这是因为<em class="kl">“R”</em>和<em class="kl">“Ay”</em>可以组合成一个单独的循环模块。</p><h1 id="f04c" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">与生成性对抗网络的关系</h1><p id="31b4" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">生成对抗网络(GAN)是一种非常流行的模型，它能够学习从数据分布中生成样本。这里介绍的新网络模型优于GAN，因为:</p><ul class=""><li id="dde3" class="kn ko iq jp b jq jr ju jv jy kp kc kq kg kr kk ks kt ku kv bi translated">他们不是在一个极大极小游戏中被训练，而是直接为一个有用的任务被训练，所以鉴别器和生成器都是直接有用的</li><li id="f5c1" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">他们学习创建有用的输入表示，同时也能够生成新的输入</li><li id="02da" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">他们可以学习根据输入生成目标数据</li><li id="201b" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">发生器和鉴别器网络连接在一起，消除了收敛问题</li><li id="02cc" class="kn ko iq jp b jq kw ju kx jy ky kc kz kg la kk ks kt ku kv bi translated">与GAN 提供的<a class="ae km" href="https://channel9.msdn.com/Events/Neural-Information-Processing-Systems-Conference/Neural-Information-Processing-Systems-Conference-NIPS-2016/Generative-Adversarial-Networks" rel="noopener ugc nofollow" target="_blank">难看的结果相比，该生成器提供了近乎完美的照片级真实样本(见下文)</a></li></ul><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/a7cec02fdf4d993b16d124bb27a63765.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/1*p5LSHZ0two5c4pt5CSYYhg.gif"/></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Example of CortexNet predictive capabilities — Left: current frame, Center: next frame ground truth, Right: predicted next frame</figcaption></figure><h1 id="727b" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">其他型号的注意事项</h1><p id="e762" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">像CortexNet这样的模型让人联想到<a class="ae km" href="https://arxiv.org/abs/1601.06759" rel="noopener ugc nofollow" target="_blank">像素递归网络</a>及其各种实现(<a class="ae km" href="https://arxiv.org/abs/1606.05328" rel="noopener ugc nofollow" target="_blank"> PixelCNN </a>、<a class="ae km" href="https://openreview.net/pdf?id=BJrFC6ceg" rel="noopener ugc nofollow" target="_blank"> Pixel CNN++ </a>、<a class="ae km" href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/" rel="noopener ugc nofollow" target="_blank"> WaveNet </a>、<a class="ae km" href="http://ruotianluo.github.io/2017/01/11/pixelcnn-wavenet/" rel="noopener ugc nofollow" target="_blank">等</a>)。这些模型旨在对输入数据的分布进行建模:(“我们的目标是估计自然图像上的分布，该分布可用于计算[数据]的可能性并生成新的数据。”).他们只专注于生成新的现实数据样本，但没有显示出学习现实生活任务的表示。这些模型的推理速度也非常慢。</p><h1 id="19b5" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论</h1><p id="3910" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">关于这个话题的一篇论文是<a class="ae km" href="https://arxiv.org/abs/1706.02735" rel="noopener ugc nofollow" target="_blank">这里</a>。CortexNet 仍在研究和评估中。例如，最近的PredNet论文对预测编码和梯形网络进行了比较，PredNet在某些任务上胜出。PredNet用于执行方向不变的人脸分类，使用较高层表示。它还可以预测数据集中的转向角，但主要是使用网络第一层的简单运动滤波器。这项任务不需要对特征进行层次分解。</p><h1 id="812d" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">关于作者</h1><p id="7e75" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mb ka kb kc mc ke kf kg md ki kj kk ij bi translated">我在硬件和软件方面都有将近20年的神经网络经验(一个罕见的组合)。在这里看关于我:<a class="ae km" href="https://medium.com/@culurciello/" rel="noopener">媒介</a>、<a class="ae km" href="https://e-lab.github.io/html/contact-eugenio-culurciello.html" rel="noopener ugc nofollow" target="_blank">网页</a>、<a class="ae km" href="https://scholar.google.com/citations?user=SeGmqkIAAAAJ" rel="noopener ugc nofollow" target="_blank">学者</a>、<a class="ae km" href="https://www.linkedin.com/in/eugenioculurciello/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>等等…</p></div></div>    
</body>
</html>