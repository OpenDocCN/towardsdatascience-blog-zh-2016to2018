<html>
<head>
<title>Bayesian Linear Regression in Python: Using Machine Learning to Predict Student Grades Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的贝叶斯线性回归:使用机器学习预测学生成绩第1部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bayesian-linear-regression-in-python-using-machine-learning-to-predict-student-grades-part-1-7d0ad817fca5?source=collection_archive---------1-----------------------#2018-04-20">https://towardsdatascience.com/bayesian-linear-regression-in-python-using-machine-learning-to-predict-student-grades-part-1-7d0ad817fca5?source=collection_archive---------1-----------------------#2018-04-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/bf466a58f4c35b7dea495832a39e61e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cWQzLX_ee7JP-w1ZXR6Czg.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="2643" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">探索性数据分析、特性选择和基准测试</h2></div><p id="b1b0" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">即使在与贝叶斯线性建模理论斗争了几个星期并写了一篇关于它的博客文章之后，我也不能说我完全理解了这个概念。因此，抱着边做边学是最有效的技术的心态，我开始做一个数据科学项目，使用贝叶斯线性回归作为我选择的机器学习模型。</p><p id="49eb" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这篇文章是两篇记录该项目的文章中的第一篇。我想展示一个完整的数据科学管道的例子，所以这第一篇文章将集中于定义问题、探索性数据分析和设置基准。<a class="ae lm" href="https://medium.com/@williamkoehrsen/bayesian-linear-regression-in-python-using-machine-learning-to-predict-student-grades-part-2-b72059a8ac7e" rel="noopener">的第二部分</a>将完全专注于实现贝叶斯线性回归并解释结果，所以如果你已经有了EDA，<a class="ae lm" href="https://medium.com/@williamkoehrsen/bayesian-linear-regression-in-python-using-machine-learning-to-predict-student-grades-part-2-b72059a8ac7e" rel="noopener">前往那里</a>。如果没有，或者如果您只是想看一些不错的图，请留在这里，我们将介绍如何开始解决数据科学问题。</p><p id="35cc" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">该项目的完整代码可以在GitHub上的<a class="ae lm" href="https://github.com/WillKoehrsen/Data-Analysis/blob/master/bayesian_lr/Bayesian%20Linear%20Regression%20Project.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a>中找到。我鼓励任何感兴趣的人来看看，并把自己的旋转这个项目。请随意使用、构建和以任何方式分发代码！</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><p id="2d37" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我喜欢专注于使用真实世界的数据，在这个项目中，我们将探索从葡萄牙中学收集的学生表现数据。这些数据包括学生的个人和学术特征以及期末成绩。我们的目标是创建一个可以根据学生信息预测成绩的模型。这个数据集，以及许多其他用于测试模型或尝试数据科学技术的有用数据集，可在<a class="ae lm" href="https://archive.ics.uci.edu/ml/datasets/student+performance" rel="noopener ugc nofollow" target="_blank"> UCI机器学习库</a>上获得。</p><h1 id="45e9" class="lu lv jb bd lw lx ly lz ma mb mc md me kh mf ki mg kk mh kl mi kn mj ko mk ml bi translated">探索性数据分析</h1><p id="a5d2" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">解决数据科学问题的第一步(一旦你清理了数据)是<a class="ae lm" href="https://en.wikipedia.org/wiki/Exploratory_data_analysis" rel="noopener ugc nofollow" target="_blank">探索性数据分析(EDA) </a>。这是一个开放式的过程，我们在数据集中寻找异常、有趣的趋势或模式以及相关性。这些本身可能是有趣的，它们可以为我们的建模提供信息。基本上，我们使用EDA来找出我们的数据可以告诉我们什么！</p><p id="dc6d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">首先，我们来看一个熊猫数据帧的数据快照:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="76cc" class="na lv jb mw b gy nb nc l nd ne">import pandas as pd</span><span id="ef07" class="na lv jb mw b gy nf nc l nd ne">df = pd.read_csv(‘data/student-mat.csv’)<br/>df.head()</span></pre><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ng"><img src="../Images/d85346a014380811c0a409a0646889b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R8YLLLVT2Znx7F4xxwZcNA.png"/></div></div></figure><p id="5a85" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">总共有633个观察值和33个变量。每行是一个学生，每列包含一个不同的特征。等级列是我们的目标变量(也称为响应)，这使得这成为一个<strong class="ks jc">监督、回归</strong>机器学习任务。它是受监督的，因为我们有一组已知目标的训练数据，在训练过程中，我们希望我们的模型学会根据其他变量预测分数。我们将把等级视为连续的，这使得这成为一个回归问题(从技术上讲，等级只取整数值，所以它是一个<a class="ae lm" href="https://stats.idre.ucla.edu/other/mult-pkg/whatstat/what-is-the-difference-between-categorical-ordinal-and-interval-variables/" rel="noopener ugc nofollow" target="_blank">名义变量</a>)。</p><p id="aeca" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">感兴趣的主要变量是分数，所以让我们来看一下分布，以检查偏斜:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="61e8" class="na lv jb mw b gy nb nc l nd ne">import matplotlib.pyplot as plt</span><span id="939f" class="na lv jb mw b gy nf nc l nd ne"># Histogram of grades<br/>plt.hist(df['Grade'], bins = 14)<br/>plt.xlabel('Grade')<br/>plt.ylabel('Count')<br/>plt.title('Distribution of Final Grades')</span></pre><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/8ef9b1b99f384953c86c4f14cd7fbe54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*pJdbKnQQ5mk5pvMoRuNLAw.png"/></div></figure><p id="1f05" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">分数接近正态分布，众数为11(该学校的分数范围为0-20)。虽然总体分数没有明显的倾斜，但是某些类别的学生可能会有倾斜的分数。为了观察分类变量对等级的影响，我们可以制作等级分布的<a class="ae lm" rel="noopener" target="_blank" href="/histograms-and-density-plots-in-python-f6bda88f5ac0">密度图</a>，用分类变量的值来着色。为此，我们使用了<a class="ae lm" href="https://seaborn.pydata.org/" rel="noopener ugc nofollow" target="_blank"> seaborn </a>库和<code class="fe ni nj nk mw b">kdeplot</code>函数。以下是按位置(城市或农村)绘制分布图的代码:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="bec6" class="na lv jb mw b gy nb nc l nd ne">import seaborn as sns</span><span id="7a78" class="na lv jb mw b gy nf nc l nd ne"># Make one plot for each different location<br/>sns.kdeplot(df.ix[df['address'] == 'U', 'Grade'], <br/>            label = 'Urban', shade = True)<br/>sns.kdeplot(df.ix[df['address'] == 'R', 'Grade'], <br/>            label = 'Rural', shade = True)</span><span id="7a7d" class="na lv jb mw b gy nf nc l nd ne"># Add labeling<br/>plt.xlabel('Grade')<br/>plt.ylabel('Density')<br/>plt.title('Density Plot of Final Grades by Location')</span></pre><p id="8128" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们可以使用类似的代码来绘制guardian的分数分布，结果如下所示:</p><div class="mr ms mt mu gt ab cb"><figure class="nl is nm nn no np nq paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/ad4853d02c7ac5d34e7cf3bafc394a3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*Y6ZDYpb6_YfhXp7uo0ZehA.png"/></div></figure><figure class="nl is nr nn no np nq paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/e4824d511912bce7b70faf08d681437d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*LyooPawqtZ2JDOhkQMJzlQ.png"/></div></figure></div><p id="fa52" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">密度图上的实际值很难解释，但我们可以用图的形状进行比较。地理位置似乎对学生成绩没有实质性的影响，卫报也没有。诸如此类的图可以为我们的建模提供信息，因为它们告诉我们知道地点或监护人是否有助于预测最终分数。当然，我们想用一个比单一情节更严谨的衡量标准来得出这些结论，后面我们会用统计数据来佐证我们的直觉！</p><h1 id="7a18" class="lu lv jb bd lw lx ly lz ma mb mc md me kh mf ki mg kk mh kl mi kn mj ko mk ml bi translated">特征选择</h1><p id="60e0" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">正如我们从图中看到的，我们并不期望每个变量都与最终成绩相关，所以我们需要执行<a class="ae lm" href="https://en.wikipedia.org/wiki/Feature_selection" rel="noopener ugc nofollow" target="_blank">特征选择</a>(也称为维度缩减)来只选择“相关”变量。这取决于问题，但因为我们将在这个项目中进行线性建模，我们可以使用一个简单的测量方法，称为<a class="ae lm" href="https://onlinecourses.science.psu.edu/stat501/node/256" rel="noopener ugc nofollow" target="_blank">相关系数</a>来确定预测分数最有用的变量。这是一个介于-1和+1之间的值，用于衡量两个变量之间线性关系的方向和强度。</p><p id="9776" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">为了选择有限数量的变量，我们可以找到那些与最终成绩有最大相关性(或正或负)的变量。在熊猫身上寻找相关性非常简单:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="563f" class="na lv jb mw b gy nb nc l nd ne"># Find correlations and sort<br/>df.corr()['Grade'].sort_values()</span><span id="b51c" class="na lv jb mw b gy nf nc l nd ne"><strong class="mw jc">failures     -0.384569<br/>absences     -0.204230<br/>Dalc         -0.196891<br/>Walc         -0.178839<br/>traveltime   -0.129654<br/>goout        -0.111228<br/>freetime     -0.105206<br/>health       -0.096461<br/>age          -0.042505<br/>famrel        0.072888<br/>Fedu          0.204392<br/>studytime     0.249855<br/>Medu          0.278690</strong></span></pre><p id="bf90" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">至少以我的基本社会科学知识来看，这些相关性似乎是有道理的！<code class="fe ni nj nk mw b">failures</code>是以前上课失败的次数，与成绩呈负相关，<code class="fe ni nj nk mw b">absences</code>也是，缺课的次数。这种负相关说明随着这些变量的增加，最终成绩有下降的趋势(虽然我们只能说这是一种相关而不是一个变量导致另一个变量下降)。另一方面，每周学习的量<code class="fe ni nj nk mw b">studytime</code>和母亲的教育水平<code class="fe ni nj nk mw b">Medu</code>都与成绩呈正相关。</p><p id="8324" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">相关性只能在数字变量之间计算，因此要找到分类变量和等级之间的关系，我们必须对分类变量进行一次性编码，然后计算相关系数。<a class="ae lm" href="https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f?gi=af9695dcf290" rel="noopener ugc nofollow" target="_blank"> One-hot encoding </a>是为分类变量中的每个类别创建一列的过程。以下是一次性编码前后的分类列示例:</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/407579c6038fb8d943a87de83ec45d43.png" data-original-src="https://miro.medium.com/v2/resize:fit:252/format:webp/1*pafD1EBz9ipWhviQbpHsSA.png"/></div></figure><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/733bd88a30810b3532a44602c5986235.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*MM767ROXNQsOHNnVrF0w1w.png"/></div></figure><p id="731c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">一键编码是机器学习管道中的标准步骤，使用pandas库很容易做到:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="f2ef" class="na lv jb mw b gy nb nc l nd ne"># Select only categorical variables<br/>category_df = df.select_dtypes('object')</span><span id="73e6" class="na lv jb mw b gy nf nc l nd ne"># One hot encode the variables<br/>dummy_df = pd.get_dummies(category_df)</span><span id="1132" class="na lv jb mw b gy nf nc l nd ne"># Put the grade back in the dataframe<br/>dummy_df['Grade'] = df['Grade']</span><span id="2b4f" class="na lv jb mw b gy nf nc l nd ne"># Find correlations with grade<br/>dummy_df.corr()['Grade'].sort_values()</span><span id="ad0b" class="na lv jb mw b gy nf nc l nd ne"><strong class="mw jc">higher_no           -0.343742<br/>school_MS           -0.227632<br/>Mjob_at_home        -0.158496<br/>reason_course       -0.138195<br/>internet_no         -0.131408<br/>address_R           -0.128350<br/>address_U            0.128350<br/>internet_yes         0.131408<br/>Fjob_teacher         0.160938<br/>Mjob_teacher         0.173851<br/>reason_reputation    0.185979<br/>school_GP            0.227632<br/>higher_yes           0.343742</strong></span></pre><p id="0a48" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们再次看到直观上有意义的关系:<code class="fe ni nj nk mw b">higher_no</code>表示学生不想继续接受高等教育，并且与分数负相关，<code class="fe ni nj nk mw b">higher_yes </code>表示学生确实想要接受高等教育，并且显示出正相关。<code class="fe ni nj nk mw b">Mjob_at_home </code>表示母亲待在家里，与成绩负相关，<code class="fe ni nj nk mw b">Mjob_teacher</code>表示母亲教书，与成绩正相关。</p><p id="e640" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在这个问题中，我们将使用这些结果来进行特征选择，只保留与最终成绩高度相关的6个变量。6是一个任意的数字，我发现它在模型中工作得很好，这表明很多机器学习只是实验！</p><p id="230e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在特征选择后，我们最终使用的最后六个变量(详见笔记本<a class="ae lm" href="https://github.com/WillKoehrsen/Data-Analysis/blob/master/bayesian_lr/Bayesian%20Linear%20Regression%20Project.ipynb" rel="noopener ugc nofollow" target="_blank">和</a>)显示在新数据帧的快照中。(我重命名了这些列，以便它们更直观):</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/6174213e600ebdf3233c8dca78c87833.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*UZebBxHNeAbSk128ryzPkA.png"/></div></figure><p id="bc0e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">变量的<a class="ae lm" href="https://archive.ics.uci.edu/ml/datasets/student+performance#" rel="noopener ugc nofollow" target="_blank">完整描述在UCI机器学习库中，但这里有一个简要概述:</a></p><ul class=""><li id="faa0" class="nv nw jb ks b kt ku kw kx kz nx ld ny lh nz ll oa ob oc od bi translated"><code class="fe ni nj nk mw b">failures</code>:以前的班级失败</li><li id="63f2" class="nv nw jb ks b kt oe kw of kz og ld oh lh oi ll oa ob oc od bi translated"><code class="fe ni nj nk mw b">higher_edu</code>:二元表示学生是否会接受高等教育</li><li id="7d80" class="nv nw jb ks b kt oe kw of kz og ld oh lh oi ll oa ob oc od bi translated"><code class="fe ni nj nk mw b">mother_edu</code>:母亲的教育水平</li><li id="65c1" class="nv nw jb ks b kt oe kw of kz og ld oh lh oi ll oa ob oc od bi translated"><code class="fe ni nj nk mw b">studytime</code>:每周学习量</li><li id="27c4" class="nv nw jb ks b kt oe kw of kz og ld oh lh oi ll oa ob oc od bi translated"><code class="fe ni nj nk mw b">father_edu</code>:父亲的受教育程度</li><li id="fcd8" class="nv nw jb ks b kt oe kw of kz og ld oh lh oi ll oa ob oc od bi translated"><code class="fe ni nj nk mw b">absences</code>:学期内缺课</li></ul><p id="7b89" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">当我们执行特性选择时，我们还使用<a class="ae lm" href="http://scikit-learn.org/" rel="noopener ugc nofollow" target="_blank"> Scikit-learn </a>函数将数据分成训练集和测试集。这是必要的，因为我们需要有一个坚持测试集来评估我们的模型，并确保它不会过度拟合测试数据:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="1682" class="na lv jb mw b gy nb nc l nd ne">from sklearn.model_selection import train_test_split</span><span id="aa88" class="na lv jb mw b gy nf nc l nd ne"># df is features and labels are the targets <br/># Split by putting 25% in the testing set<br/>X_train, X_test, y_train, y_test = train_test_split(df, labels, <br/>                                                   test_size = 0.25,<br/>                                                    random_state=42)</span></pre><p id="156f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这留给我们474个训练观察和159个测试数据点。</p><h2 id="0429" class="na lv jb bd lw oj ok dn ma ol om dp me kz on oo mg ld op oq mi lh or os mk ot bi translated">检查所选要素</h2><p id="b596" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">我最喜欢的图形之一是<a class="ae lm" rel="noopener" target="_blank" href="/visualizing-data-with-pair-plots-in-python-f228cf529166">对图</a>，它非常适合显示变量的分布以及变量对之间的关系。这里我使用seaborn <code class="fe ni nj nk mw b">PairGrid</code>函数来显示所选特性的Pairs图:</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ou"><img src="../Images/7cd5ec7150804ef9a3a5d9b5634d6fdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X93MffVHjT9UqeOK75EU_A.png"/></div></div></figure><p id="6810" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这个情节里编码了很多信息！在上面的三角形中，我们绘制了每个变量的散点图。请注意，大多数变量都是离散整数，这意味着它们只取特定的值。在对角线上，我们有直方图显示单个变量的分布。右下角有二维密度图和变量之间的相关系数。</p><p id="a616" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">为了解释该图，我们可以选择一个变量，并查看行和列，以找到与所有其他变量的关系。例如，第一行显示了我们的目标<code class="fe ni nj nk mw b">Grade</code>与其他变量的散点图。第一列显示了<code class="fe ni nj nk mw b">Grade</code>和其他变量之间的相关系数。我们看到<code class="fe ni nj nk mw b">failures</code>在绝对量级上与最终成绩的相关性最大。</p><p id="ac2f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">作为对所选数据的另一种探索，我们可以绘制每个变量的分布图，如果分数高于12的中值，则用颜色标记。为了绘制这些图，我们在数据框中创建一个列，将等级与12进行比较，然后将所有值绘制在密度图中。</p><figure class="mr ms mt mu gt is"><div class="bz fp l di"><div class="ov ow l"/></div></figure><p id="642f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这产生了以下图:</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ox"><img src="../Images/e3063faf269f785100c3089f43d28562.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wz-884Qa4A9k7bYIRv61jQ.png"/></div></div></figure><p id="68e9" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">绿色分布代表成绩处于或高于中间值的学生，红色代表低于中间值的学生。我们可以看到，有些变量与成绩更为正相关(如<code class="fe ni nj nk mw b">studytime</code>)，而另一些变量则是低成绩的指标，如低<code class="fe ni nj nk mw b">father_edu</code>。</p><p id="f850" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">EDA让我们对数据集有了很好的了解。我们制作图表，找到变量之间的关系，并使用这些来执行特征选择，以便只保留与我们的任务最相关的变量。虽然EDA是建模的先驱，但它本身也很有用，许多数据科学问题可以通过我们在这里制作的图表和统计数据来解决。</p><h2 id="863f" class="na lv jb bd lw oj ok dn ma ol om dp me kz on oo mg ld op oq mi lh or os mk ot bi translated">建立基线指标</h2><p id="ab59" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">机器学习管道中最容易被忽视的一个方面是建立基线。是的，如果您的分类模型达到99%的准确率，这可能看起来令人印象深刻，但是如果我们每次都通过猜测相同的类来获得98%的准确率，会怎么样呢？我们真的想花时间为这个问题建立一个模型吗？一个好的基线允许我们评估我们的模型(或者任何模型)是否适用于这个任务。</p><p id="d86d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">对于回归，一个好的简单基线就是猜测测试数据中每个观察值的目标中值。在我们的问题中，中位数是12，所以让我们评估一个模型的准确性，该模型天真地预测测试集上的每个学生都是12。我们将使用2个指标来评估预测:</p><ul class=""><li id="16a2" class="nv nw jb ks b kt ku kw kx kz nx ld ny lh nz ll oa ob oc od bi translated"><strong class="ks jc">平均绝对误差(MAE) </strong>:预测值与真实值之差的绝对值的平均值。</li><li id="35e7" class="nv nw jb ks b kt oe kw of kz og ld oh lh oi ll oa ob oc od bi translated"><strong class="ks jc">均方根误差(RMSE) </strong>:预测值和真实值之间的平均平方差的平方根。</li></ul><p id="6a4c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">平均绝对误差很容易解释，因为它代表了我们平均离正确值有多远。均方根误差对较大误差的惩罚更重，通常用于回归任务。根据具体情况，这两个指标可能都合适，我们将使用这两个指标进行比较。(<a class="ae lm" href="https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d" rel="noopener">这里讨论一下这些指标的优点</a>。)</p><p id="2f15" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">当我们对测试集上的每个例子预测12时，我们得到这些结果:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="8299" class="na lv jb mw b gy nb nc l nd ne"><strong class="mw jc">Median Baseline  MAE: 2.1761<br/>Median Baseline RMSE: 2.6777</strong></span></pre><p id="82c9" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">如果我们的机器学习模型无法击败这些指标，那么我们要么需要获得更多数据，尝试另一种方法，要么得出机器学习不适用于我们的问题的结论！</p><p id="24e3" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们的建模重点是贝叶斯线性回归，但将我们的结果与标准技术(如线性回归、支持向量机或基于树的方法)的结果进行比较会有所帮助。我们将在数据集上评估其中的几种方法。幸运的是，这些都很容易用Scikit-Learn等Python库来实现。检查笔记本上的代码，但这里是6个不同模型的结果以及原始基线:</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ox"><img src="../Images/e5f7950840587066c65faaaec580d763.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BqeMG4iljDYxx2e4fyxOcA.png"/></div></div></figure><p id="2f81" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">幸运的是，我们看到所有的模型最好的基线表明机器学习将为这个问题工作。总体而言，<a class="ae lm" href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html" rel="noopener ugc nofollow" target="_blank">梯度增强回归方法</a>表现最佳，尽管<a class="ae lm" href="http://setosa.io/ev/ordinary-least-squares-regression/" rel="noopener ugc nofollow" target="_blank">普通最小二乘(OLS)线性回归</a> ( <a class="ae lm" href="https://stats.stackexchange.com/questions/171423/is-ols-the-frequentist-approach-to-linear-regression" rel="noopener ugc nofollow" target="_blank">线性建模的频率主义方法</a>)也表现良好。</p><figure class="mr ms mt mu gt is gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/a586ededc2de3c9bf2e144ef3a26e7b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:460/format:webp/1*9NxHigUNFQ8voWEXEK8klw.png"/></div></figure></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><p id="9182" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">作为最后的练习，我们可以解释OLS线性回归模型。线性回归是最简单的机器学习技术，在具有大量特征的复杂非线性问题上表现不佳，但它具有易于解释的优势。我们可以使用训练好的模型从线性回归中提取预测公式。下面是公式:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="689a" class="na lv jb mw b gy nb nc l nd ne"><strong class="mw jc">Grade = 9.19 - 1.32 * failures + 1.86 * higher_edu + 0.26 * mother_edu + 0.58 * studytime + 0.03 * father_edu - 0.07 * absences</strong></span></pre><p id="d340" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">截距，9.19，代表我们的猜测，如果一个学生的每个变量都是0。系数(也称为权重或模型参数)表示相应变量单位增加的影响。例如，每增加一次以前的失败，学生的分数预计会减少1.32分，母亲的教育每增加一分，学生的分数增加0.26分。在解决问题时，我经常喜欢从线性回归开始，因为如果它足够好，我们就有了一个完全可以解释的模型，我们可以用它来进行预测。</p><h1 id="6612" class="lu lv jb bd lw lx ly lz ma mb mc md me kh mf ki mg kk mh kl mi kn mj ko mk ml bi translated">结论</h1><p id="331e" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">虽然机器学习得到了所有的关注，但它通常只是数据科学项目的一小部分。大部分工作——也是大部分价值——来自于获取、清理和探索数据。只有当我们牢牢掌握了数据的结构和其中的关系，我们才应该着手建立机器学习模型。我想展示这个项目的整个过程，以展示一个典型的数据科学工作流程。在这个项目的前半部分，我们:</p><ul class=""><li id="875d" class="nv nw jb ks b kt ku kw kx kz nx ld ny lh nz ll oa ob oc od bi translated">探索数据以发现有趣的模式、趋势或异常</li><li id="19a5" class="nv nw jb ks b kt oe kw of kz og ld oh lh oi ll oa ob oc od bi translated">检查特征和目标之间的相关性</li><li id="9cac" class="nv nw jb ks b kt oe kw of kz og ld oh lh oi ll oa ob oc od bi translated">使用相关值执行特征选择</li><li id="387d" class="nv nw jb ks b kt oe kw of kz og ld oh lh oi ll oa ob oc od bi translated">建立了基线和基准机器学习模型</li></ul><p id="111e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这些技术同样适用于任何机器学习问题，所以请随意将它们作为您下一个项目的起点。虽然特定机器学习模型的确切实现细节可能不同，但数据科学问题的<a class="ae lm" rel="noopener" target="_blank" href="/a-data-science-workflow-26c3f05a010e">总体结构是相当一致的</a>。</p><p id="b2f4" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><a class="ae lm" href="https://medium.com/@williamkoehrsen/bayesian-linear-regression-in-python-using-machine-learning-to-predict-student-grades-part-2-b72059a8ac7e" rel="noopener">在本系列的下半部分</a>，我们将使用Python 中的<a class="ae lm" href="http://docs.pymc.io/notebooks/getting_started" rel="noopener ugc nofollow" target="_blank"> PyMC3实现一个贝叶斯线性回归模型。我们将建立模型，训练模型(在这种情况下，这意味着从后验抽样)，检查模型的推论，并使用结果进行预测。我们在那里见！</a></p><p id="240e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">一如既往，我欢迎反馈和建设性的批评。你可以在推特上找到我。</p></div></div>    
</body>
</html>