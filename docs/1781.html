<html>
<head>
<title>Deep Gray Matter (DGM) Segmentation using 3D Convolutional Neural Network: application to QSM (Part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用3D卷积神经网络的深部灰质(DGM)分割:在QSM的应用(第一部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-gray-matter-dgm-segmentation-using-neural-network-application-to-qsm-a0183cb3e3ae?source=collection_archive---------4-----------------------#2017-10-20">https://towardsdatascience.com/deep-gray-matter-dgm-segmentation-using-neural-network-application-to-qsm-a0183cb3e3ae?source=collection_archive---------4-----------------------#2017-10-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="ee8a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">【更新2018–02–04】:新的结果可以在<a class="ae kl" href="https://medium.com/@zheliu/deep-gray-matter-dgm-segmentation-using-3d-convolutional-neural-network-application-to-qsm-part-83c247416389" rel="noopener"> Part 2 </a>找到。</p><h1 id="bff2" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">密码</h1><p id="9634" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">可在Github获得:【https://github.com/zl376/segDGM_CNN T2】</p><h1 id="9406" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">动机</h1><p id="1ea2" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">在MRI分析中，计算机化的自动分割是期望的，并且实际上被广泛研究。具体而言，对于QSM(定量磁化率绘图)，一种量化和描绘受试者中铁/钙分布的MRI技术，深灰质(DGM)的感兴趣区域(ROI)测量是不同重建算法之间一致性的公认度量。DGM铁矿资源丰富，是QSM的一个亮点，因此通常选择该地区作为研究目标。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/e985093d0c8204be0ad044764f4d6dc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cfltK3B4BWV93t1__ZjrsA.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Deep Gray Matter includes: Basal ganglia (Globus pallidus, Putamen and Caudate nucleus), subthalamic nucleus and substantia nigra.</figcaption></figure><p id="7a34" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通常，DGM ROI的绘制是由经验丰富的放射科医生手动完成的，这需要花费大量的时间，并且固有地限制了分析的样本量(&lt;20 subjects). Therefore, I try to train a neural network to segment the DGM based on QSM, for ROI measurement analysis at a potentially large scale (e.g. ~500 subjects).</p><h1 id="aefb" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">Method</h1><p id="9012" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">Convolutional Neural Network is chosen as the framework for segmentation. The model used in this work is based on:</p><ul class=""><li id="9a4b" class="mf mg iq jp b jq jr ju jv jy mh kc mi kg mj kk mk ml mm mn bi translated"><a class="ae kl" href="http://www.sciencedirect.com/science/article/pii/S1053811917303324" rel="noopener ugc nofollow" target="_blank">用于MRI皮质下分割的3D全卷积网络:一项大规模研究</a></li><li id="e111" class="mf mg iq jp b jq mo ju mp jy mq kc mr kg ms kk mk ml mm mn bi translated"><a class="ae kl" href="https://github.com/joseabernal/iSeg2017-nic_vicorob" rel="noopener ugc nofollow" target="_blank">使用三维完全卷积神经网络和伪标记进行六个月婴儿脑组织分割</a></li></ul><p id="7c60" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当前的CNN是通过以下平台/包实现的:</p><ul class=""><li id="2dc3" class="mf mg iq jp b jq jr ju jv jy mh kc mi kg mj kk mk ml mm mn bi translated">张量流</li><li id="f310" class="mf mg iq jp b jq mo ju mp jy mq kc mr kg ms kk mk ml mm mn bi translated">Python 3.5</li><li id="0372" class="mf mg iq jp b jq mo ju mp jy mq kc mr kg ms kk mk ml mm mn bi translated">Keras 2.0.2</li></ul><h1 id="6d30" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">数据预处理</h1><p id="5aaf" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">这项工作收集并命名了来自20个受试者的QSM。由有经验的专家在每个病例上绘制不同深灰质(DGM)的ROI，并将其作为参考分割。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mt"><img src="../Images/11207a98f3a37e6bb4ba93dca03002a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o_F0IXiQ9rFSXhBH5Pq-fA.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Example for QSM (left) and ROI (right) for DGM</figcaption></figure><p id="901e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">QSM重建的原始结果跨越一系列矩阵大小、分辨率和覆盖范围(视野)，因此数据在输入网络之前需要归一化。</p><h2 id="af47" class="mu kn iq bd ko mv mw dn ks mx my dp kw jy mz na la kc nb nc le kg nd ne li nf bi translated">数据标准化</h2><p id="c7bc" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">所有20个三维图像被重新调整到相同的体素尺寸(1毫米、1毫米、3毫米)并被裁剪成矩阵尺寸(160、220、48)。这提供了(16厘米，22厘米，14.4厘米)的体积覆盖，对于普通人的大脑来说足够大。QSM的磁化率值被裁剪为-0.2ppm至0.2ppm，并重新调整为0~255。从人工分割中提取11个类别:1个类别用于背景，2个类别(左/右)用于5个DGM中的每一个。处理后的图像保存为Nifti文件，并提供给以下CNN。</p><p id="5994" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">15个案例表示为训练集，5个用于测试。</p><h1 id="5545" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">训练CNN</h1><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ng"><img src="../Images/e2d0cf55be959ebc318e0ac27d2eba1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4b25_fbpdmx9IavsWjaBTQ.jpeg"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Overview of the 3D CNN, as proposed by <a class="ae kl" href="http://www.sciencedirect.com/science/article/pii/S1053811917303324" rel="noopener ugc nofollow" target="_blank">Dolz et al. Neuroimage 2017</a>.</figcaption></figure><p id="4ee3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如在用于iSeg2017 的<a class="ae kl" href="https://github.com/joseabernal/iSeg2017-nic_vicorob" rel="noopener ugc nofollow" target="_blank">解决方案中所建议的，输入3D体积(QSM和类别标签)被分割成对应于输出片尺寸(9，9，9)的更小的片(27，27，27)，并且仅具有背景标签的那些被从训练中丢弃。这个技巧极大地减少了数据的大小，从而减少了用于训练的内存。对于这项工作，这里的切片厚度(3毫米)比他们的(1毫米)大3倍，因此输入面片大小选择为<strong class="jp ir"> (27，27，21) </strong>，对应于输出大小(9，9，3)。</a></p><p id="4674" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">选择1/4的输入数据进行验证。选择交叉熵作为损失函数。</p><h2 id="1fce" class="mu kn iq bd ko mv mw dn ks mx my dp kw jy mz na la kc nb nc le kg nd ne li nf bi translated">针对误报的微调</h2><p id="46a6" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">由于一些补丁在训练前就被丢弃了，这些区域的信息还没有被CNN利用。在训练CNN之后，如果这些小块通过网络并与参考标签比较(验证)，观察到背景类可能被错误分类为DGM，这被表征为假阳性。</p><p id="813c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">那些假阳性被CNN的第二轮微调处理:那些具有假阳性的小块被包括在输入集合中；然后，基于先前获得的“最优”权重，使用扩充的输入数据来重新训练网络。</p><h2 id="2ab1" class="mu kn iq bd ko mv mw dn ks mx my dp kw jy mz na la kc nb nc le kg nd ne li nf bi translated">参数选择</h2><p id="846c" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">学习率被指定为0.0001，然后减少到0.00001。最大历元数为40，当验证损失停止下降时，触发提前停止。</p><h1 id="022b" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">后处理</h1><p id="704a" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">正如在<a class="ae kl" href="http://www.sciencedirect.com/science/article/pii/S1053811917303324" rel="noopener ugc nofollow" target="_blank">大型研究论文</a>中注意到的，分割可能由一些孤立的小“岛”组成，而不是目标DGM构造。这是为了在每个DGM ROI的分割中保持最大的连通分量。</p><h1 id="d4b3" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">结果和评估</h1><p id="9eeb" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">计算每个DGM的精度(真阳性对所有阳性预测)和<a class="ae kl" href="https://en.wikipedia.org/wiki/Sørensen–Dice_coefficient" rel="noopener ugc nofollow" target="_blank">骰子点数</a>，如下所示。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nh"><img src="../Images/dfff8144e4ee4cf606318bfa598a1785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yFht1hvc0wKTsGRYIHJOlQ.png"/></div></div></figure><p id="1b48" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一个很好的例子:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ni"><img src="../Images/bb19893a3a17107d6d71b8f7dfda0885.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tp7yJhQdiMqpEv_iaCdVkQ.png"/></div></div></figure><p id="381c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一个不太好的例子:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ni"><img src="../Images/c4e3b78d1dd7a076b2d96d2bfa09f157.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sNx6HDixgzZLThcZ8fNseQ.png"/></div></div></figure><p id="d5f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在结果中观察到对特定DGM(尤其是黑质和尾状核)的低估。对于这两个DGM，这也在表中表示为低骰子分数。</p><h1 id="7ecf" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">讨论</h1><h2 id="8d88" class="mu kn iq bd ko mv mw dn ks mx my dp kw jy mz na la kc nb nc le kg nd ne li nf bi translated">样本量</h2><p id="07e0" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">在这项工作中，样本量有点小(15个训练+ 5个测试)，但已经给出了一些有希望的结果，如上所示。保存所有3D碎片所需的昂贵的3D卷积和存储器是使用大样本量的主要障碍。在目前的训练平台上(酷睿i3，16GB RAM，11GB内存的GTX 1080Ti)，微调阶段占用了大约50%的GPU内存。潜在地，样本大小可以加倍(到~40)并且可以使用交叉验证来进一步评估CNN的性能。</p><h2 id="fd83" class="mu kn iq bd ko mv mw dn ks mx my dp kw jy mz na la kc nb nc le kg nd ne li nf bi translated">损失函数</h2><p id="d313" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">在当前的训练中，分类交叉熵被用作损失函数。虽然Dice分数等其他指标被广泛用于量化ROI协议，但有趣的是，看看用Dice分数代替交叉熵是否会提高CNN。</p><h2 id="69c1" class="mu kn iq bd ko mv mw dn ks mx my dp kw jy mz na la kc nb nc le kg nd ne li nf bi translated">分割不足</h2><p id="9435" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">当应用于5个测试病例时，CNN有时不能描绘某些DGM区域的整个结构，尤其是尾状核。这可能与卷积层中使用的内核大小有关。</p><p id="9925" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就引出了另一个有趣的问题:<em class="nj">欠分割真的是ROI分析的一个问题吗，尤其是在比较不同的QSM重建算法时？</em></p><h2 id="1cab" class="mu kn iq bd ko mv mw dn ks mx my dp kw jy mz na la kc nb nc le kg nd ne li nf bi translated">多类vs .二进制？</h2><p id="6194" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">考虑到DGM在解剖和功能上是相互联系的，至少对于基底神经节而言是如此，在基底神经节中，苍白球、壳核和尾状核之间的界面难以确定，因此多类分割可能不是这一特定任务的最佳框架。同时，整个任务可能被分成更小的子任务，其中我们使用二元分类器来分割每个ROI:例如，在分割左侧苍白球时，目标结构中的体素被标记为类1，而其他所有的被表示为类0。训练速度可以受益于这种任务划分，因为对于每个子任务(ROI ),涉及的补丁数量比原始多类任务中的小得多。当所有子任务同时执行时，训练过程以ROI数量的因子加速。</p><h2 id="c98c" class="mu kn iq bd ko mv mw dn ks mx my dp kw jy mz na la kc nb nc le kg nd ne li nf bi translated">多模态输入</h2><p id="d3e0" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">在<a class="ae kl" href="https://github.com/joseabernal/iSeg2017-nic_vicorob" rel="noopener ugc nofollow" target="_blank">iseg 2017</a>的解决方案中，T1和T2加权图像均用作每个受试者的输入。T1和T2加权图像显示的不同对比度可能有助于区分不同的结构。而在QSM的研究中，T1/T2图像通常是稀少的，或者如果有的话，也是未注册的，因为它们是在不同的时段获得的。然而，其他图像模态，如幅度(单回波)或R2*图(演示信号在多个回波中衰减的速度)很容易与每个QSM图一起使用，并可以并入当前的CNN。它对多通道输入数据的性能将是一个有趣的研究课题。</p></div></div>    
</body>
</html>