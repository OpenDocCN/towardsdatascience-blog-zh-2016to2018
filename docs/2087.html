<html>
<head>
<title>NIPS 2017 symposium and workshop: interpretable and Bayesian machine learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NIPS 2017研讨会和讲习班:可解释和贝叶斯机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nips-2017-symposium-and-workshop-interpretable-and-bayesian-machine-learning-fca56edfebe4?source=collection_archive---------6-----------------------#2017-12-16">https://towardsdatascience.com/nips-2017-symposium-and-workshop-interpretable-and-bayesian-machine-learning-fca56edfebe4?source=collection_archive---------6-----------------------#2017-12-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3e0a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">我的第一次NIPS出席和总结</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/62f8516816980452697dfc071354e611.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iQZZax8YKqisq24DCafI_w.jpeg"/></div></div></figure><p id="b255" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">上周，我参加了在加州长滩举行的NIPS(神经信息处理系统)2017会议。这是我第一次参加NIPS。</p><h1 id="b164" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">什么是NIPS？</h1><p id="e527" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated"><a class="ae mk" href="https://nips.cc/" rel="noopener ugc nofollow" target="_blank"> NIPS </a>是世界上最大的机器学习(ML) /人工智能(AI)会议之一。NIPS会议由三个项目组成:指导、主要活动(包括研讨会)和研讨会。今年，约有8000人出席，比去年增加了约30%，显示出对机器学习的兴趣越来越大。</p><p id="f59c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我只参加了研讨会和专题讨论会，但是根据它们的内容，我可以看到每个研讨会都是一个专门的专题，一整天都致力于一个单一的主题。每个研讨会由5-6个讲座和海报会议组成。大多数工作坊最后还会有小组讨论。我参加了关于贝叶斯ML的研讨会和关于可解释ML的座谈会。</p><h1 id="4783" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">赞助商</h1><p id="2c99" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">在谈论大会演讲之前，我首先想让你看看赞助商名单，因为它可以显示当前机器学习在行业中的格局。仅举几个赞助商的例子，<strong class="kt ir">微软、IBM Research、奥迪、英特尔Nervana </strong>是钻石赞助商(8万美元赞助)，其次是白金赞助商(4万美元)，如<strong class="kt ir">苹果、优步、脸书、谷歌、百度、阿里巴巴、亚马逊、DeepMind </strong>等。综合列表见<a class="ae mk" href="https://nips.cc/Conferences/2017/Sponsors" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><h1 id="2271" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">主题</h1><p id="b1ae" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">研讨会原定了两天。每个研讨会都是全天的，包括来自学术界和工业界的演讲以及海报展示。今年，大约有50个讲习班。这些主题涵盖了学科和技术/方法方面的广泛材料。</p><p id="f6b1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">就学科而言，有专门针对学术领域的研讨会，</p><ul class=""><li id="ed8c" class="ml mm iq kt b ku kv kx ky la mn le mo li mp lm mq mr ms mt bi translated">生物</li><li id="96dd" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">神经系统科学</li><li id="5b26" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">医学</li><li id="d12a" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">自然科学</li></ul><p id="33e5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">IT相关行业，</p><ul class=""><li id="50c8" class="ml mm iq kt b ku kv kx ky la mn le mo li mp lm mq mr ms mt bi translated">机器人学</li><li id="bcb9" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">网络安全</li><li id="fda5" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">系统</li><li id="83b8" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">超级计算</li><li id="90cd" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">物联网设备</li><li id="fd6d" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">软件开发</li><li id="a926" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">运输</li></ul><p id="ab2c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">以及更多与人类相关的领域</p><ul class=""><li id="f52f" class="ml mm iq kt b ku kv kx ky la mn le mo li mp lm mq mr ms mt bi translated">卫生保健</li><li id="f78f" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">AI透明度/公平性</li><li id="35e5" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">发展中国家的ML应用</li><li id="a193" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">创意和设计。</li></ul><p id="d33f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">ML技术方面的主题也变化很大；</p><ul class=""><li id="2ff3" class="ml mm iq kt b ku kv kx ky la mn le mo li mp lm mq mr ms mt bi translated">深度学习(通用)</li><li id="6432" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">深度强化学习</li><li id="dba1" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">贝叶斯深度学习</li><li id="770e" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">元学习</li><li id="3e28" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">半监督学习</li><li id="8062" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">建议</li><li id="d4f3" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">因果推理</li><li id="66ca" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">自然语言处理</li><li id="143b" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">音频信号处理</li><li id="2073" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">时间序列</li><li id="33f9" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">可量测性</li><li id="2eab" class="ml mm iq kt b ku mu kx mv la mw le mx li my lm mq mr ms mt bi translated">可视化和交流</li></ul><h1 id="f06f" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">研讨会:<a class="ae mk" href="http://interpretable.ml/" rel="noopener ugc nofollow" target="_blank">可解释机器学习</a></h1><p id="88b6" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">我在研讨会前一天到达，参加了关于可解释ML的研讨会。</p><p id="a4a9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">可解释的ML不仅有利于帮助用户理解ML模型的结果，而且有利于使人工智能安全可靠。然而，可解释的ML是具有挑战性的。总的来说，演讲者同意很难定义术语“可解释性”，因为它是一个以人为中心的术语，依赖于用户的类型，这甚至可能涉及用户体验方面。另外，当前的可解释ML方法也有局限性。目前，大致有两种方式来构建可解释的ML算法:1)使用简单(例如，线性)算法，或者2)使用局部描述黑盒模型的“模仿”算法(例如，LIME)。两者都有缺点；如果数据具有复杂的分布，简单的算法很可能具有较低的精度，并且模拟算法很容易失败。无论如何，这一部分的讨论试图解决当前ML景观中的问题，并检验可解释ML的不同元素。</p><p id="8071" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了在图像分类/识别任务中使用可解释性ML，奇莉·瓦格斯塔夫(JPL)展示了如何通过使用<a class="ae mk" href="https://github.com/wkiri/DEMUD" rel="noopener ugc nofollow" target="_blank"> DEMUD </a>来可视化深度神经网络中的可解释性和学习过程，DEMUD 学习连续信息之间的残差(差异)。Kilian Q. Weinberger (Cornell)提出了对现代神经网络的担忧，这些网络具有很差的校准置信度(即<a class="ae mk" href="https://arxiv.org/pdf/1706.04599.pdf" rel="noopener ugc nofollow" target="_blank">过度自信</a>，这在自动驾驶汽车和自动医疗诊断等实际应用中可能是一个问题。</p><p id="335a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Jenn Wortman Vaughan(微软)建议可解释性应该跨学科理解，应该考虑人类；根据用户的不同，可解释性可能有不同的含义。沃恩使用亚马逊机械土耳其人进行了一项有趣的实验<a class="ae mk" href="http://s.interpretable.ml/nips_interpretable_ml_2017_jenn_wortman_vaughan.pdf" rel="noopener ugc nofollow" target="_blank">，在那里她测试了人类受试者对简单模型的理解是否优于更复杂的模型(例如，黑盒、更多功能)。受试者能够更好地遵循更简单的模型，尽管他们对两个模型的信心水平相似(与人们对黑盒模型的信任度低于简单模型的普遍看法相反)。这是一项初步的工作，但它简单而新颖，因为这项研究试图真正包括人类，并测量他们对ML模型的反应及其预测。</a></p><p id="36ca" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">还进行了小组讨论，发言者回答了一系列问题。首先，他们承认定义“可解释性”是困难的。他们同意贝叶斯方法可以通过提供一些因素和预测不确定性之间关系的信息来帮助黑盒模型。他们还证实，金融和医药等高风险行业领域更抵制黑箱模型，更喜欢可解释性。也有一些对“模仿模型”的批评，因为他们没有提供一个基本的解释，而是更多的事后解释。为了比较可解释模型的不同方法，研究人员同意需要进行涉及人类的实验。总的来说，他们一致认为，要在这个问题上取得突破，首先应该进行系统的人体实验，并更好地定义可解释性。</p><h1 id="bb55" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">车间</h1><p id="1153" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">今年大约有50场研讨会，有很多有趣的话题。很难选择参加哪一个，但我决定参加贝叶斯机器学习。我做出这个决定背后的动机是1)我在博士期间学习了贝叶斯推理，我对这个主题略有熟悉，2)我一直对深度学习持怀疑态度，深度学习的贝叶斯治疗听起来像是对当前深度学习炒作的一种补救措施，3)贝叶斯机器学习是机器学习中的一个新兴主题。尽管两个研讨会都侧重于技术细节(如同大多数贝叶斯推理材料)，但我还是想总结几个要点。</p><h1 id="3e9e" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">第一天:<a class="ae mk" href="http://approximateinference.org/" rel="noopener ugc nofollow" target="_blank">近似贝叶斯推理的进展</a></h1><p id="354f" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">尽管在深度学习方面取得了显著的进步，但这些深度神经网络缺乏解决其预测中的不确定性的能力，并且没有利用概率论。因此，最近研究人员一直在尝试融合贝叶斯方法和深度学习。贝叶斯推理的主要挑战是在计算后验概率时近似难以处理的边际概率分布。有两种方法可以解决这个问题；一种是设计一个易于估计的概率分布，该概率分布接近真实分布并试图减小这两个分布之间的距离，另一种是使用抽样方法(蒙特卡罗模拟)建立后验概率。第一种方法通常被称为变分推理(VI)。大概，第二种方法中最流行的方法就是马尔可夫链蒙特卡罗(MCMC)。尽管每种方法都有自己的优点和缺点，但大多数人对VI比对抽样方法更感兴趣，主要是因为VI更快，更具确定性。</p><p id="d2a8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在近似贝叶斯推理研讨会上提出了许多新颖的方法。Josip Djolonga(苏黎世联邦理工学院)提出了一种近似方法，这种方法利用了欺骗双样本统计测试的想法。“如果我们能骗过统计测试，学习到的分布应该是真实数据的一个很好的模型。”李英珍提出了<a class="ae mk" href="https://arxiv.org/abs/1705.07107" rel="noopener ugc nofollow" target="_blank">直接估计得分函数而不是近似优化目标的思想，用于基于梯度的优化</a>，可以缓解广义敌对网络(GAN)的缺陷，如过拟合和低估损失函数。Kira Kempinska(伦敦大学学院)给出了另一个辉煌，他引入了<a class="ae mk" href="http://bayesiandeeplearning.org/2017/papers/6.pdf" rel="noopener ugc nofollow" target="_blank">对抗序列蒙特卡罗</a>方法，将近似问题公式化为两人游戏，类似于GAN。</p><p id="4211" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">来自工业界的受邀演讲也很有趣。来自网飞的Dawen Liang展示了我们如何使用变分自动编码器(VAE)来构建推荐系统，特别是因为该问题更多地是一个小数据问题，并且用户-项目交互矩阵仅在它是正的情况下才被观察到(即，在负和无之间没有区别)。来自亚马逊的Andreas Damianou介绍了<a class="ae mk" href="http://proceedings.mlr.press/v31/damianou13a.pdf" rel="noopener ugc nofollow" target="_blank">深度高斯过程</a>，其中的动机是，(再次)利用当前深度学习方法中通过更好地逼近难以处理的分布而包含的推理(即，模型应该根据它们对预测的确定程度以不同的方式表现)。</p><h1 id="a687" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">第二天:<a class="ae mk" href="http://bayesiandeeplearning.org/" rel="noopener ugc nofollow" target="_blank">贝叶斯深度学习</a></h1><p id="6f35" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">从主题上看，这次研讨会与第一次非常相似。然而，在这里，演讲者通过关注概率规划和贝叶斯神经网络(不仅仅是近似方法)展示了一个略大的画面。</p><p id="486f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">会议以Dustin Tran(哥伦比亚大学/谷歌)的演讲开始，他是概率编程库的首席开发人员<a class="ae mk" href="http://edwardlib.org/" rel="noopener ugc nofollow" target="_blank"> Edward </a>。他的演讲是关于概率编程的库和概述。Edward通过支持有向图形模型来支持贝叶斯推理。它是基于TensorFlow构建的，尽管我没有使用过Edward，但根据演示文稿中的代码截图，它的语法似乎与我以前使用过的pymc3非常相似；你定义你的变量的图形结构，它们是随机的还是确定的，这些变量应该有什么分布，等等。它支持变分推理和蒙特卡罗方法。达斯汀预测，即使概率编程可能有很高的认知负担，但由于分布式、编译和加速系统，它将变得更容易使用，这允许在多台机器上进行概率编程。</p><p id="207a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">本次会议的特别演讲人是Max Welling(阿姆斯特丹大学/高通)，他发表了大量关于贝叶斯机器学习的研究，并因其关于<a class="ae mk" href="https://arxiv.org/abs/1312.6114" rel="noopener ugc nofollow" target="_blank">变分自动编码器</a>的论文而闻名。他对Bayesain深度学习进行了概述。首先，他通过重申贝叶斯方法的好处开始了他的讲话:1)我们可以用一个原则来正则化模型，但不会浪费数据(不需要交叉验证)，2)我们可以测量不确定性，3)贝叶斯方法可以用于严格的模型选择。然后他提出了一个开放式的问题；做决策时，我们应该如何处理量化的不确定性？对我来说，测量不确定性和量化不确定性的实际应用可能是两回事。在演讲的最后，他提到贝叶斯深度学习有三条主线；1)深度高斯过程，2)信息瓶颈，以及3)贝叶斯丢失。关于最后一个，他提到事实证明快速退出法是<a class="ae mk" href="https://arxiv.org/abs/1711.02989" rel="noopener ugc nofollow" target="_blank">实际上不是贝叶斯方法</a>，研究人员正在研究全贝叶斯方法。</p><p id="3bbd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Gintare Karolina Dziugaite(剑桥大学/矢量研究所)做了一个有趣的技术演讲，她和Daniel M. Roy(多伦多大学/矢量研究所)设计了一种改进的随机梯度下降(SGD)方法，即“<a class="ae mk" href="http://bayesiandeeplearning.org/2017/papers/53.pdf" rel="noopener ugc nofollow" target="_blank">熵-SGD </a>”，以缓解SGD的过拟合问题。这个问题已经由<a class="ae mk" href="https://arxiv.org/abs/1703.04730" rel="noopener ugc nofollow" target="_blank"> Koh和梁</a>提出，他们的论文被选为今年国际机器学习大会的最佳论文。在Koh和Liang的论文中，证明了具有SGD的深度神经网络可以学习训练数据中完全随机化的标签。</p><h1 id="3483" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">个人想法</h1><p id="24a9" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">尽管我只参加了整个会议的一半，但我可以说，我在NIPS的机器学习领域经历了两个看似非常不同的领域。关于可解释ML的研讨会更多的是关于实际应用和它对人们的影响。研讨会集中讨论了在现代神经网络中注入贝叶斯思想的技术。尽管这些从表面上看起来很不一样，但我实际上认为这两者之间有共同点:研究人员最终希望通过从模型(不确定性)中提取更多信息来建立一个“更智能”的机器，它可以对人类更加负责和透明。</p></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><p id="80be" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ng">原载于2017年12月16日</em><a class="ae mk" href="https://hongsupshin.com/2017/12/16/nips-2017-symposium-and-workshop-interpretable-and-bayesian-machine-learning/" rel="noopener ugc nofollow" target="_blank"><em class="ng">hongsupshin.com</em></a><em class="ng">。</em></p></div></div>    
</body>
</html>