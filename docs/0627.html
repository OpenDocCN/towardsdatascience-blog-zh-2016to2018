<html>
<head>
<title>Boosting the accuracy of your Machine Learning models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">提高机器学习模型的准确性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/boosting-the-accuracy-of-your-machine-learning-models-f878d6a2d185?source=collection_archive---------0-----------------------#2017-05-30">https://towardsdatascience.com/boosting-the-accuracy-of-your-machine-learning-models-f878d6a2d185?source=collection_archive---------0-----------------------#2017-05-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/3e9e1405f4a9150be078fd1dfff4beda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OBkIA141BUtaCblnLlYTxA.jpeg"/></div></div></figure><div class=""/><p id="2d95" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">厌倦了机器学习模型的低准确率吗？助推是来帮忙的。<em class="kw"> Boosting是一种流行的机器学习算法，可以提高你的模型的准确性，</em>就像赛车手使用nitrous boost来提高他们的汽车速度一样。</p><p id="8978" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Boosting使用基本的机器学习算法来拟合数据。这可以是任何算法，但决策树是最广泛使用的。要知道为什么会这样，请继续阅读。<strong class="ka jc"> <em class="kw">另外，boosting算法很容易用决策树来解释，这将是本文的重点。</em> </strong>它建立在boosting之外的方法之上，可以提高决策树的准确性。关于基于树的方法的介绍，请在这里阅读我的另一篇文章<a class="ae kx" href="https://medium.com/towards-data-science/decision-trees-in-machine-learning-641b9c4e8052" rel="noopener"><strong class="ka jc"/></a>。</p><h2 id="01b9" class="ky kz jb bd la lb lc dn ld le lf dp lg kj lh li lj kn lk ll lm kr ln lo lp lq bi translated">拔靴带</h2><p id="8092" class="pw-post-body-paragraph jy jz jb ka b kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr lv kt ku kv ij bi translated">我想先解释一个重要的基础技术，叫做<strong class="ka jc">引导</strong>。假设我们需要学习一个决策树，根据100个输入来预测房子的价格。<em class="kw">考虑到</em> <a class="ae kx" href="https://medium.com/towards-data-science/balancing-bias-and-variance-to-control-errors-in-machine-learning-16ced95724db" rel="noopener"> <em class="kw">方差</em> </a> <em class="kw">的问题，这样的决策树预测准确率会很低。</em>这意味着，如果我们将训练数据随机分成两部分，并为这两部分安装决策树，我们可能会得到完全不同的结果。我们真正想要的是一个结果，如果重复应用于不同的数据集，它的方差很低。</p><blockquote class="lw"><p id="5768" class="lx ly jb bd lz ma mb mc md me mf kv dk translated">我们可以使用Bootstrapping来提高决策树的预测精度</p></blockquote><ol class=""><li id="e9c1" class="mg mh jb ka b kb mi kf mj kj mk kn ml kr mm kv mn mo mp mq bi translated">使用替换创建数据集的许多(例如100个)随机子样本(意味着我们可以多次选择相同的值)。</li><li id="2609" class="mg mh jb ka b kb mr kf ms kj mt kn mu kr mv kv mn mo mp mq bi translated">对每个样本学习(训练)一个决策树。</li><li id="5f07" class="mg mh jb ka b kb mr kf ms kj mt kn mu kr mv kv mn mo mp mq bi translated">给定新数据集，计算每个子样本的预测。</li><li id="9ab5" class="mg mh jb ka b kb mr kf ms kj mt kn mu kr mv kv mn mo mp mq bi translated">计算我们收集的所有预测的平均值(也称为bootstrap估计)，并将其用作我们对数据的估计预测。</li></ol><p id="272d" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该程序同样适用于<em class="kw">分类树</em>。例如，如果我们有5个决策树，它们对输入样本进行以下类别预测:蓝色、蓝色、红色、蓝色和红色，我们将选择最频繁的类别并预测蓝色。</p><p id="2195" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc"> <em class="kw">用这种方法，树长得很深，不用修剪</em> </strong>。<strong class="ka jc"> <em class="kw">因此每一株树都有很高的方差，但偏差很低。对这些树进行平均可以显著降低方差。</em> </strong></p><p id="bf61" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw"> Bootstrapping是一种强大的统计方法，用于从数据样本中估计数量</em>。数量可以是一种描述性统计，如平均值或标准差。<strong class="ka jc"> <em class="kw">将Bootstrapping过程应用于高方差机器学习算法，通常是上例所示的决策树，称为Bagging(或bootstrap aggregating)。</em> </strong></p><h2 id="fafb" class="ky kz jb bd la lb lc dn ld le lf dp lg kj lh li lj kn lk ll lm kr ln lo lp lq bi translated"><strong class="ak">误差估计</strong></h2><p id="fc03" class="pw-post-body-paragraph jy jz jb ka b kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr lv kt ku kv ij bi translated">估算袋装模型测试误差的简单方法是<strong class="ka jc">袋外误差估算</strong>，无需交叉验证。未用于拟合给定袋装树的观测值称为袋外(OOB)观测值。我们可以简单地预测第<em class="kw"> i </em>次观察的反应，使用每一棵树，其中观察是OOB。我们对这些预测的回答进行平均，或者采取多数投票，这取决于回答是定量的还是定性的。<em class="kw">可以计算总体OOB MSE(均方误差)或分类误差率。</em>这是一个可接受的测试误差率，因为预测仅基于不适合使用该观测值的树木。</p><h2 id="a4c0" class="ky kz jb bd la lb lc dn ld le lf dp lg kj lh li lj kn lk ll lm kr ln lo lp lq bi translated">随机森林</h2><p id="c4d5" class="pw-post-body-paragraph jy jz jb ka b kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr lv kt ku kv ij bi translated">决策树渴望最小化成本，这意味着它们利用最强的预测器/分类器来分割分支。<em class="kw">因此，从自举样本中得到的大多数树将在不同的分裂中使用相同的强预测器。这与树相关并导致差异</em>。</p><blockquote class="lw"><p id="b5e9" class="lx ly jb bd lz ma mb mc md me mf kv dk translated">我们可以使用随机森林来提高袋装树的预测精度</p></blockquote><p id="f933" class="pw-post-body-paragraph jy jz jb ka b kb mi kd ke kf mj kh ki kj mw kl km kn mx kp kq kr my kt ku kv ij bi translated">在分割任何树的分支时，从全部的<em class="kw"> p </em>预测值中选择随机抽样的<em class="kw"> m </em>个预测值作为分割候选值。然后允许分裂只使用那些<em class="kw"> m </em>预测器中的一个。在每一次分裂时，都要对m个预测值进行新的采样。您可以尝试不同的值，并使用交叉验证进行调整。</p><ul class=""><li id="23dc" class="mg mh jb ka b kb kc kf kg kj mz kn na kr nb kv nc mo mp mq bi translated">对于分类，一个好的缺省值是:m = sqrt(p)</li><li id="d17f" class="mg mh jb ka b kb mr kf ms kj mt kn mu kr mv kv nc mo mp mq bi translated">对于回归，一个好的缺省值是:m = p/3</li></ul><p id="00b0" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，平均而言，splits的(<em class="kw">p</em>—<em class="kw">m</em>)/<em class="kw">p</em>甚至不会考虑强预测器。这被称为<strong class="ka jc"> <em class="kw">去相关</em> </strong> <em class="kw">树，因为我们使用相同的强预测器来解决每个树的问题。</em></p><blockquote class="nd ne nf"><p id="59ec" class="jy jz kw ka b kb kc kd ke kf kg kh ki ng kk kl km nh ko kp kq ni ks kt ku kv ij bi translated"><strong class="ka jc">如果<em class="jb"> m </em> = <em class="jb"> p </em>那么随机森林等于装袋。</strong></p></blockquote><h2 id="fdc1" class="ky kz jb bd la lb lc dn ld le lf dp lg kj lh li lj kn lk ll lm kr ln lo lp lq bi translated">特征重要性</h2><p id="12e2" class="pw-post-body-paragraph jy jz jb ka b kb lr kd ke kf ls kh ki kj lt kl km kn lu kp kq kr lv kt ku kv ij bi translated">计算完全长成的树的一个问题是，我们不容易解释结果。也不再清楚哪些变量对这种关系是重要的。<em class="kw">计算变量在每个分割点的误差函数的下降，给我们一个特征重要性的概念</em>。<strong class="ka jc"> <em class="kw">这意味着我们记录了由于给定预测因子上的分裂而减少的误差总量，对所有袋装树进行平均。较大的值表示重要的预测值。</em> </strong>在回归问题中这可能是残差平方和的下降，在分类中这可能是基尼系数。</p><h2 id="1de3" class="ky kz jb bd la lb lc dn ld le lf dp lg kj lh li lj kn lk ll lm kr ln lo lp lq bi translated">助推</h2><blockquote class="lw"><p id="b1c3" class="lx ly jb bd lz ma mb mc md me mf kv dk translated">使用Boosting算法可以进一步提高决策树的预测精度。</p></blockquote><p id="ad26" class="pw-post-body-paragraph jy jz jb ka b kb mi kd ke kf mj kh ki kj mw kl km kn mx kp kq kr my kt ku kv ij bi translated">boosting背后的基本思想是将许多弱学习者转化成一个强学习者。 我们所说的弱学习者是什么意思？</p><p id="d6d4" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc"> <em class="kw">弱学习器</em> </strong>是一种学习器，当它试图标记数据时，无论训练数据的分布如何，它总是比机会做得更好。比机会做得更好意味着我们的错误率总是小于1/2。<em class="kw">这意味着学习算法总是要学习一些东西，并且不会总是完全准确，即，当学习输入和目标之间的关系时，它是弱的和差的。</em>这也意味着使用单个预测器/分类器形成的规则单独来说并不强大。</p><p id="376e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们开始在数据集中寻找弱学习者，通过做一些分布并从它们形成小决策树。树的大小是使用它的分裂数来调整的。通常情况下，1可以很好地工作，其中每棵树都由一个单独的裂口组成。这种树被称为<strong class="ka jc">决策树桩。</strong></p><p id="775c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">boosting采用的另一个参数是迭代次数或树的数量。此外，它会根据输入是否被正确预测/分类来为输入分配权重。让我们看看算法。</p><ol class=""><li id="5e5f" class="mg mh jb ka b kb kc kf kg kj mz kn na kr nb kv mn mo mp mq bi translated"><strong class="ka jc">首先，用相等的权重初始化输入</strong>。它使用第一个基本学习算法来完成这个任务，这通常是一个决策树桩。这意味着，在第一阶段，它将是一个弱学习者，将适合数据的子样本，并对所有数据进行预测。</li><li id="0c28" class="mg mh jb ka b kb mr kf ms kj mt kn mu kr mv kv mn mo mp mq bi translated">现在我们做下面的<strong class="ka jc">直到达到树的最大数量</strong>:</li></ol><ul class=""><li id="bbe5" class="mg mh jb ka b kb kc kf kg kj mz kn na kr nb kv nc mo mp mq bi translated">基于以前的运行更新输入的权重，对于错误预测/分类的输入，权重更高</li><li id="3075" class="mg mh jb ka b kb mr kf ms kj mt kn mu kr mv kv nc mo mp mq bi translated">制定另一个规则(在这种情况下是决策树桩),并使其适合数据的子样本。注意，这个时间规则将通过记住错误分类的输入(具有较高权重的输入)来形成。</li><li id="b22e" class="mg mh jb ka b kb mr kf ms kj mt kn mu kr mv kv nc mo mp mq bi translated">最后，我们使用该规则预测/分类所有输入。</li></ul><p id="793a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">3.<strong class="ka jc">迭代完成后，我们将弱规则组合成一个强规则</strong>，然后将其用作我们的模型。</p><p id="2697" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">借助图表可以更好地解释上述算法。假设我们有10个输入观察值，我们想把它们归类为“+”或“-”。</p><figure class="nk nl nm nn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nj"><img src="../Images/72fd37e1429c0d511f7f794995ee609e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*OCbjhFH6kfquNOO3RGE9Aw.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Image source : Analytics Vidhya</figcaption></figure><ul class=""><li id="e900" class="mg mh jb ka b kb kc kf kg kj mz kn na kr nb kv nc mo mp mq bi translated">如上所示，升压算法将从框1开始。它为所有输入分配相等的权重(由符号的大小表示),并使用决策树桩D1预测蓝色区域的输入为“+”,红色区域的输入为“-”。</li><li id="612d" class="mg mh jb ka b kb mr kf ms kj mt kn mu kr mv kv nc mo mp mq bi translated">在下一次迭代中，框2，您可以看到错误分类的加号的权重大于其他输入。所以选择了一个判定难题D2，这样，这些观察现在被正确地分类了。</li><li id="c8f8" class="mg mh jb ka b kb mr kf ms kj mt kn mu kr mv kv nc mo mp mq bi translated">在最后的迭代中，框3，它具有来自先前运行的3个错误分类的否定。因此选择判定树桩D3来纠正这种情况。</li><li id="630c" class="mg mh jb ka b kb mr kf ms kj mt kn mu kr mv kv nc mo mp mq bi translated">最后，输出强学习器或框3具有通过组合各个弱决策树桩而形成的强规则。你可以看到我们是如何提高模型的分类能力的。</li></ul><p id="b417" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在回归设置中，预测误差(通常使用最小二乘法计算)用于调整输入的权重，因此学习者更关注误差大的输入。</p><p id="7574" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">这种类型的增强方法被称为自适应增强或AdaBoost。</strong>与树一样，boosting方法也将损失函数降至最低。<em class="kw">在Adaboost的情况下，是指数损失函数</em>。</p><p id="337f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">boosting的另一个流行版本是梯度Boosting算法</strong>。基本概念保持不变，<em class="kw">除了这里我们不玩权重，但是</em> <strong class="ka jc"> <em class="kw">拟合残差</em> </strong>(预测和原始结果的差异的度量)而不是原始结果上的模型。<strong class="ka jc"> </strong>这意味着新的弱学习器是在牢记具有高残差的输入的情况下形成的。</p><p id="7bc9" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这两种算法中，调谐参数<strong class="ka jc"><em class="kw">λ</em>或<em class="kw">收缩</em> </strong> <em class="kw"> </em>通过允许更多不同形状的树攻击残差来进一步减慢过程。这也被称为<strong class="ka jc">学习率</strong>，因为它控制每棵树对模型贡献的大小。如你所见，<strong class="ka jc"> <em class="kw"> Boosting也不涉及</em> </strong>的自举，取而代之的是每棵树都适合原始数据的一个修改版本。而不是拟合单个大型决策树，这导致难以拟合数据，并可能过度拟合。<strong class="ka jc"> <em class="kw">助推法学习慢。</em> </strong></p><p id="c16a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">正如你所看到的，这个算法用决策树解释得很清楚，但是还有其他的原因，它主要用在树上。</p><ol class=""><li id="10e3" class="mg mh jb ka b kb kc kf kg kj mz kn na kr nb kv mn mo mp mq bi translated"><strong class="ka jc"> <em class="kw">决策树是非线性的。用线性模型来提升根本就不能很好地工作。</em>T3】</strong></li><li id="599d" class="mg mh jb ka b kb mr kf ms kj mt kn mu kr mv kv mn mo mp mq bi translated"><strong class="ka jc"> <em class="kw">弱学习者需要始终如一地胜过随机猜测。您通常不需要对决策树进行任何参数调整来获得该行为。</em> </strong>比如训练一只SVM，确实需要参数搜索。由于数据在每次迭代中被重新加权，所以您可能需要在每次迭代中进行另一次参数搜索。所以你要大幅度增加你的工作量。</li><li id="8f85" class="mg mh jb ka b kb mr kf ms kj mt kn mu kr mv kv mn mo mp mq bi translated">决策树的训练速度相当快。 因为我们要建造100或1000座这样的房子，这是一笔不错的资产。它们的分类速度也很快，当您需要运行100个或1000个来输出您的决策时，这也很重要。</li><li id="2a7e" class="mg mh jb ka b kb mr kf ms kj mt kn mu kr mv kv mn mo mp mq bi translated">通过改变深度<strong class="ka jc"> <em class="kw">你可以简单容易地控制偏差/方差的权衡，</em> </strong>知道增强可以减少偏差，但也可以显著减少方差。</li></ol><p id="9f90" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是对boosting的一个极其简化(可能很天真)的解释，但会帮助您理解非常基础的东西。实现这个算法的一个流行库是<strong class="ka jc"> Scikit-Learn </strong>。它有一个很棒的api，只需几行python代码就能让你的模型运行起来。</p></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><p id="e979" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你喜欢这篇文章，一定要点击下面的❤来推荐它，如果你有任何问题，<strong class="ka jc">留下评论</strong>，我会尽力回答。</p><p id="ff24" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我很快会写更多关于如何实现不同的升压算法。所以，为了更加了解机器学习的世界，<strong class="ka jc">跟我来</strong>。这是最好的办法，等我多写点这样的文章就知道了。</p><p id="ddff" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">也可以在<strong class="ka jc"> Twitter关注我在</strong><a class="ae kx" href="https://twitter.com/Prashant_1722" rel="noopener ugc nofollow" target="_blank"><strong class="ka jc">@ pra shant _ 1722</strong></a>，<a class="ae kx" href="mailto:pr.span24@gmail.com" rel="noopener ugc nofollow" target="_blank"> <strong class="ka jc">直接发邮件给我</strong> </a>或者<a class="ae kx" href="https://www.linkedin.com/in/prashantgupta17/" rel="noopener ugc nofollow" target="_blank"> <strong class="ka jc">在linkedin </strong> </a>上找我。我很乐意收到你的来信。</p><p id="17f7" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">乡亲们，祝你们有美好的一天:)</p></div></div>    
</body>
</html>