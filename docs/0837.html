<html>
<head>
<title>Identifying Traffic Signs with Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用深度学习识别交通标志</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/identifying-traffic-signs-with-deep-learning-5151eece09cb?source=collection_archive---------2-----------------------#2017-06-28">https://towardsdatascience.com/identifying-traffic-signs-with-deep-learning-5151eece09cb?source=collection_archive---------2-----------------------#2017-06-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="64d6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">交通标志的成功检测和分类是自动驾驶汽车需要解决的重要问题之一。想法是让汽车足够智能，以达到成功自动化最少人类互动。在图像识别、自然语言处理、自动驾驶汽车等相关领域，<a class="ae kl" href="https://en.wikipedia.org/wiki/Deep_learning" rel="noopener ugc nofollow" target="_blank">深度学习</a>相对于经典机器学习方法的优势迅速上升，并辅之以GPU(图形处理单元)的进步，这令人震惊。</p><h2 id="efd1" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">深度学习</h2><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi lf"><img src="../Images/38c52645b017d985e4b88439c659f6f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*JvdSYRKD1IEI0sQIaHTU2w.png"/></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Attendance at the Annual Conference on Neural Information Processing Systems (NIPS)</figcaption></figure><p id="4557" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">图表只显示了2015年和2016年<a class="ae kl" href="http://beamandrew.github.io/deeplearning/2016/12/12/nips-2016.html" rel="noopener ugc nofollow" target="_blank"> NIPS </a>有超过6000人参加。图表显示对深度学习和相关技术的兴趣激增。</p><p id="00b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">深度学习</strong>是一种机器学习技术，其中人工神经网络使用多个隐藏层。这要归功于两位著名的神经生理学家大卫·胡贝尔和托尔斯滕·威塞尔，他们展示了视觉皮层中的神经元是如何工作的。他们的工作确定了具有相似功能的神经元如何组织成列，这些列是微小的计算机器，将信息传递到大脑的更高区域，在那里视觉图像逐渐形成。</p><p id="cd85" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="lr">通俗地说</em>大脑结合低级特征，如基本形状、曲线，并从中构建更复杂的形状。深度卷积神经网络也类似。它首先识别低级特征，然后学习识别和组合这些特征，以学习更复杂的模式。这些不同级别的功能来自网络的不同层。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ls"><img src="../Images/73ed9c7b6f165d80cbe349585c4d9d68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ji5QhY9QXBlpNNLH4qAcNA.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Feature Visualization of Convnet trained on ImageNet from [Zeiler &amp; Fergus 2013]</figcaption></figure><p id="fec7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们不会进一步深入深度学习和反向传播如何工作的数学解释。跟随<a class="ae kl" href="http://cs231n.github.io/" rel="noopener ugc nofollow" target="_blank"> cs231n </a>和本<a class="ae kl" href="https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b" rel="noopener">博客</a>深入了解。让我们看看简单的深度卷积神经网络如何在交通标志数据集上执行。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi lx"><img src="../Images/d3924625bb07a71bab57756152c930a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fhe3WQbZtEFRtnb6LOINuQ.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Traffic Sign Images and Classification Probabilities</figcaption></figure><h2 id="e966" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">模型架构和超级参数</h2><p id="655a" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated"><a class="ae kl" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>用于实现交通标志分类的深度conv网。RELU用于激活以引入非线性，不同百分比的退出用于避免不同阶段的过拟合。很难相信简单的深度网络能够在训练数据上达到高精度。以下是用于交通标志分类的架构。这里是<a class="ae kl" href="https://github.com/linux-devil/traffic_sign_classifier" rel="noopener ugc nofollow" target="_blank">链接</a>到我的源代码。架构灵感来自<a class="ae kl" href="http://www.pyimagesearch.com/2016/08/01/lenet-convolutional-neural-network-in-python/" rel="noopener ugc nofollow" target="_blank"> LeNet </a>，也被视为深度学习中的“Hello World”。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi md"><img src="../Images/3217fef8e620d2786c2ac2cbf1badbc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*pnkaZ0pwLRLalyvhEJ5b5A.png"/></div></figure><p id="8162" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在探索了LeNet之后，我决定从简单的架构开始。想法是从简单开始，如果需要，增加更多的复杂性。架构与上面张贴的图表相同。将图像转换为灰度确实有助于获得更好的准确性。使用<strong class="jp ir"> <em class="lr">【亚当】</em></strong><em class="lr"><strong class="jp ir"/></em> 优化器为<strong class="jp ir"> 256 </strong> <strong class="jp ir"> <em class="lr">批量</em> </strong>训练模型<strong class="jp ir"> <em class="lr"> 40个历元</em> </strong>，学习率最初设置为0.0001，后来进一步增加到<strong class="jp ir"> <em class="lr"> 0.001 </em> </strong>以收敛到目标精度。我发现这个<a class="ae kl" href="http://sebastianruder.com/optimizing-gradient-descent/index.html#adam" rel="noopener ugc nofollow" target="_blank">博客</a>真的很有助于理解不同的梯度下降优化算法。这是我在tensorflow上面的第一个模型。下面是这个模型的一个小片段。</p><pre class="lg lh li lj gt me mf mg mh aw mi bi"><span id="204e" class="km kn iq mf b gy mj mk l ml mm"><strong class="mf ir">def</strong> deepnn_model(x,train=<strong class="mf ir">True</strong>):<br/>    <em class="lr"># Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer</em><br/>    x =   tf.nn.conv2d(x, layer1_weight, strides=[1, 1, 1, 1], padding='VALID')<br/>    x =   tf.nn.bias_add(x, layer1_bias)<br/>    x =   tf.nn.relu(x)<br/>    x = tf.nn.max_pool(x,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1],padding='SAME')<br/>    <strong class="mf ir">if</strong>(train):<br/>        x = tf.nn.dropout(x, dropout1)<br/><br/>    x =   tf.nn.conv2d(x, layer2_weight, strides=[1, 1, 1, 1], padding='VALID')<br/>    x =   tf.nn.bias_add(x, layer2_bias)<br/>    x =   tf.nn.relu(x)<br/>    conv2 = tf.nn.max_pool(x,ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1],padding='SAME')<br/>    <strong class="mf ir">if</strong>(train):<br/>        conv2 = tf.nn.dropout(conv2, dropout2)<br/><br/>    fc0   = flatten(conv2)<br/>    fc1 = tf.add(tf.matmul(fc0, flat_weight),bias_flat)<br/>    fc1 = tf.nn.relu(fc1)<br/>    <strong class="mf ir">if</strong>(train):<br/>        fc1 = tf.nn.dropout(fc1, dropout3)<br/>    <br/>    fc1 = tf.add(tf.matmul(fc1, flat_weight2),bias_flat2)<br/>    fc1 = tf.nn.relu(fc1)<br/>    <strong class="mf ir">if</strong>(train):<br/>        fc1 = tf.nn.dropout(fc1, dropout4)<br/>    fc1 = tf.add(tf.matmul(fc1, flat_weight3),bias_flat3)<br/>    logits = tf.nn.relu(fc1)<br/><br/>    <strong class="mf ir">return</strong> logits</span></pre><h2 id="167b" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">结果</h2><p id="e454" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">我的目标是从简单的架构开始，达到90%的准确性，我惊讶地发现在第一次运行中，它接近94%的准确性。进一步向模型中添加更多的层和复杂性，并辅以数据扩充，可以实现高达98%的准确性。</p><h2 id="6ac9" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">讨论</h2><p id="68b9" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">深度学习真的令人印象深刻，它带来的结果看起来很有前途。从图像识别到自然语言处理，可能性是无穷无尽的。在了解了<a class="ae kl" href="https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b" rel="noopener">反向传播</a>和卷积神经网络等相关概念后，我个人很难相信它完全是这篇<a class="ae kl" href="https://sinews.siam.org/Details-Page/deep-deep-trouble-4" rel="noopener ugc nofollow" target="_blank">文章</a>中提到的黑箱。请随时提问，评论和建议。迫不及待地想在这个领域探索更多。</p><h2 id="8718" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">参考</h2><p id="b931" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated"><a class="ae kl" href="https://www.udacity.com/drive" rel="noopener ugc nofollow" target="_blank"> Udacity </a>自动驾驶汽车工程师纳米学位。</p><p id="99e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">G <a class="ae kl" href="https://github.com/linux-devil/traffic_sign_classifier" rel="noopener ugc nofollow" target="_blank"> ithub </a>回购源代码。</p><p id="d811" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="http://cs231n.github.io/" rel="noopener ugc nofollow" target="_blank"> CS231n </a>课程和<a class="mn mo ep" href="https://medium.com/u/ac9d9a35533e?source=post_page-----5151eece09cb--------------------------------" rel="noopener" target="_blank"> Andrej Karpathy </a>关于卷积神经网络的<a class="ae kl" href="https://www.youtube.com/watch?v=g-PvXUjD6qg&amp;list=PLlJy-eBtNFt6EuMxFYRiNRS07MCWN5UIA" rel="noopener ugc nofollow" target="_blank">视频讲座</a>。</p><p id="4d6a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://github.com/udacity/CarND-Traffic-Sign-Classifier-Project" rel="noopener ugc nofollow" target="_blank">交通标志分类器项目</a>。</p><p id="d09b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">交通标志d <a class="ae kl" href="http://benchmark.ini.rub.de/?section=gtsrb&amp;subsection=dataset" rel="noopener ugc nofollow" target="_blank">数据来源</a></p></div></div>    
</body>
</html>