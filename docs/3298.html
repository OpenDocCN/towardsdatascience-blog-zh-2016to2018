<html>
<head>
<title>Intuitive Guide to Understanding KL Divergence</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解KL分歧的直观指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence-2b382ca2b2a8?source=collection_archive---------0-----------------------#2018-04-30">https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence-2b382ca2b2a8?source=collection_archive---------0-----------------------#2018-04-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="c176" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/light-on-math" rel="noopener" target="_blank">点亮数学机器学习</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div class="gh gi jw"><img src="../Images/30a1b4acb2c198d57cb43ce9ba96af1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*k5QmUdmTR8eB3qWh2kjXmg.jpeg"/></div></figure><p id="91c1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我正在开始一系列新的博客文章，遵循初学者友好的方法来理解机器学习中一些具有挑战性的概念。首先，我们将从KL散度开始。</p><p id="80c9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ja">代号:</strong> <a class="ae lb" href="https://github.com/thushv89/nlp_examples_thushv_dot_com/blob/master/kl_divergence.ipynb" rel="noopener ugc nofollow" target="_blank">此处</a></p><p id="24d3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本系列的其他文章可以在下面找到。</p><p id="64db" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ja">A B</strong><a class="ae lb" href="http://www.thushv.com/computer_vision/light-on-math-machine-learning-intuitive-guide-to-convolution-neural-networks/" rel="noopener ugc nofollow" target="_blank"><strong class="kf ja">C</strong></a><strong class="kf ja"/><a class="ae lb" rel="noopener" target="_blank" href="/light-on-math-machine-learning-intuitive-guide-to-understanding-decision-trees-adb2165ccab7"><strong class="kf ja">D</strong></a><strong class="kf ja">* E F</strong><a class="ae lb" rel="noopener" target="_blank" href="/light-on-math-ml-intuitive-guide-to-understanding-glove-embeddings-b13b4f19c010"><strong class="kf ja">G</strong></a><strong class="kf ja">* H I J K</strong><a class="ae lb" rel="noopener" target="_blank" href="/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158"><strong class="kf ja">L</strong></a><strong class="kf ja">* M</strong><a class="ae lb" rel="noopener" target="_blank" href="/light-on-math-machine-learning-intuitive-guide-to-neural-style-transfer-ef88e46697ee"><strong class="kf ja">N</strong></a><strong class="kf ja">O P Q R S T U V</strong></p><p id="9f2a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">*表示中等付费墙后面的文章</p><h1 id="3b36" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">概念基础</h1><p id="4ed3" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">首先，让我们建立一些基本规则。我们将定义一些我们需要知道的事情，比如我们的手背来理解KL散度。</p><h2 id="6b7c" class="mf ld iq bd le mg mh dn li mi mj dp lm ko mk ml lq ks mm mn lu kw mo mp ly iw bi translated">什么是发行版</h2><p id="0634" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">所谓分布，我们指的是不同的东西，如数据分布或概率分布。这里我们感兴趣的是概率分布。想象你在一张纸上画两条轴(即<strong class="kf ja"> <em class="mq"> X </em> </strong>和<strong class="kf ja"> <em class="mq"> Y </em> </strong>)，我喜欢把一个分布想象成两条轴之间掉下来的一根线；<strong class="kf ja">T9】XT11】和<strong class="kf ja">T13】YT15】。<strong class="kf ja"> <em class="mq"> X </em> </strong>表示您有兴趣获取概率的不同值。<em class="mq"> Y </em>代表在<strong class="kf ja"> <em class="mq"> X </em> </strong>轴上观察到某个值的概率(即<strong class="kf ja"> <em class="mq"> y=p(x) </em> </strong>)。我在下面想象这一点。</strong></strong></p><figure class="ms mt mu mv gt ka gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/18bdefae971e658ae9bebfb7449a352b.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*-lft2w25vwzNERvy7N7NPA.png"/></div></figure><p id="2dd2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是一个连续的概率分布。例如，将轴<strong class="kf ja"> <em class="mq"> X </em> </strong>想象为一个人的高度，将轴<strong class="kf ja"> <em class="mq"> Y </em> </strong>想象为找到具有该高度的人的概率。</p><p id="af70" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你想使这种概率分布离散，你可以把这根线切成固定长度的段，然后把这些段以水平的方式转动。然后创建连接每条线的边缘和x轴的矩形。这是一个离散的概率分布。</p><h2 id="444b" class="mf ld iq bd le mg mh dn li mi mj dp lm ko mk ml lq ks mm mn lu kw mo mp ly iw bi translated">什么是事件？</h2><p id="1e08" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">对于离散概率分布，一个事件就是你观察到<em class="mq"> X </em>取某个值(例如<strong class="kf ja"> <em class="mq"> X=1 </em> </strong>)。我们姑且称<strong class="kf ja"> <em class="mq"> P(X=1) </em> </strong>事件发生的概率<strong class="kf ja"> <em class="mq"> X=1 </em> </strong>。在连续空间中你可以把这想象成一个数值范围(例如<strong class="kf ja"><em class="mq">0.95&lt;X&lt;1.05</em></strong>)。请注意，事件的定义不限于x轴上的值。然而，考虑到这一点，我们可以继续前进。</p><h1 id="97a2" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">回到KL分歧</h1><p id="4910" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">为了从这一点继续下去，我将谦虚地使用这篇<a class="ae lb" href="https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained" rel="noopener ugc nofollow" target="_blank">博文</a>【1】中的例子。这是一篇解释KL分歧的很好的文章，但是我觉得解释中的一些错综复杂之处可以解释得更详细一些。好了，我们开始吧。</p><h1 id="822f" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">我们试图解决的问题</h1><p id="e4a1" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">因此，在[1]中解决的问题的要点是，我们是一群访问广阔的外层空间的科学家，我们发现了一些太空蠕虫。这些太空蠕虫有不同数量的牙齿。现在我们需要将这些信息发送回地球。但是从太空向地球发送信息是昂贵的。所以我们需要用最少的信息量来表达这些信息。一个很好的方法是，我们不记录单个的数字，而是画一个图，其中<strong class="kf ja"> <em class="mq"> X </em> </strong>轴是已经观察到的不同齿数(<em class="mq"> 0，1，2，…，等等)。</em>)并使<strong class="kf ja"> <em class="mq"> Y </em> </strong>轴看到一个带<em class="mq"> x </em>多齿的蜗杆的概率(即带<strong class="kf ja"> <em class="mq"> x </em> <em class="mq">齿的蜗杆数/蜗杆总数</em> </strong>)。我们已经把我们的观察转换成一个分布。</p><p id="5874" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这种分发比发送单个蠕虫的信息更有效。但是我们可以做得更好。我们可以用一个已知的分布(如均匀分布、二项式分布、正态分布等)来表示这个分布。).例如，如果我们用均匀分布来表示真实分布，我们只需要发送两条信息就可以恢复真实数据；蠕虫的均匀概率和数量。但是我们如何知道哪种分布更好地解释了真实的分布呢？这就是KL分歧的来源。</p><blockquote class="mw"><p id="2ca5" class="mx my iq bd mz na nb nc nd ne nf la dk translated">直觉:KL散度是衡量两个分布(例如线程)之间匹配的一种方式</p></blockquote><p id="1586" class="pw-post-body-paragraph kd ke iq kf b kg ng ki kj kk nh km kn ko ni kq kr ks nj ku kv kw nk ky kz la ij bi translated">因此，我们可以使用KL散度来确保我们将真实分布与一些解释简单且众所周知的分布很好地匹配。</p><h1 id="8db8" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">让我们改变例子中的一些东西</h1><p id="928e" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">为了能够检查数值的正确性，让我们将概率值改为更人性化的值(与[1]中使用的值相比)。我们将做如下假设。假设我们有100条虫子。我们有以下数量的蠕虫。</p><ul class=""><li id="4db6" class="nl nm iq kf b kg kh kk kl ko nn ks no kw np la nq nr ns nt bi translated">0齿:2(概率:<em class="mq"> p0=0.02 </em></li><li id="5e0a" class="nl nm iq kf b kg nu kk nv ko nw ks nx kw ny la nq nr ns nt bi translated">1齿:3(概率:<em class="mq"> p1=0.03 </em></li><li id="06f4" class="nl nm iq kf b kg nu kk nv ko nw ks nx kw ny la nq nr ns nt bi translated">2齿:5(概率:<em class="mq"> p2=0.05 </em></li><li id="5ff4" class="nl nm iq kf b kg nu kk nv ko nw ks nx kw ny la nq nr ns nt bi translated">3齿:14(概率:<em class="mq"> p3=0.14 </em></li><li id="c2c0" class="nl nm iq kf b kg nu kk nv ko nw ks nx kw ny la nq nr ns nt bi translated">4齿:16(概率:<em class="mq"> p4=0.16 </em></li><li id="d175" class="nl nm iq kf b kg nu kk nv ko nw ks nx kw ny la nq nr ns nt bi translated">5齿:15(概率:<em class="mq"> p5=0.15 </em>)</li><li id="3fc6" class="nl nm iq kf b kg nu kk nv ko nw ks nx kw ny la nq nr ns nt bi translated">6齿:12(概率:<em class="mq"> p6=0.12 </em>)</li><li id="7d72" class="nl nm iq kf b kg nu kk nv ko nw ks nx kw ny la nq nr ns nt bi translated">7齿:8(概率:<em class="mq"> p7=0.08 </em>)</li><li id="4d53" class="nl nm iq kf b kg nu kk nv ko nw ks nx kw ny la nq nr ns nt bi translated">8齿:10(概率:<em class="mq"> p8=0.1 </em>)</li><li id="8d95" class="nl nm iq kf b kg nu kk nv ko nw ks nx kw ny la nq nr ns nt bi translated">9齿:8(概率:<em class="mq"> p9=0.08 </em>)</li><li id="53af" class="nl nm iq kf b kg nu kk nv ko nw ks nx kw ny la nq nr ns nt bi translated">10齿:7(概率:<em class="mq"> p10=0.07 </em>)</li></ul><p id="4cc7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">快速理智检查！让我们确保值加起来是100，概率加起来是1.0。</p><p id="3f1e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mq">总蠕虫数= 2+3+5+14+16+15+12+8+10+8+7 = 100</em><br/><em class="mq">总概率= 0.02+0.03+0.05+0.14+0.16+0.15+…。0.12+0.08+0.1+0.08+0.07 = 1.0</em></p><p id="751f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是它的视觉效果。</p><figure class="ms mt mu mv gt ka gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/b0a6a6dd6d967e87d1aab6962bf15dfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*7qvVe_BVWhXcd340OV3ZcA.png"/></div></figure><h1 id="9135" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">第一次尝试:用均匀分布建模</h1><p id="3826" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">现在，让我们先试着用均匀分布来模拟这个分布。均匀分布只有一个参数；一致概率；给定事件发生的概率。</p><p id="d76c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mq">p _ uniform = 1/总事件数=1/11 = 0.0909 </em></p><p id="4f69" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是均匀分布和真正的并排分布的样子。</p><figure class="ms mt mu mv gt ka gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/d9351bf633128288b452e74c13af1d01.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*wkBqQtpQdHXnfJTlqD0B9A.png"/></div></figure><p id="0d9f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们把这个结果放在一边，我们将用另一种类型的分布来模拟真实的分布。</p><h1 id="3be7" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">第二次尝试:用二项式分布建模</h1><p id="965e" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">通过计算一枚硬币正面落地的概率，你可能对二项式概率很熟悉。我们可以把同样的概念推广到我们的问题上。对于一枚硬币，你有两种可能的输出，假设硬币正面落地的概率是<strong class="kf ja"> <em class="mq"> p </em> </strong>，你运行这个实验进行<strong class="kf ja"> <em class="mq"> n </em> </strong>次试验，获得<strong class="kf ja"> <em class="mq"> k </em> </strong>成功的概率由下式给出:</p><figure class="ms mt mu mv gt ka gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/36e9e1585f6d89485ee31d1cef34d58e.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*yQaK6IhT_7dM5DrSoFu42g.png"/></div></figure><h2 id="1cfa" class="mf ld iq bd le mg mh dn li mi mj dp lm ko mk ml lq ks mm mn lu kw mo mp ly iw bi translated">打破平衡</h2><p id="7eb9" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">让我们顺便了解一下二项分布中的每一项，看看它们是否有意义。第一任是<strong class="kf ja"> <em class="mq"> p^k </em> </strong>。我们要获得<strong class="kf ja"> <em class="mq"> k </em> </strong>的成功，其中单次成功的概率是<strong class="kf ja"> <em class="mq"> p </em> </strong>。那么获得<strong class="kf ja"> <em class="mq"> k </em> </strong>成功的概率就是<strong class="kf ja"><em class="mq"/></strong>。请记住，我们正在为<strong class="kf ja"> <em class="mq"> n </em> </strong>试验运行实验。因此，会有<strong class="kf ja"> <em class="mq"> n-k </em> </strong>次失败的试验，失败概率为<strong class="kf ja"><em class="mq">【1-p】</em></strong>。所以获得<strong class="kf ja"> <em class="mq"> k </em> </strong>成功的概率是<strong class="kf ja"><em class="mq">p^k(1-p)^{n-k}</em></strong>的联合概率。我们的工作不会就此结束。<strong class="kf ja"> <em class="mq"> k </em> </strong>试验可以在<em class="mq"> n </em>试验中进行不同的排列。要在<strong class="kf ja"><em class="mq"/></strong>空间内排列的不同排列<em class="mq"> k </em>元素的数量由下式给出:</p><figure class="ms mt mu mv gt ka gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/4cd20b644ecb52ef39e035d48c9f1526.png" data-original-src="https://miro.medium.com/v2/resize:fit:420/format:webp/1*Tks4fPwu6wfNSLqeoOiWQw.png"/></div></figure><p id="b88c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将所有这些相乘，我们得到了成功的二项式概率。</p><h2 id="89c4" class="mf ld iq bd le mg mh dn li mi mj dp lm ko mk ml lq ks mm mn lu kw mo mp ly iw bi translated">二项分布的均值和方差</h2><p id="b655" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">我们还可以定义二项分布的均值和方差。这些是由，</p><p id="d74c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mq">均值= np <br/>方差= np(1-p) </em></p><p id="f5bb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">意思反映了什么？Mean是您运行<em class="mq"> n </em>次试验后获得的预期(平均)成功次数。如果每次试验的成功概率为<em class="mq"> p </em>，那么可以说如果你进行<strong class="kf ja"> <em class="mq"> n </em> </strong>次试验，你将获得<strong class="kf ja"> <em class="mq"> np </em> </strong>次成功。接下来方差代表什么？它表示成功试验的真实次数偏离平均值的程度。为了理解方差，让我们假设<strong class="kf ja"> <em class="mq"> n=1 </em> </strong>。那么方程就是，<strong class="kf ja"> <em class="mq">方差=p(1-p) </em> </strong>。当<strong class="kf ja"> <em class="mq"> p=0.5 </em> </strong>(获得正面和反面的可能性相等)时，方差最高；当<strong class="kf ja"> <em class="mq"> p=1 </em> </strong>或<strong class="kf ja"> <em class="mq"> p=0 </em> </strong>(肯定获得正面/反面)时，方差最低。</p><h2 id="2cef" class="mf ld iq bd le mg mh dn li mi mj dp lm ko mk ml lq ks mm mn lu kw mo mp ly iw bi translated">回到建模</h2><p id="3c60" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">现在有了对二项分布的坚实理解，让我们回到我们手头的问题。让我们先计算一下蠕虫的预期齿数。那会是，</p><figure class="ms mt mu mv gt ka gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/3b5b46aa903a1969baa8bbd07a47bbef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*xzCMJfrP2PgWy_EK5VgaPw.png"/></div></figure><p id="eee3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">已知均值，我们可以计算出<strong class="kf ja"> <em class="mq"> p </em> </strong>其中，<br/> <em class="mq">均值= NP<br/>5.44 = 10p<br/>p = 0.544</em></p><p id="b694" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意比<strong class="kf ja"> <em class="mq"> n </em> </strong>是从蠕虫种群中观察到的最大齿数。你可能会问为什么我们没有选择<strong class="kf ja"> <em class="mq"> n </em> </strong>作为蠕虫总数(即<strong class="kf ja"> <em class="mq"> 100 </em> </strong>)或者事件总数(即<strong class="kf ja"> <em class="mq"> 11 </em> </strong>)。我们很快就会看到原因。有了这个，我们可以定义任意数量的牙齿的概率如下。</p><blockquote class="od oe of"><p id="9d80" class="kd ke mq kf b kg kh ki kj kk kl km kn og kp kq kr oh kt ku kv oi kx ky kz la ij bi translated">鉴于牙齿可以取值到10，那么看到k颗牙齿的概率是多少(其中看到一颗牙齿就是试验成功)。</p></blockquote><p id="463d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从抛硬币的角度来看，这就像在问，</p><blockquote class="od oe of"><p id="c92d" class="kd ke mq kf b kg kh ki kj kk kl km kn og kp kq kr oh kt ku kv oi kx ky kz la ij bi translated">假设我有10次翻转，观察到k头的概率是多少。</p></blockquote><p id="090a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">形式上，我们计算所有不同的<strong class="kf ja"> <em class="mq"> k </em> </strong>值的概率<strong class="kf ja"><em class="mq"/></strong>。这里<strong class="kf ja"> <em class="mq"> k </em> </strong>成为我们要观察的齿数。而<strong class="kf ja"><em class="mq">【pk^{bi}】</em></strong>则是第k个<em class="mq"/>齿仓的二项概率(即0齿、1齿等)。).所以当我们如下计算它们时，</p><p id="7abe" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mq"> p0^{bi} = (10！/(0!10!))0.544⁰(1–0.544)^{10} = 0.0004<br/>p1^{bi} =(10！/(1!9!))0.544(1–0.544)⁹= 0.0046<br/>p2^{bi} =(10！/(2!8!))0.544(1–0.544)⁸= 0.0249</em></p><p id="b568" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mq">……<br/>p9^{bi} =(10！/(9!1!))0.544⁹(1–0.544)= 0.0190<br/>p10^{bi} =(10！/(10!0!))0.544^{10}(1–0.544)⁰= 0.0023</em></p><p id="bef3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是真实分布和二项分布的比较。</p><figure class="ms mt mu mv gt ka gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/085626eada6722bdbd1aaf5a895d0ce6.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*Afsv-D0cBzqfIA0dQicaQg.png"/></div></figure><h1 id="37b1" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">让我们总结一下我们所拥有的</h1><p id="d3d6" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">好吧，回头想想我们到目前为止做了什么。首先我们理解了我们想要解决的问题。问题是用最少的努力把某种太空蠕虫牙齿的统计数据发送到整个空间。为此，我们考虑用一些已知的分布来表示蠕虫的真实统计数据，因此我们可以只发送该分布的参数，而不是真实统计数据。我们研究了两种类型的分布，得出了以下统计数据。<br/> <br/> *均匀分布—概率为<strong class="kf ja"> <em class="mq"> 0.0909 </em> </strong> <br/> *二项分布—其中<strong class="kf ja"> <em class="mq"> n=10 </em> </strong>，<strong class="kf ja"> <em class="mq"> p=0.544 </em> </strong>和<strong class="kf ja"> <em class="mq"> k </em> </strong>取0到10之间的不同值</p><p id="f189" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在让我们在一个地方可视化一切</p><figure class="ms mt mu mv gt ka gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/f1845e5425b075ada76bbfaeae4b5cf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*lVmVwCibUhMOVIAIdoW2lw.png"/></div></figure><h1 id="f34e" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">我们如何定量地决定哪些是最好的？</h1><p id="6dea" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">有了这些复杂的计算，我们需要一种方法来衡量每个近似分布与真实分布之间的匹配程度。这一点很重要，这样，当我们传递信息时，我们可以安心，不用担心“我的选择正确吗？”在我们的余生中。</p><p id="241d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是KL背离的由来。KL散度的正式定义如下。</p><figure class="ms mt mu mv gt ka gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/09bd6b0d560ef01cd7341d1d25019905.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*G3ocBJfKHgc6rSK-pjzMfQ.png"/></div></figure><p id="4436" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里的<strong class="kf ja"><em class="mq"/></strong>是近似值，而<strong class="kf ja"> <em class="mq"> p(x) </em> </strong>是真实分布，我们感兴趣的是匹配<strong class="kf ja"><em class="mq">【q(x)</em></strong>来。直观地，这测量了给定的任意分布与真实分布的偏差。如果两个分布完全匹配，<strong class="kf ja"><em class="mq">[D _ { KL }(p | | q)= 0</em></strong>否则可以取<strong class="kf ja"> <em class="mq"> 0 </em> </strong>和<strong class="kf ja"> <em class="mq"> ∞ </em> </strong>之间的值。KL散度值越低，我们将真实分布与我们的近似值匹配得越好。</p><h1 id="86fb" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">KL背离的直观分解</h1><p id="8d49" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">让我们一块一块来看KL发散。先取<strong class="kf ja"><em class="mq">log(p(x _ I)/q(x _ I))</em></strong>分量。如果<strong class="kf ja"> <em class="mq"> q(x_i) </em> </strong>高于<strong class="kf ja"> <em class="mq"> p(x_i) </em> </strong>会怎么样？那么这个组件将产生一个负值(因为小于1的log值是负值)。另一方面，如果<strong class="kf ja"> <em class="mq"> q(x_i) </em> </strong>总是小于<strong class="kf ja"> <em class="mq"> p(x_i) </em> </strong>这个分量将产生正值。只有当<strong class="kf ja"><em class="mq">p(x _ I)= q(x _ I)</em></strong>时，该值才会为零。然后为了使这成为一个<a class="ae lb" href="https://en.wikipedia.org/wiki/Expected_value" rel="noopener ugc nofollow" target="_blank">期望值</a>，你用<strong class="kf ja"> <em class="mq"> p(x_i) </em> </strong>对log分量进行加权。这意味着，<strong class="kf ja"> <em class="mq"> p(x_i) </em> </strong>概率较高的匹配区域比<strong class="kf ja"> <em class="mq"> p(x_i) </em> </strong>概率较低的匹配区域更重要。</p><p id="c1d1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">直觉上，优先正确匹配近似值中的真正高概率事件是有意义的。从数学上讲，这允许您自动忽略位于真实分布支持面(支持面是分布使用的x轴上的全长)之外的分布区域。此外，这避免了计算log(0)  如果您试图计算超出真实分布支持范围的任何区域的log分量，将会出现这种情况。</p><h1 id="6db8" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">计算KL散度</h1><p id="6432" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">现在让我们计算我们得到的每个近似分布的KL散度。首先让我们来看看均匀分布。</p><figure class="ms mt mu mv gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="ol om di on bf oo"><div class="gh gi ok"><img src="../Images/92f581b334e30d9b6ec06a94d533f60a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*--mo5p4TRtbV2EF8uU7S_w.png"/></div></div></figure><p id="1c8e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在对于我们得到的二项分布，</p><figure class="ms mt mu mv gt ka gh gi paragraph-image"><div role="button" tabindex="0" class="ol om di on bf oo"><div class="gh gi op"><img src="../Images/64308c054bfbc353de187787b2558108.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fAMDfLIyo7ovyqwXnCMfnw.png"/></div></div></figure><h1 id="7e01" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">关于二项式均值的KL散度</h1><p id="5906" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">现在让我们来玩一下KL散度。首先，我们将看到当二项分布的成功概率改变时，KL散度是如何变化的。不幸的是，我们不能对均匀分布做同样的事情，因为我们不能改变概率，因为<strong class="kf ja"> <em class="mq"> n </em> </strong>是固定的。</p><figure class="ms mt mu mv gt ka gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/5cee8529e6e58de56e1b0bd50449e057.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*03CRThV0yx_3eVYneRuddg.png"/></div></figure><p id="cd42" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以看到，随着我们远离我们的选择(红点)，KL散度迅速增加。事实上，如果你打印一些与我们的选择相差很小的KL散度值<strong class="kf ja">δ</strong>，你会看到我们选择的成功概率给出了最小的KL散度。</p><p id="f2f2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们对KL散度的讨论到此结束。</p><h1 id="6e27" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">结论</h1><p id="eab0" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">现在我们有了一些可靠的结果，虽然均匀分布看起来很简单，没有什么信息，而二项式分布更微妙，但均匀分布比二项式分布更符合真实分布。说实话，这个结果其实让我很意外。因为我期望二项式能更好地模拟真实分布。因此，这给了我们一个重要的教训，那就是为什么我们不应该只相信我们的直觉！</p><p id="710c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">代码:<a class="ae lb" href="https://github.com/thushv89/exercises_thushv_dot_com/blob/master/kl_divergence.ipynb" rel="noopener ugc nofollow" target="_blank">此处</a></p><h1 id="8c50" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">KL divergence的乐趣</h1><p id="af8d" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">你可以通过玩KL散度来获得更多的乐趣，从而更好地理解KL散度。你可以在<a class="ae lb" href="http://www.thushv.com/machine-learning/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence/" rel="noopener ugc nofollow" target="_blank">我的博客</a>中了解更多。</p><h1 id="5c9a" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">参考</h1><p id="6632" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">[1]<a class="ae lb" href="https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained" rel="noopener ugc nofollow" target="_blank">https://www . countbayesie . com/blog/2017/5/9/kull back-lei bler-divergence-explained</a></p><p id="a5bd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意:请去我的<a class="ae lb" href="http://www.thushv.com" rel="noopener ugc nofollow" target="_blank">网站</a>看看，因为我也在那里贴了更多机器学习的东西。</p><p id="2324" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ja">小提示</strong>:我很高兴地宣布，我的关于使用TensorFlow进行自然语言处理的书已经出版了，供大家购买！这本书非常适合寻求基于现代深度学习的解决方案的实用视角的初级/中级读者。这本书附有指导读者实现各种NLP应用的练习。你可以在<a class="ae lb" href="https://www.packtpub.com/application-development/natural-language-processing-tensorflow" rel="noopener ugc nofollow" target="_blank"> Packt </a>网站或者<a class="ae lb" href="https://www.amazon.com/Natural-Language-Processing-TensorFlow-Ganegedara-ebook/dp/B077Q3VZFR" rel="noopener ugc nofollow" target="_blank">亚马逊</a>找到。</p><figure class="ms mt mu mv gt ka gh gi paragraph-image"><a href="https://www.packtpub.com/application-development/natural-language-processing-tensorflow"><div class="gh gi or"><img src="../Images/a26416885527e7d72e0020ab6e514219.png" data-original-src="https://miro.medium.com/v2/resize:fit:474/format:webp/1*MB81csUvPp8lTmsEkxrLaA.jpeg"/></div></a></figure></div></div>    
</body>
</html>