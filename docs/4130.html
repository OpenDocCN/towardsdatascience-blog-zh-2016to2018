<html>
<head>
<title>Deep learning for specific information extraction from unstructured texts</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于从非结构化文本中抽取特定信息的深度学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-for-specific-information-extraction-from-unstructured-texts-12c5b9dceada?source=collection_archive---------1-----------------------#2018-07-21">https://towardsdatascience.com/deep-learning-for-specific-information-extraction-from-unstructured-texts-12c5b9dceada?source=collection_archive---------1-----------------------#2018-07-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/52b886aa545de9d4ed3f2dfd134f3056.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*55sCYsXj4BXvTx-Lbkd0ow.jpeg"/></div></div></figure><p id="ce18" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是与我们的<a class="ae kw" href="https://iki.ai/" rel="noopener ugc nofollow" target="_blank"> iki </a>项目工作相关的系列技术帖子的第一篇，涵盖了机器学习和深度学习技术用于解决各种自然语言处理和理解问题的一些应用案例。</p><p id="b98c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">在这篇文章中，我们将解决从非结构化文本中提取某些特定信息的问题</strong>。我们需要从用户的简历中提取他们的技能，即使他们是以任意的方式写的，比如“在生产服务器上部署量化交易算法”。</p><p id="e189" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">本帖有一个</strong> <a class="ae kw" href="http://intuition.engineering/skills" rel="noopener ugc nofollow" target="_blank"> <strong class="ka ir">演示页面</strong> </a>，在你的简历上查看我们模特的表现。</p><h2 id="0dc4" class="kx ky iq bd kz la lb dn lc ld le dp lf kj lg lh li kn lj lk ll kr lm ln lo lp bi translated">语言模型</h2><p id="a91b" class="pw-post-body-paragraph jy jz iq ka b kb lq kd ke kf lr kh ki kj ls kl km kn lt kp kq kr lu kt ku kv ij bi translated">现代语言模型(<a class="ae kw" href="https://arxiv.org/abs/1801.06146" rel="noopener ugc nofollow" target="_blank"> ULMfit </a>，<a class="ae kw" href="https://allennlp.org/elmo" rel="noopener ugc nofollow" target="_blank"> ELMo </a>)使用无监督学习技术，例如在大型文本语料库上创建 RNNs 嵌入，以在更具体的监督训练步骤之前获得语言结构的一些原始“知识”。相反，在某些情况下，你需要一个在非常具体的小数据集上训练的模型。这些模型对一般的语言结构几乎一无所知，并且只能处理特殊的文本特征。一个经典的例子是用于电影评论或新闻数据集的幼稚情感分析工具——最简单的工作模型只能在“好”或“坏”形容词同义词和一些强调词存在的情况下运行。在我们的研究中，我们利用了两种方法的优点。</p><p id="7fda" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一般来说，当分析某个文本语料库时，我们会查看每个文本的全部词汇。文本矢量化的流行方法，例如<em class="lv"> tfidf、</em> <a class="ae kw" href="https://www.tensorflow.org/tutorials/word2vec" rel="noopener ugc nofollow" target="_blank"> <em class="lv"> word2vec </em> </a> <em class="lv">或</em><a class="ae kw" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank"><em class="lv">GloVe</em></a><em class="lv"/>模型使用整个文档的词汇来创建其向量，除了停用词(例如冠词、代词和在这种统计平均过程中带来很少语义意义的其他相当通用的语言元素)。如果有一个更具体的任务，你有一些关于文本语料库的额外信息，你可能会说一些信息比另一些更有价值。例如，要对烹饪食谱语料库进行分析，从文本中提取配料或菜名类别是很重要的。另一个例子是从简历的语料库中提取专业技能。例如，如果我们可以通过将简历与提取的技能向量相关联来对每份简历进行矢量化，这将让我们更成功地进行行业职位聚类。</p><p id="bfa2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">示例:</p><p id="37cd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="lv">简历:</em> </strong> <em class="lv">数据科学家，在机器学习、大数据、开发、统计和分析方面有动手能力。我的数据科学家团队实施了 Python 机器学习模型集成、堆叠和特征工程，展示了预测分析的高准确率。使用 Doc2Vec 单词嵌入和神经网络创建了一个推荐系统。</em></p><p id="cce6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="lv">提取专业技能:</em> </strong> <em class="lv">机器学习、大数据、开发、统计、分析、Python 机器学习模型集成、堆栈、特征工程、预测分析、Doc2Vec、单词嵌入、神经网络。</em></p><h2 id="2e68" class="kx ky iq bd kz la lb dn lc ld le dp lf kj lg lh li kn lj lk ll kr lm ln lo lp bi translated">步骤 1:词性标注</h2><p id="76c8" class="pw-post-body-paragraph jy jz iq ka b kb lq kd ke kf lr kh ki kj ls kl km kn lt kp kq kr lu kt ku kv ij bi translated">实体抽取的任务是文本挖掘类问题的一部分——从非结构化的文本中抽取一些结构化的信息。让我们仔细看看建议的实体提取方法。至于主要存在于所谓的名词短语中的技能，我们提取过程的第一步将是由<a class="ae kw" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> NLTK 库</a>内置方法执行的实体识别(从文本中提取信息的检验，<a class="ae kw" href="https://www.nltk.org/book/ch07.html" rel="noopener ugc nofollow" target="_blank"> NLTK book，part 7 </a>)。词性标注方法提取名词短语，并建立代表名词短语和句子其他部分之间关系的树。NLTK 库有许多工具可以执行这样的短语分解。</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lw"><img src="../Images/1f58dcfb0b1cc688052a20f5c37c681f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BwkQ3sl9jESciEPlyZu4Wg.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk"><em class="mf">NLTK book, chapter 7, pic 2.2: An example of a simple regular expression based NP Chunker.</em></figcaption></figure><p id="d057" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们可以将模型定义为给出句子分解的正则表达式(例如，我们可以将一个短语定义为多个形容词加一个名词),或者我们可以在 NLTK 中带有提取的名词短语示例的标记数量的文本上教授模型。这一步导致接收许多实体，其中一些是目标技能，一些不是——除了技能 CV 可以包含一些其他实体，如地点、人员、对象、组织等等。</p><h2 id="11ce" class="kx ky iq bd kz la lb dn lc ld le dp lf kj lg lh li kn lj lk ll kr lm ln lo lp bi translated">步骤 2:用于候选分类的深度学习架构</h2><p id="79c2" class="pw-post-body-paragraph jy jz iq ka b kb lq kd ke kf lr kh ki kj ls kl km kn lt kp kq kr lu kt ku kv ij bi translated">下一步是实体分类。这里的目标很简单——区分技能和“非技能”。用于训练的特征集是根据候选短语的结构和上下文构成的。显然，为了训练一个模型，我们必须创建一个带标签的训练集，我们手动为 1500 个提取的实体做了这件事，这些实体中有技能和“非技能”。</p><blockquote class="mg"><p id="0cb1" class="mh mi iq bd mj mk ml mm mn mo mp kv dk translated">我们从来没有试图让我们的模型适合一些有限的硬编码技能，该模型背后的核心思想是学习英语简历中技能的语义，并使用该模型提取看不见的技能。</p></blockquote><p id="21ed" class="pw-post-body-paragraph jy jz iq ka b kb mq kd ke kf mr kh ki kj ms kl km kn mt kp kq kr mu kt ku kv ij bi translated">每个单词的向量由二进制特征组成，如数字或其他特殊字符的出现(技能通常包含数字和符号:C#、Python3)、首字母大写或整个单词大写(SQL)。我们还检查一个单词是否出现在英语词汇和一些主题列表中，如名称、地名等。使用所列特征的最终模型在实体测试集上显示了 74.4%的正确结果。使用另一个二元特征来描述候选中流行的英语前缀和后缀的存在，将模型的性能提高到测试集上 77.3%的正确结果。在模型的特征集中加入编码词性的独热向量后，我们的结果提高到了 84.6%。</p><p id="23b8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">可靠的语义单词嵌入模型不能在 CV 数据集上训练，它太小并且太窄，为了减轻这个问题，你应该使用在其他一些非常大的数据集上训练的单词嵌入。我们使用 50 维的手套模型向量，在测试集上将我们的模型性能提高到 89.1%的正确结果。<strong class="ka ir">您可以通过上传您简历中的文本，在我们的</strong> <a class="ae kw" href="https://intuition.engineering/skills" rel="noopener ugc nofollow" target="_blank"> <strong class="ka ir">演示</strong> </a> <strong class="ka ir">中玩最终模型。</strong></p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lw"><img src="../Images/86d20da55bee32b64605e9c9d326cdfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ORQjzTETyHJomGjtiJqScA.png"/></div></div></figure><p id="1656" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">流行的词性标注者(<a class="ae kw" href="https://www.nltk.org/book/ch05.html" rel="noopener ugc nofollow" target="_blank"> NLTK POS tagger </a>，<a class="ae kw" href="https://nlp.stanford.edu/software/tagger.html" rel="noopener ugc nofollow" target="_blank"> Stanford POS tagger </a>)经常在简历的短语标注任务中出错。原因是，为了突出经验并赋予其一定的结构(人们以谓语而不是主语开始句子，有时短语缺少适当的语法结构)，简历文本经常忽略语法，许多单词是特定的术语或名称。我们必须编写自己的 postager 来解决上述问题。</p><p id="b960" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">分类是用 Keras 神经网络执行的，该网络具有三个输入层，每个输入层被设计成接受特殊类别的数据。第一输入层采用由候选短语的上述特征组成的可变长度向量，该候选短语可以具有任意数量的单词。这个特征向量用 LSTM 层处理。</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mv"><img src="../Images/07855501270904c19d3eeb7d29324432.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6jNjvDvTaIhodaIiqRJ_hw.png"/></div></div></figure><p id="a685" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">第二个可变长度向量带来上下文结构信息。对于给定的窗口大小 n，我们取候选短语右侧的 n 个相邻单词和左侧的 n 个单词，这些单词的矢量表示被连接成可变长度矢量并被传递到 LSTM 层。我们发现最优的 n=3。</p><p id="fd79" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">第三输入层具有固定的长度，并利用关于候选短语及其上下文的一般信息来处理向量——短语及其上下文中的单词向量的坐标最大值和最小值，这些信息以及其他信息表示整个短语中许多二元特征的存在或不存在。</p><p id="b55f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们称这个建筑技能为“拖拉机”,这就是。</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mw"><img src="../Images/34caa7074782e1173a5d32dc3a7b0be8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qExsGPU0_exp_8wmC0NO-w.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Skills Extractor network architecture</figcaption></figure><p id="d813" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">它的 Keras 实现如下所示:</p><figure class="lx ly lz ma gt jr"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="1827" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在学习率降低到 0.0001 的情况下，用 Adam 优化器实现了模型训练的最佳结果。我们选择 binary_crossentropy 作为损失函数，因为该模型被设计成分类成两类。</p><p id="fd6f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了方便使用，我们加入拟合方法，利用交叉验证和预测函数进行神经网络的训练和自动停止，形成候选短语特征向量的预测。</p><figure class="lx ly lz ma gt jr"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="6569" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">pad_sequences 函数将特征序列列表转换为一个 2d 数组，其宽度等于列表中最长的序列。这是为了将进入 LSTM 层的可变长度数据转换成模型训练所需的格式。</p><p id="1506" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">onehot_transformfunction 将目标值 0 和 1 转换为 one-hot 向量[1，0]和[0，1]</p><figure class="lx ly lz ma gt jr"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="f36e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">只要实体及其上下文中的字数是任意的，使用稀疏固定长度向量看起来就不合理。因此，处理任意长度向量的递归神经网络在这里成为一种方便且非常自然的解决方案。我们的测试证明，使用密集层来处理固定长度向量，使用 LSTM 层来处理可变长度向量的架构是最佳的。</p><p id="21c4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">已经用密集层与 LSTM 层的不同组合测试了几种架构。最终的架构配置(层的大小和数量)显示了交叉验证测试的最佳结果，这对应于训练数据的最佳使用。可以通过增加训练数据集的大小以及适当地缩放层的大小和数量来执行进一步的模型调整，使用相同的数据集进行后期调整会导致模型过度拟合。</p><h2 id="0647" class="kx ky iq bd kz la lb dn lc ld le dp lf kj lg lh li kn lj lk ll kr lm ln lo lp bi translated">结果</h2><figure class="lx ly lz ma gt jr"><div class="bz fp l di"><div class="mx my l"/></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Examples of extracted skills</figcaption></figure><p id="09db" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">所有用于模型训练的简历都来自 IT 行业。我们很高兴地看到，我们的模型在属于其他行业(如设计和金融)的简历数据集上也显示出相当合理的性能。显然，处理结构和风格完全不同的 cv 会导致模型性能降低。我们还想提一下，我们对“技能”概念的理解可能与其他人不同。对于我们的模型来说，一个困难的情况是分辨新公司名称中的技能，因为技能通常等同于软件框架，有时你无法分辨这是提到的初创公司名称，还是新的 JS 框架或 Python 库。然而，在大多数情况下，我们的模型可以成为自动 CV 分析的有用工具，并且与一些统计方法一起可以解决任意 CV 语料库上的广泛的数据科学任务。</p></div></div>    
</body>
</html>