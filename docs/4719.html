<html>
<head>
<title>Healthcare Dataset with Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带 Spark 的医疗数据集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/healthcare-dataset-with-spark-6bf48019892b?source=collection_archive---------5-----------------------#2018-09-02">https://towardsdatascience.com/healthcare-dataset-with-spark-6bf48019892b?source=collection_archive---------5-----------------------#2018-09-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div class="gh gi io"><img src="../Images/cdceab0ad847c6cc96293b6d04535901.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*9-Eb7ebglUp0QHN4oVoV6g.png"/></div></figure><div class=""/><p id="e6be" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw iy"> Spark </strong>是来自 Apache 的开源项目。它也是大数据和机器学习最常用的分析引擎。</p><p id="b60e" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这篇文章将重点介绍如何快速开始使用 Spark 开发预测算法。</p><p id="1b07" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我选择了来自 kaggle.com 的“医疗保健数据集中风数据”数据集，这是世界上最大的数据科学家和机器学习社区。</p><p id="48aa" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw iy">内容:</strong></p><p id="6949" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">根据世界卫生组织，缺血性心脏病和中风是世界上最大的杀手。</p><p id="75b4" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">来自官方网站的信息:<a class="ae ks" href="http://www.who.int/news-room/fact-sheets/detail/the-top-10-causes-of-death" rel="noopener ugc nofollow" target="_blank">http://www . who . int/news-room/fact-sheets/detail/the-top-10-causes of death</a></p><p id="4732" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们需要做的是利用患者给定的信息来预测中风概率。这是一个分类问题，我们将尝试预测某个观察值属于某个类别的概率(在我们的案例中是中风的概率)。</p><p id="5a31" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">有很多算法来解决分类问题，我将使用决策树算法。</p><p id="e361" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw iy">设置火花并获取数据</strong></p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="c100" class="lc ld ix ky b gy le lf l lg lh"><strong class="ky iy">from</strong> <strong class="ky iy">pyspark.sql</strong> <strong class="ky iy">import</strong> SparkSession<br/><strong class="ky iy">import</strong> <strong class="ky iy">pyspark.sql</strong> <strong class="ky iy">as</strong> <strong class="ky iy">sparksql</strong><br/>spark = SparkSession.builder.appName('stroke').getOrCreate()</span><span id="5860" class="lc ld ix ky b gy li lf l lg lh">train = spark.read.csv('train_2v.csv', inferSchema=<strong class="ky iy">True</strong>,header=<strong class="ky iy">True</strong>)</span></pre><h1 id="b2b3" class="lj ld ix bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated"><strong class="ak">探索数据</strong></h1><p id="bb31" class="pw-post-body-paragraph ju jv ix jw b jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn mk kp kq kr ij bi translated">导入数据后要执行的第一个操作是获取数据外观的一些信息。可以使用以下命令:</p><ul class=""><li id="e296" class="ml mm ix jw b jx jy kb kc kf mn kj mo kn mp kr mq mr ms mt bi translated">df.printSchema()</li><li id="b674" class="ml mm ix jw b jx mu kb mv kf mw kj mx kn my kr mq mr ms mt bi translated">df.describe()</li><li id="d118" class="ml mm ix jw b jx mu kb mv kf mw kj mx kn my kr mq mr ms mt bi translated">df.dtypes</li></ul><figure class="kt ku kv kw gt is gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/0b271e707d826619d7beb4f8354c5a76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*WVTKL4XVPjyB8XDyEu63JQ.png"/></div></figure><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="2abe" class="lc ld ix ky b gy le lf l lg lh">train.groupBy('stroke').count().show()</span><span id="f635" class="lc ld ix ky b gy li lf l lg lh">+------+-----+<br/>|stroke|count|<br/>+------+-----+<br/>|     1|  783|<br/>|     0|42617|<br/>+------+-----+</span></pre><p id="c4dd" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">从这个观察可以看出。这是一个<strong class="jw iy">不平衡数据集，</strong>其中属于一个类的观测值数量明显低于属于其他类的观测值数量。在这种情况下，预测模型可能会有偏差且不准确。有不同的策略来处理不平衡的数据集，因此这超出了本文的范围，我将重点讨论 Spark。要查找有关不平衡数据集的更多信息:</p><p id="87c1" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><a class="ae ks" href="https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2017/03/不平衡-分类-问题/ </a></p><p id="c9a0" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这里我们有许多病人的临床测量数据(如高血压、心脏病、年龄、家族病史)，以及每个病人是否患过中风的信息。在实践中，我们希望这种方法能够根据临床测量结果准确预测未来患者的中风风险。</p><figure class="kt ku kv kw gt is gh gi paragraph-image"><div class="gh gi na"><img src="../Images/2084cc465541602270db22cc2e51a365.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*3exwRyxaFZuhGB4hk-2K0Q.png"/></div></figure><h1 id="18f7" class="lj ld ix bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated"><strong class="ak">分析</strong></h1><p id="62b3" class="pw-post-body-paragraph ju jv ix jw b jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn mk kp kq kr ij bi translated">使用基本操作进行简要分析。有几种方法可以做到:</p><ul class=""><li id="0038" class="ml mm ix jw b jx jy kb kc kf mn kj mo kn mp kr mq mr ms mt bi translated">数据帧为结构化数据操作提供了特定于领域的语言，可以通过属性或索引来访问数据帧的列。</li><li id="b144" class="ml mm ix jw b jx mu kb mv kf mw kj mx kn my kr mq mr ms mt bi translated">以编程方式运行 SQL 查询并将结果作为数据帧返回</li></ul><p id="0a3b" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">例如，要了解哪种类型的工作有更多的中风病例，我们可以做以下工作:</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="f443" class="lc ld ix ky b gy le lf l lg lh"><em class="nb"># create DataFrame as a temporary view</em><br/>train.createOrReplaceTempView('table')</span></pre><p id="6b51" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">SQL 查询</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="5345" class="lc ld ix ky b gy le lf l lg lh">spark.sql("SELECT work_type, count(work_type) as work_type_count FROM table WHERE stroke == 1 GROUP BY work_type ORDER BY work_type_count DESC").show()</span><span id="11b6" class="lc ld ix ky b gy li lf l lg lh">+-------------+---------------+<br/>|    work_type|work_type_count|<br/>+-------------+---------------+<br/>|      Private|            441|<br/>|Self-employed|            251|<br/>|     Govt_job|             89|<br/>|     children|              2|<br/>+-------------+---------------+</span></pre><p id="ef1a" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">看来私活是这个数据集中最危险的工种。</p><p id="a609" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">让我们找出谁参与了这次临床测量。</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="ac80" class="lc ld ix ky b gy le lf l lg lh">spark.sql("SELECT gender, count(gender) as count_gender, count(gender)*100/sum(count(gender)) over() as percent FROM table GROUP BY gender").show()</span><span id="1451" class="lc ld ix ky b gy li lf l lg lh">+------+------------+-------------------+<br/>|gender|count_gender|            percent|<br/>+------+------------+-------------------+<br/>|Female|       25665|  59.13594470046083|<br/>| Other|          11|0.02534562211981567|<br/>|  Male|       17724|  40.83870967741935|<br/>+------+------------+-------------------+</span></pre><p id="f6df" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">所有参与中风研究的人中，59%是女性，只有 40%是男性。</p><p id="b038" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">根据该信息，有可能检索关于多少女性/男性患有中风信息:</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="8844" class="lc ld ix ky b gy le lf l lg lh">spark.sql("SELECT gender, count(gender), (COUNT(gender) * 100.0) /(SELECT count(gender) FROM table WHERE gender == 'Male') as percentage FROM table WHERE stroke = '1' and gender = 'Male' GROUP BY gender").show()</span><span id="bfe8" class="lc ld ix ky b gy li lf l lg lh">+------+-------------+--------------------+<br/>|gender|count(gender)|          percentage|<br/>+------+-------------+--------------------+<br/>|  Male|          352|1.986007673211464...|<br/>+------+-------------+--------------------+</span><span id="a5c1" class="lc ld ix ky b gy li lf l lg lh"><br/>spark.sql("SELECT gender, count(gender), (COUNT(gender) * 100.0) /(SELECT count(gender) FROM table WHERE gender == 'Female') as percentage FROM table WHERE stroke = '1' and gender = 'Female' GROUP BY gender").show()</span><span id="dcf1" class="lc ld ix ky b gy li lf l lg lh">+------+-------------+--------------------+<br/>|gender|count(gender)|          percentage|<br/>+------+-------------+--------------------+<br/>|Female|          431|1.679329826612117...|<br/>+------+-------------+--------------------+</span></pre><p id="8996" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">1.68%的女性和近 2%的男性曾患过中风。</p><p id="6611" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们还可以看到年龄是否对中风有影响，以及年龄带来的风险。</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="8d6f" class="lc ld ix ky b gy le lf l lg lh">spark.sql("SELECT age, count(age) as age_count FROM table WHERE stroke == 1 GROUP BY age ORDER BY age_count DESC").show()</span><span id="0414" class="lc ld ix ky b gy li lf l lg lh">+----+---------+<br/>| age|age_count|<br/>+----+---------+<br/>|79.0|       70|<br/>|78.0|       57|<br/>|80.0|       49|<br/>|81.0|       43|<br/>|82.0|       36|<br/>|70.0|       25|<br/>|77.0|       24|<br/>|74.0|       24|<br/>|76.0|       24|<br/>|67.0|       23|<br/>|75.0|       23|<br/>|72.0|       21|<br/>|68.0|       20|<br/>|59.0|       20|<br/>|69.0|       20|<br/>|71.0|       19|<br/>|57.0|       19|<br/>|63.0|       18|<br/>|65.0|       18|<br/>|66.0|       17|<br/>+----+---------+<br/>only showing top 20 rows</span></pre><p id="adea" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我可以用<strong class="jw iy">过滤</strong>运算，计算出 50 年后人们的中风病例数。</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="d041" class="lc ld ix ky b gy le lf l lg lh">train.filter((train['stroke'] == 1) &amp; (train['age'] &gt; '50')).count()</span><span id="2815" class="lc ld ix ky b gy li lf l lg lh">result: 708</span></pre><p id="0b82" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们可以看到<strong class="jw iy">年龄</strong>是发生中风的一个重要风险因素。</p><h1 id="035a" class="lj ld ix bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated"><strong class="ak">清洗数据</strong></h1><p id="98d6" class="pw-post-body-paragraph ju jv ix jw b jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn mk kp kq kr ij bi translated">探索的下一步是处理分类值和缺失值。smoking_status 和 bmi 参数缺少值。</p><p id="4ed6" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我将用“无信息”的值填写<strong class="jw iy"> smoking_status </strong>，用平均值填写<strong class="jw iy"> bmi </strong>参数。</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="8f30" class="lc ld ix ky b gy le lf l lg lh"><em class="nb"># fill in missing values</em><br/>train_f = train.na.fill('No Info', subset=['smoking_status'])</span><span id="e3c2" class="lc ld ix ky b gy li lf l lg lh"><em class="nb"># fill in miss values with mean</em><br/><strong class="ky iy">from</strong> <strong class="ky iy">pyspark.sql.functions</strong> <strong class="ky iy">import</strong> mean<br/>mean = train_f.select(mean(train_f['bmi'])).collect()<br/>mean_bmi = mean[0][0]<br/>train_f = train_f.na.fill(mean_bmi,['bmi'])</span></pre><p id="5f45" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw iy">大多数 ML 算法</strong>不能直接处理<strong class="jw iy">分类数据</strong>。编码允许期望连续特征的算法使用分类特征。</p><p id="09b5" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">string indexer-&gt; onehotencode-&gt; vector assembler</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="af38" class="lc ld ix ky b gy le lf l lg lh"><strong class="ky iy">from</strong> <strong class="ky iy">pyspark.ml.feature</strong> <strong class="ky iy">import</strong> (VectorAssembler,OneHotEncoder,<br/>                                StringIndexer)</span></pre><figure class="kt ku kv kw gt is gh gi paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="gh gi nc"><img src="../Images/688f24f59c1fadb4ef8003a9ee764155.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xb9if4QxYVgS8Y4Yiw-jEg.png"/></div></div></figure><p id="5803" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">它不需要事先知道一个特性中有多少类别，由<strong class="jw iy"> StringIndexer </strong>和<strong class="jw iy"> OneHotEncoder </strong>的组合来处理。</p><p id="52ad" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">下一步是创建一个组装器，它将给定的列列表组合成一个向量列来训练 ML 模型。我将使用在 one_hot_encoding 之后得到的向量列。</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="61a4" class="lc ld ix ky b gy le lf l lg lh">assembler = VectorAssembler(inputCols=['genderVec',<br/> 'age',<br/> 'hypertension',<br/> 'heart_disease',<br/> 'ever_marriedVec',<br/> 'work_typeVec',<br/> 'Residence_typeVec',<br/> 'avg_glucose_level',<br/> 'bmi',<br/> 'smoking_statusVec'],outputCol='features')</span></pre><p id="6e0f" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">然后我们将创建一个决策树对象。为此，我们需要导入决策树分类器。</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="2bff" class="lc ld ix ky b gy le lf l lg lh"><strong class="ky iy">from</strong> <strong class="ky iy">pyspark.ml.classification</strong> <strong class="ky iy">import</strong> DecisionTreeClassifier</span><span id="cfff" class="lc ld ix ky b gy li lf l lg lh">dtc = DecisionTreeClassifier(labelCol='stroke',featuresCol='features')</span></pre><p id="9dde" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">到目前为止，我们有一个包含许多阶段的复杂任务，需要执行这些阶段来处理数据。为了包装所有火花，ML 表示这样一个工作流，作为一个<strong class="jw iy">管道</strong>，它由一系列按照特定顺序运行的<strong class="jw iy">管道阶段</strong>组成。</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="256e" class="lc ld ix ky b gy le lf l lg lh"><strong class="ky iy">from</strong> <strong class="ky iy">pyspark.ml</strong> <strong class="ky iy">import</strong> Pipeline</span><span id="8efb" class="lc ld ix ky b gy li lf l lg lh">pipeline = Pipeline(stages=[gender_indexer, ever_married_indexer, work_type_indexer, Residence_type_indexer,<br/>                           smoking_status_indexer, gender_encoder, ever_married_encoder, work_type_encoder,<br/>                           Residence_type_encoder, smoking_status_encoder, assembler, dtc])</span></pre><p id="8266" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">下一步是<strong class="jw iy">拆分</strong>数据集进行训练和测试。</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="faeb" class="lc ld ix ky b gy le lf l lg lh">train_data,test_data = train_f.randomSplit([0.7,0.3])</span></pre><p id="21db" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我现在要做的是拟合模型。为此，我将使用创建的管道和 train_data</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="44f2" class="lc ld ix ky b gy le lf l lg lh">model = pipeline.fit(train_data)</span></pre><p id="1522" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">之后，转换测试数据。</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="6716" class="lc ld ix ky b gy le lf l lg lh">dtc_predictions = model.transform(test_data)</span></pre><p id="f1fd" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">现在是时候评估一个模型了</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="be38" class="lc ld ix ky b gy le lf l lg lh"><strong class="ky iy">from</strong> <strong class="ky iy">pyspark.ml.evaluation</strong> <strong class="ky iy">import</strong> MulticlassClassificationEvaluator</span><span id="c4d2" class="lc ld ix ky b gy li lf l lg lh"><em class="nb"># Select (prediction, true label) and compute test error</em><br/>acc_evaluator = MulticlassClassificationEvaluator(labelCol="stroke", predictionCol="prediction", metricName="accuracy")</span><span id="14c2" class="lc ld ix ky b gy li lf l lg lh">dtc_acc = acc_evaluator.evaluate(dtc_predictions)</span><span id="5140" class="lc ld ix ky b gy li lf l lg lh">print('A Decision Tree algorithm had an accuracy of: <strong class="ky iy">{0:2.2f}</strong>%'.format(dtc_acc*100))</span></pre><p id="4388" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">决策树算法的准确率为 98.08%</p><p id="3ae2" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">正如在开始时所定义的，不平衡数据集的预测模型可能具有误导性的准确性。</p><h1 id="30d8" class="lj ld ix bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated"><strong class="ak">结论</strong></h1><p id="e4cb" class="pw-post-body-paragraph ju jv ix jw b jx mg jz ka kb mh kd ke kf mi kh ki kj mj kl km kn mk kp kq kr ij bi translated">Apache Spark 是一个开源框架，它非常简洁易用。</p></div></div>    
</body>
</html>