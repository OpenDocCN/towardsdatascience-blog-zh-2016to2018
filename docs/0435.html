<html>
<head>
<title>Learning to rank with Python scikit-learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">学习使用Python scikit进行排名-学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learning-to-rank-with-python-scikit-learn-327a5cfd81f?source=collection_archive---------0-----------------------#2017-05-03">https://towardsdatascience.com/learning-to-rank-with-python-scikit-learn-327a5cfd81f?source=collection_archive---------0-----------------------#2017-05-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="0151" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你经营一个电子商务网站，一个经典的问题是在搜索页面上排列你的产品，以最大化你的商品被销售的可能性。例如，如果你在卖鞋，你希望搜索结果页面中的第一双鞋是最有可能被购买的。</p><p id="7a5a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于机器学习的广泛采用，现在比以往任何时候都更容易建立和部署自动学习用户喜欢什么并相应地对产品目录进行排名的模型。在这篇博文中，我将分享如何使用一个简单的端到端示例，使用<a class="ae kl" href="https://grouplens.org/datasets/movielens/100k/" rel="noopener ugc nofollow" target="_blank"> movielens开放数据集</a>来构建这样的模型。</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h1 id="78d1" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">介绍</h1><p id="9d32" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">想象一下，你有一个电子商务网站，你正在设计一种算法，在你的搜索页面中对你的产品进行排序。你展示的第一件物品是什么？评论最好的那个？价格最低的那个？还是两者都有？问题很快变得复杂起来。</p><p id="d7bb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一个简单的解决方案是利用你的直觉，从你的客户那里收集反馈，或者从你的网站上获取指标，手工制作适合你的完美配方。不太科学不是吗？一种更复杂的方法包括建立许多排名公式，并使用<a class="ae kl" href="http://www.alfredo.motta.name/ab-testing-from-scratch/" rel="noopener ugc nofollow" target="_blank"> A/B测试</a>来选择具有最佳性能的一个。</p><p id="4782" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这里，我们将使用来自客户的数据来自动学习他们的<em class="lw">偏好函数</em>，这样我们的搜索页面的排名将最大化获得<em class="lw">转化率</em>的可能性(即客户购买你的商品)。具体来说，我们将学习如何根据人工生成的用户数据对来自<a class="ae kl" href="https://grouplens.org/datasets/movielens/100k/" rel="noopener ugc nofollow" target="_blank"> movielens开放数据集</a>的电影进行排名。Github 上的<a class="ae kl" href="https://github.com/mottalrd/learning-to-rank" rel="noopener ugc nofollow" target="_blank">提供了Jupyter笔记本格式的完整步骤。</a></p><h1 id="b80c" class="kt ku iq bd kv kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq bi translated">准备培训数据</h1><p id="7e11" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">为了学习我们的排名模型，我们首先需要一些训练数据。因此，让我们生成一些模拟网站用户行为的示例:</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="4bf0" class="ml ku iq mh b gy mm mn l mo mp">event_1: &lt;customer_1, movie_1, fail&gt;<br/>event_2: &lt;customer_1, movie_2, fail&gt;<br/>event_3: &lt;customer_1, movie_3, success&gt;<br/>event_4: &lt;customer_2, movie_2, fail&gt;<br/>event_5: &lt;customer_2, movie_3, success&gt;<br/>…</span></pre><p id="bd58" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">列表可以解释为:<em class="lw"> customer_1 </em>看了<em class="lw"> movie_1 </em>和<em class="lw"> movie_2 </em>但决定不买。然后看了<em class="lw"> movie_3 </em>决定买电影。同样的<em class="lw">顾客_2 </em>看了<em class="lw">电影_2 </em>但决定不买。然后看了<em class="lw"> movie_3 </em>决定买。</p><p id="4f07" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在真实世界的场景中，你可以从你选择的分析工具中获得这些事件，但是对于这篇博文，我将人工生成它们。为此，我们将为每部电影关联一个<em class="lw"> buy_probability </em>属性，并相应地生成用户事件。</p><p id="8569" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的原始电影数据如下所示:</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="0b07" class="ml ku iq mh b gy mm mn l mo mp">movie_data.dtypes</span><span id="fb7e" class="ml ku iq mh b gy mq mn l mo mp">title object<br/>release_date datetime64[ns]<br/>unknown int64<br/>Action int64<br/>Adventure int64<br/>Animation int64<br/>Children’s int64<br/>Comedy int64<br/>Crime int64<br/>Documentary int64<br/>Drama int64<br/>Fantasy int64<br/>Film-Noir int64<br/>Horror int64<br/>Musical int64<br/>Mystery int64<br/>Romance int64<br/>Sci-Fi int64<br/>Thriller int64<br/>War int64<br/>Western int64<br/>ratings_average float64<br/>ratings_count int64<br/>price float64<br/>dtype: object<br/></span></pre><p id="0a4e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是数据集中一部电影的例子:</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="2835" class="ml ku iq mh b gy mm mn l mo mp">‘title’, ‘release_date’, ‘unknown’, ‘Action’, ‘Adventure’, ‘Animation’, “Children’s”, ‘Comedy’, ‘Crime’, ‘Documentary’, ‘Drama’, ‘Fantasy’, ‘Film-Noir’, ‘Horror’, ‘Musical’, ‘Mystery’, ‘Romance’, ‘Sci-Fi’, ‘Thriller’, ‘War’, ‘Western’, ‘ratings_average’, ‘ratings_count’, ‘price’<br/>‘Toy Story (1995)’, Timestamp(‘1995–01–01 00:00:00’), 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3.8783185840707963, 452, 7.0</span></pre><p id="29d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们假设我们的用户将仅基于价格做出购买决定，并看看我们的机器学习模型是否能够学习这样的功能。对于这个数据集，电影价格的范围在0到10之间(查看github以了解价格是如何分配的)，所以我决定人工定义购买概率如下:</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="1455" class="ml ku iq mh b gy mm mn l mo mp">movie_data[‘buy_probability’] = 1 — movie_data[‘price’] * 0.1</span></pre><p id="f223" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">根据购买概率函数，我们的完美排名应该是这样的:</p><figure class="mc md me mf gt ms gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/09a82476d65a483e69c78994ae821a72.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*nFBtB5ChSO_2TCY6bE5O0Q.png"/></div></figure><p id="6a5a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">没有火箭科学，价格最低的电影最有可能被购买，因此应该排在第一位。现在让我们基于这些数据生成一些用户事件。每个用户都有许多积极和消极的事件与之相关联。正面事件是指用户购买了一部电影。负面事件是指用户看了电影，但决定不购买。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="2b5d" class="ml ku iq mh b gy mm mn l mo mp">class User:<br/>    def __init__(self, id):<br/>        self.id = id<br/>        self.positive = []<br/>        self.negative = []<br/>        <br/>    def add_positive(self, movie_id):<br/>        self.positive.append(movie_id)<br/>    <br/>    def add_negative(self, movie_id):<br/>        self.negative.append(movie_id)<br/>    <br/>    def get_positive(self):<br/>        return self.positive<br/>    <br/>    def get_negative(self):<br/>        return self.negative</span></pre><p id="7763" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在继续之前，我们希望所有的特征都被标准化，以帮助我们的学习算法。所以让我们把这个弄清楚。还要注意，我们将删除<em class="lw"> buy_probability </em>属性，这样我们就不会在学习阶段使用它(用机器学习的术语来说，这相当于作弊！).</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="4187" class="ml ku iq mh b gy mm mn l mo mp">def build_learning_data_from(movie_data):<br/>    feature_columns = np.setdiff1d(movie_data.columns, np.array(['title', 'buy_probability']))<br/>    learning_data = movie_data.loc[:, feature_columns]<br/>    <br/>    scaler = StandardScaler()<br/>    learning_data.loc[:, ('price')] = scaler.fit_transform(learning_data[['price']])<br/>    learning_data['ratings_average'] = scaler.fit_transform(learning_data[['ratings_average']])<br/>    learning_data['ratings_count'] = scaler.fit_transform(learning_data[['ratings_count']])<br/>    learning_data['release_date'] = learning_data['release_date'].apply(lambda x: x.year)<br/>    learning_data['release_date'] = scaler.fit_transform(learning_data[['release_date']])<br/>    <br/>    return learning_data</span></pre><p id="bee1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，使用下面显示的“EventsGenerator”类，我们可以生成我们的用户事件。为了简单起见，让我们假设我们有<em class="lw"> 1000个</em>用户，并且每个用户将打开<em class="lw"> 20部</em>电影。真实世界的数据显然会有所不同，但原理是一样的。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="912a" class="ml ku iq mh b gy mm mn l mo mp">np.random.seed(1)</span><span id="609c" class="ml ku iq mh b gy mq mn l mo mp">class EventsGenerator:<br/>    NUM_OF_OPENED_MOVIES_PER_USER = 20<br/>    NUM_OF_USERS = 1000</span><span id="57de" class="ml ku iq mh b gy mq mn l mo mp">def __init__(self, learning_data, buy_probability):<br/>        self.learning_data = learning_data<br/>        self.buy_probability = buy_probability<br/>        self.users = []<br/>        for id in range(1, self.NUM_OF_USERS):<br/>            self.users.append(User(id))<br/>        <br/>    def run(self):<br/>        for user in self.users:<br/>            opened_movies = np.random.choice(self.learning_data.index.values, self.NUM_OF_OPENED_MOVIES_PER_USER)<br/>            self.__add_positives_and_negatives_to(user, opened_movies)</span><span id="49f1" class="ml ku iq mh b gy mq mn l mo mp">return self.__build_events_data()</span><span id="d146" class="ml ku iq mh b gy mq mn l mo mp">def __add_positives_and_negatives_to(self, user, opened_movies):<br/>        for movie_id in opened_movies:<br/>            if np.random.binomial(1, self.buy_probability.loc[movie_id]): <br/>                user.add_positive(movie_id)<br/>            else:<br/>                user.add_negative(movie_id)<br/>                <br/>    def __build_events_data(self):<br/>        events_data = []<br/>        <br/>        for user in self.users:<br/>            for positive_id in user.get_positive():<br/>                tmp = learning_data.loc[positive_id].to_dict()<br/>                tmp['outcome'] = 1<br/>                events_data += [tmp]<br/>            <br/>            for negative_id in user.get_negative():<br/>                tmp = learning_data.loc[negative_id].to_dict()<br/>                tmp['outcome'] = 0<br/>                events_data += [tmp]<br/>                <br/>        return pd.DataFrame(events_data)</span></pre><p id="c3e2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就是所有东西粘在一起的原因。<em class="lw">事件生成器</em>获取标准化的电影数据，并使用购买概率来生成用户事件。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="52ec" class="ml ku iq mh b gy mm mn l mo mp">learning_data = build_learning_data_from(movie_data)<br/>events_data = EventsGenerator(learning_data, movie_data['buy_probability']).run()</span></pre><p id="7c02" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是其中一个事件的样子:</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="bbc5" class="ml ku iq mh b gy mm mn l mo mp">'Action', 'Adventure', 'Animation', "Children's", 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western', 'outcome', 'price',    'ratings_average', 'ratings_count', 'release_date', 'unknown'<br/>1,        1,           0,           0,            0,        0,       0,             0,       0,         0,           0,        0,         0,         0,         0,        0,          0,     1,         0,         0.28363692, 0.16953213,        -0.14286941,     0.39397757,     0</span></pre><p id="efd1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这种情况下，由于我们在函数<em class="lw">build _ learning _ data _ from(movie _ data)</em>中所做的操作，我们得到了一个否定的结果(值为0)，并且这些特征已经被归一化并集中在零。</p><p id="470e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果我们绘制事件图，我们可以看到分布反映了人们大多购买廉价电影的想法。由于正常化，价格再次以零为中心。</p><figure class="mc md me mf gt ms gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/5d7ef6bab5d0e89ac37938cb5b3ff01f.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*YbwtrBJ7wk1Zg1IkIUTfzQ.png"/></div></figure><h1 id="8757" class="kt ku iq bd kv kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq bi translated">训练我们的模型</h1><p id="72f9" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">现在我们有了我们的事件，让我们看看我们的模型在学习(简单)“购买概率”函数方面有多好。我们将把我们的数据分成一个训练和测试集，以测量模型性能(但请确保您知道<a class="ae kl" href="http://www.alfredo.motta.name/cross-validation-done-wrong/" rel="noopener ugc nofollow" target="_blank">交叉验证如何工作</a>)，并使用这个通用函数来打印不同模型的性能。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="6d44" class="ml ku iq mh b gy mm mn l mo mp">def train_model(model, prediction_function, X_train, y_train, X_test, y_test):<br/>    model.fit(X_train, y_train)<br/>    <br/>    y_train_pred = prediction_function(model, X_train)</span><span id="c309" class="ml ku iq mh b gy mq mn l mo mp">print('train precision: ' + str(precision_score(y_train, y_train_pred)))<br/>    print('train recall: ' + str(recall_score(y_train, y_train_pred)))<br/>    print('train accuracy: ' + str(accuracy_score(y_train, y_train_pred)))</span><span id="cf92" class="ml ku iq mh b gy mq mn l mo mp">y_test_pred = prediction_function(model, X_test)</span><span id="989c" class="ml ku iq mh b gy mq mn l mo mp">print('test precision: ' + str(precision_score(y_test, y_test_pred)))<br/>    print('test recall: ' + str(recall_score(y_test, y_test_pred)))<br/>    print('test accuracy: ' + str(accuracy_score(y_test, y_test_pred)))<br/>    <br/>    return model</span></pre><p id="ffdb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用scikit-learn训练各种模型现在只是把东西粘在一起的问题。让我们从逻辑回归开始:</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="54e2" class="ml ku iq mh b gy mm mn l mo mp">def get_predicted_outcome(model, data):<br/>    return np.argmax(model.predict_proba(data), axis=1).astype(np.float32)</span><span id="bc14" class="ml ku iq mh b gy mq mn l mo mp">def get_predicted_rank(model, data):<br/>    return model.predict_proba(data)[:, 1]</span><span id="a107" class="ml ku iq mh b gy mq mn l mo mp">model = train_model(LogisticRegression(), get_predicted_outcome, X_train, y_train, X_test, y_test)</span></pre><p id="4aa8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这为我们提供了以下性能</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="9456" class="ml ku iq mh b gy mm mn l mo mp">train precision: 0.717381689518<br/>train recall: 0.716596235113<br/>train accuracy: 0.717328291166<br/>test precision: 0.720525676086<br/>test recall: 0.726374636238<br/>test accuracy: 0.721590909091</span></pre><p id="4d7e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以使用神经网络和决策树来做同样的事情。这是一个具有23个输入(与电影特征的数量相同)和46个隐含层神经元(隐含层神经元加倍是一个常见的经验法则)的神经网络。</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="dcea" class="ml ku iq mh b gy mm mn l mo mp">from nolearn.lasagne import NeuralNet</span><span id="7245" class="ml ku iq mh b gy mq mn l mo mp">def nn():<br/>    return NeuralNet(<br/>        layers=[  # three layers: one hidden layer<br/>            ('input', layers.InputLayer),<br/>            ('hidden', layers.DenseLayer),<br/>            ('output', layers.DenseLayer),<br/>            ],<br/>        # layer parameters:<br/>        input_shape=(None, 23),  # this code won't compile without SIZE being set<br/>        hidden_num_units=46,  # number of units in hidden layer<br/>        output_nonlinearity=None,  # output layer uses identity function<br/>        output_num_units=1,  # this code won't compile without OUTPUTS being set</span><span id="674f" class="ml ku iq mh b gy mq mn l mo mp"># optimization method:<br/>        update_learning_rate=0.01, <br/>        regression=True,  # If you're doing classification you want this off<br/>        max_epochs=50,  # more epochs can be good, <br/>        verbose=1, # enabled so that you see meaningful output when the program runs<br/>    )</span><span id="426c" class="ml ku iq mh b gy mq mn l mo mp">def get_predicted_outcome(model, data):<br/>    return np.rint(model.predict(data))</span><span id="07de" class="ml ku iq mh b gy mq mn l mo mp">def get_predicted_rank(model, data):<br/>    return model.predict(data)</span></pre><p id="39f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是我们得到的表现</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="062a" class="ml ku iq mh b gy mm mn l mo mp">model = train_model(<br/> nn(), <br/> get_predicted_outcome, <br/> X_train.astype(np.float32), <br/> y_train.astype(np.float32), <br/> X_test.astype(np.float32), <br/> y_test.astype(np.float32)<br/>)</span><span id="6a44" class="ml ku iq mh b gy mq mn l mo mp">train precision: 0.698486217804<br/>train recall: 0.687534749249<br/>train accuracy: 0.65721971972<br/>test precision: 0.667556742323<br/>test recall: 0.679655641142<br/>test accuracy: 0.636136136136</span></pre><p id="bece" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后是决策树</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="a65a" class="ml ku iq mh b gy mm mn l mo mp">def get_predicted_outcome(model, data):<br/>    return np.argmax(model.predict_proba(data), axis=1).astype(np.float32)</span><span id="a008" class="ml ku iq mh b gy mq mn l mo mp">def get_predicted_rank(model, data):<br/>    return model.predict_proba(data)[:, 1]</span></pre><p id="bdc5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这为我们提供了以下性能</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="a4af" class="ml ku iq mh b gy mm mn l mo mp">from sklearn import tree<br/>model = train_model(tree.DecisionTreeClassifier(), get_predicted_outcome, X_train, y_train, X_test, y_test)</span><span id="81a8" class="ml ku iq mh b gy mq mn l mo mp">train precision: 0.680947848951<br/>train recall: 0.711256135779<br/>train accuracy: 0.653892069603<br/>test precision: 0.668242778542<br/>test recall: 0.704538759602<br/>test accuracy: 0.644044702235</span></pre><p id="5a16" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以将各种排名标绘在一起进行比较。排名曲线的形状与我们用来定义<em class="lw">购买概率</em>的曲线非常相似，这证实了我们的算法正确地学习了<em class="lw">偏好函数</em>。</p><p id="6159" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">描述buy_probability的形状并不完全相同，因为用户事件是随机生成的(均值等于<em class="lw"> buy_probability </em>的二项式分布)，所以模型只能根据生成的事件来近似潜在的事实。</p><figure class="mc md me mf gt ms gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/7ff03b0fecf68530b03d6a86619513e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*tn2VfQOYNKlooMrNb6sgyQ.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Logistic regression</figcaption></figure><figure class="mc md me mf gt ms gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/386619bc25482fb60a4a5b66065059eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*eSEwv0sc13_Q28zz2CcRFQ.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Decision trees</figcaption></figure><figure class="mc md me mf gt ms gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/99bd12bfc7de8cfe9a2bd0a32d7bd09c.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*yDzstxegAm65f6DQnzm6rA.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Neural Network</figcaption></figure><h1 id="ca1d" class="kt ku iq bd kv kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq bi translated">下一步是什么</h1><p id="2ef8" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">一旦你得到了你的排名估计，你可以简单地将它们保存在你选择的数据库中，并开始为你的页面服务。随着时间的推移，你的用户的行为可能会像你的目录中的产品一样发生变化，所以要确保你有一些程序来每周更新你的排名数字，如果不是每天的话。根据一个简单的手工制作的线性公式对你的新模型进行A/B测试也是一个好主意，这样你就可以验证自己，机器学习是否确实在帮助你收集更多的转化率。</p><p id="c508" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你更喜欢戴科学家的帽子，你也可以在Github 上运行Jupyter笔记本<a class="ae kl" href="https://github.com/mottalrd/learning-to-rank" rel="noopener ugc nofollow" target="_blank">，用不同的公式计算<em class="lw"> buy_probability </em>，看看这些模型能够在多大程度上发现潜在的真相。我确实尝试了价格和评级的非线性函数的线性组合，它在相似的准确度水平下工作得同样好。</a></p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="3013" class="ml ku iq mh b gy mm mn l mo mp">price_component = np.sqrt(movie_data['price'] * 0.1)<br/>ratings_component = np.sqrt(movie_data['ratings_average'] * 0.1 * 2)<br/>movie_data['buy_probability'] = 1 - price_component * 0.2 - ratings_component * 0.8</span></pre><p id="9d42" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，与这里概述的方法不同的方法是使用事件对来学习排序函数。这个想法是，你给学习算法输入一对这样的事件:</p><pre class="mc md me mf gt mg mh mi mj aw mk bi"><span id="5106" class="ml ku iq mh b gy mm mn l mo mp">pair_event_1: &lt;customer_1, movie_1, fail, movie_3, success&gt;<br/>pair_event_2: &lt;customer_2, movie_2, fail, movie_3, success&gt;<br/>pair_event_3: &lt;customer_3, movie_1, fail, movie_2, success&gt;<br/>...</span></pre><p id="0ac1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有了这样的例子，你可以猜到一个好的排序是“电影_3，电影_2，电影_1 ”,因为不同客户的选择强制了我们的电影集合的总排序。尽管预测成对的结果与上面显示的例子具有相似的准确性，但为我们的电影集提出一个全局排序证明是困难的(NP完全困难，如来自&amp; T labs 的<a class="ae kl" href="https://www.jair.org/media/587/live-587-1790-jair.pdf" rel="noopener ugc nofollow" target="_blank">这篇论文所示)，我们将不得不求助于贪婪算法进行排序，这会影响最终结果的质量。Julien le tessier</a><a class="ae kl" href="http://dec0de.me/2014/10/learning-to-rank-1" rel="noopener ugc nofollow" target="_blank">的这篇博客文章对这种方法进行了更深入的描述。</a></p><h1 id="bc16" class="kt ku iq bd kv kw lx ky kz la ly lc ld le lz lg lh li ma lk ll lm mb lo lp lq bi translated">结论</h1><p id="6385" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">在这篇博文中，我介绍了如何利用用户事件数据来教会机器学习算法如何对你的产品目录进行最佳排序，以最大化你的商品被购买的可能性。我们看到了逻辑回归、神经网络和决策树如何实现相似的性能，以及如何将您的模型部署到生产中。</p><p id="2add" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">期待在评论中听到你的想法，如果你喜欢这个博客，你也可以在Twitter上关注我。</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><p id="c388" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="lw">最初发表于</em> <a class="ae kl" href="http://www.alfredo.motta.name/learning-to-rank-with-python-scikit-learn/" rel="noopener ugc nofollow" target="_blank"> <em class="lw">阿尔弗雷多</em> </a> <em class="lw">。</em></p></div></div>    
</body>
</html>