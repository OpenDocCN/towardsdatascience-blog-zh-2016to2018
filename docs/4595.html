<html>
<head>
<title>Machine learning algorithms can help us to estimate the risk of a financial decision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习算法可以帮助我们评估金融决策的风险</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/financial-data-analysis-2f86b1341e6e?source=collection_archive---------15-----------------------#2018-08-24">https://towardsdatascience.com/financial-data-analysis-2f86b1341e6e?source=collection_archive---------15-----------------------#2018-08-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7381" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">贷款资格预测:探索性数据分析</h2></div><p id="802e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本系列的第一部分的<a class="ae lb" href="https://medium.com/@sabber/financial-data-analysis-80ba39149126" rel="noopener">中，我展示了一些必要的数据处理，包括:移除常量特征、移除重复特征、移除重复行、移除与 85%缺失值相关的特征&gt;。这些是我们需要在几乎每个数据集上执行的初步步骤。完成上述处理后，我能够移除 60 个不相关的特征，剩下 153 个初始特征中的 93 个。在</a><a class="ae lb" href="https://medium.com/@sabber/financial-data-analysis-bf4b5e78c45c" rel="noopener">的第二部分</a>，我手动检查了每一个特征，处理文本并删除了一些不必要的特征。在数据处理和清理结束时，我们有 36 个相关特征。</p><p id="6305" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这一部分，我对所选择的 36 个特征进行了一些探索性的分析。这些分析包括可视化特征的相关系数，去除高度共线的特征。</p><p id="fdc1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们从导入库和读取具有所选功能的数据集开始:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="dba6" class="ll lm iq lh b gy ln lo l lp lq">import warnings<br/>warnings.filterwarnings("ignore")</span><span id="581a" class="ll lm iq lh b gy lr lo l lp lq">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="b3bc" class="ll lm iq lh b gy lr lo l lp lq">from sklearn.utils import shuffle, class_weight<br/>from sklearn import preprocessing<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import accuracy_score, classification_report, confusion_matrix</span></pre><p id="5e97" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">读取数据</strong></p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="2392" class="ll lm iq lh b gy ln lo l lp lq">df_selected = pd.read_csv('./data/df_selected.csv')</span></pre><p id="4825" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">特征关联</strong></p><p id="a391" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可视化特征之间的关系是一组数据可能对应于另一组数据的方式之一。特别是在机器学习中，特征相关性的重要性是显著的。它帮助我们识别坏的和高度共线的特征。相关矩阵也可以用于特征工程。在下图中，显示了特征之间的关系:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="10cc" class="ll lm iq lh b gy ln lo l lp lq">corr = df_selected.corr()<br/>plt.figure(figsize = (10, 8))<br/>sns.heatmap(corr)<br/>plt.show()</span></pre><figure class="lc ld le lf gt lt gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/75d67780a57de2b50b1bb1191778d9fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*vkEYqqglCNInJWpSQLqo_g.png"/></div></figure><p id="1637" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从上面的图中，我们看到解释特性关系有点棘手。所以，我们要具体一点。例如，如果我们想知道特征是如何与目标变量相关的，我们必须编写下面的代码来获得特征与目标变量的相关系数:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="79ce" class="ll lm iq lh b gy ln lo l lp lq">corr['loan_status'].sort_values(ascending = False)<br/>                   .to_frame('corr_value')<br/>                   .reset_index()</span></pre><figure class="lc ld le lf gt lt gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/1618a5f84a09dd7203a3f790b6e4e26c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*aPJAuZqSc89_6Iv2SCqOZA.png"/></div></figure><p id="a53a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从上面打印的结果来看，sub_grade 与目标变量贷款状态的正相关性最高，其次是等级、利率等。Fico_range_high 和 Fico_range_low 的负相关性最高。由于 Fico_range_high 和 Fico_range_low 具有几乎相同的相关系数(-0.136)，所以我们可以将它们合并，取它们的平均值并删除它们。</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="9e66" class="ll lm iq lh b gy ln lo l lp lq">df_selected['avg_fico_score'] = (df_selected['fico_range_high'] + df_selected['fico_range_low'])/2.0</span><span id="fba6" class="ll lm iq lh b gy lr lo l lp lq">df_selected.drop(['fico_range_low','fico_range_high'], axis=1, inplace=True)</span></pre><p id="699a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">寻找高度相关的特征</strong></p><p id="130c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们有了要素的相关系数矩阵，查找高度共线(高度相关)的要素变得更加容易。使用下面的代码，我找到了共线特性:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="dee8" class="ll lm iq lh b gy ln lo l lp lq">funded_amnt           loan_amnt           1.000000<br/>funded_amnt_inv       loan_amnt           0.999996<br/>                      funded_amnt         0.999996<br/>int_rate              term                0.435879<br/>installment           loan_amnt           0.952673<br/>                      funded_amnt         0.952673<br/>                      funded_amnt_inv     0.952653<br/>grade                 term                0.446887<br/>                      int_rate            0.962951<br/>sub_grade             term                0.454138<br/>                      int_rate            0.985559<br/>                      grade               0.976940<br/>total_acc             open_acc            0.689583<br/>acc_open_past_24mths  open_acc            0.482634<br/>                      total_acc           0.428877<br/>mort_acc              home_ownership     -0.477745<br/>pub_rec_bankruptcies  pub_rec             0.642983<br/>tax_liens             pub_rec             0.695931<br/>credit_history        earliest_cr_year   -0.994442<br/>fico_grade            int_rate            0.792840<br/>                      grade               0.821197<br/>                      sub_grade           0.798134</span></pre><p id="4fd7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从上面的结果中，我们看到' funded_amnt '和' loan_amnt '有 100%的相关性，这告诉我们，它们本质上是一样的。同样，' funded_amnt_inv '与' loan_amnt '和' funded_amnt '的关联度几乎是 100%。因此，我删除了' funded_amnt '，' funded_amnt_inv '功能。</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="c4cf" class="ll lm iq lh b gy ln lo l lp lq">df_selected.drop(['funded_amnt','funded_amnt_inv'], axis=1, inplace=True)</span></pre><p id="e241" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我还发现以下特性与建模目的无关。因此，我将它们从数据中删除:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="7f6b" class="ll lm iq lh b gy ln lo l lp lq">df_selected.drop(‘earliest_cr_year’, axis = 1, inplace=True)<br/>df_selected.drop('issue_year', axis = 1, inplace=True)</span></pre><p id="6c1b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">删除特性后，我们得到了 29 个最相关和最重要的特性以及一个目标特性‘loan _ status’。</p><p id="54ed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">分类特征与连续特征</strong></p><p id="9d8b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好的，让我们看看这些特征是具有分类值还是连续值。它帮助我们找到合适的建模算法:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="f3f2" class="ll lm iq lh b gy ln lo l lp lq">cat_features.remove('loan_status')</span><span id="3bd2" class="ll lm iq lh b gy lr lo l lp lq">['term',<br/> 'grade',<br/> 'emp_length',<br/> 'home_ownership',<br/> 'verification_status',<br/> 'purpose',<br/> 'initial_list_status',<br/> 'application_type',<br/> 'pub_rec_bankruptcies',<br/> 'disbursement_method',<br/> 'issue_month',<br/> 'issue_year']</span></pre><p id="2ed9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们看到 12 个特征≤14 个唯一值。只有六个要素具有超过 1200 个唯一值。这意味着大多数特征都是绝对的。因此，基于树的算法将是尝试的第一选择。</p><p id="0353" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">还有许多其他可以执行的 EDA。但由于时间的限制，我不会做进一步的分析功能。相反，在下一部分中，我将着重于选择一个合适的算法，然后创建一个模型。</p><p id="4485" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在<a class="ae lb" href="https://medium.com/@sabber/financial-data-analysis-51e7275d0ae" rel="noopener">系列的下一部分</a>，我将开始创建模型。同时，如果你对这部分有任何问题，请在下面写下你的意见。你可以联系我:</p><pre class="lc ld le lf gt lg lh li lj aw lk bi"><span id="16c3" class="ll lm iq lh b gy ln lo l lp lq">Email: sabbers@gmail.com<br/>LinkedIn: <a class="ae lb" href="https://www.linkedin.com/in/sabber-ahamed/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/sabber-ahamed/</a><br/>Github: <a class="ae lb" href="https://github.com/msahamed" rel="noopener ugc nofollow" target="_blank">https://github.com/msahamed</a><br/>Medium: <a class="ae lb" href="https://medium.com/@sabber/" rel="noopener">https://medium.com/@sabber/</a></span></pre></div></div>    
</body>
</html>