<html>
<head>
<title>Symbolic Regression and Genetic Programming</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">符号回归和遗传编程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/symbolic-regression-and-genetic-programming-8aed39e7f030?source=collection_archive---------7-----------------------#2018-07-02">https://towardsdatascience.com/symbolic-regression-and-genetic-programming-8aed39e7f030?source=collection_archive---------7-----------------------#2018-07-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/a364cc2c71513ee0baac9f99e8317376.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Drd2Jxzu8UCmDG3Sz0ZcfA.png"/></div></div></figure></div><div class="ab cl jy jz hu ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="ij ik il im in"><p id="e06c" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">符号回归和遗传编程远未成为主流的机器学习技术。然而，他们绝对值得相当多的关注。这篇文章是一个温和而非正式的介绍。</p><h1 id="fcc2" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">动机</h1><p id="3df6" class="pw-post-body-paragraph kf kg iq kh b ki mb kk kl km mc ko kp kq md ks kt ku me kw kx ky mf la lb lc ij bi translated">想象一下，有人让你在不使用矩阵或求和符号的情况下，写下单输出神经网络的正向传递。啊？为了使事情变得简单，你可能会想到最普通的神经网络:具有一个隐藏层的多层感知器。所以在矩阵符号中，它看起来像这样</p><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mg"><img src="../Images/3484cf7f284f220a8decf06bb264a455.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x7_J-nu2kS74S4VK5aGB5w.png"/></div></div></figure><p id="c1cc" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">好的，为了去掉矩阵符号，你需要决定输入和隐藏层的大小。假设有 3 个输入特征和 4 个隐藏节点。所以你的矩阵是:</p><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ml"><img src="../Images/ff91cfcd1cf32c128c730ad8320f95b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NjP8EIp_3mm0guUSx7V-4A.png"/></div></div></figure><p id="1648" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">最后也是最乏味的一步是写出所有的东西，没有任何矩阵和求和符号</p><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mm"><img src="../Images/c43ae09604c92c1aa7c25a77769d27d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4II2c4qYmFCpnOZBAZmmpw.png"/></div></div></figure><p id="4585" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">尽管这种表述非常不切实际，但它清楚地表明了一件重要的事情:预测只是对输入要素应用基本数学运算的结果。具体来说，这些操作是加法、乘法和合成。换句话说，我们把一堆代表数学运算的<strong class="kh ir">符号表达式组合起来，希望得到正确的预测。</strong></p><p id="0c16" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">这是一个转折。利用神经网络，人们试图找到所有的<em class="mn"> w </em>和<em class="mn"> b </em>的最优值，使得某个损失函数最小化。然而，另一个想法是修复所有的<em class="mn"> w </em>和<em class="mn"> b </em>，只改变符号表达式 iteself！或者换句话说，改变逼近器的函数形式。这正是<strong class="kh ir">符号回归</strong>的意义所在。改变自然可以有两种形式。您可以添加新的符号表达式(数学运算)或删除一些现有的符号表达式。</p><h1 id="b665" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">但是怎么做呢？</h1><p id="afbc" class="pw-post-body-paragraph kf kg iq kh b ki mb kk kl km mc ko kp kq md ks kt ku me kw kx ky mf la lb lc ij bi translated">与优化权重不同，对于符号回归，以可以使用梯度下降技术的方式将问题公式化并不是微不足道的。但是，很容易评估单个表达式的性能。那么我们如何想出这种实现低损耗的神奇表达呢？进入<strong class="kh ir">遗传编程</strong>。</p><p id="abb8" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">遗传编程(GP)和更臭名昭著的遗传算法(GA)之间的区别在于，GP 将解表示为树，而 GA 表示为字符串。使用树表示的主要原因是能够捕捉解决方案的内在结构。这与我们的应用非常相关，因为每个数学表达式都可以通过树来表示。参见下面的例子</p><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mo"><img src="../Images/6cf2486b903202b5e142ce15be51310f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*T01eiDRE9zPnCcsC.png"/></div></div></figure><p id="4d22" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">可以基于回归度量(如均方误差或平均绝对误差)为每棵树分配适合度分数。对于 GP，还需要决定如何执行交叉和变异。有几种不同的方法可以做到这一点，但让我们只描述一种简单的方法。</p><p id="af89" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">对于突变，最简单的程序是所谓的点突变。树的随机节点被选择和改变。需要注意节点类型，因为一个节点可以表示不同的操作(一元、二元、…)。</p><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mo"><img src="../Images/e347b26dedb7bce191e598e55b555983.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DD4uzyl-f1zviuZA.png"/></div></div></figure><p id="f076" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">交叉使用 2 个具有高适应值的解决方案，并尝试将它们结合起来。标准的方法是从捐献者那里得到一个随机的子树，并把它插入到父树的随机子树中。</p><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mo"><img src="../Images/6bc26bf09f9286ff897ff57bce6ed156.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ULVrvhR7gehJp8Jg.png"/></div></div></figure></div><div class="ab cl jy jz hu ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="ij ik il im in"><h1 id="1dea" class="ld le iq bd lf lg mp li lj lk mq lm ln lo mr lq lr ls ms lu lv lw mt ly lz ma bi translated">gplearn</h1><p id="8bbd" class="pw-post-body-paragraph kf kg iq kh b ki mb kk kl km mc ko kp kq md ks kt ku me kw kx ky mf la lb lc ij bi translated">当然，你可以自己编码所有的东西，但是已经有一些开源包关注这个主题了。我能找到的最好的一个叫做<strong class="kh ir"> gplearn </strong>。它最大的优点是它遵循了 scikit-learn API ( <code class="fe mu mv mw mx b">fit</code>和<code class="fe mu mv mw mx b">transform</code> / <code class="fe mu mv mw mx b">predict</code>方法)。</p><p id="5430" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">它实现了两个主要的算法:回归和转换。对于回归，适应度函数只是一个度量，如均方误差或平均绝对误差。然而，transformer 通过尝试最大化等于相关性(spearman 或 pearson)的适应度函数，从原始特征中创建新特征。</p><p id="cfc6" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">一旦安装完毕，用户可以通过属性<code class="fe mu mv mw mx b">_program</code>检查最佳解决方案。请注意，有多个超参数可以定制演进的所有主要部分。我鼓励你阅读官方文档并熟悉其中的一些，特别是如果你想防止像过度拟合这样的事情发生，或者如果你只是想寻求加速。</p><h1 id="b6ad" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">脸书度量数据集</h1><p id="fac2" class="pw-post-body-paragraph kf kg iq kh b ki mb kk kl km mc ko kp kq md ks kt ku me kw kx ky mf la lb lc ij bi translated">为了说明 gplearn 在实践中是如何工作的，让我们从 UCI 机器学习库中取一个名为脸书度量的玩具数据集(<a class="ae my" href="http://archive.ics.uci.edu/ml/datasets/Facebook+metrics" rel="noopener ugc nofollow" target="_blank">链接</a>)。它是根据一个未公开的化妆品品牌脸书·佩奇设计的。参见下面感兴趣的属性。</p><figure class="mh mi mj mk gt jr"><div class="bz fp l di"><div class="mz na l"/></div></figure><p id="0cf4" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">目标<code class="fe mu mv mw mx b">Total Interactions</code>是一个帖子发布后获得的所有赞、分享和评论的总和。我们应用一些预处理，然后训练符号回归器。为了简单起见，只启用默认的二元运算:<code class="fe mu mv mw mx b">add</code>、<code class="fe mu mv mw mx b">sub</code>、<code class="fe mu mv mw mx b">mul</code>、<code class="fe mu mv mw mx b">div</code>。20 代之后最合适的解决方案如下。</p><blockquote class="nb nc nd"><p id="1bb0" class="kf kg mn kh b ki kj kk kl km kn ko kp ne kr ks kt nf kv kw kx ng kz la lb lc ij bi translated"><em class="iq">add(add(mul(Post Hour，Post Month)，sub(payed _ 1.0，Category_3))，add(add(mul(Post Hour，Post Weekday)，div(mul(Post Hour，Post Month)，sub(Category_3，Category_1))，mul(add(Post Weekday，Category_1)，add(Type_Photo，Post Month)))，add(sub(payed _ 1.0，Category_3)，sub(Type_Status，payed _ 1.0)))</em></p></blockquote><p id="7e42" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">显然，这种文本格式对于可视化来说不是最佳的。请参见下面的树形图。</p><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mo"><img src="../Images/61ab364bf4113fb771d4ddbc124953ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ohjCIimkpngA4spp.png"/></div></div></figure><p id="1efd" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">嗯，这到底是什么意思？我如何最大化互动？嗯，这并不重要。符号回归的输出很难理解但是加油，真的很酷！</p><p id="c90a" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated">如果你想看实施细节和与标准回归的比较，请随意查看笔记本<a class="ae my" href="https://github.com/jankrepl/symbolic-regression-genetic-programming/blob/master/main.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h1 id="6436" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">附言（同 postscript）；警官（police sergeant）</h1><p id="f648" class="pw-post-body-paragraph kf kg iq kh b ki mb kk kl km mc ko kp kq md ks kt ku me kw kx ky mf la lb lc ij bi translated">我第一次接触符号回归是在 Kaggle ( <a class="ae my" href="https://www.kaggle.com/scirpus/genetic-programming-lb-0-0643904" rel="noopener ugc nofollow" target="_blank"> example_1 </a>和<a class="ae my" href="https://www.kaggle.com/scirpus/genetic-programming-lb-0-88" rel="noopener ugc nofollow" target="_blank"> example_2 </a>)上浏览公共内核的时候。期待一些精心制作的代码片段，当我看到这些可怕的公式设法在官方排行榜上获得非常体面的分数时，我忍不住笑了。</p></div><div class="ab cl jy jz hu ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="ij ik il im in"><h1 id="bfec" class="ld le iq bd lf lg mp li lj lk mq lm ln lo mr lq lr ls ms lu lv lw mt ly lz ma bi translated">参考</h1><ol class=""><li id="adab" class="nh ni iq kh b ki mb km mc kq nj ku nk ky nl lc nm nn no np bi translated">约翰·科扎，《基因编程是通过自然选择为计算机编程的一种方式》统计与计算 4，第 2 期(1994):87–112</li><li id="4610" class="nh ni iq kh b ki nq km nr kq ns ku nt ky nu lc nm nn no np bi translated">(莫罗等人，2016 年)莫罗，s .，丽塔，p .，&amp;瓦拉，B. (2016 年)。预测社交媒体性能指标和评估对品牌建设的影响:一种数据挖掘方法。商业研究杂志，69(9)，3341–3351。</li><li id="f6dc" class="nh ni iq kh b ki nq km nr kq ns ku nt ky nu lc nm nn no np bi translated"><a class="ae my" href="http://gplearn.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> gplearn 文档</a></li></ol><p id="4426" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated"><strong class="kh ir">更新:</strong>2018 年 7 月 2 日</p></div><div class="ab cl jy jz hu ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="ij ik il im in"><p id="3a8a" class="pw-post-body-paragraph kf kg iq kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ij bi translated"><em class="mn">原载于 2018 年 7 月 2 日</em><a class="ae my" href="https://jankrepl.github.io/symbolic-regression/" rel="noopener ugc nofollow" target="_blank"><em class="mn">jank repl . github . io</em></a><em class="mn">。</em></p></div></div>    
</body>
</html>