<html>
<head>
<title>Preprocessing with sklearn: a complete and comprehensive guide</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 sklearn 进行预处理:完整而全面的指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/preprocessing-with-sklearn-a-complete-and-comprehensive-guide-670cb98fcfb9?source=collection_archive---------0-----------------------#2018-12-13">https://towardsdatascience.com/preprocessing-with-sklearn-a-complete-and-comprehensive-guide-670cb98fcfb9?source=collection_archive---------0-----------------------#2018-12-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="8b38" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于有抱负的数据科学家来说，有时可能很难在预处理技术的森林中找到出路。<em class="kl"> Sklearn </em>它的<strong class="jp ir">预处理库</strong>形成了一个坚实的基础，指导您完成数据科学管道中的这项重要任务。虽然 Sklearn 有相当可靠的文档，但它经常忽略不同概念之间的流线和直觉。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/d8fb64f959933d47edd8da920c9ac275.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*j9TC7PTOq1YaQ5se.png"/></div></div></figure><p id="3153" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本文旨在成为一个关于使用<strong class="jp ir"> sklearn v0.20.0 </strong>进行预处理的完整指南。它包含了 sklearn 中可用的<em class="kl">所有</em>实用函数和 transformer 类，并补充了其他常用库中的一些有用函数。最重要的是，文章是按照一个逻辑顺序<strong class="jp ir">来组织的，这个逻辑顺序</strong>代表了执行所讨论的转换的顺序。</p><p id="3b7b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将处理以下主题:</p><ul class=""><li id="ae77" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk ld le lf lg bi translated">缺少值</li><li id="ba96" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">多项式特征</li><li id="7fc2" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">分类特征</li><li id="1af4" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">数字特征</li><li id="9e9d" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">自定义转换</li><li id="6443" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">特征缩放</li><li id="5cbe" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">正常化</li></ul><p id="e112" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意，第三步和第四步可以互换执行，因为这些转换应该彼此独立地执行。</p><h1 id="f3b1" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">缺少值</h1><p id="2c2a" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">处理缺失值是一项重要的预处理任务，如果处理不当，可能会严重影响模型的质量。在处理缺失值时，应该提出几个问题:</p><blockquote class="mp mq mr"><p id="7996" class="jn jo kl jp b jq jr js jt ju jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj kk ij bi translated">我是否有缺失的值？它们在数据中是如何表达的？我应该扣留缺失值的样本吗？或者我应该换掉它们？如果是，应该用哪些值替换？</p></blockquote><p id="17e5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在开始处理缺失值之前，重要的是<strong class="jp ir">识别缺失值</strong>并知道它们被哪个值替代。通过将元数据信息与探索性分析相结合，您应该能够发现这一点。</p><p id="e81f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦您对丢失的数据有了更多的了解，您就必须决定是否要保留带有丢失数据的条目。根据 Chris Albon ( <em class="kl">机器学习与 Python 食谱</em>)的说法，这个决定应该部分取决于<strong class="jp ir">随机缺失值的程度</strong>。</p><p id="f2fd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果它们是完全随机的，它们不会给出任何额外的信息，可以省略。另一方面，如果它们不是随机的，值丢失的事实本身就是信息，可以表示为额外的二进制特征。</p><p id="27da" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">还要记住，因为缺少一个值而删除整个观察可能是一个糟糕的决定，会导致信息丢失。就像保留一整行缺失值，因为它有一个有意义的缺失值，这可能不是您的最佳选择。</p><p id="df15" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们使用 sklearn 的<em class="kl"> MissingIndicator </em>通过一些编码示例来实现这个理论。为了给我们的代码赋予一些意义，我们将创建一个非常小的数据集，包含三个特性和五个样本。数据包含明显的缺失值，表示为<em class="kl">非数字</em>或<em class="kl"> 999 </em>。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="46c6" class="na ln iq mw b gy nb nc l nd ne">import numpy as np<br/>import pandas as pd</span><span id="d74c" class="na ln iq mw b gy nf nc l nd ne">X = pd.DataFrame(<br/>    np.array([5,7,8, np.NaN, np.NaN, np.NaN, -5,<br/>              0,25,999,1,-1, np.NaN, 0, np.NaN])\<br/>              .reshape((5,3)))</span><span id="fd87" class="na ln iq mw b gy nf nc l nd ne">X.columns = ['f1', 'f2', 'f3'] #feature 1, feature 2, feature 3</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/003d5a13b4cc35d174a994db612d70bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:408/format:webp/1*GOuqmvEWiJqvrRwWUNjgCQ.png"/></div><figcaption class="nh ni gj gh gi nj nk bd b be z dk">Data set with three features and five samples</figcaption></figure><p id="11d8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">快速浏览一下数据，这样您就知道丢失的值在哪里。使用 pandas 的<em class="kl"> dropna </em>函数，可以从数据中删除包含大量无意义缺失值的行或列。让我们来看看最重要的参数:</p><ul class=""><li id="827e" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk ld le lf lg bi translated"><em class="kl">轴</em> : 0 为行，1 为列</li><li id="88f6" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated"><em class="kl"> tresh </em>:非 NaN 的不删除一行或一列的数目</li><li id="0916" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">就地:更新框架</li></ul><p id="37d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们通过删除所有只有<em class="kl">和</em>缺少值的行(<em class="kl">轴</em> =0)来更新数据集。注意，在这种情况下，除了将<em class="kl"> tresh </em>设置为 1，您还可以将<em class="kl"> how </em>参数设置为<em class="kl">‘all’</em>。结果，我们的第二个样本被丢弃，因为它只包含丢失的值。请注意，为了方便起见，我们重置了索引并删除了旧的索引列。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="df46" class="na ln iq mw b gy nb nc l nd ne">X.dropna(axis=0, thresh=1, inplace=True)</span><span id="483b" class="na ln iq mw b gy nf nc l nd ne">X.reset_index(inplace=True)</span><span id="ba9b" class="na ln iq mw b gy nf nc l nd ne">X.drop(['index'], axis=1, inplace=True)</span></pre><p id="343b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们创建一些额外的布尔特征，告诉我们样本是否缺少某个特征的值。首先从<em class="kl"> sklearn.impute </em>导入<em class="kl"> MissingIndicator </em>(注意需要<strong class="jp ir">版本 0.20.0 </strong>)(用'<em class="kl">conda update sci kit-learn</em>'更新)。</p><p id="7958" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不幸的是，<em class="kl">缺失指示器</em>不支持多种类型的缺失值(<a class="ae nl" href="https://stackoverflow.com/questions/53002403/sklearn-impute-missingindicator-valueerror-input-contains-nan-infinity-or-a-va" rel="noopener ugc nofollow" target="_blank">参见 Stackoverflow </a>上的这个问题)。因此，我们必须将数据帧中的<em class="kl"> 999 </em>值转换为<em class="kl"> NaN </em>值。接下来，我们创建、拟合并转换一个 MissingIndicator 对象，该对象将检测数据中的所有<em class="kl"> NaN 的</em>。</p><p id="e420" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从这个指示符，我们可以创建一个新的数据帧，用布尔值表示一个实例是否缺少某个特性的值。但是为什么我们只有两个新专栏，而我们有三个原始功能？删除第二个样本后，<em class="kl"> f2 </em>不再有缺失值。如果<em class="kl">缺失指示器</em>没有检测到特征中的任何缺失值，它不会从该特征创建一个新特征。</p><p id="18e1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们稍后会将这个新特性添加到我们的原始数据中，现在我们可以将它们存储在<em class="kl">指示器</em>变量中。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="12f2" class="na ln iq mw b gy nb nc l nd ne">from sklearn.impute import MissingIndicator</span><span id="eee6" class="na ln iq mw b gy nf nc l nd ne">X.replace({999.0 : np.NaN}, inplace=True)</span><span id="fa09" class="na ln iq mw b gy nf nc l nd ne">indicator = MissingIndicator(missing_values=np.NaN)</span><span id="92e4" class="na ln iq mw b gy nf nc l nd ne">indicator = indicator.fit_transform(X)</span><span id="9fae" class="na ln iq mw b gy nf nc l nd ne">indicator = pd.DataFrame(indicator, columns=['m1', 'm3'])</span></pre><p id="cd1b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在决定保留(一些)缺失值并创建缺失值指示器后，下一个问题是是否应该替换缺失值。当缺失值被表示为<em class="kl">而不是数字</em> ( <em class="kl"> np)时，大多数学习算法表现不佳。NaN </em>)并且需要某种形式的缺失值插补。要知道有些库和算法，比如<em class="kl"> XGBoost </em>、<em class="kl">可以</em>处理缺失值，通过学习自动估算这些值。</p><h2 id="5c58" class="na ln iq bd lo nm nn dn ls no np dp lw jy nq nr ma kc ns nt me kg nu nv mi nw bi translated">输入值</h2><p id="adba" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">为了用通用策略填充缺失值，sklearn 提供了一个<em class="kl">简单估算器</em>。四个主要策略是<em class="kl">均值</em>、<em class="kl">最频繁</em>、<em class="kl">中值</em>和<em class="kl">常量</em>(不要忘记设置<em class="kl">填充值</em>参数<strong class="jp ir"> ) </strong>。在下面的例子中，我们用特征的平均值估算数据框架 X 的缺失值。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="8a69" class="na ln iq mw b gy nb nc l nd ne">from sklearn.impute import SimpleImputer</span><span id="a671" class="na ln iq mw b gy nf nc l nd ne">imp = SimpleImputer(missing_values=np.nan, strategy='mean')</span><span id="6f17" class="na ln iq mw b gy nf nc l nd ne">imp.fit_transform(X)</span></pre><p id="d1b7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意，返回的值被放入一个<em class="kl"> Numpy </em>数组，我们丢失了所有的元信息。由于所有这些策略都可以在<em class="kl"> pandas </em>中模仿，我们将使用 pandas <em class="kl"> fillna </em>方法来估算缺失值。对于表示的‘T28’，我们可以使用下面的代码。这个<em class="kl"> pandas </em>实现还提供了向前填充(<em class="kl"> ffill </em>)或向后填充(<em class="kl">bfil</em>)的选项，这在处理时间序列时非常方便。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="ac69" class="na ln iq mw b gy nb nc l nd ne">X.fillna(X.mean(), inplace=True)</span></pre><p id="b1ae" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其他常用的估算缺失数据的方法是<strong class="jp ir">用 k 近邻</strong> (KNN) <strong class="jp ir">算法</strong>对数据进行聚类，或者<strong class="jp ir">使用各种插值方法对值进行插值</strong>。这两种技术都没有在<em class="kl"> sklearn </em>的预处理库中实现，这里就不讨论了。</p><h1 id="01d2" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">多项式特征</h1><p id="d9cb" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">创建多项式要素是一种简单而常用的要素工程方法，它通过组合要素来增加数字输入数据的复杂性。</p><p id="b6b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我们想要包含特征和目标之间存在非线性关系的概念时，通常会创建多项式特征<strong class="jp ir">。它们主要用于增加几乎没有特征的线性模型的复杂性，或者当我们怀疑一个特征的效果依赖于另一个特征时。</strong></p><p id="b7ab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在处理缺失值之前，您需要决定是否要使用多项式要素。例如，如果您将所有缺少的值替换为 0，则使用此功能的所有叉积都将为 0。此外，如果不替换丢失的值(<em class="kl"> NaN </em>)，创建多项式特征将在<em class="kl"> fit_transform </em>阶段产生值错误，因为输入应该是有限的。</p><p id="be26" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这方面，用中值或平均值代替缺失值似乎是一个合理的选择。由于我对此并不完全确定，也找不到任何一致的信息，<a class="ae nl" href="https://datascience.stackexchange.com/questions/40003/handling-missing-values-to-optimize-polynomial-features" rel="noopener ugc nofollow" target="_blank">我在数据科学 StackExchange </a>上问了这个问题。</p><p id="180b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl"> Sklearn </em>提供了一个<em class="kl">多项式特征</em>类来从头创建多项式特征。<em class="kl">次数</em>参数决定多项式的最大次数。例如，当<em class="kl">度</em>设置为 2 且 X=x1，x2 时，创建的特征将为 1，x1，x2，x1，x1x2 和 x2。<em class="kl"> interaction_only </em>参数让函数知道我们只需要交互特性，即 1、x1、x2 和 x1x2。</p><p id="71ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里，我们创建了三次多项式特征，也是唯一的交互特征。结果我们得到四个新特征:<em class="kl"> f1.f2 </em>、<em class="kl"> f1.f3 </em>、<em class="kl"> f2.f3 </em>和<em class="kl"> f1.f2.f3 </em>。请注意，我们的原始特征也包含在输出中，并且我们会切掉新特征，以便稍后添加到我们的数据中。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="9bd1" class="na ln iq mw b gy nb nc l nd ne">from sklearn.preprocessing import PolynomialFeatures</span><span id="35b3" class="na ln iq mw b gy nf nc l nd ne">poly = PolynomialFeatures(degree=3, interaction_only=True)</span><span id="8797" class="na ln iq mw b gy nf nc l nd ne">polynomials = pd.DataFrame(poly\<br/>                           .fit_transform(X), <br/>                           columns=['0','1','2','3', <br/>                                    'p1', 'p2', 'p3', 'p4'])\<br/>                                        [['p1', 'p2', 'p3', 'p4']]</span></pre><p id="c681" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如任何其他形式的特征工程一样，在进行任何特征缩放之前，创建多项式特征<em class="kl">是很重要的。</em></p><p id="cd8f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，让我们用 pandas <em class="kl"> concat </em>方法将新的缺失指标特征和多项式特征连接到我们的数据中。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="85e3" class="na ln iq mw b gy nb nc l nd ne">X = pd.concat([X, indicator, polynomials], axis=1)</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/fa99db0f6a335adf1c1a450c30260c9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*cYZP26jphBcq_mCFbaEvqg.png"/></div><figcaption class="nh ni gj gh gi nj nk bd b be z dk">Dataframe with original features (f), missing value indicators (m) and polynomial features (p)</figcaption></figure><h1 id="ce2e" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">分类特征</h1><p id="9898" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">分类数据的筛选是数据预处理过程中的另一个重要过程。不幸的是，<em class="kl"> sklearn 的</em>机器学习库不支持处理分类数据。即使对于基于树的模型，也有必要<strong class="jp ir">将分类特征转换成数字表示</strong>。</p><p id="4d53" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在开始转换数据之前，确定您正在处理的要素是否是有序的(相对于名义的)非常重要。<strong class="jp ir">有序特征</strong>最好描述为<strong class="jp ir">具有自然有序类别的特征，类别之间的距离未知</strong>。</p><p id="4bb1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦你知道你正在处理什么类型的分类数据，你就可以选择一个合适的转换工具。在 sklearn 中，将有一个用于序数数据的<em class="kl"> OrdinalEncoder </em>，以及一个用于名义数据的<em class="kl"> OneHotEncoder </em>。</p><p id="e4b1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们考虑一个简单的例子来演示这两个类是如何工作的。创建一个具有五个条目和三个特征的数据框架:<em class="kl">性别</em>、<em class="kl">血型</em>和<em class="kl">教育程度</em>。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="5f9e" class="na ln iq mw b gy nb nc l nd ne">X = pd.DataFrame(<br/>    np.array(['M', 'O-', 'medium',<br/>             'M', 'O-', 'high',<br/>              'F', 'O+', 'high',<br/>              'F', 'AB', 'low',<br/>              'F', 'B+', np.NaN])<br/>              .reshape((5,3)))</span><span id="e695" class="na ln iq mw b gy nf nc l nd ne">X.columns = ['sex', 'blood_type', 'edu_level']</span></pre><p id="43a1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">查看数据框架，您应该注意到教育水平是唯一的顺序特征(可以排序，类别之间的距离未知)。我们将从用<em class="kl"> OrdinalEncoder </em>类编码这个特性开始。导入该类并创建一个新实例。然后通过将该特征拟合并转换到编码器来更新教育水平特征。结果应该如下所示。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="6b84" class="na ln iq mw b gy nb nc l nd ne">from sklearn.preprocessing import OrdinalEncoder</span><span id="2a31" class="na ln iq mw b gy nf nc l nd ne">encoder = OrdinalEncoder()</span><span id="88f7" class="na ln iq mw b gy nf nc l nd ne">X.edu_level = encoder.fit_transform(X.edu_level.values.reshape(-1, 1))</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/ee87ed654e528c141c53111556f6a067.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*VJoERQks8uiJ6oJu4WzWfA.png"/></div></figure><p id="d15a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意这里我们有一个相当烦人的问题:<strong class="jp ir">我们丢失的值被编码成一个单独的类(3.0) </strong>。仔细阅读文档可以发现，这个问题还没有解决方案。一个好的迹象是，<em class="kl"> sklearn </em>开发者正在<a class="ae nl" href="https://github.com/scikit-learn/scikit-learn/issues/11996" rel="noopener ugc nofollow" target="_blank">讨论实现一个合适的解决方案</a>的可能性。</p><p id="bbc5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">另一个问题是<strong class="jp ir">我们的数据顺序没有得到尊重</strong>。幸运的是，这可以通过将特性的唯一值的有序列表传递给<em class="kl">类别</em>参数来解决。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="5779" class="na ln iq mw b gy nb nc l nd ne">encoder = OrdinalEncoder(categories=['low', 'medium', 'high'])</span></pre><p id="0ae2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要解决第一个问题，我们必须求助于熊猫。<em class="kl">因式分解</em>方法提供了一种替代方法，可以处理缺失值并尊重我们的值的顺序。第一步是将特征转换为有序熊猫<em class="kl">分类</em>。传递一个<em class="kl">类别列表</em>(包括缺失值的类别)并将<em class="kl">有序</em>参数设置为<em class="kl">真</em>。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="2e73" class="na ln iq mw b gy nb nc l nd ne">cat = pd.Categorical(X.edu_level, <br/>                     categories=['missing', 'low', <br/>                                 'medium', 'high'], <br/>                     ordered=True)</span></pre><p id="9fbd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">用<em class="kl">缺失</em>类别替换缺失值。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="c29c" class="na ln iq mw b gy nb nc l nd ne">cat.fillna('missing')</span></pre><p id="93c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，将分类参数设置为<em class="kl">真</em>的<em class="kl">分类</em>进行因式分解，并将输出分配给<em class="kl">教育水平</em>特征。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="2886" class="na ln iq mw b gy nb nc l nd ne">labels, unique = pd.factorize(cat, sort=True)</span><span id="2716" class="na ln iq mw b gy nf nc l nd ne">X.edu_level = labels</span></pre><p id="e588" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这一次的结果更令人满意，因为数据是数值型的，仍然是有序的，缺失值被替换为 0。请注意，用最小值替换缺失值可能并不总是最佳选择。其他选项是<strong class="jp ir">将其放在最常见的类别中，或者在特征分类时将其放在中间值的类别中</strong>。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/d725d288846f041686a7a584f4bb0b18.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*WDp0YxuRaZxWmQJHaxBLFQ.png"/></div></figure><p id="901d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在让我们转向另外两个，名义特征。请记住，我们不能用数字来代替这些特征，因为这意味着这些特征是有顺序的，这在性别或血型的情况下是不正确的。</p><p id="c850" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最流行的标称特征编码方式是<strong class="jp ir">一次热编码</strong>。本质上，<strong class="jp ir">具有<em class="kl"> n </em>个类别的每个分类特征被转换成<em class="kl"> n </em>个二元特征</strong>。</p><p id="cfd1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们看一下我们的例子，把事情弄清楚。首先导入<em class="kl"> OneHotEncoder </em>类，并创建一个新实例，将输出数据类型设置为 integer。这不会改变我们的数据将如何被解释，但会提高我们输出的可读性。</p><p id="62d5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，拟合并转换我们的两个名义范畴。这个转换的输出将是一个稀疏矩阵，这意味着我们必须将矩阵转换成一个数组(<em class="kl">)。toarray() </em>)才能将其倒入数据帧中。当初始化一个新的类实例时，可以通过将<em class="kl">稀疏</em>参数设置为<em class="kl">假</em>来省略这个步骤。分配列名，输出就可以添加到其他数据中了(<em class="kl"> edu_level </em>特性)。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="e388" class="na ln iq mw b gy nb nc l nd ne">from sklearn.preprocessing import OneHotEncoder</span><span id="44d9" class="na ln iq mw b gy nf nc l nd ne">onehot = OneHotEncoder(dtype=np.int, sparse=True)</span><span id="2bbf" class="na ln iq mw b gy nf nc l nd ne">nominals = pd.DataFrame(<br/>    onehot.fit_transform(X[['sex', 'blood_type']])\<br/>    .toarray(),<br/>    columns=['F', 'M', 'AB', 'B+','O+', 'O-'])</span><span id="f449" class="na ln iq mw b gy nf nc l nd ne">nominals['edu_level'] = X.edu_level<br/></span></pre><p id="f520" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将输出(<em class="kl">名词</em>)与我们的原始数据进行比较，以确保一切都以正确的方式进行。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi oa"><img src="../Images/78be165ca35edb44f5eb1c48974a7f68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*hcO6JMuC7N9pKc34ETqUFQ.png"/></div></div><figcaption class="nh ni gj gh gi nj nk bd b be z dk">Encoded data versus original data</figcaption></figure><p id="fb33" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为我们的数据中没有丢失值，所以说明如何用<em class="kl">onehotencode</em>处理丢失值是很重要的。丢失的值可以很容易地作为一个额外的特性来处理。注意，要做到这一点，您需要首先用一个任意值替换丢失的值(例如，<em class="kl">‘missing’</em>)如果您另一方面想忽略丢失的值并创建一个全为零的实例(<em class="kl"> False </em>)，您只需将<em class="kl"> OneHotEncoder </em>的<em class="kl">handle _ unknown</em>参数设置为<em class="kl"> ignore </em>。</p><h1 id="6d34" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">数字特征</h1><p id="9bc9" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">就像分类数据可以被编码一样，数字特征可以被“解码”成分类特征。最常见的两种方法是<strong class="jp ir">离散化</strong>和<strong class="jp ir">二值化</strong>。</p><h2 id="c902" class="na ln iq bd lo nm nn dn ls no np dp lw jy nq nr ma kc ns nt me kg nu nv mi nw bi translated">[数]离散化</h2><p id="4040" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">离散化，也称为量化或宁滨，<strong class="jp ir">将连续特征分成预先指定数量的类别</strong>(箱)，从而使数据离散。</p><p id="85e1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">离散化的主要目标之一是显著地<strong class="jp ir">减少连续属性</strong>的离散区间的数量。因此，为什么这种转换可以提高基于树的模型的性能。</p><p id="5a7a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Sklearn 提供了一个<em class="kl"> KBinsDiscretizer </em>类来处理这个问题。您唯一需要指定的是每个特征的面元数量(<em class="kl">n _ 面元</em>)以及如何对这些面元进行编码(<em class="kl">序数</em>、<em class="kl">一个热点</em>或<em class="kl">一个热点密集</em>)。可选的<em class="kl">策略</em>参数可以设置为三个值:</p><ul class=""><li id="bccf" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk ld le lf lg bi translated"><em class="kl">统一</em>，其中每个特征中的所有箱具有相同的宽度。</li><li id="90ff" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated"><em class="kl">分位数(</em>默认)，其中每个特征中的所有条柱具有相同的点数。</li><li id="d28e" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated"><em class="kl">k 均值</em>，其中每个箱中的所有值都具有相同的 1D k 均值聚类的最近中心。</li></ul><p id="6193" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">小心选择策略参数很重要。例如，使用统一策略对异常值非常敏感，会使您最终得到只有几个数据点的条柱，即异常值。</p><p id="68c3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们转向我们的例子来进行一些澄清。导入<em class="kl"> KBinsDiscretizer </em>类并创建一个新实例，该实例具有三个 bin、序号编码和统一策略(所有 bin 都具有相同的宽度)。然后，拟合并转换我们所有原始的、缺失的指标和多项式数据。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="21e7" class="na ln iq mw b gy nb nc l nd ne">from sklearn.preprocessing import KBinsDiscretizer</span><span id="231f" class="na ln iq mw b gy nf nc l nd ne">disc = KBinsDiscretizer(n_bins=3, encode='uniform', <br/>                        strategy='uniform')</span><span id="cac3" class="na ln iq mw b gy nf nc l nd ne">disc.fit_transform(X)</span></pre><p id="9662" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果输出对您没有意义，调用离散化器(<em class="kl">圆盘</em>)上的<em class="kl"> bin_edges_ </em>属性，看看这些面元是如何划分的。然后尝试另一种策略，并查看面元边缘如何相应地变化。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/cb238dc85fee0c32f47f1436d2cb8f03.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*JrwWnThL2rvpZjJPn1YTmA.png"/></div><figcaption class="nh ni gj gh gi nj nk bd b be z dk">Discretized output</figcaption></figure><h2 id="6ee5" class="na ln iq bd lo nm nn dn ls no np dp lw jy nq nr ma kc ns nt me kg nu nv mi nw bi translated">二值化</h2><p id="b362" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">特征二值化是<strong class="jp ir">对数字特征进行阈值处理以获得布尔值</strong>的过程。或者换句话说，基于阈值给每个样本分配一个布尔值(<em class="kl">真</em>或<em class="kl">假</em>)。注意，二进制化是二进制离散化的极端形式。</p><p id="bf47" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">总的来说，二值化作为一种<strong class="jp ir">特征工程技术是有用的，用于创建新的特征来表示有意义的东西</strong>。就像上面提到的<em class="kl">缺失指示器</em>用来标记有意义的缺失值。</p><p id="713c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">sklearn 中的<em class="kl">二进制化器</em>类以非常直观的方式实现二进制化。您需要指定的唯一参数是<em class="kl">阈值</em>和<em class="kl">复制</em>。所有低于或等于阈值的值被替换为 0，高于阈值的值被替换为 1。如果复印设置为<em class="kl">假</em>，则执行原位二值化，否则进行复印。</p><p id="12c0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">考虑我们示例中的<em class="kl">特征 3 </em> ( <em class="kl"> f3 </em>)，让我们创建一个额外的二元特征，对于正值使用<em class="kl">真</em>，对于负值使用<em class="kl">假</em>。导入<em class="kl">二进制化器</em>类，创建一个阈值设置为零的新实例，并复制到<em class="kl"> True </em>。然后，将二进制化器安装并转换到<em class="kl">特征 3。</em>输出是一个带有布尔值的新数组。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="57e3" class="na ln iq mw b gy nb nc l nd ne">from sklearn.preprocessing import Binarizer</span><span id="bd65" class="na ln iq mw b gy nf nc l nd ne">binarizer = Binarizer(threshold=0, copy=True)</span><span id="cb28" class="na ln iq mw b gy nf nc l nd ne">binarizer.fit_transform(X.f3.values.reshape(-1, 1))</span></pre><h1 id="cd00" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">定制变压器</h1><p id="c36a" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">如果您想将现有的函数转换成转换器，以帮助数据清理或处理，您可以使用<em class="kl"> FunctionTransformer </em>从任意函数实现转换器。如果你正在使用<em class="kl"> sklearn </em>中的<em class="kl">管道</em>，这个类可能会很有用，但是可以很容易地通过将 lambda 函数应用到你想要转换的特征来替换(如下所示)。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="12da" class="na ln iq mw b gy nb nc l nd ne">from sklearn.preprocessing import FunctionTransformer</span><span id="bca6" class="na ln iq mw b gy nf nc l nd ne">transformer = FunctionTransformer(np.log1p, validate=True)</span><span id="4cce" class="na ln iq mw b gy nf nc l nd ne">transformer.fit_transform(X.f2.values.reshape(-1, 1)) #same output</span><span id="f16a" class="na ln iq mw b gy nf nc l nd ne">X.f2.apply(lambda x : np.log1p(x)) #same output</span></pre><h1 id="adb3" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">特征缩放</h1><p id="10cb" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">预处理管道中的下一个逻辑步骤是缩放我们的特征。在应用任何缩放变换之前，将你的数据分成一个训练集和一个测试集是非常重要的。如果您之前就开始缩放，您的训练(和测试)数据可能会围绕一个平均值(见下文)进行缩放，而这个平均值实际上并不是训练或测试数据的平均值，从而忽略了您最初缩放的全部原因。</p><h2 id="8683" class="na ln iq bd lo nm nn dn ls no np dp lw jy nq nr ma kc ns nt me kg nu nv mi nw bi translated">标准化</h2><p id="19b1" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">标准化是一种转换，<strong class="jp ir">通过移除每个特征的平均值来集中数据，然后通过将(非恒定)特征除以它们的标准偏差来缩放数据</strong>。标准化数据后，平均值为零，标准偏差为一。</p><p id="2890" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">标准化可以极大地提高模型的性能。例如，学习算法的目标函数中使用的许多元素(如支持向量机的 RBF 核或线性模型的 l1 和 l2 正则化子)假设所有特征都以零为中心，并且具有相同顺序的方差。如果某个特征的方差比其他特征的方差大几个数量级，那么它可能会主导目标函数，使估计器无法像预期的那样正确地从其他特征中学习。</p><p id="b3c5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">根据你的需求和数据，sklearn 提供了一堆定标器:<em class="kl">标准定标器</em>、<em class="kl">最小最大定标器</em>、<em class="kl">最大最小定标器</em>和<em class="kl">鲁棒定标器</em>。</p><h2 id="067a" class="na ln iq bd lo nm nn dn ls no np dp lw jy nq nr ma kc ns nt me kg nu nv mi nw bi translated">标准缩放器</h2><p id="4ba5" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated"><em class="kl"> Sklearn </em>它的主定标器<em class="kl"> StandardScaler </em>使用一个严格的标准化定义来标准化数据。它<strong class="jp ir">通过使用以下公式纯粹地将数据</strong>居中，其中<em class="kl"> u </em>是平均值，<em class="kl"> s </em>是标准偏差。</p><blockquote class="oc"><p id="c5a5" class="od oe iq bd of og oh oi oj ok ol kk dk translated">x _ scaled =(x-u)/s</p></blockquote><p id="2150" class="pw-post-body-paragraph jn jo iq jp b jq om js jt ju on jw jx jy oo ka kb kc op ke kf kg oq ki kj kk ij bi translated">让我们看看我们的例子，看看这在实践中。在我们开始编码之前，我们应该记住我们的第四个实例的值是缺失的，我们用平均值代替了它。如果我们在上面的公式中输入平均值，标准化后的结果应该为零。我们来测试一下。</p><p id="fdd2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">导入<em class="kl"> StandardScaler </em>类并创建一个新实例。请注意，对于稀疏矩阵，您可以将<em class="kl"> with_mean </em>参数设置为<em class="kl"> False </em>以避免数值集中在零附近。然后，将定标器安装并转换至<em class="kl">特征 3 </em>。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="a79f" class="na ln iq mw b gy nb nc l nd ne">from sklearn.preprocessing import StandardScaler</span><span id="bf0c" class="na ln iq mw b gy nf nc l nd ne">scaler = StandardScaler()</span><span id="923d" class="na ln iq mw b gy nf nc l nd ne">scaler.fit_transform(X.f3.values.reshape(-1, 1))</span></pre><p id="e61b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不出所料，第四个实例的值为零。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi or"><img src="../Images/d16d877c3529d4034c168b821e11f173.png" data-original-src="https://miro.medium.com/v2/resize:fit:426/format:webp/1*yFmtjB-kY8bjJQSCJDJyQA.png"/></div><figcaption class="nh ni gj gh gi nj nk bd b be z dk">Ouput of standard scaling feature 3</figcaption></figure><h2 id="58ff" class="na ln iq bd lo nm nn dn ls no np dp lw jy nq nr ma kc ns nt me kg nu nv mi nw bi translated">最小最大缩放器</h2><p id="a03a" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated"><em class="kl">最小最大缩放器</em>通过<strong class="jp ir">将每个特征缩放到给定范围</strong>来变换特征。该范围可以通过指定<em class="kl">特征范围</em>参数来设置(默认为<em class="kl"> (0，1) </em>)。此缩放器更适合非高斯分布或标准偏差非常小的情况。然而，它对异常值很敏感，所以如果数据中有异常值，你可能需要考虑另一个缩放器。</p><blockquote class="oc"><p id="8853" class="od oe iq bd of og oh oi oj ok ol kk dk translated">x _ scaled =(x-min(x))/(max(x)-min(x))</p></blockquote><p id="669d" class="pw-post-body-paragraph jn jo iq jp b jq om js jt ju on jw jx jy oo ka kb kc op ke kf kg oq ki kj kk ij bi translated">导入和使用<em class="kl">最小最大缩放器</em>的工作方式与<em class="kl">标准缩放器</em>完全相同——就像下面所有的缩放器一样。唯一的区别在于启动新实例时的参数。</p><p id="e327" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里我们将<em class="kl">特征 3 </em> ( <em class="kl"> f3 </em>)缩放到-3 和 3 之间的比例。正如所料，我们的最大值(<em class="kl"> 25 </em>)被转换为 3，最小值(- <em class="kl"> 1 </em>)被转换为-3。所有其他值在这些值之间线性缩放。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="ff41" class="na ln iq mw b gy nb nc l nd ne">from sklearn.preprocessing import MinMaxScaler</span><span id="967e" class="na ln iq mw b gy nf nc l nd ne">scaler = MinMaxScaler(feature_range=(-3,3))</span><span id="f2c6" class="na ln iq mw b gy nf nc l nd ne">scaler.fit_transform(X.f3.values.reshape(-1, 1))</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi os"><img src="../Images/3b9eb4ad25a74f7d2f5c2af246558686.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/1*f79W5Qa_xbmkJ9DjuN95OQ.png"/></div><figcaption class="nh ni gj gh gi nj nk bd b be z dk">Feature 3 before and after applying the MinMaxScaler</figcaption></figure><h2 id="ce10" class="na ln iq bd lo nm nn dn ls no np dp lw jy nq nr ma kc ns nt me kg nu nv mi nw bi translated">MaxAbs 定标器</h2><p id="738f" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated"><em class="kl">maxabscaler</em>的工作方式与<em class="kl"> MinMaxScaler </em>非常相似，但会根据<strong class="jp ir">绝对最大值</strong>自动将数据缩放至<em class="kl"> [-1，1] </em>范围。该缩放器用于已经以零为中心的<strong class="jp ir">数据或稀疏数据</strong>。它不会移动/居中数据，因此不会破坏任何稀疏性。</p><blockquote class="oc"><p id="04fd" class="od oe iq bd of og oh oi oj ok ol kk dk translated">x_scaled = x / max(abs(x))</p></blockquote><p id="820f" class="pw-post-body-paragraph jn jo iq jp b jq om js jt ju on jw jx jy oo ka kb kc op ke kf kg oq ki kj kk ij bi translated">让我们再次使用<em class="kl">maxabscaler</em>对<em class="kl">特性 3 </em>进行转换，并将输出与原始数据进行比较。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="386d" class="na ln iq mw b gy nb nc l nd ne">from sklearn.preprocessing import MaxAbsScaler</span><span id="cd38" class="na ln iq mw b gy nf nc l nd ne">scaler = MaxAbsScaler()</span><span id="8d20" class="na ln iq mw b gy nf nc l nd ne">scaler.fit_transform(X.f3.values.reshape(-1, 1))</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/f3cf16f071e6f61f9206e6f961ce4a7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*Z6w7AIsC4qO6o2B3ncKPfg.png"/></div><figcaption class="nh ni gj gh gi nj nk bd b be z dk">Feature 3 before and after applying the MaxAbsScaler</figcaption></figure><h2 id="ea53" class="na ln iq bd lo nm nn dn ls no np dp lw jy nq nr ma kc ns nt me kg nu nv mi nw bi translated">鲁棒定标器</h2><p id="e7d4" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">如果您的数据包含许多异常值<strong class="jp ir"/>，使用数据的平均值和标准偏差进行缩放可能不会很好。在这些情况下，您可以使用<em class="kl">鲁棒定标器</em>。<strong class="jp ir">移除中间值，并根据分位数范围</strong>缩放数据。文档中没有规定<em class="kl">鲁棒定标器</em>的确切公式。如果你想要完整的细节，你可以随时查看源代码。</p><p id="20dd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">默认情况下，缩放器使用四分位数范围(IQR)，即第一个四分位数和第三个四分位数之间的范围。当启动<em class="kl">鲁棒定标器</em>的新实例时，可以通过指定<em class="kl"> quantile_range </em>参数来手动设置分位数范围。这里，我们使用从<em class="kl"> 10% </em>到<em class="kl"> 90% </em>的分位数范围来变换<em class="kl">特征 3 </em>。</p><pre class="kn ko kp kq gt mv mw mx my aw mz bi"><span id="7d41" class="na ln iq mw b gy nb nc l nd ne">from sklearn.preprocessing import RobustScaler</span><span id="72b6" class="na ln iq mw b gy nf nc l nd ne">robust = RobustScaler(quantile_range = (0.1,0.9))</span><span id="c3bc" class="na ln iq mw b gy nf nc l nd ne">robust.fit_transform(X.f3.values.reshape(-1, 1))</span></pre><h1 id="11bb" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">正常化</h1><p id="486d" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">归一化是指<strong class="jp ir">将单个样本缩放至单位范数</strong>的过程。基本上，当算法根据数据点之间形成的加权关系进行预测时，您需要对数据进行规范化。将输入缩放到单位规范是<strong class="jp ir">文本分类或聚类</strong>的常见操作。</p><blockquote class="mp mq mr"><p id="22df" class="jn jo kl jp b jq jr js jt ju jv jw jx ms jz ka kb mt kd ke kf mu kh ki kj kk ij bi translated">缩放(例如标准化)和规格化之间的一个关键区别是规格化是一个<strong class="jp ir">行操作</strong>，而缩放是一个列操作。</p></blockquote><p id="10c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">虽然有许多其他方法来归一化数据，但是<em class="kl"> sklearn </em>提供了三个范数(与单个值进行比较的值):<em class="kl"> l1 </em>、<em class="kl"> l2 </em>和<em class="kl"> max </em>。创建<em class="kl">规格化器</em>类的新实例时，可以在<em class="kl">规格化</em>参数下指定所需的规格化。</p><p id="9599" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面，可用范数的公式将在 Python 代码中讨论和实现——结果是数据集<em class="kl"> X </em>中每个样本的分母列表。</p><h2 id="eaa8" class="na ln iq bd lo nm nn dn ls no np dp lw jy nq nr ma kc ns nt me kg nu nv mi nw bi translated">马克斯</h2><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/83d4e487ac26bc422a87f868d4ea6b65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*9P0yLssAfA7u363Uwf87mg.png"/></div></figure><p id="31e8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">最大值</em>范数使用绝对最大值，对样本的作用与<em class="kl">最大值缩放器</em>对特征的作用相同。</p><blockquote class="oc"><p id="d2db" class="od oe iq bd of og oh oi oj ok ol kk dk translated">x_normalized = x / max(x)</p></blockquote><pre class="ov ow ox oy oz mv mw mx my aw mz bi"><span id="ad0b" class="na ln iq mw b gy nb nc l nd ne">norm_max = <br/>list(<strong class="mw ir">max</strong>(list(abs(i) for i in X.iloc[r])) for r in range(len(X)))</span></pre><h2 id="62a2" class="na ln iq bd lo nm nn dn ls no np dp lw jy nq nr ma kc ns nt me kg nu nv mi nw bi translated">l1 '</h2><p id="9a22" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated"><em class="kl"> l1 </em>范数使用<strong class="jp ir">所有值的总和</strong>作为，因此给予所有参数相等的惩罚，加强稀疏性。</p><blockquote class="oc"><p id="e75e" class="od oe iq bd of og oh oi oj ok ol kk dk translated">X _ 规格化= x / sum(X)</p></blockquote><pre class="ov ow ox oy oz mv mw mx my aw mz bi"><span id="72fa" class="na ln iq mw b gy nb nc l nd ne">norm_l1 = <br/>list(<strong class="mw ir">sum</strong>(list(abs(i) for i in X.iloc[r])) for r in range(len(X)))</span></pre><h2 id="d794" class="na ln iq bd lo nm nn dn ls no np dp lw jy nq nr ma kc ns nt me kg nu nv mi nw bi translated">l2 '</h2><p id="6254" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">l2 范数使用所有平方值之和的平方根。这创建了平滑和旋转不变性。一些模型，如 PCA，假设旋转不变性，因此<em class="kl"> l2 </em>将执行得更好。</p><blockquote class="oc"><p id="2b1c" class="od oe iq bd of og oh oi oj ok ol kk dk translated">X _ normalized = X/sqrt(sum((I * * 2)for I in X))</p></blockquote><pre class="ov ow ox oy oz mv mw mx my aw mz bi"><span id="91de" class="na ln iq mw b gy nb nc l nd ne">norm_l2 = <br/>list(math.sqrt(sum(list((i**2) for i in X.iloc[r]))) <br/> for r in range(len(X)))</span></pre><p id="f79c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">——请随时在评论中或私信中告诉我任何不一致或错误。— </strong></p><h1 id="58ab" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">来源</h1><div class="pa pb gp gr pc pd"><a href="https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing" rel="noopener  ugc nofollow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ir gy z fp pi fr fs pj fu fw ip bi translated">4.3.预处理数据-sci kit-学习 0.20.1 文档</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">例如，学习算法的目标函数中使用的许多元素(如支持向量机的 RBF 核…</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">scikit-learn.org</p></div></div><div class="pm l"><div class="pn l po pp pq pm pr kw pd"/></div></div></a></div><div class="pa pb gp gr pc pd"><a href="https://swaathi.com/2017/04/29/normalizing-data/" rel="noopener  ugc nofollow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ir gy z fp pi fr fs pj fu fw ip bi translated">规范化数据-人工智能系列的第一部分</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">与 nave en(Skcript 的 AI Dev)合著。在机器学习中，更多的时候是不对数据应用算法…</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">swaathi.com</p></div></div><div class="pm l"><div class="ps l po pp pq pm pr kw pd"/></div></div></a></div><div class="pa pb gp gr pc pd"><a href="http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html" rel="noopener  ugc nofollow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ir gy z fp pi fr fs pj fu fw ip bi translated">人工智能神经网络常见问题，第 2 部分，共 7 部分:学习部分——我是否应该标准化/规范化/重新调整</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">人工智能神经网络常见问题，第 2 部分，共 7 部分:学习部分——我是否应该标准化/规范化/重新调整</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">人工智能神经网络常见问题，第 2 部分，共 7 部分:学习部分——我应该标准化/规范化/重标 thewww.faqs.org 吗</p></div></div><div class="pm l"><div class="pt l po pp pq pm pr kw pd"/></div></div></a></div><div class="pa pb gp gr pc pd"><a href="https://www.oreilly.com/library/view/machine-learning-with/9781491989371/ch04.html" rel="noopener  ugc nofollow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ir gy z fp pi fr fs pj fu fw ip bi translated">使用 Python 的机器学习食谱</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">量化数据是对某些东西的度量——无论是班级规模、月销售额还是学生成绩。自然的方式…</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">www.oreilly.com</p></div></div></div></a></div><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="pu pv l"/></div></figure><div class="pa pb gp gr pc pd"><a href="https://machinelearningmastery.com/prepare-data-machine-learning-python-scikit-learn/" rel="noopener  ugc nofollow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ir gy z fp pi fr fs pj fu fw ip bi translated">如何使用 Scikit-Learn 为 Python 中的机器学习准备数据</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">许多机器学习算法会对你的数据做出假设。在…中准备数据通常是一个非常好的主意</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">machinelearningmastery.com</p></div></div><div class="pm l"><div class="pw l po pp pq pm pr kw pd"/></div></div></a></div><div class="pa pb gp gr pc pd"><a href="https://medium.com/@rrfd/standardize-or-normalize-examples-in-python-e3f174b65dfc" rel="noopener follow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ir gy z fp pi fr fs pj fu fw ip bi translated">标准化还是常态化？Python 中的示例</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">一个常见的误解是，什么是标准化数据以及何时标准化数据与标准化日期之间的区别。</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">medium.com</p></div></div><div class="pm l"><div class="px l po pp pq pm pr kw pd"/></div></div></a></div><div class="pa pb gp gr pc pd"><a href="http://benalexkeen.com/feature-scaling-with-scikit-learn/" rel="noopener  ugc nofollow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ir gy z fp pi fr fs pj fu fw ip bi translated">使用 scikit-learn 扩展功能</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">在这篇文章中，我们探索了 scikit-learn 中实现的 3 种特征缩放方法:标准缩放器假设…</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">benalexkeen.com</p></div></div></div></a></div></div></div>    
</body>
</html>