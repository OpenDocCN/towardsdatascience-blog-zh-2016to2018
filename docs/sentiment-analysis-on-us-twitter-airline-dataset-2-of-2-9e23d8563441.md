# 美国 Twitter 航空数据集上的情感分析—第 2 页，共 2 页

> 原文：<https://towardsdatascience.com/sentiment-analysis-on-us-twitter-airline-dataset-2-of-2-9e23d8563441?source=collection_archive---------6----------------------->

在数据集上可以找到在[最后一篇文章](https://medium.com/towards-data-science/sentiment-analysis-on-us-twitter-airline-dataset-1-of-2-2417f204b971)中所做的分析结果。但是现在，我的目标是让这些统计数据在每条微博上更新，或者每小时更新一次。因此，首先，有必要训练一个分类器，能够将新推文分为正面和负面。

选择的分类器是朴素贝叶斯分类器。该分类器是最简单的监督机器学习方法之一，并且结果是可接受的。

用于训练分类器的步骤如下:

*   将 NLTK 与 punkt 一起使用
*   定义了一组无用词(用 nltk 停用词和字符串标点符号)来正确标记推文
*   将负面和正面的推文符号化，并定义特征
*   用训练集制作了朴素贝叶斯情感分类器
*   测试分类器并找到准确性

正如我在上一篇文章中所写的，NLTK 是一个非常强大的库，所以创建分类器很容易。转换成代码的步骤如下:

正如我们所见，分类器的准确率约为 86%，这个结果取决于用于训练的少量 tweets。我只用了 2000 条推文，因为这个数据集的正面推文只有大约 2400 条。负面推文的数量更高，但我不能使用所有这些推文。有必要用相同数量的正面和负面推文训练分类器，以避免引入偏差。

这项工作的最后一步是使用负面推文来训练一个分类器，以找出负面推文的原因。定义分类器的步骤与第一个分类器相同，但现在的子集只有负面推文。

在这项工作中，我试图只对负面推文的前两个原因进行分类，因为其他原因没有足够的数据。所有其他推文被归类为*其他*。

对于这个分类器，达到的准确率是 69%，不太好。但是使用的推文数量只有 1000 和 400 来验证分类器。

# 结论

准确度为 86%的第一分类器是可接受的，因为人类的准确度约为 80%。但是第二种的精度是不能接受的，因为太低了。

如果我们考虑组合准确度(负面和正面的分类，以及负面推文的原因分类)，它下降到 59%。

这些结果的主要原因是因为数据集几乎没有正面的推文，也没有针对每个负面原因的推文。不排除使用更复杂的分类器可以达到更好的结果。

*原载于 2017 年 10 月 3 日*[*【devklaus.wordpress.com】*](https://devklaus.wordpress.com/2017/10/03/sentiment-analysis-on-us-twitter-airline-dataset-2-of-2/)*。*