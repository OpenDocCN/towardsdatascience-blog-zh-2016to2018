<html>
<head>
<title>Processing XML with AWS Glue and Databricks Spark-XML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 AWS Glue 和 Databricks Spark-XML 处理 XML</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/use-aws-glue-and-or-databricks-spark-xml-to-process-xml-data-21eaef390fda?source=collection_archive---------2-----------------------#2018-12-25">https://towardsdatascience.com/use-aws-glue-and-or-databricks-spark-xml-to-process-xml-data-21eaef390fda?source=collection_archive---------2-----------------------#2018-12-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e1cc" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">快速介绍 Glue 和一些 XML 处理技巧，这从来都不容易</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/2da413030c02876d9a108db5901f80d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HaCDr-XQxGPN7g61AL3psg.jpeg"/></div></div></figure><p id="a4ef" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi ln translated">如果您对数据的质量和结构有严格的规定，使用非结构化数据有时会很麻烦，可能会包括对数据进行控制的<strong class="kt ir">庞大的</strong>任务。</p><p id="e5b6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在本文中，我将分享我使用 Glue transformations 和 Databricks Spark-xml 库处理 XML 文件的经验。</p></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><p id="ad55" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">AWS Glue 是 AWS 提供的 ETL 服务。它有三个主要组件，即数据目录、爬虫和 ETL 作业。因为爬虫帮助你提取你的数据的信息(模式和统计)，数据目录被用于集中的元数据管理。使用 ETL 作业，您可以使用 Glue proposed 脚本或带有附加库和 jar 的自定义脚本来处理存储在 AWS 数据存储上的数据。</p></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><p id="2956" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">XML…首先，您可以使用 Glue crawler 来探索数据模式。由于 xml 数据大多是多级嵌套的，所以爬行的元数据表将具有复杂的数据类型，如结构、结构数组……并且您将无法使用 Athena 查询 xml，因为它不受支持。所以有必要将 xml 转换成平面格式。要展平 xml，您可以选择一种简单的方法来使用 Glue 的魔法(！)，一个简单的技巧将其转换为 csv 格式，或者您可以使用 Glue transformations 来展平数据，稍后我将对此进行详细说明。</p><p id="c269" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">您需要小心展平，这可能会导致空值，即使数据在原始结构中是可用的。</p><p id="df34" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我将给出一个替代方法的例子，根据您的用例选择哪一个取决于您。</p><ul class=""><li id="fae9" class="md me iq kt b ku kv kx ky la mf le mg li mh lm mi mj mk ml bi translated">爬网 XML</li><li id="f351" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated">使用粘合作业转换为 CSV</li><li id="0831" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated">使用 Glue PySpark 转换来展平数据</li><li id="dd32" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated">另一种方法是:使用 Databricks Spark-xml</li></ul></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><p id="32b2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">数据集:【http://opensource.adobe.com/Spry/data/donuts.xml T4】</p><p id="067a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">代码片段:<a class="ae mr" href="https://github.com/elifinspace/GlueETL/tree/article-2" rel="noopener ugc nofollow" target="_blank">https://github.com/elifinspace/GlueETL/tree/article-2</a></p><p id="30ab" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">0.将数据集上传到 S3:</p><p id="068a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">从给定的链接下载文件，并转到 AWS 控制台上的 S3 服务。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/887a105a143976300aa094c9258b674e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cj6jnZFVnxH1GX3Ee_Z4TQ.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Create a bucket with “aws-glue-” prefix(I am leaving settings default for now)</figcaption></figure><p id="6bd7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">单击 bucket 名称，然后单击 Upload:(这是最简单的方法，您也可以设置 AWS CLI 以从本地机器与 AWS 服务交互，这需要更多的工作，包括安装 AWS CLI/配置等。)</p><p id="d9a2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">点击添加文件，选择你想上传的文件，然后点击上传。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/d190016b0681f240cd6af436be130746.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wPXlzOxmoR69zAdAHd6GVA.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">You can setup security/lifecycle configurations, if you click Next.</figcaption></figure><ol class=""><li id="47cd" class="md me iq kt b ku kv kx ky la mf le mg li mh lm my mj mk ml bi translated">爬网 XML 元数据</li></ol><p id="14e5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，如果您知道 xml 数据中的标记可以选择作为模式探索的基础级别，那么您可以在 Glue 中创建一个定制的分类器。如果没有自定义分类器，Glue 将从顶层推断模式。</p><p id="4682" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在上面的 xml 数据集示例中，我将选择“items”作为我的分类器，并像下面这样轻松地创建分类器:</p><p id="022b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">转到 Glue UI，单击数据目录部分下的分类器选项卡。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/c1a3b88ea3cea0fc37b5f6f5fc5f2f68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*52CIcWgboJN0xEianPBPyA.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">“item” will be the root level for the schema exploration</figcaption></figure><p id="3cbf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我用分类器创建了爬虫:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi na"><img src="../Images/f8c615bad95476b2d46685c97b94f335.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ulDL3QA1dWMN5925PjGh5A.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Give the crawler a name and Select the classifier from the list</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/605cbf8cbf67e1c6e0b2ec10bb560a5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1BmHcIMWc0R4bmqjf94oZA.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Leave everything as default for now , browse for the sample data location (‘Include path’)</figcaption></figure><p id="7179" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">添加另一个数据存储:否</p><p id="f36a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">您可以在 S3 存储桶上使用具有相关读/写权限的 IAM 角色，也可以创建一个新角色:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/d17db3abe4caf4ada5b248467378f8f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qj38BuPetMFimVvdo5jjTA.png"/></div></div></figure><p id="7bfb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">频率:按需运行</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/152f240b081eaebf7cc0a06848d3add5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Oy4wCkcsx4TCilXsFzwsOw.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Choose the default db(or you can create a new one) and leave settings as default</figcaption></figure><p id="200f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">查看并单击完成。</p><p id="35a8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在我们已经准备好运行爬虫了:选择爬虫并点击 Run Crawler，一旦状态为“ready ”,访问数据库部分并查看数据库中的表。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/61f3e5f78ae27b2d45ea2c7af23c45ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lEGZgtmRbbxrMqKycGHLmw.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">(Tables added :1 means that our metadata table is created )</figcaption></figure><p id="688e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">转到表并过滤您的数据库:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nf"><img src="../Images/ac7fee0f7c9c0a65b272b0b99fac6a8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P2ciCHnVt28V1mrqLVYgMw.png"/></div></div></figure><p id="6d5f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">单击表名，输出模式如下:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ng"><img src="../Images/b8e54b0c5855b9be8ce58b9afeef5e3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LfBl22JBOxXXohZ4EEw4Eg.png"/></div></div></figure><p id="1e99" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在我们有了模式的概念，但是我们有复杂的数据类型，需要将数据扁平化。</p><p id="5df3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">2.转换为 CSV:</p><p id="2a6c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这很简单，我们将使用 Glue 提供的脚本:</p><p id="3394" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">转到 ETL 菜单中的作业部分并添加作业:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/aab9c294d40faa114ec22d5fa5e3b6f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*31shEdvc4fCULe0Sj4i_gg.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Name the job and choose the IAM role we created earlier simply(make sure that this role has permissions to read/write from/to source and target locations)</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/957aea2ba022c38a0e9ce9ddf37bfb4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r6m49L3aHkCrZLogRdZCZA.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nj"><img src="../Images/464b277cf5eba72ddf22b7bd7a6984bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OtNtzIKxQyqi89wHmwwKQA.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Tick the option above,Choose the target data store as S3 ,format CSV and set target path</figcaption></figure><p id="080a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在是神奇的一步:(如果我们选择 parquet 作为格式，我们将自己进行展平，因为 Parquet 可以有复杂的类型，但对于 csv 来说，映射很容易显示。)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/151ace349af83a6576d44f90ee03280d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aWF0uYhpNuq9a361VNp2FA.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">You can rename, change the data types, remove and add columns in target. I want to point that the array fields mapped to string which is not desirable from my point of view.</figcaption></figure><p id="c068" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我把一切都保留为默认，审查，保存并继续编辑脚本。</p><p id="b17c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">粘附建议的脚本:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nl"><img src="../Images/a6c2230454cf367cafacc8d802ba03cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wZi_9SQzaGYGNegJq8q6eg.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">We can Run the job immediately or edit the script in any way.Since it is a python code fundamentally, you have the option to convert the dynamic frame into spark dataframe, apply udfs etc. and convert back to dynamic frame and save the output.(You can stick to Glue transforms, if you wish .They might be quite useful sometimes since the Glue Context provides extended Spark transformations.)</figcaption></figure><p id="6f3c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我在建议的脚本中添加了一些行来生成单个 csv 输出，否则输出将是基于分区的多个小 CSV 文件。</p><p id="41e9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">保存并单击“Run Job ”,这将带来一个配置检查，因此您可以将 DPU 设置为 2(最小的值)并按如下方式设置超时:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nm"><img src="../Images/30fb0de403bef3b31764e8472bc02527.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jqa9rP-4qbpvB-hJ9h2IjQ.png"/></div></div></figure><p id="2008" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们运行并查看输出。您可以监视 Glue UI 中的状态，如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nn"><img src="../Images/8caa00aeff9f4cb5d3c05b6ebf485ca6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yn9R3O7eQPTdyLDCfe-esQ.png"/></div></div></figure><p id="7042" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">运行状态成功后，转到您的目标 S3 位置:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/b302e5236e638262bf25812612d960c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3c0Ira5el6B2yCuf3G__yQ.png"/></div></div></figure><p id="f9cb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">单击文件名并转到如下所示的“选择自”选项卡:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/5b6cc86448bff0dcc831e807cf7d585e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i9-ucd-3nLZla707DpsiXg.png"/></div></div></figure><p id="e6c4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果向下滚动，可以通过单击显示文件预览/运行 SQL(Athena 在后台)轻松预览和查询小文件:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/e53e85870458168a927859de4e3066d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QXAnhL3_8SXiqSAGKmUtyw.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">The struct fields propagated but the array fields remained, to explode array type columns, we will use pyspark.sql explode in coming stages.</figcaption></figure><p id="0ee3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">3.粘合 PySpark 转换用于取消嵌套</p><p id="7f8c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Glue 提供了两种 pyspark 变换:</p><ul class=""><li id="9528" class="md me iq kt b ku kv kx ky la mf le mg li mh lm mi mj mk ml bi translated">Relationalize:取消嵌套列、透视数组列、为关系操作(连接等)生成连接键。)，生成帧列表</li><li id="6e7b" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated">UnnestFrame:取消框架嵌套，为数组类型的列生成 joinkey，生成一个包含所有字段(包括 join key 列)的框架。</li></ul><p id="8709" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们将使用 Glue DevEndpoint 来可视化这些转换:</p><p id="f456" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Glue DevEndpoint 是数据存储的连接点，用于调试脚本，使用 Glue Context 和 Sagemaker 或 Zeppelin 笔记本对数据进行探索性分析。</p><p id="bc76" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">此外，您还可以从 Cloud9 访问这个端点，cloud 9 是基于云的 IDE 环境，用于编写、运行和调试您的代码。您只需要在 Cloud9 实例上生成 ssh 密钥，并在创建端点时添加公共 SSH 密钥。要连接到端点，您将使用端点详细信息中的“SSH 到 Python REPL”命令(在 Glue UI 中单击端点名称)，用您在 Cloud9 实例上的位置替换私钥参数。</p><ul class=""><li id="8f6c" class="md me iq kt b ku kv kx ky la mf le mg li mh lm mi mj mk ml bi translated">创建一个 Glue DevEndpoint 和一个 Sagemaker 笔记本:</li></ul><p id="3dc2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我将把这个端点也用于 Databricks spark-xml 示例，所以从<a class="ae mr" href="https://mvnrepository.com/artifact/com.databricks/spark-xml_2.11/0.4.1" rel="noopener ugc nofollow" target="_blank">https://mvnrepository . com/artifact/com . data bricks/spark-XML _ 2.11/0 . 4 . 1</a>下载 jar 文件到您的 PC，上传 jar 到 S3 并相应地设置“依赖 jars 路径”:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/a0e5b592e64c7256dba0ae0999700cf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sAu2CwyLLww84nHl43KW1Q.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Name it and choose the IAM role we used before.If you have a codebase you want to use, you can add its path to Python library path.</figcaption></figure><p id="83d3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">您可以将所有其他配置保留为默认配置，然后单击 Finish。大约需要。端点准备就绪需要 6 分钟。</p><p id="42e2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一旦端点准备就绪，我们就可以创建一个笔记本来连接它。</p><p id="111b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">选择您的端点，然后从操作下拉列表中单击创建 Sagemaker 笔记本。笔记本创建完成后，需要几分钟时间准备就绪。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/2d4bdfc6a217935502d39d8c29372c7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l9S-Z7EHhYx3xYpjV21pxg.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Name it, leave default settings and name the new IAM role , click Create Notebook</figcaption></figure><p id="9982" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">打开笔记本并创建一个新的 Pyspark 笔记本:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/ae11251db48a19d64548da485c36af46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*desPr764aNqhvAayH5jcPw.png"/></div></div></figure><p id="26b6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">您可以从我们之前创建的 csv 作业中复制并粘贴样板文件，如下所示更改 glueContext 行，并注释掉与作业相关的库和代码片段:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/8794151ead5b3ede929e1ff737140d9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u2mquzQH8jyRBpvMLe15KQ.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">You can either create dynamic frame from catalog, or using “from options” with which you can point to a specific S3 location to read the data and, without creating a classifier as we did before ,you can just set format options to read the data.</figcaption></figure><p id="4912" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">你可以在<a class="ae mr" href="https://docs.aws.amazon.com/glue/latest/dg/aws-glue-programming-etl-format.html" rel="noopener ugc nofollow" target="_blank">https://docs . AWS . Amazon . com/glue/latest/DG/AWS-glue-programming-ETL-format . html</a>中找到更多关于格式选项的信息</p><ul class=""><li id="9d11" class="md me iq kt b ku kv kx ky la mf le mg li mh lm mi mj mk ml bi translated">关系化:</li></ul><p id="7fcb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我在以下步骤中使用了由 from options 创建的框架:(即使您使用了 catalog 选项，输出也是一样的，因为 catalog 不会为数据保存静态模式。)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nv"><img src="../Images/381a983d579ace398cbda0d7d766d83b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VNbOvN_ymfupiOoj-KQKFA.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">You can see that the transform returns a list of frames, each has an id and index col for join keys and array elements respectively.</figcaption></figure><p id="a9db" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果看根表会更清楚。例如，填充在根表的这个字段中只有一个整数值，这个值与上面的根 _ 填充 _ 填充帧中的 id 列相匹配。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nw"><img src="../Images/a0ccf95386e0ba0d87267ae7b9c1c697.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HiHBqA4ZB80JGJJB3NbfDQ.png"/></div></div></figure><p id="ecf0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">重要的是，我们看到“batters.batter”字段传播到多个列中。对于项目 2，“batters.batter”列被标识为 struct，但是对于项目 3，该字段是一个数组！。所以用胶水工作的难度就来了。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nx"><img src="../Images/04184d8c24fccca48516aee5eb64ee15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wUuGX3zeJRyxN4pMCw-mWA.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">If you have complicated multilevel nested complicated structure then this behavior might cause lack of maintenance and control over the outputs and problems such as data loss ,so alternative solutions should be considered.</figcaption></figure><ul class=""><li id="1f65" class="md me iq kt b ku kv kx ky la mf le mg li mh lm mi mj mk ml bi translated">Unnest 框架:</li></ul><p id="7340" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们看看这个转换将如何给我们一个不同的输出:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/85760266dae8c237442cba0271f9f799.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eXamSsDeN0knHOE47rusMA.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">We can see that this time everything is in one frame but again “batters.batter” resulted in multiple columns , this brings uncertainty around the number of columns also. Considering an ETL pipeline, each time a new file comes in, this structure will probably change.</figcaption></figure><p id="cf8c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">和 unnest 可以展开上层结构，但在展平结构数组方面无效。因此，由于我们不能在动态帧上应用 UDF，我们需要将动态帧转换为 Spark 数据帧，并在列上应用 explode，以将数组类型的列分散到多行中。我将把这部分留给你自己调查。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/a62ec2f936b81923a897f586a9f12c1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BHu3ye8ZZvpgP5H-OdgaUw.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Moreover I would expect to have not two different spread of “batters.batter” and imho there could be an “array of structs” type column for this field and the “item 2” would have an array of length 1 having its one struct data.</figcaption></figure><p id="4961" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后… Databricks spark-xml:</p><p id="d3c1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这可能不是最好的解决方案，但这个软件包在控制和精度方面非常有用。一个很好的特性是，不可解析的记录也会被检测到，并且一个 _corrupt_record 列会被添加相关信息。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/696e31b378dc23f26284e0d02800c838.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ID-9efD0oUvnP0QL8kZTzg.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Now here is the difference I expected :) . You can see that “batters.batter” is an array of structs. Moreover for more reading options, you can have a look at <a class="ae mr" href="https://github.com/databricks/spark-xml" rel="noopener ugc nofollow" target="_blank">https://github.com/databricks/spark-xml</a></figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/66b60d40b43d24f5e0691abee96ec223.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rVRsbePPCZXQ0XtH2LaOgQ.png"/></div></div><figcaption class="mt mu gj gh gi mv mw bd b be z dk">Batters : No nulls, no probs</figcaption></figure><p id="7e21" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，您不需要考虑是否存在结构或数组列，您可以通过使用提取的模式来编写一个用于展开数组列的通用函数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/05a8e50dfb793bd773319491fcb20c9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R279YsUwLWa8ixBp9OAWfA.png"/></div></div></figure><p id="7745" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">顺便提一下，我在 Glue 环境中使用了 Databricks 的 Spark-XML，但是您可以将它用作独立的 python 脚本，因为它独立于 Glue。</p><p id="fa1f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们看到，尽管 Glue 提供了一行转换来处理半/非结构化数据，但是如果我们有复杂的数据类型，我们需要处理样本，看看什么符合我们的目的。</p><p id="f1e9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">希望你喜欢它！</p></div></div>    
</body>
</html>