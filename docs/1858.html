<html>
<head>
<title>Implementing a Generative Adversarial Network (GAN/DCGAN) to Draw Human Faces</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实现生成性对抗网络(GAN/DCGAN)来绘制人脸</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-a-generative-adversarial-network-gan-dcgan-to-draw-human-faces-8291616904a?source=collection_archive---------0-----------------------#2017-11-04">https://towardsdatascience.com/implementing-a-generative-adversarial-network-gan-dcgan-to-draw-human-faces-8291616904a?source=collection_archive---------0-----------------------#2017-11-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="9f5d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在上一个教程中，我们学习了使用<a class="ae ko" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>来设计一个<a class="ae ko" href="https://medium.com/towards-data-science/teaching-a-variational-autoencoder-vae-to-draw-mnist-characters-978675c95776" rel="noopener">变分自动编码器</a> (VAE)，它可以绘制MNIST字符。大多数创建的数字看起来很好。只有一个缺点——一些创建的图像看起来有点模糊。用<em class="kp">均方误差</em>损失函数训练VAE。然而，很难对精确的字符边缘位置进行编码，这导致网络无法确定这些边缘。如果一个字符的边缘开始向左或向右多几个像素真的有关系吗？我不这么认为。</p><p id="8534" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在本文中，我们将了解如何训练一个不依赖于均方误差或任何相关损失函数的网络，而是让它自己学习真实图像的样子。我们将要了解的架构叫做<a class="ae ko" href="https://arxiv.org/pdf/1511.06434.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="js iu">深度卷积生成对抗网络(DCGAN) </strong> </a>。罗威尔·阿蒂恩萨在三月下旬写的一篇很棒的文章启发我完成了这个项目，他教我们如何在keras应用同样的技术。为了能够与上一个基于VAE的模型进行比较，我们将首先看看如何实现一个能够绘制<a class="ae ko" href="https://en.wikipedia.org/wiki/MNIST_database" rel="noopener ugc nofollow" target="_blank"> MNIST </a>角色的DCGAN。之后，我们将在一个更酷的项目中应用我们的知识——只需一些小的调整，我们的网络将学会如何绘制(半)逼真的人脸！</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ks"><img src="../Images/ed7f5a53f68be208f1cffa3f201f6853.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7qhYUn7XsEi5_wKLimoQtQ.png"/></div></div></figure><h1 id="6ace" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">深度卷积生成对抗网络</h1><p id="c48e" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">像VAE一样，DCGAN是一种学习生成新内容的架构。就像VAE一样，DCGAN由两部分组成。在这种情况下，它们是:</p><ul class=""><li id="8e4a" class="mh mi it js b jt ju jx jy kb mj kf mk kj ml kn mm mn mo mp bi translated"><em class="kp">鉴别器，</em>，<em class="kp"> </em>学习如何从我们想要创建的类型的真实对象中辨别出赝品</li><li id="d83d" class="mh mi it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated"><em class="kp">生成器，</em><em class="kp"/>创建新内容并试图欺骗鉴别器</li></ul><p id="eaea" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">基本思想是两个网络部分相互竞争。当鉴别器变得更好时，生成器也需要变得更好，否则它不能再欺骗鉴别器了。类似地，当发生器变得更好时，鉴别器也必须变得更好，否则它将失去区分真假内容的能力。</p><p id="db41" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你想对GANs有更多的直觉，这里有一篇<a class="ae ko" href="https://hackernoon.com/how-do-gans-intuitively-work-2dda07f247a1" rel="noopener ugc nofollow" target="_blank">的文章</a>，作者<a class="kq kr ep" href="https://medium.com/u/5b7a47762eb2?source=post_page-----8291616904a--------------------------------" rel="noopener" target="_blank">chan chana sornsountorn</a>，描述了一些应用了DCGANs的创意项目。其中一个项目是MNIST人物的生成，另一个是人脸的生成。在本文中，我们将了解如何在Python和Tensorflow中实现所描述的技术。我们将从MNIST的角色开始。如果你想看这个教程的全部代码，去我的github账号看看<a class="ae ko" href="https://github.com/FelixMohr/Deep-learning-with-Python/blob/master/DCGAN-MNIST.ipynb" rel="noopener ugc nofollow" target="_blank"> MNIST </a>和<a class="ae ko" href="https://github.com/FelixMohr/Deep-learning-with-Python/blob/master/DCGAN-face.ipynb" rel="noopener ugc nofollow" target="_blank">人脸生成</a>的代码。</p><div class="mv mw gp gr mx my"><a href="https://github.com/FelixMohr/Deep-learning-with-Python" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd iu gy z fp nd fr fs ne fu fw is bi translated">Felix mohr/使用Python进行深度学习</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">在GitHub上创建一个帐户，为深度学习Python开发做贡献。</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">github.com</p></div></div><div class="nh l"><div class="ni l nj nk nl nh nm lc my"/></div></div></a></div><h1 id="7528" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">设置基础</h1><p id="64ad" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">所以，让我们直接进入代码。</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="nn no l"/></div></figure><p id="3287" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">和上一篇教程一样，我们使用tensorflow自己的方法来访问批量的MNIST字符。我们将批量大小设置为64。我们的生成器将噪声作为输入。这些输入的数量被设置为100。批量标准化大大改善了这个网络的训练。对于tensorflow应用批处理规范化，我们需要让它知道我们是否处于训练模式。<code class="fe np nq nr ns b">keep_prob</code>变量将由我们的辍学层使用，我们引入辍学层是为了获得更稳定的学习结果。<code class="fe np nq nr ns b">lrelu</code>定义了流行的leaky ReLU，希望tensorflow的未来版本能够支持它！我首先尝试将标准ReLUs应用于这个网络，但这导致了众所周知的<a class="ae ko" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)#Potential_problems" rel="noopener ugc nofollow" target="_blank"> <em class="kp">死亡ReLU问题</em> </a>，并且我收到了看起来像Kazimir Malevich的艺术品的生成图像——我只是得到了<a class="ae ko" href="https://en.wikipedia.org/wiki/Black_Square_(painting)" rel="noopener ugc nofollow" target="_blank">黑色方块</a>。</p><p id="a33e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，我们定义一个函数<code class="fe np nq nr ns b">binary_crossentropy</code>，我们将在以后计算损失时使用它。</p><h1 id="792e" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">鉴别器</h1><p id="8cc2" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">现在，我们可以定义鉴别器。它看起来类似于我们的VAE的编码器部分。作为输入，它采用真实或虚假的MNIST数字(28 x 28像素灰度图像)并应用一系列卷积。最后，我们使用sigmoid来确保我们的输出可以被解释为输入图像是真实的MNIST字符的概率。</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="nn no l"/></div></figure><h1 id="c55b" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">发电机</h1><p id="2b69" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">发生器——就像我们的VAE中的解码器部分——接收噪音，并尝试学习如何将噪音转换为数字。为此，它应用了几个转置卷积。一开始我没有对生成器应用批量归一化，它的学习好像真的效率不高。应用批量标准化图层后，学习能力有了很大提高。此外，我首先有一个更大的密集层接受发电机的输入。这导致发生器总是产生相同的输出，不管输入噪声是什么，例如，它总是输出看起来完全相同的9(<a class="ae ko" href="http://aiden.nibali.org/blog/2017-01-18-mode-collapse-gans/" rel="noopener ugc nofollow" target="_blank">模式崩溃</a>)。另一方面，根本不使用密集层会导致生成器在多次迭代后没有学到任何有意义的东西。老实说，调整发电机需要相当大的努力！</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="nn no l"/></div></figure><h1 id="5e57" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">损失函数和优化器</h1><p id="3638" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">现在，我们将两部分连接在一起，就像我们在上一个教程中对VAE的编码器和解码器所做的那样。但是，我们必须创建两个鉴别器对象:</p><ul class=""><li id="e087" class="mh mi it js b jt ju jx jy kb mj kf mk kj ml kn mm mn mo mp bi translated">第一个对象接收实像</li><li id="784f" class="mh mi it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated">第二对象接收假图像</li></ul><p id="9cee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">第二个对象的<code class="fe np nq nr ns b">reuse</code>被设置为<code class="fe np nq nr ns b">True</code>，所以两个对象共享它们的变量。我们需要两种情况来计算两种类型的损失:</p><ul class=""><li id="ce9a" class="mh mi it js b jt ju jx jy kb mj kf mk kj ml kn mm mn mo mp bi translated">当接收真实图像时，鉴别器应该学会计算高值(接近<em class="kp"> 1 </em>)，这意味着它确信输入图像是真实的</li><li id="eb8c" class="mh mi it js b jt mq jx mr kb ms kf mt kj mu kn mm mn mo mp bi translated">当接收到假图像时，它应该计算低值(接近<em class="kp"> 0 </em>，这意味着它确信输入图像不是真实的</li></ul><p id="f7f1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为此，我们使用前面定义的<em class="kp">二元交叉熵</em>函数。生成器试图实现相反的目标，它试图让鉴别器给假图像分配高值。</p><p id="04d4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，我们也应用一些正则化。我们创建了两个不同的优化器，一个用于鉴别器，一个用于生成器。我们必须定义允许这些优化器修改哪些变量，否则生成器的优化器可能会弄乱鉴别器的变量，反之亦然。</p><p id="f9f9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在应用批处理规范化时，我们必须向我们的优化器提供<code class="fe np nq nr ns b">update_ops</code>——看看<a class="ae ko" href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/batch_norm" rel="noopener ugc nofollow" target="_blank"> tensorflow文档</a>,了解关于这个主题的更多信息。</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="nn no l"/></div></figure><h1 id="06b6" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">训练GAN</h1><p id="d695" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">最后，有趣的部分开始了——让我们训练我们的网络！我们向生成器输入随机值，它将学习从这些噪音中生成数字。我们还注意，通过平衡它们的损失，生成器和鉴别器都不会变得太强，否则，这将抑制任一部分的学习，甚至可能阻止网络学习任何东西(我有过这种经验)。</p><figure class="kt ku kv kw gt kx"><div class="bz fp l di"><div class="nn no l"/></div></figure><h1 id="7324" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">MNIST结果</h1><p id="06ca" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">看看我们的生成器绘制的图片——它们看起来比VAE绘制的图片更真实，后者的边缘看起来更模糊。然而，训练比训练另一个模型花费的时间要长得多。我还必须提到，在创建的角色看起来有意义之前，我需要比<a class="kq kr ep" href="https://medium.com/u/8599a4bace36?source=post_page-----8291616904a--------------------------------" rel="noopener" target="_blank">罗威尔·阿蒂恩萨</a>更多的迭代，所以特别是如果你没有强大的GPU，你可能想参考本文顶部提到的他的架构。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/46849c0b48e0b731fabcc8c4f130e46d.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/1*Wgo66f5X4Ika871GZ6XpFA.gif"/></div><figcaption class="nu nv gj gh gi nw nx bd b be z dk">MNIST characters created by our DCGAN</figcaption></figure><p id="527a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是一个真正的优势，我们不依赖于基于像素位置的损失函数，使结果看起来不那么模糊。这在创建更复杂的数据时尤其重要，例如人脸图片。所以，只要有点耐心，结果最终会回报你的。</p><h1 id="cf4f" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">画人脸</h1><p id="f42c" class="pw-post-body-paragraph jq jr it js b jt mc jv jw jx md jz ka kb me kd ke kf mf kh ki kj mg kl km kn im bi translated">我不会详细介绍生成人脸的完整代码，因为架构基本上是一样的。主要区别在于，我们现在使用三个颜色通道，而不是像以前那样使用一个通道，并且我们允许卷积转置层针对这种更复杂的输入数据学习更多的滤波器。你可以在我的<a class="ae ko" href="https://github.com/FelixMohr/Deep-learning-with-Python" rel="noopener ugc nofollow" target="_blank"> github </a>找到完整的代码。</p><p id="f770" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我使用的数据集是麻省大学的<a class="ae ko" href="http://vis-www.cs.umass.edu/lfw/" rel="noopener ugc nofollow" target="_blank"> LFW(野外标记人脸)</a>数据集。或许使用更大的数据集可以改善结果，但我还没有尝试过。为了让学习在相当长的时间内发生，我将图像缩小到40 x 40像素，并以前面提到的相同方式训练DCGAN。生成器的卷积变换层创建了更多的过滤器，因为这个数据集比MNIST数据集更复杂。</p><figure class="kt ku kv kw gt kx gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/ff9bb8c7f76177df6ab161e44c08c2e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/1*9pXeeZ2nD0t49YtqXmqotQ.gif"/></div><figcaption class="nu nv gj gh gi nw nx bd b be z dk">Faces drawn by our neural network</figcaption></figure><p id="4889" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">看看结果吧！我在特斯拉K80 GPU上训练了大约一个小时的网络，以获得这些。也许这些家伙不会骗你相信他们是真人。但是想想看，神经网络以前从未见过任何人，在完成MNIST项目后，我们对它的重新设计付出了多么少的努力！这项技术显然有很大的应用潜力。</p><p id="509d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你喜欢这篇文章，你可能也会对我的关于使用变分自动编码器  <em class="kp">生成MNIST字符的</em> <a class="ae ko" href="https://medium.com/towards-data-science/teaching-a-variational-autoencoder-vae-to-draw-mnist-characters-978675c95776" rel="noopener"> <em class="kp">教程感兴趣。</em></a></p></div></div>    
</body>
</html>