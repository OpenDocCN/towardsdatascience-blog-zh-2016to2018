<html>
<head>
<title>Prototyping a Recommender System Step by Step Part 2: Alternating Least Square (ALS) Matrix Factorization in Collaborative Filtering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一步一步建立推荐系统的原型第二部分:协同过滤中的交替最小二乘矩阵分解</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-2-alternating-least-square-als-matrix-4a76c58714a1?source=collection_archive---------1-----------------------#2018-11-17">https://towardsdatascience.com/prototyping-a-recommender-system-step-by-step-part-2-alternating-least-square-als-matrix-4a76c58714a1?source=collection_archive---------1-----------------------#2018-11-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/6593b57fe340e868d1be2962ad7c52ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EZu5sHcoyDhsRC00C9ZCTg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Item Based Collaborative Filtering Movie Recommender</figcaption></figure><p id="57bc" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">第一部分的<em class="la">推荐系统</em>可以在这里找到<a class="ae lb" rel="noopener" target="_blank" href="/prototyping-a-recommender-system-step-by-step-part-1-knn-item-based-collaborative-filtering-637969614ea"><em class="la"/></a></p><p id="ac5d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在上一篇<a class="ae lb" href="https://medium.com/@keliao/prototyping-a-recommender-system-step-by-step-part-1-knn-item-based-collaborative-filtering-637969614ea" rel="noopener"><em class="la"/></a>文章中，我们讨论了很多如何构建我们自己的推荐系统，并且用<strong class="ke ir"> Pandas </strong>和<strong class="ke ir"> Scikit-learn </strong>实现了一个<strong class="ke ir"> KNN 基于项目的协同过滤</strong>电影推荐器。KNN 推荐系统的源代码可以在我的<a class="ae lb" href="https://github.com/KevinLiao159/MyDataSciencePortfolio/blob/master/movie_recommender/src/knn_recommender.py" rel="noopener ugc nofollow" target="_blank"> <em class="la"> Github repo </em> </a>中找到。<br/> <br/>在本帖中，我们将讨论如何用更复杂的机器学习技术来改进我们的电影推荐系统:<strong class="ke ir">矩阵分解</strong>。在这篇文章的后面，我们将讨论为什么我们要在协同过滤中使用矩阵分解，什么是矩阵分解，它是如何在<strong class="ke ir"> Spark </strong>中实现的。</p><h1 id="ed32" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">基于项目的协同过滤的缺点</h1><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ma"><img src="../Images/2df542ec57611e8529e223c2bfb17793.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6gB-RTb3ANp3lrkdvhC2CQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Output of KNN Item Based Collaborative Filtering Recommender From Previous Post</figcaption></figure><p id="7f53" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在<a class="ae lb" href="https://medium.com/@keliao/prototyping-a-recommender-system-step-by-step-part-1-knn-item-based-collaborative-filtering-637969614ea" rel="noopener"> <em class="la">上一篇</em> </a>的最后一节，我们向模特询问了一些电影推荐。在我们评估了推荐的电影列表后，我们很快发现了 KNN 方法的两个明显的局限性。一是“人气偏差”，二是“物品冷启动问题”。如果底层的训练数据太大而不适合一台机器，就会有另一个限制，即“可伸缩性问题”</p><ul class=""><li id="48e7" class="mf mg iq ke b kf kg kj kk kn mh kr mi kv mj kz mk ml mm mn bi translated"><strong class="ke ir">流行偏好:</strong>指系统推荐互动最多的电影，没有任何个性化</li><li id="0ca5" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated"><strong class="ke ir">项目冷启动问题</strong>:指添加到目录中的电影没有互动或者互动很少，而推荐者依靠电影的互动来进行推荐</li><li id="e8cb" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated"><strong class="ke ir">可扩展性问题</strong>:指当越来越多的用户和电影加入我们的数据库时，缺乏扩展到更大数据集的能力</li></ul><p id="ba9c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">以上三点对于协同过滤推荐系统来说都是非常典型的挑战。它们与用户-电影(或电影-用户)交互矩阵一起自然到达，其中每个条目记录用户<code class="fe mt mu mv mw b">i</code>和电影<code class="fe mt mu mv mw b">j</code>的交互。在现实世界中，绝大多数电影很少甚至根本没有得到用户的评价。我们看到的是一个极其稀疏的矩阵，99%以上的条目都缺少值。</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/d0048f56e7fda53bdf138eebe7293bdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rvCsSPh2EHj-B2HFwAgwmg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Sparse Rating Data</figcaption></figure><p id="f5b9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">有了这样的稀疏矩阵，有哪些 ML 算法可以训练出来，可靠的做出推断？为了找到问题的解决方案，我们正在有效地解决数据稀疏问题。</p><h1 id="fa10" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">矩阵分解</h1><p id="01e6" class="pw-post-body-paragraph kc kd iq ke b kf my kh ki kj mz kl km kn na kp kq kr nb kt ku kv nc kx ky kz ij bi translated">在协同过滤中，<strong class="ke ir">矩阵分解</strong>是针对稀疏数据问题的最先进的解决方案，尽管它是从<a class="ae lb" href="https://www.netflixprize.com/" rel="noopener ugc nofollow" target="_blank"> <em class="la"> Netflix 奖挑战赛</em> </a>开始广为人知的。</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nd"><img src="../Images/223415259245d67c9eec0b3747d55999.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xMxQL_V9CWeLggrk-Uyzmg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Matrix Factorization of Movie Ratings Data</figcaption></figure><p id="07b8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">什么是矩阵分解？矩阵分解只是线性代数中矩阵的一系列数学运算。具体地说，矩阵分解是将矩阵分解成矩阵的乘积。在协同过滤的情况下，<strong class="ke ir">矩阵分解</strong>算法通过<strong class="ke ir">将</strong>用户-项目交互矩阵分解为两个<strong class="ke ir">低维度矩形矩阵</strong>的乘积来工作。一个矩阵可以被视为用户矩阵，其中行代表用户，列是潜在因素。另一个矩阵是项目矩阵，其中行是潜在因素，列代表项目。</p><p id="2075" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">矩阵分解如何解决我们的问题？</p><ol class=""><li id="b103" class="mf mg iq ke b kf kg kj kk kn mh kr mi kv mj kz ne ml mm mn bi translated">模型学习将评级矩阵分解为用户和电影表示，这允许模型为用户预测更好的个性化电影评级</li><li id="6b36" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz ne ml mm mn bi translated">通过矩阵分解，不太出名的电影可以像受欢迎的电影一样具有丰富的潜在表示，这提高了推荐器推荐不太出名的电影的能力</li></ol><p id="03ba" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在稀疏用户-项目交互矩阵中，用户<code class="fe mt mu mv mw b">u</code>将给予项目<code class="fe mt mu mv mw b">i</code>的预测评级被计算为:</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/e9b767f2fda07fbbd69e96a8d0ebba90.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*EwHsfRtda-N-IUj-lMtQpg.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">where H is user matrix, W is item matrix</figcaption></figure><p id="b16a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">用户<code class="fe mt mu mv mw b">u</code>对项目<code class="fe mt mu mv mw b">i</code>的评分可以表示为用户潜在向量和项目潜在向量的点积。</p><p id="b4d3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">注意，在上面的公式中，<strong class="ke ir">潜在因素</strong>的数量可以通过交叉验证来调整。<strong class="ke ir">潜在因素</strong>是用户-项目交互矩阵投影出的低维潜在空间中的特征。矩阵分解背后的思想是使用潜在因素在低得多的维度空间中表示用户偏好或电影主题。矩阵分解是机器学习中非常有效的<strong class="ke ir">降维</strong>技术之一。</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ng"><img src="../Images/b1c20e8f5ec20fb5d89408e280011ddf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HJut9UgXP5STwpYInxvJVg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Variance Explained By Components In PCA</figcaption></figure><p id="0bc9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">很像<strong class="ke ir"> PCA </strong>中<strong class="ke ir">成分</strong>的概念，潜在因素的数量决定了我们想要在一个低维空间中存储的抽象信息量。具有一个潜在因子的矩阵分解相当于<em class="la">最受欢迎的</em>或<em class="la">最受欢迎的</em>推荐器(例如，推荐具有最多交互而没有任何个性化的项目)。增加潜在因素的数量将改善个性化，直到因素的数量变得太高，此时模型开始过度拟合。避免过度拟合的常见策略是将<strong class="ke ir">正则化项</strong>添加到目标函数中。</p><p id="b871" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">矩阵分解的目的是最小化真实评级和预测评级之间的误差:</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/9df45faefc53616db59f64f6098cb6a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Oi7FYyZc31s5x3hsk8a48Q.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">where H is user matrix, W is item matrix</figcaption></figure><p id="c106" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">一旦我们有了目标函数，我们只需要一个训练例程(例如梯度下降)来完成一个矩阵分解算法的实现。这个实现实际上叫做<strong class="ke ir"> Funk SVD </strong>。它是以西蒙·芬克的名字命名的，他在 2006 年网飞奖挑战中与研究界分享了他的发现。</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ni"><img src="../Images/6e7cc1e6123b0f75f573224bafe46824.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tYxWuyksovxA1Thu8PggPQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Scaling Machine Learning Applications With Distributed Computing</figcaption></figure><p id="6107" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">尽管 Funk SVD 在那段时间对于单机的矩阵分解非常有效，但是随着今天数据量的增长，它不具有可伸缩性。对于兆兆字节甚至千兆字节的数据，不可能将如此大的数据加载到一台机器上。因此，我们需要一个机器学习模型(或框架)，它可以在机器集群中传播的数据集上进行训练。</p><h1 id="0c6c" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">带 Spark ML 的交替最小二乘法(ALS)</h1><p id="306b" class="pw-post-body-paragraph kc kd iq ke b kf my kh ki kj mz kl km kn na kp kq kr nb kt ku kv nc kx ky kz ij bi translated">交替最小二乘法(ALS)也是一种矩阵分解算法，它以并行方式运行。ALS 是在 Apache Spark ML 中实现的，是为大规模协同过滤问题而构建的。ALS 在解决收视率数据的可扩展性和稀疏性方面做得很好，它很简单，可以很好地扩展到非常大的数据集。</p><p id="0c64" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">ALS 背后的一些高层次想法是:</p><ul class=""><li id="6839" class="mf mg iq ke b kf kg kj kk kn mh kr mi kv mj kz mk ml mm mn bi translated">其目标函数与 Funk SVD 略有不同:ALS 使用<strong class="ke ir"> L2 正则化</strong>，而 Funk 使用<strong class="ke ir"> L1 正则化</strong></li><li id="cd15" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated">其训练套路不同:ALS 最小化<strong class="ke ir">两个损失函数交替</strong>；它首先固定用户矩阵，然后用项目矩阵进行梯度下降；然后，它保持项目矩阵固定，并与用户矩阵运行梯度下降</li><li id="e16b" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated">它的可伸缩性:ALS 在来自一个机器集群的底层训练数据的多个分区上以<strong class="ke ir">并行</strong>运行它的梯度下降</li></ul><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nj"><img src="../Images/1d245f7be25907a867032bcece5f7796.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OqbfYwHNfpR0ZUsY7AH3NQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Pseudocode For SGD In Matrix Factorization</figcaption></figure><p id="8a76" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果你有兴趣了解更多关于 ALS 的知识，可以在本文中找到更多细节:<a class="ae lb" href="https://endymecy.gitbooks.io/spark-ml-source-analysis/content/%E6%8E%A8%E8%8D%90/papers/Large-scale%20Parallel%20Collaborative%20Filtering%20the%20Netflix%20Prize.pdf" rel="noopener ugc nofollow" target="_blank"><em class="la">Netflix 奖大规模并行协同过滤</em> </a></p><p id="d618" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">就像其他机器学习算法一样，ALS 也有自己的一套超参数。我们可能想通过<strong class="ke ir">保持验证</strong>或<strong class="ke ir">交叉验证</strong>来调整它的超参数。</p><p id="b306" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">交替最小二乘法(ALS)中最重要的超参数:</p><ul class=""><li id="cb68" class="mf mg iq ke b kf kg kj kk kn mh kr mi kv mj kz mk ml mm mn bi translated">maxIter:要运行的最大迭代次数(默认为 10)</li><li id="c4e0" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated">等级:模型中潜在因素的数量(默认为 10)</li><li id="1095" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz mk ml mm mn bi translated">reg param:ALS 中的正则化参数(默认为 1.0)</li></ul><p id="a067" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">超参数调整是许多机器学习项目中高度重复的任务。我们可以将它编码到一个函数中，以加速调优迭代。</p><figure class="mb mc md me gt jr"><div class="bz fp l di"><div class="nk nl l"/></div></figure><p id="9378" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">经过调优，我们找到了超参数的最佳选择:<code class="fe mt mu mv mw b">maxIter=10</code>、<code class="fe mt mu mv mw b">regParam=0.05</code>、<code class="fe mt mu mv mw b">rank=20</code></p><h1 id="8a57" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">实施 ALS 推荐系统</h1><p id="4bf8" class="pw-post-body-paragraph kc kd iq ke b kf my kh ki kj mz kl km kn na kp kq kr nb kt ku kv nc kx ky kz ij bi translated">现在我们知道我们有一个精彩的电影推荐模型，接下来的问题是:我们如何将我们的精彩模型产品化为推荐系统？机器学习模型产品化是另一个大话题，我不会详细谈论它。在这篇文章中，我将展示如何为 ALS 推荐者建立一个 MVP(最小可行产品)版本。</p><p id="fbb9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">要将模型产品化，我们需要围绕模型建立工作流。典型的 ML 工作流程大致从通过一组预定义的 ETL 作业、离线/在线模型训练的数据准备开始，然后将训练好的模型吸收到 web 服务中用于生产。在我们的例子中，我们将构建一个非常简单的电影推荐器来完成这项工作。我们的工作流程如下:</p><ol class=""><li id="3c64" class="mf mg iq ke b kf kg kj kk kn mh kr mi kv mj kz ne ml mm mn bi translated">新用户输入他/她喜欢的电影，然后系统为该模型创建新的用户-电影交互样本</li><li id="532c" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz ne ml mm mn bi translated">系统根据新输入的数据重新训练 ALS 模型</li><li id="1334" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz ne ml mm mn bi translated">系统创建用于推理的电影数据(在我的例子中，我从数据中抽取所有电影)</li><li id="859a" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz ne ml mm mn bi translated">系统为用户对所有电影进行分级预测</li><li id="cf39" class="mf mg iq ke b kf mo kj mp kn mq kr mr kv ms kz ne ml mm mn bi translated">系统基于电影分级预测的排名为该用户输出前 N 个电影推荐</li></ol><p id="12ac" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">下面是我们的 MVP 推荐系统的一小段源代码:</p><figure class="mb mc md me gt jr"><div class="bz fp l di"><div class="nk nl l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">snippet of our final step in ALS recommender’s implementation</figcaption></figure><p id="8871" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这个片段演示了我们推荐器实现中的<code class="fe mt mu mv mw b">make_recommendations</code>方法。请在我的<a class="ae lb" href="https://github.com/KevinLiao159/MyDataSciencePortfolio/blob/master/movie_recommender/src/als_recommender.py" rel="noopener ugc nofollow" target="_blank"> <em class="la"> GitHub Repo </em> </a>中找到推荐器应用的详细源代码。</p><h1 id="c6a7" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">我们来做一些推荐吧</h1><p id="4294" class="pw-post-body-paragraph kc kd iq ke b kf my kh ki kj mz kl km kn na kp kq kr nb kt ku kv nc kx ky kz ij bi translated">一旦我们在 python 脚本中将 ALS 推荐系统实现为一个小的<strong class="ke ir"> Pyspark </strong>程序，我们就可以将我们的 spark 应用程序提交到具有客户端部署模式或集群部署模式的集群，并享受分布式计算的强大功能。</p><p id="991d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">最后，我们完成了技术细节和实现。现在让我们向我们的推荐人要一些电影推荐。我将假装一个新用户，将我最喜欢的电影“钢铁侠”再次输入这个新的推荐系统。看看它给我推荐了哪些电影。希望它们不是我之前看过很多遍的热门电影列表。</p><p id="29d2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">出于演示的目的，我通过在终端中运行以下命令在本地提交我的 spark 应用程序:(命令的指令可以在这里找到<a class="ae lb" href="https://github.com/KevinLiao159/MyDataSciencePortfolio/blob/0bc389b38de4573863446c4c90cbca3c31f7b0ef/movie_recommender/src/als_recommender.py#L313" rel="noopener ugc nofollow" target="_blank"/>)</p><pre class="mb mc md me gt nm mw nn no aw np bi"><span id="642d" class="nq ld iq mw b gy nr ns l nt nu">spark-submit --master local[4] --driver-memory 4g <br/>             --executor-memory 8g src/als_recommender.py <br/>             --movie_name "Iron Man" --top_n 10</span></pre><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nv"><img src="../Images/5e102cf4b81cdf0f6bf9dfbd6405b344.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tllu7jihkhbmuKQ8FuuJMA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">List of Movie Recommendations Based On My Favorite Movie: “Iron Man”</figcaption></figure><p id="b3e8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">耶！！用 Spark 成功运行我们的电影推荐器。</p><p id="8717" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这份新的电影推荐名单与之前的 KNN 推荐名单完全不同，非常有趣！！我从未看过这份新名单中的任何一部电影。我发现新的推荐者向我推荐不寻常的电影非常令人惊讶。对于其他用户来说，它们可能太不寻常了，这是有问题的。</p><p id="1f86" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">进一步改进我们的电影推荐系统的一个想法是将这个新的电影推荐列表与 KNN 推荐器的先前列表混合。我们基本上实现了一个混合推荐系统，这个混合推荐系统可以向用户提供流行和不太了解的内容。</p><h1 id="379e" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">摘要</h1><p id="59e0" class="pw-post-body-paragraph kc kd iq ke b kf my kh ki kj mz kl km kn na kp kq kr nb kt ku kv nc kx ky kz ij bi translated">在这篇文章中，我们介绍了如何用<strong class="ke ir">矩阵分解</strong>来改进协同过滤推荐系统。我们了解到矩阵分解可以解决协同过滤中的“流行偏见”和“项目冷启动”问题。我们还利用<strong class="ke ir"> Spark ML </strong>实现了使用<strong class="ke ir">交替最小二乘(ALS) </strong>的分布式推荐系统。这篇博文的<strong class="ke ir"> Jupyter 笔记本版本</strong>可以在这里 找到<a class="ae lb" href="https://github.com/KevinLiao159/MyDataSciencePortfolio/blob/master/movie_recommender/movie_recommendation_using_ALS.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="la">。如果你想玩我的<strong class="ke ir">源码</strong>，可以在这里</em> </a>找到<a class="ae lb" href="https://github.com/KevinLiao159/MyDataSciencePortfolio/blob/master/movie_recommender/src/als_recommender.py" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="2c5c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在我的下一篇文章中，我们将深入探讨矩阵分解技术。我们可以用<strong class="ke ir"> Keras 中的<strong class="ke ir">神经网络</strong>实现<strong class="ke ir"> </strong>开发一个更一般化形式的矩阵分解模型。</strong>敬请期待！在那之前，尽情享受机器学习和推荐器吧！</p></div><div class="ab cl nw nx hu ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="ij ik il im in"><p id="84b1" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">喜欢你读的书吗？在我的 Github 查看更多数据科学/机器学习项目: <a class="ae lb" href="https://github.com/KevinLiao159/MyDataSciencePortfolio" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ir"> <em class="la">凯文的数据科学作品集</em> </strong> </a></p></div></div>    
</body>
</html>