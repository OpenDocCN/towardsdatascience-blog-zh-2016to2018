<html>
<head>
<title>Why do we care so much about explainable algorithms? In defense of the black box</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么我们如此关心可解释的算法？为黑盒辩护</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc?source=collection_archive---------6-----------------------#2018-01-11">https://towardsdatascience.com/why-do-we-care-so-much-about-explainable-algorithms-in-defense-of-the-black-box-d9e3bc01e0dc?source=collection_archive---------6-----------------------#2018-01-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b2de" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">请记住，最暗的黑色盒子是你两耳之间的粉红色糊状盒子</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c23397a20028a3b2718e9bdf547567fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cH536JJL3BAWwGmvWm7CXQ.jpeg"/></div></div></figure><p id="049b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">算法开始在各种领域的高风险应用中使用。包括给罪犯判刑，开医疗处方，雇佣员工。为了应对这种向人工智能驱动的决策的转变，许多<a class="ae ln" href="https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/" rel="noopener ugc nofollow" target="_blank">墨水已经洒了出来</a>和<a class="ae ln" href="https://www.jacobinmag.com/2016/09/big-data-algorithms-math-facebook-advertisement-marketing/" rel="noopener ugc nofollow" target="_blank">许多人对<a class="ae ln" href="https://mobile.nytimes.com/2017/11/21/magazine/can-ai-be-taught-to-explain-itself.html" rel="noopener ugc nofollow" target="_blank">机器学习算法</a>的“黑箱”问题感到惊愕</a>。许多记者和评论家深思熟虑地指出了算法歧视少数群体的潜力，载入了不应影响后续决策的虚假变量，并使用了任何人都无法合理化的难以理解的复杂逻辑。</p><div class="lo lp gp gr lq lr"><a href="https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/" rel="noopener  ugc nofollow" target="_blank"><div class="ls ab fo"><div class="lt ab lu cl cj lv"><h2 class="bd ir gy z fp lw fr fs lx fu fw ip bi translated">人工智能有一个很大的问题:即使是它的创造者也无法解释它是如何工作的</h2><div class="ly l"><h3 class="bd b gy z fp lw fr fs lx fu fw dk translated">去年，一辆奇怪的自动驾驶汽车被投放到新泽西州蒙茅斯县安静的道路上。的…</h3></div><div class="lz l"><p class="bd b dl z fp lw fr fs lx fu fw dk translated">www.technologyreview.com</p></div></div><div class="ma l"><div class="mb l mc md me ma mf kp lr"/></div></div></a></div><p id="e723" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在许多情况下，这些担忧是有根据的，算法的实现应该非常谨慎。然而，当我们继续为机器学习算法寻找新的应用时，我们不应该让这种对算法可解释性的关注蒙蔽了我们对这个世界的一个残酷事实的认识:人类的决定往往是反复无常的，不合理的，并不比最不透明的算法更可解释。</p><h2 id="e753" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">背景很重要</h2><p id="9d0e" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">为了这个讨论的目的，将算法的应用分成两类是有用的:一类是当算法被用来自动化当前由人类做出的决策时；另一类是应用程序，其中算法被用来取代基于规则的过程。基于规则的流程是指使用一组简单且易于衡量的标准来做出决策的流程。基于规则的过程之所以伟大，正是因为它们是如此的可审查。当然，规则本身可能并不伟大(如在许多强制性判决法规中)，但至少基于规则的程序已经清楚地阐明了可以与其他提案进行辩论和评估的标准。</p><p id="6df6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">“可解释性”在第二类应用中的价值是非常明显的。从基于规则的世界转向由随机森林和神经网络组成的黑箱世界，可以理解会让政策制定者迷失方向。如果一所大学过去使用简单的 SAT 和 GPA 作为录取决定的截止点，那么用一个经过数十种特征训练的深度神经网络来取代这一过程，显然会提出一些具体的问题，即 SAT 分数和 GPA 如何影响算法的录取决定。</p><p id="3dfb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">然而，我不认为第一类应用需要同样的可解释性标准——当算法被用来代替纯粹的人类决策时。<a class="ae ln" rel="noopener" target="_blank" href="/are-machines-biased-or-are-we-biased-against-machines-17982310152b">正如我在别处提到的</a>(其他研究人员也强调了<a class="ae ln" href="http://trustworthy-algorithms.org/whitepapers/Bo%20Cowgill.pdf" rel="noopener ugc nofollow" target="_blank"/>)，评估算法对它们所取代的系统的效用是很重要的。这就是为什么两种类型的应用程序之间的区别——那些取代人类的应用程序和那些取代规则的应用程序——很重要。当我们特别关注算法取代人类的应用时，很明显，可解释性是一个站不住脚的双重标准。</p><div class="lo lp gp gr lq lr"><a rel="noopener follow" target="_blank" href="/are-machines-biased-or-are-we-biased-against-machines-17982310152b"><div class="ls ab fo"><div class="lt ab lu cl cj lv"><h2 class="bd ir gy z fp lw fr fs lx fu fw ip bi translated">是机器有偏见还是我们对机器有偏见？</h2><div class="lz l"><p class="bd b dl z fp lw fr fs lx fu fw dk translated">towardsdatascience.com</p></div></div><div class="ma l"><div class="ne l mc md me ma mf kp lr"/></div></div></a></div><h2 id="5851" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">可以预见，人类是不理性的</h2><p id="03a2" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">虽然机器学习和算法决策的最新进展是最近才发生的，但人脑已经存在很长时间了。关于算法如何做出决策的新研究层出不穷，但研究人员已经花了几十年(如果不是几千年的话！)来研究人脑是如何做决定的。这项研究最具可复制性和一致性的发现之一是，在几乎所有可以想象的环境中，外部因素都会影响人类的决策。</p><p id="92e0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一个简单的例子就是心理学家所说的“锚定效应”。为了证明人类是多么容易受到无关信息的影响，请考虑 Ariely，Lowenstein 和 Prelec (2003 年)的经典研究:研究人员要求学生写下他们的社会安全号码的最后两位数，并表明他们是否愿意为一盒巧克力支付该金额。为了引出学生们对巧克力的真实估价，他们让学生们在强制拍卖中对盒子出价。虽然你和我都应该清楚，你的 SSN 的最后两位数字(本质上是一个随机数)与你对一盒巧克力的价值没有关系，但研究人员发现，SSN 数字与学生的实际支付意愿之间存在显著的相关性。此外，尽管有相反的统计证据，绝大多数学生坚持认为他们的 SSN 数字对他们的投标没有影响。</p><p id="9b5d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">另一个广泛宣传的影响人类决策的不相关因素的例子是<a class="ae ln" href="http://www.pnas.org/content/108/17/6889" rel="noopener ugc nofollow" target="_blank">“饥饿法官”研究</a>。研究结果表明，法官更有可能在午休后(当他们吃饱时)而不是午休前(当他们血糖低时)给予被告有利的假释决定。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/6fd159ac21be4bd564c02f65225981ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/0*IXdR0-QowsHlx-IG.gif"/></div><figcaption class="ng nh gj gh gi ni nj bd b be z dk">Judges become less favorable as their shift wears on (Danzinger et al., 2011)</figcaption></figure><p id="ef05" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">也许你对这些特殊的例子有些疑虑:它们感觉太做作，赌注不够高，样本量不够大，或者混杂变量没有得到充分的控制。(有效的批评确实存在；例如参见<a class="ae ln" href="http://economics.mit.edu/files/11713" rel="noopener ugc nofollow" target="_blank">【1】</a><a class="ae ln" href="http://nautil.us/blog/impossibly-hungry-judges" rel="noopener ugc nofollow" target="_blank">【2】</a>。)我们非常欢迎你忽略这些研究，但有数百个经过充分研究的重大认知偏差的例子。事实上，行为经济学家<a class="ae ln" href="https://www.nytimes.com/2017/10/09/business/nobel-economics-richard-thaler.html?_r=0" rel="noopener ugc nofollow" target="_blank">理查德·塞勒最近获得了诺贝尔奖</a>，很大程度上是因为他职业生涯中的工作证明了这些认知偏差即使在具有重大后果的高风险情况下也依然存在。你不能忽视的是大量关于判断和决策的研究得出的压倒性结论:人类总是让外部因素影响他们的决定。</p><div class="lo lp gp gr lq lr"><a href="https://en.wikipedia.org/wiki/Heuristics_in_judgment_and_decision-making" rel="noopener  ugc nofollow" target="_blank"><div class="ls ab fo"><div class="lt ab lu cl cj lv"><h2 class="bd ir gy z fp lw fr fs lx fu fw ip bi translated">判断和决策中的启发法-维基百科</h2><div class="ly l"><h3 class="bd b gy z fp lw fr fs lx fu fw dk translated">认知科学家司马贺最初提出，人类的判断受到可用信息的限制…</h3></div><div class="lz l"><p class="bd b dl z fp lw fr fs lx fu fw dk translated">en.wikipedia.org</p></div></div><div class="ma l"><div class="nk l mc md me ma mf kp lr"/></div></div></a></div><h2 id="cbbf" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">至少我们可以解释自己…对吗？</h2><p id="f0bc" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">虽然认知偏见本身是有害的，但更糟糕的是，当你要求人们解释他们的决定时，他们往往不知道为什么会这样做。正如 Ariely 的学生坚持认为他们的社会安全号码不会影响他们对巧克力盒子的感知，我们经常甚至没有意识到偏见是如何进入我们的思维过程的。此外，即使我们确实为某个特定的决定提供了看似合理的理由，也有充分的证据表明这些理由往往只是虚构的。</p><p id="94a9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">尼斯贝特和威尔逊(1977)所著的《<a class="ae ln" href="http://www.wisebrain.org/papers/Self-ReportofInnerStates.pdf" rel="noopener ugc nofollow" target="_blank">告诉我们更多我们所不知道的事情】》是一篇证明这些效应的经典论文。我强烈建议阅读整篇论文，以充分理解人类凭空得出似乎合理的合理化是多么荒谬，但我将让他们的摘要中的一个简单总结来说明这一点:</a></p><blockquote class="nl nm nn"><p id="b581" class="kr ks no kt b ku kv jr kw kx ky ju kz np lb lc ld nq lf lg lh nr lj lk ll lm ij bi translated">证据审查表明，可能很少或没有直接内省访问更高层次的认知过程。受试者有时(a)不知道对反应有重要影响的刺激的存在，(b)不知道反应的存在，以及(c)不知道刺激影响了反应。</p></blockquote><p id="9a44" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这是一种花哨的学术说法，意思是人们通常不知道他们为什么做出一个特定的决定，即使研究人员可以从统计上证明有外部因素参与。</p><h2 id="d8ad" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">算法毕竟没有那么糟糕</h2><p id="f33a" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">当我们正确评估使用算法来自动化人类决策时——通过记住我们自己的认知偏差的普遍性和可预测性——相比之下，它们实际上开始看起来相当有利。至少用一个算法会在它移动的开始和结束时给你相同的答案。算法也没有任何社会声誉或自我来维护。所以，当我们开始窥视他们的内心，调查他们是如何做出一个特定的决定时，他们无法用看似合理的、<em class="no">事后</em>，一般般的合理化来为自己辩护。</p><p id="ddda" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">不要误解我:我完全赞成更好地理解不透明的算法是如何做出决定的。但现在是我们停止欺骗自己，相信人类在合理化自己的决定时会变得更加透明的时候了。事实上，只有凭借算法的确定性和一致性——而不是人类的不可预测性和反复无常——我们甚至可以开始严格地询问它们的逻辑，并衡量它们随着时间的推移而得到的改善。</p><h2 id="72c5" class="mg mh iq bd mi mj mk dn ml mm mn dp mo la mp mq mr le ms mt mu li mv mw mx my bi translated">我们失去了理解，但我们获得了结果</h2><p id="9788" class="pw-post-body-paragraph kr ks iq kt b ku mz jr kw kx na ju kz la nb lc ld le nc lg lh li nd lk ll lm ij bi translated">对一个社会科学家或经济学家来说，可解释性绝对是最重要的:大多数科学研究的主要目标是得出一个理论，解释事物如何以及为什么会以它们的方式工作。然而，对于一个结果主义者——也就是说，一个主要关心世界上实际发生的事情的人——来说，可解释性必须退居二线。如果我们关心减少种族不公正的数量，增加所有阶层的公平机会，那么这就是我们应该用来比较人类和算法决策者的标准。</p><p id="0737" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">只要算法真的能减少偏见和歧视——正如他们在关于这个话题的现有研究中所显示的那样<a class="ae ln" href="https://academic.oup.com/qje/article/133/1/237/4095198" rel="noopener ugc nofollow" target="_blank">——我们就应该把可解释性放在次要位置。确保算法是可解释的无疑是一个有价值的目标——但那些坚持可解释的人必须问，这个目标是否比我们寻求改善的系统中的实际结果更有价值。</a></p></div></div>    
</body>
</html>