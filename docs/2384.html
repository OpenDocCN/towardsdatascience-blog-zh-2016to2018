<html>
<head>
<title>Only Numpy: Deriving Forward Feed on Multi-Dimensional Recurrent Neural Networks (Spatial LSTM) by “ Generative Image Modeling Using Spatial LSTMs”</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Only Numpy:通过“使用空间 LSTMs 的生成图像建模”导出多维递归神经网络(空间 LSTM)的前馈</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/only-numpy-deriving-forward-feed-on-multi-dimensional-recurrent-neural-networks-spatial-lstm-by-35d111906258?source=collection_archive---------6-----------------------#2018-01-19">https://towardsdatascience.com/only-numpy-deriving-forward-feed-on-multi-dimensional-recurrent-neural-networks-spatial-lstm-by-35d111906258?source=collection_archive---------6-----------------------#2018-01-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="3a39" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">多维递归神经网络，我一听到它的名字就对它产生了兴趣。所以今天，我将尝试针对空间 LSTM 的网络结构介绍<a class="ae kl" href="https://arxiv.org/pdf/1506.03478.pdf" rel="noopener ugc nofollow" target="_blank">。</a>“使用空间 LSTMs 的生成式图像建模”Lucas Theis。同样在今天的博客中，我们将对 2D·LSTM 进行<strong class="jp ir">前馈。</strong></p><p id="b27d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我还买了一个新的马克笔——橙色和绿色的 XD</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><p id="627b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">从 1D LSTM 转换到 2D LSTM </strong></p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi kt"><img src="../Images/450b60bf79b353de0f998635731fe012.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9LWkkJL1kooyNPUC-J5Iqg.jpeg"/></div></div></figure><p id="61a9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面的图片展示了我们如何把 1D·LSTM 的想法带到 2D·LSTM。将它们应用到图像上。从上面的照片中需要注意的非常重要的一点是单元格状态和隐藏状态。</p><p id="c8df" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">黄色方框→ 1D LSTM <br/>绿色方框→转置的 1D LSTM <br/>(把它想象成矩阵中的一列)<br/>粉色方框→ 2D LSTM</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi kt"><img src="../Images/4c7df2142908d92cda9b38d862bdc689.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bI5S7BymtG25lc9p98ZXOA.jpeg"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">1D LSTM that depends on Time</figcaption></figure><p id="e29d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如上所述，对于 1D·LSTM，我们在开始训练网络之前初始化 C(0)和 h(0)。有多种方法来初始化这些值，例如在论文“<a class="ae kl" href="https://arxiv.org/pdf/1502.03044.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lj"> Show，Attend and Tell:Neural Image Caption Generation with Visual Attention</em></a>”中，作者通过称为 MLP 的东西来初始化第一个值——我只能假设它是多层感知器。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/da63d3a10748094544c5cbd0fd19220a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*gRlwDVBrPdEizZgn_m5KFw.png"/></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Image from original Paper <a class="ae kl" href="https://arxiv.org/pdf/1502.03044.pdf" rel="noopener ugc nofollow" target="_blank">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></figcaption></figure><p id="4480" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是在 2D LSTM，我们必须初始化更多的单元格和隐藏状态值。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi kt"><img src="../Images/8492dd7bbd544ee8609b8e6b6a598a3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GbTcDwPZzl_n0dstg9TC5g.jpeg"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">2D LSTM respect to time</figcaption></figure><p id="cb5e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如上所示，我们不仅需要从 C(0，1)初始化到 C(0，j)，还需要从 C(1，0)初始化到 C(i，0)。所有隐藏状态都是如此。现在我们可以做一些有趣的事情，因为我们知道了 1D·LSTM 和 2D·LSTM 的结构，让我们想象一下 3D LSTM。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi kt"><img src="../Images/ffb458cc2fff941951df3de7fc4fe6b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oGjlvZILrbdY8m1QmuUwew.jpeg"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">3D LSTM</figcaption></figure><p id="6158" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">她真是个美人，不是吗？:D <br/>同样，橙色方框是第一个单元格和隐藏状态的位置。这个网络的应用不仅仅局限于视频数据，还有更多。现在我们知道了一般的结构，让我们回到论文“<a class="ae kl" href="https://arxiv.org/pdf/1506.03478.pdf" rel="noopener ugc nofollow" target="_blank">使用空间 LSTMs 生成图像建模</a></p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><p id="e7dc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">空间长短期记忆</strong></p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi ll"><img src="../Images/90d9fe8ffda5341e1cbe6a9c94b5cdd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WUpXVTApe33jBHCSLOxCBQ.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Image from original <a class="ae kl" href="https://arxiv.org/pdf/1506.03478.pdf" rel="noopener ugc nofollow" target="_blank">paper</a></figcaption></figure><p id="b696" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以正如作者所说，最初的 SLSTM 是由两位作者 Graves &amp; Schmidhuber 提出的。要查看这两位作者的论文，请单击“<a class="ae kl" href="http://people.idsia.ch/~juergen/nips2009.pdf" rel="noopener ugc nofollow" target="_blank"><em class="lj"/></a>”使用多维递归神经网络进行脱机手写识别。在那篇论文中，作者对什么是 2D·LSTM 有一个很好的设想，如下所示。然而，我正在研究的论文有更清晰的数学方程来描述 SLSTM。(如上所示)</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi lm"><img src="../Images/80f86078ca46cf05066553aee80a2115.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FFsHcYAPCcDaXrDqY70hHQ.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Image from paper <a class="ae kl" href="http://people.idsia.ch/~juergen/nips2009.pdf" rel="noopener ugc nofollow" target="_blank">Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks</a></figcaption></figure></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><p id="4808" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">样本训练数据</strong></p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/b1631c536d2ba3e8f303b0945da445b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*tVAZfsSUwzKmLmTtyn7-eQ.png"/></div></figure><p id="6013" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，我们将对一个非常简单的训练数据进行前馈传递，这是一个尺寸为 2*2(总共 4 个像素)的图像，如上面的黑框所示。</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><p id="40a7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">网络架构</strong></p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi lo"><img src="../Images/ce257470135a20ad6d9bd71ab5d435b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mKvGWEHX63r85zM4A5v6hw.png"/></div></div></figure><p id="d4b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我知道它看起来不好，但我不得不使用整个白板来制作图表 LOL 所以在这里和我一起工作。让我们从头开始。</p><p id="1174" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先每个盒子代表一个 LSTM 盒子，建筑是从著名的<a class="ae kl" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank"> Colah 博客</a>衍生而来。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi lp"><img src="../Images/ea43e4397cf96ab16388c8e7f9b793cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M_6_SCIyJDoUNy0fxzt_gg.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Image from <a class="ae kl" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank">Colah Blog</a></figcaption></figure><p id="2211" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其次，下面是时间戳信息。</p><p id="8640" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">红框→时间戳为(1，1)时进给<br/>绿框→时间戳为(2，1)时进给<br/>橙框→时间戳为(1，2)时进给<br/>紫框→时间戳为(2，2)时进给</p><p id="2965" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第三，每个蓝星代表我们在每个时间戳可以计算的成本函数。</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><p id="a158" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">向前进给</strong></p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi lq"><img src="../Images/80cbf70989ead58e744c60de6a4753e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KNlnYWXf3v4klmjlgAgsEg.png"/></div></div></figure><p id="f682" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">再说一次，我知道这看起来很糟糕，但是对于 LSTM 方程来说，它总是很混乱。</p><p id="d75d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">需要注意的是，所有用蓝色标记<strong class="jp ir">写的变量都是已经初始化的值。所以不要担心它们是从哪里冒出来的，它们是事先被初始化的。</strong></p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi kt"><img src="../Images/69ea8f73bd1b3092be9e166d08bea845.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-mxTRc5pSe2gDszSGn5z-w.jpeg"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Detailed Look at Forward Feed at Time Stamp (1,1) and (1,2)</figcaption></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi lr"><img src="../Images/5c54917a7c5c1dd5f3e81f7d1a0ac0ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SmIgRiph_914wLgzeZiDLw.jpeg"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Detailed Look at Forward Feed at Time Stamp (2,1) and (2,2)</figcaption></figure></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h2 id="576a" class="ls lt iq bd lu lv lw dn lx ly lz dp ma jy mb mc md kc me mf mg kg mh mi mj mk bi translated">最后的话</h2><p id="660e" class="pw-post-body-paragraph jn jo iq jp b jq ml js jt ju mm jw jx jy mn ka kb kc mo ke kf kg mp ki kj kk ij bi translated">我无法想象这个网络的反向传播过程，用手来推导它们会很有趣。我希望有一天会这样做。</p><p id="74f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 找我。</p><p id="ccc9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">同时，在我的 twitter <a class="ae kl" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，并访问<a class="ae kl" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或我的<a class="ae kl" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。如果你感兴趣的话，我还在简单的 RNN <a class="ae kl" href="https://medium.com/@SeoJaeDuk/only-numpy-vanilla-recurrent-neural-network-with-activation-deriving-back-propagation-through-time-4110964a9316" rel="noopener">上做了反向传播。</a></p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><p id="e59c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">参考文献</strong></p><ol class=""><li id="3a09" class="mq mr iq jp b jq jr ju jv jy ms kc mt kg mu kk mv mw mx my bi translated">Theis，l .，&amp; Bethge，M. (2015 年)。使用空间 LSTMs 的生成式图像建模。在<em class="lj">神经信息处理系统的进展</em>(1927-1935 页)。</li><li id="8ab7" class="mq mr iq jp b jq mz ju na jy nb kc nc kg nd kk mv mw mx my bi translated">更正，abs/1502.03044，。许凯文和(2015)。展示、参与和讲述:视觉神经图像字幕生成。</li><li id="2cbb" class="mq mr iq jp b jq mz ju na jy nb kc nc kg nd kk mv mw mx my bi translated">更正，abs/0705.2011，。亚历克斯·格雷夫斯和(2007)。多维递归神经网络。</li><li id="915b" class="mq mr iq jp b jq mz ju na jy nb kc nc kg nd kk mv mw mx my bi translated">了解 LSTM 网络。(未注明)。检索于 2018 年 1 月 19 日，来自<a class="ae kl" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></li><li id="7902" class="mq mr iq jp b jq mz ju na jy nb kc nc kg nd kk mv mw mx my bi translated">Graves，a .，&amp; Schmidhuber，J. (2009)。基于多维递归神经网络的脱机手写识别。在<em class="lj">神经信息处理系统的进展</em>(第 545–552 页)。</li></ol></div></div>    
</body>
</html>