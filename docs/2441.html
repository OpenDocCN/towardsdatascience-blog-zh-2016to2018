<html>
<head>
<title>Measuring Object Detection models — mAP — What is Mean Average Precision?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">测量对象检测模型-地图-什么是平均精度？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-is-map-understanding-the-statistic-of-choice-for-comparing-object-detection-models-1ea4f67a9dbd?source=collection_archive---------0-----------------------#2018-01-26">https://towardsdatascience.com/what-is-map-understanding-the-statistic-of-choice-for-comparing-object-detection-models-1ea4f67a9dbd?source=collection_archive---------0-----------------------#2018-01-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/a95b1e9224e0a8833bd53227c093a709.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zwQ9aGBOfZrV3XB4jlg9Rw.jpeg"/></div></div></figure><p id="7ae1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于使用机器学习解决的大多数常见问题，通常有多个模型可用。每个人都有自己的怪癖，并会根据各种因素表现不同。</p><p id="d846" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">每个模型都根据其在数据集<strong class="ka ir">上的表现来判断，通常称为“验证/测试”数据集</strong>。这种性能是用各种统计数据来衡量的——准确度、精确度、召回率等。选择的统计数据通常特定于您的特定应用程序和用例。对于每个应用程序来说，找到一个可以用来客观比较模型的指标是至关重要的。</p><p id="9e08" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在本文中，我们将讨论用于对象检测问题的最常见的度量标准— <em class="kw">平均精度</em>也就是<em class="kw">图。</em></p><p id="8408" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">大多数时候，这些指标很容易理解和计算。例如，在二进制分类中，<strong class="ka ir">精度和召回率</strong>是一种简单直观的统计。</p><p id="dbf0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">另一方面，物体检测是一个相当不同的…有趣的问题。</p><p id="21e0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">即使你的物体检测器在一幅图像中检测到一只猫，如果你在它所在的图像中找不到</em><strong class="ka ir"><em class="kw"/></strong><em class="kw">的位置，也没有用。</em></p><p id="88ae" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于您预测的是图像中物体的<strong class="ka ir">出现</strong> <em class="kw">和</em> <strong class="ka ir">位置</strong>，因此我们如何计算这一指标相当有趣。</p><p id="c27c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">首先，让我们定义对象检测问题，以便我们在同一页上。</p><h1 id="c6c4" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">目标检测问题</h1><p id="71d3" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">这就是我所说的“目标检测问题”,</p><blockquote class="ma"><p id="9c2f" class="mb mc iq bd md me mf mg mh mi mj kv dk translated"><em class="mk">给定一幅图像，找到其中的物体，定位它们的位置，并进行分类。</em></p></blockquote><p id="9264" class="pw-post-body-paragraph jy jz iq ka b kb ml kd ke kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv ij bi translated">对象检测模型通常在一组固定的类上训练，因此该模型将仅定位和分类图像中的那些类。</p><p id="dddd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，对象的位置通常是边界矩形的形式。</p><p id="3ff2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，对象检测涉及图像中对象的<strong class="ka ir">定位</strong>和该对象的<strong class="ka ir">分类</strong>。</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mq"><img src="../Images/72508f5bc489edaa842a60688248820a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AaMN-JY96ETB96rD.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk"><em class="mk">Image 1 — Few prominent Image Processing problems [Image taken from Stanford’s CS231n Course slides(lecture 8)]</em></figcaption></figure><p id="be1f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如下所述，平均精度特别用于预测对象位置和类别的算法。因此，从<em class="kw">图像1，</em>我们可以看到，它对于评估定位模型、对象检测模型和分割模型是有用的。</p><h1 id="87b5" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">评估对象检测模型</h1><h2 id="6870" class="mz ky iq bd kz na nb dn ld nc nd dp lh kj ne nf ll kn ng nh lp kr ni nj lt nk bi translated"><strong class="ak">为什么要地图？</strong></h2><p id="fb7f" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">对象检测问题中的每个图像可能具有不同类别的不同对象。如前所述，模型的分类和定位都需要评估。因此，在图像分类问题中使用的标准精度度量不能直接应用于此。这就是mAP(平均精度)发挥作用的地方。我希望在这篇文章结束时，你能够理解它的含义和代表。</p><h2 id="5115" class="mz ky iq bd kz na nb dn ld nc nd dp lh kj ne nf ll kn ng nh lp kr ni nj lt nk bi translated"><strong class="ak">关于地面真相</strong></h2><p id="0685" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">对于任何算法，总是在与真实数据的比较中评估指标。我们只知道训练、验证和测试数据集的基本事实信息。</p><p id="47c7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于对象检测问题，地面真实包括<strong class="ka ir">图像、</strong>图像中对象的<strong class="ka ir">类以及该图像中每个对象<em class="kw"> ** </em>的<strong class="ka ir">真实边界框</strong>。</strong></p><p id="b83e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">一个例子:</strong></p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/66e5698c9f75972bbd1c5fa07913e7bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*tdNef5S6upPNdF6m.png"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk"><em class="mk">Human visualisation of the ground truth</em></figcaption></figure><p id="ffde" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">我们被给予实际的图像(jpg、png等)和作为文本的其他注释(边界框坐标(x、y、宽度和高度)和类)，红色框和文本标签仅被绘制在该图像上以供我们人类可视化。</em></p><p id="a094" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于这个特殊的例子，我们的模型在训练中得到的是这个</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/76ca077ff958eaf3538adf18f2be281b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*xqfNcXJ6RcLc8zBk.png"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk"><em class="mk">The actual image</em></figcaption></figure><p id="f85c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">以及定义地面实况的3组数字(假设该图像是1000x800px，所有这些坐标都是像素，<em class="kw">也近似为</em>)</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nm"><img src="../Images/b672e3b4242e3137795328199659d176.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lGKaKNZB8mIri1RQDCAEQQ.png"/></div></div></figure><p id="db02" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，让我们把手弄脏，看看地图是如何计算的。</p><p id="1e50" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我将在另一篇文章中讨论各种对象检测算法、它们的方法和性能。现在，让我们假设我们有一个经过训练的模型，我们正在验证集上评估它的结果。</p><h1 id="38b1" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">计算地图</h1><p id="edbc" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">让我们说，原始图像和地面真相注释是我们在上面看到的。训练和验证数据以相同的方式对所有图像进行注释。</p><p id="23d5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该模型将返回大量预测，但在这些预测中，大多数预测都具有非常低的关联置信度得分，因此我们只考虑高于某个报告置信度得分的预测。</p><p id="2682" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们通过我们的模型运行原始图像，并且这是在置信度阈值化之后对象检测算法返回的，</p><p id="8463" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">带边框的图像-</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/12fbabd414c7ed2dcaa6cf4212453e31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*Tg2iEXPhD06CO4Xi.png"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk"><em class="mk">Results from our model</em></figcaption></figure><p id="473c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，由于我们人类是物体检测专家，我们可以说这些检测是正确的。但是我们如何对此进行量化呢？</p><p id="dca4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">我们首先需要知道这些检测中每一个的正确性有多大</em>。告诉我们一个给定的边界框的正确性的度量是联合上的— <strong class="ka ir"> IoU </strong> — <strong class="ka ir">交集</strong>。这是一个非常简单的视觉量。</p><p id="f9d7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">就单词而言，有些人会说这个名字是不言自明的，但是我们需要一个更好的解释。我简单解释一下欠条，<em class="kw">对于真正想要详细解释的人，</em> <a class="ae nn" href="http://pyimagesearch.com" rel="noopener ugc nofollow" target="_blank"> <em class="kw">阿德里安·罗斯布鲁克</em> </a> <em class="kw">有一篇</em> <a class="ae nn" href="https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/" rel="noopener ugc nofollow" target="_blank"> <em class="kw">真正的好文章</em> </a> <em class="kw">可以参考一下。</em></p><h1 id="b219" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">借据</h1><p id="283d" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated"><strong class="ka ir">交集/并集是预测框和基础事实框的交集和并集之间的比率。</strong>这种统计也被称为Jaccard指数，由Paul Jaccard在20世纪初首次发布。</p><p id="31e3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了获得交集和并集值，我们首先将预测框覆盖在基础真值框上。(见图片)</p><p id="5fae" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，对于每个类，与预测框和地面真实框重叠的区域是<em class="kw">交集</em>区域，并且跨越的总区域是<em class="kw">联合</em>。</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/72c5dfdf3ed6d887358388e1b7a168ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*hQz4WpRd2JqTE-Rm.png"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk"><em class="mk">We’ll show this example only for the horse</em></figcaption></figure><p id="dc2d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">上面的horse类的交集和并集如下所示，</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi no"><img src="../Images/22d8d5e887e640e4cc665927048ba007.png" data-original-src="https://miro.medium.com/v2/resize:fit:598/format:webp/0*4fLMlCt9rrP6vJch.png"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk"><em class="mk">In this case the intersection is pretty large</em></figcaption></figure><p id="42ad" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">交集包括重叠区域(青色区域)，并集包括橙色和青色区域。</p><p id="76ee" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">欠条的计算方法如下</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/088a74bb38fefc3443537cb9ac3e59a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/0*2LNZGR93ZZDUyiGr.png"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk"><em class="mk">This Image is inspired by the pyimagesearch article, which was inspired by University of Pittsburg’s CS1699 HW assignment4</em></figcaption></figure><h1 id="f10d" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">识别正确的检测并计算精度</h1><p id="b7af" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">对于<a class="ae nn" href="https://medium.com/@starang/precision-and-recall-a-brief-intro-38589a21a09" rel="noopener">计算精度和召回</a>，就像所有机器学习问题一样，我们必须识别真阳性、假阳性、真阴性和假阴性。</p><p id="f1fa" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了得到真阳性和假阳性，我们使用IoU。使用IoU，我们现在必须确定检测(阳性)是正确的(真)还是错误的(假)。最常用的阈值是0.5，即如果IoU &gt; 0.5，则认为是<strong class="ka ir">真阳性</strong>，否则认为是<strong class="ka ir">假阳性</strong>。COCO评估指标建议测量各种IoU阈值，但为简单起见，我们将坚持0.5，这是帕斯卡VOC指标。</p><p id="729a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了计算召回率，我们需要否定的计数。由于图像中我们没有预测到物体的每一部分都被认为是负面的，所以测量“真正的”负面效果有点没用。所以我们只测量“假”否定。我们的模型遗漏的对象。</p><p id="e26a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，另一个要考虑的因素是模型为每次检测报告的<em class="kw">置信度</em>。通过改变我们的信心阈值，我们可以改变一个预测框是积极的还是消极的。基本上，高于阈值的所有预测(盒+类)被认为是正盒，低于阈值的所有预测是负盒。</p><p id="0c15" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，对于每个图像，我们都有基础数据，它告诉我们该图像中给定类别的实际对象的数量。</p><p id="0d1f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，我们使用模型报告的每个阳性检测框的地面真实值来计算IoU。使用这个值和我们的IoU阈值(比如0.5)，我们计算图像中每个类别的正确检测的<strong class="ka ir">数量(<em class="kw"> A </em> ) </strong>。这用于计算每个类的精度[TP/(TP+FP)]</p><blockquote class="ma"><p id="8a82" class="mb mc iq bd md me mf mg mh mi mj kv dk translated">精度= TP / (TP+FP)</p></blockquote><p id="5dc3" class="pw-post-body-paragraph jy jz iq ka b kb ml kd ke kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv ij bi translated">由于我们已经计算了正确预测的<strong class="ka ir">数量(<em class="kw"> A </em> ) </strong>(真阳性)和<strong class="ka ir">漏检</strong>(假阴性)，因此我们现在可以使用此公式计算该类模型的<strong class="ka ir">召回(<em class="kw"> A </em> / <em class="kw"> B </em> ) </strong>)。</p><blockquote class="ma"><p id="eb35" class="mb mc iq bd md me mf mg mh mi mj kv dk translated">召回= TP / (TP+FN)</p></blockquote><h1 id="3ceb" class="kx ky iq bd kz la lb lc ld le lf lg lh li nq lk ll lm nr lo lp lq ns ls lt lu bi translated">计算平均精度</h1><p id="5517" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">平均精度是一个有不同定义的术语。这种度量通常用于信息检索和对象检测领域。这两个域有不同的计算mAP的方法。我们将讨论对象检测相关的地图。</p><p id="0cc3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当前流行的mAP的对象检测定义在2007年的PASCAL视觉对象类(VOC)挑战中首次正式化，该挑战包括各种图像处理任务。关于确切的文件，请参考<a class="ae nn" href="http://homepages.inf.ed.ac.uk/ckiw/postscript/ijcv_voc09.pdf" rel="noopener ugc nofollow" target="_blank">和</a>。</p><p id="a3d0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们使用与上一节提到的相同的方法来计算精度和召回率。</p><p id="e968" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但是，如前所述，我们至少有2个其他变量决定精确度和召回率的值，它们是<em class="kw"> IOU </em>和<em class="kw">置信度</em>阈值。</p><p id="fba8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">IOU是一个简单的几何指标，很容易标准化，例如PASCAL VOC challange基于固定的50% IOU来评估mAP。(MSCOCO挑战赛更进一步，在5%到95%的不同阈值范围内评估mAP。另一方面，置信度因模型而异，对我的模型设计50%的置信度可能相当于对其他人的模型设计80%的置信度，这将改变精确回忆曲线的形状。因此，PASCAL VOC组织者想出了一种方法来解释这种差异。</p><p id="4206" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们现在需要一个度量来以模型不可知的方式评估模型。</p><p id="8758" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这篇论文建议我们计算一个叫做AP ie的度量。平均精度</p><pre class="mr ms mt mu gt nt nu nv nw aw nx bi"><span id="a636" class="mz ky iq nu b gy ny nz l oa ob">For a given task and class, the precision/recall curve is<br/>computed from a method’s ranked output. Recall is defined<br/>as the proportion of all positive examples ranked above a<br/>given rank. Precision is the proportion of all examples above<br/>that rank which are from the positive class. The AP summarises<br/>the shape of the precision/recall curve, and is de-<br/>fined as the mean precision at a set of eleven equally spaced<br/>recall levels [0,0.1,...,1]:</span></pre><p id="668c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这意味着我们选择了11个不同的置信度阈值(决定了“等级”)。阈值应该是这样的，在那些置信度值下的<strong class="ka ir">回忆</strong>是0、0.1、0.2、0.3、…、0.9和1.0。AP现在被定义为在这些选定的11个召回值处的<strong class="ka ir">精度</strong>值的平均值。这导致该图是整个精确召回曲线的总体视图。</p><p id="a8fd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">本文还对上述计算中所用的精度进行了详细的计算。</p><pre class="mr ms mt mu gt nt nu nv nw aw nx bi"><span id="1bee" class="mz ky iq nu b gy ny nz l oa ob">The precision at each recall level r is interpolated by taking<br/>the maximum precision measured for a method for which<br/>the corresponding recall exceeds r.</span></pre><p id="cff8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">基本上，我们使用给定召回值的最大精度。</p><p id="063c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，该图是上面测量的所有类的所有平均精度值的平均值。</p><p id="3d7d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这实质上是如何为对象检测评估计算平均精度的。有时可能会有一些变化，例如COCO评估更加严格，使用各种借据和对象大小强制执行各种指标(<a class="ae nn" href="http://cocodataset.org/#detection-eval" rel="noopener ugc nofollow" target="_blank">更多细节请点击</a>)。如果你们中的任何一个人想让我说得更详细，请在评论中告诉我。</p><p id="e997" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">因此，总结一下，平均精度，从字面上看，是数据集中所有类的平均精度(AP)的平均值。</strong></p><p id="76e1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">比较地图值时需要记住的一些要点</em></p><ol class=""><li id="dc43" class="oc od iq ka b kb kc kf kg kj oe kn of kr og kv oh oi oj ok bi translated">MAP总是在固定的数据集上进行计算。</li><li id="bcba" class="oc od iq ka b kb ol kf om kj on kn oo kr op kv oh oi oj ok bi translated">尽管解释模型输出的绝对量化并不容易，但MAP通过提供一个非常好的相对度量来帮助我们。当我们在流行的公共数据集上计算该度量时，该度量可以很容易地用于比较新旧对象检测方法。</li><li id="818d" class="oc od iq ka b kb ol kf om kj on kn oo kr op kv oh oi oj ok bi translated">根据类在训练数据中的分布情况，平均精度值可能会从某些类的非常高(具有良好的训练数据)到非常低(具有较少/较差数据的类)不等。所以你的地图可能是中等的，但是你的模型可能对某些职业真的很好，对某些职业真的很差。因此，在分析模型结果时，查看单个类的平均精度是明智的。这些值也可以作为添加更多训练样本的指标。</li></ol></div><div class="ab cl oq or hu os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="ij ik il im in"><p id="8900" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">原载于2018年1月27日tarangshah.com</em><a class="ae nn" href="http://tarangshah.com/blog/2018-01-27/what-is-map-understanding-the-statistic-of-choice-for-comparing-object-detection-models/" rel="noopener ugc nofollow" target="_blank"><em class="kw"/></a><em class="kw">。2018年5月27日更新</em></p></div></div>    
</body>
</html>