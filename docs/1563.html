<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://towardsdatascience.com/accelerating-deep-neural-networks-1231273c48aa?source=collection_archive---------3-----------------------#2017-09-20">https://towardsdatascience.com/accelerating-deep-neural-networks-1231273c48aa?source=collection_archive---------3-----------------------#2017-09-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="3ddc" class="io ip iq bd ir is it dn iu iv iw dp ix iy iz ja jb jc jd je jf jg jh ji jj jk bi translated">加速深度神经网络</h2><p id="8680" class="pw-post-body-paragraph jl jm iq jn b jo jp jq jr js jt ju jv iy jw jx jy jc jz ka kb jg kc kd ke kf ij bi translated">神经网络“慢”的原因有很多，包括加载/存储延迟、将数据移入和移出GPU管道、GPU中管道的有限宽度(由编译器映射)、大多数神经网络计算中不必要的额外精度(对结果没有影响的大量微小数字)、输入数据的稀疏性(大量0)以及许多其他因素。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div class="gh gi kg"><img src="../Images/b5d32860db14d2f6986c64879dd6d727.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/0*srthVCtM1hU7Xv5B.gif"/></div><figcaption class="ko kp gj gh gi kq kr bd b be z dk">Neural Networks compile for A LONG TIME. (Credit: <a class="ae ks" href="http://itexperts.co.za/computer-become-slow/" rel="noopener ugc nofollow" target="_blank">IT Experts</a>)</figcaption></figure><p id="656b" class="pw-post-body-paragraph jl jm iq jn b jo kt jq jr js ku ju jv iy kv jx jy jc kw ka kb jg kx kd ke kf ij bi translated">如何才能让深度神经网络训练、测试、预测更快？一种方法是编写更快的算法，像<a class="ae ks" href="https://www.tensorflow.org/versions/r0.12/api_docs/python/nn/activation_functions_" rel="noopener ugc nofollow" target="_blank"> relu激活函数</a>，它<a class="ae ks" href="https://algorithmsdatascience.quora.com/ReLu-compared-against-Sigmoid-Softmax-Tanh" rel="noopener ugc nofollow" target="_blank">比tanh和sigmoid </a>快得多，另一种方法是编写更好的编译器，将神经网络映射到硬件中。第三种方法是我今天想告诉你们的。制造更好的硬件，我说的更好是指更快的处理速度。矩阵乘法和索引是深度学习的核心，这是一个“<a class="ae ks" href="https://en.wikipedia.org/wiki/Embarrassingly_parallel" rel="noopener ugc nofollow" target="_blank">令人尴尬的并行问题</a>”这就是让硬件人员真正感兴趣的地方:解决方案应该“简单”，或者至少不是不可能的。在<a class="ae ks" href="https://medium.com/@lemaysolutions/ai-tools-are-popping-like-popcorn-3baa6793271f" rel="noopener">最近的一篇文章</a>中，我提到了一篇由MIT+Nvidia编写的关于加速深度神经网络的最新进展的精彩<a class="ae ks" href="http://www.rle.mit.edu/eems/wp-content/uploads/2017/06/ISCA-2017-Hardware-Architectures-for-DNN-Tutorial.pdf" rel="noopener ugc nofollow" target="_blank">综合评论。</a></p><p id="d244" class="pw-post-body-paragraph jl jm iq jn b jo kt jq jr js ku ju jv iy kv jx jy jc kw ka kb jg kx kd ke kf ij bi translated">过去几年发明了一些非常酷的定制硬件解决方案，如nVidia的Volta GPUs、Google的TPU和一系列FPGA加速器。</p><p id="c24a" class="pw-post-body-paragraph jl jm iq jn b jo kt jq jr js ku ju jv iy kv jx jy jc kw ka kb jg kx kd ke kf ij bi translated">不要把我的喇叭吹得太大，让我告诉你关于FPGA的东西，因为TPU和伏打的东西更“商业化”。英特尔(Altera)和Xilinx是唯一从销售FPGA中受益的公司，所以你不会听到太多关于它们的消息，但AWS有FPGA实例，你可以在FPGA上获得的I/O非常疯狂。</p><p id="4828" class="pw-post-body-paragraph jl jm iq jn b jo kt jq jr js ku ju jv iy kv jx jy jc kw ka kb jg kx kd ke kf ij bi translated">早在2011年，我和我的合作者在FPGAs上构建了定制处理器，以加速神经网络计算。那时我们真的很喜欢<a class="ae ks" href="https://en.wikipedia.org/wiki/Bidirectional_associative_memory" rel="noopener ugc nofollow" target="_blank">双向</a>和<a class="ae ks" href="https://www.eriksmistad.no/hopfield-network/" rel="noopener ugc nofollow" target="_blank"> Hopfield </a>联想记忆神经网络(无监督学习)，而今天我们使用更多的监督学习方法，如DNNs、CNN和RNNs。简而言之，在监督学习下，你可以在大多数问题上获得更好的结果。</p><div class="ky kz gp gr la lb"><a href="http://ieeexplore.ieee.org/document/5873060/?reload=true&amp;arnumber=5873060" rel="noopener  ugc nofollow" target="_blank"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd lg gy z fp lh fr fs li fu fw lj bi translated">人工神经网络专用集成电路芯片- IEEE会议出版物</h2><div class="lk l"><h3 class="bd b gy z fp lh fr fs li fu fw dk translated">被称为ASIPs的定制专用处理器在当代嵌入式系统中越来越常见…</h3></div><div class="ll l"><p class="bd b dl z fp lh fr fs li fu fw dk translated">ieeexplore.ieee.org</p></div></div></div></a></div><p id="829a" class="pw-post-body-paragraph jl jm iq jn b jo kt jq jr js ku ju jv iy kv jx jy jc kw ka kb jg kx kd ke kf ij bi translated">在另一篇论文中，也是在2011年，我和我的合作者在FPGA上使用查找表来加速神经网络遇到的最常见的计算。</p><div class="ky kz gp gr la lb"><a href="http://ieeexplore.ieee.org/document/6030491/?arnumber=6030491" rel="noopener  ugc nofollow" target="_blank"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd lg gy z fp lh fr fs li fu fw lj bi translated">使用自定义指令在FPGA上加速人工神经网络- IEEE会议…</h2><div class="lk l"><h3 class="bd b gy z fp lh fr fs li fu fw dk translated">在本文中，我们提出了加速一个预训练前馈人工神经网络执行NIOS…</h3></div><div class="ll l"><p class="bd b dl z fp lh fr fs li fu fw dk translated">ieeexplore.ieee.org</p></div></div></div></a></div><p id="a6c6" class="pw-post-body-paragraph jl jm iq jn b jo kt jq jr js ku ju jv iy kv jx jy jc kw ka kb jg kx kd ke kf ij bi translated">这些方法今天仍然适用。你甚至可以嵌入，花100美元买一个小小的并行板，把一个小的神经网络直接映射到系统上的FPGA中。它有一个ARM9处理器，运行linux，并且有一个16 CPU的片上网络用于协同处理。主要的缺点是，如果你推得太用力，这种信用卡大小的超级计算机不会真的熔化和着火，但在许多情况下，芯片会因受热而损坏自己，即使有被动散热器。</p><div class="ky kz gp gr la lb"><a href="https://www.parallella.org/board/" rel="noopener  ugc nofollow" target="_blank"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd lg gy z fp lh fr fs li fu fw lj bi translated">平行游戏攻略</h2><div class="lk l"><h3 class="bd b gy z fp lh fr fs li fu fw dk translated">Parallella计算机是一款高性能、信用卡大小的计算机，基于来自…的Epiphany多核芯片</h3></div><div class="ll l"><p class="bd b dl z fp lh fr fs li fu fw dk translated">www.parallella.org</p></div></div><div class="lm l"><div class="ln l lo lp lq lm lr km lb"/></div></div></a></div><p id="9d34" class="pw-post-body-paragraph jl jm iq jn b jo kt jq jr js ku ju jv iy kv jx jy jc kw ka kb jg kx kd ke kf ij bi translated">好吧，也许我是杞人忧天。这里是一个<a class="ae ks" href="https://www.youtube.com/watch?v=ikBdR1C59u8" rel="noopener ugc nofollow" target="_blank">树莓pi散热器讨论</a>少了很多闪光灯。<a class="ae ks" href="https://www.youtube.com/watch?v=e6okZKRwnTQ" rel="noopener ugc nofollow" target="_blank">多一个为好</a>。在我关于神经网络的工作中，我们在AWS中为大多数项目使用p实例GPU。对于我接触过的客户来说，FPGAs的定制性太强了。而且没有好的简单方法将Keras连接到FPGA。哦好吧。</p><p id="3772" class="pw-post-body-paragraph jl jm iq jn b jo kt jq jr js ku ju jv iy kv jx jy jc kw ka kb jg kx kd ke kf ij bi translated">我将留给你们一段勇敢的黑客用过热的CPU烹饪香肠的视频:</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="ls lt l"/></div></figure><p id="17b5" class="pw-post-body-paragraph jl jm iq jn b jo kt jq jr js ku ju jv iy kv jx jy jc kw ka kb jg kx kd ke kf ij bi translated">如果你喜欢这篇关于人工智能的文章，那么请尝试一下<strong class="jn lg">拍手工具</strong>。跟着我们走。去吧。我也很高兴在评论中听到你的反馈。你怎么想呢?</p><p id="77b4" class="pw-post-body-paragraph jl jm iq jn b jo kt jq jr js ku ju jv iy kv jx jy jc kw ka kb jg kx kd ke kf ij bi translated">编码快乐！</p><p id="d405" class="pw-post-body-paragraph jl jm iq jn b jo kt jq jr js ku ju jv iy kv jx jy jc kw ka kb jg kx kd ke kf ij bi translated">——丹尼尔<br/> <a class="ae ks" href="mailto:daniel@lemay.ai" rel="noopener ugc nofollow" target="_blank">丹尼尔@lemay.ai </a> ←打个招呼。<br/><a class="ae ks" href="https://lemay.ai" rel="noopener ugc nofollow" target="_blank">LEMAY . AI</a><br/>1(855)LEMAY-AI</p><p id="8427" class="pw-post-body-paragraph jl jm iq jn b jo kt jq jr js ku ju jv iy kv jx jy jc kw ka kb jg kx kd ke kf ij bi translated">您可能喜欢的其他文章:</p><ul class=""><li id="167e" class="lu lv iq jn b jo kt js ku iy lw jc lx jg ly kf lz ma mb mc bi translated"><a class="ae ks" rel="noopener" target="_blank" href="/artificial-intelligence-and-bad-data-fbf2564c541a">人工智能和不良数据</a></li><li id="d59c" class="lu lv iq jn b jo md js me iy mf jc mg jg mh kf lz ma mb mc bi translated"><a class="ae ks" rel="noopener" target="_blank" href="/artificial-intelligence-hyperparameters-48fa29daa516">人工智能:超参数</a></li><li id="4172" class="lu lv iq jn b jo md js me iy mf jc mg jg mh kf lz ma mb mc bi translated"><a class="ae ks" href="https://medium.com/towards-data-science/artificial-intelligence-get-your-users-to-label-your-data-b5fa7c0c9e00" rel="noopener">人工智能:让你的用户给你的数据贴上标签</a></li></ul></div></div>    
</body>
</html>