<html>
<head>
<title>Building a book Recommendation System using Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Keras 构建图书推荐系统</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-book-recommendation-system-using-keras-1fba34180699?source=collection_archive---------8-----------------------#2018-11-22">https://towardsdatascience.com/building-a-book-recommendation-system-using-keras-1fba34180699?source=collection_archive---------8-----------------------#2018-11-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6000" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何使用嵌入创建图书推荐系统？</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e98432030e045e1657bd00232513e48c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6KkbjNMw7WwRGm8I"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Figure 1: Photo by <a class="ae kv" href="https://unsplash.com/@brandi1?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Brandi Redd</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="3843" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">推荐系统试图预测用户在给出其旧的项目评级或偏好的情况下将给予项目的评级或偏好。几乎每个大公司都使用推荐系统来提高他们的服务质量。</p><p id="ad6a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文中，我们将看看如何使用嵌入来创建图书推荐系统。</p><p id="e213" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于我们的数据，我们将使用<a class="ae kv" href="https://www.kaggle.com/zygmunt/goodbooks-10k" rel="noopener ugc nofollow" target="_blank"> goodbooks-10k 数据集</a>，其中包含一万本不同的书籍和大约一百万个评级。它有三个特性 book_id、user_id 和 rating。如果你不想自己从 Kaggle 下载数据集，你可以从<a class="ae kv" href="https://github.com/TannerGilbert/Tutorials/blob/master/Recommendation%20System/Recommendation%20System.ipynb" rel="noopener ugc nofollow" target="_blank">我的 Github 库</a>获得文件以及本文中的完整代码。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="d44d" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">把...嵌入</h1><p id="ba21" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">嵌入是从离散对象到连续值向量的映射，比如我们的例子中的单词或书籍的 id。这可用于查找离散对象之间的相似性，如果模型不使用嵌入层，这些相似性对模型来说是不明显的。</p><p id="daad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">嵌入向量是低维的，并且在训练网络时被更新。下图显示了使用<a class="ae kv" href="http://projector.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> Tensorflows 嵌入投影仪</a>创建的嵌入示例。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/4d700d9e9f1acf092877321189c105f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0-Yt0qZ38wpGFEsd"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Figure 2: Projector Embeddings</figcaption></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="b8b4" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">获取数据</h1><p id="ff0f" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">熊猫将用于数据集中的加载。然后，数据将被分成一个训练和测试集，我们将创建两个变量，为我们提供唯一的用户和图书数量。</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="ecc1" class="nc ma iq my b gy nd ne l nf ng">dataset = pd.read_csv('ratings.csv')<br/>train, test = train_test_split(dataset, test_size=0.2, random_state=42)<br/>n_users = len(dataset.user_id.unique())<br/>n_books = len(dataset.book_id.unique())</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/febec4c5a57e9406fa9d7ab25a0aa746.png" data-original-src="https://miro.medium.com/v2/resize:fit:386/format:webp/1*IHH2-AvqWlmWkD95zxYMow.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Figure 3: Rating-Dataset Head</figcaption></figure><p id="8b55" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据集已经被清理，所以我们不需要采取任何进一步的数据清理或预处理步骤。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="f26c" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">创建嵌入模型</h1><p id="592b" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated"><a class="ae kv" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras 深度学习框架</a>使得创建神经网络嵌入以及使用多个输入和输出层变得容易。</p><p id="20bf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的模型将具有以下结构:</p><ol class=""><li id="49ea" class="ni nj iq ky b kz la lc ld lf nk lj nl ln nm lr nn no np nq bi translated"><strong class="ky ir">输入:</strong>书籍和用户的输入</li><li id="1d6c" class="ni nj iq ky b kz nr lc ns lf nt lj nu ln nv lr nn no np nq bi translated"><strong class="ky ir">嵌入层:</strong>书籍和用户的嵌入</li><li id="6c7e" class="ni nj iq ky b kz nr lc ns lf nt lj nu ln nv lr nn no np nq bi translated"><strong class="ky ir">点:</strong>使用点积合并嵌入</li></ol><p id="ecf8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在嵌入模型中，嵌入是在训练期间学习的权重。这些嵌入不仅可以用于提取关于数据的信息，还可以被提取和可视化。</p><p id="1e74" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">出于简单的原因，我没有在最后添加任何完全连接的层，尽管这可能会增加相当多的准确性。因此，如果你想要一个更准确的模型，这是可以尝试的。</p><p id="a66c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是创建模型的代码:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="ffb6" class="nc ma iq my b gy nd ne l nf ng">from keras.layers import Input, Embedding, Flatten, Dot, Dense<br/>from keras.models import Model</span><span id="1d59" class="nc ma iq my b gy nw ne l nf ng">book_input = Input(shape=[1], name="Book-Input")<br/>book_embedding = Embedding(n_books+1, 5, name="Book-Embedding")(book_input)<br/>book_vec = Flatten(name="Flatten-Books")(book_embedding)</span><span id="4435" class="nc ma iq my b gy nw ne l nf ng">user_input = Input(shape=[1], name="User-Input")<br/>user_embedding = Embedding(n_users+1, 5, name="User-Embedding")(user_input)<br/>user_vec = Flatten(name="Flatten-Users")(user_embedding)</span><span id="db09" class="nc ma iq my b gy nw ne l nf ng">prod = Dot(name="Dot-Product", axes=1)([book_vec, user_vec])<br/>model = Model([user_input, book_input], prod)<br/>model.compile('adam', 'mean_squared_error')</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="8e90" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">训练模型</h1><p id="823b" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">现在我们已经创建了我们的模型，我们准备训练它。因为我们有两个输入层(一个用于书籍，一个用于用户)，所以我们需要指定一个训练数据数组作为我们的 x 数据。对于本文，我训练了 10 个时期的模型，但是如果你想得到更好的结果，你可以训练更长的时间。</p><p id="027a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下是培训代码:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="e868" class="nc ma iq my b gy nd ne l nf ng">history = model.fit([train.user_id, train.book_id], train.rating, epochs=10, verbose=1)<br/>model.save('regression_model.h5')</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="db3f" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">可视化嵌入</h1><p id="639f" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">嵌入可以用来可视化概念，比如我们案例中不同书籍之间的关系。为了可视化这些概念，我们需要使用降维技术进一步降低维度，如<a class="ae kv" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank">主成分分析(PSA) </a>或<a class="ae kv" href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" rel="noopener ugc nofollow" target="_blank">t-分布式随机邻居嵌入(TSNE) </a>。</p><p id="e3b2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从 10000 个维度(每本书一个)开始，我们使用嵌入将它们映射到 5 个维度，然后使用 PCA 或 TSNE 将它们进一步映射到 2 个维度。</p><p id="a25f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，我们需要使用<em class="nx"> get_layer </em>函数提取嵌入内容:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="c3dc" class="nc ma iq my b gy nd ne l nf ng"># Extract embeddings<br/>book_em = model.get_layer('Book-Embedding')<br/>book_em_weights = book_em.get_weights()[0]</span></pre><p id="e894" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们将使用 PCA 将我们的嵌入转换为二维，然后使用<a class="ae kv" href="https://seaborn.pydata.org/" rel="noopener ugc nofollow" target="_blank"> Seaborn </a>散布结果:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="4149" class="nc ma iq my b gy nd ne l nf ng">from sklearn.decomposition import PCA<br/>import seaborn as sns</span><span id="f7a8" class="nc ma iq my b gy nw ne l nf ng">pca = PCA(n_components=2)<br/>pca_result = pca.fit_transform(book_em_weights)<br/>sns.scatterplot(x=pca_result[:,0], y=pca_result[:,1])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/db6328ba3e1027feadede6c4648b8dfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/0*NYcnEHv5FQLNixMV"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Figure 4: Visualizing embeddings with PCA</figcaption></figure><p id="8b1e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用 TSNE 也可以做到这一点:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="7a5f" class="nc ma iq my b gy nd ne l nf ng">from sklearn.manifold import TSNE</span><span id="709a" class="nc ma iq my b gy nw ne l nf ng">tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)<br/>tnse_results = tsne.fit_transform(book_em_weights)<br/>sns.scatterplot(x=tnse_results[:,0], y=tnse_results[:,1])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/325913236ab162d07e4f7995c3b6f426.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/0*8vsEn6iLNOPmwDH8"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Figure 5: Visualizing embeddings with TSNE</figcaption></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="2be2" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">提出建议</h1><p id="3ee7" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">使用我们训练过的模型进行推荐很简单。我们只需要输入一个用户和所有的书，然后选择对这个特定用户有最高预测评分的书。</p><p id="a2fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面的代码显示了为特定用户进行预测的过程:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="3080" class="nc ma iq my b gy nd ne l nf ng"># Creating dataset for making recommendations for the first user<br/>book_data = np.array(list(set(dataset.book_id)))<br/>user = np.array([1 for i in range(len(book_data))])<br/>predictions = model.predict([user, book_data])<br/>predictions = np.array([a[0] for a in predictions])<br/>recommended_book_ids = (-predictions).argsort()[:5]<br/>print(recommended_book_ids)<br/>print(predictions[recommended_book_ids])</span></pre><p id="f888" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此代码输出:</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="a244" class="nc ma iq my b gy nd ne l nf ng">array([4942, 7638, 8853, 9079, 9841], dtype=int64)<br/>array([5.341809 , 5.159592 , 4.9970446, 4.9722786, 4.903894 ], dtype=float32)</span></pre><p id="d15b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以使用图书 id，通过使用<em class="nx"> books.csv </em>文件来获得关于图书的更多信息。</p><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="11ed" class="nc ma iq my b gy nd ne l nf ng">books = pd.read_csv(‘books.csv’)<br/>books.head()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/e730702466e9b6c3705369d167be661c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*1Iti3XItw5YJCmCiy1oCLw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Figure 6: Book-Dataset Head</figcaption></figure><pre class="kg kh ki kj gt mx my mz na aw nb bi"><span id="893e" class="nc ma iq my b gy nd ne l nf ng">print(books[books[‘id’].isin(recommended_book_ids)])</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/e841e0943c2f6d45e7f6082a4e242655.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h2fmK7C2NC_lB62pHEUpPw.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Figure 7: Recommended books</figcaption></figure></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="3eaf" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">结论</h1><p id="2e0c" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">嵌入是一种从离散对象(如单词)到连续值向量的映射方法。它们对于寻找相似性、可视化目的以及作为另一个机器学习模型的输入是有用的。</p><p id="5970" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个例子当然不是完美的，为了获得更好的性能，可以尝试很多方法。但是对于更高级的问题，这是学习如何使用嵌入的一个很好的起点。</p><p id="86a1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以添加一些东西来获得更好的结果:</p><ul class=""><li id="a207" class="ni nj iq ky b kz la lc ld lf nk lj nl ln nm lr oc no np nq bi translated">在点积后添加完全连接的层</li><li id="d246" class="ni nj iq ky b kz nr lc ns lf nt lj nu ln nv lr oc no np nq bi translated">为更多时代而训练</li><li id="6c11" class="ni nj iq ky b kz nr lc ns lf nt lj nu ln nv lr oc no np nq bi translated">缩放评级栏</li><li id="bc70" class="ni nj iq ky b kz nr lc ns lf nt lj nu ln nv lr oc no np nq bi translated">等等。</li></ul><p id="651f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你喜欢这篇文章，可以考虑订阅我的 Youtube 频道并在社交媒体上关注我。</p><p id="a69c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你有任何问题或批评，可以通过<a class="ae kv" href="https://twitter.com/Tanner__Gilbert" rel="noopener ugc nofollow" target="_blank"> Twitter </a>或评论区联系我。</p></div></div>    
</body>
</html>