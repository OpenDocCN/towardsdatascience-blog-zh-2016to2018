<html>
<head>
<title>Wide Residual Networks with Interactive Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有交互代码的宽剩余网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/wide-residual-networks-with-interactive-code-f9ef6b0bab29?source=collection_archive---------9-----------------------#2018-05-24">https://towardsdatascience.com/wide-residual-networks-with-interactive-code-f9ef6b0bab29?source=collection_archive---------9-----------------------#2018-05-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/9a46aecfc6ba01a2e4ac112849208d3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/1*xbULpRjPHP0RXtCf6KF0TQ.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Gif from this <a class="ae jy" href="https://giphy.com/gifs/highway-xdUIwnITXl3OM" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="853c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我的期末考试终于结束了，我想通过实现 wide res net 来庆祝一下。此外，这将是一个很短的帖子，因为我想回到写博客的心情，希望我不会让你失望！</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><figure class="le lf lg lh gt jr"><div class="bz fp l di"><div class="li lj l"/></div></figure></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="763b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">广残网</strong></p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lk"><img src="../Images/0d08ab5c0f9c86818a88efc5afc64471.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h5NBLevU5XkWedeXgn3jdw.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image from this <a class="ae jy" href="http://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="d28d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">红框</strong> →卷积神经网络中增加的特征图数量</p><p id="8593" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">该论文的作者称之为宽残差网络的主要原因是由于每一层的特征地图大小的增加。如上所述，当我指的是特征图大小时，我指的是在每个卷积层上创建的通道数，但是，请记住，该特征图大小也可以减小。</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="9da3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">网络架构(层/全/面向对象)</strong></p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lp"><img src="../Images/e07356eba2907ef9617d8c962a8ed393.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ooJgZdRenFun-96qOYoFVA.png"/></div></div></figure><p id="9825" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">红框</strong> →我们要实现的网络层。</p><p id="b0a9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">每一层与传统的残差网络几乎相同，然而如上所述，特征图的数量已经增加。现在，让我们来看看我们将要使用的完整网络体系结构。另外，请注意，上图中没有显示批处理规范化和 ReLu()激活。</p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lq"><img src="../Images/3c6ae32b3a4782e9912f3cbd05ec5edb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SfgpYdDQOrYppwjIYVRVNw.png"/></div></div></figure><p id="4b97" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">以上是我们将要实施的完整网络架构，我们可以观察到两个变量，即 N 和 k。这里 k 是我们希望每层的特征图增加多少，N 是每层中卷积块的数量。因此，对于我们的网络，我将 N 设置为 1，K 设置为 8，因此我们的网络只有 8 层，但每层都有许多特征地图。现在让我们看看网络的 OOP 形式。</p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/227ec30db6cbc000c0247e1520c42fc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:492/format:webp/1*tkeuv7TA2nEYBk6H0M_F2w.png"/></div></figure><p id="9c1d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，网络本身并不深，但是我们可以观察到每一层都有大量的要素地图。</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="07d8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">优化</strong></p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi ls"><img src="../Images/ad95ae834268ba55b0eff91ac284d043.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3iNoPt-uM3-Q2iY6-6hoEA.png"/></div></div></figure><p id="3cff" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">正如上文所见，原始论文使用了具有内斯特罗夫动量的 SGD，对我来说，我将使用 ADAM，当然这将使模型过度拟合训练数据，有关此主题的更多信息请单击此处<a class="ae jy" href="https://shaoanlu.wordpress.com/2017/05/29/sgd-all-which-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/" rel="noopener ugc nofollow" target="_blank">。</a></p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="918f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果</strong></p><div class="le lf lg lh gt ab cb"><figure class="lt jr lu lv lw lx ly paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/6c31104fcec892ab858712572a1dec1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Z8H_TrsDZZoIu7NsBrRxsg.png"/></div></figure><figure class="lt jr lu lv lw lx ly paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/a25146228023ed9ad91e984fe6a13618.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*LSGEdeMd-wbMv-kjNiclRg.png"/></div></figure></div><div class="ab cb"><figure class="lt jr lu lv lw lx ly paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/55d596592d48359d62b232d623ebaf45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*58qsZ0z4i1Ga7X96qgg66w.png"/></div></figure><figure class="lt jr lu lv lw lx ly paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/c2146767cc72696380af2d8be4feda08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*R09iccKIWTt8en1v4tUYhQ.png"/></div></figure></div><p id="f529" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左上</strong> →训练精度随时间变化<br/> <strong class="kb ir">右上</strong> →训练成本随时间变化<br/> <strong class="kb ir">左下</strong> →测试精度随时间变化<br/> <strong class="kb ir">右下</strong> →测试成本随时间变化</p><p id="40de" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">考虑到 CIFAR 10 数据集由 50000 幅训练图像和 10000 幅测试图像组成，我们的 8 层宽 Resnet 仅在训练图像上表现良好。然而，我们可以清楚地观察到，该模型已经过度拟合于训练数据。(测试图像的最佳准确度只有 17%。)</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="5ed8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">互动代码/透明度</strong></p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lz"><img src="../Images/8dc3deaf6729d001be42f8ba16cca276.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7RCcWmn14UxtfBQNTE2jZA.png"/></div></div></figure><p id="efd0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于 Google Colab，你需要一个 Google 帐户来查看代码，而且你不能在 Google Colab 中运行只读脚本，所以在你的操场上复制一份。最后，我永远不会请求允许访问你在 Google Drive 上的文件，仅供参考。编码快乐！</p><p id="c140" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">要获取这篇<a class="ae jy" href="https://colab.research.google.com/drive/1Db64YnpnZwG3zjulRC8spKuonmHQipaE" rel="noopener ugc nofollow" target="_blank">文章的代码，请点击这里。</a></p><p id="ae26" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">为了让这个实验更加透明，我已经将我的命令窗口的所有输出上传到我的 Github，要从我的 cmd <a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/WideResNet/wide_res.txt" rel="noopener ugc nofollow" target="_blank">访问输出，请点击这里。</a></p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="67bd" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">最后的话</strong></p><p id="7c21" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">看到结果令人失望，但我很有信心用正确的正则化技术，这个网络会表现得更好。</p><p id="402f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 给我，如果你想看我所有写作的列表，请在这里查看我的网站。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的 twitter <a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，并访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。如果你感兴趣的话，我还做了解耦神经网络的比较。</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="aa38" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="638c" class="mb mc iq kb b kc kd kg kh kk md ko me ks mf kw mg mh mi mj bi translated">Zagoruyko 和 n . Komodakis(2016 年)。广泛的剩余网络。arXiv 预印本 arXiv:1605.07146 。</li><li id="37de" class="mb mc iq kb b kc mk kg ml kk mm ko mn ks mo kw mg mh mi mj bi translated">神经网络 PyTorch 教程 0.4.0 文档。(2018).Pytorch.org。检索于 2018 年 4 月 27 日，来自<a class="ae jy" href="http://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html" rel="noopener ugc nofollow" target="_blank">http://py torch . org/tutorials/beginner/blitz/neural _ networks _ tutorial . html</a></li><li id="3e5c" class="mb mc iq kb b kc mk kg ml kk mm ko mn ks mo kw mg mh mi mj bi translated">SGD &gt;亚当？？哪一个是最好的优化程序:狗对猫玩具实验。(2017).萨卢。检索于 2018 年 4 月 27 日，来自<a class="ae jy" href="https://shaoanlu.wordpress.com/2017/05/29/sgd-all-which-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/" rel="noopener ugc nofollow" target="_blank">https://Shao anlu . WordPress . com/2017/05/29/SGD-all-the-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/</a></li><li id="cefc" class="mb mc iq kb b kc mk kg ml kk mm ko mn ks mo kw mg mh mi mj bi translated">CIFAR-10 和 CIFAR-100 数据集。(2018).Cs.toronto.edu。检索于 2018 年 4 月 27 日，来自<a class="ae jy" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank">https://www.cs.toronto.edu/~kriz/cifar.html</a></li></ol></div></div>    
</body>
</html>