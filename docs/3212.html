<html>
<head>
<title>Yet Another Twitter Sentiment Analysis Part 1 — tackling class imbalance</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">另一个推特情绪分析第一部分——解决阶级不平衡</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/yet-another-twitter-sentiment-analysis-part-1-tackling-class-imbalance-4d7a7f717d44?source=collection_archive---------2-----------------------#2018-04-20">https://towardsdatascience.com/yet-another-twitter-sentiment-analysis-part-1-tackling-class-imbalance-4d7a7f717d44?source=collection_archive---------2-----------------------#2018-04-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/a78224c946bde26a3f6fb4621d3b75f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Dik9foW_TafeNcPD"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo by <a class="ae kc" href="https://unsplash.com/@saltsup?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Piret Ilver</a> on <a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="ae58" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不久前，我在Twitter情绪分析上完成了11篇系列博文。为什么我要再做一次情感分析？我想进一步扩展，对真实检索的推文进行情感分析。我之前的情感分析项目还有其他限制。</p><ol class=""><li id="15bd" class="lb lc iq kf b kg kh kk kl ko ld ks le kw lf la lg lh li lj bi translated">该项目停止在最终的训练模型上，并且缺乏对检索到的推文的模型应用</li><li id="b89c" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">该模型仅在正面和负面类别上训练，因此它缺乏预测中性类别的能力</li></ol><p id="3ce4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">关于中性类别，可以为负面、中性和正面类别设置阈值，并将最终输出概率值映射到三个类别中的一个，但我想用训练数据训练一个模型，该模型有三个情感类别:负面、中性和正面。</p><p id="100d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为我已经写了一个相当长的关于NLP，情感分析的系列文章，如果一个概念已经在我以前的文章中提到过，我就不详细解释了。此外，主要的数据可视化将与检索到的tweets有关，我不会对我用于训练和测试模型的数据进行大量的数据可视化。</p><p id="c7ff" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">除了我将附上的简短代码块，你可以在这篇文章的末尾找到整个Jupyter笔记本的链接。</p><h1 id="8104" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">数据</h1><p id="fbff" class="pw-post-body-paragraph kd ke iq kf b kg mo ki kj kk mp km kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">为了训练我的情感分类器，我需要一个满足以下条件的数据集。</p><ul class=""><li id="913f" class="lb lc iq kf b kg kh kk kl ko ld ks le kw lf la mt lh li lj bi translated">优选地，推特带有注释情感标签的文本数据</li><li id="be32" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la mt lh li lj bi translated">有3个情绪等级:消极，中立，积极</li><li id="fd4b" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la mt lh li lj bi translated">大到可以训练一个模特</li></ul><p id="e182" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我在谷歌上寻找一个好的数据源时，我了解到了一个著名的NLP竞赛，叫做SemEval。<a class="ae kc" href="http://alt.qcri.org/semeval2017/" rel="noopener ugc nofollow" target="_blank"> SemEval(语义评估)是正在进行的一系列计算语义分析系统的评估，由SIGLEX组织，SIGLEX是计算语言学协会词汇方面的特别兴趣小组。</a></p><p id="a593" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你对NLP感兴趣，你可能已经听说过这个。来自世界各地的高技能团队在几个任务上竞争，例如“语义文本相似度”、“多语言语义单词相似度”等。比赛任务之一是推特情感分析。它也有几个子任务，但我想重点关注的是“<a class="ae kc" href="http://alt.qcri.org/semeval2017/task4/" rel="noopener ugc nofollow" target="_blank">子任务a .:消息极性分类:给定一条消息，分类该消息是正面、负面还是中性情绪</a>”。</p><p id="0006" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">幸运的是，他们为比赛提供的数据集<a class="ae kc" href="http://alt.qcri.org/semeval2017/task4/index.php?id=data-and-tools" rel="noopener ugc nofollow" target="_blank">可供下载</a>。训练数据由SemEval之前的训练和测试数据组成。更棒的是他们提供测试数据，所有参赛的队伍都是用同样的测试数据打分。这意味着我可以将我的模型性能与2017年SemEval的参与者进行比较。</p><p id="4806" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我先下载了SemEval 2017 Task 4的<a class="ae kc" href="http://alt.qcri.org/semeval2017/task4/index.php?id=download-the-full-training-data-for-semeval-2017-task-4" rel="noopener ugc nofollow" target="_blank">全训数据</a>。</p><p id="fc02" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">总共有11个txt文件，跨度从SemEval 2013到SemEval 2016。当试图将文件读入熊猫数据帧时，我发现两个文件不能作为tsv文件正确加载。似乎有一些条目没有正确地用制表符分隔，所以最终会有10条或更多的推文粘在一起。我本来可以尝试用提供的tweet ID来检索它们，但是我决定先忽略这两个文件，用9个txt文件组成一个训练集。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="86a9" class="nd lr iq mz b gy ne nf l ng nh">import pandas as pd  <br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>plt.style.use('fivethirtyeight')</span><span id="1da2" class="nd lr iq mz b gy ni nf l ng nh">%matplotlib inline<br/>%config InlineBackend.figure_format = 'retina'</span></pre><p id="d7d4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦我导入了基本的依赖项，我将把数据读入熊猫数据框架。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="dac7" class="nd lr iq mz b gy ne nf l ng nh">import glob<br/>path ='Subtask_A/'<br/>all_files = glob.glob(path + "/twitter*.txt")<br/>frame = pd.DataFrame()<br/>list_ = []<br/>for file_ in all_files:<br/>    df = pd.read_csv(file_,index_col=None, sep='\t', header=None, names=['id','sentiment','text','to_delete'])<br/>    list_.append(df.iloc[:,:-1])<br/>df = pd.concat(list_)</span><span id="9d73" class="nd lr iq mz b gy ni nf l ng nh">df = df.drop_duplicates()<br/>df = df.reset_index(drop=True)<br/>df.tail()</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nj"><img src="../Images/c7ab9d1787a75339e02483809c33ba99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ix0OCIENN_1IpcRJnFsXqQ.png"/></div></div></figure><p id="560f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据集看起来相当简单，有单独的tweet ID、情感标签和tweet文本。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="82de" class="nd lr iq mz b gy ne nf l ng nh">df.info()</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nk"><img src="../Images/8d6cf5646d1e9399e1d05ecaa6c83a06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zhB3mOuoR_n8_c6ydKqAlw.png"/></div></div></figure><p id="989f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">总共有41705条推文。作为另一项健全性检查，让我们看看每条推文中有多少单词。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="0004" class="nd lr iq mz b gy ne nf l ng nh">df['token_length'] = [len(x.split(" ")) for x in df.text]<br/>max(df.token_length)</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nl"><img src="../Images/a4adbeaf4511ff9734fbca976e6d2241.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*08fBOXRhQ-uF4r9AmMVeLA.png"/></div></div></figure><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="9d5a" class="nd lr iq mz b gy ne nf l ng nh">df.loc[df.token_length.idxmax(),'text']</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nm"><img src="../Images/d35e9eea89f6d757c765c99445799839.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XUcuIeIlXMtW7OBq4BOeyA.png"/></div></div></figure><p id="019b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好的，令牌长度看起来很好，最大令牌长度的tweet看起来像是一个正确解析的tweet。让我们来看看数据的类别分布。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="2063" class="nd lr iq mz b gy ne nf l ng nh">df.sentiment.value_counts()</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nn"><img src="../Images/829fa6ea76c438156a1157b62a40d2b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1et1gdypV8j_CK7hd7Jp9w.png"/></div></div></figure><p id="2be0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据不平衡，负类的数据条目最少，为6，485个，中性类的数据条目最多，为19，466个。我想重新平衡数据，这样我至少在训练时会有一个平衡的数据集。我将在定义清洗函数后处理这个问题。</p><h1 id="ccc1" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">数据清理</h1><p id="af14" class="pw-post-body-paragraph kd ke iq kf b kg mo ki kj kk mp km kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">数据清理过程与我之前的项目类似，但这次我添加了一个很长的收缩列表，以将大多数收缩形式扩展为其原始形式如“不要”到“不要”。这一次，我使用Spacy而不是Regex来解析文档，并过滤数字、URL、标点符号等。以下是我清理推文的步骤。</p><ol class=""><li id="c91f" class="lb lc iq kf b kg kh kk kl ko ld ks le kw lf la lg lh li lj bi translated">解码:unicode字符前的多余“\”的unicode_escape，然后是unidecode</li><li id="bd95" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">撇号处理:人们用两个字符来表示缩写。“'”(撇号)和“'”(单引号)。如果这两个符号都用于收缩，将很难检测和正确映射正确的展开形式。所以任何“'”(撇号)都改成“'”(单引号)</li><li id="326d" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">收缩检查:检查是否有收缩形式，并将其替换为原始形式</li><li id="ec42" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">解析:已完成空间解析</li><li id="97a7" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">使用Spacy方法过滤标点、空格、数字、URL，同时保持hashtag的文本内容完整</li><li id="c6ac" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">移除@提及</li><li id="c94f" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">Lemmatize:使用Spacy方法对每个标记进行lemma tize。引理_ '。代词保持原样，因为Spacy lemmatizer将每个代词转换为“-PRON-”</li><li id="ade1" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">特殊字符删除</li><li id="00b9" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">单音节标记去除</li><li id="3eba" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">拼写纠正:这是一个简单的拼写纠正，处理重复的字符，如“sooooo goooood”。如果同一个字符重复出现两次以上，它会将重复次数缩短为两次。例如,“sooooo goooood”将被转换为“soo good”。这不是一个完美的解决方案，因为即使在纠正之后，在“soo”的情况下，它也不是正确的拼写。但是通过将“sooo”、“sooo”、“sooooo”变成同一个单词“soo ”,至少有助于减少特征空间</li></ol><figure class="mu mv mw mx gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="mu mv mw mx gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="4575" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好了，现在让我们看看这个自定义清理器是如何处理推文的。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="7314" class="nd lr iq mz b gy ne nf l ng nh">pd.set_option('display.max_colwidth', -1)<br/>df.text[:10]</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nq"><img src="../Images/5fcc4c043816736e0199ec02ad2d4c58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hlm_nDmImSchJABmM-jKYQ.png"/></div></div></figure><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="2308" class="nd lr iq mz b gy ne nf l ng nh">[spacy_cleaner(t) for t in df.text[:10]]</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nr"><img src="../Images/43ee5a5b674286d96cb83dc64c162960.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CTStPb-h_BH3Y8Ly5MlhDw.png"/></div></div></figure><p id="9ce2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">看起来它正在做我想让它做的事情。我将清理“text”列，并创建一个名为“clean_text”的新列。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="31e6" class="nd lr iq mz b gy ne nf l ng nh">df['clean_text'] = [spacy_cleaner(t) for t in df.text]</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ns"><img src="../Images/df3ad3bbc979bf32b7b26a454e2036ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NnmLTg_DbUU8OPef9rDjPg.png"/></div></div></figure><p id="72eb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过运行清理功能，我可以看到它遇到了一些“无效的转义序列”。让我们看看这些是什么。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="9494" class="nd lr iq mz b gy ne nf l ng nh">for i,t in enumerate(df.text):<br/>    if '\m' in t:<br/>        print(i,t)</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nm"><img src="../Images/e7b54fc809f1db9405c888b433156a86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pNZGa3FStoJgbCEyODY5Dw.png"/></div></div></figure><p id="a663" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">包含“\m”的推文实际上包含一个表情符号“\m/”,我在谷歌上搜索后才知道这件事。显然，<a class="ae kc" href="https://www.urbandictionary.com/define.php?term=%5Cm%2F" rel="noopener ugc nofollow" target="_blank"> '\m/'代表你用手做的喇叭手势</a>。这种手势在金属音乐中很流行。无论如何，这只是一个警告，而不是一个错误。让我们看看清洁工是如何处理这个问题的。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="2b67" class="nd lr iq mz b gy ne nf l ng nh">df.text[2064]</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nt"><img src="../Images/7a5c5b19c8e36bfbc3dd80c161968b87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tURM3BljD_l2mdnQEHkN1Q.png"/></div></div></figure><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="506f" class="nd lr iq mz b gy ne nf l ng nh">spacy_cleaner(df.text[2064])</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nu"><img src="../Images/848bc71e945a9a695b7f370a00fb1208.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4AdHxtbzTmWaAj8UAdvsVg.png"/></div></div></figure><p id="0a5c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这看起来又像是在做我想让它做的事情。到目前为止一切顺利。</p><h1 id="a9d4" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">不平衡学习</h1><p id="b57f" class="pw-post-body-paragraph kd ke iq kf b kg mo ki kj kk mp km kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">"<a class="ae kc" href="https://www3.nd.edu/~dial/publications/chawla2004editorial.pdf" rel="noopener ugc nofollow" target="_blank">在分类问题中，当某些类别的实例比其他类别多得多时，通常会出现类别不平衡问题。在这种情况下，标准分类器往往会被大类淹没，而忽略小类。</a></p><p id="3b4e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我已经意识到的，训练数据并不是完全平衡的，“中立”类的数据是“消极”类的3倍，“积极”类的数据是“消极”类的2.4倍。我将尝试用三种不同的数据拟合一个模型；过采样、下采样、原始，以了解不同的采样技术如何影响分类器的学习。</p><p id="d4ec" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我将用来比较不同数据集性能的简单默认分类器是逻辑回归。从我以前的情感分析项目中，我了解到Tf-Idf和逻辑回归是一个非常强大的组合。在我应用任何其他更复杂的模型，如人工神经网络，美国有线电视新闻网，RNN等，与逻辑回归的性能将有望给我一个好主意，我应该选择哪些数据采样方法。如果你想更多地了解Tf-Idf，以及它如何从文本中提取特征，你可以查看我的旧帖子，“另一个使用Python的Twitter情绪分析-第5部分”。</p><p id="e435" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在验证方面，我会使用K重交叉验证。在我之前的项目中，我把数据分成三份；训练、验证、测试和所有参数调整都是用保留的验证集完成的，最后将模型应用于测试集。考虑到我有超过一百万的数据用于训练，这种验证集方法是可以接受的。但是这一次，我拥有的数据要小得多(大约40，000条推文)，通过从数据中省去验证集，我们可能会省去关于数据的有趣信息。</p><h1 id="48cc" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">原始不平衡数据</h1><figure class="mu mv mw mx gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="7be5" class="nd lr iq mz b gy ne nf l ng nh">from sklearn.pipeline import Pipeline</span><span id="ddee" class="nd lr iq mz b gy ni nf l ng nh">original_pipeline = Pipeline([<br/>    ('vectorizer', tvec),<br/>    ('classifier', lr)<br/>])</span><span id="c1f5" class="nd lr iq mz b gy ni nf l ng nh">lr_cv(5, df.clean_text, df.sentiment, original_pipeline, 'macro')</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nv"><img src="../Images/7876591cadbc45d79a9fac2f05755d35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*13Mn1OMjwVv_8-3A6t4uuw.png"/></div></div></figure><p id="d390" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于没有任何重采样的数据，我们可以看到精度高于召回率。如果你想了解更多关于精确度和召回率的知识，你可以查看我的旧帖子，“T2，另一个使用Python的Twitter情绪分析——第四部分”。</p><p id="c9b2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们仔细观察每一次折叠的结果，我们还可以看到，否定类别的召回率很低，大约为28~30%，而否定类别的准确率高达61~65%。这意味着分类器非常挑剔，不认为许多事情是负面的。它归类为负面的所有文本有61~65%的时间确实是负面的。然而，它也错过了很多实际的负面类，因为它非常挑剔。我们的召回率很低，但是准确率很高。这种精确和回忆背后的直觉来自Andreas Klintberg 的<a class="ae kc" href="https://medium.com/@klintcho/explaining-precision-and-recall-c770eb9c69e9" rel="noopener">媒体博客。</a></p><h1 id="c7de" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">过采样</h1><p id="6165" class="pw-post-body-paragraph kd ke iq kf b kg mo ki kj kk mp km kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">有一个非常有用的Python包叫做“<a class="ae kc" href="https://github.com/scikit-learn-contrib/imbalanced-learn" rel="noopener ugc nofollow" target="_blank">unbalanced-Learn</a>”，它帮助你处理类不平衡问题，它与Scikit Learn兼容，并且易于实现。</p><p id="487e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在不平衡学习中，可以使用不同的技术进行过采样。我会用两个以下。</p><ol class=""><li id="9778" class="lb lc iq kf b kg kh kk kl ko ld ks le kw lf la lg lh li lj bi translated">RandomOverSampler</li><li id="93d4" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">合成少数过采样技术</li></ol><p id="5625" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果使用过采样数据进行交叉验证，还有一点需要考虑。如果在交叉验证之前过采样，过采样少数类会导致过拟合问题。为什么会这样呢？因为通过在交叉验证拆分之前进行过采样，您已经将验证数据的信息泄露给了您的训练集。就像他们说的“已经看到的，不能再看不见了。”</p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/eec82eebf1cc6ffa03cf17f4e903314d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*mH9kfU3Oq3PsXIBeCKXkYg.jpeg"/></div></figure><p id="ca8a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你想要更详细的解释，我推荐这个Youtube视频"<a class="ae kc" href="https://youtu.be/DQC_YE3I5ig" rel="noopener ugc nofollow" target="_blank">机器学习——过- &amp;欠采样——Python/Scikit/Scikit-imb learn</a>"</p><p id="3db9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">幸运的是，我在上面定义为“lr_cv()”的交叉验证函数将只适合交叉验证拆分后的训练集拆分，因此它不会向模型泄露任何验证集的信息。</p><h2 id="8d7b" class="nd lr iq bd ls nx ny dn lw nz oa dp ma ko ob oc me ks od oe mi kw of og mm oh bi translated">RandomOverSampler</h2><p id="7459" class="pw-post-body-paragraph kd ke iq kf b kg mo ki kj kk mp km kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">随机过采样只是重复少数类的一些样本并平衡数据集中类之间的样本数量的过程。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="4ad7" class="nd lr iq mz b gy ne nf l ng nh">from imblearn.pipeline import make_pipeline<br/>from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler</span><span id="9f1c" class="nd lr iq mz b gy ni nf l ng nh">ROS_pipeline = make_pipeline(tvec, RandomOverSampler(random_state=777),lr)<br/>SMOTE_pipeline = make_pipeline(tvec, SMOTE(random_state=777),lr)<br/></span></pre><p id="7963" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们安装每个管道之前，让我们看看RadomOverSampler是做什么的。为了更容易看到，我在下面定义了一些玩具文本数据，以及每个文本的目标情感值。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="c30b" class="nd lr iq mz b gy ne nf l ng nh">sent1 = "I love dogs"<br/>sent2 = "I don't like dogs"<br/>sent3 = "I adore cats"<br/>sent4 = "I hate spiders"<br/>sent5 = "I like dogs"<br/>testing_text = pd.Series([sent1, sent2, sent3, sent4, sent5])<br/>testing_target = pd.Series([1,0,1,0,1])</span></pre><p id="7b93" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我的玩具数据一共5个条目，目标情绪是三正两负。为了平衡，这个玩具数据需要多一个负类的条目。</p><p id="aa70" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一件事是采样器将无法处理原始文本数据。它必须被转换到一个特征空间，过采样器才能工作。我将首先安装tfidf矢量器，并使用文本的Tf-Idf表示进行过采样。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="37b9" class="nd lr iq mz b gy ne nf l ng nh">tv = TfidfVectorizer(stop_words=None, max_features=100000)<br/>testing_tfidf = tv.fit_transform(testing_text)<br/>ros = RandomOverSampler(random_state=777)<br/>X_ROS, y_ROS = ros.fit_sample(testing_tfidf, testing_target)<br/>pd.DataFrame(testing_tfidf.todense(), columns=tv.get_feature_names())</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oi"><img src="../Images/095bce6014b00a4e796787caf897e544.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SPCOfbVTQjx9U3vqHPKy7w.png"/></div></div></figure><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="ae7f" class="nd lr iq mz b gy ne nf l ng nh">pd.DataFrame(X_ROS.todense(), columns=tv.get_feature_names())</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oj"><img src="../Images/dd310e53e8a0b5f3a04061d73e225e72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kDugWPm0El-Rt_LMDFBlKw.png"/></div></div></figure><p id="3927" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过运行RandomOverSampler，现在我们在末尾多了一个条目。RandomOverSampler添加的最后一个条目与从顶部开始的第四个条目(索引号3)完全相同。RandomOverSampler只是重复少数类的一些条目来平衡数据。如果我们看看RandomOverSampler之后的目标情绪，我们可以看到它现在通过添加更多的负面类条目而在类之间达到了完美的平衡。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="ba88" class="nd lr iq mz b gy ne nf l ng nh">y_ROS</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ok"><img src="../Images/8180490c6af4e2a1e20226a5b027dcb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XhtVaKOzmPb7s2MHplR0gA.png"/></div></div></figure><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="bdb9" class="nd lr iq mz b gy ne nf l ng nh">lr_cv(5, df.clean_text, df.sentiment, ROS_pipeline, 'macro')</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ol"><img src="../Images/51914481458ee1333a347a828be17e93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uPkyVJPuAiDlx1So7T7SfA.png"/></div></div></figure><p id="3cae" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与用原始不平衡数据建立的模型相比，现在的模型表现相反。负类的准确率在47~49%左右，但是召回率要高得多，在64~67%之间。现在我们面临着高召回率，低准确率的局面。这意味着分类器认为很多东西是负面的。然而，它也认为大量的非否定性文本是否定性的。所以从我们的数据集中，我们得到了许多被归类为否定的文本，它们中的许多在实际否定集中，然而，它们中的许多也是非否定的。</p><p id="a3fb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是在没有重采样的情况下，负类的召回率低至28~30%,而通过重采样得到的负类的精确率在47~49%左右。</p><p id="296b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一种方法是看f1分数，它是精确度和召回率的调和平均值。原始不平衡数据的准确率为66.51%，F1值为60.01%。然而，采用过采样时，我们得到的精度略低，为65.95%，但F1值却高得多，为64.18%</p><h2 id="21c5" class="nd lr iq bd ls nx ny dn lw nz oa dp ma ko ob oc me ks od oe mi kw of og mm oh bi translated">合成少数过采样技术</h2><p id="dc7f" class="pw-post-body-paragraph kd ke iq kf b kg mo ki kj kk mp km kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">SMOTE是一种过采样方法，其中通过创建“合成”样本对少数类进行过采样，而不是通过替换进行过采样。</p><p id="c89c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据最初的研究论文“<a class="ae kc" href="https://www.jair.org/media/953/live-953-2037-jair.pdf" rel="noopener ugc nofollow" target="_blank">SMOTE:Synthetic Minority Over-sampling Technique</a>”(Chawla et al .，2002)，“合成样本以如下方式生成:取所考虑的特征向量(样本)与其最近邻之间的差。将该差乘以0和1之间的随机数，并将其添加到所考虑的特征向量中。这导致沿着两个特定特征之间的线段选择一个随机点。这种方法有效地迫使少数类的决策区域变得更普遍。”这意味着当SMOTE创建一个新的合成数据时，它将选择一个数据进行复制，并查看其k个最近的邻居。然后，在特征空间上，它将在原始样本和它的邻居之间的特征空间中创建随机值。</p><p id="3ab6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦你看到玩具数据的例子，它会变得更加清晰。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="ab4b" class="nd lr iq mz b gy ne nf l ng nh">smt = SMOTE(random_state=777, k_neighbors=1)<br/>X_SMOTE, y_SMOTE = smt.fit_sample(testing_tfidf, testing_target)<br/>pd.DataFrame(X_SMOTE.todense(), columns=tv.get_feature_names())</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi om"><img src="../Images/6e1f49688ad3e81115461f8af9a42827.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kEIXuHRAb9bmRyeHDi_PfQ.png"/></div></div></figure><p id="7395" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后一个条目是SMOTE创建的数据。为了更容易看出，我们只看负类。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="4d20" class="nd lr iq mz b gy ne nf l ng nh">pd.DataFrame(X_SMOTE.todense()[y_SMOTE == 0], columns=tv.get_feature_names())</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi on"><img src="../Images/4a3226a19ad971458d002ef276d84bfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W8vbtKsJbIZB_-57rM5UAw.png"/></div></div></figure><p id="c7ec" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面的两个条目是原始数据，下面的一个是合成数据。你可以看到它不只是重复原始数据。相反，Tf-Idf值是通过取前两个原始数据之间的随机值来创建的。如您所见，如果两个原始数据的Tf-Idf值都为0，那么合成数据的这些特征也为0，如“adore”、“cactus”、“cats”，因为如果两个值相同，则它们之间没有随机值。对于这个玩具数据，我特意将k_neighbors定义为1，因为只有两个负类条目，如果SMOTE选择一个进行复制，那么就只剩下一个其他的负类条目作为邻居。</p><p id="634c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在让我们来拟合SMOTE管道，看看它如何影响性能。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="0496" class="nd lr iq mz b gy ne nf l ng nh">lr_cv(5, df.clean_text, df.sentiment, SMOTE_pipeline, 'macro')</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oo"><img src="../Images/b180a10e97f8c5bb6b3affceb9059127.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4359lS2NNGwCe_SqDmewlg.png"/></div></div></figure><p id="bc3f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与随机过采样相比，SMOTE采样似乎具有略高的精度和F1值。根据目前的结果，似乎选择SMOTE过采样比原始或随机过采样更可取。</p><h1 id="6999" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">向下采样</h1><p id="f375" class="pw-post-body-paragraph kd ke iq kf b kg mo ki kj kk mp km kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">下采样怎么样？如果我们在上述过采样中对少数类进行过采样，利用下采样，我们试图减少多数类的数据，从而使数据类平衡。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="df98" class="nd lr iq mz b gy ne nf l ng nh">from imblearn.under_sampling import NearMiss, RandomUnderSampler</span><span id="5d9b" class="nd lr iq mz b gy ni nf l ng nh">RUS_pipeline = make_pipeline(tvec, RandomUnderSampler(random_state=777),lr)<br/>NM1_pipeline = make_pipeline(tvec, NearMiss(ratio='not minority',random_state=777, version = 1),lr)<br/>NM2_pipeline = make_pipeline(tvec, NearMiss(ratio='not minority',random_state=777, version = 2),lr)<br/>NM3_pipeline = make_pipeline(tvec, NearMiss(ratio=nm3_dict,random_state=777, version = 3, n_neighbors_ver3=4),lr)</span></pre><h2 id="8fa4" class="nd lr iq bd ls nx ny dn lw nz oa dp ma ko ob oc me ks od oe mi kw of og mm oh bi translated">随机欠采样器</h2><p id="e082" class="pw-post-body-paragraph kd ke iq kf b kg mo ki kj kk mp km kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">同样，在我们运行管道之前，让我们将它应用于玩具数据，看看它能做什么。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="211a" class="nd lr iq mz b gy ne nf l ng nh">rus = RandomUnderSampler(random_state=777)<br/>X_RUS, y_RUS = rus.fit_sample(testing_tfidf, testing_target)<br/>pd.DataFrame(X_RUS.todense(), columns=tv.get_feature_names())</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi op"><img src="../Images/ff1c4dd25a1d49842d45dfd03f337bb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LQxBt1i9LmJtlzZtF1xCqw.png"/></div></div></figure><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="4ba0" class="nd lr iq mz b gy ne nf l ng nh">pd.DataFrame(testing_tfidf.todense(), columns=tv.get_feature_names())</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oq"><img src="../Images/939114629de5e74efc7d0f798b7f43af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2msf__1CFbRq-Lhb7AqG2g.png"/></div></div></figure><p id="fba7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与原始不平衡数据相比，我们可以看到下采样数据少了一个条目，这是原始数据中属于正类的最后一个条目。RandomUnderSampler通过从多数类中随机移除数据来减少多数类。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="9b75" class="nd lr iq mz b gy ne nf l ng nh">lr_cv(5, df.clean_text, df.sentiment, RUS_pipeline, 'macro')</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi or"><img src="../Images/37ed8bfabc7cb7ed35422581c7b3ab86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PVhpBsP_h4LRUhppMZTjPg.png"/></div></div></figure><p id="af52" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在准确性和F1的分数已经明显下降。但低精度和高召回率的特点与过采样数据相同。只是整体表现下降了。</p><h2 id="68ae" class="nd lr iq bd ls nx ny dn lw nz oa dp ma ko ob oc me ks od oe mi kw of og mm oh bi translated">差点错过</h2><p id="3391" class="pw-post-body-paragraph kd ke iq kf b kg mo ki kj kk mp km kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">根据“不平衡学习”的文档，“<a class="ae kc" href="http://contrib.scikit-learn.org/imbalanced-learn/stable/under_sampling.html#controlled-under-sampling" rel="noopener ugc nofollow" target="_blank"> NearMiss增加了一些启发式规则来选择样本。NearMiss实现了3种不同类型的启发式算法，可通过参数version进行选择。NearMiss启发式规则基于最近邻算法。</a></p><p id="fcc7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">还有一篇关于重采样技术的好论文。“<a class="ae kc" href="https://arxiv.org/pdf/1608.06048.pdf" rel="noopener ugc nofollow" target="_blank">用于改善不平衡数据集分类性能的重采样技术调查</a>”(Ajinkya More，2016年)</p><p id="ee8a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我借用了莫尔论文中对NearMiss三个不同版本的解释。</p><h2 id="4eee" class="nd lr iq bd ls nx ny dn lw nz oa dp ma ko ob oc me ks od oe mi kw of og mm oh bi translated">近距离-1</h2><p id="6d70" class="pw-post-body-paragraph kd ke iq kf b kg mo ki kj kk mp km kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">在NearMiss-1中，来自多数类的那些点到少数类中k个最近点的平均距离最低的点被保留。这意味着它将保持与少数阶级相似的多数阶级的观点。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="b512" class="nd lr iq mz b gy ne nf l ng nh">nm = NearMiss(ratio='not minority',random_state=777, version=1, n_neighbors=1)<br/>X_nm, y_nm = nm.fit_sample(testing_tfidf, testing_target)<br/>pd.DataFrame(X_nm.todense(), columns=tv.get_feature_names())</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi os"><img src="../Images/c759a2cd1bef0c8c4eba8f46d6e08c3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IV1HFhRaJvdzhr4Mt6KMqQ.png"/></div></div></figure><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="da0f" class="nd lr iq mz b gy ne nf l ng nh">pd.DataFrame(testing_tfidf.todense(), columns=tv.get_feature_names())</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ot"><img src="../Images/12177e1bcf7ab4e3ba2106938a95d5d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TWF6_ctQkf2iGEbaVF-Z5w.png"/></div></div></figure><p id="2a93" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到，NearMiss-1已经删除了文本“I adore cats”的条目，这是有意义的，因为单词“adore”和“cats”都只出现在该条目中，因此使其在特征空间中的Tf-Idf表示方面与少数民族类最不同。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="a6b0" class="nd lr iq mz b gy ne nf l ng nh">lr_cv(5, df.clean_text, df.sentiment, NM1_pipeline, 'macro')</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ou"><img src="../Images/aba8ebd3e18016bb73df7b35115ca416.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oh6fvttCAHVjmSabJDPSjA.png"/></div></div></figure><p id="7c12" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">看起来准确性和F1分数都比随机欠采样差。</p><h2 id="815f" class="nd lr iq bd ls nx ny dn lw nz oa dp ma ko ob oc me ks od oe mi kw of og mm oh bi translated">近地小行星-2</h2><p id="edff" class="pw-post-body-paragraph kd ke iq kf b kg mo ki kj kk mp km kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">与NearMiss-1相反，NearMiss-2保留了多数类中那些到少数类中k个最远点的平均距离最低的点。换句话说，它会保留多数阶级与少数阶级最大的不同点。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="1d0a" class="nd lr iq mz b gy ne nf l ng nh">nm = NearMiss(ratio='not minority',random_state=777, version=2, n_neighbors=1)<br/>X_nm, y_nm = nm.fit_sample(testing_tfidf, testing_target)<br/>pd.DataFrame(X_nm.todense(), columns=tv.get_feature_names())</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ov"><img src="../Images/9d25e8c5ccfdd0c573256c0976257fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L6Lsa8JJg0KQ3m_qhRzlaA.png"/></div></div></figure><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="d344" class="nd lr iq mz b gy ne nf l ng nh">pd.DataFrame(testing_tfidf.todense(), columns=tv.get_feature_names())</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ow"><img src="../Images/26f698392a3781c1f6d04a9f68885514.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UZucmjOqruSsrQLPLJ5w3g.png"/></div></div></figure><p id="de71" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们可以看到，NearMiss-2删除了文本“我喜欢狗”的条目，这也是有意义的，因为我们也有一个负面条目“我不喜欢狗”。两个条目在不同的类中，但是它们共享两个相同的标记“like”和“dogs”。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="2ebd" class="nd lr iq mz b gy ne nf l ng nh">lr_cv(5, df.clean_text, df.sentiment, NM2_pipeline, 'macro')</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nv"><img src="../Images/ba5711df9190075343c0551a3adedfd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QVqocTFybngSzXa91veK3w.png"/></div></div></figure><p id="261d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与NearMiss-1相比，准确性和F1得分甚至更低。我们还可以看到，所有指标在不同的筹码之间波动很大。</p><h2 id="d24c" class="nd lr iq bd ls nx ny dn lw nz oa dp ma ko ob oc me ks od oe mi kw of og mm oh bi translated">NearMiss-3</h2><p id="5a60" class="pw-post-body-paragraph kd ke iq kf b kg mo ki kj kk mp km kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">最后的NearMiss变体NearMiss-3为少数类中的每个点选择多数类中的k个最近邻。在这种情况下，欠采样比率直接由k控制。例如，如果我们将k设置为4，则NearMiss-3将选择每个少数类条目的4个最近邻居。</p><p id="8412" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们将根据我们设置的n个邻居，得到比少数类更多或更少的多数类样本。例如，对于我的数据集，如果我在默认n_neighbors_ver3为3的情况下运行NearMiss-3，它将会抱怨，并且中性类(在我的数据集中是多数类)的数量将小于负类(在我的数据集中是少数类)。因此，我显式地将n_neighbors_ver3设置为4，这样我将拥有足够多的多数类数据，至少与少数类的数量相同。</p><p id="f625" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有一点我不能完全确定，就是当用n_neighbors_ver3参数选择的所有数据都多于少数类时，它应用什么样的过滤。正如您将在下面看到的，在应用NearMiss-3之后，数据集达到了完美的平衡。然而，如果算法只是根据n_neighbors_ver3参数选择最近的邻居，我怀疑它最终会为每个类提供完全相同的条目数。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="d9ab" class="nd lr iq mz b gy ne nf l ng nh">lr_cv(5, df.clean_text, df.sentiment, NM3_pipeline, 'macro')</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ox"><img src="../Images/a5d204ba3817b9907622a627b728b8eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1XtsuwPpZbTqv6WZY4mGkw.png"/></div></div></figure><p id="fe5d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">NearMiss-3产生了NearMiss家族中最稳健的结果，但略低于RandomUnderSampling。</p><pre class="mu mv mw mx gt my mz na nb aw nc bi"><span id="4c37" class="nd lr iq mz b gy ne nf l ng nh">from collections import Counter</span><span id="5d1b" class="nd lr iq mz b gy ni nf l ng nh">nm3 = NearMiss(ratio='not minority',random_state=777, version=3, n_neighbors_ver3=4)<br/>tvec = TfidfVectorizer(stop_words=None, max_features=100000, ngram_range=(1, 3))<br/>df_tfidf = tvec.fit_transform(df.clean_text)<br/>X_res, y_res = nm3.fit_sample(df_tfidf, df.sentiment)<br/>print('Distribution before NearMiss-3: {}'.format(Counter(df.sentiment)))<br/>print('Distribution after NearMiss-3: {}'.format(Counter(y_res)))</span></pre><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oy"><img src="../Images/0cbcae8c1fb1c5621f5b5170902266b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pWu7oJbZ4H1kFXV63lYZ4A.png"/></div></div></figure><h1 id="f759" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated">结果</h1><p id="6aec" class="pw-post-body-paragraph kd ke iq kf b kg mo ki kj kk mp km kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated"><strong class="kf ir">五重交叉验证结果</strong> <em class="lp">(用于验证的分类器:默认设置的逻辑回归)</em></p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oz"><img src="../Images/179f45ed23ddad34d187e8a310547d45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XJFlVcjuSbLBigQCMzIUDQ.png"/></div></div></figure><p id="708f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基于上述结果，我将在下一篇文章中使用的采样技术将被SMOTE。在下一篇文章中，我将使用SMOTE过采样数据尝试不同的分类器。</p><p id="6426" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">感谢您的阅读，您可以通过以下链接找到Jupyter笔记本:</p><div class="pa pb gp gr pc pd"><a href="https://github.com/tthustla/yet_another_tiwtter_sentiment_analysis_part1/blob/master/Yet_Another_Twitter_Sentiment_Analysis_part1-Copy1.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="pe ab fo"><div class="pf ab pg cl cj ph"><h2 class="bd ir gy z fp pi fr fs pj fu fw ip bi translated">tthustlea/yeth _ another _ tiw tter _情操_分析_part1</h2><div class="pk l"><h3 class="bd b gy z fp pi fr fs pj fu fw dk translated">通过在GitHub上创建一个帐户，为另一个_ tiwtter _情操_分析_part1开发做出贡献。</h3></div><div class="pl l"><p class="bd b dl z fp pi fr fs pj fu fw dk translated">github.com</p></div></div><div class="pm l"><div class="pn l po pp pq pm pr jw pd"/></div></div></a></div></div></div>    
</body>
</html>