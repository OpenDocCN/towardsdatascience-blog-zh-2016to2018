<html>
<head>
<title>Out of Core Genomics in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 中的核心基因组学</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/out-of-core-genomics-8aa5ef487d1e?source=collection_archive---------4-----------------------#2017-12-26">https://towardsdatascience.com/out-of-core-genomics-8aa5ef487d1e?source=collection_archive---------4-----------------------#2017-12-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/d114012d17ac1e04ad2edb1e601e310b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SOcLTHqePMga4YNKPTll6Q.jpeg"/></div></div></figure><div class=""/><p id="047e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">通常情况下，数据科学家想要探索一个不适合内存的数据集。随着数据量的持续增长，我们处理这些数据的工具也需要扩展。这篇文章的动机源于我对处理<a class="ae kw" href="https://opensnp.org/" rel="noopener ugc nofollow" target="_blank"> openSNP </a>数据的兴趣。openSNP 是一个开源平台，用户可以从<a class="ae kw" href="https://www.23andme.com/" rel="noopener ugc nofollow" target="_blank"> 23andMe </a>等直接面向消费者的遗传学公司上传他们的基因型数据。原始结果文件通常有几十万条记录，每条记录代表人类基因组中的一个位置。openSNP 数据中有超过 4，000 个原始结果文件。然而，我的笔记本电脑运行的 VirtualBox 只有 5GB RAM，这意味着我需要找到一些超出标准 pandas 库的聪明解决方案，以便处理这么多数据。这篇文章描述了几个可以从核外计算中受益的应用之一。</p><h1 id="4275" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">下载 openSNP 数据</h1><p id="c5cb" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">openSNP 有超过 40 GB 的基因型和表型数据存储为文本文件！<br/>出于本演示的目的，分析将仅限于 23andMe 文件。下面是几个 shell 命令，用于下载原始数据，创建目录，并将 23andMe 文件移动到它们自己的目录中。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="me mf l"/></div></figure><p id="147e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这里有一个示例 23andMe 结果文件，文件头用<code class="fe mg mh mi mj b">#</code>注释掉，然后有 600，000+行基因型数据。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mk"><img src="../Images/18a8e8712ee7bfb8654018d9b5d85f3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fnqa7CuiK8vYH03TOyvclw.jpeg"/></div></div></figure><h1 id="e5b0" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">提取合理规模的测试集</h1><p id="452a" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">在本练习中，使用完整 openSNP 数据的一个可管理的子集，以便在合理的时间内执行演示。创建一个新目录，复制以名称:<code class="fe mg mh mi mj b">user21</code>开头的基因型文件。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="me mf l"/></div></figure><h1 id="391c" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">纯种熊猫</h1><p id="55a4" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">首先，从一个纯粹的<a class="ae kw" href="http://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank">熊猫</a> <code class="fe mg mh mi mj b">read_csv</code>解决方案开始，这应该是 Python 数据科学家所熟悉的。尽量在内存中创建一个大的<code class="fe mg mh mi mj b">DataFrame</code>。<code class="fe mg mh mi mj b">join</code>方法可以完成这项任务。尽管这是一个昂贵的操作，我们刚刚提取的测试数据集足够小，它将成功执行。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="me mf l"/></div></figure><pre class="ma mb mc md gt ml mj mm mn aw mo bi"><span id="fb3f" class="mp ky jb mj b gy mq mr l ms mt">CPU times: user 7min 48s, sys: 9.83 s, total: 7min 58s <br/>Wall time: 8min 15s</span></pre><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mu"><img src="../Images/f78d08e2ae186bedf47db00391acd3dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d78X7nVdCLeSey2RNwsrcw.png"/></div></div></figure><p id="2468" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在 43 个文件的测试集上，整个<code class="fe mg mh mi mj b">DataFrame</code>适合内存。然而，对包含 1，915 个文件的整个 openSNP 数据集使用这种纯 pandas 方法最终会使笔记本电脑崩溃，因为它会耗尽物理内存。</p><h1 id="2c4f" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">Dask —并行核外数据帧</h1><p id="50d0" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">进入<a class="ae kw" href="http://dask.pydata.org/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> dask </a>，一个实现核外数据帧的 Python 库。它的 API 类似于 pandas，增加了一些额外的方法和参数。Dask 创建了一个计算图，它将并行读取相同的文件，并创建一个“lazy”<code class="fe mg mh mi mj b">DataFrame</code>,直到<code class="fe mg mh mi mj b">comptue()</code>被显式调用后才会执行。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/14cc62b32952f1348b82b9de4625b5a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/0*VtPcoXneqzWWzmdQ.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk">example computation graph from <a class="ae kw" href="http://dask.pydata.org/en/latest/_images/pipeline.png" rel="noopener ugc nofollow" target="_blank">http://dask.pydata.org/en/latest/_images/pipeline.png</a></figcaption></figure><p id="2d64" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">惰性地将基因型文件读入 dask 数据帧，这个操作实际上并没有将文件读入内存，这可以通过 cpu 时间来证明，相反，它构建了一个类似于上图的图形。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="me mf l"/></div></figure><pre class="ma mb mc md gt ml mj mm mn aw mo bi"><span id="b6e3" class="mp ky jb mj b gy mq mr l ms mt">CPU times: user 112 ms, sys: 52 ms, total: 164 ms <br/>Wall time: 298 ms</span></pre><p id="3d09" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对 dask 数据帧执行操作，如<code class="fe mg mh mi mj b">set_index()</code>触发计算。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="me mf l"/></div></figure><pre class="ma mb mc md gt ml mj mm mn aw mo bi"><span id="0078" class="mp ky jb mj b gy mq mr l ms mt">CPU times: user 4min 44s, sys: 23 s, total: 5min 7s <br/>Wall time: 4min 45s</span></pre><p id="b01f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">dask <code class="fe mg mh mi mj b">compute()</code>方法提供了熟悉的结果。因为<code class="fe mg mh mi mj b">join</code>方法不是在 dask 数据框架上执行的，与纯 pandas 方法相反，只调查一个记录(或一个 SNP)。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="me mf l"/></div></figure><pre class="ma mb mc md gt ml mj mm mn aw mo bi"><span id="7011" class="mp ky jb mj b gy mq mr l ms mt">CPU times: user 3min 31s, sys: 36.1 s, total: 4min 7s <br/>Wall time: 3min 46s </span><span id="e7ea" class="mp ky jb mj b gy na mr l ms mt">CC 37 <br/>CT 5<br/>TT 1 <br/>Name: genotype, dtype: int64</span></pre><p id="fca1" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">同样，与<code class="fe mg mh mi mj b">ddf</code> (dask)相反，<code class="fe mg mh mi mj b">gtdf</code>在内存中，所以这个操作非常快。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="me mf l"/></div></figure><pre class="ma mb mc md gt ml mj mm mn aw mo bi"><span id="a1fd" class="mp ky jb mj b gy mq mr l ms mt">CPU times: user 4.3 s, sys: 8.1 s, total: 12.4 s <br/>Wall time: 1min 1s</span><span id="8fd6" class="mp ky jb mj b gy na mr l ms mt">CC 37 <br/>CT 5<br/>TT 1 <br/>Name: rs1333525, dtype: int64</span></pre><p id="841c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">乍一看，计算时间是骗人的。dask 方法花费了更长的时间，因为计算缓慢，它仍然必须读取所有文件，然后执行操作。然而，当你考虑到加入数据帧所需的<strong class="ka jc"> 8 分 15 秒</strong>加上<code class="fe mg mh mi mj b">gtdf.loc[rs13333525'].value_counts()</code>的<strong class="ka jc"> 1 分 1 秒</strong>时，那就是<strong class="ka jc"> 9 分 16 秒</strong>。相比之下，dask 方法需要 3 个步骤。第一次设置计算图形为&lt; 1 秒。所以真正的比较来自于设定指标的<strong class="ka jc"> 4 分 45 秒</strong>和执行<code class="fe mg mh mi mj b">ddf.loc['rs1333525']['genotype'].value_counts().compute()</code>的<strong class="ka jc"> 3 分 46 秒</strong>总计<strong class="ka jc"> 8 分 31 秒</strong>。在我们只有 43 个文件的测试数据上，这似乎是一个微小的加速。当数据帧根本放不进内存时,<code class="fe mg mh mi mj b">dask</code>的真正威力就发挥出来了。</p><h1 id="2bb1" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">提高查询性能—转换。txt/。csv 呼叫拼花地板！</h1><p id="1c46" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">如果能加快 dask 查询的速度就好了，这样我们就可以在合理的时间内使用数据帧进行下游分析。解决方案是将原始文本数据以有效的二进制格式存储在磁盘上。传统上，一个流行的选择是<a class="ae kw" href="https://support.hdfgroup.org/HDF5/doc/H5.intro.html" rel="noopener ugc nofollow" target="_blank"> HDF5 </a>，但是我选择使用<a class="ae kw" href="https://parquet.apache.org/" rel="noopener ugc nofollow" target="_blank"> parquet </a>，因为 HDF5 可能很难使用。Dask 使用了<a class="ae kw" href="http://fastparquet.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> fastparquet </a>实现。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="me mf l"/></div></figure><pre class="ma mb mc md gt ml mj mm mn aw mo bi"><span id="0246" class="mp ky jb mj b gy mq mr l ms mt">CPU times: user 12min 35s, sys: 1min 41s, total: 14min 17s<br/>Wall time: 19min 30s</span></pre><p id="cf2a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从本质上讲，这样做的目的是将<code class="fe mg mh mi mj b">.txt</code>文件转换成 parquet 文件。从中真正获得了多少性能？重温 dask 数据帧<code class="fe mg mh mi mj b">ddf</code>，记得计算<code class="fe mg mh mi mj b">value_counts()</code>花了 3 分 46 秒。转换为拼花格式后进行比较。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="me mf l"/></div></figure><pre class="ma mb mc md gt ml mj mm mn aw mo bi"><span id="3ee5" class="mp ky jb mj b gy mq mr l ms mt">CPU times: user 8.18 s, sys: 608 ms, total: 8.79 s <br/>Wall time: 11.7 s </span><span id="d4a7" class="mp ky jb mj b gy na mr l ms mt">CC 37 <br/>CT 5 <br/>TT 1 <br/>Name: genotype, dtype: int64</span></pre><p id="9d39" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Parquet 为查询数据提供了显著的性能提升，即使只有 43 个文件的验证集。将这个扩展到 1915 个文件，并行的<code class="fe mg mh mi mj b">.txt</code>版本<code class="fe mg mh mi mj b">ddf</code>，花了 5 个多小时来执行一个 SNP 的<code class="fe mg mh mi mj b">value_counts()</code>。在 1915 号文件上<code class="fe mg mh mi mj b">DataFrame</code>花了几个小时。一旦看到查询性能的提高，从<code class="fe mg mh mi mj b">.txt</code>或<code class="fe mg mh mi mj b">.csv</code>转换到 parquet 的前期成本是值得的。</p><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nb"><img src="../Images/aca73affa689eaddb72de67cfbf832fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0AuKtKnFQJrjB8QTsh5Gew.jpeg"/></div></div></figure><h1 id="449c" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">整个 openSNP 数据集上的性能</h1><p id="b64a" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">我使用上面相同的命令预先计算了整个<code class="fe mg mh mi mj b">gt23</code>目录的拼花文件，并将拼花文件存储在<code class="fe mg mh mi mj b">gt23_pq</code>中。需要清理和/或删除一些格式错误的文件。</p><pre class="ma mb mc md gt ml mj mm mn aw mo bi"><span id="c717" class="mp ky jb mj b gy mq mr l ms mt">$ find gt23_pq/ -type f | wc -l</span><span id="8949" class="mp ky jb mj b gy na mr l ms mt">1898</span></pre><p id="a26c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，发出与前面代码块中的测试数据集相同的<code class="fe mg mh mi mj b">value_counts()</code>命令，但是这将考虑所有的 23andMe 基因型文件。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="me mf l"/></div></figure><pre class="ma mb mc md gt ml mj mm mn aw mo bi"><span id="9539" class="mp ky jb mj b gy mq mr l ms mt">CPU times: user 6.67 s, sys: 112 ms, total: 6.78 s<br/>Wall time: 7.2 s</span><span id="cf8a" class="mp ky jb mj b gy na mr l ms mt">CC    1625<br/>CT     277<br/>TT      13<br/>Name: genotype, dtype: int64</span></pre><p id="b79c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这些结果凸显了拼花地板远优于<code class="fe mg mh mi mj b">.csv</code>或<code class="fe mg mh mi mj b">.txt</code>的性能。此外，dask 证明了当物理内存受到限制时，它作为一个易于使用的工具的价值。到目前为止，您可能已经注意到，我无法将用户标识符分配给每一列。<code class="fe mg mh mi mj b">dd.read_csv()</code>假设每个文件中的列名相同。</p><h1 id="1e62" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">在整个 openSNP 数据集上实现</h1><p id="ae8a" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">教程的 dask 和 parquet 部分已经结束。我想展示 dask 和 parquet 如何轻松地处理大型数据集。以下示例比较了 openSNP 数据和<a class="ae kw" href="http://exac.broadinstitute.org/" rel="noopener ugc nofollow" target="_blank"> exAC </a>数据中的不同频率。</p><figure class="ma mb mc md gt is"><div class="bz fp l di"><div class="me mf l"/></div></figure><figure class="ma mb mc md gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nd"><img src="../Images/6c6430cd81f04ce5fbaf5b23807dc0bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vxwd1k0HJ30tt6bVvp4rlw.png"/></div></div></figure><p id="d371" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我希望这篇文章对你有用，并在处理结构化文本文件时考虑使用 dask 和 parquet。我真的鼓励你查看 dask 和 parquet 文档，并跟随他们的一些教程。感谢阅读，欢迎评论和代码改进！</p></div><div class="ab cl ne nf hu ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="ij ik il im in"><p id="f162" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从我的 github 页面站点更新【https://arvkevi.github.io/Out_of_Core_Genomics.html T2】</p></div></div>    
</body>
</html>