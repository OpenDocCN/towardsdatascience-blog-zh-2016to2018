<html>
<head>
<title>Facial Recognition Using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习的面部识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/facial-recognition-using-deep-learning-a74e9059a150?source=collection_archive---------0-----------------------#2017-03-22">https://towardsdatascience.com/facial-recognition-using-deep-learning-a74e9059a150?source=collection_archive---------0-----------------------#2017-03-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="3244" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">卷积神经网络允许我们从图像中提取广泛的特征。事实证明，我们也可以将这种特征提取的想法用于人脸识别！这就是我们在本教程中要探索的，使用深度 conv 网进行人脸识别。<em class="kl">注:这是人脸</em> <strong class="jp ir"> <em class="kl">识别</em> </strong> <em class="kl">(即实际告知是谁的脸)</em> <strong class="jp ir"> <em class="kl">不是</em> </strong> <em class="kl">只是检测(即识别一张图片中的人脸)。</em></p><blockquote class="km kn ko"><p id="765e" class="jn jo kl jp b jq jr js jt ju jv jw jx kp jz ka kb kq kd ke kf kr kh ki kj kk ij bi translated">如果你不知道什么是深度学习(或者什么是神经网络)，请阅读我的帖子<a class="ae ks" href="https://medium.com/towards-data-science/intro-to-deep-learning-d5caceedcf85#.p61qh0vz8" rel="noopener">初学者的深度学习</a>。如果你想尝试一个使用卷积神经网络进行图像分类的基础教程，你可以尝试<a class="ae ks" href="https://medium.com/@sntaus/image-classification-using-deep-learning-hello-world-tutorial-a47d02fd9db1#.52f0684bj" rel="noopener">这个教程</a>。请记住，本教程假设您有基本的编程经验(最好是 Python)，并且您了解深度学习和神经网络的基本思想。</p></blockquote><p id="d5ec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将要使用的人脸识别方法相当简单。这里的关键是让一个深度神经网络产生一串描述一张脸的数字(称为人脸编码)。当您传入同一个人的两个不同图像时，网络应该为这两个图像返回相似的输出(即更接近的数字)，而当您传入两个不同人的图像时，网络应该为这两个图像返回非常不同的输出。这意味着需要训练神经网络来自动识别面部的不同特征，并基于此计算数字。神经网络的输出可以被认为是特定人脸的标识符——如果你传入同一个人的不同图像，神经网络的输出将非常相似/接近，而如果你传入不同人的图像，输出将非常不同。</p><p id="cdba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">谢天谢地，我们不必经历训练或建立自己的神经网络的麻烦。我们可以通过我们可以使用的<a class="ae ks" href="http://dlib.net/" rel="noopener ugc nofollow" target="_blank"> dlib </a>访问一个经过训练的模型。它确实做了我们需要它做的事情——当我们传入某人的面部图像时，它输出一串数字(面部编码);比较来自不同图像的人脸编码将告诉我们某人的脸是否与我们有图像的任何人相匹配。以下是我们将采取的步骤:</p><ol class=""><li id="4568" class="kt ku iq jp b jq jr ju jv jy kv kc kw kg kx kk ky kz la lb bi translated">检测/识别图像中的人脸(使用人脸检测模型)——为了简单起见，本教程将只使用包含一个人脸/人的图像，而不是更多/更少</li><li id="cfdf" class="kt ku iq jp b jq lc ju ld jy le kc lf kg lg kk ky kz la lb bi translated">预测面部姿态/ <strong class="jp ir">界标</strong>(针对步骤 1 中识别的面部)</li><li id="f5c5" class="kt ku iq jp b jq lc ju ld jy le kc lf kg lg kk ky kz la lb bi translated">使用来自步骤 2 的数据和实际图像，计算面部<strong class="jp ir">编码</strong>(描述面部的数字)</li><li id="400f" class="kt ku iq jp b jq lc ju ld jy le kc lf kg lg kk ky kz la lb bi translated"><strong class="jp ir">比较</strong>已知人脸的人脸编码和测试图像中的人脸编码，判断照片中的人是谁</li></ol><p id="cb91" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">希望你对这将如何工作有一个基本的概念(当然上面的描述是非常简化的)。现在是时候开始建设了！</p><h1 id="804e" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">准备图像</h1><p id="f17b" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">首先，创建一个项目文件夹(只是一个保存代码和图片的文件夹)。对我来说它叫做<code class="fe mk ml mm mn b">face_recognition</code>，但是你可以随便叫它什么。在该文件夹中，创建另一个名为<code class="fe mk ml mm mn b">images</code>的文件夹。这是一个文件夹，将保存您要对其运行人脸识别的不同人的图像。从脸书下载一些你朋友的图片(每人一张)，将图片重新命名为你朋友的名字(如<code class="fe mk ml mm mn b">taus.jpg</code>或<code class="fe mk ml mm mn b">john.jpg</code>，并将它们全部保存在你刚刚创建的这个<code class="fe mk ml mm mn b">images</code>文件夹中。需要记住的一件重要事情是:请确保所有这些图像中只有一张脸(即它们不能是组图)，并且它们都是 JPEG 格式，文件名以<code class="fe mk ml mm mn b">.jpg</code>结尾。</p><p id="7599" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，在您的项目文件夹中创建另一个文件夹(对我来说是<code class="fe mk ml mm mn b">face_recognition</code>文件夹)，并将其命名为<code class="fe mk ml mm mn b">test</code>。该文件夹将包含您在<code class="fe mk ml mm mn b">images</code>文件夹中存储的同一个人的<strong class="jp ir">不同的</strong>图像。再次，确保每张照片只有一个人在里面。在<code class="fe mk ml mm mn b">test</code>文件夹中，您可以随意命名图像文件，并且您可以拥有每个人的多张照片(因为我们将对<code class="fe mk ml mm mn b">test</code>文件夹中的所有照片运行人脸识别)。</p><h1 id="26e4" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">安装依赖项</h1><p id="cb16" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">这个项目最重要的依赖项是 Python 2.7 和 pip。您可以使用 Anaconda 2(这只是一个预打包了 pip 的 Python 发行版)通过点击<a class="ae ks" href="https://docs.continuum.io/anaconda/install" rel="noopener ugc nofollow" target="_blank">链接</a>来安装这两个版本(如果您还没有安装的话)。<em class="kl">注意:请</em> <strong class="jp ir"> <em class="kl">确保</em></strong><em class="kl">Anaconda 2</em><strong class="jp ir"><em class="kl">被</em> </strong> <em class="kl">添加到您的</em><strong class="jp ir"><em class="kl">PATH</em></strong><em class="kl">中，并注册为您的系统 Python 2.7(安装过程中会有提示；只需按“是”或勾选复选框)。</em></p><p id="1abc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您已经完成了 Anaconda 2 的设置，或者您已经预先在机器上安装了 Python 2.7 和 pip，那么您可以继续安装<a class="ae ks" href="http://dlib.net/" rel="noopener ugc nofollow" target="_blank"> dlib </a>(我们将使用的机器学习库)和其他依赖项。为此，请在终端(Mac OS 或 Linux)或命令提示符(Windows)中键入以下命令:</p><pre class="mo mp mq mr gt ms mn mt mu aw mv bi"><span id="cee1" class="mw li iq mn b gy mx my l mz na">pip install --user numpy scipy dlib</span></pre><p id="6d9b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您是 Mac 或 Linux 用户，并且在使用上述命令时遇到问题，请尝试以下命令:</p><pre class="mo mp mq mr gt ms mn mt mu aw mv bi"><span id="d4ba" class="mw li iq mn b gy mx my l mz na">sudo pip install --user numpy scipy dlib</span></pre><p id="6173" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果上述过程对您不起作用，您可能需要手动下载、编译和安装 dlib 及其 Python API。为此，你必须读一些关于 http://dlib.net/的书。不幸的是，这超出了这篇博文的范围，因此我不会在这里讨论。</p><p id="ae22" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你需要做的最后一件事是下载预先训练好的人脸识别模型。你需要两种型号。一个模型预测一张脸的形状/姿势(基本上给你形状在图像中如何定位的数字)。另一个模型，获取人脸并给你人脸编码(基本上是描述那个特定人的脸的数字)。以下是关于如何下载、提取和准备它们的说明:</p><ol class=""><li id="f5d6" class="kt ku iq jp b jq jr ju jv jy kv kc kw kg kx kk ky kz la lb bi translated">从<a class="ae ks" href="http://dlib.net/files/dlib_face_recognition_resnet_model_v1.dat.bz2" rel="noopener ugc nofollow" target="_blank">这个链接</a>下载<code class="fe mk ml mm mn b">dlib_face_recognition_resnet_model_v1.dat.bz2</code>，从<a class="ae ks" href="http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2" rel="noopener ugc nofollow" target="_blank">这个链接</a>下载<code class="fe mk ml mm mn b">shape_predictor_68_face_landmarks.dat.bz2</code></li><li id="f024" class="kt ku iq jp b jq lc ju ld jy le kc lf kg lg kk ky kz la lb bi translated">一旦下载了这两个文件，就需要解压它们(它们以 bz2 格式压缩)。在 Windows 上，您可以使用<a class="ae ks" href="http://www.e7z.org/" rel="noopener ugc nofollow" target="_blank"> Easy 7-zip </a>来完成此操作。在 Mac 或 Linux 上，您应该能够双击文件并提取它们。如果这不起作用，只需在您的终端中输入这两个文件:<code class="fe mk ml mm mn b">bzip2 <strong class="jp ir">{PATH_TO_FILE}</strong> --decompress</code>(用您试图提取的文件的实际路径替换<code class="fe mk ml mm mn b">{PATH_TO_FILE}</code>；对我来说，命令应该是<code class="fe mk ml mm mn b">bzip2 ~/Downloads/dlib_face_recognition_resnet_model_v1.dat.bz2 --decompress</code>和<code class="fe mk ml mm mn b">bzip2 ~/Downloads/shape_predictor_68_face_landmarks.dat.bz2 --decompress</code>。</li><li id="b6f9" class="kt ku iq jp b jq lc ju ld jy le kc lf kg lg kk ky kz la lb bi translated">一旦你提取它们，你应该有两个名为<code class="fe mk ml mm mn b">dlib_face_recognition_resnet_model_v1.dat</code>和<code class="fe mk ml mm mn b">shape_predictor_68_face_landmarks.dat</code>的文件。将这两个文件复制到您的项目文件夹中(对我来说，这是我为这个项目创建的<code class="fe mk ml mm mn b">face_recognition</code>文件夹)。</li></ol><h1 id="ca54" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">代码！</h1><p id="c6d0" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">现在，你已经设置好了一切，在一个文本编辑器(最好是<a class="ae ks" href="http://atom.io" rel="noopener ugc nofollow" target="_blank"> Atom </a>或<a class="ae ks" href="https://www.sublimetext.com/" rel="noopener ugc nofollow" target="_blank"> Sublime Text </a>)中打开你的项目文件夹(我称之为<code class="fe mk ml mm mn b">face_recognition</code>)。在名为<code class="fe mk ml mm mn b">recognize.py</code>的文件夹中创建一个新文件。这是我们将添加代码来匹配你的朋友的脸。注意，这个过程有两个主要部分:首先，在<code class="fe mk ml mm mn b">images</code>文件夹中加载已知人脸的人脸编码；完成后，从存储在<code class="fe mk ml mm mn b">test</code>文件夹中的人脸/图像中获取人脸编码，并将它们与我们所有已知的人脸一一匹配。我们将逐步完成这一部分。如果您想看到它运行，您可以将该部分中的所有代码一个接一个地复制粘贴到您的文件中(即，按照下面列出的相同顺序合并所有单独的代码部分)。仔细阅读每个代码块中的注释，了解它的作用。</p><p id="653f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第 1 部分:初始化和设置— </strong>在这里，我们导入所需的库，并设置人脸识别所需的对象/参数。</p><pre class="mo mp mq mr gt ms mn mt mu aw mv bi"><span id="8f01" class="mw li iq mn b gy mx my l mz na">import dlib<br/>import scipy.misc<br/>import numpy as np<br/>import os</span><span id="f4ad" class="mw li iq mn b gy nb my l mz na"># Get Face Detector from dlib<br/># This allows us to detect faces in images<br/>face_detector = dlib.get_frontal_face_detector()</span><span id="74f8" class="mw li iq mn b gy nb my l mz na"># Get Pose Predictor from dlib<br/># This allows us to detect landmark points in faces and understand the pose/angle of the face<br/>shape_predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')</span><span id="39bb" class="mw li iq mn b gy nb my l mz na"># Get the face recognition model<br/># This is what gives us the face encodings (numbers that identify the face of a particular person)<br/>face_recognition_model = dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')</span><span id="3fa1" class="mw li iq mn b gy nb my l mz na"># This is the tolerance for face comparisons<br/># The lower the number - the stricter the comparison<br/># To avoid false matches, use lower value<br/># To avoid false negatives (i.e. faces of the same person doesn't match), use higher value<br/># 0.5-0.6 works well<br/>TOLERANCE = 0.6</span></pre><p id="d205" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第 2 部分:从图像中获取人脸编码— </strong>这里我们编写一个函数，它将获取一个图像文件名，并为我们提供该图像的人脸编码。</p><pre class="mo mp mq mr gt ms mn mt mu aw mv bi"><span id="0f49" class="mw li iq mn b gy mx my l mz na"># This function will take an image and return its face encodings using the neural network<br/>def get_face_encodings(path_to_image):<br/>    # Load image using scipy<br/>    image = scipy.misc.imread(path_to_image)</span><span id="caf3" class="mw li iq mn b gy nb my l mz na">    # Detect faces using the face detector<br/>    detected_faces = face_detector(image, 1)</span><span id="12f5" class="mw li iq mn b gy nb my l mz na">    # Get pose/landmarks of those faces<br/>    # Will be used as an input to the function that computes face encodings<br/>    # This allows the neural network to be able to produce similar numbers for faces of the same people, regardless of camera angle and/or face positioning in the image<br/>    shapes_faces = [shape_predictor(image, face) for face in detected_faces]</span><span id="ab34" class="mw li iq mn b gy nb my l mz na">    # For every face detected, compute the face encodings<br/>    return [np.array(face_recognition_model.compute_face_descriptor(image, face_pose, 1)) for face_pose in shapes_faces]</span></pre><p id="368a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第 3a 部分:比较人脸— </strong>我们在这里编写一个函数，它将给定的人脸编码与一系列已知的人脸编码进行比较。它将返回一个布尔值(真/假)数组，指示是否存在匹配。</p><pre class="mo mp mq mr gt ms mn mt mu aw mv bi"><span id="7403" class="mw li iq mn b gy mx my l mz na"># This function takes a list of known faces<br/>def compare_face_encodings(known_faces, face):<br/>    # Finds the difference between each known face and the given face (that we are comparing)<br/>    # Calculate norm for the differences with each known face<br/>    # Return an array with True/Face values based on whether or not a known face matched with the given face<br/>    # A match occurs when the (norm) difference between a known face and the given face is less than or equal to the TOLERANCE value<br/>    return (np.linalg.norm(known_faces - face, axis=1) &lt;= TOLERANCE)</span></pre><p id="fbe4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第 3b 部分:查找匹配— </strong>这里我们编写了一个函数，它将接受一个已知人脸编码列表、一个人名列表(对应于已知人脸编码列表)和一个要查找匹配的人脸。它将调用 3a 中的函数，并返回与给定人脸匹配的人的姓名。</p><pre class="mo mp mq mr gt ms mn mt mu aw mv bi"><span id="a498" class="mw li iq mn b gy mx my l mz na"># This function returns the name of the person whose image matches with the given face (or 'Not Found')<br/># known_faces is a list of face encodings<br/># names is a list of the names of people (in the same order as the face encodings - to match the name with an encoding)<br/># face is the face we are looking for<br/>def find_match(known_faces, names, face):<br/>    # Call compare_face_encodings to get a list of True/False values indicating whether or not there's a match<br/>    matches = compare_face_encodings(known_faces, face)</span><span id="ce76" class="mw li iq mn b gy nb my l mz na">    # Return the name of the first match<br/>    count = 0<br/>    for match in matches:<br/>        if match:<br/>            return names[count]<br/>        count += 1</span><span id="61de" class="mw li iq mn b gy nb my l mz na">    # Return not found if no match found<br/>    return 'Not Found'</span></pre><p id="a676" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">至此，我们拥有了运行程序所需的函数。是时候编写应用程序的最后一部分了(我将把它分成两个独立的部分)。</p><p id="a9d7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第 4a 部分:获取</strong> <code class="fe mk ml mm mn b">images</code> <strong class="jp ir">文件夹</strong>中所有人脸的人脸编码</p><pre class="mo mp mq mr gt ms mn mt mu aw mv bi"><span id="7052" class="mw li iq mn b gy mx my l mz na"># Get path to all the known images<br/># Filtering on .jpg extension - so this will only work with JPEG images ending with .jpg<br/>image_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir('images/'))</span><span id="ccb7" class="mw li iq mn b gy nb my l mz na"># Sort in alphabetical order<br/>image_filenames = sorted(image_filenames)</span><span id="d6be" class="mw li iq mn b gy nb my l mz na"># Get full paths to images<br/>paths_to_images = ['images/' + x for x in image_filenames]</span><span id="1d53" class="mw li iq mn b gy nb my l mz na"># List of face encodings we have<br/>face_encodings = []</span><span id="ff5d" class="mw li iq mn b gy nb my l mz na"># Loop over images to get the encoding one by one<br/>for path_to_image in paths_to_images:<br/>    # Get face encodings from the image<br/>    face_encodings_in_image = get_face_encodings(path_to_image)</span><span id="759b" class="mw li iq mn b gy nb my l mz na">    # Make sure there's exactly one face in the image<br/>    if len(face_encodings_in_image) != 1:<br/>        print("Please change image: " + path_to_image + " - it has " + str(len(face_encodings_in_image)) + " faces; it can only have one")<br/>        exit()</span><span id="a4c0" class="mw li iq mn b gy nb my l mz na">    # Append the face encoding found in that image to the list of face encodings we have<br/>    face_encodings.append(get_face_encodings(path_to_image)[0])</span></pre><p id="4289" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">部分 4b:将</strong> <code class="fe mk ml mm mn b">test</code> <strong class="jp ir">文件夹中的每张图像与已知人脸进行匹配(逐个)</strong></p><pre class="mo mp mq mr gt ms mn mt mu aw mv bi"><span id="7d33" class="mw li iq mn b gy mx my l mz na"># Get path to all the test images<br/># Filtering on .jpg extension - so this will only work with JPEG images ending with .jpg<br/>test_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir('test/'))</span><span id="2e4e" class="mw li iq mn b gy nb my l mz na"># Get full paths to test images<br/>paths_to_test_images = ['test/' + x for x in test_filenames]</span><span id="1b48" class="mw li iq mn b gy nb my l mz na"># Get list of names of people by eliminating the .JPG extension from image filenames<br/>names = [x[:-4] for x in image_filenames]</span><span id="e748" class="mw li iq mn b gy nb my l mz na"># Iterate over test images to find match one by one<br/>for path_to_image in paths_to_test_images:<br/>    # Get face encodings from the test image<br/>    face_encodings_in_image = get_face_encodings(path_to_image)</span><span id="7458" class="mw li iq mn b gy nb my l mz na">    # Make sure there's exactly one face in the image<br/>    if len(face_encodings_in_image) != 1:<br/>        print("Please change image: " + path_to_image + " - it has " + str(len(face_encodings_in_image)) + " faces; it can only have one")<br/>        exit()</span><span id="f1ac" class="mw li iq mn b gy nb my l mz na">    # Find match for the face encoding found in this test image<br/>    match = find_match(face_encodings, names, face_encodings_in_image[0])</span><span id="d6fb" class="mw li iq mn b gy nb my l mz na">    # Print the path of test image and the corresponding match<br/>    print(path_to_image, match)</span></pre><p id="e9b0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">就是这样！一旦你将第 1 部分到第 4b 部分的所有代码复制粘贴到<code class="fe mk ml mm mn b">recognize.py</code>文件中(一个接一个——按照我写它们的顺序),你应该能够使用你的终端(Mac OS 或者 Linux)或者命令提示符(Windows)通过输入这些命令来运行它(用你的项目文件夹的完整路径替换<code class="fe mk ml mm mn b"><strong class="jp ir">{PROJECT_FOLDER_PATH}</strong></code>;对我来说是<strong class="jp ir"> </strong> <code class="fe mk ml mm mn b">/Users/taus/face_recognition</code>):</p><pre class="mo mp mq mr gt ms mn mt mu aw mv bi"><span id="64fb" class="mw li iq mn b gy mx my l mz na">cd <strong class="mn ir">{PROJECT_FOLDER_PATH}<br/></strong>python recognize.py</span></pre><p id="0cf5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这将为您提供类似如下的输出:</p><pre class="mo mp mq mr gt ms mn mt mu aw mv bi"><span id="bcd3" class="mw li iq mn b gy mx my l mz na">('test/1.jpg', 'Shihab')<br/>('test/2.jpg', 'Not Found')<br/>('test/3.jpg', 'Taus')<br/>('test/4.jpg', 'Mifrah')<br/>('test/5.jpg', 'Mubin')</span></pre><p id="e7ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">文件名旁边的名称显示与给定人脸匹配的人的姓名。请注意，这可能并不适用于所有图像。为了获得此代码的最佳性能，请尝试使用人脸清晰可见的图像。当然，还有其他方法可以使它准确(比如通过实际修改我们的代码来检查多个图像或者使用抖动，等等)。)但这只是为了让你对人脸识别的工作原理有一个基本的了解。</p><p id="7a73" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇文章的灵感来自于亚当·盖特基(Adam Geitgey)的博客文章(T3)和(T4)关于人脸识别的 Github 报告(T5)。此外，我们正在使用 dlib 网站上提供的一些预先训练好的模型——所以向他们致敬，让他们可以公开访问。我的主要目标是介绍和解释人脸识别的基本深度学习解决方案。当然，有更简单的方法来做同样的事情，但我认为我应该使用<a class="ae ks" href="http://dlib.net/" rel="noopener ugc nofollow" target="_blank"> dlib </a>来一部分一部分地(详细地)做这件事，这样你就能真正理解不同的运动部件。还有其他运行人脸识别的方法(非深度学习)，请随意研究它们。这种方法很酷的一点是，你可以用每个人/对象的一两张图像来运行它(假设该模型在实际区分两张脸方面做得很好)。</p><p id="5d9d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不管怎样，我希望你喜欢这篇文章。请随意发表评论。</p></div></div>    
</body>
</html>