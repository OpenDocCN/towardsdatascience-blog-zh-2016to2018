<html>
<head>
<title>[ Paper Summary ] A Comparison of Audio Signal Preprocessing Methods for Deep Neural Networks on Music Tagging</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">【论文摘要】音乐标注深度神经网络音频信号预处理方法的比较</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/paper-summary-a-comparison-of-audio-signal-preprocessing-methods-for-deep-neural-networks-on-92a7bfacce26?source=collection_archive---------11-----------------------#2018-06-24">https://towardsdatascience.com/paper-summary-a-comparison-of-audio-signal-preprocessing-methods-for-deep-neural-networks-on-92a7bfacce26?source=collection_archive---------11-----------------------#2018-06-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/3637b0dd2b9076a3bcde7d6aee6ec57b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*iO5bWtD2J9f1akGQMx6a8g.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">GIF from this <a class="ae jy" href="https://giphy.com/gifs/song-music-blog-PpfHisi2v5Yxa" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="24ae" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我的一个朋友正在用神经网络处理音频文件，他推荐我读这篇文章。</p><blockquote class="kx ky kz"><p id="1eb9" class="jz ka la kb b kc kd ke kf kg kh ki kj lb kl km kn lc kp kq kr ld kt ku kv kw ij bi translated"><strong class="kb ir">请注意，这篇帖子是为了我未来的自己复习这篇论文上的材料，而不是从头再看一遍。</strong></p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="lp lq l"/></div></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="2c0d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">摘要</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lr"><img src="../Images/0070745b18d93e85ffe237cec3535ca1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MMcmWSMNueNLwpOpG3uaiw.png"/></div></div></figure><p id="43e1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">本文作者使用深度神经网络对<a class="ae jy" href="https://www.lifewire.com/what-is-music-tagging-2438569" rel="noopener ugc nofollow" target="_blank">音乐标注</a>进行了实验。他们比较了对数幅度压缩、<a class="ae jy" href="https://www.cirrusresearch.co.uk/blog/2011/08/what-are-a-c-z-frequency-weightings/" rel="noopener ugc nofollow" target="_blank">频率加权</a>和缩放等不同的预处理方法，发现幅度压缩是最好的预处理方法。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="39fe" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">简介</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/3034bb83d0e63400a5b285da81b03efb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*T-voeA4sVVQ3Q02RGs6Wqg.png"/></div></figure><p id="86fd" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">机器学习中的许多优化都是通过超参数调整来完成的，然而输入数据的质量不容忽视。这也适用于音频预处理，本文比较了对数压缩技术和数字音频压缩技术。</p><p id="83b7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><em class="la"> log(X+alpha)其中 alpha 可以是任意常数，例如非常小的数(例如 10e-7)或 1 </em></p><p id="4219" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">其他预处理技术。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="1fdd" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">实验和讨论</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lx"><img src="../Images/04d635b878e84cf522807fcda739014b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iAz_THU56dJvspKitI8OvA.png"/></div></div></figure><p id="fd36" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在本节中，作者描述了网络体系结构以及输入数据结构。简而言之，他们使用了一个具有 ELU 激活的卷积神经网络，输入数据的维数为(1，96，1360)。他们还从<a class="ae jy" href="https://labrosa.ee.columbia.edu/millionsong/" rel="noopener ugc nofollow" target="_blank">百万首歌曲数据集</a>中获取音乐数据，并使用离散傅立叶变换将音频转换为 96 * 1360 维。(使用 python 库<a class="ae jy" href="https://github.com/keunwoochoi/kapre" rel="noopener ugc nofollow" target="_blank"> Kapre </a>和<a class="ae jy" href="https://librosa.github.io/librosa/" rel="noopener ugc nofollow" target="_blank"> LibROSA </a>。)</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="848d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> 2.1。不同初始化的差异</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ly"><img src="../Images/9302be0dae1655037ab9620a02b37bb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZOLqwEG49hIRwWFOw582UQ.png"/></div></div></figure><p id="2551" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在这里，作者描述了他们没有选择使用 k 倍交叉验证的事实，相反，他们重复了 15 次实验，并比较了每次实验的 AUC 分数。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lz"><img src="../Images/36b2db9d2b94f0e3d2e1eef35cb7b30a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F9p_l-ME2_LkIcE88-McFQ.png"/></div></div></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="1a94" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> 2.2。时间-频率表示法</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ma"><img src="../Images/4c2503052f36c0b3e19e7aeed6f23f1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HkVu2UHlhVFNYlK5bMAqzg.png"/></div></div></figure><p id="8521" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><a class="ae jy" href="https://en.wikipedia.org/wiki/Short-time_Fourier_transform" rel="noopener ugc nofollow" target="_blank"> STFT </a>和<a class="ae jy" href="http://www.fon.hum.uva.nl/praat/manual/MelSpectrogram.html" rel="noopener ugc nofollow" target="_blank"> melspectrogram </a>是音频分类中最流行的表示输入数据的方法。(一般认为 melspectograms 是更小数据集的更好选择。)然而，当作者使用这两种预处理方法进行各种体验时，他们发现情况并非如此。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mb"><img src="../Images/59f1186736c7f4d5d70c431361ce7bb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Job8-RPAfWqo6Sane6d_Rw.png"/></div></div></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="3983" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> 2.3。比例效应和频率轴权重的分析</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mc"><img src="../Images/260b16cc3be99b2b75897e7ba6aabfa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ya4BM_0OWVSNvu4j9_JH0A.png"/></div></div></figure><p id="c665" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在本节中，作者试验了两种不同的输入表示 log-melspectrogram 和 melspectrogram，三种频率加权方案 per-frequency、A-weighting 和 bypass，以及两种缩放方法 X10 (on)和 X1 (off)。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi md"><img src="../Images/99b6c988f8d9f11bca3ad6ae7935ba0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GPpyEC54FVwIeX2DVos70w.png"/></div></div></figure><p id="6548" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，当用 log()函数预处理音频时(使用或不使用缩放因子 10，我们可以观察到 AUC 分数的增加。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="5154" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> 2.4。量值的对数压缩</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lz"><img src="../Images/adc05237f9a35b16216821a2510f7189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*at-6it-4UgLuyFKVt-Serg.png"/></div></div></figure><p id="2ceb" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">将 log()函数应用于音频文件是一个好主意的原因之一，因为它将数据的分布改变为高斯分布。如下所示，当对 melSpectrogram 应用 log()函数时，我们可以观察到平滑的钟形曲线。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi me"><img src="../Images/0ff20d3ea2a75aad9b6546372131f57b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hZQ1Ukf3DPgdL7DjplVRfA.png"/></div></div></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="2e73" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结论</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/a9cd6b695ff5b2fdae8ef125280e4528.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*Tzhkknh8p_HupZq2vnhHxw.png"/></div></figure><p id="67e1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">作者发现对数标度是音乐分类任务的最佳预处理方法。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="4f81" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">最后的话</strong></p><p id="d63b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这是一本相当有趣的读物。</p><p id="403d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 给我，如果你想看我所有写作的列表，请<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">在这里查看我的网站</a>。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">与此同时，请在我的 twitter <a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，并访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。我也实现了<a class="ae jy" href="https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec" rel="noopener">广残网，请点击这里查看博文 pos </a> t</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="76bf" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="ef94" class="mg mh iq kb b kc kd kg kh kk mi ko mj ks mk kw ml mm mn mo bi translated">Cho，k .，Fazekas，g .，Cho，k .，和 Sandler，M. (2017 年)。音乐标注深度神经网络音频信号预处理方法的比较。Arxiv.org。检索于 2018 年 6 月 23 日，来自<a class="ae jy" href="https://arxiv.org/abs/1709.01922" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1709.01922</a></li><li id="30a5" class="mg mh iq kb b kc mp kg mq kk mr ko ms ks mt kw ml mm mn mo bi translated">什么是 A、C 和 Z 频率权重？——noise news。(2011).噪音新闻。检索于 2018 年 6 月 24 日，来自<a class="ae jy" href="https://www.cirrusresearch.co.uk/blog/2011/08/what-are-a-c-z-frequency-weightings/" rel="noopener ugc nofollow" target="_blank">https://www . cirrus research . co . uk/blog/2011/08/what-are-a-c-z-frequency-weightings/</a></li><li id="2ecf" class="mg mh iq kb b kc mp kg mq kk mr ko ms ks mt kw ml mm mn mo bi translated">歌曲元数据以及为什么它隐藏在您的数字音乐文件中。(2018).救生索。检索于 2018 年 6 月 24 日，来自 https://www.lifewire.com/what-is-music-tagging-2438569<a class="ae jy" href="https://www.lifewire.com/what-is-music-tagging-2438569" rel="noopener ugc nofollow" target="_blank"/></li><li id="d04b" class="mg mh iq kb b kc mp kg mq kk mr ko ms ks mt kw ml mm mn mo bi translated">百万首歌曲数据集。(2018).Labrosa.ee.columbia.edu。检索于 2018 年 6 月 24 日，来自 https://labrosa.ee.columbia.edu/millionsong/<a class="ae jy" href="https://labrosa.ee.columbia.edu/millionsong/" rel="noopener ugc nofollow" target="_blank"/></li><li id="7623" class="mg mh iq kb b kc mp kg mq kk mr ko ms ks mt kw ml mm mn mo bi translated">LibROSA — librosa 0.6.1 文档。(2018).librosa . github . io . 2018 年 6 月 24 日检索，来自<a class="ae jy" href="https://librosa.github.io/librosa/" rel="noopener ugc nofollow" target="_blank">https://librosa.github.io/librosa/</a></li><li id="58c7" class="mg mh iq kb b kc mp kg mq kk mr ko ms ks mt kw ml mm mn mo bi translated">keunwochoi/kapre。(2018).GitHub。检索于 2018 年 6 月 24 日，来自<a class="ae jy" href="https://github.com/keunwoochoi/kapre" rel="noopener ugc nofollow" target="_blank">https://github.com/keunwoochoi/kapre</a></li><li id="3c36" class="mg mh iq kb b kc mp kg mq kk mr ko ms ks mt kw ml mm mn mo bi translated">短时傅立叶变换。(2018).En.wikipedia.org。检索于 2018 年 6 月 24 日，来自<a class="ae jy" href="https://en.wikipedia.org/wiki/Short-time_Fourier_transform" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Short-time_Fourier_transform</a></li><li id="4ebd" class="mg mh iq kb b kc mp kg mq kk mr ko ms ks mt kw ml mm mn mo bi translated">梅尔声谱图。(2018).Fon.hum.uva.nl .检索于 2018 年 6 月 24 日，来自<a class="ae jy" href="http://www.fon.hum.uva.nl/praat/manual/MelSpectrogram.html" rel="noopener ugc nofollow" target="_blank">http://www.fon.hum.uva.nl/praat/manual/MelSpectrogram.html</a></li></ol></div></div>    
</body>
</html>