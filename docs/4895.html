<html>
<head>
<title>Decrypt Generative Artificial Intelligence and GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解密生成式人工智能和 GANs</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/decrypt-generative-artificial-intelligence-and-gans-16646dbb4426?source=collection_archive---------9-----------------------#2018-09-13">https://towardsdatascience.com/decrypt-generative-artificial-intelligence-and-gans-16646dbb4426?source=collection_archive---------9-----------------------#2018-09-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="28e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">大家好，</p><p id="0813" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">今天的话题是 AI 的一个非常令人兴奋的方面，叫做生成式人工智能。简言之，生成式人工智能指的是一种算法，它使机器能够使用文本、音频文件和图像等东西来<strong class="jp ir">创建/生成</strong>内容。在之前的<a class="ae kl" href="https://sergioskar.github.io/Autoencoder/" rel="noopener ugc nofollow" target="_blank">帖子</a>中，我谈到了变化的自动编码器以及它们如何用来生成新图像。我提到过它们是一个更大的模型集的一部分，称为生成模型，我将在下一篇文章中更多地讨论它们。所以我们在这里。</p><p id="a492" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如我在那篇文章中简要解释的，有两种模式。判别性和生成性。第一类是最常见的模型，如卷积或递归神经网络，用于区分/辨别数据中的模式，以便将它们归类。图像识别、皮肤癌诊断、以太坊预测等应用都属于判别模式的范畴。</p><p id="bbad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">后者能够在数据中生成<strong class="jp ir">新模式</strong>。因此，他们可以产生新的图像，新的文本，新的音乐。以严格的数学形式来说，判别模型试图估计后验概率 p(y|x)，这是给定输入样本(手写数字的图像)的输出样本(例如手写数字)<strong class="jp ir">的概率。另一方面，生成模型估计联合概率 p(x，y)，这是输入样本和样本输出同时为真的概率。实际上，它试图计算一组类的分布，而不是它们之间的边界。</strong></p><p id="11c5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你能想象可能性吗？嗯，你可以通过查看该领域的当前进展和一些现有的应用来了解它们。迄今为止，生成模型已经被用于从图像中产生文本，开发肿瘤学分子，发现新药，将梵高等艺术家的风格转化为新的图像。我敢肯定你听说过 Deepfakes，他们把名人的脸放在任何类型的视频上。如果你认为你能分辨真假，那就别想了。你不能。</p><p id="0f98" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你点击了上面的一些链接，你可能会注意到一些更有趣的东西。由于一种叫做 GANs 的东西，所有的应用都成为可能。GANs 或<strong class="jp ir">生成性对抗网络</strong>是大多数生成性应用背后的基础架构。当然，还有许多其他很酷的模型，如变分自动编码器、深度玻尔兹曼机器、马尔可夫链，但 GANs 是过去三年围绕生成式人工智能有如此多宣传的原因。</p><h1 id="27ec" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">什么是生成性对抗网络？</h1><p id="16ab" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">2016 年，伊恩·古德菲勒(Ian Goodfellow)在过去十年最有前途的人工智能<a class="ae kl" href="https://arxiv.org/pdf/1406.2661.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中引入了生成性对抗网络。它们是一种无监督的学习技术，基于一个简单的前提:</p><p id="eb6e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你想生成新的数据。你是做什么的？你建造两个模型<strong class="jp ir">。你训练第一个产生假数据，第二个辨别真假。你让他们互相竞争</strong>。</p><p id="d140" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">嘣！这就是了。我希望事情就这么简单。它不是。但这是 GANs 背后的主要原则。</p><p id="1ebb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好的，让我们进入一些细节。第一个模型是神经网络，称为生成器。生成器的工作是产生虚假数据，输入时只有噪音。第二个模型，鉴别器，接收真实图像和伪造图像(由生成器产生)作为输入，并学习识别图像是否是伪造的。当你让他们互相竞争并同时训练他们时，奇迹就开始了:</p><p id="4fb2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">生成器在图像生成方面变得越来越好，因为它的最终目标是欺骗鉴别器。鉴别器变得越来越擅长区分真假图像，因为它的目标是不被愚弄。结果是我们现在有了来自鉴别器的难以置信的真实的假数据。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/f08f89fd6f599d64c15e63a89fea7f48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*E0prGC0pXhrO4QcE.jpg"/></div></div></figure><p id="0a51" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上图是一个很好的类比，描述了 GAN 之间的功能。生成者可以被视为制造欺诈性文件的伪造者，而鉴别者可以被视为试图检测这些文件的侦探。他们参与了一场零和游戏，随着时间的推移，他们都变得越来越好。</p><p id="37e8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">到目前为止一切顺利。我们有模型，现在我们必须训练它们。这就是问题开始出现的地方，因为它不是我们用梯度下降和损失函数训练神经网络的标准方法。这里我们有两个相互竞争的模型。那么，我们该怎么办？</p><p id="5b98" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们不确定。GAN 的优化是目前最活跃的研究领域之一，不断有新的论文出现。我将尝试解释这里的基础，我需要一些数学和一些博弈论。！！)来做到这一点。请不要离开。和我在一起，最后，一切都会变得有意义。</p><h1 id="7ca4" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">如何训练他们？</h1><p id="4bb2" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">我们可以认为这里有一个<a class="ae kl" href="https://en.wikipedia.org/wiki/Minimax" rel="noopener ugc nofollow" target="_blank">极小极大</a>博弈。引用维基百科的话:“一个玩家的马希民值是在不知道其他玩家的行动的情况下，该玩家能够确定得到的最高值；等价地，这是当其他玩家知道该玩家的动作时，他们可以强迫该玩家接受的最低值”</p><p id="7a45" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">换句话说，第一个玩家试图最大化他的奖励，同时最小化他的对手奖励。第二个玩家试图完成完全相同的目标。</p><p id="9af4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们的例子中，<strong class="jp ir">鉴别器试图最大化分配正确标签给真实数据和生成样本的概率。而生成器试图最小化鉴别器正确答案的概率</strong>。</p><p id="bb8e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将损失表示为一个极大极小函数:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mb"><img src="../Images/3bd57970cb1834848d072f2f22fed0ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xVU_ZCXCai_BOIut.jpg"/></div></div></figure><p id="01db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是什么？</p><p id="23f5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">鉴别器试图使函数最大化；因此，我们可以对目标函数执行梯度上升。生成器试图最小化函数；因此，我们可以对函数进行梯度下降。通过在梯度上升和下降之间交替，可以训练模型。</p><p id="6deb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当鉴别器不能最大化函数，生成器不能最小化函数时，训练停止。用博弈论的术语来说，他们达到纳什均衡。</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="f0d9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我希望你还在。这是主要的想法，被称为对抗性训练。当然，有几个经常出现的陷阱，例如:</p><ul class=""><li id="8cc9" class="me mf iq jp b jq jr ju jv jy mg kc mh kg mi kk mj mk ml mm bi translated">模型参数振荡并且从不收敛，</li><li id="9ffe" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">鉴别器太成功了，以至于发生器梯度消失</li><li id="0400" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">它对超参数高度敏感</li><li id="51f0" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">生成器产生有限种类的样本</li></ul><p id="f7f8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在过去的几年里，科学家们为解决这些问题做出了巨大的贡献，我们可以说已经取得了很大的进展。只要在<a class="ae kl" href="http://www.arxiv-sanity.com/" rel="noopener ugc nofollow" target="_blank"> arxiv-sanity </a>上快速搜索一下。不过，现在还早。记住。甘的存在不到三年。</p><p id="991d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我将用一些关键事实来结束我的发言。如果你跳过整篇文章，没关系。但是不要忽略这些:</p><ul class=""><li id="f4e2" class="me mf iq jp b jq jr ju jv jy mg kc mh kg mi kk mj mk ml mm bi translated">生成式人工智能用于从真实数据中生成新数据</li><li id="be98" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">GAI 最突出的模式是生成性对抗网络。</li><li id="697f" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">甘的是两个神经网络参与了一个游戏。第一个试图制造新的虚假数据，第二个试图将它们与真实数据区分开来。随着训练的进行，他们都越来越擅长自己的工作。</li><li id="782a" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">甘的训练还有很多工作要做</li><li id="9cd3" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">GAN 的实时应用是……(我该如何用一个词来形容呢？嗯嗯……)huuuuge。</li></ul><p id="9b14" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">菲尼托…</p><blockquote class="ms mt mu"><p id="41f0" class="jn jo mv jp b jq jr js jt ju jv jw jx mw jz ka kb mx kd ke kf my kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="iq">如果您有任何想法、评论、问题或者您只想了解我的最新内容，请随时在</em></strong><a class="ae kl" href="https://www.linkedin.com/in/sergios-karagiannakos/" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">Linkedin</strong></a><strong class="jp ir">，</strong><a class="ae kl" href="https://twitter.com/KarSergios" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">Twitter</strong></a><strong class="jp ir">，</strong><a class="ae kl" href="https://www.instagram.com/sergios_krg/" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">insta gram</strong></a><strong class="jp ir">，</strong><a class="ae kl" href="https://github.com/SergiosKar" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">Github</strong></a><strong class="jp ir">或在我的</strong></p></blockquote></div><div class="ab cl mz na hu nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ij ik il im in"><p id="ef77" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="mv">原载于 2018 年 9 月 13 日</em><a class="ae kl" href="https://sergioskar.github.io/Generative_Artificial_Intelligence/" rel="noopener ugc nofollow" target="_blank"><em class="mv">sergioskar . github . io</em></a><em class="mv">。</em></p></div></div>    
</body>
</html>