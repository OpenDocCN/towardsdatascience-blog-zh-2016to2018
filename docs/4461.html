<html>
<head>
<title>Classify butterfly images with deep learning in Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Keras 中用深度学习对蝴蝶图像进行分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/classify-butterfly-images-with-deep-learning-in-keras-b3101fe0f98?source=collection_archive---------5-----------------------#2018-08-17">https://towardsdatascience.com/classify-butterfly-images-with-deep-learning-in-keras-b3101fe0f98?source=collection_archive---------5-----------------------#2018-08-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/cb94eb4278856d6fb1ff177305d9e16c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K4agkAxY1R6zPzK8s_CqbQ.jpeg"/></div></div></figure><p id="0915" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">不久前，我在荷兰组织<a class="ae kw" href="https://www.vlinderstichting.nl/actueel/nieuws/nieuwsbericht/?bericht=1492" rel="noopener ugc nofollow" target="_blank"> Vlinderstichting </a>的网站上读到了一篇有趣的博文。每年他们组织一次蝴蝶计数。志愿者帮助确定他们花园里不同的蝴蝶种类。Vlinderstichting 收集并分析结果。</p><p id="83a1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于蝴蝶种类的确定是由志愿者完成的，这个过程不可避免地容易出错。因此，<strong class="ka ir"><em class="kx">Vlinderstichting</em></strong>的工作量太大，因为他们必须手动检查提交的内容是否正确。</p><p id="859b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">具体来说，有三种蝴蝶的 Vlinderstichting 得到了许多错误的判定。这些是</p><ul class=""><li id="776c" class="ky kz iq ka b kb kc kf kg kj la kn lb kr lc kv ld le lf lg bi translated">棕褐色或棕褐色</li><li id="cf84" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated"><a class="ae kw" href="https://en.wikipedia.org/wiki/Gatekeeper_(butterfly)" rel="noopener ugc nofollow" target="_blank">看门人</a>或 Pyronia tithonus</li><li id="b6a1" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated"><a class="ae kw" href="https://en.wikipedia.org/wiki/Small_heath_(butterfly)" rel="noopener ugc nofollow" target="_blank">小石南</a>或蒲葵</li></ul><p id="f354" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在本文中，我将描述拟合深度学习模型的步骤，该模型有助于区分前两种蝴蝶。</p><h1 id="6749" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">使用 Flickr API 下载图像</h1><p id="74e0" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">为了训练一个卷积神经网络，我需要<strong class="ka ir"> <em class="kx">找到带有正确标签的蝴蝶图像</em> </strong>。当然，我可以自己给我想分类的蝴蝶拍照。他们有时在我的花园里飞来飞去…</p><p id="0491" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">开玩笑，那要花很长时间。为此，我需要一种自动获取图像的方法。为此，我通过 Python 使用了<strong class="ka ir"> <em class="kx"> Flickr API </em> </strong>。</p><h2 id="74a0" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">设置 Flickr API</h2><p id="8173" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">首先，我用 pip 安装了<a class="ae kw" href="https://pypi.python.org/pypi/flickrapi/2.3" rel="noopener ugc nofollow" target="_blank"> <strong class="ka ir"> <em class="kx"> flickrapi 包</em> </strong> </a>。然后我在 Flickr 网站上创建必要的<a class="ae kw" href="https://www.flickr.com/services/api/misc.api_keys.html" rel="noopener ugc nofollow" target="_blank"> API 键</a>来连接 Flickr API。</p><p id="6d2a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">除了 flickrapi 包之外，我还导入了<strong class="ka ir"> <em class="kx"> os </em> </strong>和<strong class="ka ir"> <em class="kx"> urllib </em> </strong>包，用于下载图像和设置目录。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="7872" class="mp ln iq ng b gy nk nl l nm nn">from flickrapi import FlickrAPI<br/>import urllib<br/>import os<br/>import config</span></pre><p id="ec27" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在<strong class="ka ir"> <em class="kx"> config </em> </strong>模块中，我为 Flickr API 定义了公钥和密钥。这只是一个 Python 脚本(config.py ),代码如下:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="95f8" class="mp ln iq ng b gy nk nl l nm nn">API_KEY = 'XXXXXXXXXXXXXXXXX'  // replace with your key<br/>API_SECRET = 'XXXXXXXXXXXXXXXXX'  // replace with your secret<br/>IMG_FOLDER = 'XXXXXXXXXXXXXXXXX'  // replace with your folder to store the images</span></pre><p id="4c14" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">出于安全原因，我将这些<strong class="ka ir"> <em class="kx">密钥保存在一个单独的文件中</em> </strong>。因此，您可以将代码保存在公共存储库中，如 GitHub 或 BitBucket，并将 config.py 放在. gitignore 中。因此，您可以与其他人共享您的代码，而不必担心有人会访问您的凭据。</p><p id="8880" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了提取不同蝴蝶种类的图像，我写了一个函数<strong class="ka ir"><em class="kx">download _ Flickr _ photos</em></strong>。我会一步一步解释这个函数。此外，我已经在 GitHub<a class="ae kw" href="https://github.com/bertcarremans/Vlindervinder/tree/master/flickr" rel="noopener ugc nofollow" target="_blank">上发布了完整的代码。</a></p><h2 id="fd02" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">输入参数</h2><p id="1609" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">首先，我检查输入参数的类型或值是否正确。如果没有，我会抛出一个错误。参数的解释可以在函数的 docstring 中找到。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="071d" class="mp ln iq ng b gy nk nl l nm nn">if not (isinstance(keywords, str) or isinstance(keywords, list)):<br/>    raise AttributeError('keywords must be a string or a list of strings')</span><span id="a3c5" class="mp ln iq ng b gy no nl l nm nn">if not (size in ['thumbnail', 'square', 'medium', 'original']):<br/>    raise AttributeError('size must be "thumbnail", "square", "medium" or "original"')</span><span id="88fb" class="mp ln iq ng b gy no nl l nm nn">if not (max_nb_img == -1 or (max_nb_img &gt; 0 and isinstance(max_nb_img, int))):<br/>    raise AttributeError('max_nb_img must be an integer greater than zero or equal to -1')</span></pre><p id="91dd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">其次，我定义了稍后将在 walk 方法中使用的一些参数。我为关键字创建了一个列表，并确定需要从哪个 URL 下载图像。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="7fc8" class="mp ln iq ng b gy nk nl l nm nn">if isinstance(keywords, str):<br/>    keywords_list = []<br/>    keywords_list.append(keywords)<br/>else:<br/>    keywords_list = keywords<br/>if size == 'thumbnail':<br/>    size_url = 'url_t'<br/>elif size == 'square':<br/>    size_url = 'url_q'<br/>elif size == 'medium':<br/>    size_url = 'url_c'<br/>elif size == 'original':<br/>    size_url = 'url_o'</span></pre><h2 id="fa6c" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">连接到 Flickr API</h2><p id="0999" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">接下来，我连接到 Flickr API。在 FlickrAPI 调用中，我使用了配置模块中定义的 API 键。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="8ff9" class="mp ln iq ng b gy nk nl l nm nn">flickr = FlickrAPI(config.API_KEY, config.API_SECRET)</span></pre><h2 id="6947" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">为每种蝴蝶创建子文件夹</h2><p id="ef4b" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">我将每种蝴蝶的图片保存在单独的子文件夹中。每个子文件夹的名称是蝴蝶物种的名称，由关键字。如果子文件夹还不存在，我就创建它。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="6010" class="mp ln iq ng b gy nk nl l nm nn">results_folder = config.IMG_FOLDER + keyword.replace(" ", "_") + "/"<br/>if not os.path.exists(results_folder):<br/>    os.makedirs(results_folder)</span></pre><h2 id="b0a3" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">在 Flickr 图书馆里漫步</h2><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="fab7" class="mp ln iq ng b gy nk nl l nm nn">photos = flickr.walk(<br/>    text=keyword,<br/>    extras='url_m',<br/>    license='1,2,4,5',<br/>    per_page=50)</span></pre><p id="3666" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我使用 Flickr API 的<strong class="ka ir"> <em class="kx"> walk </em> </strong>方法来搜索指定关键字的图像。这个 walk 方法与 Flickr API 中的<a class="ae kw" href="http://www.flickr.com/services/api/flickr.photos.search.html" rel="noopener ugc nofollow" target="_blank">搜索方法</a>具有相同的参数。</p><p id="06bd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在<strong class="ka ir"> <em class="kx">文本参数中，</em> </strong> <em class="kx"> </em>我使用关键字来搜索与该关键字相关的图片。其次，在<strong class="ka ir"> <em class="kx"> extras 参数中，</em> </strong>我指定<strong class="ka ir"> <em class="kx"> url_m </em> </strong>为小、中尺寸的图片。在这个<a class="ae kw" href="http://librdf.org/flickcurl/api/flickcurl-searching-search-extras.html" rel="noopener ugc nofollow" target="_blank"> Flickcurl C 库</a>中给出了关于图像大小和它们各自 URL 的更多解释。</p><p id="bd59" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">第三，在<strong class="ka ir"> <em class="kx">许可参数中，</em> </strong>我选择了带有非商业许可的图像。关于许可证代码及其含义的更多信息可以在 Flickr <a class="ae kw" href="https://www.flickr.com/services/api/flickr.photos.licenses.getInfo.html" rel="noopener ugc nofollow" target="_blank"> API 平台</a>上找到。最后，<strong class="ka ir"> <em class="kx"> per_page 参数</em> </strong>指定了我允许每页显示多少张图片。</p><p id="b97e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，我有一个名为<strong class="ka ir"> <em class="kx">的图片生成器</em> </strong>来下载图片。</p><h2 id="6292" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">下载 Flickr 图像</h2><p id="92e9" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">有了照片生成器，我可以下载搜索查询中找到的所有图片。首先，我得到了下载图片的具体网址。然后我增加 count 变量，并使用这个计数器来创建图像文件名。</p><p id="9663" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用<strong class="ka ir"> <em class="kx"> urlretrieve </em> </strong>方法，我下载图像并保存在蝴蝶种类的文件夹中。如果出现错误，我会打印出错误消息。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="a89b" class="mp ln iq ng b gy nk nl l nm nn">for photo in photos:<br/>    try:<br/>        url=photo.get('url_m')<br/>        print(url)<br/>        count += 1<br/>        urllib.request.urlretrieve(url,  results_folder + str(count) +".jpg")<br/>    except Exception as e:<br/>        print(e, 'Download failure')</span></pre><p id="1962" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了下载多种蝴蝶，我创建了一个列表，并在循环 中调用函数 download_flickr_photos。为了简单起见，我只下载了上面提到的三种蝴蝶中的两种。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="b7f6" class="mp ln iq ng b gy nk nl l nm nn">butterflies = ['meadow brown butterfly', 'gatekeeper butterfly']<br/>for butterfly in butterflies:<br/>    download_flickr_photos(butterfly)</span></pre><h1 id="94f7" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">图像的数据扩充</h1><p id="59d0" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">在少量图像 上训练 convnet 将导致<strong class="ka ir"> <em class="kx">过拟合</em> </strong>。因此，该模型在分类新的、看不见的图像时会出错。数据扩充有助于避免这种情况。幸运的是，Keras 有一些很好的工具来轻松转换图像。</p><p id="5937" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我写了另一篇关于如何防止过度合身的文章，你可以点击下面的链接。</p><p id="8487" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我想和我儿子在路上给汽车“分类”的方式做个比较。目前他只有 2 岁，还没有见过像成年人一样多的车。所以你可以说他的图像“训练集”相当小。因此，他更有可能将汽车分类错误。例如，他有时会误把救护车当成警车。</p><p id="dd3d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">随着他年龄的增长，他会看到更多的救护车和警车，以及我将给他的相应标签。因此，他的训练集将变得更大，从而他将更正确地对它们进行分类。</p><p id="47a9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">出于这个原因，我们需要<strong class="ka ir"> <em class="kx">向 convnet 提供比目前更多的蝴蝶图片</em> </strong>。一个简单的解决方案是<strong class="ka ir">数据扩充</strong>。简而言之，这意味着对 Flickr 图像应用一组变换。</p><p id="8254" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Keras 提供了<a class="ae kw" href="https://keras.io/preprocessing/image/" rel="noopener ugc nofollow" target="_blank"> <strong class="ka ir"> <em class="kx">大范围的图像变换</em> </strong> </a>。但首先，我们必须转换图像，以便 Keras 可以使用它们。</p><h2 id="233d" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">将图像转换为数字</h2><p id="c881" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">我们从导入 Keras 模块开始。我们将用一个示例图像来演示图像转换。为此，我们使用了<strong class="ka ir"> <em class="kx"> load_img </em> </strong>方法。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="9083" class="mp ln iq ng b gy nk nl l nm nn">from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img</span><span id="1f12" class="mp ln iq ng b gy no nl l nm nn">i = load_img('data/train/maniola_jurtina/1.jpg' )<br/>x = img_to_array(i)<br/>x = x.reshape((1,) + x.shape)</span></pre><p id="1847" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">load_img 方法创建一个 Python 图像库文件。我们需要将它转换成一个 Numpy 数组，以便稍后在<strong class="ka ir"><em class="kx">imagedata generator</em></strong>方法中使用。用方便的<strong class="ka ir"> <em class="kx"> img_to_array </em> </strong>方法就搞定了。因此，我们有一个 75x75x3 形状的数组。这些尺寸反映了宽度、高度和 RGB 值。</p><p id="f7b6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">事实上，图像的每个像素有 3 个 RGB 值。这些范围在 0 到 255 之间，代表红色、绿色和蓝色的强度。较低的值代表较高的强度，较高的值代表较低的强度。例如，一个像素可以表示为这三个值的列表[ 78，136，60]。黑色将表示为[0，0，0]。</p><p id="ff00" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后，我们需要添加一个额外的维度，以避免在应用转换时出现值错误。这是通过<strong class="ka ir"> <em class="kx">整形</em> </strong>功能完成的。</p><p id="148d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">好了，现在我们有东西可以用了。让我们继续转换。</p><h2 id="ec99" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">旋转</h2><p id="d52a" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">通过指定一个 0 到 180 之间的值，Keras 将<strong class="ka ir"> <em class="kx">随机选择一个角度</em> </strong>来旋转图像。它会顺时针或逆时针转动。在我们的例子中，图像最大旋转 90 度。</p><p id="1053" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">ImageDataGenerator 还有一个参数<strong class="ka ir"> <em class="kx"> fill_mode </em> </strong>。默认值为“最近”。通过在原始图像的宽度和高度范围内旋转图像，我们得到了“空”像素。fill_mode 然后使用最近的像素来填充这个空白空间。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="7b8a" class="mp ln iq ng b gy nk nl l nm nn">imgGen = ImageDataGenerator(rotation_range = 90)</span><span id="6e72" class="mp ln iq ng b gy no nl l nm nn">i = 1<br/>for batch in imgGen.flow(x, batch_size=1, save_to_dir='example_transformations', save_format='jpeg', save_prefix='trsf'):<br/>    i += 1<br/>    if i &amp;gt; 3:<br/>        break</span></pre><p id="bac3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在<strong class="ka ir"> <em class="kx">流</em> </strong>方法中，我们指定将转换后的图像保存到哪里。请确保该目录存在！为了方便起见，我们还给新创建的图像加上前缀。flow 方法可以无限运行，但是对于这个例子，我们只生成三个图像。所以当我们的计数器达到这个值时，我们就中断 for 循环。你可以在下面看到结果。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/3e9d8c26a799b9c28d6f7952d63d3e73.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/0*13zgRDGD4wiCXaV4"/></div></figure><h2 id="57bf" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">宽度移动</h2><p id="44e8" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">在<strong class="ka ir"><em class="kx">width _ shift _ range</em></strong>参数中，您可以指定图像向左或向右移动的原始宽度的比率。同样，fill_mode 将填充新创建的空像素。对于其余的示例，我将只展示如何用相应的参数实例化 ImageDataGenerator。生成图像的代码与旋转示例中的代码相同。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="5626" class="mp ln iq ng b gy nk nl l nm nn">imgGen = ImageDataGenerator(width_shift_range = 90)</span></pre><p id="eb89" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在变换后的图像中，我们看到图像向右移动。空像素被填充，这使它看起来有点拉伸。</p><p id="49ef" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">通过为<strong class="ka ir"><em class="kx">height _ shift _ range</em></strong>参数指定一个值，同样可以实现上移或下移。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/07e552922e7a83688b428a8571cc1942.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/0*6QPKSelfUNv3nqpP"/></div></figure><h2 id="c5f9" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">重新调节</h2><p id="5c1b" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">在任何其他预处理之前，重新缩放图像会将每个像素的 RGB 值<strong class="ka ir"> <em class="kx">乘以选定的值</em> </strong>。在我们的示例中，我们对值应用最小-最大缩放。因此，这些值的范围将在 0 和 1 之间。这使得值更小，模型更容易处理。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="8fbf" class="mp ln iq ng b gy nk nl l nm nn">imgGen = ImageDataGenerator(rescale = 1./255)</span></pre><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/23350c2faf1e76b991d21ac454bbecb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/0*cL16CxQRI8ku95G0"/></div></figure><h2 id="719b" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">剪(羊毛)</h2><p id="df6c" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">使用<strong class="ka ir"> <em class="kx">剪切范围</em> </strong>参数，我们可以指定必须如何应用剪切变换。当该值设置得太高时，这种变换会产生相当奇怪的图像。所以不要定的太高。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="1544" class="mp ln iq ng b gy nk nl l nm nn">imgGen = ImageDataGenerator(shear_range = 0.2)</span></pre><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/2696ea2d3569365902cd77eff70e35e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/0*0hz6PRFDhCcZqroI"/></div></figure><h2 id="b0c4" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">一款云视频会议软件</h2><p id="e2d6" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">这种变换将<strong class="ka ir"> <em class="kx">放大到画面</em> </strong>内部。就像剪切参数一样，这个值不应该被夸大以保持图像的真实感。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="f671" class="mp ln iq ng b gy nk nl l nm nn">imgGen = ImageDataGenerator(zoom_range = 0.2)</span></pre><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/85910c0f2ace22141b44e4e27257686b.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/0*KZcllgjjicFeJZ2B"/></div></figure><h2 id="3a59" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">水平翻转</h2><p id="5884" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">这种变换水平翻转图像。生活有时会很简单…</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="0535" class="mp ln iq ng b gy nk nl l nm nn">imgGen = ImageDataGenerator(horizontal_flip = True)</span></pre><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/2890069d5a7a68934be3660b60f03a7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:380/0*j2499m0rsxeWA8US"/></div></figure><h2 id="e200" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">所有转换组合</h2><p id="a688" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">现在我们已经分别看到了每个变换的效果，我们一起应用所有的组合。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="167d" class="mp ln iq ng b gy nk nl l nm nn">imgGen = ImageDataGenerator(<br/>    rotation_range = 40,<br/>    width_shift_range = 0.2,<br/>    height_shift_range = 0.2,<br/>    rescale = 1./255,<br/>    shear_range = 0.2,<br/>    zoom_range = 0.2,<br/>    horizontal_flip = True)</span><span id="33a6" class="mp ln iq ng b gy no nl l nm nn">i = 1<br/>for batch in imgGen.flow(x, batch_size=1, save_to_dir='example_transformations', save_format='jpeg', save_prefix='all'):<br/>    i += 1<br/>    if i &amp;gt; 3:<br/>        break</span></pre><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/ea828275fc5f53036e2096ba145ac2d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/0*OalIoIrSd47zo6U6"/></div></figure><h2 id="c2a6" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">设置文件夹结构</h2><p id="4988" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">我们需要将这些图像存储在特定的文件夹结构中。因此，我们可以使用方法<strong class="ka ir"><em class="kx">flow _ from _ directory</em></strong>来扩充图像并创建相应的标签。该文件夹结构需要如下所示:</p><ul class=""><li id="6674" class="ky kz iq ka b kb kc kf kg kj la kn lb kr lc kv ld le lf lg bi translated"><strong class="ka ir">列车</strong></li><li id="a7a6" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">马尼奥拉 _ 尤尔蒂纳</li><li id="233e" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">0.jpg</li><li id="8864" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">1.jpg</li><li id="9af0" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi">…</li><li id="0059" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">pyronia_tithonus</li><li id="d48e" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">0.jpg</li><li id="d956" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">1.jpg</li><li id="3024" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi">…</li><li id="1560" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated"><strong class="ka ir">验证</strong></li><li id="f35e" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">马尼奥拉 _ 尤尔蒂纳</li><li id="09f7" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">0.jpg</li><li id="1406" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">1.jpg</li><li id="08aa" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi">…</li><li id="9071" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">pyronia_tithonus</li><li id="3b7c" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">0.jpg</li><li id="dc47" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">1.jpg</li><li id="959e" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi">…</li></ul><p id="34b1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了创建这个文件夹结构，我创建了一个要点<a class="ae kw" href="https://gist.github.com/bertcarremans/679624f369ed9270472e37f8333244f5" rel="noopener ugc nofollow" target="_blank"><strong class="ka ir"><em class="kx">img _ train _ test _ split . py</em></strong></a>。请随意在您的项目中使用它。</p><h2 id="97e7" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">创建发电机</h2><p id="df95" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">和以前一样，我们为训练生成器指定配置参数。验证图像将不会被转换为训练图像。我们只划分 RGB 值，使它们变小。</p><p id="b50c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"><em class="kx">flow _ from _ directory</em></strong>方法从 train 或 validation 文件夹中获取图像，并生成 32 个转换图像的批次。通过将<strong class="ka ir"> <em class="kx"> class_mode </em> </strong>设置为‘二进制’,基于图像的文件夹名称创建一维标签。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="c3c2" class="mp ln iq ng b gy nk nl l nm nn">train_datagen = ImageDataGenerator(<br/>    rotation_range = 40,<br/>    width_shift_range = 0.2,<br/>    height_shift_range = 0.2,<br/>    rescale = 1./255,<br/>    shear_range = 0.2,<br/>    zoom_range = 0.2,<br/>    horizontal_flip = True)</span><span id="c2d3" class="mp ln iq ng b gy no nl l nm nn">validation_datagen = ImageDataGenerator(rescale=1./255)</span><span id="3417" class="mp ln iq ng b gy no nl l nm nn">train_generator = train_datagen.flow_from_directory(<br/>    'data/train',<br/>    batch_size=32,<br/>    class_mode='binary')</span><span id="464a" class="mp ln iq ng b gy no nl l nm nn">validation_generator = validation_datagen.flow_from_directory(<br/>    'data/validation',<br/>    batch_size=32,<br/>    class_mode='binary')</span></pre><h2 id="13f7" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">不同的图像尺寸呢？</h2><p id="5849" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">Flickr API 允许您下载特定大小的图像。然而，<strong class="ka ir"> <em class="kx">在现实应用中，图像尺寸并不总是恒定的</em> </strong>。如果图像的纵横比相同，我们可以简单地调整图像的大小。否则，我们可以裁剪图像。不幸的是，很难在保持我们想要分类的对象完整的同时裁剪图像。</p><p id="a6c8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Keras 可以处理不同大小的图像。配置模型时，您可以在<strong class="ka ir"><em class="kx">input _ shape</em></strong>中为宽度和高度指定<strong class="ka ir"> <em class="kx"> None。</em></strong></p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="7e57" class="mp ln iq ng b gy nk nl l nm nn">input_shape=(3, None, None)  # Theano<br/>input_shape=(None, None, 3)  # Tensorflow</span></pre><p id="1455" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我想展示的是，它可以处理不同的图像尺寸，然而，它有一些缺点。</p><ul class=""><li id="c696" class="ky kz iq ka b kb kc kf kg kj la kn lb kr lc kv ld le lf lg bi translated">并非所有层(如展平)都将“无”作为输入尺寸</li><li id="8686" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">运行起来计算量可能很大</li></ul><h1 id="e9ea" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">构建深度学习模型</h1><p id="3193" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">在本文的剩余部分，我将讨论卷积神经网络的结构，并用我们的 butterfly 项目中的一些例子来说明。在本文的最后，我们将有我们的第一个分类结果。</p><h2 id="0434" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">卷积神经网络由哪几层组成？</h2><p id="c9fa" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">当然，您可以选择将多少层及其类型添加到您的卷积神经网络(也称为 CNN 或 convnet)。在这个项目中，我们将从以下结构开始:</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/9887249ffce0b0a891dffac247279d72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/0*CQ1MMd7iHaxt2vyb"/></div></figure><p id="7155" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们了解每一层的作用，以及我们如何用 Keras 创建它们。</p><h2 id="de0c" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">输入层</h2><p id="8ba6" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">这些不同版本的图像通过几次变换进行了修改。然后，这些图像被转换成数字表示或矩阵。</p><p id="8202" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这个矩阵的尺寸将是<strong class="ka ir"> <em class="kx">宽 x 高 x(颜色)通道数</em> </strong> <em class="kx">。</em>对于 RGB 图像，通道数量为三个。对于灰度图像，这等于 1。下面你可以看到一个 7×7 的 RGB 图像的数字表示。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/42cb57fac5421471fd9171ae3b070350.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/0*uiTW_iwX3T1EkRec"/></div></figure><p id="2ddd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于我们的图像大小为 75×75，我们需要在添加第一个卷积层时在 input_shape 参数中指定。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="93b8" class="mp ln iq ng b gy nk nl l nm nn">cnn = Sequential()<br/>cnn.add(Conv2D(32,(3,3), input_shape = (3 ,75 ,75)))</span></pre><h2 id="adfc" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">卷积层</h2><p id="e4ba" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">在前几层中，卷积神经网络将寻找<strong class="ka ir"><em class="kx"/></strong>的低级特征，如水平或垂直边缘。我们在网络中走得越远，它将寻找更高级的特征，例如蝴蝶的翅膀。但是，当它只获得数字作为输入时，它如何检测特征呢？这就是过滤器发挥作用的地方。</p><h2 id="b04f" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">过滤器(或内核)</h2><p id="c272" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">您可以将滤镜想象为扫描图像的特定大小的探照灯。下面的过滤器示例的尺寸<strong class="ka ir">为 3x3x3，包含检测垂直边缘的权重。对于灰度图像，尺寸应该是 3x3x1。通常，过滤器的尺寸小于我们要分类的图像。通常使用 3×3、5×5 或 7×7。第三维应该总是等于通道的数量。</strong></p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/520f63535ff39d4ca87f8ffc8de721e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/0*iO1ffMmvSQzRGjBK"/></div></figure><p id="9765" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">扫描图像时，会转换 RGB 值。它通过将 RGB 值乘以滤镜的<strong class="ka ir">权重</strong>来完成这一转换。最后，相乘后的值在所有通道上求和。在我们的 7x7x3 图像示例和 3x3x3 滤镜中，这将导致 5x5x1 的结果。</p><p id="a81b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下面的动画说明了这个<strong class="ka ir"> <em class="kx">卷积运算</em> </strong>。为简单起见，我们只在红色通道中寻找垂直边缘。因此，绿色和蓝色通道的权重都等于零。但是您应该记住，这些通道的乘法结果会添加到红色通道的结果中。</p><p id="7843" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如下所示，卷积层将产生数值结果。当您有较高的数字时，这意味着过滤器遇到了它正在寻找的特征。在我们的例子中，垂直边缘。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/d4ffa3c549306bbf27dd322d7fcb9763.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/0*ykXVTApvty9Q0lAX"/></div></figure><p id="ed26" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们可以指定想要一个以上的过滤器。这些过滤器可以在图像中寻找它们自己的特征。假设我们使用 32 个大小为 3x3x3 的过滤器。在我们的示例中，所有过滤器的结果叠加在一起，最终得到一个 5x5x32 的体积。在上面的代码片段中，我们添加了 32 个大小为 3x3x3 的过滤器。</p><h2 id="976d" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">进展</h2><p id="4aee" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">在上面的例子中，我们看到滤镜<strong class="ka ir"> <em class="kx">一次上移</em> </strong>一个像素。这就是所谓的跨步。我们可以增加过滤器上移的像素数量。增加步幅将更快地减小原始图像的尺寸。在下面的示例中，您可以看到滤镜如何以步长 2 移动，这将导致 3x3x3 滤镜的 3x3x1 结果和 7x7x3 图像。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/b4743c9efdc5038e89b1a6112ad4edbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/0*Ds4PLixAjvOMPF9j"/></div></figure><h2 id="4cfe" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">填料</h2><p id="7b7f" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">通过应用滤镜，原始图像的<strong class="ka ir"> <em class="kx">维度被快速缩小</em> </strong>。尤其是图像边缘的像素在卷积运算中只使用一次。这导致了信息的丢失。如果要避免这种情况，可以指定填充。填充会在图像周围添加“额外像素”。</p><p id="e607" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">假设我们在 7x7x3 图像周围添加一个像素的填充。这产生了 9x9x3 的图像。如果我们应用一个 3x3x3 的过滤器，步长为 1，我们最终得到 7x7x1 的结果。因此，在这种情况下，我们保留原始图像的尺寸，外部像素被多次使用。</p><p id="725f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您可以计算具有特定填充和步长的卷积运算的结果，如下所示:</p><p id="3b95" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 1 + [(原始维度+填充 x 2 —过滤维度)/步幅大小] </strong></p><p id="8967" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">例如，假设我们有这样的 conv 层设置:</p><ul class=""><li id="b78d" class="ky kz iq ka b kb kc kf kg kj la kn lb kr lc kv ld le lf lg bi translated">7x7x3 图像</li><li id="ae7f" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">3x3x3 过滤器</li><li id="4a33" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">1 个像素的填充</li><li id="151a" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">2 像素的步幅</li></ul><p id="8730" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这将得出 1+[(7+1 x 2–3)/2]= 4</p><h2 id="857f" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">为什么我们需要卷积层？</h2><p id="5a7d" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">使用 conv 层的一个好处是估计的参数数量<strong class="ka ir"> <em class="kx">要少得多</em> </strong>。比普通隐藏层低得多。假设我们继续使用 7x7x3 的示例图像和 3x3x3 的滤镜，没有填充，步幅为 1。卷积层将有 5x5x1 + 1 个偏差= 26 个权重要估计。在隐层中具有 7x7x3 输入和 5x5x1 神经元的神经网络中，我们将需要估计 3.675 个权重。想象一下，当你有更大的图像时，这个数字是多少…</p><h2 id="e065" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">ReLu 层</h2><p id="749a" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">或<strong class="ka ir"> <em class="kx">整流线性单元层。</em> </strong>这一层给网络增加了非线性。卷积层是线性层，因为它将滤波器权重和 RGB 值的乘积相加。</p><p id="8bf3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于 x &lt;= 0. Otherwise, it is equal to the value of x. The code in Keras to add a ReLu layer is:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="f623" class="mp ln iq ng b gy nk nl l nm nn">cnn.add(Activation(‘relu’))</span></pre><h2 id="eb15" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">Pooling</h2><p id="9716" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">Pooling aggregates the input volume in order to <strong class="ka ir"> <em class="kx">的所有值，ReLu 函数的结果等于零。进一步减小尺寸</em> </strong>。这加快了计算时间，因为要估计的参数数量减少了。除此之外，通过使网络更加健壮，它有助于避免过拟合。下面我们举例说明最大池的大小为 2×2，步幅为 2。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/656910221b53b4877a89a7ee74ea71f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/0*9q3rhJssuh_2xtxw"/></div></figure><p id="083c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Keras 中添加大小为 2×2 的池的代码是:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="02bb" class="mp ln iq ng b gy nk nl l nm nn">cnn.add(MaxPooling2D(pool_size = (2 ,2)))</span></pre><h2 id="fb45" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">全连接层</h2><p id="7a11" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">最后，convnet 能够检测输入图像中的更高级特征。然后，这可以作为全连接层的输入。在此之前，我们将展平最后一个 ReLu 层的输出。展平意味着我们把它转换成一个矢量。然后向量值被连接到完全连接层中的所有神经元。为了在 Python 中做到这一点，我们使用了以下 Keras 函数:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="378c" class="mp ln iq ng b gy nk nl l nm nn">cnn.add(Flatten())        <br/>cnn.add(Dense(64))</span></pre><h2 id="cd6f" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">拒绝传统社会的人</h2><p id="5fd5" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">就像合用一样，辍学可以帮助<strong class="ka ir"> <em class="kx">避免过度适应</em> </strong>。在模型训练期间，它随机将输入的指定部分设置为零。辍学率在 20%到 50%之间被认为是有效的。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="de19" class="mp ln iq ng b gy nk nl l nm nn">cnn.add(Dropout(0.2))</span></pre><h2 id="b3bb" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">乙状结肠激活</h2><p id="c843" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">因为我们想要产生一个<strong class="ka ir"> <em class="kx">概率</em> </strong>图像是两个蝴蝶种类之一(即二进制分类)，我们可以使用一个 sigmoid 激活层。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="8b3e" class="mp ln iq ng b gy nk nl l nm nn">cnn.add(Activation('relu'))<br/>cnn.add(Dense(1))<br/>cnn.add(Activation( 'sigmoid'))</span></pre><h2 id="3dee" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">卷积神经网络在蝴蝶图像中的应用</h2><p id="e8f5" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">现在我们可以定义完整的卷积神经网络结构，如本文开头所示。首先，我们需要导入必要的 Keras 模块。然后，我们可以开始添加我们上面解释的层。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="ae68" class="mp ln iq ng b gy nk nl l nm nn">from keras.models import Sequential<br/>from keras.layers import Conv2D, MaxPooling2D<br/>from keras.layers import Activation, Flatten, Dense, Dropout<br/>from keras.preprocessing.image import ImageDataGenerator</span><span id="ae63" class="mp ln iq ng b gy no nl l nm nn">import time</span><span id="a8be" class="mp ln iq ng b gy no nl l nm nn">IMG_SIZE = # Replace with the size of your images<br/>NB_CHANNELS = # 3 for RGB images or 1 for grayscale images<br/>BATCH_SIZE = # Typical values are 8, 16 or 32<br/>NB_TRAIN_IMG = # Replace with the total number training images<br/>NB_VALID_IMG = # Replace with the total number validation images</span></pre><p id="a7b8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我做了一些额外的参数明确的 conv 层。这里有一个简短的解释:</p><ul class=""><li id="8e79" class="ky kz iq ka b kb kc kf kg kj la kn lb kr lc kv ld le lf lg bi translated"><strong class="ka ir"> <em class="kx"> kernel_size </em> </strong>指定过滤器的大小。因此，对于第一个 conv 层，这是 2×2 的大小</li><li id="8858" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated"><strong class="ka ir"><em class="kx">padding = ' same '</em></strong>表示应用零填充，这样原始图像尺寸被保留。</li><li id="4488" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated"><strong class="ka ir"><em class="kx">padding = ' valid '</em></strong>表示我们不应用任何填充。</li><li id="964a" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated"><strong class="ka ir"><em class="kx">data _ format = ' channels _ last '</em></strong>只是在 input_shape 参数中最后指定颜色通道的个数。</li></ul><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="2d2c" class="mp ln iq ng b gy nk nl l nm nn">cnn = Sequential()</span><span id="7b65" class="mp ln iq ng b gy no nl l nm nn">cnn.add(Conv2D(filters=32, <br/>               kernel_size=(2,2), <br/>               strides=(1,1),<br/>               padding='same',<br/>               input_shape=(IMG_SIZE,IMG_SIZE,NB_CHANNELS),<br/>               data_format='channels_last'))<br/>cnn.add(Activation('relu'))<br/>cnn.add(MaxPooling2D(pool_size=(2,2),<br/>                     strides=2))</span><span id="4ec5" class="mp ln iq ng b gy no nl l nm nn">cnn.add(Conv2D(filters=64,<br/>               kernel_size=(2,2),<br/>               strides=(1,1),<br/>               padding='valid'))<br/>cnn.add(Activation('relu'))<br/>cnn.add(MaxPooling2D(pool_size=(2,2),<br/>                     strides=2))</span><span id="9689" class="mp ln iq ng b gy no nl l nm nn">cnn.add(Flatten())        <br/>cnn.add(Dense(64))<br/>cnn.add(Activation('relu'))</span><span id="7208" class="mp ln iq ng b gy no nl l nm nn">cnn.add(Dropout(0.25))</span><span id="6e94" class="mp ln iq ng b gy no nl l nm nn">cnn.add(Dense(1))<br/>cnn.add(Activation('sigmoid'))</span><span id="3a96" class="mp ln iq ng b gy no nl l nm nn">cnn.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])</span></pre><p id="2a44" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后，我们编译这个网络结构，并设置损失参数为<strong class="ka ir"><em class="kx">binary _ cross entropy</em></strong>，这对于二进制目标是好的，并使用<strong class="ka ir"> <em class="kx">准确度</em> </strong>作为评估度量。</p><p id="40c0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在指定了网络结构之后，我们为训练和验证样本创建生成器。在训练样本上，我们如上所述应用<strong class="ka ir"> <em class="kx">数据扩充</em> </strong>。对于验证样本，我们不应用任何增强，因为它们仅用于评估模型性能。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="0141" class="mp ln iq ng b gy nk nl l nm nn">train_datagen = ImageDataGenerator(<br/>    rotation_range = 40,                  <br/>    width_shift_range = 0.2,                  <br/>    height_shift_range = 0.2,                  <br/>    rescale = 1./255,                  <br/>    shear_range = 0.2,                  <br/>    zoom_range = 0.2,                     <br/>    horizontal_flip = True)</span><span id="7186" class="mp ln iq ng b gy no nl l nm nn">validation_datagen = ImageDataGenerator(rescale = 1./255)</span><span id="e8a6" class="mp ln iq ng b gy no nl l nm nn">train_generator = train_datagen.flow_from_directory(<br/>    '../flickr/img/train',<br/>    target_size=(IMG_SIZE,IMG_SIZE),<br/>    class_mode='binary',<br/>    batch_size = BATCH_SIZE)</span><span id="789c" class="mp ln iq ng b gy no nl l nm nn">validation_generator = validation_datagen.flow_from_directory(<br/>    '../flickr/img/validation',<br/>    target_size=(IMG_SIZE,IMG_SIZE),<br/>    class_mode='binary',<br/>    batch_size = BATCH_SIZE)</span></pre><p id="d899" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用生成器上的<strong class="ka ir"><em class="kx">flow _ from _ directory</em></strong><em class="kx"/>方法，我们可以轻松地遍历指定目录中的所有图像。</p><p id="a215" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后，我们可以在训练数据上拟合卷积神经网络，并用验证数据进行评估。模型的最终权重可以被保存并在以后重用。</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="167e" class="mp ln iq ng b gy nk nl l nm nn">start = time.time()<br/>cnn.fit_generator(<br/>    train_generator,<br/>    steps_per_epoch=NB_TRAIN_IMG//BATCH_SIZE,<br/>    epochs=50,<br/>    validation_data=validation_generator,<br/>    validation_steps=NB_VALID_IMG//BATCH_SIZE)<br/>end = time.time()<br/>print('Processing time:',(end - start)/60)</span><span id="9aa8" class="mp ln iq ng b gy no nl l nm nn">cnn.save_weights('cnn_baseline.h5')</span></pre><p id="e529" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kx">历元的数量</em> </strong>被任意设置为 50。一个时期是向前传播的循环，检查误差，然后在向后传播期间调整权重。</p><p id="4c3d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"><em class="kx">steps _ per _ epoch</em></strong>设置为训练图像的数量除以批量大小(顺便说一下，双除法符号将确保结果是整数而不是浮点数)。指定一个大于 1 的<strong class="ka ir"><em class="kx"/></strong>批量将会加快进程。validation_steps 参数同上。</p><h2 id="d077" class="mp ln iq bd lo mq mr dn ls ms mt dp lw kj mu mv ma kn mw mx me kr my mz mi na bi translated">结果</h2><p id="97aa" class="pw-post-body-paragraph jy jz iq ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">运行 50 个纪元后，我们的训练精度为 0.8091，验证精度为 0.7359。所以卷积神经网络仍然遭受相当多的<strong class="ka ir">过拟合</strong>。我们还看到验证的准确性变化很大。这是因为我们有一小组验证样本。最好每轮评估都做 k 倍交叉验证。但这需要相当长的时间。</p><p id="1154" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了解决过度拟合问题，我们可以:</p><ul class=""><li id="0a37" class="ky kz iq ka b kb kc kf kg kj la kn lb kr lc kv ld le lf lg bi translated">增加辍学率</li><li id="eec8" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">在每一层应用下降</li><li id="f210" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">查找更多培训数据</li></ul><p id="040f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将研究前两个选项并监控结果。我们第一个模型的结果将作为基线。在应用额外的漏失层并增加漏失率后，模型的过度拟合程度会有所降低。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/1d85e04e869523f8f942f2f539b4ae0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*WtRA-Cng7X2EWK7zdtdC8g.png"/></div></figure><p id="12df" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我希望你们都喜欢读这篇文章，并且学到了一些新的东西。完整代码可在<a class="ae kw" href="https://github.com/bertcarremans/Vlindervinder" rel="noopener ugc nofollow" target="_blank"> Github </a>上获得。干杯！</p></div></div>    
</body>
</html>