<html>
<head>
<title>Dataset creation and cleaning: Web Scraping using Python — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据集创建和清理:使用 Python 进行 Web 抓取—第 1 部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dataset-creation-and-cleaning-web-scraping-using-python-part-1-33afbf360b6b?source=collection_archive---------5-----------------------#2018-10-01">https://towardsdatascience.com/dataset-creation-and-cleaning-web-scraping-using-python-part-1-33afbf360b6b?source=collection_archive---------5-----------------------#2018-10-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/708a1d32fd52c41885310952aec090bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eOzuh_vmxVmyKkqy"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">“world map poster near book and easel” by <a class="ae kc" href="https://unsplash.com/@nicnut?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Nicola Nuttall</a> on <a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="dff6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我的<a class="ae kc" rel="noopener" target="_blank" href="/creating-a-dataset-using-an-api-with-python-dcc1607616d">上一篇文章</a>中，我讨论了使用应用编程接口(API)和 Python 库生成数据集。API 允许我们以一种简单的方式从网站中获取非常有用的信息。然而，并非所有网站都有 API，这使得收集相关数据变得困难。在这种情况下，我们可以使用网络抓取来访问网站的内容并创建我们的数据集。</p><blockquote class="lb lc ld"><p id="3d10" class="kd ke le kf b kg kh ki kj kk kl km kn lf kp kq kr lg kt ku kv lh kx ky kz la ij bi translated">网络抓取是一种用于从网站提取大量数据的技术，通过这种技术，数据被提取并以表格(电子表格)格式保存到您计算机中的本地文件或数据库中。— <a class="ae kc" href="https://www.webharvy.com/articles/what-is-web-scraping.html" rel="noopener ugc nofollow" target="_blank">韦伯维</a></p></blockquote><p id="a879" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一般来说，网络搜集包括访问大量网站并从这些网站收集数据。然而，我们可以限制自己从单一来源收集大量信息，并将其用作数据集。在这个特殊的例子中，我们将探索维基百科。我还会解释我们需要的 HTML 基础知识。完整的项目可以在 Github 知识库<a class="ae kc" href="https://github.com/kb22/Web-Scraping-using-Python" rel="noopener ugc nofollow" target="_blank">中使用 Python </a>进行网络抓取。</p><p id="057e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个例子只是为了演示。但是，我们必须始终遵循网站指南，然后才能抓取该网站并出于任何商业目的访问其数据。</p><p id="0d1e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是一篇由两部分组成的文章。在第一部分中，我们将探索如何使用 BeautifulSoup 从网站获取数据，在第二部分中，我们将清理收集的数据集。</p><h1 id="c751" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">确定内容</h1><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mg"><img src="../Images/554dc89ac4141b19ed57d517b4969748.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nx_oauzxt2m6f-BP"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">“man drawing on dry-erase board” by <a class="ae kc" href="https://unsplash.com/@kaleidico?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Kaleidico</a> on <a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="e8f4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将访问<a class="ae kc" href="https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population" rel="noopener ugc nofollow" target="_blank">按人口统计的国家和属地列表</a>维基百科网页。该网页包括一个表格，其中列有国名、人口、数据收集日期、占世界人口的百分比和来源。如果我们去任何一个国家的页面，所有关于它的信息都写在页面上，右边有一个标准框。该框包括许多信息，如总面积、含水量、GDP 等。</p><p id="31ad" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里，我们将把这两个网页的数据合并成一个数据集。</p><ol class=""><li id="3bc8" class="ml mm iq kf b kg kh kk kl ko mn ks mo kw mp la mq mr ms mt bi translated"><strong class="kf ir">国家列表:</strong>在访问第一页时，我们将提取国家列表、其人口和占世界人口的百分比。</li><li id="cef3" class="ml mm iq kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated"><strong class="kf ir">国家:</strong>然后我们将访问每个国家的页面，并获得包括总面积、水资源百分比和 GDP(名义)在内的信息。</li></ol><p id="cf5f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我们的最终数据集将包括每个国家的信息。</p><h1 id="6b91" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">HTML 基础</h1><p id="a9e4" class="pw-post-body-paragraph kd ke iq kf b kg mz ki kj kk na km kn ko nb kq kr ks nc ku kv kw nd ky kz la ij bi translated">您在浏览器中浏览的每个网页实际上都是用<a class="ae kc" href="https://en.wikipedia.org/wiki/HTML" rel="noopener ugc nofollow" target="_blank">超文本标记语言(HTML) </a>构建的。它有两个部分，<strong class="kf ir"> head </strong>包含标题和任何样式和 JavaScript 的导入，<strong class="kf ir"> body </strong>包含显示为网页的内容。我们对网页的主体感兴趣。</p><p id="197e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">HTML 由标签组成。标签由开始的<code class="fe ne nf ng nh b">&lt;</code>和结束的<code class="fe ne nf ng nh b">&gt; </code>尖括号描述，尖括号内的标签名称作为开始，如果在开始的尖括号后有正斜杠<code class="fe ne nf ng nh b">/</code>，则标记结束。比如<code class="fe ne nf ng nh b">&lt;div&gt;&lt;/div&gt;</code>、<code class="fe ne nf ng nh b">&lt;p&gt;Some text&lt;/p&gt;</code>等。</p><figure class="mh mi mj mk gt jr"><div class="bz fp l di"><div class="ni nj l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Homepage.html as an example</figcaption></figure><p id="a8ae" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有两种方法可以直接访问网页上的任何元素(标签)。我们可以使用唯一的<strong class="kf ir"> id </strong>，或者我们可以使用可以与多个元素关联的<strong class="kf ir">类</strong>。在这里，我们可以看到<code class="fe ne nf ng nh b">&lt;div&gt;</code>的属性<em class="le"> id </em>为<code class="fe ne nf ng nh b">base</code>，作为对该元素的引用，而所有用<code class="fe ne nf ng nh b">td</code>标记的表格单元格都有相同的<em class="le">类</em>，称为<code class="fe ne nf ng nh b">data</code>。</p><p id="9d4b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通常有用的标签包括:</p><ol class=""><li id="bc21" class="ml mm iq kf b kg kh kk kl ko mn ks mo kw mp la mq mr ms mt bi translated">每当你包含某些内容时，你就把它们一起包含在这个单一的实体中。它可以作为许多不同元素的父元素。因此，如果这里应用了一些样式更改，它们也会反映在它的子元素中。</li><li id="409d" class="ml mm iq kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated"><code class="fe ne nf ng nh b">&lt;a&gt;</code>:该标签中描述了链接，其属性<code class="fe ne nf ng nh b">href</code>中提到了点击该链接将加载的网页。</li><li id="881e" class="ml mm iq kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated"><code class="fe ne nf ng nh b">&lt;p&gt;</code>:每当一些信息要以文本块的形式显示在网页上时，就使用这个标签。每个这样的标签都作为它自己的段落出现。</li><li id="1470" class="ml mm iq kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated"><code class="fe ne nf ng nh b">&lt;span&gt;</code>:当信息要内联显示时，我们使用这个标签。当两个这样的标签并排放置时，它们会出现在同一行，不像段落标签。</li><li id="fedf" class="ml mm iq kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated"><code class="fe ne nf ng nh b">&lt;table&gt;</code>:表格借助该标签在 HTML 中显示，其中数据显示在由行和列交叉形成的单元格中。</li></ol><h1 id="6aed" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">导入库</h1><p id="c16b" class="pw-post-body-paragraph kd ke iq kf b kg mz ki kj kk na km kn ko nb kq kr ks nc ku kv kw nd ky kz la ij bi translated">我们首先从导入必要的库开始，即 numpy、pandas、urllib 和 BeautifulSoup。</p><ol class=""><li id="f652" class="ml mm iq kf b kg kh kk kl ko mn ks mo kw mp la mq mr ms mt bi translated">numpy: 一个非常流行的库，它使得数组操作变得非常简单和快速。</li><li id="97a9" class="ml mm iq kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated">它帮助我们转换表格结构中的数据，因此我们可以使用已经被高效开发的众多函数来操作数据。</li><li id="dc32" class="ml mm iq kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated">我们使用这个库来打开我们想要从中提取数据的 url。</li><li id="3344" class="ml mm iq kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated"><strong class="kf ir"> BeautifulSoup: </strong>这个库帮助我们获得想要处理的页面的 HTML 结构。然后，我们可以使用它的功能来访问特定的元素并提取相关信息。</li></ol><figure class="mh mi mj mk gt jr"><div class="bz fp l di"><div class="ni nj l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Import all libraries</figcaption></figure><h1 id="74d1" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">了解数据</h1><p id="10af" class="pw-post-body-paragraph kd ke iq kf b kg mz ki kj kk na km kn ko nb kq kr ks nc ku kv kw nd ky kz la ij bi translated">最初，我们定义我们只是读取 url，然后从中提取 HTML 的基本功能。我们会在需要的地方引入新的功能。</p><figure class="mh mi mj mk gt jr"><div class="bz fp l di"><div class="ni nj l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Function to get HTML of a webpage</figcaption></figure><p id="8e54" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在<code class="fe ne nf ng nh b">getHTMLContent()</code>函数中，我们传入 URL。这里，我们首先使用<code class="fe ne nf ng nh b">urlopen</code>方法打开 url。这使我们能够应用 BeautifulSoup 库来使用解析器获取 HTML。虽然有许多可用的解析器，但在这个例子中我们使用了<code class="fe ne nf ng nh b">html.parser</code>，它使我们能够解析 HTML 文件。然后，我们简单地返回输出，然后我们可以用它来提取我们的数据。</p><p id="e54d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们使用这个函数来获取国家列表的维基百科页面的 HTML 内容。我们看到这些国家出现在一张表格中。因此，我们使用<code class="fe ne nf ng nh b">find_all()</code>方法来查找页面上的所有表格。我们在这个函数中提供的参数决定了它返回的元素。当我们需要表格时，我们将参数作为<code class="fe ne nf ng nh b">table</code>传递，然后遍历所有的表格来确定我们需要的表格。</p><figure class="mh mi mj mk gt jr"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="08de" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们用<code class="fe ne nf ng nh b">prettify()</code>函数打印每个表格。该函数使输出更具可读性。现在，我们需要分析输出，看看哪个表有我们要搜索的数据。经过大量的检查，我们可以看到带有类<em class="le"> wikitable sortable </em>的表中有我们需要的数据。因此，我们的下一步是访问这个表及其数据。为此，我们将使用函数<code class="fe ne nf ng nh b">find()</code>,它不仅允许我们指定我们正在寻找的元素，还允许我们指定它的属性，比如类名。</p><figure class="mh mi mj mk gt jr"><div class="bz fp l di"><div class="ni nj l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Print all country links</figcaption></figure><p id="f8a1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">HTML 中的表格由标签<code class="fe ne nf ng nh b">&lt;tr&gt;&lt;/tr&gt;</code>表示的行组成。每一行都有单元格，这些单元格可以是使用<code class="fe ne nf ng nh b">&lt;th&gt;&lt;/th&gt;</code>定义的标题，也可以是使用<code class="fe ne nf ng nh b">&lt;td&gt;&lt;/td&gt;</code>定义的数据。因此，要访问每个国家的网页，我们可以从表格的国家列(第二列)的单元格中获取链接。因此，我们遍历表中的所有行，并读取变量<code class="fe ne nf ng nh b">country_link</code>中第二列的数据。对于每一行，我们提取单元格，并在第二列中获得元素<code class="fe ne nf ng nh b">a</code>(Python 中的编号从 0 开始，因此第二列意味着<code class="fe ne nf ng nh b">cell[1]</code>)。最后，我们打印所有的链接。</p><figure class="mh mi mj mk gt jr"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="675b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些链接不包括基地址，所以每当我们访问这些链接时，我们将附加<code class="fe ne nf ng nh b"><a class="ae kc" href="https://en.wikipedia.org" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org</a></code>作为前缀。</p><p id="ffaa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然我开发的从每个国家的网页中提取数据的功能可能看起来很小，但在我完成这个功能之前，已经对它进行了多次迭代。让我们一步一步来探索。</p><p id="9e89" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每个国家的页面右侧都有一个信息框，包括座右铭、名称、GDP、面积和其他重要特征。所以，首先我们用和以前一样的步骤来识别这个盒子的名称，它是一个类为<code class="fe ne nf ng nh b">infobox geography vcard</code>的表。接下来，我们定义变量<code class="fe ne nf ng nh b">additional_details</code>来收集我们将从这个页面获得的所有信息，放在一个数组中，然后我们可以将这个数组追加到国家数据集的列表中。</p><p id="b516" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我们在国家页面进入 Chrome 浏览器的 inspect 模式(右击任意位置并选择<code class="fe ne nf ng nh b">Inspect</code>选项)时，我们可以查看表格中每个标题的类别。我们对四个领域感兴趣，<em class="le">面积—总面积、水(%)，以及 GDP(名义)—总量、人均</em>。</p><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nk"><img src="../Images/c89efebc6cb994f9f36e58616e1844f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AZHP-Y7RWcBD6COfRwTnZA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Area — Total Area and Water (%)</figcaption></figure><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nk"><img src="../Images/009581c80170df5290504cf984fee689.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IbWD9CLotVt7oUS5dfLfYg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">GDP (nominal) — Total and Per capita</figcaption></figure><p id="6700" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以很容易地推断出标题<code class="fe ne nf ng nh b">Area</code>和<code class="fe ne nf ng nh b">GDP (nominal)</code>有类<code class="fe ne nf ng nh b">mergedtoprow</code>，而我们想要提取的数据有类<code class="fe ne nf ng nh b">mergedrow</code>或<code class="fe ne nf ng nh b">mergedrowbottom</code>。但是，我们不能直接访问任何数据元素，因为它们发生的顺序会根据每个国家而变化。对于一些国家，特定字段可能缺失，且<code class="fe ne nf ng nh b">total area</code>的<code class="fe ne nf ng nh b">mergedrow</code>可能是第 6 位，而对于一些其他国家，它可能是第 7 位。因此，我们需要首先看到<code class="fe ne nf ng nh b">mergedtoprow</code>的文本，如果它与面积或 GDP(名义)匹配，我们应该读取并收集这些数据。</p><p id="bd81" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">看起来很简单，但是当我尝试的时候，我立刻发现了一个问题，因为有些国家的<code class="fe ne nf ng nh b">water (%)</code>超过了 100。这是不可能的，因此，我们一定遗漏了什么。这是我意识到问题所在的时候。你看，如果我们在区域标题后读取两个值，并且缺少水值，我们将错误地读取人口的第一个值，从而给我们错误的数据。因此，我们需要确保当<code class="fe ne nf ng nh b">Population</code>标题被识别时，我们停止读取值。</p><p id="0d7d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们可以简单地将我们所有的知识添加到函数<code class="fe ne nf ng nh b">getAdditionalDetails()</code>中。我们定义变量<code class="fe ne nf ng nh b">read_content</code>来标记是否读取下一个值。除了前面描述的函数之外，我们在这里还使用了三种类型的函数:</p><ol class=""><li id="24f6" class="ml mm iq kf b kg kh kk kl ko mn ks mo kw mp la mq mr ms mt bi translated"><code class="fe ne nf ng nh b">get()</code>:这使我们不仅能找到，还能得到对特定元素的引用。</li><li id="75cd" class="ml mm iq kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated"><code class="fe ne nf ng nh b">get_text()</code>:获取元素开始和结束标签中的值。</li><li id="a408" class="ml mm iq kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated"><code class="fe ne nf ng nh b">strip()</code>:这将删除文本中可能出现的任何额外的前导和尾随空格。我们还可以指定我们希望删除的任何特定值，例如，在我们的情况下，新的行字符<code class="fe ne nf ng nh b">\n</code>。</li></ol><figure class="mh mi mj mk gt jr"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="755a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">迭代表中的所有行，迭代器检查当前行是否是匹配<em class="le">区域</em>或<em class="le"> GDP(名义)</em>的标题，并开始读取。在读取模式下，它会检查新元素是总面积还是总面积，如果是，它会读取并继续读取，以便在下一次运行时分别读取水(%)或人均 GDP。</p><p id="8d61" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们使用<code class="fe ne nf ng nh b">try</code>和<code class="fe ne nf ng nh b">except</code>来确保即使我们错过了某些值，我们的整个过程也不会结束。这是我在遍历完整的国家列表时学到的另一个教训。有些国家没有我们需要的所有信息，或者我们可能找不到所需名称的表格。在这种情况下，我们的流程可能会抛出一个错误，我们必须捕获该错误以返回一个空数组，并允许该流程在其他国家继续进行。</p><h1 id="8c71" class="li lj iq bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">创建数据集</h1><p id="93c8" class="pw-post-body-paragraph kd ke iq kf b kg mz ki kj kk na km kn ko nb kq kr ks nc ku kv kw nd ky kz la ij bi translated">最后，我们现在知道我们需要收集哪些信息以及如何收集。</p><p id="0084" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们首先从国家列表中读取表格的每一行，并收集每个国家的名称、人口和占世界人口的百分比。然后，我们使用该链接获得所有其他详细信息，包括总面积、水(%)、总 GDP 和人均 GDP。但是，如果附加信息少于 4，则该国家的信息缺失，我们不使用该数据。否则，我们将所有的信息添加到<code class="fe ne nf ng nh b">data_content</code>数组中，该数组被编译到<code class="fe ne nf ng nh b">dataset</code>数据帧中。</p><figure class="mh mi mj mk gt jr"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="afea" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们阅读表格的标题，并为 4 个额外的列添加标题。这些作为我们的数据集的标题，我们将其导出到一个. CSV 文件中，可以在这里找到<a class="ae kc" href="https://github.com/kb22/Web-Scraping-using-Python/blob/master/Dataset.csv" rel="noopener ugc nofollow" target="_blank"/>。</p></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><p id="ba30" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管我们的数据集现在已经准备好了，但它不是最有用的格式。我们需要使用适当的格式、统一的指标并删除不必要的符号和值来清理这个数据集。我们将在本文的第二部分讨论这个问题。</p><p id="d30b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">希望你喜欢我的文章。请随时伸出手，分享你的想法。</p></div></div>    
</body>
</html>