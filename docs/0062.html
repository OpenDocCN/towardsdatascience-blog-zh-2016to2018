<html>
<head>
<title>Tackling the Quora Questions dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解决Quora问题数据集</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tackling-the-quora-questions-dataset-43666c74bb0e?source=collection_archive---------1-----------------------#2017-03-03">https://towardsdatascience.com/tackling-the-quora-questions-dataset-43666c74bb0e?source=collection_archive---------1-----------------------#2017-03-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="fbd0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">语义相似性基本上是决定两个文档彼此有多相似，评估它对于识别重复帖子、半监督标签、两篇新闻文章是否谈论同一件事以及许多其他应用非常有用。因此，当Quora在一月份发布了一个潜在重复问题的数据集时，我非常感兴趣，我决定看看我是否可以快速建立一个合理的方法。TL；大卫:得到有效的东西很容易，但是得到真正有效的东西很难——但是我越来越接近了。</p><h1 id="78d3" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">预处理</h1><p id="7452" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">该文件包含大约405，000个问题对，其中大约150，000个是重复的，255，000个是不同的。这种类的不平衡直接意味着，只要在每条记录上返回“distinct ”,就可以获得63%的准确率，所以我决定平衡这两个类，以确保分类器真正学到了一些东西。我还必须纠正TSV格式的一些小问题(本质上，一些问题包含了不该包含的新行，这扰乱了Python的csv模块)。然后我使用<a class="ae kl" href="https://github.com/myleott/ark-twokenize-py" rel="noopener ugc nofollow" target="_blank"> twokenize.py </a>对数据进行了标记化，这是<a class="ae kl" href="https://github.com/brendano/ark-tweet-nlp/blob/master/src/cmu/arktweetnlp/Twokenize.java" rel="noopener ugc nofollow" target="_blank"> CMU的ark-tweet-nlp标记器</a>的一个端口，其中<a class="ae kl" href="https://github.com/Sentimentron/ark-twokenize-py" rel="noopener ugc nofollow" target="_blank">做了一些修改，增加了对Python 3 </a>的支持。使用这个标记器没有特别的要求，但是我发现它在tweets和大多数你可以在网上找到的其他非正式文本上表现得相当好。</p><h1 id="af60" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">基线</h1><p id="875e" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">当一个简单的解决方案可以解决问题时，没有必要一头扎进一个复杂的解决方案，所以为了获得一个合理的基线，我决定使用一个标准的单词袋方法，同时使用线性和朴素贝叶斯分类器。scikit-learn可以轻松处理这种事情，它的训练速度非常快，实际上很难击败——线性模型在自我评估中达到了大约81%的准确率，这使它达到了我在深度模型中达到的最高水平。</p><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="lu lv l"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Baseline assessment script.</figcaption></figure><h1 id="7764" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">德拉库拉</h1><p id="296e" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated"><a class="ae kl" href="https://medium.com/@sentimentron/faceoff-theano-vs-tensorflow-e25648c31800#.igabc1icy" rel="noopener">我以前写过关于Dracula </a>的文章——它是一个字符级的自然语言模型，通过双向LSTMs构建更高级别的单词和文档表示。自从我上一次写这篇文章以来，我已经稍微改变了设计，去掉了特别昂贵的字符级LSTMs，代之以卷积层:这导致了更大的单词级表示，并且看起来比旧方法稍微更准确，至少在Twitter词性标注方面。在此基础上需要的唯一修改是1)同时对两个问题重复该模型，以产生文档级向量，以及2)最终分类层，其将两者结合起来，以产生重复/不重复答案。我尝试了两种不同的方法来得出最终答案:</p><ul class=""><li id="c810" class="ma mb iq jp b jq jr ju jv jy mc kc md kg me kk mf mg mh mi bi translated">模型1使用标准的softmax层，它可以被解释为每个类的概率度量。这种情况下的成本函数是标准平均softmax交叉熵。</li><li id="61be" class="ma mb iq jp b jq mj ju mk jy ml kc mm kg mn kk mf mg mh mi bi translated">模型2将每个文档向量折叠成128个条目，然后使用欧几里德距离来比较它们。本来想用余弦距离，但是这个好像训练起来有难度。为了构建成本函数，我反转了标签(因此1变成了“不相关”，0变成了“重复”)，并对预测距离与标签进行了均方误差分析。相似的问题逐渐获得相似的表示，而不相关的问题则没有，同时保持合理的权重。</li></ul><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mo"><img src="../Images/39b15ec915844ad681c0bf5b17ffd1dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bFaERft7D7e4cEE37m9CmQ.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Pretty messy high-level overview of model 2: two source documents are run through identical Dracula models, and the final document vectors are compared with Euclidean distance.</figcaption></figure><figure class="lp lq lr ls gt lt"><div class="bz fp l di"><div class="lu lv l"/></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">The core of the model — most of the other code in the repository is just data and IO.</figcaption></figure><h1 id="001b" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">比较</h1><p id="6e4b" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">Dracula的一个问题是，它非常慢，并且需要花费许多小时来运行数据集的一遍，所以为了保持我的性情，我选择报告50:50平衡训练的模型的准确性，以及保留的评估和测试集，以及原始文件的一个小样本(我称之为猜测集)，以了解它处理类不平衡的情况。评估集和测试集的区别在于，<strong class="jp ir">评估集是在训练</strong> <strong class="jp ir">时使用的，以确保模型不会过度拟合训练数据</strong>，并让我了解模型是否在学习一些东西；而<strong class="jp ir">测试数据在训练</strong>期间根本不使用，纯粹代表模型的性能。评估不用于基线训练，但显示模型在50:50班级平衡时的表现。猜测集是从原始文件中提取的，具有正确的类别比例，因此它可能包含训练、评估和测试数据，以及新的示例。事情是这样的:</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/0ce740c06bc44ab9a02d03174a2a38a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*gPNHSF9DVuqBA6lGR3G7Gw.png"/></div></figure><p id="020d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如前所述，基线在自我评估下表现得相当好，但是对于看不见的例子似乎表现得很差。这可能是因为它使用了一个热门词嵌入，这可能意味着它不能很好地概括新的例子。即便如此，67%也不应该被低估，因为它训练起来非常容易和快速——而且通过一些额外的功能工程，它可以很容易地变得更好。模型1似乎在看不见的例子上做得更好，但是仍然显示出过度拟合的迹象——我的假设是分类层很难将输入其中的两个文档向量关联起来。模型2在最初的试验中表现得特别好:由于每个字符只有8个浮点数的嵌入大小，它在看不见的例子上比模型1表现得更好，当用更大的嵌入大小重新训练时，它表现得甚至更好。也就是说，它仍然是最有趣的变体——它提供了良好的准确性和快速(相对而言)的训练，而文件大小不到64浮点模型的1%。</p><h1 id="5b57" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">将来的</h1><p id="50ce" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">因为我的时间和资源有限，所以我可以做很多超参数优化——特别是改变双向字级LSTMs的数量，并试验卷积层的数量和大小。我对谷歌在上周的TensorFlow开发峰会上宣布的Tensorboard 中增加的功能感到兴奋，这些功能基本上允许你为一系列超参数试验绘制有趣的指标，以及他们的新部署选项。我还想扩展训练数据，以纳入更多的重复问题数据集，以及额外的短文档相似性任务。</p><h1 id="ae7d" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">密码</h1><p id="9080" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">所有三个模型和基线的代码都在Github上:</p><ul class=""><li id="8e06" class="ma mb iq jp b jq jr ju jv jy mc kc md kg me kk mf mg mh mi bi translated"><a class="ae kl" href="https://github.com/Sentimentron/Dracula/tree/quora-model-1" rel="noopener ugc nofollow" target="_blank">模式一</a></li><li id="a086" class="ma mb iq jp b jq mj ju mk jy ml kc mm kg mn kk mf mg mh mi bi translated"><a class="ae kl" href="https://github.com/Sentimentron/Dracula/tree/quora-model-2-8" rel="noopener ugc nofollow" target="_blank">型号2 </a> (8尺寸嵌入)</li><li id="a471" class="ma mb iq jp b jq mj ju mk jy ml kc mm kg mn kk mf mg mh mi bi translated"><a class="ae kl" href="https://github.com/Sentimentron/Dracula/tree/quora-model-2-64" rel="noopener ugc nofollow" target="_blank">模式2 </a> (64尺寸嵌入)</li></ul><p id="bc2c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有关下载模型的说明，请查看README.md文件。</p></div></div>    
</body>
</html>