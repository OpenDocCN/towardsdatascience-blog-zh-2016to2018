<html>
<head>
<title>Thoughts on Adversarial Discriminative Domain Adaptation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于对抗性歧视性领域适应的思考</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/thoughts-on-adversarial-discriminative-domain-adaptation-f48e3938d518?source=collection_archive---------8-----------------------#2017-07-19">https://towardsdatascience.com/thoughts-on-adversarial-discriminative-domain-adaptation-f48e3938d518?source=collection_archive---------8-----------------------#2017-07-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="2106" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我偶然浏览了一下<a class="ae kl" href="https://arxiv.org/pdf/1702.05464" rel="noopener ugc nofollow" target="_blank">这篇论文</a>讨论了当测试图像属于不同于训练集的域时的图像分类。</p><p id="2c57" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我们有模型训练的情况时，例如动物的2D图片，并且面临需要对动物的3D图像进行分类的情况时，领域适应就发挥作用了。虽然它们属于同一个类(马)，但模型很困惑，因为它们看起来不同于它从中学习特征的马的图像。</p><p id="2936" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本文主要介绍了一种称为对抗鉴别域自适应的技术，它采用了GAN的思想，通过使用鉴别器来区分来自源域和目标域的图像。</p><p id="936c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于图像可以属于不同的域，我们首先学习到一个公共特征空间的映射，以便我们可以将一个域不变向量馈送给我们的鉴别器。我们在这里使用一个判别模型，并试图通过一个编码器(足够接近一个生成器，但不完全是一个)来学习映射。鉴别器接收来自两个域的映射，并判断图像是否属于源域。</p><p id="a666" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">ADDA为其鉴别器使用损失函数，使其完全依赖于其目标分布。优化损失函数基本上试图标记目标分布图像，就好像它们属于源域一样。对于映射，我们对源域和目标域使用联合权重，仅仅是因为由于不同的域，在一个域中学习的特征不需要在另一个域中相同。</p><p id="8029" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">建筑:</strong></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/89bcf131dacc8ef62702aaeadad11227.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2VhnQ_PxrJWM88MMXE6F2A.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Architecture for ADDA. (Source: <a class="ae kl" href="https://arxiv.org/pdf/1702.05464.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1702.05464.pdf</a>)</figcaption></figure><p id="eea2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们使用两种不同的CNN来学习映射。我们首先使用典型的图像分类技术训练源CNN和源分类器。在这一步之后，我们修复了源CNN和分类器。</p><p id="1655" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，在领域适应步骤中，我们通过标准的广告过程训练鉴别器和目标CNN。我们在这个阶段维护源映射并学习目标映射。</p><p id="d6c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，在测试阶段，我们使用目标映射对测试图像进行编码，并在其上运行分类器。</p><p id="b021" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">感谢阅读！</p></div></div>    
</body>
</html>