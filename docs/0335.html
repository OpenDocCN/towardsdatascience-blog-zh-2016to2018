<html>
<head>
<title>Transfer Learning using PyTorch — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用PyTorch进行迁移学习—第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/transfer-learning-using-pytorch-part-2-9c5b18e15551?source=collection_archive---------1-----------------------#2017-04-19">https://towardsdatascience.com/transfer-learning-using-pytorch-part-2-9c5b18e15551?source=collection_archive---------1-----------------------#2017-04-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="bbde" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在之前的博客中，我们讨论了神经网络如何使用迁移学习来完成各种计算机视觉任务。在这篇博客中，我们将探讨以下内容。</p><ol class=""><li id="85f6" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">VGG建筑</li><li id="c6b1" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">使用预卷积特征微调VGG</li><li id="6bd4" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">准确(性)</li><li id="7126" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">PyTorch和Keras在Tensorflow上的性能比较</li></ol><h2 id="2e47" class="la lb iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">VGG建筑:</h2><p id="b20c" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">迁移学习中研究最多的深度学习模型之一是VGG。我们将对VGG进行一个高层次的概述，以了解它是如何在迁移学习中得到最佳应用的。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ly"><img src="../Images/5c9561662e521a441060f65fde495956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3sD-1ZR9R6UaEOil9FFErQ.png"/></div></div></figure><p id="3aa8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">VGG模型可以分为两种逻辑块</p><ol class=""><li id="2133" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated"><strong class="jp ir">卷积块:</strong></li></ol><p id="3b10" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">预训练的VGG模型在超过1000个类别的图像网络数据集上被训练。卷积块包含多个卷积层。初始层包含低级特征，如直线、曲线。这个模块中的最后卷积层包含更复杂的图像特征，比如手、腿、眼睛等等。下图捕捉了不同图层中捕捉的特征类型。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi mk"><img src="../Images/a9e4481f57f42ff047cd630ffcf56aee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jPCEik198_CjtmSL2H6o4g.png"/></div></div></figure><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ml"><img src="../Images/566d9937feebab5242ea0fa1f0a00bb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Y6HZxK-lOmqB8KnizTCow.png"/></div></div></figure><p id="7764" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从上面的图像中可以看出，预训练模型的卷积层捕捉到的特征可以用于大多数类型的图像问题。上述功能可能不适用于卡通动画、医学图像等问题，因为它们需要完全不同的功能。</p><p id="c09f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">卷积层表现出两个重要的特性</p><ol class=""><li id="79bc" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">与全连接层相比，所需的参数数量要少得多。例如，具有3 * 3 * 64大小过滤器的卷积层仅需要576个参数。</li><li id="c280" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">卷积图层的计算开销很大，计算输出需要更长时间。</li></ol><p id="1b3c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 2。全连接块:</strong></p><p id="732a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该区块包含密集(在Keras中)/线性(在PyTorch中)层，并有缺失。FC层中要学习的参数数量巨大，但计算时间却少得多。</p><p id="6d07" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，我们通常最终按原样从VGG模型的卷积块中提取预卷积特征，并且仅训练通常来自全连接块的VGG模型的最后几层。</p><h2 id="511a" class="la lb iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated"><strong class="ak">使用预卷积功能微调VGG:</strong></h2><p id="8648" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">正如我们所知，卷积层的计算成本很高，因此计算一次卷积层的输出并使用它们来训练完全连接的层是有意义的。这种方法加快了使用迁移学习训练新模型的过程。例如，如果1次迭代需要3分钟来训练模型，则通过预先计算卷积层输出(假设需要2分钟),而对于FC块中的其余迭代，每次迭代只需要几秒钟。</p><p id="0011" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">预卷积特性:</strong></p><p id="dead" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我使用的是来自<strong class="jp ir"> kaggle </strong> 的<a class="ae kl" href="https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">猫狗</strong>数据集，包含25000张图片。我保留了2000张图片用于验证，剩下的23000张用于训练。</a></p><p id="9f38" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">硬件基准测试于:</strong></p><p id="00aa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我在上面提到的实验中使用了英特尔i7处理器、64 gb内存和Titan X GPU。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi mm"><img src="../Images/5ec6e4fe115ba4df281fdd4da9ea5913.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*90emu6g1cyUbpfnD-aZfRA.jpeg"/></div></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">My Monster playing with NN weights :)</figcaption></figure><p id="d53a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了计算卷积特征，我们让所有图像通过卷积层。幸运的是pytorch将VGG实现为两个逻辑块，由特征(卷积块)和分类器块(FC)组成。在下面的代码中，我们将使用features块来计算卷积层的输出。我们将它存储到bcolz数组中，以便进一步处理。Bcolz数组提供了一个压缩和更快的方法来处理数组。</p><pre class="lz ma mb mc gt mr ms mt mu aw mv bi"><span id="2f8e" class="la lb iq ms b gy mw mx l my mz">model_vgg = models.vgg16(pretrained=True)<br/>for param in model_vgg.parameters():<br/>    param.requires_grad = False<br/>def preconvfeat(dataset):<br/>    conv_features = []<br/>    labels_list = []<br/>    for data in dataset:<br/>        inputs,labels = data</span><span id="2f56" class="la lb iq ms b gy na mx l my mz">inputs , labels = Variable(inputs.cuda()),Variable(labels.cuda())<br/>        x = model_vgg.features(inputs)<br/>        conv_features.extend(x.data.cpu().numpy())<br/>        labels_list.extend(labels.data.cpu().numpy())<br/>    conv_features = np.concatenate([[feat] for feat in conv_features])<br/>    return (conv_features,labels_list)</span></pre><p id="413c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我花了<strong class="jp ir"> 1分8秒</strong>来计算23000幅图像的训练数据集的特征。大小大约是600 mb。</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nb"><img src="../Images/741205d457fae511afa3cce7b717be39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VRpV55rqN8N_1m31uR3D1Q.png"/></div></div></figure><p id="6033" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">微调:</strong></p><p id="20b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以使用处理过的特征来训练完全连接的层。对于<strong class="jp ir"> 10次迭代</strong>，花费了<strong class="jp ir"> 25秒</strong>。使用VGG分类器块的代码段。</p><pre class="lz ma mb mc gt mr ms mt mu aw mv bi"><span id="ced8" class="la lb iq ms b gy mw mx l my mz">for param in model_vgg.classifier[6].parameters():<br/>    param.requires_grad = True<br/>train_model(model=model_vgg.classifier,size=dset_sizes['train'],conv_feat=conv_feat_train,labels=labels_train,epochs=10,optimizer=optimizer,train=True,shuffle=True)</span></pre><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nc"><img src="../Images/d71450e06a2d925a15f22ad2725335a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SevYK4P8FwPpBwHK1RuQjg.png"/></div></div></figure><h2 id="42b0" class="la lb iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">精确度:</h2><p id="f66e" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">在运行该模型大约30个时期之后，即在不到几分钟的时间内，验证准确度达到97%。通过增加批次归一化和降低压差值，可以进一步提高精度。在这个笔记本里，我已经包括了我尝试过的其他实验。</p><h2 id="133a" class="la lb iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">PyTorch VGG和Keras在Tensorflow VGG上的性能比较；</h2><p id="a501" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">我在Tensorflow上使用Keras已经有一段时间了。所以我很想看看他们在时间方面的表现。我使用PyTorch版本0.1.11和Tensorflow版本1.0.1进行实验。</p><p id="d49e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">进行的实验:在卷积层权重不变的情况下运行预训练的VGG模型。未计算任何卷积特征。运行了10个时期的23000幅图像。下面是我的结果。</p><p id="efe5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">PyTorch — 15分19秒</p><p id="62d8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Tensoflow上的keras—31分29秒</p><p id="daf9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">PyTorch有数据加载器，可以一次使用多个线程来加载数据。当使用6个线程时，VGG模型的性能提高到11分钟。</p><p id="ef71" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">更新:根据下面的推文，我已经尝试使用keras和6个工人进行预处理，每个时期的性能从3分21秒提高到1分40秒。PyTorch花了6个工人1分11秒。</strong></p><figure class="lz ma mb mc gt md"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="b68d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">结论:我在使用Keras和pytorch时所做的一些观察。Keras太抽象，好上手，快速建立标准模型。预计性能将优于PyTorch，但看起来并非如此，尽管TensorFlow有许多改进。另一方面，PyTorch提供了类似于Python NumPy的API以及在GPU上操作的能力。学习曲线比tensorflow小得多，比Keras灵活得多。因此，如果你对深度学习充满热情，那么你绝对应该看看PyTorch。</strong></p><p id="6329" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">除了框架，我们还讨论了如何使用预卷积特性更快地训练模型。事实上，杰瑞米·霍华德在他的第二部分课程中，即将推出的</strong> <a class="ae kl" href="http://course.fast.ai/" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir"> MOOC </strong> </a> <strong class="jp ir">讨论了脸书如何使用这些预先令人费解的特性的一种有趣的方法。该方法指出，“当不同的团队在同一数据集上工作时，计算这些卷积特征并使其对所有团队可用是很有意义的。”。这种方法将在建立模型时节省大量时间。事实上，脸书也在用类似的方式处理这个问题。</strong></p><p id="eaa3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可以在这里找到与实验<a class="ae kl" href="https://github.com/svishnu88/pytorch" rel="noopener ugc nofollow" target="_blank">相关的代码。</a></p><p id="a300" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可以在LinkedIn上找到我</p></div></div>    
</body>
</html>