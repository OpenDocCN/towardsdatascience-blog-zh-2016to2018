<html>
<head>
<title>Building a Real-Time Object Recognition App with Tensorflow and OpenCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Tensorflow 和 OpenCV 构建实时物体识别应用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-real-time-object-recognition-app-with-tensorflow-and-opencv-b7a2b4ebdc32?source=collection_archive---------0-----------------------#2017-06-22">https://towardsdatascience.com/building-a-real-time-object-recognition-app-with-tensorflow-and-opencv-b7a2b4ebdc32?source=collection_archive---------0-----------------------#2017-06-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="7f77" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我将介绍如何使用 Python 3(具体来说是 3.5)中的<a class="ae kl" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank">tensor flow(TF)新的对象检测 API </a>和<a class="ae kl" href="http://opencv.org/" rel="noopener ugc nofollow" target="_blank"> OpenCV </a>轻松构建自己的实时对象识别应用程序。重点将放在我创建它时所面临的挑战上。你可以在<a class="ae kl" href="https://github.com/datitran/Object-Detector-App" rel="noopener ugc nofollow" target="_blank">我的回购</a>上找到完整的代码。</p><p id="67b2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这也是正在运行的应用程序:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi km"><img src="../Images/c64e390791fa2ef256b7cf8c78c838e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*oa1lPNxTOF6Hyia8g9dOBg.gif"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk"><strong class="bd ky">Me trying to classify some random stuff on my desk:)</strong></figcaption></figure><h1 id="2dda" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated"><strong class="ak">动机</strong></h1><p id="606f" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated"><a class="ae kl" href="https://research.googleblog.com/2017/06/supercharge-your-computer-vision-models.html" rel="noopener ugc nofollow" target="_blank">谷歌刚刚发布了</a>他们新的 TensorFlow 物体检测 API。第一个版本包含:</p><ul class=""><li id="fa24" class="mc md iq jp b jq jr ju jv jy me kc mf kg mg kk mh mi mj mk bi translated">一些<a class="ae kl" href="https://github.com/tensorflow/models/blob/477ed41e7e4e8a8443bc633846eb01e2182dc68a/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank">预训练的模型</a>(特别关注轻量模型，以便它们可以在移动设备上运行)</li><li id="933f" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">一个<a class="ae kl" href="https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter 笔记本</a>示例，其中包含一款已发布的型号</li><li id="3285" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated"><a class="ae kl" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_locally.md" rel="noopener ugc nofollow" target="_blank">一些非常方便的脚本</a>可用于模型的重新训练，例如，在您自己的数据集上。</li></ul><p id="7e76" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我想把我的手放在这个新的很酷的东西上，并有一些时间来构建一个简单的实时对象识别演示。</p><h1 id="ce0e" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated"><strong class="ak">物体检测演示</strong></h1><p id="be1d" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">首先，我调出了<a class="ae kl" href="https://github.com/tensorflow/models" rel="noopener ugc nofollow" target="_blank"> TensorFlow models repo </a>，然后又看了一下他们发布的<a class="ae kl" href="https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>。它基本上走过了使用预训练模型的所有步骤。在他们的例子中，他们使用了<a class="ae kl" href="https://arxiv.org/abs/1512.02325" rel="noopener ugc nofollow" target="_blank">“带 Mobilenet 的 SSD”</a>模型，但你也可以在他们所谓的<a class="ae kl" href="https://github.com/tensorflow/models/blob/477ed41e7e4e8a8443bc633846eb01e2182dc68a/object_detection/g3doc/detection_model_zoo.md" rel="noopener ugc nofollow" target="_blank">“tensor flow 检测模型动物园”</a>上下载其他几个预先训练好的模型。顺便说一下，这些模型是在<a class="ae kl" href="http://mscoco.org/" rel="noopener ugc nofollow" target="_blank"> COCO </a>数据集上训练的，并根据模型速度(慢、中和快)和模型性能(mAP —平均精度)而变化。</p><p id="93b0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我接下来做的是运行这个例子。这个例子实际上是有据可查的。本质上，它是这样做的:</p><ol class=""><li id="12d2" class="mc md iq jp b jq jr ju jv jy me kc mf kg mg kk mq mi mj mk bi translated">导入所需的软件包，如 TensorFlow、PIL 等。</li><li id="0e07" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mq mi mj mk bi translated">定义一些变量，如班级人数、模型名称等。</li><li id="af45" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mq mi mj mk bi translated">下载冻结模型(。pb — <a class="ae kl" href="https://developers.google.com/protocol-buffers/" rel="noopener ugc nofollow" target="_blank"> protobuf </a>)并将其加载到内存中</li><li id="2372" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mq mi mj mk bi translated">加载一些辅助代码，例如标签转换器的索引</li><li id="386b" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mq mi mj mk bi translated">两幅测试图像上的检测代码本身</li></ol><p id="53e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">注意:</strong>在运行示例之前，请务必查看<a class="ae kl" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md" rel="noopener ugc nofollow" target="_blank">设置注意事项</a>。特别是，protobuf 编译部分非常重要:</p><pre class="kn ko kp kq gt mr ms mt mu aw mv bi"><span id="e3d3" class="mw la iq ms b gy mx my l mz na"># From tensorflow/models/research/<br/>protoc object_detection/protos/*.proto --python_out=.</span></pre><p id="a7c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果不运行这个命令，这个示例将无法运行。</p><p id="90ab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我采用他们的代码，并对其进行了相应的修改:</p><ul class=""><li id="3663" class="mc md iq jp b jq jr ju jv jy me kc mf kg mg kk mh mi mj mk bi translated">删除模型下载部分</li><li id="b8b6" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">PIL 是不需要的，因为 OpenCV 中的视频流已经在 numpy 数组中了(PIL 也是一个非常大的开销，特别是当使用它来读取图像或视频流时)</li><li id="544f" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">TensorFlow 会话没有“with”语句，因为这是一个巨大的开销，特别是当每次会话都需要在每个流之后启动时</li></ul><p id="acbb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我用 OpenCV 把它和我的网络摄像头连接起来。有很多例子向你解释如何去做，甚至是官方文档。所以，我就不深究了。更有趣的部分是我为提高应用程序的性能而做的优化。在我的例子中，我看到了良好的 fps——每秒帧数。</p><p id="4e80" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一般来说，许多 OpenCV 示例的普通/朴素实现并不是真正的最佳实现，例如 OpenCV 中的一些函数严重受限于 I/O。所以我不得不想出各种办法来解决这个问题:</p><ul class=""><li id="78ba" class="mc md iq jp b jq jr ju jv jy me kc mf kg mg kk mh mi mj mk bi translated">从网络摄像头读取帧会导致大量的 I/O。我的想法是用<a class="ae kl" href="https://docs.python.org/3.5/library/multiprocessing.html" rel="noopener ugc nofollow" target="_blank">多处理库</a>将这部分完全转移到不同的 Python 进程。这不知何故没有奏效。在 Stackoverflow 上有一些解释为什么它不工作，但我没有深入探讨这个问题。幸运的是，我从<a class="ae kl" href="http://www.pyimagesearch.com/2015/12/21/increasing-webcam-fps-with-python-and-opencv/" rel="noopener ugc nofollow" target="_blank">的 Adrian Rosebrock 的网站“pyimagesearch”</a>上找到了一个非常好的例子，使用<a class="ae kl" href="https://docs.python.org/3.5/library/threading.html" rel="noopener ugc nofollow" target="_blank">线程</a>代替它大大提高了我的 fps。顺便说一下，如果你想知道多处理和线程之间的区别，在 Stackoverflow 上有一个很好的解释。</li><li id="c294" class="mc md iq jp b jq ml ju mm jy mn kc mo kg mp kk mh mi mj mk bi translated">每次应用程序启动时，将冻结的模型加载到内存中是一项很大的开销。我已经为每次运行使用了一个 TF 会话，但这仍然非常慢。那么我是怎么解决这个问题的呢？解决办法很简单。在这种情况下，我使用多处理库将对象检测部分的繁重工作转移到多个进程中。应用程序的初始启动会很慢，因为每个进程都需要将模型加载到内存中并启动 TF 会话，但在此之后，我们将受益于并行性😁</li></ul><div class="nb nc gp gr nd ne"><a href="https://asciinema.org/a/125852" rel="noopener  ugc nofollow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd ir gy z fp nj fr fs nk fu fw ip bi translated">与多个工作人员一起运行对象检测演示。</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">由 datitran 录制</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">asciinema.org</p></div></div><div class="nn l"><div class="no l np nq nr nn ns ks ne"/></div></div></a></div><ul class=""><li id="d100" class="mc md iq jp b jq jr ju jv jy me kc mf kg mg kk mh mi mj mk bi translated">减少视频流中帧的宽度和高度也大大提高了 fps。</li></ul><p id="fdc4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">注意:</strong>如果你像我一样使用 Mac OSX，并且使用 OpenCV 3.1，OpenCV 的 VideoCapture 可能会在一段时间后崩溃。已经有<a class="ae kl" href="https://github.com/opencv/opencv/issues/5874" rel="noopener ugc nofollow" target="_blank">个问题提交</a>。切换回 OpenCV 3.0 解决了这个问题。</p><h1 id="cedf" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">结论与展望</h1><p id="6980" class="pw-post-body-paragraph jn jo iq jp b jq lx js jt ju ly jw jx jy lz ka kb kc ma ke kf kg mb ki kj kk ij bi translated">给我一个❤️，如果你喜欢这个职位:)拉代码，并尝试自己。一定要看看 Tensorflow 对象检测 API。到目前为止，从第一眼看上去，它非常简洁明了。我想尝试的下一件事是用 API 训练我自己的数据集，并为我想到的其他应用程序使用预训练的模型。我对应用程序的性能也不完全满意。fps 速率仍然不是最佳的。OpenCV 中仍然有许多我无法影响的瓶颈，但是我可以尝试一些替代方法，比如使用<a class="ae kl" href="https://webrtc.org/" rel="noopener ugc nofollow" target="_blank"> WebRTC </a>。然而，这是基于网络的。此外，我正在考虑使用异步方法调用(async)来提高我的 fps 率。敬请期待！</p><p id="042d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在推特上关注我:<a class="ae kl" href="https://twitter.com/datitran" rel="noopener ugc nofollow" target="_blank"> @datitran </a></p></div></div>    
</body>
</html>