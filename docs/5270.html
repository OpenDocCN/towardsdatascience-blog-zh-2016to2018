<html>
<head>
<title>Understanding and visualizing ResNets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解和可视化资源</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-and-visualizing-resnets-442284831be8?source=collection_archive---------1-----------------------#2018-10-08">https://towardsdatascience.com/understanding-and-visualizing-resnets-442284831be8?source=collection_archive---------1-----------------------#2018-10-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="47bd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇文章可以在 PDF <a class="ae kl" href="http://pabloruizruiz10.com/resources/CNNs/ResNets.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><p id="e6a7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是关于 CNN 架构的<a class="ae kl" href="https://medium.com/@pabloruizruiz/deep-convolutional-neural-networks-ccf96f830178" rel="noopener">系列教程的一部分</a>。</p><p id="8b77" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">主要目的是深入了解 ResNet，并深入研究 ResNet34 for ImageNet 数据集。</p><ul class=""><li id="2cdb" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">对于应用于 CIFAR10 的 ResNets，这里还有另外一个教程<a class="ae kl" href="https://medium.com/@pabloruizruiz/resnets-for-cifar-10-e63e900524e0" rel="noopener"/>。</li><li id="907c" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">还有 PyTorch 实现详细教程<a class="ae kl" href="http://www.pabloruizruiz10.com/resources/CNNs/ResNet-PyTorch.html" rel="noopener ugc nofollow" target="_blank">这里</a>。</li></ul><p id="84c5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">索引</strong></p><ul class=""><li id="e1bb" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">背景</li><li id="e9a0" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">动机</li><li id="613a" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">ResNets 解决什么问题？</li><li id="0ffc" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">体系结构</li><li id="ad94" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">摘要</li></ul></div><div class="ab cl la lb hu lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="ij ik il im in"><h1 id="0fc4" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">背景</h1><p id="c621" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">研究人员观察到，当涉及到卷积神经网络时，肯定“<em class="mk">越深越好”</em>是有意义的。这是有意义的，因为模型应该更有能力(它们适应任何空间增加的灵活性，因为它们有更大的参数空间来探索)。然而，已经注意到，在一定深度之后，性能会下降。</p><p id="c4b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是 VGG 的瓶颈之一。他们不能达到预期的深度，因为他们开始失去归纳能力。</p><h1 id="32aa" class="lh li iq bd lj lk ml lm ln lo mm lq lr ls mn lu lv lw mo ly lz ma mp mc md me bi translated">动机</h1><p id="aedd" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">由于神经网络是良好的函数逼近器，它们应该能够容易地求解识别函数，其中函数的输出成为输入本身。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/5c68b44191951ce2b6856b58ae67aa98.png" data-original-src="https://miro.medium.com/v2/resize:fit:226/format:webp/1*c2Pdaa_8i-akMdb4sz00qw.png"/></div></figure><p id="fd1f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">按照同样的逻辑，如果我们绕过模型第一层的输入，作为模型最后一层的输出，网络应该能够预测它之前学习的函数和添加的输入。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi my"><img src="../Images/41afac34b3d1e51db6d29a9d55579a6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:354/format:webp/1*Pj5r0fEcNkodaSoa7ESjgw.png"/></div></figure><p id="a86f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">直觉告诉我们，学习 f(x) = 0 对网络来说一定很容易。</p><h1 id="052f" class="lh li iq bd lj lk ml lm ln lo mm lq lr ls mn lu lv lw mo ly lz ma mp mc md me bi translated">ResNets 解决什么问题？</h1><p id="713a" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">ResNets 解决的问题之一就是著名的已知<a class="ae kl" href="https://medium.com/@anishsingh20/the-vanishing-gradient-problem-48ae7f501257" rel="noopener"> <strong class="jp ir">消失渐变</strong> </a>。这是因为当网络太深时，在链规则的几次应用之后，计算损失函数的梯度容易收缩到零。这导致权重永远不会更新其值，因此没有学习被执行。</p><p id="7a30" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有了 ResNets，<strong class="jp ir">渐变可以直接通过跳过连接从后面的层向后流到初始过滤器</strong>。</p><h1 id="b52d" class="lh li iq bd lj lk ml lm ln lo mm lq lr ls mn lu lv lw mo ly lz ma mp mc md me bi translated">体系结构</h1><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/b57eee616f2f5731898ef80deaba7fe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*kBlZtheCjJiA3F1e0IurCw.png"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Figure 1. ResNet 34 from original paper [1]</figcaption></figure><p id="aae9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于 ResNet 可以具有可变的大小，这取决于模型的每一层有多大，以及它有多少层，我们将遵循作者在论文[1] — ResNet 34 中描述的，以便解释这些网络之后的结构。</p><p id="b734" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你看了一下这篇论文，你可能会看到一些如下的图表，你很难理解。让我们通过研究每一步的细节来描绘这些数字。</p><p id="6f60" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这里，我们可以看到 ResNet(右边的那个)由一个卷积和合并步骤(在 orange 上)组成，后面是 4 层类似的行为。</p><p id="bbb2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">每一层都遵循相同的模式。它们分别与固定的特征映射维度(F) [64，128，256，512]执行 3×3 卷积，每两次卷积绕过输入。此外，宽度(W)和高度(H)尺寸在整个层中保持不变。</p><p id="69bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">虚线在那里，正是因为输入体积的维度发生了变化(当然是因为卷积而减少)。注意，层与层之间的这种减少是通过在每层的第一个回旋处将步幅从 1 增加到 2 来实现的；而不是像我们习惯看到的下采样器那样通过汇集操作。</p><p id="7de7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在该表中，总结了每一层的输出大小以及该结构中每一点的卷积核的维数。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ne"><img src="../Images/99173e54b46f049e306c141f4883c10e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I2557MCaFdNUm4q9TfvOpw.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Figure 2. Sizes of outputs and convolutional kernels for ResNet 34</figcaption></figure><p id="9160" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但这是不可见的。我们想要图像！一张图片胜过千言万语！</p><p id="1842" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">图 3 是我更喜欢看到卷积模型的方式，从这里我将解释每一层。</p><p id="ddc1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我更喜欢观察通过模型的体积是如何改变它们的大小的。这种方式更容易理解特定模型的机制，能够根据我们的特定需求进行调整——我们将看到仅仅改变数据集如何迫使改变整个模型的架构。此外，我将尝试遵循接近于<a class="ae kl" href="https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py" rel="noopener ugc nofollow" target="_blank"> PyTorch 官方实现</a>的符号，以便稍后在 PyTorch 上实现它时更容易。</p><p id="3234" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，论文中的 ResNet 主要针对 ImageNet 数据集进行解释。但是我第一次想用 ResNets 的集合做实验时，我不得不在 CIFAR10 上做。显然，由于 CIFAR10 输入图像是(32x32)而不是(224x224)，因此需要修改 ResNets 的结构。如果您想控制应用到您的 ResNet 的修改，您需要了解细节。<a class="ae kl" href="https://medium.com/@pabloruizruiz/resnets-for-cifar-10-e63e900524e0" rel="noopener">这另一个</a>教程是当前应用于 CIFAR10 的一个简化版。</p><p id="4afb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以，我们一层一层来！</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ne"><img src="../Images/637add46cbd10f31b2b80df7d89be92d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y-u7dH4WC-dXyn9jOG4w0w.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Figure 3. Another look at ResNet 34</figcaption></figure><h1 id="b78f" class="lh li iq bd lj lk ml lm ln lo mm lq lr ls mn lu lv lw mo ly lz ma mp mc md me bi translated">卷积 1</h1><p id="7f6e" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">在进入公共层行为之前，ResNet 上的第一步是一个块(此处称为 Conv1 ),由卷积+批处理规范化+最大池操作组成。</p><p id="9008" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你不记得卷积和池操作是如何执行的，快速看一下我画的这个图来解释它们，因为我在这里重用了它们的一部分<a class="ae kl" href="http://pabloruizruiz10.com/resources/CNNs/Convolution_Pooling.pdf" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="969b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先有一个卷积运算。在图 1 中，我们可以看到他们使用的内核大小为 7，特征映射大小为 64。您需要推断它们在每个维度上用零填充了 3 次——并在 PyTorch 文档中进行检查。考虑到这一点，从图 4 中可以看出，该操作的输出大小将是一个(112x122)卷。由于(64 个中的)每个卷积滤波器在输出音量中提供一个通道，因此我们最终得到(112x112x64)的输出音量——注意，为了简化说明，这不包括批次维度。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/d4280a242b926d90a231a7b54ba97f41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*CJn_fMeW4m2OSt71jzO4WA.png"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Figure 4. Conv1 — Convolution</figcaption></figure><p id="098b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下一步是批处理规范化，这是一个基于元素的操作，因此不会改变卷的大小。最后，我们有一个跨度为 2 的(3x3)最大池操作。我们还可以推断，他们首先填充输入体积，因此最终体积具有所需的尺寸。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi nk"><img src="../Images/900070f291dff066ca7773b98d43c299.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_kbJ_fvRhVPQ1fRRssEwhA.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Figure 5. Conv1 — Max Pooling</figcaption></figure><h1 id="8386" class="lh li iq bd lj lk ml lm ln lo mm lq lr ls mn lu lv lw mo ly lz ma mp mc md me bi translated">ResNet 层</h1><p id="bdcf" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">所以，我们来解释一下这个重复的名字，block。一个 ResNet 的每一层都由几个块组成。这是因为当 ResNets 更深入时，它们通常通过增加块内的操作数量来实现，但总层数保持不变，即 4 层。<strong class="jp ir"> <em class="mk">这里的运算是指对一个输入进行卷积、批量归一化和 ReLU 激活，除了最后一个没有 ReLU 的块的运算。</em> </strong></p><p id="3150" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，在 PyTorch 实现中，他们区分包含 2 个操作的块<strong class="jp ir">基本块</strong>和包含 3 个操作的块<strong class="jp ir">瓶颈块</strong>。注意，通常这些操作中的每一个都被称为层，但是我们已经为一组块使用了层。</p><p id="4095" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们现在面临一个基本问题。输入音量是 Conv1 的最后一个输出音量。让我们看看图 6，看看这个模块内部发生了什么。</p><h1 id="82a6" class="lh li iq bd lj lk ml lm ln lo mm lq lr ls mn lu lv lw mo ly lz ma mp mc md me bi translated">第一区</h1><h2 id="117d" class="nl li iq bd lj nm nn dn ln no np dp lr jy nq nr lv kc ns nt lz kg nu nv md nw bi translated">1 卷积</h2><p id="7de1" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">我们正在复制纸上每一层的简化操作。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi nx"><img src="../Images/d41dbb281b22b428a4c349689d22be37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fW8FORQBlikQTOAUVBqMGA.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Figure 6. Layer 1, block 1, operation 1</figcaption></figure><p id="50cb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们现在可以仔细检查我们使用的[3x3，64]内核和输出大小为[56x56]的论文中的表格。我们可以看到，正如我们前面提到的，在一个数据块中，卷的大小是如何保持不变的。这是因为使用了填充= 1，并且跨距也是 1。让我们看看这如何扩展到整个块，以覆盖表中出现的 2 [3x3，64]。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ne"><img src="../Images/949007e8580e0394e014663727f78a79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Cdsm7k2gf9QUEwAlsbT8A.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Figure 7. Layer 1, block 1</figcaption></figure><p id="e8e1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">相同的过程可以扩展到整个层，如图 8 所示。现在，<strong class="jp ir"> <em class="mk">我们可以完整的读取</em> </strong>表格的整个单元格了(只是重述一下我们在 Conv2_x 层的 34 层 ResNet 中。</p><p id="7c46" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以看到如何在层 中使用<strong class="jp ir"><em class="mk">【3x 3，64】x 3 次。</em></strong></p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ne"><img src="../Images/8fa51c06de4a75f4eadee160f709adf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CgSI0jjpzQGPVS4hB1EHng.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Figure 8. Layer 1</figcaption></figure><h1 id="2adc" class="lh li iq bd lj lk ml lm ln lo mm lq lr ls mn lu lv lw mo ly lz ma mp mc md me bi translated">模式</h1><p id="dfcb" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">下一步是从整个块升级到整个层。在图 1 中，我们可以看到这些层是如何通过颜色区分的。但是，如果我们观察每一层的第一个操作，我们会发现第一层使用的步幅是 2，而不是其他层使用的 1。</p><p id="d756" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这意味着通过网络的音量的<strong class="jp ir"> <em class="mk">下采样是通过增加步幅来实现的，而不是像通常的 CNN 那样的汇集操作</em> </strong>。事实上，在我们的 Conv1 层中只执行了一次最大池化操作，在 ResNet 的末尾，就在图 1 中完全连接的密集层之前，执行了一次平均池化操作。</p><p id="2a53" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还可以看到 ResNet 层上的另一个重复图案，点层代表维度的变化。这和我们刚才说的一致。每一层的第一个操作是减少维度，因此我们还需要调整通过跳过连接的卷的大小，这样我们就可以像图 7 中那样添加它们。</p><p id="bf6e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种跳过连接上的差异在文中被称为<strong class="jp ir"> <em class="mk">恒等式快捷方式</em> </strong>和<strong class="jp ir"> <em class="mk">投影快捷方式</em> </strong>。恒等快捷方式是我们已经讨论过的，简单地绕过加法运算符的输入量。投影快捷方式执行卷积运算，以确保此加法运算中的体积大小相同。从纸上我们可以看到<strong class="jp ir"> <em class="mk">匹配</em> </strong>输出尺寸有两种选择。或者<strong class="jp ir"> <em class="mk">填充输入音量</em> </strong>或者执行<strong class="jp ir"> <em class="mk"> 1x1 卷积</em> </strong>。这里显示了第二个选项。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ne"><img src="../Images/33cbbe007f43123beb9f45303380bb12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ymjFDIMD6DDiTEwkTYT4Ng.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Figure 9. Layer2, Block 1, operation 1</figcaption></figure><p id="c52c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">图 9 显示了通过将跨距增加到 2 来执行的下采样。滤波器的数量被加倍，以试图保持每个操作的时间复杂度(<em class="mk"> 56*64 = 28*128 </em>)。另外，请注意，由于卷被修改，现在无法执行添加操作。在捷径中，我们需要应用一种下采样策略。1x1 卷积方法如图 10 所示。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ne"><img src="../Images/7e30581d87ac8390c37489422342c1e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2B8EPyRlepndtWDDc9KUFQ.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Figure 10. Projection Shortcut</figcaption></figure><p id="33fd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最终的图片如图 11 所示，其中每个线程的 2 个输出卷大小相同，可以相加。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ne"><img src="../Images/61c9e5525b2018a06653deb07b9a8c6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xd-OIT9GRwLaM3F5jdbfzQ.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Figure 11. Layer 2, Block 1</figcaption></figure><p id="e920" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在图 12 中，我们可以看到整个第二层的全局情况。下面的第 3 层和第 4 层的行为完全相同，只是改变了引入体积的尺寸。</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ne"><img src="../Images/00cd063022618964ea211fa02844cfd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*17tD3GCz2zJq8ifoWCS9dA.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Figure 12.Layer 2</figcaption></figure><h1 id="e4fa" class="lh li iq bd lj lk ml lm ln lo mm lq lr ls mn lu lv lw mo ly lz ma mp mc md me bi translated">摘要</h1><p id="cb31" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">遵循作者建立的解释规则的结果产生了如图 2 所示的以下结构:</p><figure class="mr ms mt mu gt mv gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/f0c32f2a4a3bb4ef6cd5e62579a8f7ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*r1c1C2RY8tkR_SvdV6aHsw.png"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Table 1. ResNets architectures for ImageNet</figcaption></figure><h1 id="1d2d" class="lh li iq bd lj lk ml lm ln lo mm lq lr ls mn lu lv lw mo ly lz ma mp mc md me bi translated">文献学</h1><p id="f2ab" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">[1]何国光，张，任，孙，“深度残差学习在图像识别中的应用”，<em class="mk">，</em>，2016。</p></div></div>    
</body>
</html>