<html>
<head>
<title>Over-fitting and Regularization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">过度拟合和正则化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/over-fitting-and-regularization-64d16100f45c?source=collection_archive---------1-----------------------#2017-10-11">https://towardsdatascience.com/over-fitting-and-regularization-64d16100f45c?source=collection_archive---------1-----------------------#2017-10-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="d0f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">机器学习</p><p id="0b29" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在有监督的机器学习中，模型是在数据的子集上训练的，也就是训练数据。目标是根据训练数据计算每个训练示例的目标。</p><p id="6bee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，当模型在训练数据中学习信号和噪声时，就会发生过度拟合，并且在模型没有训练的新数据上表现不佳。在下面的例子中，你可以看到前几步的欠拟合和后几步的过拟合。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/7e12b3f090cd74104cee06d68f1d231e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*u2MTHaUPMJ8rkTYjm2nHww.gif"/></div></div></figure><p id="48ae" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，有几种方法可以避免在训练数据上过度拟合模型，如交叉验证采样、减少特征数量、修剪、正则化等。</p><p id="654d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">随着模型复杂性的增加，正则化基本上增加了惩罚。正则化参数(lambda)惩罚除截距之外的所有参数，以便模型概括数据，不会过度拟合。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kx"><img src="../Images/25d9df7bae34c2dfd75ef3bbe23e4fa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*-kA1uR2nBKf_1rsrKLFfkQ.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Regularization in cost function</figcaption></figure><p id="a5c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在上面的gif中，随着复杂度的增加，正则化将增加对更高术语的惩罚。这将降低高次项的重要性，并使模型变得不那么复杂。</p><p id="ab27" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">敬请关注下一篇文章，它将涵盖不同类型的正规化技术。</p></div></div>    
</body>
</html>