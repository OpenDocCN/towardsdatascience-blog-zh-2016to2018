<html>
<head>
<title>Metrics &amp; Random Processes in Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分类中的度量和随机过程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/metrics-random-processes-in-classification-fd5bafa79505?source=collection_archive---------2-----------------------#2017-07-25">https://towardsdatascience.com/metrics-random-processes-in-classification-fd5bafa79505?source=collection_archive---------2-----------------------#2017-07-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="4528" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在他的书《机器学习》的介绍中，<a class="ae kl" href="http://www.cs.cmu.edu/afs/cs.cmu.edu/user/mitchell/ftp/mlbook.html" rel="noopener ugc nofollow" target="_blank">Tom Mitchell教授</a>将<strong class="jp ir">学习</strong>定义如下:</p><blockquote class="km kn ko"><p id="ff37" class="jn jo kp jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">对于某类任务<em class="iq"> T </em>和<strong class="jp ir">性能测量</strong> <em class="iq"> P </em>，如果由<em class="iq"> P </em>测量的计算机程序在<em class="iq"> T </em>任务中的性能随着经验<em class="iq"> E </em>而提高，则称该计算机程序<strong class="jp ir">从经验<em class="iq"> E </em>中学习</strong>。</p></blockquote><p id="af97" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">事实上，只有通过预定义的性能指标或<strong class="jp ir">指标</strong>进行评估时，我们才能谈论算法学习。当执行分类任务时，选择正确的指标可能比调整模型参数更重要。为了说明这一点，我们将回顾现有的<strong class="jp ir">最常见的指标</strong>，并展示它们的优缺点，然后集中讨论具有潜在<strong class="jp ir">随机过程</strong>的分类任务的特殊情况，在这种情况下，通常的分类指标都不起作用，并提出一种替代方案。</p></div><div class="ab cl kt ku hu kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ij ik il im in"><h2 id="ec7e" class="la lb iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">准确(性)</h2><p id="b298" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated"><strong class="jp ir">准确度分数</strong>(通常写成<strong class="jp ir"> ACC </strong>)是人们能想到的最直接的度量标准。它只是简单地计算我们在预测总数中预测正确类别的次数。更正式的说法是:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ly"><img src="../Images/335a774b752457f87a52a9e6cc7613c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CSNTS5PT25-F9q_cbEa3Gw.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">Notations : p_i is the i-th prediction, y_i the i-th target and N the sample size.</figcaption></figure><p id="5a3b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">就像任何指标一样，这一指标也有其利弊。从好的方面来说，这很容易理解和解释，因为具有80%的准确性简单地表明有80%的机会在看不见的数据上预测正确的类别——当然，前提是我们的模型不会过度拟合和概括得很好。然而，当数据集中的类分布是<strong class="jp ir">不平衡的</strong>，例如<strong class="jp ir"> </strong>当负目标(0)比正目标(1)多得多时，该度量变得无用。事实上，如果95%的目标是否定的，那么一个总是预测(0)的非常简单(和糟糕)的模型将实现95%的准确度分数，尽管完全没有用。在这些情况下——这是相当常见的——其他指标如<strong class="jp ir">混淆矩阵</strong>就派上用场了。</p><h2 id="5bec" class="la lb iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">混淆矩阵</h2><p id="3724" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">混淆矩阵试图比简单的准确度分数更详细地描述分类器的性能。它可以表示为一个<strong class="jp ir">计数表</strong>，在给定真实值为正或为负的情况下，计数正预测值和负预测值的数量。例如，如果我们要为之前的坏分类器计算一个混淆矩阵，它看起来像这样:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/b1b687d41557d531d4343292b4bc9ae5.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*CaxyEhO1Cl0BtVn1oUwZcQ.png"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">Notations : T/F for True/False, P/N for Positive/Negative</figcaption></figure><p id="9337" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里我们选择了2000的假设样本量。我们可以看到，数据是高度不平衡的，只有5%的阳性，95%的阴性(0+1900)/2000)，并且分类器总是预测一个负值(“预测值”的“阳性”行为空)。但是，尽管允许我们快速浏览预测的分布，在这种状态下，混淆矩阵并没有真正给我们更多的洞察力。另一种方法是用每一列的总和除以每一列的总和，得到所谓的T2归一化混淆矩阵:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/415f1ce6fbafd4423b1893f0f9d02103.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*n_kxxJptLBsemQSNL8dERQ.png"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">Normalized confusion matrix. Notation : R for rate.</figcaption></figure><p id="d6ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于这种标准化，对角线上的每个<strong class="jp ir">值</strong>成为预测正确类别的<strong class="jp ir">经验条件概率</strong>。当以真类为正的条件时，这种概率称为真正率或<strong class="jp ir">灵敏度，否则称为真负率或<strong class="jp ir">特异性</strong>。因为这些比率不依赖于类别分布，所以使用混淆矩阵通常比依赖准确度得分更可取。在训练过程中，可以将灵敏度和特异性最大化，以收敛到<em class="kp">完美分类器</em>——其混淆矩阵等于同一性，因为它只预测实际上是正确类别的类别。在我们的例子中，我们立即看到了一些错误，因为敏感度为零，因此我们可以得出结论，我们注定是坏的分类器确实是坏的(哈利路亚！).</strong></p><h2 id="02d5" class="la lb iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">ROC / AUC</h2><p id="496c" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">一般来说，为了对样本进行分类，分类器会计算一个介于零和一之间的<strong class="jp ir">真实值</strong>——或者任何其他可以映射到[0，1]的区间——然后通过使用内部<strong class="jp ir">判别</strong> <strong class="jp ir">阈值</strong>(通常默认设置为50%)来映射该值，高于该阈值时，它会预测正的和反的。这样一个阈值的选择会极大地影响前面指标显示的结果。事实上，如果我们的模型高度偏向负值，即如果它预测的值分布非常接近零，使用50%或更高的阈值可能会导致它总是预测负值，而选择更低的阈值可能会导致更多的正值，因此可能会更好地反映分类器的性能。</p><p id="df0a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">考虑所有可能阈值的一种方法是依靠<strong class="jp ir"> ROC曲线</strong>和<strong class="jp ir"> AUC分数</strong>。ROC曲线是坐标为<strong class="jp ir">(灵敏度，1-特异性)</strong>或(TPR，FPR)的点的集合，其中每个点对应于相同分类器的性能，但具有不同的阈值。可以看出，对于足够大的数据集，尽管有鉴别阈值，但完全随机的分类器总是将其坐标放在对角线[(0，0)，(1，1)]上，也称为无鉴别线。此外，如果一个点在这条线以上的半平面中，那么下面的不等式成立:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ly"><img src="../Images/aa7f7e39467628149ff31c0fdfedc6d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5fTaR2NCuafdWGESP48cHQ.png"/></div></div></figure><p id="bda5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">换句话说，混淆矩阵对角线上的每个概率都大于50%，这意味着我们有超过50%的机会正确预测每个类别，在这种情况下，我们说我们的分类器表现<strong class="jp ir">比随机猜测</strong>更好。同样的推理也适用于比随机猜测更差的线下点。然而，如果一个分类器总是在所有阈值的非歧视线以下，简单地翻转它的预测就可以使它在线以上，因此是一个可接受的模型。</p><p id="82a6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当阈值为T=0时，所有分类器系统地预测阳性，因此它们都位于ROC空间中的(1，1)处。相反，当T = 1时，发生相反的事情，并且所有分类器都在(0，0)处。为了说明这一点，这里有两个很好的ROC曲线的例子:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/6f098dbeae40c4c659f5bffadfb1b497.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*5cuH-ntKOoujERpa68mSaw.png"/></div></figure><p id="afc8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是我们如何使用这个度量来比较模型呢？当给定一组分类器时，在每个给定的特异性值，最好的分类器必须具有最好的灵敏度。因此，选择最佳模型的近似方法是保留ROC曲线严格高于所有其他模型的模型。不幸的是，这只有在几条曲线之间有明确的顺序时才能实现。为了解决这个问题，我们可以求助于一个更具聚合性的指标，即<strong class="jp ir"> AUC得分</strong>。</p><p id="4bf5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于每条ROC曲线，曲线下有一个相关的面积或<strong class="jp ir"> AUC得分</strong>。该AUC直接依赖于ROC曲线，但具有一些额外的优点，第一个优点是它允许我们使用真实值客观地比较分类器，而不是依赖于图形的视觉解释。此外，可以表明AUC等于分类器对随机选择的正实例的排序高于随机选择的负实例的概率。考虑到这一点，我们看到AUC是用于二元分类任务的比任何以前的度量更强大的工具，因为它对不平衡数据集是稳定的，易于解释并且客观地对分类器的性能进行排序。</p></div><div class="ab cl kt ku hu kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ij ik il im in"><p id="9f9a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些指标中的任何一个(尤其是AUC)在任何确定性场景中都会发挥很好的作用，比如找出<a class="ae kl" href="https://hackernoon.com/how-hbos-silicon-valley-built-not-hotdog-with-mobile-tensorflow-keras-react-native-ef03260747f3" rel="noopener ugc nofollow" target="_blank">某物是否是热狗</a>。在这些情况下，目标值是一组预测值的<strong class="jp ir">确定性函数</strong>，并且可以尝试按照通常的例程直接处理分类任务来估计该函数。但是在<strong class="jp ir">随机场景</strong>中，目标除了确定性函数之外还具有<strong class="jp ir">随机不可预测成分，预测类别只是估计概率</strong>的一个代理，也是<strong class="jp ir">估计概率</strong>的结果。例如，如果我们试图预测一次公平的掷硬币的结果，对于一个足够大的数据集，没有一个模型可以达到超过50%的准确率，无论它有多精确。在这种情况下，潜在的目标和我们唯一希望做的事情是评估过程的概率，并找到最佳模型，即预测总是50%。</p><blockquote class="mq"><p id="b336" class="mr ms iq bd mt mu mv mw mx my mz kk dk translated"><em class="na">不幸的是</em>，<em class="na">到目前为止，我们所看到的指标并没有表达出我们在寻找这些概率方面有多好</em>。</p></blockquote><p id="f42b" class="pw-post-body-paragraph jn jo iq jp b jq nb js jt ju nc jw jx jy nd ka kb kc ne ke kf kg nf ki kj kk ij bi translated">事实上，对于公平的掷硬币和足够大的数据集，除了不能实现大于50%的准确度之外，所有的ROC曲线都将在非歧视线上，并且AUC分数将总是50%。这并没有给我们更多关于分类器发生了什么的信息，因此需要一个新的度量标准。在许多情况下，基础过程是随机的，例如:</p><ul class=""><li id="f482" class="ng nh iq jp b jq jr ju jv jy ni kc nj kg nk kk nl nm nn no bi translated">预测量子力学实验的结果，例如，电子的自旋是向上还是向下。</li><li id="b64b" class="ng nh iq jp b jq np ju nq jy nr kc ns kg nt kk nl nm nn no bi translated">预测扑克游戏中看不见的牌。</li><li id="efa9" class="ng nh iq jp b jq np ju nq jy nr kc ns kg nt kk nl nm nn no bi translated">预测一个学生是否会在一项特定的任务中取得成功(我们在Kwyk 做的事情)</li></ul><p id="8a52" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在所有这些情况下，使用简单的分类标准会阻止我们在建模方面前进。那么我们应该使用什么度量标准呢？因为我们想要一个度量来告诉我们在预测每个类的<strong class="jp ir">连续</strong>概率<strong class="jp ir"> <em class="kp"> </em> </strong>方面有多好，所以我们将关注一个<strong class="jp ir">回归度量</strong><strong class="jp ir">MSE</strong>。</p><h2 id="e0a2" class="la lb iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">均方误差</h2><p id="1aa4" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">均方差或<strong class="jp ir"> MSE </strong>是预测值和实际值之间的平方差的平均值。它可以正式写成:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ly"><img src="../Images/f0d8cdb8f10312bc4cd7d466ab9d33cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2tmszYuCrZ4M6e4LYu4pSw.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">Notations : p_i is the i-th prediction, y_i the i-th target and N the sample size.</figcaption></figure><p id="8460" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在二元分类的情况下，其中<strong class="jp ir"> <em class="kp"> y </em> </strong>是离散变量(0或1)<strong class="jp ir"><em class="kp">p</em></strong>是成功的预测概率，它也被称为<strong class="jp ir"> Brier score </strong>。</p><p id="2c93" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了公平起见，如果我们选择使用的模型总是对所有样本预测相同的概率，快速查看MSE配置文件可以让我们找到最佳模型:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/ed8096702e683d401c11157e52b94ea6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*VKtnLnRYE5iEsVN8sqM59Q.png"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">MSE values for a fair coin toss when the predicted probability varies from 0 to 1.</figcaption></figure><p id="a100" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一个开始，但是我们看到当模型是最优时，MSE不为零。事实上，总是预测50%是我们可以选择的模拟公平抛硬币的最佳模型，因为潜在的过程是a <a class="ae kl" href="https://en.wikipedia.org/wiki/Bernoulli_distribution" rel="noopener ugc nofollow" target="_blank">伯努利</a> B(0.5)。但是因为最小均方差是0.25，我们可以认为还有一个更好的模型，均方差是0.25。这里，p=0.5时剩余的MSE对应于任务中的<strong class="jp ir">固有随机性</strong>。事实上，当一个过程具有不确定性时，由于我们试图预测的数据中的不确定性，MSE中总是存在不可避免的误差。现在让我们注意0.25正好是a B(0.5)的方差，它是我们过程的分布。</p><p id="d152" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用MSE实际上允许我们在一组分类器之间进行区分，并确定最佳选项，但是我们仍然没有一个度量标准来告诉我们离完美模型还有多远。这是使用任何先前度量的确定性任务的情况:对于<em class="kp">完美模型</em>来说，准确度分数是100%，混淆矩阵等于同一性，并且ROC曲线是AUC = 1的平方。在任何情况下，我们都看到，由于我们感兴趣的随机过程的本质，MSE不可能为零，但我们也知道一种将随机观察结果与其潜在概率联系起来的方法，这就是<strong class="jp ir">大数定律(LLN) </strong>。</p><p id="d912" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">事实上，如果预测的概率有任何意义，并且如果我们为每个预测的概率建立一个组，其中我们收集所有相应的目标，对于一个足够大的组，目标的平均值应该收敛到预测的概率。这是朝着期望的度量迈出的又一步，因为我们可以查看每组中平均目标和预测概率之间的差异，我们的分类器越好，这些差异就应该收敛到零。但是当该过程具有连续分布时，这些组的大小将几乎不会增长，并且LLN将无法生效。这个问题的一个解决方案是将不同的预测概率一起分组到<strong class="jp ir"> K个组</strong>的每一个<strong class="jp ir"> n_k </strong>元素中，并将组内平均成功率(目标的平均值)与组的平均概率进行比较。</p><p id="53cc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们看看当我们进行这样的分组时MSE会发生什么，这里BS代表<strong class="jp ir"> Brier Score </strong>:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ly"><img src="../Images/27b0e1aa3b7f65d056b8e473e844168c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rn-m0GBumWJ42RDpDUqUBg.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">Source : <a class="ae kl" href="http://journals.ametsoc.org/doi/pdf/10.1175/2007WAF2006116.1" rel="noopener ugc nofollow" target="_blank">“Two Extra Components in the Brier Score Decomposition”</a></figcaption></figure><p id="af96" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上述计算表明Brier分数/MSE是5项相互作用的结果:</p><ul class=""><li id="ce2d" class="ng nh iq jp b jq jr ju jv jy ni kc nj kg nk kk nl nm nn no bi translated"><strong class="jp ir">不确定性</strong> (UNC):不确定性显示了<strong class="jp ir">在我们的任务中固有的随机性</strong>。例如，如果我们预测的目标总是0或1，UNC就是0，因为在要预测的数据中没有任何不确定性。相反，对于一个完全随机的实验，比如之前的公平抛硬币，不确定性是最大的，等于0.25。</li><li id="e13a" class="ng nh iq jp b jq np ju nq jy nr kc ns kg nt kk nl nm nn no bi translated"><strong class="jp ir">可靠性</strong> (REL):可靠性项衡量每组中的平均预测与组中的平均成功率之间的<strong class="jp ir">偏差</strong>(差异)。这告诉我们，我们的模型是否预测“好”的概率。模型越精确，这一项越趋向于零，如果每个组只有一个目标，我们有REL=MSE。</li></ul><blockquote class="km kn ko"><p id="141a" class="jn jo kp jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">注意:REL术语通常可以使用<a class="ae kl" href="https://www.quora.com/What-is-called-classifier-calibration-in-machine-learning" rel="noopener ugc nofollow" target="_blank">校准方法</a>来“强制执行”。</p></blockquote><ul class=""><li id="297d" class="ng nh iq jp b jq jr ju jv jy ni kc nj kg nk kk nl nm nn no bi translated"><strong class="jp ir">Resolution</strong>(RES):Resolution项通过计算组内平均成功率与全局成功率的差异来衡量分组的<strong class="jp ir">质量。该值不能强制执行，但理想情况下，我们希望它尽可能高。高分辨率意味着分组可以很好地区分病例，当每组只有1个目标值时，分辨率最高，分辨率=UNC。</strong></li><li id="0786" class="ng nh iq jp b jq np ju nq jy nr kc ns kg nt kk nl nm nn no bi translated"><strong class="jp ir">仓内方差</strong> (WBV):这是预测的平均组内<strong class="jp ir">方差。当不同的概率组合在一起时，该值会增加，否则会减少。当REL减小时，它通常增加，因为对于较大的组，平均预测概率向平均成功率收敛，通过LLN减小REL，<strong class="jp ir"> </strong>，但是因为不同的预测概率混合在一起，所以WBV增加。</strong></li><li id="1e86" class="ng nh iq jp b jq np ju nq jy nr kc ns kg nt kk nl nm nn no bi translated">仓内协方差 (WBC):这是另一个仅由于将不同概率混合在一起而产生的术语。它是预测值和目标值之间的组内<strong class="jp ir">协方差</strong>，因此显示了两者的联合可变性。这也是唯一一个既可以肯定也可以否定的术语。我们希望它尽可能为正，以补偿当更大的概率值与更大的目标值相关联时发生的WBV，反之亦然。</li></ul><blockquote class="km kn ko"><p id="c5df" class="jn jo kp jp b jq jr js jt ju jv jw jx kq jz ka kb kr kd ke kf ks kh ki kj kk ij bi translated">注意:WBV和白细胞都为零，每个组只有一个目标。</p></blockquote><p id="0f6f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了可视化MSE分解，我们可以为n_k = 1到100个元素的K个组绘制公平抛硬币示例的每个项:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nv"><img src="../Images/12a919f625423166632429f3267d2d75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wmKXHmVlT_OPSAl2p17SmA.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">Simple case of an MSE decomposition for different groupings</figcaption></figure><p id="dc60" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如公式中的意图，MSE不依赖于分组，因此它仅在模型(预测概率)改变时改变。首先，WBV和WBC项为零，因为只预测了一个概率，因此既没有方差也没有协方差。我们可以注意到UNC平台为0.25，这代表了我们试图预测的数据的非常高(实际上是最大)的不确定性。当n_k = 1时，RES自然最大并等于UNC，但是当我们将越来越多的不同目标组合在一起时，RES降低到零。最后但并非最不重要的是，对于最优模型，REL的行为与预期一样，因为它在每个分组中都是最小值，并且由于大数定律，对于较大的分组，它收敛到零。</p><p id="85e1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在很明显，在原始的MSE度量中发生了很多事情。诚然，当试图评估具有内在随机性的任务的模型时，MSE本身就足够好了，但分解MSE=REL-RES+WBV-WBC+UNC提供了更多关于该模型实际上有多好的预测概率的洞察力，这要归功于REL项。但是为了使REL能够提供信息，分组应该足够大，以便LLN能够生效。同时，太大的分组会使指标产生偏差，因为组内预测的概率会偏离平均值，组内成功率也会偏离平均值。</p><blockquote class="mq"><p id="7bab" class="mr ms iq bd mt mu mv mw mx my mz kk dk translated">为了找到最佳分组，我们可以将目标定为最小化REL + WBV，因为第一项希望组尽可能大，而第二项惩罚太大的组。</p></blockquote><p id="7712" class="pw-post-body-paragraph jn jo iq jp b jq nb js jt ju nc jw jx jy nd ka kb kc ne ke kf kg nf ki kj kk ij bi translated">通过注意到当平均成功率不同于平均概率时，REL增长，可以找到这个优化问题的近似解决方案。对于足够大的组，该误差与<strong class="jp ir"> 1/sqrt(n_k) </strong>的数量级相同。类似地，假设我们从对预测进行排序开始，然后将它们分组到区间中，知道如果区间收敛到单个点，WBV将减小，我们可以最小化区间长度以最小化WBV。我们还注意到，假设我们假设预测是均匀分布的，区间长度是<strong class="jp ir">N _ k/N</strong>——这是一个很大的假设，但这里只是寻找一个近似解。为了补偿优化目标中任何缺失的系数，我们最小化这两项的线性组合:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ly"><img src="../Images/5f7b1c3c1773fb1b7348cdafef314009.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Eq2JteRwHbT3Dd0T2SLjg.png"/></div></div></figure><p id="fe4a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，我们找到了一个依赖于一些参数的近似解决方案，让我们改变这些参数，看看这在一些真实数据上看起来如何。</p><p id="a267" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<strong class="jp ir"> Kwyk </strong>我们提供在线数学练习，让学生做这些练习，然后利用收集到的数据来预测学生在未来的练习中是否会成功，以校准其复杂性。我们用于此任务的分类器预测每个用户在每次练习中的概率，分布如下:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/4a9ddcb0904898195ca2aa7a3cadd873.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*njiNUa3erUaAqwVLq-s_2A.png"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">Histogram of the predicted probabilities of our classifier</figcaption></figure><p id="a4c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用这些概率，我们可以为不同的组大小绘制目标函数的演化图，并查看最小值出现的位置:</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi nx"><img src="../Images/45a364999afc49678df2a5083bfc0c95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PEhQMhsYq0hQ0Wf9iYB-Tg.png"/></div></div></figure><p id="adc5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们看到最佳分组确实符合我们的手工解决方案。我们还可以看到，经验最佳值大致在<strong class="jp ir"> N^(2/3) </strong>附近，我们建议将此作为最佳团队规模的经验法则。</p></div><div class="ab cl kt ku hu kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ij ik il im in"><h2 id="3300" class="la lb iq bd lc ld le dn lf lg lh dp li jy lj lk ll kc lm ln lo kg lp lq lr ls bi translated">结论</h2><p id="2197" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">总之，我们看到通常的分类标准在随机环境中是没有用的。在这些情况下，我们必须依赖回归度量，并直接评估我们的分类器预测“好”概率的能力。解决这个问题的一个方法是使用MSE并观察算法的表现。但是MSE是许多术语之间复杂相互作用的结果，每个术语都有特定的含义和目的。在随机设置中，MSE中最有趣的部分是REL，但这是假设我们之前已经对预测进行了分组。分组可以用几种方法进行，其中一些方法信息不够丰富。为了解决这个问题，我们必须使组足够大，以使REL由于LLN而收敛，但又足够小，以避免混合太多不同的预测概率。为此，我们提出了一个经验法则，它包括对概率进行排序，然后将n_k = N^(2/3个元素分组，并在此基础上使用REL度量来评估模型。</p><p id="3486" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">奖金:</strong> <em class="kp">我们的模型在预测学生成绩方面表现如何？</em></p><p id="5586" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里是我们在<strong class="jp ir"> Kwyk </strong>的数据中看到的所有指标。我们已经在500，000个样本上训练了我们的分类器，并以66.30%的全局成功率(目标平均值)预测了500，000个不同的样本。这些指标是:</p><ul class=""><li id="07db" class="ng nh iq jp b jq jr ju jv jy ni kc nj kg nk kk nl nm nn no bi translated">准确度分数(阈值50%) = 75.34%</li><li id="91e3" class="ng nh iq jp b jq np ju nq jy nr kc ns kg nt kk nl nm nn no bi translated">混淆矩阵(阈值50%):</li></ul><p id="9bef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该模型似乎随机预测了负面影响</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/3b05893ec495fd10da1a5c81061c23e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*q4U0bysgRGYIRuf6WeTLuQ.png"/></div></figure><ul class=""><li id="56d8" class="ng nh iq jp b jq jr ju jv jy ni kc nj kg nk kk nl nm nn no bi translated">混淆矩阵(阈值60%):</li></ul><p id="bff1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在看起来没问题了…</p><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/954dd9832bc5480b6dc78c332df085eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*N9icQqHe6f1CCWmU6MO97g.png"/></div></figure><ul class=""><li id="22ab" class="ng nh iq jp b jq jr ju jv jy ni kc nj kg nk kk nl nm nn no bi translated">ROC曲线和AUC:</li></ul><figure class="lz ma mb mc gt md gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/9d40386012c076441a1570ca2b68c4da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0DtLT43uDrwdslyv3w26-Q.png"/></div></figure><p id="31fa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这意味着我们的模型有79%的机会对随机选择的正面实例评分高于随机选择的负面实例。</p><ul class=""><li id="fb9a" class="ng nh iq jp b jq jr ju jv jy ni kc nj kg nk kk nl nm nn no bi translated">MSE : 0.168(低值，但这并不能让我们对模型有所了解)</li></ul><p id="cdba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用我们的经验法则，对于n_k = N^(2/3的组) :</p><ul class=""><li id="cdcb" class="ng nh iq jp b jq jr ju jv jy ni kc nj kg nk kk nl nm nn no bi translated">UNC : 0.223(任务非常不确定，最大UNC为0.25)</li><li id="90dd" class="ng nh iq jp b jq np ju nq jy nr kc ns kg nt kk nl nm nn no bi translated">REL : 0.0002(这个模型相当精确)</li><li id="b7f4" class="ng nh iq jp b jq np ju nq jy nr kc ns kg nt kk nl nm nn no bi translated">RES : 0.054(知道maxRES = UNC，分组就很好了)</li><li id="6b10" class="ng nh iq jp b jq np ju nq jy nr kc ns kg nt kk nl nm nn no bi translated">(WBV，WBC) : (0.00001，0.00003)这些值非常低，表明分组概率非常相似。</li></ul><p id="6602" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kp">作者:</em><a class="ae kl" href="https://www.linkedin.com/in/hichamelboukkouri" rel="noopener ugc nofollow" target="_blank"><em class="kp">Hicham EL BOUKKOURI</em>T7】</a></p></div></div>    
</body>
</html>