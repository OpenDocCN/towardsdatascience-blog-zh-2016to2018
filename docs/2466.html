<html>
<head>
<title>Only Numpy: Understanding Back Propagation for Transpose Convolution in Multi Layer CNN with Example and Interactive Code.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">只有 Numpy:理解反向传播的转置卷积多层 CNN 的例子和互动代码。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/only-numpy-understanding-back-propagation-for-transpose-convolution-in-multi-layer-cnn-with-c0a07d191981?source=collection_archive---------1-----------------------#2018-01-29">https://towardsdatascience.com/only-numpy-understanding-back-propagation-for-transpose-convolution-in-multi-layer-cnn-with-c0a07d191981?source=collection_archive---------1-----------------------#2018-01-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/4ba511244c7ea797f6986244d2a319ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/1*ds548DyICdhduOXLGKZ5Dg.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Gif from this <a class="ae jy" href="https://giphy.com/gifs/math-35v2AuS45pUre/download" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="498a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">所以在过去的两天里，我很难理解转置卷积运算。但我终于明白了，今天，我们将训练一个简单的 CNN，它有两个卷积层，如下所示。</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi kx"><img src="../Images/50bfcd4c906814ba7a06fd55b7799325.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PDllWvjyz2ptoXKuN-MfWQ.jpeg"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Very Simple CNN Arch.</figcaption></figure></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="60d1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">我从哪里得到答案的有趣故事。</strong></p><p id="1b84" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">昨天，我被邀请参加一个聚会的晚宴。原因是一个非常博学的硕士生成功地完成了她的答辩，所以我们在庆祝。然而，在过去的两天里，我无法完全理解 CNN 的整个反向传播过程。<br/>当我试图在卷积层的最外层执行反向传播时，我碰了壁。</p><p id="0028" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">但在那次晚宴上，我终于明白了。</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi ln"><img src="../Images/36f44c5c9ff8b763fde59bdeeac261a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*crV_mjHW8Whnn_Hk5hpQyA.jpeg"/></div></div></figure><p id="99cd" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">看着我盘子里的鸡眼，我意识到，一直以来，我都在试图将 CNN 中的反向传播过程理解为反卷积。这是我最初的想法。</p><p id="fcdc" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">设红框为 2*2 输出图像<br/>设绿框为 3*3 内核<br/>设蓝框为 4*4 输入图像</p><p id="e4c2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">由于我们在对 4×4 图像执行卷积之后获得 2×2 输出图像，因此，在执行反向传播时，我们<strong class="kb ir">需要对 2×2 输出图像执行一些操作，以获得具有 4×4 维度的一些图像。</strong>”</p><p id="32ea" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">但是鸡眼(LOL)让我意识到我们的目标不是恢复原来的形象。相反，我们试图得到网络中每个权重的错误率。在多层 CNN 的情况下，我们需要反向传播该误差。所以哈哈，这就是我的解决方案，让我用一个具体的例子和代码来解释我的意思。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="bf6c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">网络架构</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi kx"><img src="../Images/ba279a0684499bb44ee1f7dece4b9546.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f0duDRwUV9t3PxzUK41hKw.jpeg"/></div></div></figure><p id="78ca" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所见，网络拱非常简单，只是两层卷积和一层全连通层。请注意，在执行卷积时，我们需要将内核转置(旋转)180 度，所以请注意上面照片中的绿色方框。</p><p id="8262" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="lo">还有，请注意，为了简单起见，我没有画激活层。但是在交互代码中，我用的不是 tanh()就是 archtan() </em> </strong>。</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi lp"><img src="../Images/d72ae2185b1d72ed1e970a46bef1da97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TbFLNBDhsh9HjcZGQ5KD2w.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">image <a class="ae jy" href="http://techieme.in/matrix-rotation/" rel="noopener ugc nofollow" target="_blank">from techieme</a></figcaption></figure><p id="6e66" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果你不确定矩阵旋转，<a class="ae jy" href="http://techieme.in/matrix-rotation/" rel="noopener ugc nofollow" target="_blank">请阅读本文</a>。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="5a60" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">正向进给</strong>操作<strong class="kb ir">操作</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi lq"><img src="../Images/ed07ca6053fdbc7ae560f307b5907e56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OQnoH2TxdPDS875Nt6mSXg.jpeg"/></div></div></figure><blockquote class="lr ls lt"><p id="8345" class="jz ka lo kb b kc kd ke kf kg kh ki kj lu kl km kn lv kp kq kr lw kt ku kv kw ij bi translated">**更新**我在列上犯了一个错误，绿色箭头所指的两列必须对调。谢谢亚伯拉罕·坎指出。</p></blockquote><p id="4268" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">所以如上所见，卷积运算可以写成一行。出于我稍后将解释的原因，请仔细记下红框变量，它们基本上是下一层的输入。但是在执行反向传播时，这些信息变得至关重要。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="16c1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">相对于绿色权重的反向传播</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi lx"><img src="../Images/3872eba7ec60f67da6c99899cd605e86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UaJFf5zD-eNiIrqBBI8mPQ.jpeg"/></div></div></figure><p id="b56f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">黄色方框表示学习率，同样，整个反向传播是一个标准过程。我也写下了梯度更新方程。最后，请注意红色方框中的符号“k ”,我会反复使用这个符号来表示(Out — Y)。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="dd01" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">相对于红色权重的反向传播</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi kx"><img src="../Images/6151e03d62fc7690e7b5b0ab248d1073.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dtj3oWhCNk9gRrgktlDGYw.jpeg"/></div></div></figure><p id="711f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">红框→ (Out — Y) <br/>黄框→学习率<br/>黑框→卷积运算前旋转核 180 度(或转置)——<em class="lo">还记得在卷积运算中我们旋转核吗？</em></p><p id="40e2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">一切都非常简单明了，除了紫色的盒子，那是什么？</p><p id="b5de" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">紫色框→旋转矩阵以拟合计算每个权重的导数。</strong></p><p id="a139" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在的问题是，为什么？我们为什么要这样做？</p><p id="a0ec" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">记得我告诉过你们要注意每一层的输入吗？让我们再来一次。</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi kx"><img src="../Images/baebf23923ebdb7ef18858507ec04f8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tkF4DKJVqrgp5T_tyGOaiw.jpeg"/></div></div></figure><p id="850f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">请仔细看看这些彩色的盒子。</p><p id="8859" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">橙色框</strong> →正在乘以红色 W(2，2)的输入<br/> <strong class="kb ir">浅绿色框</strong> →正在乘以红色 W(2，1)的输入<br/> <strong class="kb ir">蓝色框</strong> →正在乘以红色 W(1，2)的输入<br/> <strong class="kb ir">粉色框</strong> →正在乘以红色 W(1，1)的输入</p><p id="1e2f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">很好，这很简单，但是这和转置内核有什么关系呢？好吧，让我们这样做，因为(请看黑框等式)Out 可以写成一行，让我们对红色权重求导，如下所示。</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi kx"><img src="../Images/2cbe459cbd5e909b5416292db55522fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XQkv7G_FZrNZp4VmepXL8Q.jpeg"/></div></div></figure><blockquote class="lr ls lt"><p id="66ca" class="jz ka lo kb b kc kd ke kf kg kh ki kj lu kl km kn lv kp kq kr lw kt ku kv kw ij bi translated">**更新* * 4 月 8 日—感谢<a class="ae jy" href="https://medium.com/@ak16?source=responses---------1----------------" rel="noopener">大宇</a>和亚伯拉罕·康指出错误，坐标上有个小错误。</p></blockquote><p id="a1bf" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">深绿色方框数字→对不起，我没有绿色的笔，但它们代表绿色的砝码<strong class="kb ir">。</strong></p><p id="7c11" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如图所示，当对每个红色权重进行求导时，我们可以看到 XX 坐标因输入而异。我们需要根据每个权重来匹配这些坐标，这就是我们将矩阵旋转(转置)180 度的原因。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="bfe0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">关于蓝色重量部分 1 的反向传播</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi kx"><img src="../Images/13f1ed8bc0c4818983890c87faaf1362.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ed5YUlURDbya6MPG5Zqu5Q.jpeg"/></div></div></figure><p id="e1fb" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">蓝框</strong> →计算(K *绿色权重)和(填充的红色权重)之间的卷积<br/> <strong class="kb ir">橙色框</strong> →再次旋转矩阵以获得每个权重的导数。<br/> <strong class="kb ir">黑盒</strong> →同样的故事，卷积运算前旋转内核。</p><p id="0929" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在，问题来了，为什么要填充(紫色方框)？为什么我们需要垫红色的砝码？</p><p id="0090" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">好问题，我一会儿会解释，但是现在请继续读下去。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="e136" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">关于蓝色重量部分 2 的反向传播</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi ly"><img src="../Images/3ee5c7523340162913437969acaecb23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D6mrsUs7MHBl9ejde00AZQ.png"/></div></div></figure><p id="b87c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">蓝框</strong> →第 1 部分的计算矩阵。<br/> <strong class="kb ir">黑盒</strong> →卷积运算前转置内核。<br/> <strong class="kb ir">橙色、浅绿色、蓝色、粉色方框</strong> →计算每个蓝色权重的每个导数。</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi lz"><img src="../Images/6798a54b2d08a7e1c3c06b1b43e2e52e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xeANqi9ufUIVXSOepxc45A.jpeg"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Close look of the Rotated Kernel</figcaption></figure><p id="1c40" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">上图是在执行卷积运算时，对旋转后的内核的近距离观察。但是现在让我们再看一下输入。</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi kx"><img src="../Images/0e5d9aa27fba380d0489b3636e36f010.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fciwdsoevzZdWuX7_p6OwA.jpeg"/></div></div></figure><p id="dc23" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">再说一次，因为 Out 可以写成一行，让我们对蓝色权重求导，如下所示。</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi kx"><img src="../Images/5101fb946dfa2668f803965cefdb5195.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U38xwuuntuYgVxFjr7veBw.jpeg"/></div></div></figure><p id="a503" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">绿色框号</strong> →再次抱歉没有绿色笔<br/> <strong class="kb ir">橙色框</strong> →相对于蓝色权重(2，2)计算的渐变<br/> <strong class="kb ir">粉色框</strong> →相对于蓝色权重(1，1)计算的渐变</p><p id="112d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">因此，我们再次旋转(或转置)矩阵，以匹配每个权重的梯度。</p><p id="4349" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">另外，现在我们填充红色重量的原因很清楚了，这是为了得到每个重量的梯度，我将再次向你们展示我所说的填充红色重量的意思。(请看紫色的星星)</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi kx"><img src="../Images/64c2c66445c3f200b2e0cccebaa1ccc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*io68RRE3Vn6AFbRoQRuT_g.jpeg"/></div></div></figure></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="8682" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">交互式代码激活功能</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi kx"><img src="../Images/5b5bfba3c39aa3a06347b95d4928da83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FCKgvfWN0_Sdz9Zy8Czl7Q.png"/></div></div></figure><p id="0f9e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">绿框</strong> →激活函数的导数，因为它们具有相同的维数，我们可以只执行元素乘法</p><p id="f89a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">红框</strong> →旋转内核匹配渐变</p><p id="6602" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">蓝色方框</strong> →用零填充红色砝码(名为 W2)</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="08b0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">交互代码</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi ma"><img src="../Images/b79d0080c66deb6364b5056d44ff4bb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Oe84UZaoFj_i-dpbGxAfjQ.png"/></div></div></figure><p id="432d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">请<a class="ae jy" href="https://repl.it/@Jae_DukDuk/transpose-conv" rel="noopener ugc nofollow" target="_blank">点击此处访问互动代码。</a></p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><h2 id="ae9d" class="mb mc iq bd md me mf dn mg mh mi dp mj kk mk ml mm ko mn mo mp ks mq mr ms mt bi translated">最后的话</h2><p id="660e" class="pw-post-body-paragraph jz ka iq kb b kc mu ke kf kg mv ki kj kk mw km kn ko mx kq kr ks my ku kv kw ij bi translated">在 CNN 中理解反向传播是非常令人满意的，我两天来一直在努力理解这个概念。如果没有被邀请参加毕业晚宴，我是不可能做到这一点的，谢谢你，莎拉！</p><p id="74f7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 找我。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的 twitter <a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，并访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。如果你感兴趣，我还在这里做了解耦神经网络<a class="ae jy" href="https://becominghuman.ai/only-numpy-implementing-and-comparing-combination-of-google-brains-decoupled-neural-interfaces-6712e758c1af" rel="noopener ugc nofollow" target="_blank">的比较。</a></p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="fdd6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="d406" class="mz na iq kb b kc kd kg kh kk nb ko nc ks nd kw ne nf ng nh bi translated">D.(2015 年 10 月 25 日)。矩阵旋转和矩阵转置。检索于 2018 年 1 月 28 日，发自<a class="ae jy" href="http://techieme.in/matrix-rotation/" rel="noopener ugc nofollow" target="_blank">http://techieme.in/matrix-rotation/</a></li><li id="a1b0" class="mz na iq kb b kc ni kg nj kk nk ko nl ks nm kw ne nf ng nh bi translated">什么是反进化层？(未注明)。检索于 2018 年 1 月 28 日，来自<a class="ae jy" href="https://datascience.stackexchange.com/questions/6107/what-are-deconvolutional-layers" rel="noopener ugc nofollow" target="_blank">https://data science . stack exchange . com/questions/6107/what-is-de convolution-layers</a></li><li id="9245" class="mz na iq kb b kc ni kg nj kk nk ko nl ks nm kw ne nf ng nh bi translated"><a class="ae jy" href="http://courses.cs.tau.ac.il/Caffe_workshop/Bootcamp/pdf_lectures/Lecture%203%20CNN%20-%20backpropagation.pdf" rel="noopener ugc nofollow" target="_blank">http://courses . cs . tau . AC . il/Caffe _ workshop/boot camp/pdf _ lectures/lectures % 203% 20 CNN % 20-% 20 back propagation . pdf</a></li><li id="b7da" class="mz na iq kb b kc ni kg nj kk nk ko nl ks nm kw ne nf ng nh bi translated">Dumoulin 和 f . Visin(2016 年)。深度学习卷积算法指南。<em class="lo"> arXiv 预印本 arXiv:1603.07285 </em>。</li><li id="74c2" class="mz na iq kb b kc ni kg nj kk nk ko nl ks nm kw ne nf ng nh bi translated"><a class="ae jy" href="https://www.cc.gatech.edu/classes/AY2018/cs7643_fall/slides/L7_cnns_annotated.pdf" rel="noopener ugc nofollow" target="_blank">https://www . cc . gatech . edu/classes/ay 2018/cs 7643 _ fall/slides/L7 _ CNNs _ annotated . pdf</a></li></ol><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi nn"><img src="../Images/731acf26f5d44fdc58d99a6388fe935d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6gfnVvkMRFtjVsWF7vkClA.png"/></div></div></figure><h2 id="fd41" class="mb mc iq bd md me mf dn mg mh mi dp mj kk mk ml mm ko mn mo mp ks mq mr ms mt bi translated">这篇文章发表在<a class="ae jy" href="https://medium.com/swlh" rel="noopener"> The Startup </a>上，这是 Medium 最大的创业刊物，拥有 295，232+人关注。</h2><h2 id="7945" class="mb mc iq bd md me mf dn mg mh mi dp mj kk mk ml mm ko mn mo mp ks mq mr ms mt bi translated">在此订阅接收<a class="ae jy" href="http://growthsupply.com/the-startup-newsletter/" rel="noopener ugc nofollow" target="_blank">我们的头条新闻</a>。</h2><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi nn"><img src="../Images/731acf26f5d44fdc58d99a6388fe935d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6gfnVvkMRFtjVsWF7vkClA.png"/></div></div></figure></div></div>    
</body>
</html>