<html>
<head>
<title>Image Captioning in Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习中的图像字幕</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-captioning-in-deep-learning-9cd23fb4d8d2?source=collection_archive---------2-----------------------#2017-09-29">https://towardsdatascience.com/image-captioning-in-deep-learning-9cd23fb4d8d2?source=collection_archive---------2-----------------------#2017-09-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="263f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">什么是图像字幕？</h2></div><p id="2598" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">图像字幕</strong>是生成图像文字描述的过程。它同时使用了<strong class="kh ir">自然语言处理</strong>和<strong class="kh ir">计算机视觉</strong>来生成字幕。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/9b12e020eedab7a1ec30c9d166ce44c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6BFOIdSHlk24Z3DFEakvnQ.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Image Captioning</figcaption></figure><p id="79fd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据集将采用[ <strong class="kh ir">图像</strong> → <strong class="kh ir">标题</strong>的形式。数据集由输入图像及其相应的输出标题组成。</p><h1 id="4026" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated"><strong class="ak">网络拓扑</strong></h1><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/06f5d1c08085ce4bc87e97ea287ad51e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*vzFwXFJOrg6WRGNsYYT6qg.png"/></div></figure><h2 id="259b" class="mk ls iq bd lt ml mm dn lx mn mo dp mb ko mp mq md ks mr ms mf kw mt mu mh mv bi translated">编码器</h2><p id="3c43" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">卷积神经网络(CNN)可以被认为是一个编码器。输入图像交给 CNN 提取特征。CNN 的最后一个隐藏状态连接到解码器。</p><h2 id="9f10" class="mk ls iq bd lt ml mm dn lx mn mo dp mb ko mp mq md ks mr ms mf kw mt mu mh mv bi translated"><strong class="ak">解码器</strong></h2><p id="08cf" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">解码器是一个递归神经网络(RNN ),它在单词级别进行语言建模。第一时间步接收编码器的编码输出和<start>矢量。</start></p><h1 id="34a9" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated"><strong class="ak">培训</strong></h1><p id="97c8" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated">CNN(编码器)最后一个隐藏状态的输出被提供给解码器的第一个时间步长。我们设置<strong class="kh ir"> x1 </strong> = <strong class="kh ir"> &lt;开始&gt; </strong>向量和期望的标号<strong class="kh ir"> y1 </strong> = <strong class="kh ir">序列中的第一个字</strong>。类似地，我们设置第一个单词的<strong class="kh ir"> x2 </strong> = <strong class="kh ir">单词向量，并期望网络预测第二个单词<strong class="kh ir"/>。最后，在最后一步，<strong class="kh ir"> xT </strong> = <strong class="kh ir">最后一个字</strong>，目标标签<strong class="kh ir">yT</strong>=<strong class="kh ir">&lt;END&gt;</strong>token。</strong></p><p id="3a24" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">在训练过程中，即使解码器之前出错，也会在每个时间步向解码器提供正确的输入。</strong></p><h1 id="9656" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated"><strong class="ak">测试</strong></h1><p id="c3c9" class="pw-post-body-paragraph kf kg iq kh b ki mw jr kk kl mx ju kn ko my kq kr ks mz ku kv kw na ky kz la ij bi translated"><strong class="kh ir">图像表示</strong>被提供给解码器的第一时间步。设置<strong class="kh ir"> x1 </strong> = <strong class="kh ir"> &lt;开始&gt; </strong>向量，计算第一个字<strong class="kh ir"> y1 </strong>的分布。我们从分布中抽取一个单词(或者挑选 argmax)，将其嵌入向量设为<strong class="kh ir"> x2 </strong>，重复这个过程，直到生成<strong class="kh ir"> &lt; END &gt; </strong> token。</p><p id="0806" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">在测试期间，解码器在时间 t 的输出被反馈，并成为解码器在时间 t+1 的输入</strong></p><h1 id="93f3" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated"><strong class="ak">数据集</strong></h1><ul class=""><li id="fa7c" class="nb nc iq kh b ki mw kl mx ko nd ks ne kw nf la ng nh ni nj bi translated"><a class="ae nk" href="http://mscoco.org/dataset/#overview" rel="noopener ugc nofollow" target="_blank">语境中的常见对象(COCO) </a>。超过 120，000 张图片和描述的集合</li><li id="d167" class="nb nc iq kh b ki nl kl nm ko nn ks no kw np la ng nh ni nj bi translated"><a class="ae nk" href="http://nlp.cs.illinois.edu/HockenmaierGroup/8k-pictures.html" rel="noopener ugc nofollow" target="_blank"> Flickr 8K </a>。从 flickr.com 收集了八千张描述过的图片。</li><li id="b1c9" class="nb nc iq kh b ki nl kl nm ko nn ks no kw np la ng nh ni nj bi translated"><a class="ae nk" href="http://shannon.cs.illinois.edu/DenotationGraph/" rel="noopener ugc nofollow" target="_blank"> Flickr 30K </a>。收集了 3 万张来自 flickr.com 的图片。</li><li id="5ea6" class="nb nc iq kh b ki nl kl nm ko nn ks no kw np la ng nh ni nj bi translated"><a class="ae nk" href="http://sidgan.me/technical/2016/01/09/Exploring-Datasets" rel="noopener ugc nofollow" target="_blank">探索图像字幕数据集</a>，2016 年</li></ul></div></div>    
</body>
</html>