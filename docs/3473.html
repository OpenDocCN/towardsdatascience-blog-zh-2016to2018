<html>
<head>
<title>Deep Learning Tips and Tricks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习技巧和诀窍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-tips-and-tricks-1ef708ec5f53?source=collection_archive---------3-----------------------#2018-05-15">https://towardsdatascience.com/deep-learning-tips-and-tricks-1ef708ec5f53?source=collection_archive---------3-----------------------#2018-05-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="625a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下是我与同龄人和学生就如何优化深度模型进行的对话、信息和辩论的精华集合。如果你有有效的方法，请分享出来！！</p></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><h1 id="8ace" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">首先，为什么要调整模型？</h1><p id="fe47" class="pw-post-body-paragraph jq jr it js b jt lt jv jw jx lu jz ka kb lv kd ke kf lw kh ki kj lx kl km kn im bi translated">像卷积神经网络(CNN)这样的深度学习模型有大量的参数；我们实际上可以称之为超参数，因为它们在模型中没有被优化。你可以搜索这些超参数的最佳值，但是你需要大量的硬件和时间。那么，一个真正的数据科学家会满足于猜测这些基本参数吗？</p><p id="f7c2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">改进您的模型的最好方法之一是建立在对您的领域进行了深入研究的专家的设计和架构之上，这些专家通常拥有强大的硬件。优雅地，他们经常开源最终的建模架构和基本原理。</p><h1 id="e65e" class="kv kw it bd kx ky ly la lb lc lz le lf lg ma li lj lk mb lm ln lo mc lq lr ls bi translated">深度学习技术</h1><p id="10d0" class="pw-post-body-paragraph jq jr it js b jt lt jv jw jx lu jz ka kb lv kd ke kf lw kh ki kj lx kl km kn im bi translated">这里有一些方法可以帮助你通过预先训练的模型来提高你的健身时间和准确性:</p><ol class=""><li id="11f4" class="md me it js b jt ju jx jy kb mf kf mg kj mh kn mi mj mk ml bi translated"><strong class="js iu"> <em class="mm">研究理想的预训架构:</em> </strong>了解迁移学习的<a class="ae mn" href="https://www.analyticsvidhya.com/blog/2017/06/transfer-learning-the-art-of-fine-tuning-a-pre-trained-model/" rel="noopener ugc nofollow" target="_blank">好处</a>，或者浏览一些<a class="ae mn" href="http://www.vlfeat.org/matconvnet/pretrained/" rel="noopener ugc nofollow" target="_blank">强大的 CNN 架构</a>。考虑那些看起来不明显的领域，但是共享潜在的潜在特征。</li><li id="3e03" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn mi mj mk ml bi translated"><strong class="js iu"> <em class="mm">使用较小的学习率:</em> </strong>由于预训练的权重通常比随机初始化的权重好，所以修改要更细腻！你在这里的选择取决于学习环境和预训练的进展情况，但是检查跨时代的错误，以了解你离收敛有多近。</li><li id="6c08" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn mi mj mk ml bi translated"><strong class="js iu"> <em class="mm">使用退出:</em> </strong>与回归模型的脊和套索正则化一样，所有模型都没有优化的<em class="mm"> alpha </em>或<em class="mm">退出</em>。这是一个超参数，取决于您的具体问题，必须进行测试。从更大的变化开始——像<code class="fe mt mu mv mw b">np.logspace()</code>可以提供的数量级的更宽的网格搜索跨度——然后像上面的学习率一样下降。</li><li id="1d50" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn mi mj mk ml bi translated"><strong class="js iu"> <em class="mm">限制权重大小:</em> </strong>我们可以限制某些层的权重的最大范数(绝对值)，以便推广我们的模型</li><li id="41a3" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn mi mj mk ml bi translated"><strong class="js iu"> <em class="mm">不要碰第一层:</em> </strong>神经网络的第一个隐藏层往往会捕捉通用的和可解释的特征，如形状、曲线或跨领域的相互作用。我们应该经常不去管这些，而把重点放在优化更远的元潜在水平上。这可能意味着添加隐藏层，这样我们就不会匆忙的过程！</li><li id="c718" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn mi mj mk ml bi translated"><strong class="js iu"> <em class="mm">修改输出层:</em> </strong>用一个新的激活函数和适合你的域的输出大小替换模型默认值。但是，不要把自己局限在最明显的解决方案上。虽然 MNIST 可能看起来想要 10 个输出类，但一些数字有常见的变化，允许 12-16 个类可以更好地解决这些变化并提高模型性能！正如上面的提示一样，随着我们接近输出，深度学习模型应该越来越多地修改和定制。</li></ol><h1 id="cabb" class="kv kw it bd kx ky ly la lb lc lz le lf lg ma li lj lk mb lm ln lo mc lq lr ls bi translated">喀拉斯的技术</h1><p id="53e3" class="pw-post-body-paragraph jq jr it js b jt lt jv jw jx lu jz ka kb lv kd ke kf lw kh ki kj lx kl km kn im bi translated">以下是如何在 MNIST 的 Keras 中修改辍学和限制体重的方法:</p><pre class="mx my mz na gt nb mw nc nd aw ne bi"><span id="f2c8" class="nf kw it mw b gy ng nh l ni nj"># dropout in input and hidden layers<br/># weight constraint imposed on hidden layers<br/># ensures the max norm of the weights does not exceed 5</span><span id="b155" class="nf kw it mw b gy nk nh l ni nj">model = Sequential()</span><span id="f5b4" class="nf kw it mw b gy nk nh l ni nj">model.add(Dropout(0.2, input_shape=(784,))) # dropout on the inputs<br/># this helps mimic noise or missing data</span><span id="90f0" class="nf kw it mw b gy nk nh l ni nj">model.add(Dense(128, input_dim=784, kernel_initializer='normal', activation='relu', kernel_constraint=maxnorm(5)))</span><span id="b64d" class="nf kw it mw b gy nk nh l ni nj">model.add(Dropout(0.5))</span><span id="7ff5" class="nf kw it mw b gy nk nh l ni nj">model.add(Dense(128, kernel_initializer='normal', activation='tanh', kernel_constraint=maxnorm(5)))</span><span id="f13c" class="nf kw it mw b gy nk nh l ni nj">model.add(Dropout(0.5))</span><span id="0c11" class="nf kw it mw b gy nk nh l ni nj">model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))</span></pre><h2 id="0947" class="nf kw it bd kx nl nm dn lb nn no dp lf kb np nq lj kf nr ns ln kj nt nu lr nv bi translated">辍学最佳实践:</h2><ul class=""><li id="166a" class="md me it js b jt lt jx lu kb nw kf nx kj ny kn nz mj mk ml bi translated">使用 20–50%的小压降，建议输入<a class="ae mn" href="https://chrisalbon.com/deep_learning/keras/adding_dropout/" rel="noopener ugc nofollow" target="_blank">为 20%。太低，你的影响可以忽略不计；太高，你吃不饱。</a></li><li id="c22e" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nz mj mk ml bi translated">在输入图层和隐藏图层上使用 dropout。这已经被证明可以提高深度学习的性能。</li><li id="cf00" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nz mj mk ml bi translated">使用具有衰减和大动量的大学习率。</li><li id="7e9d" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nz mj mk ml bi translated">约束你的体重！大的学习率会导致爆炸梯度。对网络权重施加约束条件(例如大小为 5 的最大范数正则化)已被证明可以改善结果。</li><li id="8667" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nz mj mk ml bi translated">使用更大的网络。当在更大的网络上使用 dropout 时，您可能会获得更好的性能，从而为模型提供更多学习独立表示的机会。</li></ul></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><p id="c98e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以下是一个在 Keras 中对 MNIST 的 14 个类进行最终图层修改的示例:</p><pre class="mx my mz na gt nb mw nc nd aw ne bi"><span id="6d9a" class="nf kw it mw b gy ng nh l ni nj"><strong class="mw iu">from</strong> keras.layers.core <strong class="mw iu">import</strong> Activation, Dense</span><span id="f567" class="nf kw it mw b gy nk nh l ni nj">model<strong class="mw iu">.</strong>layers<strong class="mw iu">.</strong>pop() # defaults to last<br/>model<strong class="mw iu">.</strong>outputs <strong class="mw iu">=</strong> [model<strong class="mw iu">.</strong>layers[<strong class="mw iu">-</strong>1]<strong class="mw iu">.</strong>output]<br/>model<strong class="mw iu">.</strong>layers[<strong class="mw iu">-</strong>1]<strong class="mw iu">.</strong>outbound_nodes <strong class="mw iu">=</strong> []<br/>model<strong class="mw iu">.</strong>add(Dense(14, activation<strong class="mw iu">=</strong>'softmax')) </span></pre><p id="4138" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">以及如何在前五层冻结权重的示例:</p><pre class="mx my mz na gt nb mw nc nd aw ne bi"><span id="af50" class="nf kw it mw b gy ng nh l ni nj"><strong class="mw iu">for</strong> layer <strong class="mw iu">in</strong> model<strong class="mw iu">.</strong>layers[:5]:<br/>    layer<strong class="mw iu">.</strong>trainable <strong class="mw iu">=</strong> False</span></pre><p id="0a15" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">或者，我们可以将该层的学习速率设置为零，或者使用每个参数的自适应学习算法，如<a class="ae mn" href="https://keras.io/optimizers/" rel="noopener ugc nofollow" target="_blank"> Adadelta 或 Adam </a>。这有点复杂，最好在其他平台上实现，比如 Caffe。</p></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><h1 id="931d" class="kv kw it bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">预训练网络的图库:</h1><h2 id="42b2" class="nf kw it bd kx nl nm dn lb nn no dp lf kb np nq lj kf nr ns ln kj nt nu lr nv bi translated"><strong class="ak"> Keras </strong></h2><ul class=""><li id="dd27" class="md me it js b jt lt jx lu kb nw kf nx kj ny kn nz mj mk ml bi translated"><a class="ae mn" href="https://www.kaggle.com/gaborfodor/keras-pretrained-models" rel="noopener ugc nofollow" target="_blank">卡格尔列表</a></li><li id="644d" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nz mj mk ml bi translated"><a class="ae mn" href="https://keras.io/applications/" rel="noopener ugc nofollow" target="_blank"> Keras 应用</a></li><li id="1bef" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nz mj mk ml bi translated"><a class="ae mn" href="https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/" rel="noopener ugc nofollow" target="_blank"> OpenCV 示例</a></li></ul><h2 id="a908" class="nf kw it bd kx nl nm dn lb nn no dp lf kb np nq lj kf nr ns ln kj nt nu lr nv bi translated"><strong class="ak">张量流</strong></h2><ul class=""><li id="b922" class="md me it js b jt lt jx lu kb nw kf nx kj ny kn nz mj mk ml bi translated"><a class="ae mn" href="https://github.com/ry/tensorflow-vgg16" rel="noopener ugc nofollow" target="_blank"> VGG16 </a></li><li id="f746" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nz mj mk ml bi translated"><a class="ae mn" href="https://github.com/tensorflow/models/blob/master/inception/README.md#how-to-fine-tune-a-pre-trained-model-on-a-new-task" rel="noopener ugc nofollow" target="_blank">盗梦空间 V3 </a></li><li id="4a5f" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nz mj mk ml bi translated"><a class="ae mn" href="https://github.com/ry/tensorflow-resnet" rel="noopener ugc nofollow" target="_blank"> ResNet </a></li></ul><h2 id="121e" class="nf kw it bd kx nl nm dn lb nn no dp lf kb np nq lj kf nr ns ln kj nt nu lr nv bi translated"><strong class="ak">火炬</strong></h2><ul class=""><li id="6b60" class="md me it js b jt lt jx lu kb nw kf nx kj ny kn nz mj mk ml bi translated"><a class="ae mn" href="https://github.com/szagoruyko/loadcaffe" rel="noopener ugc nofollow" target="_blank"> LoadCaffe </a></li></ul><h2 id="805a" class="nf kw it bd kx nl nm dn lb nn no dp lf kb np nq lj kf nr ns ln kj nt nu lr nv bi translated"><strong class="ak">咖啡馆</strong></h2><ul class=""><li id="43cc" class="md me it js b jt lt jx lu kb nw kf nx kj ny kn nz mj mk ml bi translated"><a class="ae mn" href="https://github.com/BVLC/caffe/wiki/Model-Zoo" rel="noopener ugc nofollow" target="_blank">模型动物园</a></li></ul><h1 id="a8ed" class="kv kw it bd kx ky ly la lb lc lz le lf lg ma li lj lk mb lm ln lo mc lq lr ls bi translated"><a class="ae mn" href="http://nbviewer.jupyter.org/github/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb" rel="noopener ugc nofollow" target="_blank">在 Jupyter 中查看你的张量图</a></h1><p id="2d1e" class="pw-post-body-paragraph jq jr it js b jt lt jv jw jx lu jz ka kb lv kd ke kf lw kh ki kj lx kl km kn im bi translated">获得模型外观的视觉概念通常是很重要的。如果你在 Keras 中工作，抽象是很好的，但是不允许你深入模型的各个部分进行更深入的分析。幸运的是，下面的代码让我们可以直接用 Python 可视化我们的模型:</p><pre class="mx my mz na gt nb mw nc nd aw ne bi"><span id="44de" class="nf kw it mw b gy ng nh l ni nj"># From: <a class="ae mn" href="http://nbviewer.jupyter.org/github/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb" rel="noopener ugc nofollow" target="_blank">http://nbviewer.jupyter.org/github/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb</a><br/># Helper functions for TF Graph visualization<br/>from IPython.display import clear_output, Image, display, HTML<br/>def strip_consts(graph_def, max_const_size=32):<br/>    """Strip large constant values from graph_def."""<br/>    strip_def = tf.GraphDef()<br/>    for n0 in graph_def.node:<br/>        n = strip_def.node.add() <br/>        n.MergeFrom(n0)<br/>        if n.op == 'Const':<br/>            tensor = n.attr['value'].tensor<br/>            size = len(tensor.tensor_content)<br/>            if size &gt; max_const_size:<br/>                tensor.tensor_content = bytes("&lt;stripped %d bytes&gt;"%size, 'utf-8')<br/>    return strip_def<br/>  <br/>def rename_nodes(graph_def, rename_func):<br/>    res_def = tf.GraphDef()<br/>    for n0 in graph_def.node:<br/>        n = res_def.node.add() <br/>        n.MergeFrom(n0)<br/>        n.name = rename_func(n.name)<br/>        for i, s in enumerate(n.input):<br/>            n.input[i] = rename_func(s) if s[0]!='^' else '^'+rename_func(s[1:])<br/>    return res_def<br/>  <br/>def show_graph(graph_def, max_const_size=32):<br/>    """Visualize TensorFlow graph."""<br/>    if hasattr(graph_def, 'as_graph_def'):<br/>        graph_def = graph_def.as_graph_def()<br/>    strip_def = strip_consts(graph_def, max_const_size=max_const_size)<br/>    code = """<br/>        &lt;script&gt;<br/>          function load() {{<br/>            document.getElementById("{id}").pbtxt = {data};<br/>          }}<br/>        &lt;/script&gt;<br/>        &lt;link rel="import" href="https://tensorboard.appspot.com/tf-graph-basic.build.html" onload=load()&gt;<br/>        &lt;div style="height:600px"&gt;<br/>          &lt;tf-graph-basic id="{id}"&gt;&lt;/tf-graph-basic&gt;<br/>        &lt;/div&gt;<br/>    """.format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))<br/>  <br/>    iframe = """<br/>        &lt;iframe seamless style="width:800px;height:620px;border:0" srcdoc="{}"&gt;&lt;/iframe&gt;<br/>    """.format(code.replace('"', '&amp;quot;'))<br/>    display(HTML(iframe))</span><span id="55dd" class="nf kw it mw b gy nk nh l ni nj"># Visualizing the network graph. Be sure expand the "mixed" nodes to see their <br/># internal structure. We are going to visualize "Conv2D" nodes.<br/>graph_def = tf.get_default_graph().as_graph_def()<br/>tmp_def = rename_nodes(graph_def, lambda s:"/".join(s.split('_',1)))<br/>show_graph(tmp_def)</span></pre><h1 id="9814" class="kv kw it bd kx ky ly la lb lc lz le lf lg ma li lj lk mb lm ln lo mc lq lr ls bi translated">用 Keras 可视化你的模型</h1><p id="831d" class="pw-post-body-paragraph jq jr it js b jt lt jv jw jx lu jz ka kb lv kd ke kf lw kh ki kj lx kl km kn im bi translated">这将<a class="ae mn" href="https://keras.io/visualization/" rel="noopener ugc nofollow" target="_blank">绘制出模型</a>的图形，并将其保存为 png 文件:</p><pre class="mx my mz na gt nb mw nc nd aw ne bi"><span id="4e03" class="nf kw it mw b gy ng nh l ni nj"><strong class="mw iu">from</strong> keras.utils <strong class="mw iu">import</strong> plot_model<br/>plot_model(model, to_file='model.png')</span></pre><p id="1df5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe mt mu mv mw b">plot</code>采用两个可选参数:</p><ul class=""><li id="feef" class="md me it js b jt ju jx jy kb mf kf mg kj mh kn nz mj mk ml bi translated"><code class="fe mt mu mv mw b">show_shapes</code>(默认为假)控制是否在图形中显示输出形状。</li><li id="f194" class="md me it js b jt mo jx mp kb mq kf mr kj ms kn nz mj mk ml bi translated"><code class="fe mt mu mv mw b">show_layer_names</code>(默认为真)控制图层名称是否显示在图形中。</li></ul><p id="512e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">您也可以直接获得<code class="fe mt mu mv mw b">pydot.Graph</code>对象并自己渲染它，例如在 ipython 笔记本中显示它:</p><pre class="mx my mz na gt nb mw nc nd aw ne bi"><span id="7630" class="nf kw it mw b gy ng nh l ni nj"><strong class="mw iu">from</strong> IPython.display <strong class="mw iu">import</strong> SVG<br/><strong class="mw iu">from</strong> keras.utils.visualize_util <strong class="mw iu">import</strong> model_to_dot</span><span id="da06" class="nf kw it mw b gy nk nh l ni nj">SVG(model_to_dot(model).create(prog='dot', format='svg'))</span></pre></div><div class="ab cl ko kp hx kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="im in io ip iq"><p id="6039" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">希望这个合集对你的机器学习项目有所帮助！请在下面的评论中告诉我你是如何优化你的深度学习模型的，并在<a class="ae mn" href="https://twitter.com/ultimetis" rel="noopener ugc nofollow" target="_blank"> Twitter </a>和<a class="ae mn" href="https://www.linkedin.com/in/jbalaban/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上与我联系！</p></div></div>    
</body>
</html>