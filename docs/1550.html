<html>
<head>
<title>[ML] Formal Framework — Preliminaries</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">[ML]正式框架—准备工作</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ml-formal-framework-preliminaries-e3bb1a61a956?source=collection_archive---------6-----------------------#2017-09-18">https://towardsdatascience.com/ml-formal-framework-preliminaries-e3bb1a61a956?source=collection_archive---------6-----------------------#2017-09-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="0981" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">可以找到相当数量的机器学习论文，它们假设要理解良好的预备知识。另一方面，似乎没有那么多的出版物提供了清晰的初步介绍。</p></div><div class="ab cl kl km hu kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="ij ik il im in"><p id="360e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">分类器</strong></p><ul class=""><li id="5257" class="ks kt iq jp b jq jr ju jv jy ku kc kv kg kw kk kx ky kz la bi translated">根据某些参数化将输入元素映射到输出元素的函数</li></ul><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lb"><img src="../Images/d1131efeef9916e67e63c69eed2fa8e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/1*WksbQxLJamtq9OLKMl10wQ.gif"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Parametrizable Classifier</figcaption></figure><p id="523b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">输入空间、输出空间和参数空间</strong></p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/fdd29ffeb48e2e327312dcb09137a015.png" data-original-src="https://miro.medium.com/v2/resize:fit:52/1*3c5S3uaNyZC0nMmdvZ4gww.gif"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Domain</figcaption></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lo"><img src="../Images/05ddf193de4463a2b28500c507337534.png" data-original-src="https://miro.medium.com/v2/resize:fit:46/1*LVeMAtbX2vxJPocDX9eNgQ.gif"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Codomain</figcaption></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/df012b186fd66ad3ffcaa794d46686b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:46/1*34tGkc0FQzsY-TnbnizUzQ.gif"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Parameters Space, where the Training is performed</figcaption></figure><p id="021c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">典型地，在分类任务中，域的维度比共域的维度高得多，然后共域成为高度语义的空间</p><p id="bfda" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">数据集</strong></p><ul class=""><li id="7383" class="ks kt iq jp b jq jr ju jv jy ku kc kv kg kw kk kx ky kz la bi translated">通过对未知分布执行IID采样获得的输入-输出对的集合(全球相关)</li></ul><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/ff3748ad6c23a55c7e30a22b672fbc3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/1*G5i_hPEmyTSNkCS8j-wDoA.gif"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Training Set of N Elements</figcaption></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/d31ee386d049b248a62733f1bd1c2052.png" data-original-src="https://miro.medium.com/v2/resize:fit:38/1*sVXT-6525oMeRB21GPkEKQ.gif"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Latent World Related Distribution sampling which the Dataset is built</figcaption></figure><p id="f03d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">损失函数</strong></p><p id="d9d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用基础真值为分类结果提供分数的函数，其中零是最高分数(即完美分类)</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/1444c77720d423968c85c1869847c0d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/1*6Mn0aMIc_t3Kdr1qZcRgWQ.gif"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">It compares the Classification Result with the Expected Result from the GT and assigns a score where 0 is perfect classification and it can be upper bounded to some L or go to +\infty</figcaption></figure><p id="f5c5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果这在任何地方都是可微分的(典型地，分类器是可微分的)，那么可以使用基于梯度的方法来微调分类器参数，以便最小化训练集(可以是数据集的子集)上的损失</p><p id="76c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">学习机</strong></p><p id="e857" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">学习机是以数据驱动的方式执行给定模型的参数拟合(其选择是元参数)的算法，即依赖于训练集、要最小化的损失函数和训练/优化策略</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/97363c296fbeed91eab1eb9974925686.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/1*PR96GUVLHNRTACEA0ZWM-Q.gif"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Learning Machine performs the Parameters Fitting of the given parametric model according to the Dataset and the Loss Function</figcaption></figure></div></div>    
</body>
</html>