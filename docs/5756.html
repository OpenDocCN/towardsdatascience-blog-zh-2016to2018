<html>
<head>
<title>From Norm to Orthogonality: Fundamental Mathematics for Machine Learning with Intuitive Examples Part 2/3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从范数到正交性:带有直观例子的机器学习基础数学第 2/3 部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/from-norm-to-orthogonality-fundamental-mathematics-for-machine-learning-with-intuitive-examples-57bb898e69f2?source=collection_archive---------9-----------------------#2018-11-07">https://towardsdatascience.com/from-norm-to-orthogonality-fundamental-mathematics-for-machine-learning-with-intuitive-examples-57bb898e69f2?source=collection_archive---------9-----------------------#2018-11-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="a908" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了理解机器学习算法的数学，特别是深度学习算法，从基础到更高级建立数学概念是必不可少的。不幸的是，数学理论在许多情况下太难/抽象/枯燥，难以消化。想象你正在吃一个比萨饼，喝一杯可乐总是更容易和更有趣。</p><p id="007e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这篇文章的目的是<strong class="js iu">为基础数学理论提供直观的例子</strong>使学习体验更加愉快和难忘，那就是鸡翅配啤酒，薯条配番茄酱，里脊配葡萄酒。</p><p id="183f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">包含 3 门课程的机器学习基础数学课程组织如下:</p><p id="79e7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://medium.com/@alina.li.zhang/from-scalar-to-tensor-fundamental-mathematics-for-machine-learning-with-intuitive-examples-part-163727dfea8d" rel="noopener"> <strong class="js iu">从标量到张量</strong>:带有直观例子的机器学习基础数学<strong class="js iu">第 1/3 部分</strong> </a></p><ul class=""><li id="e43f" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated">什么是标量、矢量、矩阵和张量？</li><li id="fff2" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated">标量、向量和矩阵之间的加法</li><li id="2dfe" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated">标量、向量和矩阵之间的乘法</li><li id="1002" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated">单位矩阵和逆矩阵</li><li id="5453" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated">对角矩阵和对称矩阵</li></ul><p id="a6c6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">从范数到正交</strong>:带有直观示例的机器学习基础数学<strong class="js iu">第 2/3 部分</strong></p><ul class=""><li id="98e7" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated">向量的 1-范数，2-范数，最大范数</li><li id="31f2" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated">正交和标准正交向量</li><li id="2a5e" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated">正交矩阵</li></ul><p id="0a4c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae ko" href="https://medium.com/@alina.li.zhang/from-eigendecomposition-to-determinant-fundamental-mathematics-for-machine-learning-with-1b6b449a82c6" rel="noopener"> <strong class="js iu">从特征分解到行列式</strong>:带有直观例子的机器学习基础数学<strong class="js iu">第 3/3 部分</strong> </a></p><ul class=""><li id="268d" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated">矩阵的特征分解:特征值和特征向量</li><li id="fd39" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated">跟踪运算符</li><li id="e8f9" class="kp kq it js b jt ky jx kz kb la kf lb kj lc kn ku kv kw kx bi translated">方阵的行列式</li></ul><p id="6e94" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在本文中，我们将通过直观的例子，从范数到正交性讨论第 2/3 部分<strong class="js iu">。</strong></p><h2 id="2b9c" class="ld le it bd lf lg lh dn li lj lk dp ll kb lm ln lo kf lp lq lr kj ls lt lu lv bi translated">向量的 1-范数，2-范数，最大范数</h2><p id="d4f5" class="pw-post-body-paragraph jq jr it js b jt lw jv jw jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn im bi translated">如何度量一个矢量的大小？一种方法是使用范数函数:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/67d6f1cbedd5c392b7f35d9b2d4aea5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*0Zu_XVcIo9qDnzVA6xyE4A.png"/></div></figure><ul class=""><li id="4619" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated">1-范数:在机器学习应用中，当 0 和非 0 元素之间的差异很重要时，通常使用 1-范数。</li></ul><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/42b1a2331e40afc12a9fe217ff6dfc55.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/format:webp/1*Pz4NtkR9hXq4fu0Mg_b1HA.png"/></div></figure><p id="61d1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">例如，向量<strong class="js iu"> <em class="mk"> v </em> </strong>的 1 范数可以计算为:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ml"><img src="../Images/3a9668b94baf057fc8854981ed464b27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D2ddgOOyA5TFBiNrjgXzhQ.png"/></div></div></figure><ul class=""><li id="9006" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated"><strong class="js iu">2-范数</strong>:通称欧氏范数，是原点到向量<strong class="js iu"> <em class="mk"> x </em> </strong>所标识的点的欧氏距离。</li></ul><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/983c3932620d43677317b6fe120fb43d.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*Yramiw3hRecDkN87lEM7iA.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">Photo credit to <a class="ae ko" href="https://en.wikipedia.org/wiki/Euclidean_distance" rel="noopener ugc nofollow" target="_blank">wikipedia</a></figcaption></figure><p id="adee" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通常使用平方 2-范数而不是 2-范数本身来度量向量的大小。原因是平方 2 范数可以计算为:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/280157ae066f66c17dd693ca159b3150.png" data-original-src="https://miro.medium.com/v2/resize:fit:132/format:webp/1*TG9zKBH_ab0iwP4vmkkFcw.png"/></div></figure><p id="0dd6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这比计算 2-范数本身更方便。下面的例子说明了如何计算向量<strong class="js iu"> <em class="mk"> v: </em> </strong>的 2-范数</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mw"><img src="../Images/8f96bd6d10f8e06b520b6bde347a0c57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M-Nb0xvG_P_TJBb0GlPE1w.png"/></div></div></figure><ul class=""><li id="1eb4" class="kp kq it js b jt ju jx jy kb kr kf ks kj kt kn ku kv kw kx bi translated"><strong class="js iu">最大范数</strong>:向量中元素的最大绝对值，可以写成:</li></ul><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/e90cca17642a12fcfb22cfbe8c55aac5.png" data-original-src="https://miro.medium.com/v2/resize:fit:426/format:webp/1*x5iqiil6pZWETrQP3VBa3Q.png"/></div></figure><p id="0ec2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面的例子显示了向量<strong class="js iu"> <em class="mk"> v: </em> </strong>的最大范数的计算</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi my"><img src="../Images/efe9a3742a4b74a597194609eac57913.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*VQQvOZpe-z8kYZeyyS0CVQ.png"/></div></figure><h2 id="1597" class="ld le it bd lf lg lh dn li lj lk dp ll kb lm ln lo kf lp lq lr kj ls lt lu lv bi translated">正交和标准正交向量</h2><p id="e29b" class="pw-post-body-paragraph jq jr it js b jt lw jv jw jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn im bi translated">向量<strong class="js iu"> <em class="mk"> u </em> </strong>和向量<strong class="js iu"> <em class="mk"> v </em> </strong>彼此正交<strong class="js iu">当且仅当它们的点积为 0:</strong></p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/b6d51adf1dfbf4a796af38d61cae1330.png" data-original-src="https://miro.medium.com/v2/resize:fit:248/format:webp/1*410L6LOIWv41Iwp_JAGJYA.png"/></div></figure><p id="3fbd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">例如，在三维欧几里得空间中，</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi na"><img src="../Images/6f5a3ee391cfb632b8fac823149d9432.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*spvev1IIhmImT_yFw7LKFg.png"/></div></div></figure><p id="54d7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在几何学中，两个正交向量在欧几里得空间中相互垂直:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/ca5effcffc10499cb60b83db7ac1f071.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/0*XFgw4j6mfImcgCVB.png"/></div></figure><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/00dbc7b1b6b1e773df66ebe15315ceba.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*JtS66Lamfa_28AMw5gfZQw.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">Photo credit to <a class="ae ko" href="https://ubisafe.org/orthogonal-vector.html" rel="noopener ugc nofollow" target="_blank">ubisafe</a></figcaption></figure><p id="8db1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">向量 u 和向量 v 是一对<strong class="js iu">正交的</strong>向量的意思是:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/40aa4adbdef62020235be9f8f785c6d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*NXeFpHn24KOxXo5yo7DdUA.png"/></div></figure><p id="b9e2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它可以扩展到 3-D 欧几里得空间中的下列方程:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/aefd1b0b3d5d99c3d1d121d5e5c2ba6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*DJdfWcT-KRNp3IyfVLSK9g.png"/></div></figure><p id="61fc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">举个例子，</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi nf"><img src="../Images/55839688e62acec7f6963dc5bfc91a7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jpg_n0y-nzU6wuTNyRGArQ.png"/></div></div></figure><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/3d39baca3b0b39995c84eeef36e6460d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*sVhKbnWpC27HRP42xr_dpg.png"/></div></figure><p id="703e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，我们说，向量<strong class="js iu"> <em class="mk"> u </em> </strong>和向量<strong class="js iu"> <em class="mk"> v </em> </strong>是正交的。</p><h2 id="74f7" class="ld le it bd lf lg lh dn li lj lk dp ll kb lm ln lo kf lp lq lr kj ls lt lu lv bi translated">正交矩阵</h2><p id="864c" class="pw-post-body-paragraph jq jr it js b jt lw jv jw jx lx jz ka kb ly kd ke kf lz kh ki kj ma kl km kn im bi translated">正交矩阵是行和列正交的正方形矩阵:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/608e22beaea04626532f7fdc8aa06f37.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*5eQ3CGvobbPn9hlDmCL_Uw.png"/></div></figure><p id="7e76" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">例如，以下矩阵是正交的，因为:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi ni"><img src="../Images/087b20144d810327f0c35bd5d89b077f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t5mq-k4kcaXGA07fIT3lIQ.png"/></div></div></figure><p id="5c4a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这意味着如果一个矩阵的转置等于其逆矩阵，则该矩阵是正交的:</p><figure class="mc md me mf gt mg gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/48c740bfd40c62c2a18c5be1b096ea80.png" data-original-src="https://miro.medium.com/v2/resize:fit:280/format:webp/1*TIzzkQYm8JyKvu_bwtErWA.png"/></div></figure><p id="ff00" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，正交矩阵是机器学习中感兴趣的，因为矩阵的逆的计算非常便宜。我们需要注意的是，正交矩阵中的行和列不仅是正交的，而且是正交的。</p><p id="e503" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">恭喜你！你已经用直观的例子完成了机器学习基础数学的三分之二。你能做到的！</p><h2 id="b65f" class="ld le it bd lf lg lh dn li lj lk dp ll kb lm ln lo kf lp lq lr kj ls lt lu lv bi translated">下一步:<a class="ae ko" href="https://medium.com/@alina.li.zhang/from-eigendecomposition-to-determinant-fundamental-mathematics-for-machine-learning-with-1b6b449a82c6" rel="noopener"> <strong class="ak">从特征分解到行列式</strong>:带有直观例子的机器学习基础数学<strong class="ak">第 3/3 部分</strong> </a></h2></div></div>    
</body>
</html>