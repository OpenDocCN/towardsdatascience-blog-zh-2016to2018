<html>
<head>
<title>“A CASE OF MULTI-LABEL IMAGE CLASSIFICATION”</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">“多标签图像分类的一个例子”</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889?source=collection_archive---------6-----------------------#2018-09-23">https://towardsdatascience.com/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889?source=collection_archive---------6-----------------------#2018-09-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ece7" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">建立一个最先进的多标签图像分类器。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/1b6583dbf598aafccbe1b26272f5f957.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*1x5-I84jwNmRhy8AsSmQ4A.jpeg"/></div></figure><p id="7934" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">欢迎来到第三集<a class="ae lj" href="http://www.fast.ai/" rel="noopener ugc nofollow" target="_blank"> Fastdotai </a>，在这里我们将接手<strong class="kp ir">多标签分类</strong>的案例。在我们开始之前，我想感谢<a class="ae lj" href="https://twitter.com/jeremyphoward" rel="noopener ugc nofollow" target="_blank"> <strong class="kp ir">【杰瑞米·霍华德】</strong> </a>和<a class="ae lj" href="https://twitter.com/math_rachel" rel="noopener ugc nofollow" target="_blank"> <strong class="kp ir">雷切尔·托马斯</strong> </a>为民主化人工智能所做的努力。</p><p id="43bc" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了充分利用这个博客系列，请按照以下顺序随意探索这个系列的第一部分</p><ol class=""><li id="4bf2" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-1-e9cc80d81a9d">狗 Vs 猫图像分类</a></li><li id="1db8" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60">犬种图像分类</a></li><li id="4884" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889">多标签图像分类</a></li><li id="a07b" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-4-1-time-series-analysis-a23217418bf1">使用神经网络的时间序列分析</a></li><li id="be6b" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/nlp-sentiment-analysis-on-imdb-movie-dataset-fb0c4d346d23" rel="noopener">IMDB 电影数据集上的自然语言处理情感分析</a></li><li id="4a4e" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-1-movie-recommendation-using-fastai-a53ed8e41269">电影推荐系统的基础</a></li><li id="4f8b" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-2-collaborative-filtering-from-scratch-1877640f514a">从零开始协同过滤</a></li><li id="0674" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-3-collaborative-filtering-using-neural-network-48e49d7f9b36">使用神经网络的协同过滤</a></li><li id="61f4" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/fast-ai-season-1-episode-6-1-write-philosophy-like-nietzsche-using-rnn-8fe70cfb923c" rel="noopener">像尼采一样写哲学</a></li><li id="2e57" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/fast-ai-season-1-episode-7-1-performance-of-different-neural-networks-on-cifar-10-dataset-c6559595b529" rel="noopener">不同神经网络在 Cifar-10 数据集上的性能</a></li><li id="5d24" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://medium.com/hackernoon/single-object-detection-e65a537a1c31" rel="noopener">检测图像中最大物体的 ML 模型 Part-1 </a></li><li id="94d1" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://medium.com/hackernoon/single-object-detection-part-2-2deafc911ce7" rel="noopener"> ML 模型检测图像中最大的物体 Part-2 </a></li></ol><p id="ef40" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">没看过前几集的，请点击这里查看<a class="ae lj" href="https://medium.com/@GeneAshis/fast-ai-season-1-episode-2-1-e9cc80d81a9d" rel="noopener"> 2.1 </a>、<a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60"> 2.2 </a>。</p><p id="07fe" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">今天我们将处理<strong class="kp ir">多标签分类</strong>，这里我们有多个标签作为目标变量。在深入<strong class="kp ir">多标签分类</strong>之前，我们先了解:-</p><blockquote class="ly lz ma"><p id="1be8" class="kn ko mb kp b kq kr jr ks kt ku ju kv mc kx ky kz md lb lc ld me lf lg lh li ij bi translated"><strong class="kp ir">CNN(卷积神经网络)是如何工作的？</strong></p></blockquote><p id="8e6f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">CNN 架构有不同的部分。让我们详细地讨论它们，之后，我们将把它们结合起来，详细地讨论 CNN 的架构。所以让我们从输入开始，也就是图像</p><ol class=""><li id="4d79" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li lp lq lr ls bi translated"><strong class="kp ir">图像:- </strong></li></ol><p id="b122" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">最初，我们有一个图像。图像实际上是一个数字网格。看起来像这张图片</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/4eb491b5f39afe2eebc6644daa3e0773.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*DVsRO69AoII_n8sxPeKHyA.png"/></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk">This is how a gray-scale image representing # 7 looks like . The pixel values has been standardized between 0 and 1.</figcaption></figure><p id="6a68" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> 2。内核/过滤器:- </strong></p><p id="2b2b" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在图像的顶部，我们有一个内核。在这种情况下，核/过滤器是 3d 张量的 3×3 切片，有助于我们执行卷积。</p><p id="9d32" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这个 3 乘 3 切片内核在图像上滑动，并产生特征图。</p><p id="e93c" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">3.<strong class="kp ir">激活:- </strong></p><p id="136c" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">特征图由激活组成。激活是一个数字，计算方法如下</p><ul class=""><li id="6499" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mk lq lr ls bi translated">取相同维度的输入切片。</li><li id="7bc3" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">确保您的内核与输入片段的维度相同。</li><li id="6cd6" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">将步骤 1 中得到的输入与步骤 2 中得到的内核进行逐元素相乘</li><li id="60e6" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">然后总结一下。</li><li id="50ab" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">它产生一个数字，比如“N”。</li><li id="2a9a" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">在此基础上应用 ReLu(校正线性单位)激活功能。基本上 ReLu 就是<code class="fe ml mm mn mo b">max(0,N).</code>的意思</li><li id="f51d" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">我们得到的数字被称为“激活”。</li></ul><p id="a5a5" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">4.<strong class="kp ir">张量:- </strong></p><p id="19f9" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">假设我们的网络经过了训练，在训练结束时，它已经创建了一个卷积滤波器，其核值已经学会识别垂直和水平边缘。Pytorch 不会将这些过滤器值保存为两个不同的 9 位数组。它将值存储为张量。张量是一个高维数组。张量有一个额外的轴，可以帮助我们把这些过滤器堆叠在一起。</p><p id="20d5" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> 5。隐藏层:- </strong></p><p id="d451" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">除了输入层和输出层之外的所有层都称为隐藏层。构成激活图的层就是这样一个隐藏层。它一般被命名为<strong class="kp ir"> Conv1 </strong>和<strong class="kp ir"> Conv2 和</strong>是核卷积的结果。</p><p id="7a4a" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">然后我们得到了一个非重叠的 2 乘 2 最大池。它通过高度和宽度将分辨率减半。一般命名为<strong class="kp ir"> Maxpool </strong>。</p><p id="75a3" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">除此之外，我们还有<strong class="kp ir">密集层/全连接层</strong>。对于 max-pool 层中出现的每一个激活，我们创建一个权重，对应于被称为<strong class="kp ir">的全连接层。</strong>然后对每一个权重的每一次激活做一个和积。这将产生一个单一的数字。</p><p id="b995" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">使用额外全连接层的缺点</strong> :-这会导致过度拟合，也会降低处理速度。</p><p id="cc03" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">注意:-内核的尺寸和图像/激活图的切片的尺寸应该总是相同的。对于多通道输入，创建多通道内核。这有助于更高维的线性组合。</strong></p><p id="6ea3" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">内核值是如何更新的？</strong></p><p id="02eb" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">基本上，我们从一些随机核值开始，然后在训练期间使用随机梯度下降来更新核值，以便使核中的值有意义。以这种方式，在几个时期之后，我们到达初始层内核正在检测边缘、角的位置，并且随后更高层内核正在学习识别更重要的特征。</p><blockquote class="ly lz ma"><p id="5c66" class="kn ko mb kp b kq kr jr ks kt ku ju kv mc kx ky kz md lb lc ld me lf lg lh li ij bi translated"><strong class="kp ir">我对使用 KERAS 对 MNIST 数据集进行分类的简单 CNN 的看法</strong></p></blockquote><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><blockquote class="ly lz ma"><p id="8aec" class="kn ko mb kp b kq kr jr ks kt ku ju kv mc kx ky kz md lb lc ld me lf lg lh li ij bi translated"><strong class="kp ir">代表代码的简图(概括地说是 CNN)</strong></p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi mr"><img src="../Images/3c9305f649fde191251b7118f18092ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2lzNT1eurQFozUzcHSp-xA.png"/></div></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk">CNN in detail</figcaption></figure><p id="e049" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">所以我们从(28，28，1)输入图像开始。</p><ol class=""><li id="637a" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li lp lq lr ls bi translated">我们使用过滤器/内核来减少或增加激活图的深度/宽度，并减少激活图的高度和宽度。当我们用 32 个维数为(5，5)的核卷积维数为(28，28，1)的输入图像时，我们得到(24，24，32)的输出。</li><li id="8ef7" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated">使用{(n-f+1)，(n-f+1)，(#Kernels)}计算输出维度，其中</li></ol><ul class=""><li id="36a2" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mk lq lr ls bi translated">n=图像尺寸</li><li id="3608" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">f =内核维数</li><li id="808e" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">#内核数=内核数</li><li id="e4b4" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">所以我们得到{(28–3+1)，(28–3+1)，(#Kernels)}=(24，24，32)</li></ul><p id="32a0" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> 3。</strong>我们在深度学习中使用非线性函数/ReLU 激活函数。但是为什么呢？看看下面这个 Quora 帖子。</p><div class="mw mx gp gr my mz"><a href="https://www.quora.com/Why-does-deep-learning-architectures-only-use-the-non-linear-activation-function-in-the-hidden-layers" rel="noopener  ugc nofollow" target="_blank"><div class="na ab fo"><div class="nb ab nc cl cj nd"><h2 class="bd ir gy z fp ne fr fs nf fu fw ip bi translated">为什么深度学习/架构只使用隐藏的非线性激活函数…</h2><div class="ng l"><h3 class="bd b gy z fp ne fr fs nf fu fw dk translated">回答(第 1 题，共 9 题):“为什么使用非线性激活函数？”在没有非线性激活函数的情况下，神经网络…</h3></div><div class="nh l"><p class="bd b dl z fp ne fr fs nf fu fw dk translated">www.quora.com</p></div></div><div class="ni l"><div class="nj l nk nl nm ni nn kl mz"/></div></div></a></div><p id="89c8" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> 4。</strong>发帖称，我们使用最大池将内核的高度和宽度减少了 2 倍。</p><ul class=""><li id="f18a" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mk lq lr ls bi translated">因此，激活图(24，24，32)减少到(12，12，32)。</li></ul><p id="539d" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> 5。</strong>这个(12，12，32)激活图与 32 个维数为(3，3)的核以及现在的输出维数按照公式{(n-f+1)，(n-f+1)，(#核)} = {(12–3+1)，(12–3+1)，32}=(10，10，32)进行卷积。</p><p id="d1f1" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">6。这个(10，10，32)激活图与 10 个具有维度(10，10)的核进行卷积，现在输出维度按照公式</p><p id="6ec8" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">{(n-f+1)，(n-f+1)，(# Kernels)} = {(10–10+1)，(10–10+1)，10}=(1，1，10)。</p><p id="bb3f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> 7。</strong>最后，我们已经达到了激活的(1，1，10)维。这是倒数第二层。它吐出 10 个随机数。</p><p id="23f7" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> 8。</strong>然后我们在此基础上使用 softmax 激活将数字转换成概率。</p><p id="b642" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> 9。</strong><a class="ae lj" href="https://jamesmccaffrey.files.wordpress.com/2016/03/softmaxequation.jpg?w=640" rel="noopener ugc nofollow" target="_blank"><strong class="kp ir">soft max Activation</strong></a>返回范围从(0，1，2，3，…9)的 10 个数字的概率值，并且它还倾向于特别强烈地拾取一个事物。Softmax 只出现在最后一层。这些将是我们的<strong class="kp ir">预测值</strong>。因为这些是概率值，所以结果是 1。我们将把这些预测值与我们的目标值进行比较。请检查上述附加代码(keras.ipynb)的第 9 行，以了解目标值如何保存在<strong class="kp ir">一个热编码</strong>表单中。<strong class="kp ir">数字 5 </strong>表示如下。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/f13ebfcfd12f7c8df31785358807e67c.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*6g2DFRpUY6cejVMK2ZPqkA.png"/></div></figure><p id="7f12" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> 10。</strong>之后，我们将使用<strong class="kp ir">损失函数</strong>尽量减少 10 个预测值和 10 个目标值之间的损失。为了计算损失函数，我们使用<strong class="kp ir">梯度下降的概念</strong>。使用梯度下降保持更新参数/内核值。</p><p id="c7f8" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">11。最后，考虑最小损耗点对应的参数。并且在对测试数据集进行预测期间使用这些参数/核值。这是<strong class="kp ir">单一标签分类</strong>的概念，如狗对猫或狗的品种分类。现在我们来看一个<strong class="kp ir">多标签分类</strong>的案例。</p><p id="5e1b" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">多标签分类的最好例子是 kaggle 竞赛<a class="ae lj" href="https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/data" rel="noopener ugc nofollow" target="_blank">星球:从太空了解亚马逊</a>。所以让我们分两步来做。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np mq l"/></div></figure><p id="2e56" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi nq translated"><span class="l nr ns nt bm nu nv nw nx ny di"> 1。</span> <strong class="kp ir">下载数据，导入所需的包。</strong></p><p id="3565" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">使用以下命令<strong class="kp ir">下载</strong>数据</p><pre class="kg kh ki kj gt nz mo oa ob aw oc bi"><span id="92c0" class="od oe iq mo b gy of og l oh oi">! pip install kaggle <br/>import kaggle<br/>! kaggle competitions download -c planet-understanding-the-amazon-from-space<br/>!pip install fastai==0.7.0<br/>!pip install torchtext==0.2.3</span><span id="d55e" class="od oe iq mo b gy oj og l oh oi">!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl <br/>!pip3 install torchvision</span></pre><p id="6e9e" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">导入包并检查目录中是否存在这些文件</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi ok"><img src="../Images/b9feea634bdeaf10b22e08d44e89504b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bq10fDKbJ1KJ3gMYjCNI0A.png"/></div></div></figure><p id="93fa" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><code class="fe ml mm mn mo b">train_v2.csv </code> file 具有训练数据集中存在的文件的名称以及对应于它们的<code class="fe ml mm mn mo b">labels </code>。</p><p id="a9f6" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi nq translated"><span class="l nr ns nt bm nu nv nw nx ny di"> 2。</span> <strong class="kp ir">用熊猫熟悉数据</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ol mq l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/ef930a097373087515833cba30453fa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*s6MXpz3RbvCdAh2Acv61ow.png"/></div></figure><blockquote class="ly lz ma"><p id="7896" class="kn ko mb kp b kq kr jr ks kt ku ju kv mc kx ky kz md lb lc ld me lf lg lh li ij bi translated"><strong class="kp ir">单标签和多标签分类的区别</strong></p></blockquote><p id="b11c" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在单一标签分类中，图像是猫或狗，如下图所示</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/a7c6bb6fe897e7dfa14662721637d478.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*ZhNqnZwP78mBHwlk5bUzMg.png"/></div></figure><p id="c5fd" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">让我们检查多标签分类:-</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/f1b237f7678a26f1ce084c2d654b5292.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*of9-yDLgaUq206_sOdn1dA.png"/></div></figure><p id="3df4" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">正如我们可以看到的输出，在多标签分类的情况下，图像被分为两部分</p><ul class=""><li id="2da5" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mk lq lr ls bi translated"><strong class="kp ir">天气</strong>——资料中提到的天气有很多种。从中我们可以看到上面快照中的<strong class="kp ir">霾</strong>和<strong class="kp ir">晴</strong>。</li><li id="7015" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated"><strong class="kp ir">要素</strong>—上图中的要素列表为<strong class="kp ir">主要、农业、水。</strong></li></ul><p id="3490" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">原生</strong>代表原生雨林。</p><p id="d93d" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">农业</strong>代表用于农业用地的空地。</p><p id="e5cd" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">水</strong>代表河流或湖泊。</p><p id="8677" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">基本上，在多标签分类中，每个图像属于一个或多个类别。在上面的例子中，第一幅图像属于两类:<strong class="kp ir">霾</strong>和<strong class="kp ir">原生</strong>雨林。第二幅图像属于 4 类:<strong class="kp ir">初级</strong>、<strong class="kp ir">清晰、农业</strong>和<strong class="kp ir">水</strong>。Softmax 不是一个很好的分类这些图像的激活函数，因为它倾向于将一个图像分为一个类别，而不是多个类别。因此，Softmax 适用于单标签分类，不适用于多标签分类。</p><p id="2a59" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> Fastai 在</strong> <code class="fe ml mm mn mo b"><strong class="kp ir">train_v2.csv </strong></code> <strong class="kp ir">文件中查找标签，如果发现任何样品有一个以上的标签，它会自动切换到多标签模式。</strong></p><p id="3bd6" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如<a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60">第 2.2 集</a>所述，我们创建了一个占训练数据集 20%的验证数据集。下述命令用于创建验证数据集:-</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="0946" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi nq translated"><span class="l nr ns nt bm nu nv nw nx ny di"> 3。</span> <strong class="kp ir">获取 FASTAI 格式的数据</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="12af" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这些步骤与我们在前两集所做的相同。<code class="fe ml mm mn mo b">get_data(sz)</code>有两行代码:-</p><ul class=""><li id="d279" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mk lq lr ls bi translated">tfms_from_model 有助于数据扩充。<code class="fe ml mm mn mo b">aug_tfms=transforms_up_down</code>表示垂直翻转图像。它实际上做的不止这些。正方形图像实际上有 8 种可能的对称性，这意味着它可以旋转 0、90、180、270 度，并且可以翻转其中的每一种。这是我们对正方形对称性所能做的一切的完整列举。它被称为<code class="fe ml mm mn mo b">dihedral </code>集团。这段代码将完成完整的 8 组翻转，即<code class="fe ml mm mn mo b">dihedral </code>组旋转和翻转加上小的 10 度旋转，一点缩放，一点对比度和亮度调整。要了解更多信息，请查看<code class="fe ml mm mn mo b">fastai </code>文件夹中的<code class="fe ml mm mn mo b">transforms.py</code>文件。下面附上了<code class="fe ml mm mn mo b">transforms.py</code>中执行二面角旋转的片段。请检查我们在<code class="fe ml mm mn mo b">transforms.py</code>文件中应用的其他转换。</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><ul class=""><li id="2ca6" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mk lq lr ls bi translated"><strong class="kp ir">参数</strong> <code class="fe ml mm mn mo b"><strong class="kp ir">ImageClassfierData.from_csv(...)</strong></code> <strong class="kp ir">为:</strong></li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="0114" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">它有助于按照 fastai 格式读取文件。</p><ul class=""><li id="0183" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mk lq lr ls bi translated"><code class="fe ml mm mn mo b">PATH</code>是数据的根路径(用于存储训练模型、预计算值等)。还包含所有的数据。</li><li id="ffe9" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated"><code class="fe ml mm mn mo b">'train'</code> —包含训练数据的文件夹。</li><li id="fc0b" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated"><code class="fe ml mm mn mo b">labels.csv</code>文件有行星图像的标签。</li><li id="59e1" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated"><code class="fe ml mm mn mo b">val_idxs </code>有验证数据。它指示已经放入验证数据集中的 labels.csv 中的索引号。</li><li id="6a57" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated"><code class="fe ml mm mn mo b">test_name='test' </code>是<code class="fe ml mm mn mo b">test </code>数据集。</li><li id="12fb" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">文件名实际上在末尾有一个<code class="fe ml mm mn mo b">.jpg</code>，在<code class="fe ml mm mn mo b">labels.csv</code>文件中没有提到，因此我们有<code class="fe ml mm mn mo b">suffix=’.jpg’</code>。这将把<code class="fe ml mm mn mo b">.jpg</code>添加到文件名的末尾。</li><li id="8f0f" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated"><code class="fe ml mm mn mo b">tfms </code>是我们要申请的数据增强的转换。</li><li id="0fec" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated"><code class="fe ml mm mn mo b">bs</code>= 64 张图像的批量大小。</li></ul><p id="bca7" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">py torch 中数据加载器与数据集的概念:- </strong></p><p id="57ce" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们在之前的<a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-1-e9cc80d81a9d">剧集</a>中遇到的数据集将返回单个图像，而数据加载器将返回一小批图像。我们只能得到下一个小批量。为了将数据加载器转换成迭代器，我们使用了一个标准的 python 函数 iter。那是一个迭代器。要获取下一个迷你批次，请将 iter 传递给 next。它将返回下一批图像和标签。下文对此进行了描述</p><pre class="kg kh ki kj gt nz mo oa ob aw oc bi"><span id="1cac" class="od oe iq mo b gy of og l oh oi">x,y = next(iter(data.val_dl))<br/>y</span></pre><p id="6318" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上述命令是一个<strong class="kp ir">验证集数据加载器</strong>，将返回一个<strong class="kp ir">图像和标签的小批量</strong>。<code class="fe ml mm mn mo b">y</code>标签给出了下面的输出</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/df63f415980ceae1008a81d5ad895886.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*77vR1s33NTD0UjdY3hzW6A.png"/></div></figure><p id="b814" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">正如我们所看到的，在这 64 个样品的小批量中有 17 个标签。在上面的<code class="fe ml mm mn mo b">get_data(bs)</code>函数中已经明确提到了<code class="fe ml mm mn mo b">bs=64 </code>。要理解这些热编码标签的含义，请查看下面的代码</p><pre class="kg kh ki kj gt nz mo oa ob aw oc bi"><span id="55a4" class="od oe iq mo b gy of og l oh oi">list(zip(data.classes, y[0]))</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/0f4fbd2ae5a6f7f80be014ef1a75e09a.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*F1f86z7ib98y9o25L-_a-A.png"/></div></figure><p id="bc22" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">data.classes 具有实际的标签名称，而<code class="fe ml mm mn mo b">y[0]</code>给出了特定样本所属的所有标签的名称。如上所示，输出表示第一幅图像具有标签<strong class="kp ir">农业、清洁、初级</strong>和<strong class="kp ir">水</strong>。标签的一个热编码表示已经在下面的图像中被表示。标签的一次性编码由 Pytorch 框架在内部处理。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi or"><img src="../Images/1fc1a96fa54b96431927eaf493f1bb8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yjq0hG-qmCL4Sqe0NQ4BKQ.png"/></div></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk">Data Representation</figcaption></figure><p id="820c" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这个标签的热编码表示是<strong class="kp ir">实际</strong>值。神经网络提取 17 个这样的值(在这种情况下),这些值被称为<strong class="kp ir">预测值</strong>。我们使用损失函数和梯度下降的概念来最小化<strong class="kp ir">实际</strong>和<strong class="kp ir">预测</strong>值之间的误差。</p><p id="5fc9" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在某些情况下，图像不是那么清晰。在这种情况下，为了掌握图像的所有特征，可以使用 1.5/1.6/1.7 的倍增系数来增加图像的亮度，如下所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi os"><img src="../Images/95559b7aa65ae2ccc892f4390d75bded.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TapxhrCDE4oUwBTwQK9Z4w.png"/></div></div></figure><p id="2aef" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">使用这些行星数据的最大好处是它与 ImageNet 不同。在现实世界中处理数据时，我们没有类似于 ImageNet 数据集的数据。</p><p id="94d5" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这里，我们首先将数据大小调整为(64，64)而不是原始大小(256，256)。我们不会在狗与猫分类的情况下开始这么小，因为预训练的 resnet 网络开始时几乎完美，所以如果我们将所有东西的大小调整为(64，64)并重新训练权重，它将破坏先前预训练为好的权重。大多数 ImageNet 模型是在(224，224)或(299，299)之上训练的。我们开始这么小的主要原因是 ImageNet 图像与这个星球竞赛数据集不相似。已经在 ImageNet 数据集上训练的 Resnet 网络的主要收获是可以检测边缘、拐角、纹理和重复图案的初始层。</p><p id="cd1b" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">它是这样工作的</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="bad6" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">获取所需大小的数据，即(64，64)。</p><pre class="kg kh ki kj gt nz mo oa ob aw oc bi"><span id="b2d6" class="od oe iq mo b gy of og l oh oi">sz=64<br/>data = get_data(sz)<br/>data = data.resize(int(sz*1.3), '/tmp')</span></pre><p id="cb73" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi nq translated"><span class="l nr ns nt bm nu nv nw nx ny di"> 4。</span> <strong class="kp ir">设置神经网络，寻找最佳学习率</strong></p><pre class="kg kh ki kj gt nz mo oa ob aw oc bi"><span id="e1a9" class="od oe iq mo b gy of og l oh oi">from planet import f2</span><span id="eb6e" class="od oe iq mo b gy oj og l oh oi">metrics=[f2]<br/>f_model = resnet34</span><span id="edc8" class="od oe iq mo b gy oj og l oh oi">learn = ConvLearner.pretrained(f_model, data, metrics=metrics)<br/></span></pre><p id="e28a" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">f2 指标将在这篇博文的后面讨论。此外，在这个模型中，由于没有提到<code class="fe ml mm mn mo b">precompute=True</code>，因此默认情况下它采用<code class="fe ml mm mn mo b">precompute=False</code>。要了解这一点，点击<code class="fe ml mm mn mo b">shift+Tab</code>，它将显示所有参数及其默认值。在这个时间点当<code class="fe ml mm mn mo b">precompute=False </code>，</p><ul class=""><li id="69ba" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mk lq lr ls bi translated">我们的数据扩充是在的<strong class="kp ir">。</strong></li><li id="bb94" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">倒数第二层之前的所有层都被<strong class="kp ir">冻结</strong>。</li><li id="de59" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">在倒数第二层之后，我们将<strong class="kp ir">额外完全连接的</strong> <strong class="kp ir">层</strong>附加到最后，然后我们就有了最终输出。</li></ul><p id="441e" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在，让我们来看看最好的学习率发现者。</p><pre class="kg kh ki kj gt nz mo oa ob aw oc bi"><span id="bfcb" class="od oe iq mo b gy of og l oh oi">lrf=learn.lr_find()<br/>learn.sched.plot()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/ceb3c3866c116df1c05846109713612f.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*CVne8DFvlfBdNj1qXzbaQg.png"/></div></figure><p id="97f6" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">正如我们在<strong class="kp ir">损失</strong> <strong class="kp ir">对学习率</strong>的图表中看到的，最佳学习率可以接近 0.2。怎么会？</p><ul class=""><li id="5f56" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mk lq lr ls bi translated">如前所述，y 轴上的损失在 0.2 处最小，对应的学习率在 x 轴上是 10⁰ =1。</li><li id="65f2" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">正如前面讨论的<a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60"/>，我们可以在损失最小的点之前获得最佳学习率，因此是 0.2。</li></ul><p id="b1a4" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在使用最好的学习率<code class="fe ml mm mn mo b">0.2</code>，让我们训练我们的模型，如下面的代码所示。</p><p id="00d2" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi nq translated"><span class="l nr ns nt bm nu nv nw nx ny di"> 5。</span> <strong class="kp ir">从几个时期的预计算激活中训练最后一层。</strong></p><pre class="kg kh ki kj gt nz mo oa ob aw oc bi"><span id="cdae" class="od oe iq mo b gy of og l oh oi">lr = 0.2<br/>learn.fit(lr, 3, cycle_len=1, cycle_mult=2)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/7d82141ce0a06be0a3407b5af005cd8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*f591p25zegm-BH0kdf1y6g.png"/></div></figure><p id="a4e7" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><code class="fe ml mm mn mo b">Cycle_len </code>和<code class="fe ml mm mn mo b">Cycle_mult </code>的概念在<a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-1-e9cc80d81a9d">第 2.1 集</a>中已经详细讨论过了。到目前为止，我们只训练我们最后连接的额外的完整层。</p><p id="ef60" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">训练所有的层直到最后，</p><ul class=""><li id="8a95" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mk lq lr ls bi translated">为层的子集设置不同的学习率。</li><li id="02f3" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">解冻冻结层。</li><li id="44d2" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">开始训练所有层。</li></ul><p id="2dc3" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">要学习一组不同的特征或告诉学习者需要改变卷积滤波器，只需<code class="fe ml mm mn mo b"><strong class="kp ir">unfreeze </strong></code>所有层。<strong class="kp ir">冻结的</strong>层是其权重没有被训练或更新的层。要了解解冻和冻结图层的工作原理，请查看第 2.1 集。由于行星竞赛中的图像不同于 ImageNet 数据集:-</p><ul class=""><li id="ab4f" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mk lq lr ls bi translated">所以学习率高。</li><li id="7ef9" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">而且前面几层比后面几层需要学的更多。</li></ul><p id="f564" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi nq translated"><span class="l nr ns nt bm nu nv nw nx ny di"> 6。</span>解冻层并训练所有层。</p><pre class="kg kh ki kj gt nz mo oa ob aw oc bi"><span id="b59a" class="od oe iq mo b gy of og l oh oi">lrs = np.array([lr/9,lr/3,lr])<br/>learn.unfreeze()<br/>learn.fit(lrs, 3, cycle_len=1, cycle_mult=2)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/bec10d82f51114764a8a6342f291b3c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*z4DtE6LHQfx8uBdY9g-Xaw.png"/></div></figure><p id="404b" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">下面我们可以看到，在每一个周期后，损失大幅下降。</p><pre class="kg kh ki kj gt nz mo oa ob aw oc bi"><span id="d0f9" class="od oe iq mo b gy of og l oh oi">learn.save(f’{sz}’)<br/>learn.sched.plot_loss()</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/c42c00546115e93f3b6c182387cf6fcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*kVTlj_a7LP4OAdLmCtJDEA.png"/></div></figure><p id="a13b" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi nq translated"><span class="l nr ns nt bm nu nv nw nx ny di"> 7。</span> <strong class="kp ir">改进我们的模型，防止过度拟合:- </strong></p><p id="1502" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">从现在开始，我们将把图像尺寸增加到(128，128)并进一步增加到(256，256)以便</p><ul class=""><li id="7a05" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mk lq lr ls bi translated">减少过度拟合。</li><li id="d75b" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">减小<strong class="kp ir"> trn_loss </strong>和<strong class="kp ir"> val_loss 之间的间隙。</strong></li><li id="af32" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">训练神经网络的早期层(通过<strong class="kp ir">解冻</strong>它们),因为预训练的权重来自 ImageNet 模型，该模型与行星竞争数据集没有太多相似之处。</li></ul><pre class="kg kh ki kj gt nz mo oa ob aw oc bi"><span id="3c3d" class="od oe iq mo b gy of og l oh oi">sz=128<br/>learn.set_data(get_data(sz))<br/>learn.freeze()<br/>learn.fit(lr, 3, cycle_len=1, cycle_mult=2)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/1514763508202050d21a7356b3d71660.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*DaThiJ2SuzPiyu7Bqb-bLQ.png"/></div></figure><pre class="kg kh ki kj gt nz mo oa ob aw oc bi"><span id="6f39" class="od oe iq mo b gy of og l oh oi">learn.unfreeze()<br/>learn.fit(lrs, 3, cycle_len=1, cycle_mult=2)<br/>learn.save(f'{sz}')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/c46865d33f7e7ef646dc440f0bc06441.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*G23iTTrANpXWblsTFg9P5w.png"/></div></figure><pre class="kg kh ki kj gt nz mo oa ob aw oc bi"><span id="3eea" class="od oe iq mo b gy of og l oh oi">sz=256<br/>learn.set_data(get_data(sz))<br/>learn.freeze()<br/>learn.fit(lr, 3, cycle_len=1, cycle_mult=2)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/4fedb6e6b1723c84f01aa665d1c14b60.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*ZKRlklcE-VUTp1-BJEplrw.png"/></div></figure><pre class="kg kh ki kj gt nz mo oa ob aw oc bi"><span id="1260" class="od oe iq mo b gy of og l oh oi">learn.unfreeze()<br/>learn.fit(lrs, 3, cycle_len=1, cycle_mult=2)<br/>learn.save(f'{sz}')</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/58102f1ad1e299aafd937ec8c9cba05f.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*bQoCMXQ7AEyI7zp9hmITJg.png"/></div></figure><p id="b685" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">最后我们做一个 TTA( <a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60"> <strong class="kp ir">测试时间扩增</strong> </a>)来得到。</p><pre class="kg kh ki kj gt nz mo oa ob aw oc bi"><span id="7f1f" class="od oe iq mo b gy of og l oh oi">multi_preds, y = learn.TTA()<br/>preds = np.mean(multi_preds, 0)<br/>f2(preds,y)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/f214d5138753d7680d25532856b0a321.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/format:webp/1*nNW84KcKoHJ5zOOaIGaDlg.png"/></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk">Accuracy</figcaption></figure><p id="7e23" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> <em class="mb">瞧，我们得到一个</em> </strong> <code class="fe ml mm mn mo b"><strong class="kp ir"><em class="mb">93.6%</em></strong></code> <strong class="kp ir"> <em class="mb">的准确度，这对于多标签分类来说太好了。</em> </strong></p><p id="8645" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> <em class="mb">如果你陪我到这一步，给自己一个击掌。</em> </strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="34f9" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> <em class="mb">？？？？？？？？？？有问题的，请举手？？？？？？？？？？</em> </strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np mq l"/></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk">??? ???</figcaption></figure><p id="e2fe" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> Qs 1:-下面的命令中</strong> <code class="fe ml mm mn mo b"><strong class="kp ir">data.resize() </strong></code> <strong class="kp ir">是做什么的？</strong></p><pre class="kg kh ki kj gt nz mo oa ob aw oc bi"><span id="b44c" class="od oe iq mo b gy of og l oh oi">data = data.resize(int(sz*1.3), '/tmp')</span></pre><p id="17c0" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如果初始输入是(1000，1000 ),那么读取该 jpeg 并将其大小调整为(64，64)比训练 convnet 每批所花费的时间要多。resize 的作用是，它表示不会使用任何大于 sz*1.3 的图像。所以仔细检查并创建新的<code class="fe ml mm mn mo b">size=sz*1.3</code>的 jpegs。这一步不是必需的，但它加快了进程。</p><p id="0990" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">问题 2:-为什么行星卫星图像竞赛中这里使用的度量是</strong> <code class="fe ml mm mn mo b"><strong class="kp ir">f2 </strong></code> <strong class="kp ir">而不是精度？</strong></p><p id="3c80" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">有很多方法可以将我们在狗和猫的分类中看到的混淆矩阵转化为准确度分数。那些是</p><ul class=""><li id="2e0d" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mk lq lr ls bi translated">精确</li><li id="9b85" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">回忆</li><li id="ad4e" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated">f-β</li></ul><p id="9a0f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">根据这个竞赛标准，准确性是根据 f-Beta 分数来判断的。在 f-Beta 评分中，Beta 表示你对假阴性和假阳性的权重是多少？在 f-β中，β值是 2。当我们建立神经网络时，我们将它作为一个<code class="fe ml mm mn mo b">metrics </code>来传递。查看下面的代码。</p><pre class="kg kh ki kj gt nz mo oa ob aw oc bi"><span id="ebcc" class="od oe iq mo b gy of og l oh oi">from planet import f2</span><span id="2a2e" class="od oe iq mo b gy oj og l oh oi">metrics=[f2]<br/>f_model = resnet34</span><span id="15c6" class="od oe iq mo b gy oj og l oh oi">learn = ConvLearner.pretrained(f_model, data, metrics=metrics)</span></pre><p id="8820" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> Qs 3:-多标签和单标签分类的区别？</strong></p><p id="2c8f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">单标签分类问题的输出激活函数是 Softmax。但是如果我们必须预测特定图像中的多个标签，如下文最后一列所示</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pc"><img src="../Images/7124ae271fc3f75271e9ceb1daea34eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*o38MtMib2fRqeblW8qKxnA.png"/></div></figure><p id="edf2" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">那么 Softmax 是一个可怕的选择，因为它有强烈选择特定标签的倾向。对于多标签分类问题，我们使用的激活函数是<strong class="kp ir"> Sigmoid。</strong>fastai 库如果观察到多标签分类问题，会自动切换到 Sigmoid。Sigmoid 公式是 e^x/(1+e^x)。Sigmoid 图看起来像:-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="ms mt di mu bf mv"><div class="gh gi pd"><img src="../Images/327f53b0f499d269d30d43607ee33a3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uyaaiKwzUcL-X9v48Nl0FQ.png"/></div></div></figure><p id="4a71" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">基本上，Sigmoid 图表示的是，如果激活小于 0.5，则 Sigmoid 将返回低概率值，如果激活大于 0.5，则 Sigmoid 将返回高概率值。多件事怎么可能有高概率。</p><p id="188f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">问题 4:-蛋鸡训练如何进行？</strong></p><p id="412e" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这些层次非常重要，但其中预先训练的权重并不重要。所以最想训练的是后面几层。早期的层已经接近我们想要的，即检测边缘和角落。</p><p id="aee4" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">因此，在狗与猫的情况下，当我们从预训练的模型创建模型时，它会返回一个模型，其中所有卷积层都被冻结，一些随机设置的完全连接层被添加到末端并被解冻。所以当我们说 fit 的时候，首先，它在最后训练随机初始化的全连接层。如果某样东西真的很接近 Imagenet 数据集，那往往就是我们需要的。因为早期的层已经善于发现边缘、梯度、重复图案等。然后，当我们解冻时，我们将早期层的学习速率设置得非常低，因为我们不想对它们进行太多的更改。</p><p id="acb2" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">而在卫星数据中，早期的层似乎比后期的层更好，但我们仍然需要对它们进行相当大的改变，这就是为什么我们的学习速率比最终的学习速率小 9 倍，而不是像前一种情况那样小 1000 倍。</p><p id="644e" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">问题 5:-为什么我们不能直接从解冻所有层开始？</strong></p><p id="93a2" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们可以做到，但是需要更多的时间。首先，通过解冻最终层并保持初始层冻结，我们正在训练最终层学习更重要的功能。卷积层包含预先训练的权重，因此它们不是随机的。对于那些接近 ImageNet 的东西，它们真的很好，但是如果它们不接近 ImageNet，它们总比没有好。我们所有的 FC 层都是完全随机的，因此你总是想通过先训练它们来使完全连接的层比随机层更好，因为否则如果你直接去解冻，那么我们将在早期层权重仍然随机时摆弄早期层权重。</p><p id="c640" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">需要记住的几点是</p><ul class=""><li id="e21a" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mk lq lr ls bi translated"><strong class="kp ir">训练就是更新核值的权重和 FC 层的权重。根据权重和先前层激活输出来计算激活。</strong></li><li id="b674" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mk lq lr ls bi translated"><code class="fe ml mm mn mo b"><strong class="kp ir">learn.summary() </strong></code> <strong class="kp ir">命令用来可视化模型。</strong></li></ul><p id="6f0f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><em class="mb">如果你喜欢，那么</em><strong class="kp ir"><em class="mb">ABC</em></strong><em class="mb">(</em><strong class="kp ir"><em class="mb">永远被击节</em> </strong> <em class="mb">)。</em> <strong class="kp ir"> <em class="mb">👏 👏👏👏👏</em>😃😃😃😃😃😃😃😃😃<em class="mb">👏 👏👏👏👏👏</em> </strong> <em class="mb"> ) </em></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="np mq l"/></div></figure><p id="2b33" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如果您有任何问题，请随时在<a class="ae lj" href="http://forums.fast.ai/" rel="noopener ugc nofollow" target="_blank"> fast.ai 论坛</a>或 Twitter 上联系:<a class="ae lj" href="https://twitter.com/ashiskumarpanda" rel="noopener ugc nofollow" target="_blank"> @ashiskumarpanda </a></p><p id="4325" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><em class="mb">附:随着我继续学习其他课程，这篇博文将会更新和改进。如果你对源代码感兴趣，可以在这里查看</em><a class="ae lj" href="https://github.com/CaptainAshis/Deep_Learning-Experiment/blob/master/Planet%20Earth%20Competition/Amazonian-multi-label.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="mb"/></a><em class="mb">。</em></p><p id="4f3d" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了充分利用这个博客系列，请按照以下顺序随意探索这个系列的第一部分:- <a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-1-e9cc80d81a9d">狗和猫的图像分类</a></p><ol class=""><li id="9292" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60">犬种图像分类</a></li><li id="f4db" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889">多标签图像分类</a></li><li id="c6b9" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-4-1-time-series-analysis-a23217418bf1">使用神经网络的时间序列分析</a></li><li id="a682" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/nlp-sentiment-analysis-on-imdb-movie-dataset-fb0c4d346d23" rel="noopener">对 IMDB 电影数据集的 NLP 情感分析</a></li><li id="3c97" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-1-movie-recommendation-using-fastai-a53ed8e41269">电影推荐系统基础</a></li><li id="ea7f" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-2-collaborative-filtering-from-scratch-1877640f514a">从零开始协同过滤</a></li><li id="9683" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-3-collaborative-filtering-using-neural-network-48e49d7f9b36">使用神经网络的协同过滤</a></li><li id="cec6" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/fast-ai-season-1-episode-6-1-write-philosophy-like-nietzsche-using-rnn-8fe70cfb923c" rel="noopener">像尼采一样写哲学</a></li><li id="8fa5" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/fast-ai-season-1-episode-7-1-performance-of-different-neural-networks-on-cifar-10-dataset-c6559595b529" rel="noopener">不同神经网络在 Cifar-10 数据集上的性能</a></li><li id="4770" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://medium.com/hackernoon/single-object-detection-e65a537a1c31" rel="noopener">检测图像中最大物体的 ML 模型 Part-1 </a></li><li id="7554" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://medium.com/hackernoon/single-object-detection-part-2-2deafc911ce7" rel="noopener">检测图像中最大物体的 ML 模型 Part-2 </a></li></ol><p id="4ce8" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">编辑 1:-TFW·杰瑞米·霍华德同意你的帖子。💖💖 🙌🙌🙌 💖💖。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pe mq l"/></div></figure></div></div>    
</body>
</html>