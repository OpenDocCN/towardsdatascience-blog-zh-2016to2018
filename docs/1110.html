<html>
<head>
<title>A wizard’s guide to Adversarial Autoencoders: Part 1, Autoencoder?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对抗性自动编码器的向导指南:第1部分，自动编码器？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-wizards-guide-to-adversarial-autoencoders-part-1-autoencoder-d9a5f8795af4?source=collection_archive---------2-----------------------#2017-07-30">https://towardsdatascience.com/a-wizards-guide-to-adversarial-autoencoders-part-1-autoencoder-d9a5f8795af4?source=collection_archive---------2-----------------------#2017-07-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/ba425a61fd0d74181a258481d9d28fb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x457uwYab4_wX4g9ZJEl2Q.png"/></div></div></figure><p id="8a03" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">“如果你知道如何使用Tensorflow编写代码来对MNIST数字进行分类，那么你就可以阅读这篇文章的其余部分，否则我强烈建议你浏览Tensorflow网站上的这篇文章</em><a class="ae kx" href="https://www.tensorflow.org/get_started/mnist/beginners" rel="noopener ugc nofollow" target="_blank"><em class="kw"/></a><em class="kw"/></p><blockquote class="ky kz la"><p id="e0e2" class="jy jz kw ka b kb kc kd ke kf kg kh ki lb kk kl km lc ko kp kq ld ks kt ku kv ij bi translated">“我们现在知道，我们不需要任何新的重大突破来实现真正的人工智能。</p><p id="9642" class="jy jz kw ka b kb kc kd ke kf kg kh ki lb kk kl km lc ko kp kq ld ks kt ku kv ij bi translated">这是完全，完全，荒谬的错误。正如我在前面的陈述中所说的:大多数人类和动物的学习是无监督的学习。如果智能是一块蛋糕，无监督学习就是蛋糕，监督学习就是蛋糕上的糖衣，强化学习就是蛋糕上的樱桃。</p><p id="9434" class="jy jz kw ka b kb kc kd ke kf kg kh ki lb kk kl km lc ko kp kq ld ks kt ku kv ij bi translated">我们知道如何做糖霜和樱桃，但是我们不知道如何做蛋糕。在我们能够想到真正的人工智能之前，我们需要解决无监督学习的问题。这只是我们知道的一个障碍。那些我们不知道的呢？"</p></blockquote><p id="c8e3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是在alpha go<a class="ae kx" href="https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol" rel="noopener ugc nofollow" target="_blank">获胜</a>后，脸书人工智能研究主任阎乐存(我知道，另一个是阎乐存)的一句话。</p><p id="f6cc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们知道，卷积神经网络(CNN)或在某些情况下密集的全连接层(MLP——一些人喜欢称之为多层感知器)可以用来执行图像识别。但是，CNN(或MLP)不能单独用于执行任务，如从图像中分离内容和风格，生成真实的图像(生成模型)，使用非常小的标签集对图像进行分类或执行数据压缩(如压缩文件)。</p><p id="2be9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这些任务中的每一个都可能需要它自己的架构和训练算法。但是，如果我们能够只使用一个架构来实现上述所有任务，这不是很酷吗？一个对抗性的自动编码器(以半监督方式训练的编码器)可以使用一种架构完成所有这些任务。</p><p id="b474" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将构建一个对抗性的自动编码器，它可以压缩数据(以有损的方式压缩MNIST数字)，分离数字的样式和内容(生成不同样式的数字)，使用标记数据的一个小子集对它们进行分类，以获得高分类精度(仅使用1000个标记数字，大约95%！)并且最后还充当生成模型(以生成看起来真实的假数字)。</p><p id="af8f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在我们进入对抗性自动编码器的理论和实现部分之前，让我们后退一步，讨论一下自动编码器，看看一个简单的tensorflow实现。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ll"><img src="../Images/50a0eb8c015bff9a3488cdbcce09ecf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eLieLQIprDp4BgC63288kQ.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Autoencoder Architecture</figcaption></figure><p id="9dab" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">自动编码器是一种神经网络，它被训练以产生与其输入非常相似的输出(因此它基本上试图将其输入复制到其输出)，并且由于它不需要任何目标(标签)，所以它可以以无人监督的方式进行训练。</p><p id="71e7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">它有两个部分:</p><ol class=""><li id="5ab5" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv lz ma mb mc bi translated"><strong class="ka ir"> <em class="kw">编码器:</em> </strong>它接收一个输入<strong class="ka ir"> x </strong>(这可以是图像、文字嵌入、视频或音频数据)并产生一个输出<strong class="ka ir"> h </strong>(其中<strong class="ka ir"> h </strong>通常具有比<strong class="ka ir"> x </strong>更低的维度)。例如，编码器可以接收大小为100 x 100的图像<strong class="ka ir"> x </strong>，并产生大小为100 x 1(可以是任何大小)的输出<strong class="ka ir"> h ( </strong>也称为<em class="kw">潜在代码</em>)。在这种情况下，编码器只是压缩图像，这样它将占用更低的维度空间，这样我们现在可以看到<strong class="ka ir"> h </strong>(大小为100 x 1)可以使用比直接存储图像<strong class="ka ir"> x </strong>少100倍的内存来存储(这将导致一些数据丢失)。</li></ol><p id="937a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">我们来想一个像WinRAR这样的压缩软件(还在免费试用？)可用于压缩文件，以获得占用空间较少的zip(或rar，…)文件。自动编码器架构中的编码器执行类似的操作。</em></p><p id="47bf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果编码器由函数<strong class="ka ir"> q、</strong>表示，则</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi md"><img src="../Images/aa72fadf48a9bcd3231480d35882df44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mDDXRlbv73ZXZohkEoakWg.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Encoder</figcaption></figure><p id="9a86" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">2.<strong class="ka ir"> <em class="kw">解码器:</em> </strong>它接收编码器<strong class="ka ir"> h </strong>的输出，并试图在其输出端重建输入。继续编码器示例，<strong class="ka ir"> h </strong>现在的大小为100 x 1，解码器尝试使用<strong class="ka ir"> h </strong>恢复原始的100 x 100图像。我们将训练解码器从<strong class="ka ir"> h </strong>中获取尽可能多的信息，以重建<strong class="ka ir"> x </strong>。</p><p id="4f1a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">所以，解码器的操作类似于对WinRAR执行解压缩。</em></p><p id="0ca9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果函数<strong class="ka ir"> p </strong>代表我们的解码器，则重建图像<strong class="ka ir"> x_ </strong>为:</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi md"><img src="../Images/3ec2530e504ce6310aadfef93c0df36e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UN49zl3Mfalfi3mXTVZCzw.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Decoder</figcaption></figure><p id="d1e4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">只有当输入相关时(如来自同一域的图像)，降维才有效。如果我们每次训练自动编码器时都传递完全随机的输入，那么它就会失败。因此，最终，给定一个输入，自动编码器可以产生更低维度的输出(在编码器处)，非常类似于主成分分析(<a class="ae kx" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank"> PCA </a>)。由于我们在训练过程中不需要使用任何标签，这也是一个无人监管的模型。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><blockquote class="me"><p id="d0a9" class="mf mg iq bd mh mi mj mk ml mm mn kv dk translated">但是，除了降维，自动编码器还能用来做什么呢？</p></blockquote><ul class=""><li id="c48d" class="lu lv iq ka b kb mo kf mp kj mq kn mr kr ms kv mt ma mb mc bi translated">图像<a class="ae kx" href="http://www.jmlr.org/papers/volume11/vincent10a/vincent10a.pdf" rel="noopener ugc nofollow" target="_blank">去噪</a>其中可以使用有噪声的图像生成清晰无噪声的图像。</li></ul><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/11fa3fe2ce52facd7d9932337e8a2f81.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/0*EApgSiCJDdsBcosD.png"/></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Denoising autoencoder example on handwritten digits. Source: <a class="ae kx" href="https://www.doc.ic.ac.uk/~js4416/163/website/autoencoders/denoising.html" rel="noopener ugc nofollow" target="_blank">https://www.doc.ic.ac.uk/~js4416/163/website/autoencoders/denoising.html</a></figcaption></figure><ul class=""><li id="18e3" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv mt ma mb mc bi translated"><a class="ae kx" href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Carreira-Perpinan_Hashing_With_Binary_2015_CVPR_paper.pdf" rel="noopener ugc nofollow" target="_blank">语义哈希</a>降维可以用来加快信息检索(我发现这很有趣！).</li><li id="ccc5" class="lu lv iq ka b kb mv kf mw kj mx kn my kr mz kv mt ma mb mc bi translated">最近，以对抗方式训练的自动编码器可以用作生成模型(我们将在后面更深入地讨论)。</li></ul><p id="12cb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我将这篇文章分为四个部分:</p><ul class=""><li id="2f27" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv mt ma mb mc bi translated"><strong class="ka ir">第1部分:</strong>自动编码器？</li></ul><p id="1cc5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">我们将从使用Tensorflow实现一个简单的自动编码器开始，并减少MNIST(你肯定知道这个数据集是关于什么的)数据集图像的维数。</em></p><ul class=""><li id="8bf3" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv mt ma mb mc bi translated"><strong class="ka ir">第二部分:</strong>用对抗性的自动编码器探索潜在空间。</li></ul><p id="34d6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">我们将使用对抗学习对潜在代码(编码器的输出)引入约束。</em></p><ul class=""><li id="8e57" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv mt ma mb mc bi translated"><strong class="ka ir">第三部分:</strong>风格与内容的解开。</li></ul><p id="8e38" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">在这里，我们将使用相同的书写风格生成不同的图像。</em></p><ul class=""><li id="b5cb" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv mt ma mb mc bi translated"><strong class="ka ir">第四部分:</strong>用1000个标签给MNIST分类。</li></ul><p id="249b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">我们将训练一个AAE来对MNIST数字进行分类，仅使用1000个带标签的输入就能获得大约95%的准确率(令人印象深刻啊？).</em></p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="1167" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们从了解我们需要实现的网络架构开始第一部分。</p><p id="0d07" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如前所述，自动编码器(AE)由编码器和解码器两部分组成，让我们从一个简单的密集全连接编码器架构开始:</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi na"><img src="../Images/95e350ae86b3bf528c5ecd42c85059f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hud7t2vLY2JIP3SXn4WTDA.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Encoder Architecture</figcaption></figure><p id="37d5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">它包括一个具有784个神经元的输入层(因为我们已经将图像展平为一维)，两组1000个ReLU激活的神经元形成隐藏层，一个由2个未激活的神经元组成的输出层提供潜在代码。</p><p id="d29b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你只是想得到代码，请点击以下链接:</p><div class="nb nc gp gr nd ne"><a href="https://github.com/Naresh1318/Adversarial_Autoencoder" rel="noopener  ugc nofollow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd ir gy z fp nj fr fs nk fu fw ip bi translated">naresh 1318/Adversarial _自动编码器</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">在GitHub上创建一个帐户，为Adversarial_Autoencoder的开发做出贡献。</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">github.com</p></div></div><div class="nn l"><div class="no l np nq nr nn ns jw ne"/></div></div></a></div><p id="4164" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了在Tensorflow中实现上述架构，我们将从一个<code class="fe nt nu nv nw b">dense()</code>函数开始，该函数将帮助我们在给定输入<code class="fe nt nu nv nw b">x</code>、输入处的神经元数量<code class="fe nt nu nv nw b">n1</code>和输出处的神经元数量<code class="fe nt nu nv nw b">n2</code>的情况下构建一个密集的全连接层。<code class="fe nt nu nv nw b">name</code>参数用于设置<code class="fe nt nu nv nw b">variable_scope</code>的名称。更多关于共享变量和使用变量作用域的内容可以在这里找到<a class="ae kx" href="https://www.tensorflow.org/programmers_guide/variable_scope" rel="noopener ugc nofollow" target="_blank"/>(我强烈推荐看一看)。</p><figure class="lm ln lo lp gt jr"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="976d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我使用了<code class="fe nt nu nv nw b">tf.get_variable()</code>而不是<code class="fe nt nu nv nw b">tf.Variable()</code>来创建权重和偏差变量，这样我们就可以在以后重用训练好的模型(单独使用编码器或解码器)来传递任何想要的值，并查看它们的输出。</p><p id="2492" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，我们将使用这个<code class="fe nt nu nv nw b">dense()</code>函数来实现编码器架构。代码很简单，但是请注意，我们没有在输出中使用任何激活。</p><figure class="lm ln lo lp gt jr"><div class="bz fp l di"><div class="nx ny l"/></div></figure><ul class=""><li id="5266" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv mt ma mb mc bi translated"><code class="fe nt nu nv nw b">reuse </code>标志用于重用训练过的编码器架构。</li><li id="b1a4" class="lu lv iq ka b kb mv kf mw kj mx kn my kr mz kv mt ma mb mc bi translated">这里<code class="fe nt nu nv nw b">input_dim = 784, n_l1 = 1000, n_l2 = 1000, z_dim = 2</code>。</li></ul><p id="3c84" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">解码器以类似的方式实现，我们需要的架构是:</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nz"><img src="../Images/f8be7567d3caee2579c7f28670ffac7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0t7JrvUqyzg7AdQGDjZkRw.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Decoder Architecture</figcaption></figure><figure class="lm ln lo lp gt jr"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="c9b6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将再次使用<code class="fe nt nu nv nw b">dense()</code>函数来构建我们的解码器。然而，我对输出层使用了sigmoid激活，以确保输出值的范围在0和1之间(与我们的输入范围相同)。</p><ul class=""><li id="c89b" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv mt ma mb mc bi translated"><code class="fe nt nu nv nw b">z_dim = 2, n_l2 = 1000, n_l1 = 1000, input_dim = 784</code>与编码器相同。</li></ul><p id="4cee" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">编码器输出可以像这样连接到解码器:</p><figure class="lm ln lo lp gt jr"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="b51a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这就形成了与架构图所示完全相同的自动编码器架构。我们将通过占位符<code class="fe nt nu nv nw b">x_input</code>(大小:batch_size，784)传递输入，将目标设置为与<code class="fe nt nu nv nw b">x_input</code>相同，并将<code class="fe nt nu nv nw b">decoder_output</code>与<code class="fe nt nu nv nw b">x_input</code>进行比较。</p><p id="ad90" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用的损失函数是均方误差(MSE ),其找到输入(<code class="fe nt nu nv nw b">x_input</code>)和输出图像(<code class="fe nt nu nv nw b">decoder_output</code>)中的像素之间的距离。我们称之为重建损失，因为我们的主要目的是在输出端重建输入。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi md"><img src="../Images/0b268a7834bc91be0fcf892c376c7ef6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D9BOeBMCepHFdO2B92VMkA.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Mean Squared Error</figcaption></figure><p id="c61f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这只不过是输入和输出之间的平方差的平均值。这可以很容易地在Tensorflow中实现，如下所示:</p><figure class="lm ln lo lp gt jr"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="bc4b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我用过的优化器是AdamOptimizer(随意尝试新的，我还没有在别人身上试验过)，学习率为0.01，beta1为0.9。它可在Tensorflow上直接获得，使用方法如下:</p><figure class="lm ln lo lp gt jr"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="1d3a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">请注意，我们使用相同的损失函数通过编码器和解码器进行反向传播。(我可以使用<code class="fe nt nu nv nw b">minimize()</code>方法下的<code class="fe nt nu nv nw b">var_list</code>参数只改变编码器或解码器的权重。由于我没有提到任何，它默认为所有的可训练变量。)</p><p id="4c23" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后，我们通过使用100的批量大小传入我们的MNIST图像并使用同样的100个图像作为目标来训练我们的模型。</p><figure class="lm ln lo lp gt jr"><div class="bz fp l di"><div class="nx ny l"/></div></figure><p id="a7fe" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">github上有完整的代码:</p><div class="nb nc gp gr nd ne"><a href="https://github.com/Naresh1318/Adversarial_Autoencoder/blob/master/autoencoder.py" rel="noopener  ugc nofollow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd ir gy z fp nj fr fs nk fu fw ip bi translated">naresh 1318/Adversarial _自动编码器</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">在GitHub上创建一个帐户，为Adversarial_Autoencoder的开发做出贡献。</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">github.com</p></div></div><div class="nn l"><div class="oa l np nq nr nn ns jw ne"/></div></div></a></div><h2 id="fa91" class="ob oc iq bd od oe of dn og oh oi dp oj kj ok ol om kn on oo op kr oq or os ot bi translated"><strong class="ak">注意事项:</strong></h2><ul class=""><li id="6b81" class="lu lv iq ka b kb ou kf ov kj ow kn ox kr oy kv mt ma mb mc bi translated"><code class="fe nt nu nv nw b">generate_image_grid()</code>函数通过向经过训练的解码器传递一组数字来生成图像网格(这就是<code class="fe nt nu nv nw b">get_variable </code>派上用场的地方)。</li><li id="7cc9" class="lu lv iq ka b kb mv kf mw kj mx kn my kr mz kv mt ma mb mc bi translated">每次运行都会在以下位置生成所需的张量板文件:</li></ul><p id="a41c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><code class="fe nt nu nv nw b">./Results/&lt;model&gt;/&lt;time_stamp_and_parameters&gt;/Tensorboard</code></p><ul class=""><li id="8e80" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv mt ma mb mc bi translated">训练日志存储在:</li></ul><p id="7e8a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><code class="fe nt nu nv nw b">./Results/&lt;model&gt;/&lt;time_stamp_and_parameters&gt;/log/log.txt</code>文件。</p><ul class=""><li id="9cbb" class="lu lv iq ka b kb kc kf kg kj lw kn lx kr ly kv mt ma mb mc bi translated">将<code class="fe nt nu nv nw b">train</code>标志设置为<code class="fe nt nu nv nw b">True</code>以训练模型，或者将其设置为<code class="fe nt nu nv nw b">False</code>以显示某些随机输入的解码器输出。</li></ul><p id="a0b2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我已经训练了200个时期的模型，并显示了损失的变化和下面生成的图像:</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oz"><img src="../Images/000fb24adc0b1adda7e0da0c4e3f3e72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-VrFB68o7d-0V27PPdrutA.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Variation of reconstruction loss</figcaption></figure><p id="cf2e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">重建损失正在减少，这正是我们所希望的。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pa"><img src="../Images/3efb49fa7decfe54676184e0f5859756.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HE1SXptNzXDyYMhLPUZL2w.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Generated Images</figcaption></figure><p id="45b1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">请注意，解码器是如何通过移除输入3顶部的线条等小的不规则性来概括输出3的。</p><p id="1dc5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，如果我们只考虑经过训练的解码器，并传入一些随机数(我已经传入0，0，因为我们只有一个2-D潜在代码)作为输入，我们应该得到一些正确的数字？</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pb"><img src="../Images/47d0a8ad4fcac2a7c5ef078408e01809.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CnlhhXzud4RqTee9jRG2pQ.png"/></div></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Decoder Output at (0, 0)</figcaption></figure><p id="3a54" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但这根本不能代表一个明确的数字(好吧，至少对我来说)。</p><p id="9e81" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">其原因是因为编码器输出没有覆盖整个2-D潜在空间(在其输出分布中有很多间隙)。因此，如果我们在训练阶段输入编码器没有输入到解码器的值，我们会得到看起来很奇怪的输出图像。这可以通过在产生潜在代码时将编码器输出限制为具有随机分布(比如平均值为0.0且标准偏差为2.0的正态分布)来克服。这正是对抗性自动编码器所能做到的，我们将在第二部分中研究它的实现。</p><blockquote class="me"><p id="0bde" class="mf mg iq bd mh mi mj mk ml mm mn kv dk translated"><strong class="ak">再看看封面图片！！</strong></p><p id="dcb2" class="mf mg iq bd mh mi mj mk ml mm mn kv dk translated"><strong class="ak">懂了吗？</strong></p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="b6ba" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">希望你喜欢这篇关于自动编码器的短文。我会公开鼓励任何批评或建议来改进我的工作。</p><p id="6936" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你认为这个内容值得分享点击❤️，我喜欢它发送给我的通知！！</p><p id="beee" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">→第2部分:<a class="ae kx" href="https://medium.com/towards-data-science/a-wizards-guide-to-adversarial-autoencoders-part-2-exploring-latent-space-with-adversarial-2d53a6f8a4f9" rel="noopener">用对抗性自动编码器探索潜在空间。</a></p></div></div>    
</body>
</html>