<html>
<head>
<title>FADL2 L8: ‘Neural’ Artistic Style Transfer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">FADL2 L8:“神经”艺术风格转移</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fadl2-l8-neural-artistic-style-transfer-a2e6780ab17b?source=collection_archive---------7-----------------------#2017-07-28">https://towardsdatascience.com/fadl2-l8-neural-artistic-style-transfer-a2e6780ab17b?source=collection_archive---------7-----------------------#2017-07-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="c50a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最近完成了<a class="kl km ep" href="https://medium.com/u/34ab754f8c5e?source=post_page-----a2e6780ab17b--------------------------------" rel="noopener" target="_blank">杰瑞米·霍华德</a>的<a class="ae kn" href="http://course.fast.ai/" rel="noopener ugc nofollow" target="_blank">实用深度学习</a>的第八课(beta 版第二部分)。在这里，我将回顾一下重建本课 Jupyter 笔记本的一些工作和结果。&lt; <em class="ko">这是</em> <strong class="jp ir"> <em class="ko">非常</em> </strong> <em class="ko">粗糙</em> &gt;</p><p id="7721" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[ <em class="ko">注意:think part 2 已更名为“前沿深度学习”——应该很快就会公开发布。</em> <strong class="jp ir">亦作<em class="ko">TL；dr: </em> </strong> <em class="ko">滚动到底部观看视频</em></p><p id="e1c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我对笔记本的解读可以跟着这里:<a class="ae kn" href="https://github.com/WNoxchi/Kaukasos/blob/master/FAI02/L8_NeuralArtTrsfr_CodeAlong.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/WNoxchi/kauka SOS/blob/master/fai 02/L8 _ NeuralArtTrsfr _ code along . ipynb</a></p></div><div class="ab cl kp kq hu kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="ij ik il im in"><p id="30f5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在回顾了库导入和指定<code class="fe kw kx ky kz b">limit_mem()</code>以便 TensorFlow 不会吃掉你的 GPU 所提供的一切之后，我必须学习 Python 中的‘picking’是什么。结果，多亏了 YouTube 上的 sentdex，这只是 Python 中的序列化。什么连载？显然，它是一个接一个地发送数据流…显然，当你进行大量的磁盘访问时，它是有用的(比如为 ML 读取数据)，尽管它不提供安全性，所以要小心网络流。</p><p id="694c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我试着写了一本小型拉丁语字典:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi la"><img src="../Images/032440da0e04b00831c3c4f70a589ca8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*GxZS5EliEkCME3iOKNAyrw.png"/></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">Learning to Pickle in Python (data serialization)</figcaption></figure><p id="88ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">原来如此。我还没有看过 sentdex 更新的“<a class="ae kn" href="https://www.youtube.com/watch?v=za5s7RB_VLw" rel="noopener ugc nofollow" target="_blank">酸洗和缩放——用 Python p.6 </a>进行实用机器学习”视频，但如果我觉得有必要，我可能会看。</p><p id="7ebf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi lm translated"><span class="l ln lo lp bm lq lr ls lt lu di"> 1。</span>内容重建</p><p id="b7d9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">神经风格转移</strong></p><p id="79a2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">NST 正在创建一个新的图像，它保留了一个图像的“风格”和另一个图像的形式。例如，使用两幅输入图片创建一幅文森特·梵高风格的猫的图片:一幅猫的图片，另一幅代表梵高的绘画风格。</p><p id="343c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里有几件事很重要。该算法并没有将梵高的风格应用到猫图像本身:它从一幅新图像(像一堆随机的像素)开始，并将其构建成所需的复合图像。</p><p id="b545" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它需要一个已经足够好的模型来辨别两个输入图像的特征。所以，“眼睛在哪里”，“这是一张脸”，“这笔触是一个东西”等等。</p><p id="7c11" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第一步是初始化模型(这里是使用平均池并减去 FC 层的顶部块的修改的 VGG16 CNN):</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/d1c91c8d3f509656175910e75e649ec9.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*QACFDXrfK6JFkZeGwk38_A.png"/></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">instantiating a VGG16 model using Average-Pooling instead of Max, and excluding the end-block of Fully-Connected layers (we want convolutional features, not classification here)</figcaption></figure><p id="3c88" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们在 Keras 中定义一个计算图。一个计算图，就我目前的理解，是定义一系列对数据替身的操作。还没有数据传入，但一旦传入，程序就会知道该怎么做。我们这样做是为了定义目标图像</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/4c266c1eec1b0dd84127c04ca93c149a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*Wx-7LXDKwBg7LHcP_fBL5Q.png"/></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">`targ` isn’t any ‘thing’ yet, but more of an operational placeholder for when this bit of computation occurs.</figcaption></figure><p id="fafb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">可以看到，<code class="fe kw kx ky kz b">targ</code>是<code class="fe kw kx ky kz b">img_arr</code>上<code class="fe kw kx ky kz b">layer_model</code>的输出(预测)。<code class="fe kw kx ky kz b">layer_model</code>是一个<code class="fe kw kx ky kz b">Model</code>(<code class="fe kw kx ky kz b">keras.models.Model</code>:<a class="ae kn" href="https://keras.io/models/model/" rel="noopener ugc nofollow" target="_blank">Keras Functional API</a>)，由从其输入到<code class="fe kw kx ky kz b">layer</code>的<code class="fe kw kx ky kz b">model</code>层组成，我们将其定义为 VGG16 模型的第五个 Conv 块的第一个卷积层。<code class="fe kw kx ky kz b">img_arr</code>是经过预处理的原始图像，其预处理方式与 VGG 作者在训练其模型时预处理其 ImageNet 数据的方式相同。</p><p id="5827" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">注意</strong> : <code class="fe kw kx ky kz b">layer</code>是卷积子模型结束时的输出激活。<code class="fe kw kx ky kz b">layer_model</code>是从原模型开始到<code class="fe kw kx ky kz b">layer</code>定义的子模型。<code class="fe kw kx ky kz b">targ</code>是目标激活。损失函数试图使<code class="fe kw kx ky kz b">layer</code>和<code class="fe kw kx ky kz b">targ</code>尽可能靠近。</p><p id="c717" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种措辞可能会令人困惑，但是当你在代码中浏览它时，它更有意义。我们在整个笔记本中使用 Keras 定义了几个这样的图形。</p><p id="25ed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了让算法衡量它做得有多好，它需要以某种方式量化它的进展:一个损失/目标函数。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi lx"><img src="../Images/ea5fae2bc9ece4c35e7b42aa091fe596.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*45qOde7e4MQd17VI6Bb_RA.png"/></div></div></figure><p id="6d62" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为此，我们将损失定义为输出层和目标图像之间的<a class="ae kn" href="https://en.wikipedia.org/wiki/Mean_squared_error" rel="noopener ugc nofollow" target="_blank">均方误差</a>。</p><p id="a0c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe kw kx ky kz b">evaluator</code>是一个自定义的<code class="fe kw kx ky kz b">Evaluator</code>类，允许程序单独访问损失函数和梯度，因为 Keras 一起返回它们，但优化器需要单独查看它们。</p><p id="b7a8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个<code class="fe kw kx ky kz b">evaluator</code>，连同迭代次数，以及随机图像<code class="fe kw kx ky kz b">x</code>，进入<code class="fe kw kx ky kz b">solve_image(•)</code>，完成优化损失的工作。</p><p id="26e9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所有这些都是通过将原始图像的 conv 特征应用于随机生成的图像并更新损失函数来从原始图像中重建图像。</p><p id="a561" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基本思想是:我们通过子模型运行原始图像和新的随机图像，并使用我们的损失函数来确定它们的匹配程度。我们使用来自<code class="fe kw kx ky kz b">scipy.optimize.fmin_l_bgfs_b</code>的<a class="ae kn" href="https://en.wikipedia.org/wiki/Line_search" rel="noopener ugc nofollow" target="_blank">线搜索</a>算法作为优化器来最小化损失。当我们下一步从一个样式图像中合并样式时，我们将使用权重来平衡我们想要在多大程度上重新创建原始图像，而不是应用样式图像的样式。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mc"><img src="../Images/f284be1e44dab01cb537a29f0d634fe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GgYFuqgUnPHHryFhR7bNtg.png"/></div></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">`loss` is the sum of `style_loss`-es for all layers &amp; targets. `style_loss` is the mean-squared-error between the gramian matrix of the layer, and the gramian matrix of the target. The Gram Matrix is the dot-product of a matrix with its own transpose. ~ I think I remember in lecture, Howard saying no one really knows why it works … but it works.</figcaption></figure><p id="18ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以我们最终得到的，用我的猫 Terek 作为原始图像:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi md"><img src="../Images/91e72cf4f3495dee4237f3d97f5add59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PlSgYwk26nsVLOweySGv9w.png"/></div></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">Terek.</figcaption></figure><p id="0e18" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以及生成随机像素的图像:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi me"><img src="../Images/64b58bb35a7304878e8344d86237a4a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4JEqYETfldOxnhRg9qbchA.png"/></div></div></figure><p id="56c4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">并通过<code class="fe kw kx ky kz b">solve_image(•)</code>进行 10 次迭代:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/ce808e04e66b68a44590654f608b10e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*xwS1bX-0M8FQfv0lkff1Cg.png"/></div></figure><p id="27e4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们得到了这个不虔诚的怪物:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mg"><img src="../Images/8a6c07ac42e55efa051df411ab9cc0e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dPGxSdKqqZNK1P2abw5LTA.png"/></div></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">How cats actually see</figcaption></figure><figure class="lb lc ld le gt lf"><div class="bz fp l di"><div class="mh mi l"/></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">Here’s an animation of it (the videos in this post were all first taken on Instagram as I was coding)</figcaption></figure><p id="c017" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">尽管这看起来很糟糕，但实际上非常有趣。请记住，这种算法是采用马赛克或随机像素，通过我们上面定义的 CNN 来重建猫的图片，并根据新(目标)图像和网络中原始激活之间的均方误差来优化网络的权重和激活。这意味着将根据卷积网络中表达的特征来构建目标图像。所以这个模型必须能够区分眼睛和背景等等。较低的卷积块将为我们提供更精细的特征，而稍后的卷积块将为我们提供模型中更多的宏特征。因此，我们可以通过使用更早的卷积层来获得看起来更像原始图像的输出。</p></div><div class="ab cl kp kq hu kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="ij ik il im in"><p id="c66b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi lm translated"><span class="l ln lo lp bm lq lr ls lt lu di"> 2。</span>风格重构</p><p id="a140" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了重塑风格，我们必须做更多的事情。我们通过计算多层的损失函数来改变它。引用原始笔记本:</p><blockquote class="mj mk ml"><p id="83d3" class="jn jo ko jp b jq jr js jt ju jv jw jx mm jz ka kb mn kd ke kf mo kh ki kj kk ij bi translated">在我们计算原始卷积输出的 MSE 之前，我们先将它们转换为信道的“格拉米矩阵”(即矩阵与其转置矩阵的乘积),然后再计算它们的 MSE。目前还不清楚为什么这有助于我们实现目标，但它确实有效。一种想法是 Gramian 显示了我们在卷积层的特征是如何相互关联的，并且完全删除了所有的位置信息。所以匹配通道的 Gram 矩阵只能匹配某种类型的纹理信息，而不能匹配位置信息。</p></blockquote><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mp"><img src="../Images/e643eba56479790c9c005862cf54ed54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KGbq0qo19DlVGCTvPcbOlA.png"/></div></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">style_arr is the preprocessed style image. shp is the shape of style_arr. Note the major difference from before being that we’re building arrays from layers. Specifically 3 layers: for the 3 color-channels.</figcaption></figure><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mc"><img src="../Images/f284be1e44dab01cb537a29f0d634fe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GgYFuqgUnPHHryFhR7bNtg.png"/></div></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">`loss` is the sum of `style_loss`-es for all layers &amp; targets. `style_loss` is the mean-squared-error between the gramian matrix of the layer, and the gramian matrix of the target. The Gram Matrix is the dot-product of a matrix with its own transpose. ~ I think I remember in lecture, Howard saying no one really knows why it works … but it works.</figcaption></figure><p id="0515" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这样做，我们就可以了解梵高这幅画的风格:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/0d1fa561fc9fc474d4c59ccf5c12970b.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*VqpezuGAxHZSSatZBhMiag.png"/></div></figure><p id="264b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">并将该样式应用于这个随机生成的目标图像:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/a315b5f2b664a1d2bb2d98cf2660a10e.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*BlL8Y0UiMvjkHBKZtRvemw.png"/></div></figure><p id="95db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要在 10 次迭代后获得梵高风格的随机像素图像:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/911849293fd9ff4d5b1eebf985e7a7d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*OhpwBZ9BLqjK7MgO75WeLg.png"/></div></figure></div><div class="ab cl kp kq hu kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="ij ik il im in"><p id="fa99" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi lm translated"><span class="l ln lo lp bm lq lr ls lt lu di"> 3。</span>风格转移</p><p id="9205" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后是风格转移。我们得到了 1。投入再创造。2.风格休闲。现在把它放在一起:</p><p id="763f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是以(最终)直观的方式完成的:通过加权和添加两个损失函数来组合这两种方法。和以前一样，我们获取一系列层输出来计算风格损失。计算内容损失只需要一个图层输出。层越低:内容重建越精确。当我们将内容重建与样式合并时:更早的层/更松散的重建将为样式留出更多空间，反之亦然。</p><p id="4739" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里我们有代码使<code class="fe kw kx ky kz b">style_layers</code>成为块 1 到 5 的第二卷积层；以及<code class="fe kw kx ky kz b">content_layer</code>块 4 conv 层 2 的输出(激活):</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mt"><img src="../Images/847b15cff7bf1774e2840659b19bf566.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cLAZyD4hhZJVICjes8yDKQ.png"/></div></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">The style and content models become submodels of the full model’s input to the respective style and content outputs. NOTE: the style target outputs/activations correspond to their multiple layers. The style targets ultimate take in the style array (preprocessed style image) and likewise content target takes in the preprocessed source image (src).</figcaption></figure><p id="9928" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这创建了三个独立的输出类型:原始图像，风格图像，以及我们正在训练的像素的随机图像。</p><p id="b79f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，创建一个应用于样式输出激活的权重数组。这调整了图像重建和风格转换这两个层面的组合。注意:这是内容丢失的一个因素。系数越小(分母越大),样式对最终图像的影响就越大，直到它完全掩盖了任何原始内容。</p><p id="0a31" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">必须在<em class="ko">全风格</em>和<em class="ko">全商务之间找到最佳平衡点。</em></p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mu"><img src="../Images/7beaf27bb976924ca01400ea6bf387a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SBMcM5Hj0i2iVotDbE9bVQ.png"/></div></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">This does the thing</figcaption></figure><p id="bab9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是一些结果:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/6aadf56117817acb69e7001994216b33.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*1vzg9Nf_8a36ofwY6PL7Tw.png"/></div></figure><p id="9d38" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我偶然得到了一幅电源插头的印象派画作:</p><figure class="lb lc ld le gt lf"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="b7cf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">卷积神经网络需要固定的输入大小，因此内容、风格和输出图像必须具有相同的维度。因此，当我对我的猫的图片进行适当的裁剪时，我忘记了调整它，得到了左上角，和我用来设计风格的一幅小鸟画的尺寸一样。</p><figure class="lb lc ld le gt lf"><div class="bz fp l di"><div class="mh mi l"/></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">Artistic inspiration brought to you by Snapchat…</figcaption></figure><p id="764a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，确保我做的事情是正确的:看看我是否能在相同的输入图像上得到与杰瑞米·霍华德相同的结果:</p><figure class="lb lc ld le gt lf"><div class="bz fp l di"><div class="mw mi l"/></div></figure><p id="38a7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">肯定有些不同，当然也有相似之处，我喜欢这是第一次运行。我肯定对做好<em class="ko">风格转移感到兴奋，就像你将在这里找到的一样:<a class="ae kn" href="https://github.com/titu1994/Neural-Style-Transfer" rel="noopener ugc nofollow" target="_blank">https://github.com/titu1994/Neural-Style-Transfer</a></em></p><p id="ccda" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">足够幸运的是，看起来像“蒙版”等技术将在第 9 课中涉及，所以我甚至不需要额外学习。</p></div><div class="ab cl kp kq hu kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="ij ik il im in"><p id="94f1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以，最后一点:这不是一个从头学习的帖子。为此:你必须浏览课文和原始笔记本。但是如果你正在做这个并且想要一些额外的想法，那么希望这是有帮助的。</p><p id="51af" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我喜欢人工智能的另一点是它提供了粗略但精确的文件夹名称:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="gh gi mx"><img src="../Images/ae28f35087ee888590dc37bba53297bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0m1y6eejSjepXVcAZzgVcA.png"/></div></div></figure><p id="6b14" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">非常感谢<a class="kl km ep" href="https://medium.com/u/34ab754f8c5e?source=post_page-----a2e6780ab17b--------------------------------" rel="noopener" target="_blank">杰瑞米·霍华德</a>和<a class="kl km ep" href="https://medium.com/u/ee56d0bac1b7?source=post_page-----a2e6780ab17b--------------------------------" rel="noopener" target="_blank">瑞秋·托马斯</a>将 fast.ai 组装在一起</p></div></div>    
</body>
</html>