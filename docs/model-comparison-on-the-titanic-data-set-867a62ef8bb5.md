# Titanic 数据集上的模型比较

> 原文：<https://towardsdatascience.com/model-comparison-on-the-titanic-data-set-867a62ef8bb5?source=collection_archive---------3----------------------->

在为期 12 周的训练营中，我刚刚接触了数据科学的服务，我最喜欢的练习之一是查看模型比较。开始模型选择和 EDA 需要深思熟虑，并为我提供任何合理的见解执行。随着我成为一名数据科学家，我认为划分哪些模型最适合哪些类型的数据非常重要。这需要我自己进行大量的分析和探索。在这一点上，让我们看看泰坦尼克号数据集作为一个例子。

![](img/c46194cfbb4146f6496fec3db3d70177.png)

我应该提到，我正试图根据上面列出的几个因素来确定谁幸存了下来。在我深入研究之前，我想通过上面的表格指出，我们可以把性变成一个虚拟变量。接下来，我们应该执行和 EDA 定义我们想要的 X 和 y。

![](img/2dbbca92ffd05f82329213e47a3ef166.png)

现在，我们应该导入并准备一个训练测试分割，并创建一个名为模型评估的功能，该功能查看准确性分数、混淆矩阵和分类报告。

![](img/989c622b30e9d1cbd2cbf891d2ae6884.png)

现在让我们从 K 个最近的邻居开始。

![](img/7076f59ee47a66ded10ce80f8d1a7c89.png)

现在 KNN 使用网格搜索。

![](img/d90afba134a966a78c53ebb3b48640bc.png)

这给了我们一个 0.636363636363635 的最终分数。现在让我们试试 KNN 装袋！

![](img/d044a323af86a49805ee54a4c7130bc1.png)![](img/177e791eac54caa790bf051137fc62c3.png)

现在，逻辑回归

![](img/b0b48575600621c82017d7f00ad4321f.png)

现在我们将运行一个决策树，但首先我们要运行一个网格搜索。

![](img/8eba7556c152aeace7c1e0219c619bb5.png)![](img/c1599950d69490f2eff2527061a34fcb.png)

在这之后，我们应该在 DT 上使用装袋。

![](img/7e84d550afe72f6389a34c98a567585f.png)

最后是随机森林和多余的树。

![](img/cf52f4a75b3e645bcc753df8a0b4dd32.png)![](img/17982b9f45a96311bc56c3fcbbdfa3fe.png)![](img/f0e089255b42d910ac4bd0901b0b84b0.png)

现在我们可以开始比较我们的模型了！首先，我们可以使用训练/测试分割来确定哪个模型执行得最好:

![](img/379b72c161d4461104a6af3db4beb0c1.png)

代替训练测试分割，我们可以看一个分层的 K 折叠来看模型在那里如何排列。

![](img/f04021bd40b1e67714934b20d3804d1c.png)![](img/de42829a1466885f295ba061122f7170.png)

在这两方面，我认为决策树上的网格搜索包做得最好。使用训练测试分割，它排名很高，虽然它接近分层 k-fold 的下端，但它的误差比一些更高的预成型模型低得多！