<html>
<head>
<title>Bringing Computer Vision Datasets to a Single Format: Step towards Consistency</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将计算机视觉数据集纳入单一格式:迈向一致性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bringing-computer-vision-datasets-to-a-single-format-step-towards-consistency-870b8323bcf0?source=collection_archive---------7-----------------------#2018-04-16">https://towardsdatascience.com/bringing-computer-vision-datasets-to-a-single-format-step-towards-consistency-870b8323bcf0?source=collection_archive---------7-----------------------#2018-04-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/1b88b97c5972207d5dbdb8e1fe9f2acf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*S1JKoaVemy_q6ZZ4XTVlkQ.jpeg"/></div></figure><p id="ee3f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">当你有一个好的工作算法，并且你想在一些数据集上测试你的杰作时，几乎总是要在数据的实际加载和预处理上花费相当多的时间。如果我们能够以一种单一的格式和一致的方式访问数据(例如，总是将训练图像存储在关键字“train/image”下)，那就太好了。</p><p id="5fbf" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在这里，我将分享一个由我编写的<a class="ae ks" href="https://github.com/thushv89/PreprocessingBenchmarkDatasets" rel="noopener ugc nofollow" target="_blank"> github repo </a>，它将几个流行的数据集转换为HDF5格式。当前支持以下数据集。</p><ul class=""><li id="c5e9" class="kt ku iq jw b jx jy kb kc kf kv kj kw kn kx kr ky kz la lb bi translated"><a class="ae ks" href="http://www.image-net.org/challenges/LSVRC/" rel="noopener ugc nofollow" target="_blank"> ILSVRC ImageNet </a></li><li id="ae80" class="kt ku iq jw b jx lc kb ld kf le kj lf kn lg kr ky kz la lb bi translated"><a class="ae ks" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR 10和CIFAR 100 </a>数据集</li><li id="4fec" class="kt ku iq jw b jx lc kb ld kf le kj lf kn lg kr ky kz la lb bi translated">数据集</li></ul><h1 id="139e" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">这段代码是做什么的？</h1><p id="40ac" class="pw-post-body-paragraph ju jv iq jw b jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn mj kp kq kr ij bi translated">所以这个仓库做了很多事情。首先让我告诉你组织。代码库非常简单。每个数据集都有一个文件来预处理数据并另存为HDF5(例如，对于Imagenet，我们有<code class="fe mk ml mm mn b">preprocess_imagenet.py</code>、CIFAR-10和CIFAR-100，我们有<code class="fe mk ml mm mn b">preprocess_cifar.py</code>，对于SVHN，我们有<code class="fe mk ml mm mn b">preprocess_svhn.py</code>)。实际上，每个文件都执行以下操作:</p><ul class=""><li id="acb6" class="kt ku iq jw b jx jy kb kc kf kv kj kw kn kx kr ky kz la lb bi translated">将原始数据载入内存</li><li id="806a" class="kt ku iq jw b jx lc kb ld kf le kj lf kn lg kr ky kz la lb bi translated">执行所需的任何整形，以使数据达到适当的维度(例如，cifar数据集将图像作为向量给出，因此需要将其转换为三维矩阵)</li><li id="a345" class="kt ku iq jw b jx lc kb ld kf le kj lf kn lg kr ky kz la lb bi translated">创建一个HDF5文件来保存数据</li><li id="2bd5" class="kt ku iq jw b jx lc kb ld kf le kj lf kn lg kr ky kz la lb bi translated">使用Python多重处理库，并根据用户规范处理每个图像</li></ul><p id="1ddc" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">下面我将告诉ImageNet文件是做什么的。这是最复杂的文件，其他的都很简单。</p><p id="31ac" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这里我讨论一下<code class="fe mk ml mm mn b">preprocess_imagenet.py</code>文件的作用。这基本上将ImageNet数据的子集保存为HDF5文件。该子集是属于许多自然类别(例如植物、猫)和人工类别(例如椅子、桌子)的数据。此外，您可以在保存数据时规范化数据。</p><p id="d2df" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">一旦运行脚本，<code class="fe mk ml mm mn b">save_imagenet_as_hdf5(...)</code>函数就会接管。该函数首先在有效的数据集文件名和标签之间创建一个映射(即<code class="fe mk ml mm mn b">build_or_retrieve_valid_filename_to_synset_id_mapping(...)</code>)。接下来，它用<code class="fe mk ml mm mn b">write_art_nat_ordered_class_descriptions(...)</code>或<code class="fe mk ml mm mn b">retrieve_art_nat_ordered_class_descriptions(...)</code>隔离与ImageNet数据集(1000个类)的分类问题相关的类。然后我们使用<code class="fe mk ml mm mn b">write_selected_art_nat_synset_ids_and_descriptions(...)</code>方法将选择的人工和自然类信息写入一个xml文件。</p><p id="adbc" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">接下来，我们扫描训练数据中的所有子目录，并将所有相关数据点放入内存。接下来，我们创建HDF文件来保存数据。这是通过<code class="fe mk ml mm mn b">save_train_data_in_filenames(...)</code>功能完成的。数据将保存在以下注册表项下:</p><ul class=""><li id="91fc" class="kt ku iq jw b jx jy kb kc kf kv kj kw kn kx kr ky kz la lb bi translated"><code class="fe mk ml mm mn b">/train/images/</code></li><li id="948c" class="kt ku iq jw b jx lc kb ld kf le kj lf kn lg kr ky kz la lb bi translated"><code class="fe mk ml mm mn b">/train/images/</code></li><li id="a2d6" class="kt ku iq jw b jx lc kb ld kf le kj lf kn lg kr ky kz la lb bi translated"><code class="fe mk ml mm mn b">/valid/images/</code></li><li id="15b3" class="kt ku iq jw b jx lc kb ld kf le kj lf kn lg kr ky kz la lb bi translated"><code class="fe mk ml mm mn b">/valid/images/</code></li></ul><h1 id="6427" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">稍后访问和加载数据</h1><p id="0622" class="pw-post-body-paragraph ju jv iq jw b jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn mj kp kq kr ij bi translated">您以后可以通过以下方式访问这些保存的数据:</p><pre class="mo mp mq mr gt ms mn mt mu aw mv bi"><span id="e864" class="mw li iq mn b gy mx my l mz na">dataset_file = h5py.File(“data” + os.sep + “filename.hdf5”, “r”)</span><span id="d34b" class="mw li iq mn b gy nb my l mz na">train_dataset, train_labels = dataset_file[‘/train/images’], dataset_file[‘/train/labels’]</span><span id="b83a" class="mw li iq mn b gy nb my l mz na">test_dataset, test_labels = dataset_file[‘/test/images’], dataset_file[‘/test/labels’]</span></pre><h1 id="3036" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">编码和进一步阅读</h1><p id="3678" class="pw-post-body-paragraph ju jv iq jw b jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn mj kp kq kr ij bi translated">代码可以在这里<a class="ae ks" href="https://github.com/thushv89/PreprocessingBenchmarkDatasets" rel="noopener ugc nofollow" target="_blank">获得</a>，你可以在我的<a class="ae ks" href="http://www.thushv.com/computer_vision/bringing-computer-vision-datasets-to-a-single-format-step-towards-consistency/" rel="noopener ugc nofollow" target="_blank">博客文章</a>中查看关于代码做什么以及如何运行的完整描述。</p><p id="c976" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><strong class="jw ir">注意:</strong>如果您在运行代码时看到任何问题或错误，请通过评论或在Github页面上打开问题让我知道。这将有助于我改进代码，消除任何讨厌的错误。</p><p id="e60f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">干杯！</p></div></div>    
</body>
</html>