<html>
<head>
<title>How to create and deploy a Kubeflow Machine Learning Pipeline (Part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何创建和部署 Kubeflow 机器学习管道(第 1 部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-create-and-deploy-a-kubeflow-machine-learning-pipeline-part-1-efea7a4b650f?source=collection_archive---------3-----------------------#2018-11-21">https://towardsdatascience.com/how-to-create-and-deploy-a-kubeflow-machine-learning-pipeline-part-1-efea7a4b650f?source=collection_archive---------3-----------------------#2018-11-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="47c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">谷歌云最近宣布了一个开源项目，以简化机器学习管道的操作。在本文中，我将带您了解使用<a class="ae kl" href="https://github.com/kubeflow/pipelines" rel="noopener ugc nofollow" target="_blank"> Kubeflow Pipelines </a>(本文中的 KFP)获取现有真实世界 TensorFlow 模型并操作化该模型的培训、评估、部署和再培训的过程。</p><p id="40ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本文的<a class="ae kl" href="https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/courses/machine_learning/deepdive/06_structured/pipelines" rel="noopener ugc nofollow" target="_blank">完整代码</a>在 GitHub 上。</p><h2 id="4a6b" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">1.创建一个安装了管道的 Kubernetes 集群(一次)</h2><p id="7cf7" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated"><strong class="jp ir"> <em class="lk">注</em> </strong> <em class="lk">:我写这篇文章的时候，托管管道还没有出现。创建安装了管道的 Kubernetes 集群的一个更简单的方法是遵循这个</em> <a class="ae kl" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/06_structured/pipelines/README.md" rel="noopener ugc nofollow" target="_blank"> <em class="lk">自述文件</em> </a> <em class="lk">中的步骤。如果你这样做了，继续从第二步开始读。</em></p><p id="d3a7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">KFP 自然需要 Kubernetes 集群来运行。使用此命令启动一个 Google Kubernetes 引擎(GKE)集群，并允许 KFP 管理该集群(repo 中的<a class="ae kl" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/06_structured/pipelines/1_create_cluster.sh" rel="noopener ugc nofollow" target="_blank"> create_cluster.sh </a>):</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="d1d5" class="km kn iq lq b gy lu lv l lw lx">#!/bin/bash<br/>  <br/>CLUSTERNAME=mykfp<br/>ZONE=us-central1-b</span><span id="995e" class="km kn iq lq b gy ly lv l lw lx">gcloud config set compute/zone $ZONE<br/>gcloud beta container clusters create $CLUSTERNAME \<br/>  --cluster-version 1.11.2-gke.18 --enable-autoupgrade \<br/>  --zone $ZONE \<br/>  --scopes cloud-platform \<br/>  --enable-cloud-logging \<br/>  --enable-cloud-monitoring \<br/>  --machine-type n1-standard-2 \<br/>  --num-nodes 4</span><span id="e0ca" class="km kn iq lq b gy ly lv l lw lx">kubectl create clusterrolebinding ml-pipeline-admin-binding --clusterrole=cluster-admin --user=$(gcloud config get-value account)</span></pre><p id="94ae" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">创建一个 GKE 集群大约需要 3 分钟，因此导航到 GCP 控制台的<a class="ae kl" href="https://console.cloud.google.com/kubernetes" rel="noopener ugc nofollow" target="_blank"> GKE 部分，并确保集群已经启动并准备就绪。</a></p><p id="d0a7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦集群启动，在 GKE 集群上安装 ML 管道(repo 中的<a class="ae kl" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/06_structured/pipelines/2_deploy_kubeflow_pipelines.sh" rel="noopener ugc nofollow" target="_blank">2 _ deploy _ kube flow _ pipelines . sh</a>):</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="b769" class="km kn iq lq b gy lu lv l lw lx">#!/bin/bash<br/>PIPELINE_VERSION=0.1.3<br/>kubectl create -f <a class="ae kl" href="https://storage.googleapis.com/ml-pipeline/release/$PIPELINE_VERSION/bootstrapper.yaml" rel="noopener ugc nofollow" target="_blank">https://storage.googleapis.com/ml-pipeline/release/$PIPELINE_VERSION/bootstrapper.yaml</a></span></pre><p id="a75a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在发布页面将上述版本更改为<a class="ae kl" href="https://github.com/kubeflow/pipelines/releases" rel="noopener ugc nofollow" target="_blank">最新版本。部署此包将需要几分钟时间。您可以查看作业的状态，并等待成功运行的次数变为 1。或者，您可以告诉 kubectl 等待创建完成:</a></p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="6744" class="km kn iq lq b gy lu lv l lw lx">#!/bin/bash</span><span id="0a99" class="km kn iq lq b gy ly lv l lw lx">jobname=$(kubectl get job | tail -1 | awk '{print $1}')<br/>kubectl wait --for=condition=complete --timeout=5m $jobname</span></pre><p id="235d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在等待软件安装完成时，您可以继续阅读！</p><figure class="ll lm ln lo gt ma gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/9456b69fb466e0e81cc70cd6c32d2a70.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*kjy6XowdG7lJGCew_iyqmw.png"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Buzzwords all the way down!</figcaption></figure><h2 id="1084" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">2.管道的描述</h2><p id="aba1" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">有几种方法可以创建管道。“dev-ops”的方式是使用 Python3 和 Docker。一种对数据科学家更友好的方式是使用 Jupyter 笔记本。在后面的帖子中，我将向您展示 Jupyter notebook 方法，但在这篇帖子中，我将向您展示 Python3-Docker 机制。理解这一点是有帮助的，这样当你走 Jupyter 路线时，你就知道幕后发生了什么。</p><p id="f0fc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我将通过机器学习模型来预测婴儿的体重。该模型有以下步骤:(a)从 BigQuery 中提取数据，对其进行转换，并将转换后的数据写入云存储。(b)训练张量流估计器 API 模型，并对模型进行超参数调整(c)一旦获得最佳学习速率、批量大小等。确定后，使用这些参数对模型进行更长时间的训练，并对更多数据进行训练(d)将训练好的模型部署到云 ML 引擎。</p><p id="7ba2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是描述上述管道的 Python 代码(repo 中的<a class="ae kl" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/06_structured/pipelines/mlp_babyweight.py" rel="noopener ugc nofollow" target="_blank"> mlp_babyweight.py </a>):</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="f2c7" class="km kn iq lq b gy lu lv l lw lx">preprocess = dsl.ContainerOp(<br/>  name=<strong class="lq ir">'preprocess'</strong>,<em class="lk"><br/>  </em>image=<strong class="lq ir">'gcr.io/cloud-training-demos/babyweight-pipeline-bqtocsv:latest'</strong>,<br/>  arguments=[<br/>    <strong class="lq ir">'--project'</strong>, project,<br/>    <strong class="lq ir">'--mode'</strong>, <strong class="lq ir">'cloud'</strong>,<br/>    <strong class="lq ir">'--bucket'</strong>, bucket<br/>  ],<br/>  file_outputs={<strong class="lq ir">'bucket'</strong>: <strong class="lq ir">'/output.txt'</strong>}<br/>)</span><span id="b7ea" class="km kn iq lq b gy ly lv l lw lx">hparam_train = dsl.ContainerOp(<br/>  name=<strong class="lq ir">'hypertrain'</strong>,<em class="lk"><br/>  </em>image=<strong class="lq ir">'gcr.io/cloud-training-demos/babyweight-pipeline-hypertrain:latest'</strong>,<br/>  arguments=[<br/>    preprocess.outputs[<strong class="lq ir">'bucket'</strong>]<br/>  ],<br/>  file_outputs={<strong class="lq ir">'jobname'</strong>: <strong class="lq ir">'/output.txt'</strong>}<br/>)</span><span id="642e" class="km kn iq lq b gy ly lv l lw lx">train_tuned = dsl.ContainerOp(<br/>  name=<strong class="lq ir">'traintuned'</strong>,<em class="lk"><br/>  </em>image=<strong class="lq ir">'gcr.io/cloud-training-demos/babyweight-pipeline-traintuned-trainer:latest'</strong>,<em class="lk"><br/>  </em>arguments=[<br/>    hparam_train.outputs[<strong class="lq ir">'jobname'</strong>],<br/>    bucket<br/>  ],<br/>  file_outputs={<strong class="lq ir">'train'</strong>: <strong class="lq ir">'/output.txt'</strong>}<br/>)<br/>train_tuned.set_memory_request(<strong class="lq ir">'2G'</strong>)<br/>train_tuned.set_cpu_request(<strong class="lq ir">'1'</strong>)</span><span id="fc1d" class="km kn iq lq b gy ly lv l lw lx">deploy_cmle = dsl.ContainerOp(<br/>  name=<strong class="lq ir">'deploycmle'</strong>,<em class="lk"><br/>  </em>image=<strong class="lq ir">'gcr.io/cloud-training-demos/babyweight-pipeline-deploycmle:latest'</strong>,<br/>  arguments=[<br/>    train_tuned.outputs[<strong class="lq ir">'train'</strong>],  <em class="lk"># modeldir<br/>    </em><strong class="lq ir">'babyweight'</strong>,<br/>    <strong class="lq ir">'mlp'<br/>  </strong>],<br/>  file_outputs={<br/>    <strong class="lq ir">'model'</strong>: <strong class="lq ir">'/model.txt'</strong>,<br/>    <strong class="lq ir">'version'</strong>: <strong class="lq ir">'/version.txt'<br/>  </strong>}<br/>)</span></pre><p id="47c1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面的每个步骤都是一个 Docker 容器。Docker 容器的输出是另一个后续步骤的输入——它是一个有向无环图，当加载到 pipelines UI 中时，将如下所示:</p><figure class="ll lm ln lo gt ma gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/d9bd46017835f7640ede519d139fc62f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*w5KUdWFyxdoJ1UISLfDJ7g.png"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk">ML Pipeline</figcaption></figure><p id="05b3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(完整的端到端应用程序还包括第五步，部署 web 应用程序，为模型提供用户界面。)</p><p id="3d74" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">看一下预处理步骤:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="3c32" class="km kn iq lq b gy lu lv l lw lx">preprocess = dsl.ContainerOp(<br/>  name=<strong class="lq ir">'preprocess'</strong>,<em class="lk"><br/>  </em>image=<strong class="lq ir">'gcr.io/cloud-training-demos/babyweight-pipeline-bqtocsv:latest'</strong>,<br/>  arguments=[<br/>    <strong class="lq ir">'--project'</strong>, project,<br/>    <strong class="lq ir">'--mode'</strong>, <strong class="lq ir">'cloud'</strong>,<br/>    <strong class="lq ir">'--bucket'</strong>, bucket<br/>  ],<br/>  file_outputs={<strong class="lq ir">'bucket'</strong>: <strong class="lq ir">'/output.txt'</strong>}<br/>)</span></pre><p id="867d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意，它使用两个输入参数——项目和存储桶——并将其输出(包含预处理数据的存储桶)放在/output.txt 中。</p><p id="6669" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，第二步使用 preprocess.outputs['bucket']获取该存储桶名称，并将其输出(性能最高的超参数调优试验的作业名称)作为 hparam _ train . outputs[' job name ']供管道的第三步使用。</p><p id="bbae" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">相当简单！</p><p id="ba62" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当然，这回避了两个问题:第一步如何获得它需要的项目和桶？第二，各个步骤是如何实现的？</p><p id="0cd2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">项目和桶是通过管道参数得到的:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="369b" class="km kn iq lq b gy lu lv l lw lx">def train_and_deploy(<br/>    project='cloud-training-demos',<br/>    bucket='cloud-training-demos-ml'<br/>):</span></pre><p id="81ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本质上，项目和存储桶将由最终用户在管道运行时提供。UI 将预先填充我在上面提供的默认值:</p><figure class="ll lm ln lo gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mi"><img src="../Images/a649860babafd3dc29aae34cd72b13e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EJsvsincg05N0MMLh5UAZQ.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Pipeline parameters are provided by the end-user</figcaption></figure><p id="ce0a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本节的其余部分是关于如何实现各个步骤的。再次，正如我提到的，我将解释 Python3-Docker 的实现方式。在以后的文章中，我会解释 Jupyter 的方法。所以，如果你确信你永远不会走码头工人这条路，只需略读这一部分或者直接跳到第三部分。</p><h2 id="7c91" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">2a。预处理</h2><p id="fe27" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">在每一步中，您都需要创建一个 Docker 容器。这本质上是一个独立的程序(bash、Python、C++，无论什么),它的所有依赖项都被很好地指定，这样它就可以在集群上由 KFP 运行。</p><p id="a7da" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我的例子中，我的预处理代码是一个独立的 Python 程序，它使用 Apache Beam 并期望在云数据流上运行。所有代码都在一个名为<a class="ae kl" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/06_structured/pipelines/containers/bqtocsv/transform.py" rel="noopener ugc nofollow" target="_blank"> transform.py </a>的命令行程序中:</p><figure class="ll lm ln lo gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mn"><img src="../Images/697f851d8d249551efcb3d83d92048d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z1Nf1vhUt7W1mQSgOKtB7A.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">The preprocessing code is all in a single file called transform.py</figcaption></figure><p id="573f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我的 Dockerfile 文件必须指定所有的依赖项。幸运的是，KFP 有一堆样本容器，其中一个有我需要的所有依赖项。所以，我只是继承了它。因此，我的<a class="ae kl" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/06_structured/pipelines/containers/bqtocsv/Dockerfile" rel="noopener ugc nofollow" target="_blank"> Dockerfile </a>是全部 4 行:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="42ea" class="km kn iq lq b gy lu lv l lw lx">FROM gcr.io/ml-pipeline/ml-pipeline-dataflow-tft:latest<br/>RUN mkdir /babyweight<br/>COPY transform.py /babyweight<br/>ENTRYPOINT ["python", "/babyweight/transform.py"]</span></pre><p id="da92" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本质上，我将 transform.py 复制到 Docker 容器中，并说入口点是执行该文件。</p><p id="073b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我可以构建我的 Docker 容器，并在我的项目中的 gcr.io 中将其发布在<a class="ae kl" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/06_structured/pipelines/containers/bqtocsv/build.sh" rel="noopener ugc nofollow" target="_blank"> build.sh </a>中:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="9a55" class="km kn iq lq b gy lu lv l lw lx">CONTAINER_NAME=babyweight-pipeline-bqtocsv</span><span id="0ab4" class="km kn iq lq b gy ly lv l lw lx">docker build -t ${CONTAINER_NAME} .<br/>docker tag ${CONTAINER_NAME} gcr.io/${PROJECT_ID}/${CONTAINER_NAME}:${TAG_NAME}<br/>docker push gcr.io/${PROJECT_ID}/${CONTAINER_NAME}:${TAG_NAME}</span></pre><p id="1e35" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当然，这是我为预处理步骤指定的 image_name。</p><h2 id="1849" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">2b。CMLE 上的训练和超参数调整</h2><p id="40e2" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">我将使用<a class="ae kl" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/06_structured/pipelines/containers/hypertrain/train.sh" rel="noopener ugc nofollow" target="_blank"> bash 在云 ML 引擎上进行训练和超参数调优，以使用 gcloud </a>提交作业:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="0b89" class="km kn iq lq b gy lu lv l lw lx">gcloud ml-engine jobs submit training $JOBNAME \<br/>  --region=$REGION \<br/>  --module-name=trainer.task \<br/>  --package-path=${CODEDIR}/babyweight/trainer \<br/>  --job-dir=$OUTDIR \<br/>  --staging-bucket=gs://$BUCKET \<br/>  --scale-tier=STANDARD_1 \<br/>  --config=hyperparam.yaml \<br/>  --runtime-version=$TFVERSION \<br/><strong class="lq ir">  --stream-logs</strong> \<br/>  -- \<br/>  --bucket=${BUCKET} \<br/>  --output_dir=${OUTDIR} \<br/>  --eval_steps=10 \<br/>  --train_examples=20000</span><span id="36ba" class="km kn iq lq b gy ly lv l lw lx"># write output file for next step in pipeline<br/>echo $JOBNAME &gt; /output.txt</span></pre><p id="854a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，我使用了 gcloud 命令等待完成的-stream-logs，并注意我写出了 jobname，它是管道代码中以下步骤的契约的一部分。</p><p id="d4cd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这一次，我将通过从一个已经安装了 gcloud 的容器继承来创建<a class="ae kl" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/06_structured/pipelines/containers/hypertrain/Dockerfile" rel="noopener ugc nofollow" target="_blank">我的 Dockerfile </a>，并且 git 克隆包含实际教练代码的存储库:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="5613" class="km kn iq lq b gy lu lv l lw lx">FROM google/cloud-sdk:latest</span><span id="c689" class="km kn iq lq b gy ly lv l lw lx">RUN mkdir -p /babyweight/src &amp;&amp; \<br/>    cd /babyweight/src &amp;&amp; \<br/>    git clone <a class="ae kl" href="https://github.com/GoogleCloudPlatform/training-data-analyst" rel="noopener ugc nofollow" target="_blank">https://github.com/GoogleCloudPlatform/training-data-analyst</a></span><span id="fc01" class="km kn iq lq b gy ly lv l lw lx">COPY train.sh hyperparam.yaml ./</span><span id="c6a8" class="km kn iq lq b gy ly lv l lw lx">ENTRYPOINT ["bash", "./train.sh"]</span></pre><h2 id="b7d1" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">2c。在 Kubernetes 上进行本地培训</h2><p id="52e2" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">上面的预处理和超参数调优步骤利用了托管服务。KFP 所做的只是提交作业，并允许托管服务完成它们的工作。在 KFP 运行的 Kubernetes 集群上做点什么怎么样？</p><p id="2105" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了稍微混淆一下，让我在 GKE 集群上本地执行下一步(培训)。为此，我可以简单地运行一个直接调用 python 的 Docker 容器:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="7048" class="km kn iq lq b gy lu lv l lw lx">NEMBEDS=$(gcloud ml-engine jobs describe $HYPERJOB --format 'value(trainingOutput.trials.hyperparameters.nembeds.slice(0))')<br/>TRIALID=$(gcloud ml-engine jobs describe $HYPERJOB --format 'value(trainingOutput.trials.trialId.slice(0))')</span><span id="4712" class="km kn iq lq b gy ly lv l lw lx">...</span><span id="cceb" class="km kn iq lq b gy ly lv l lw lx">OUTDIR=gs://${BUCKET}/babyweight/hyperparam/$TRIALID<br/>python3 -m trainer.task \<br/>  --job-dir=$OUTDIR \<br/>  --bucket=${BUCKET} \<br/>  --output_dir=${OUTDIR} \<br/>  --eval_steps=10 \<br/>  --nnsize=$NNSIZE \<br/>  --batch_size=$BATCHSIZE \<br/>  --nembeds=$NEMBEDS \<br/>  --train_examples=200000</span></pre><p id="6ffd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在集群本身上执行作业有一个问题。您如何知道集群没有在执行耗尽所有可用内存的任务呢？traintuned 容器操作“保留”了必要数量的内存和 CPU。只有当必要的资源可用时，kubeflow 才会安排作业:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="6d50" class="km kn iq lq b gy lu lv l lw lx">train_tuned.set_memory_request('2G')<br/>train_tuned.set_cpu_request('1')</span></pre><h2 id="38fb" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">2d。部署到云 ML 引擎</h2><p id="b2b4" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated"><a class="ae kl" href="https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/courses/machine_learning/deepdive/06_structured/pipelines/containers/deploycmle" rel="noopener ugc nofollow" target="_blank">部署到云 ML 引擎</a>也使用 gcloud，所以那个目录下的 deploy.sh 和 build.sh 应该看起来很熟悉:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="df1f" class="km kn iq lq b gy lu lv l lw lx">gcloud ml-engine versions create ${MODEL_VERSION} \<br/>       --model ${MODEL_NAME} --origin ${MODEL_LOCATION} \<br/>       --runtime-version $TFVERSION</span><span id="e9a3" class="km kn iq lq b gy ly lv l lw lx">echo $MODEL_NAME &gt; /model.txt<br/>echo $MODEL_VERSION &gt; /version.txt</span></pre><p id="2827" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">和</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="bc09" class="km kn iq lq b gy lu lv l lw lx">FROM google/cloud-sdk:latest</span><span id="aaa0" class="km kn iq lq b gy ly lv l lw lx">RUN mkdir -p /babyweight/src &amp;&amp; \<br/>    cd /babyweight/src &amp;&amp; \<br/>    git clone <a class="ae kl" href="https://github.com/GoogleCloudPlatform/training-data-analyst" rel="noopener ugc nofollow" target="_blank">https://github.com/GoogleCloudPlatform/training-data-analyst</a></span><span id="195b" class="km kn iq lq b gy ly lv l lw lx">COPY deploy.sh ./</span><span id="bb70" class="km kn iq lq b gy ly lv l lw lx">ENTRYPOINT ["bash", "./deploy.sh"]</span></pre><p id="7ea0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如我们在 Kubernetes 集群上培训一样，我们也可以在 Kubernetes 本身上部署(参见<a class="ae kl" href="https://github.com/kubeflow/pipelines/tree/master/components/kubeflow" rel="noopener ugc nofollow" target="_blank">这个组件中的一个例子</a>)。</p><h2 id="c5b4" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">2e。编译 DSL</h2><p id="0dd1" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">现在，所有步骤的 Docker 容器都已构建完毕，我们可以将管道提交给 KFP 了，只是……KFP 要求我们将管道 Python3 文件编译成特定于领域的语言。我们使用 Python3 SDK 附带的一个名为 dsl-compile 的工具来完成这项工作。所以，先安装那个 SDK ( <a class="ae kl" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/06_structured/pipelines/3_install_sdk.sh" rel="noopener ugc nofollow" target="_blank"> 3_install_sdk.sh </a>):</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="f233" class="km kn iq lq b gy lu lv l lw lx">pip3 install python-dateutil <a class="ae kl" href="https://storage.googleapis.com/ml-pipeline/release/0.1.2/kfp.tar.gz" rel="noopener ugc nofollow" target="_blank">https://storage.googleapis.com/ml-pipeline/release/0.1.2/kfp.tar.gz</a> --upgrade</span></pre><p id="9528" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，使用以下代码编译 DSL:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="8b50" class="km kn iq lq b gy lu lv l lw lx">python3 mlp_babyweight.py mlp_babyweight.tar.gz</span></pre><p id="bf94" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">或者，您可以通过以下方式将包含 dsl-compile 的目录添加到您的路径中</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="dcf0" class="km kn iq lq b gy lu lv l lw lx">export PATH=”$PATH:`python -m site --user-base`/bin</span></pre><p id="8fe8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后调用编译器:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="e8fd" class="km kn iq lq b gy lu lv l lw lx">dsl-compile --py mlp_babyweight.py --output mlp_babyweight.tar.gz</span></pre><p id="49d5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在第 3 节中，您将把这个 tar 文件上传到 ML pipelines UI。</p><h2 id="c45c" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">3.上传管道</h2><p id="e3f3" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">用户界面服务器在端口 80 的 GKE 集群上运行。进行端口转发，以便您可以通过端口 8085 ( <a class="ae kl" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/06_structured/pipelines/4_start_ui.sh" rel="noopener ugc nofollow" target="_blank"> 4_start_ui.sh </a>)从笔记本电脑访问它:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="5678" class="km kn iq lq b gy lu lv l lw lx">export NAMESPACE=kubeflow<br/>kubectl port-forward -n ${NAMESPACE} $(kubectl get pods -n ${NAMESPACE} --selector=service=ambassador -o jsonpath='{.items[0].metadata.name}') 8085:80</span></pre><p id="5254" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，打开浏览器到<a class="ae kl" href="http://localhost:8085/pipeline." rel="noopener ugc nofollow" target="_blank">http://localhost:8085/pipeline</a>，切换到 Pipelines 选项卡。然后，上传在 2e 小节中创建的 tar.gz 文件作为管道。</p><p id="412d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这只是使图表可用。您可能会使用各种设置组合来运行它。所以，开始一个实验来保持所有这些运行。我将我的实验命名为“博客”，然后创建了一个 run。我将该运行命名为“try1 ”,并使用刚刚上传的管道进行设置:</p><figure class="ll lm ln lo gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mo"><img src="../Images/cb18b7cd3768ac87f67a9139d18b2667.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RJw7ShaUShFdBq9WJG_yUw.png"/></div></div></figure><p id="f821" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">管道现在开始运行。我可以看到正在执行的每个步骤以及每个步骤的日志:</p><figure class="ll lm ln lo gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi ca"><img src="../Images/6145d045e4883560d04fef66bad60558.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i-dJQVrtbPzsDCNAoL017w.png"/></div></div></figure><figure class="ll lm ln lo gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mp"><img src="../Images/0f2614093c1f61f17b86e7e92b409ea4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xB5h0xy96WQpJSu2QTbfHQ.png"/></div></div></figure><h2 id="acc8" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">4.实验、开发、再培训、评估…</h2><p id="4f6a" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">完整的源代码包括一些我忽略的东西。显然，完整的代码看起来并不完整，而且第一次也没有成功。我没有每次都从头开始管道，而是设置了管道，这样我就可以从任何一步开始(我正在处理的那一步)。</p><p id="a9ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是，每一步都依赖于前一步的输出。如何做到这一点？这是我的解决方案:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="c1cc" class="km kn iq lq b gy lu lv l lw lx"> <strong class="lq ir">if start_step &lt;= 2:</strong><br/>    hparam_train = dsl.ContainerOp(<br/>      name='hypertrain',<br/>      # image needs to be a compile-time string<br/>      image='gcr.io/cloud-training-demos/babyweight-pipeline-hypertrain:latest',<br/>      arguments=[<br/>        preprocess.outputs['bucket']<br/>      ],<br/>      file_outputs={'jobname': '/output.txt'}<br/>    )<br/>  <strong class="lq ir">else:<br/>    hparam_train = ObjectDict({<br/>      'outputs': {<br/>        'jobname': 'babyweight_181008_210829'<br/>      }<br/>    })</strong></span></pre><p id="6f8f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本质上，如果 start_step ≤ 2，就会创建容器 op。否则，我只需用上一步的“已知”输出创建一个字典。这样，我可以简单地将 start_step 设置为 4，跳过前面的步骤，从第 4 步开始。然而，后面的步骤将具有它们期望的来自任何先前步骤的输入。</p><p id="a64a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我的实验包括几次运行:</p><figure class="ll lm ln lo gt ma gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/9bcdb7e47309f9250b26a09e0796d013.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*YA5TBm0JCE8H_6aEhr3g3Q.png"/></div></figure><p id="95b7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">比如 try1 成功运行 3 步后失败，我可以从第 4 步开始。我需要两次尝试才能完成第四步。然后，我添加了步骤 5(部署一个 AppEngine 应用程序到 web 服务的前端)。然后，我回去尝试了阶段 3 的不同变化。</p><h2 id="c835" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">4b。再训练</h2><p id="72a3" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">当然，你不会训练一个模型一次就让它永远消失(是吗？).一旦有了更多的数据，您将需要重新训练模型。在我们的婴儿体重模型中，一旦我们有了一年的数据，我们可以想象重新训练模型。我在管道中处理这种情况的方法是请求一个 startYear 作为输入参数:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="c391" class="km kn iq lq b gy lu lv l lw lx">def train_and_deploy(<br/>    project=dsl.PipelineParam(name='project', value='cloud-training-demos'),<br/>    bucket=dsl.PipelineParam(name='bucket', value='cloud-training-demos-ml'),<br/>    startYear=dsl.PipelineParam(name='startYear', value='2000')<br/>):</span></pre><p id="3547" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">bqtocsv 步骤中的预处理代码仅提取起始年份或之后的行:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="7a78" class="km kn iq lq b gy lu lv l lw lx">WHERE year &gt;= start_year</span></pre><p id="0ded" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">并命名输出文件，这样它们就不会破坏前面的输出:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="1c4d" class="km kn iq lq b gy lu lv l lw lx">os.path.join(OUTPUT_DIR, 'train_{}.csv', start_year)</span></pre><p id="9be7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">训练现在在更大的数据集上进行，因为模式匹配是针对 train*。就是这样！</p><p id="f0b9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当然，还有其他方法来处理再培训。我们可以采用以前的模型，只根据更新的数据进行训练。像这样的语义并不难合并——使用命名约定来帮助管道做正确的事情。</p><h2 id="04e5" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">4c。评价？笔记本？</h2><p id="ba25" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">当然，通常情况下，您不会立即将一个经过训练的模型推向生产。相反，在转换所有流量之前，您将进行一些评估，也许是 A/B 测试。</p><p id="33b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，您倾向于不在 Docker 容器中开发。我在这里很幸运，因为我的 babyweight 模型几乎是一个 Python 包，并且非常方便归档。如果您在 Jupyter 笔记本上完成所有的模型开发，会怎么样？</p><p id="605c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如何进行评估，以及如何将笔记本转换为管道是另一篇博文的主题。注意这个空间。</p><h2 id="9ddf" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">5.动手吧！</h2><p id="577c" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">本文的<a class="ae kl" href="https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/courses/machine_learning/deepdive/06_structured/pipelines" rel="noopener ugc nofollow" target="_blank">完整代码</a>在 GitHub 上。克隆 repo 并按照自述文件中的步骤操作。</p><p id="bba4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">另外，请阅读<a class="ae kl" href="https://cloud.google.com/blog/products/ai-machine-learning/getting-started-kubeflow-pipelines" rel="noopener ugc nofollow" target="_blank"> Amy Unruh 关于 Kubeflow 管道入门的博文</a>。</p></div></div>    
</body>
</html>