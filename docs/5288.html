<html>
<head>
<title>A Primer on how to optimize the Learning Rate of Deep Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于如何优化深度神经网络学习速率的初级读本</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learning-rate-a6e7b84f1658?source=collection_archive---------6-----------------------#2018-10-09">https://towardsdatascience.com/learning-rate-a6e7b84f1658?source=collection_archive---------6-----------------------#2018-10-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/495897678641e5b6ef7822002f8b7dc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*mJaKTcmR1doWqGrS"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><a class="ae jd" href="https://unsplash.com/@victoire_jonch?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Victoire Joncheray</a> on <a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><p id="3ed1" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">训练深度神经网络时的一个主要挑战是平衡最终解决方案的质量和达到最终解决方案所需的训练时间。学习率是优化这种平衡的最重要的超参数。</p><p id="57fb" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以认为小学习率和大学习率具有不同的个性:</p><ul class=""><li id="88fe" class="lb lc jg kf b kg kh kk kl ko ld ks le kw lf la lg lh li lj bi translated">小学习率谨慎。也就是说，它使网络缓慢而小心地调整。</li><li id="4a5b" class="lb lc jg kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">学习率大就是浮躁。也就是说，它调整得很快，但可能会超调。</li></ul><p id="4bf5" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当你做深度学习时，你想让网络同时快速而精确地学习。在这篇文章中，我向你展示了三种不同的选择，在谨慎和浮躁之间找到平衡:</p><ol class=""><li id="ca43" class="lb lc jg kf b kg kh kk kl ko ld ks le kw lf la lp lh li lj bi translated">决定一个既不太低也不太高的学习率，即找到最佳的折衷。</li><li id="e848" class="lb lc jg kf b kg lk kk ll ko lm ks ln kw lo la lp lh li lj bi translated">一旦你接近一个最佳解决方案，在训练期间从高到低调整学习速率以减慢速度。</li><li id="1090" class="lb lc jg kf b kg lk kk ll ko lm ks ln kw lo la lp lh li lj bi translated">在高学习率和低学习率之间摇摆，创造一个混合体。</li></ol><p id="116d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇文章是作为一个引子，并不涵盖细节。如果你想了解更多，我推荐 Pavel Surmenok 的这篇文章:</p><div class="ip iq gp gr ir ls"><a rel="noopener follow" target="_blank" href="/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0"><div class="lt ab fo"><div class="lu ab lv cl cj lw"><h2 class="bd jh gy z fp lx fr fs ly fu fw jf bi translated">估计深度神经网络的最佳学习速率</h2><div class="lz l"><h3 class="bd b gy z fp lx fr fs ly fu fw dk translated">学习率是用于训练深度神经网络的最重要的超参数之一。</h3></div><div class="ma l"><p class="bd b dl z fp lx fr fs ly fu fw dk translated">towardsdatascience.com</p></div></div><div class="mb l"><div class="mc l md me mf mb mg ix ls"/></div></div></a></div></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><h2 id="3337" class="mo mp jg bd mq mr ms dn mt mu mv dp mw ko mx my mz ks na nb nc kw nd ne nf ng bi translated">选择 1:折衷——固定学习率</h2><p id="865a" class="pw-post-body-paragraph kd ke jg kf b kg nh ki kj kk ni km kn ko nj kq kr ks nk ku kv kw nl ky kz la ij bi translated">最基本的方法是坚持默认值，并希望最好的结果。</p><p id="5a73" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一个选项的更好实现是测试各种可能的值。根据损失的变化，你可以选择更高或更低的学习率。目标是找到仍能减少损失的最快速度。</p><p id="4b0c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">鉴于这种选择的简单性，固定的学习率会让你走得比你预期的更远。然而，还有更好的选择。</p></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><h2 id="afb8" class="mo mp jg bd mq mr ms dn mt mu mv dp mw ko mx my mz ks na nb nc kw nd ne nf ng bi translated">选项 2:顺序——随着时间的推移，学习率降低</h2><p id="3679" class="pw-post-body-paragraph kd ke jg kf b kg nh ki kj kk ni km kn ko nj kq kr ks nk ku kv kw nl ky kz la ij bi translated">第二种选择是以高学习速率开始，以利用速度优势，然后切换到低学习速率，以优化结果。有两种主要的变化。</p><p id="caaf" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，你可以根据损失函数的变化来调整学习速率。也就是说，每当损失函数停止改进时，你就降低学习速率以进一步优化。</p><p id="6223" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第二，您可以应用更平滑的函数形式，并根据训练时间调整学习速率。也就是说，学习率的降低与损失函数没有直接关系。</p><p id="00b3" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与固定学习率相比，这两种方法及其变体都是改进，因为它们结合了小学习率和大学习率的优点。然而，还有更大的改进余地。</p></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><h2 id="85bd" class="mo mp jg bd mq mr ms dn mt mu mv dp mw ko mx my mz ks na nb nc kw nd ne nf ng bi translated">选项 3:混合式学习率——走走停停</h2><p id="be88" class="pw-post-body-paragraph kd ke jg kf b kg nh ki kj kk ni km kn ko nj kq kr ks nk ku kv kw nl ky kz la ij bi translated">主要的想法是，由快转慢非常有帮助，我们应该在训练中不止一次地这样做。还有两个额外的优势:</p><ol class=""><li id="f633" class="lb lc jg kf b kg kh kk kl ko ld ks le kw lf la lp lh li lj bi translated">跳回到高学习率有助于避免局部最优。</li><li id="dbac" class="lb lc jg kf b kg lk kk ll ko lm ks ln kw lo la lp lh li lj bi translated">高学习率在穿过损失函数的平坦区域时更快。</li></ol><p id="cf55" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">综上所述，第三种选择是将第二种选择重复几次。</p></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><h2 id="141a" class="mo mp jg bd mq mr ms dn mt mu mv dp mw ko mx my mz ks na nb nc kw nd ne nf ng bi translated">但是我们没有优化算法吗？</h2><p id="deeb" class="pw-post-body-paragraph kd ke jg kf b kg nh ki kj kk ni km kn ko nj kq kr ks nk ku kv kw nl ky kz la ij bi translated"><strong class="kf jh">是的</strong>，因为最先进的优化算法，如<em class="nm">亚当</em>根据训练过程改变每个人体重的学习率。如果你想更多地了解亚当，我推荐这篇博文:</p><div class="ip iq gp gr ir ls"><a href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/" rel="noopener  ugc nofollow" target="_blank"><div class="lt ab fo"><div class="lu ab lv cl cj lw"><h2 class="bd jh gy z fp lx fr fs ly fu fw jf bi translated">深度学习的 Adam 优化算法简介</h2><div class="lz l"><h3 class="bd b gy z fp lx fr fs ly fu fw dk translated">你的深度学习模型的优化算法的选择可能意味着良好结果之间的差异…</h3></div><div class="ma l"><p class="bd b dl z fp lx fr fs ly fu fw dk translated">machinelearningmastery.com</p></div></div><div class="mb l"><div class="nn l md me mf mb mg ix ls"/></div></div></a></div><p id="b2a0" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">没有</strong>，因为即使是<em class="nm"> Adam </em>也有两个与学习率相关的参数，分别是<code class="fe no np nq nr b">lr</code>用于学习率和<code class="fe no np nq nr b">decay</code> ( <a class="ae jd" href="https://keras.io/optimizers/" rel="noopener ugc nofollow" target="_blank">参见<em class="nm"> Keras </em>实现</a>)。也就是说，<em class="nm"> Adam </em>需要一个学习速率来开始，以及它是否应该包括衰减函数的信息。如果你想使用这些参数，你需要考虑如何应用选项 1 和 2。</p><p id="36b7" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">还有一种算法实现了选项 3。它被称为<em class="nm">重启的随机梯度下降</em>，并由<a class="lq lr ep" href="https://medium.com/u/cc8070255a47?source=post_page-----a6e7b84f1658--------------------------------" rel="noopener" target="_blank">马克·霍夫曼</a>进行了精彩的解释:</p><div class="ip iq gp gr ir ls"><a href="https://medium.com/38th-street-studios/exploring-stochastic-gradient-descent-with-restarts-sgdr-fa206c38a74e" rel="noopener follow" target="_blank"><div class="lt ab fo"><div class="lu ab lv cl cj lw"><h2 class="bd jh gy z fp lx fr fs ly fu fw jf bi translated">探索重新开始的随机梯度下降(SGDR)</h2><div class="lz l"><h3 class="bd b gy z fp lx fr fs ly fu fw dk translated">这是我第一篇深度学习的博文。我在 2017 年 1 月左右开始了我的深度学习之旅，在我听说了…</h3></div><div class="ma l"><p class="bd b dl z fp lx fr fs ly fu fw dk translated">medium.com</p></div></div><div class="mb l"><div class="ns l md me mf mb mg ix ls"/></div></div></a></div></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><figure class="nu nv nw nx gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nt"><img src="../Images/162cb3e3a0cac11779582ac14b01eac9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wcJv3IPsW0_luRSZ"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><a class="ae jd" href="https://unsplash.com/@jens_johnsson?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jens Johnsson</a> on <a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="1be2" class="mo mp jg bd mq mr ms dn mt mu mv dp mw ko mx my mz ks na nb nc kw nd ne nf ng bi translated">你下一步应该做什么</h2><p id="ace1" class="pw-post-body-paragraph kd ke jg kf b kg nh ki kj kk ni km kn ko nj kq kr ks nk ku kv kw nl ky kz la ij bi translated">我所知道的关于深度学习的最好的课程是由<em class="nm"> fast.ai </em>公开提供的课程。还有同一个团队写的刚到 1.0 版本的 Python 包，如果你关心深度学习，<a class="ae jd" href="http://course.fast.ai/lessons/lesson1.html" rel="noopener ugc nofollow" target="_blank">到这里上第一堂课</a>。</p></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><p id="aa6d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">总体来说，你对学习率和训练深度学习有什么看法？请在评论中或在<a class="ae jd" href="https://twitter.com/TimoBohm" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上告诉我。我也很乐意在 LinkedIn 上联系。<strong class="kf jh">感谢阅读，留点👏🏻如果这对你有帮助，让我们继续学习吧！</strong></p></div></div>    
</body>
</html>