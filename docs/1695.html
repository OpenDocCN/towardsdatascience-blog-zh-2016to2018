<html>
<head>
<title>October Edition: Text Understanding</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">十月版:课文理解</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/october-edition-text-understanding-c3594faf2964?source=collection_archive---------7-----------------------#2017-10-04">https://towardsdatascience.com/october-edition-text-understanding-c3594faf2964?source=collection_archive---------7-----------------------#2017-10-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0172" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">9篇必读文章</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/6589210d600acd115588e340889b4632.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eIRJ7hOFhrfyftvgTKKcQg.jpeg"/></div></div></figure><h2 id="7613" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><a class="ae ln" href="https://medium.com/towards-data-science/how-to-get-started-in-nlp-6a62aa4eaeff" rel="noopener">如何开始使用NLP </a></h2><p id="3a4a" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw la lx ly lz le ma mb mc li md me mf mg ij bi translated">由<a class="mh mi ep" href="https://medium.com/u/2293e00f0e75?source=post_page-----c3594faf2964--------------------------------" rel="noopener" target="_blank">梅勒妮·托西克</a> — 3分钟阅读。</p><p id="7ad6" class="pw-post-body-paragraph lo lp iq lq b lr mj jr lt lu mk ju lw la ml ly lz le mm mb mc li mn me mf mg ij bi translated">我在某处读到过，如果你不得不回答同一个问题两次，把它变成一篇博客文章可能是个好主意。为了遵守这条规则，也为了给我未来的自己节省一些时间，现在我对这个问题的标准答案是:我的背景是科学，我对学习NLP感兴趣。</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h2 id="fa8d" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><a class="ae ln" href="https://medium.com/towards-data-science/word-vectors-for-non-nlp-data-and-research-people-8d689c692353" rel="noopener">非NLP数据和研究人员的词向量</a></h2><p id="6e71" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw la lx ly lz le ma mb mc li md me mf mg ij bi translated">通过<a class="mh mi ep" href="https://medium.com/u/c8ea102f0a01?source=post_page-----c3594faf2964--------------------------------" rel="noopener" target="_blank">康纳麦当劳</a> — 8分钟阅读。</p><p id="3f74" class="pw-post-body-paragraph lo lp iq lq b lr mj jr lt lu mk ju lw la ml ly lz le mm mb mc li mn me mf mg ij bi translated">单词向量代表了在提高我们分析单词、句子和文档之间关系的能力方面的一个重大飞跃。</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h2 id="d2bf" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><a class="ae ln" href="https://medium.com/towards-data-science/a-non-nlp-application-of-word2vec-c637e35d3668" rel="noopener">word 2 vec的非自然语言处理应用</a></h2><p id="1d01" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw la lx ly lz le ma mb mc li md me mf mg ij bi translated">通过<a class="mh mi ep" href="https://medium.com/u/1354d75818ea?source=post_page-----c3594faf2964--------------------------------" rel="noopener" target="_blank"> Kwyk </a> — 6分钟读取。</p><p id="64d0" class="pw-post-body-paragraph lo lp iq lq b lr mj jr lt lu mk ju lw la ml ly lz le mm mb mc li mn me mf mg ij bi translated">当使用<strong class="lq ir">机器学习</strong>解决问题时，拥有正确的<strong class="lq ir">数据</strong>至关重要。不幸的是，原始数据通常是“不干净的”和<strong class="lq ir">非结构化的</strong>。<a class="ae ln" href="https://en.wikipedia.org/wiki/Natural_language_processing" rel="noopener ugc nofollow" target="_blank">自然语言处理</a> ( <strong class="lq ir"> NLP </strong> ) <strong class="lq ir"> </strong>从业者对这个问题很熟悉，因为他们所有的数据都是<strong class="lq ir">文本</strong>。</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h2 id="7685" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><a class="ae ln" href="https://medium.com/towards-data-science/convolutional-attention-model-for-natural-language-inference-a754834c0d83" rel="noopener">用于自然语言推理的卷积注意力模型</a></h2><p id="6f53" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw la lx ly lz le ma mb mc li md me mf mg ij bi translated">通过<a class="mh mi ep" href="https://medium.com/u/f123cbbbb2c3?source=post_page-----c3594faf2964--------------------------------" rel="noopener" target="_blank">Marek galo VI</a>—5分钟阅读。</p><p id="dde2" class="pw-post-body-paragraph lo lp iq lq b lr mj jr lt lu mk ju lw la ml ly lz le mm mb mc li mn me mf mg ij bi translated">在这篇文章中，我想向你展示一个我在Quora问题配对竞赛中使用的模型。首先，我将描述一个用于自然语言推理的可分解注意力模型(<a class="ae ln" href="https://arxiv.org/pdf/1606.01933.pdf" rel="noopener ugc nofollow" target="_blank">帕里克等人，2016 </a>)，然后用卷积层对其进行扩展，以提高损失和分类精度。</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h2 id="3e3e" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><a class="ae ln" href="https://medium.com/towards-data-science/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a" rel="noopener">机器学习，NLP:使用scikit-learn、python和NLTK的文本分类。</a></h2><p id="fd3d" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw la lx ly lz le ma mb mc li md me mf mg ij bi translated">由<a class="mh mi ep" href="https://medium.com/u/a5598ec05185?source=post_page-----c3594faf2964--------------------------------" rel="noopener" target="_blank">贾韦德谢赫</a> — 7分钟读取。</p><p id="640a" class="pw-post-body-paragraph lo lp iq lq b lr mj jr lt lu mk ju lw la ml ly lz le mm mb mc li mn me mf mg ij bi translated"><strong class="lq ir">文档/文本分类</strong>是<em class="mv">监督的</em>机器学习(ML)中重要而典型的任务之一。为文档分配类别，文档可以是网页、图书馆书籍、媒体文章、图库等。有许多应用，例如垃圾邮件过滤、电子邮件路由、情感分析等。</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h2 id="b403" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><a class="ae ln" href="https://medium.com/towards-data-science/a-data-science-exercise-how-similar-is-trump-to-other-presidents-based-on-inaugural-speeches-8fa7f534a5fb" rel="noopener">一个数据科学练习:根据就职演说，特朗普与其他总统有多相似？</a></h2><p id="6b20" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw la lx ly lz le ma mb mc li md me mf mg ij bi translated">由<a class="mh mi ep" href="https://medium.com/u/d56a4a50fc50?source=post_page-----c3594faf2964--------------------------------" rel="noopener" target="_blank">布莱恩·雷</a> — 4分钟读完。</p><p id="c8b8" class="pw-post-body-paragraph lo lp iq lq b lr mj jr lt lu mk ju lw la ml ly lz le mm mb mc li mn me mf mg ij bi translated">这是基于谷歌团队编写的一些NLP(自然语言处理)<a class="ae ln" href="https://en.wikipedia.org/wiki/Word2vec" rel="noopener ugc nofollow" target="_blank"> Doc2Vec </a>算法的运行结果。(浅层，两层神经网络)。</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h2 id="3e97" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">这首诗是什么时候写的？我的电脑可以告诉你</h2><p id="a96c" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw la lx ly lz le ma mb mc li md me mf mg ij bi translated">由<a class="mh mi ep" href="https://medium.com/u/cc12e71672c8?source=post_page-----c3594faf2964--------------------------------" rel="noopener" target="_blank">查姆格鲁克</a> — 6分钟读完。</p><p id="3473" class="pw-post-body-paragraph lo lp iq lq b lr mj jr lt lu mk ju lw la ml ly lz le mm mb mc li mn me mf mg ij bi translated">我最近的项目真的很令人兴奋。我热爱诗歌已经有一段时间了，所以我选择它作为我第一次涉足自然语言处理(NLP)的主要领域。</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h2 id="5dba" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><a class="ae ln" href="https://medium.com/towards-data-science/meme-search-using-pretrained-word2vec-9f8df0a1ade3" rel="noopener">使用预先训练的word2vec进行迷因搜索</a></h2><p id="c816" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw la lx ly lz le ma mb mc li md me mf mg ij bi translated">通过<a class="mh mi ep" href="https://medium.com/u/7612afea778b?source=post_page-----c3594faf2964--------------------------------" rel="noopener" target="_blank"> Eyyüb Sari </a> — 6分钟读取。</p><p id="6119" class="pw-post-body-paragraph lo lp iq lq b lr mj jr lt lu mk ju lw la ml ly lz le mm mb mc li mn me mf mg ij bi translated">模因抵得上千言万语。它们是一种文化。我和我的朋友过去常常用Giphy在Messenger上发送很多这样的消息。</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h2 id="dd19" class="kr ks iq bd kt ku kv dn kw kx ky dp kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><a class="ae ln" href="https://medium.com/towards-data-science/scikit-learn-for-text-analysis-of-amazon-fine-food-reviews-ea3b232c2c1b" rel="noopener">Scikit-了解亚马逊美食评论的文本分析</a></h2><p id="8e3b" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw la lx ly lz le ma mb mc li md me mf mg ij bi translated">由<a class="mh mi ep" href="https://medium.com/u/731d8566944a?source=post_page-----c3594faf2964--------------------------------" rel="noopener" target="_blank">苏珊李</a> — 7分钟读完。</p><p id="2417" class="pw-post-body-paragraph lo lp iq lq b lr mj jr lt lu mk ju lw la ml ly lz le mm mb mc li mn me mf mg ij bi translated">我们知道<a class="ae ln" href="https://www.entrepreneur.com/article/253361#" rel="noopener ugc nofollow" target="_blank">亚马逊产品评论对商家很重要</a>，因为这些评论对我们如何做出购买决定有着巨大的影响。</p></div></div>    
</body>
</html>