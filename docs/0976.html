<html>
<head>
<title>Visual Attention Model in Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习中的视觉注意模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/visual-attention-model-in-deep-learning-708813c2912c?source=collection_archive---------1-----------------------#2017-07-17">https://towardsdatascience.com/visual-attention-model-in-deep-learning-708813c2912c?source=collection_archive---------1-----------------------#2017-07-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="09be" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">摘要</h1><p id="cb88" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">本练习的主要目的是研究视觉注意模型的发展现状和主要工作。研究了两个数据集:扩展MNIST和支持向量回归机。前一个数据集侧重于规范问题——手写数字识别，但具有杂乱和翻译，后一个数据集侧重于现实世界的问题——街景门牌号码(SVHN)转录。在本练习中，我们以培养良好直觉的方式研究了以下论文，以选择合适的模型来应对上述挑战。</p><p id="c076" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">对于扩充的MNIST数据集:</p><ul class=""><li id="18c6" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li lt lu lv lw bi translated">基线模型基于经典的2层CNN</li><li id="7942" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li lt lu lv lw bi translated">参考文献[2]，目标模型是具有LSTM循环注意模型(RAM)</li></ul><p id="4760" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">对于SVHN数据集:</p><ul class=""><li id="72db" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li lt lu lv lw bi translated">基线模型基于11层CNN:用卷积网络提取图像特征，然后用多个独立的密集层预测有序序列，参考文献[1]</li><li id="9011" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li lt lu lv lw bi translated">参考文献[3]，目标模型是具有LSTM和卷积网络深度循环注意模型(DRAM)</li></ul><p id="2db4" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">此外:</p><ul class=""><li id="31f2" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li lt lu lv lw bi translated">空间变换网络也作为视觉注意机制的最新发展进行了研究，参见论文[5]</li></ul><p id="fafb" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">上述两个数据集挑战都集中在数字识别上。在本练习中，MNIST用于演示一位数识别的解决方案，而SVHN用于显示多位数序列识别的结果。</p><h1 id="9e0e" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">扩充MNIST数据集</h1><h2 id="ad7f" class="mc jo iq bd jp md me dn jt mf mg dp jx kw mh mi kb la mj mk kf le ml mm kj mn bi translated">数据扩充</h2><p id="a263" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">由于原始MNIST数据集是用于说明深度学习的规范数据集，其中简单的多层感知器可以获得非常高的精度，因此原始MNIST被增加了额外的噪声和失真，以便使问题更具挑战性，并导致诸如SVHN的真实世界问题。</p><p id="2898" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">增强后的MNIST数据集示例如下所示:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi mo"><img src="../Images/da7bc428b9eb73d14582b59000c42489.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CRR5WONVcTn8OtQyLnAuuA.png"/></div></div></figure><p id="8422" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">上面的增强MNIST数据集杂乱无章，没有中心。增强过程如下:<br/> (1)在100x100的画布中随机选择一个位置对原始的28x28图像进行平移，生成平移。<br/> (2)通过随机选择一个训练/验证28x28图像，然后随机裁剪8次9x9补丁，然后将所有8个裁剪的图像拼接成增强的100x100图像，来产生失真噪声</p><p id="8951" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">对于经典方法来说，扩充的MNIST数据集似乎很难，让我们首先尝试一下。</p><h2 id="3e17" class="mc jo iq bd jp md me dn jt mf mg dp jx kw mh mi kb la mj mk kf le ml mm kj mn bi translated">数据预处理</h2><p id="edcb" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">除了数据扩充之外，每个图像像素值在[0，1]的范围内被归一化。</p><p id="1e57" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">MNIST数据集非常平衡。没有应用额外的数据预处理。</p><h2 id="135c" class="mc jo iq bd jp md me dn jt mf mg dp jx kw mh mi kb la mj mk kf le ml mm kj mn bi translated">基线方法:仅CNN</h2><p id="f93e" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">基线方法是使用经典卷积模型架构，该架构适用于原始MNIST数据集。MLP没有被用作基线模型，因为它没有表现出经典模型的最佳效果。卷积模型架构取自<a class="ae na" href="https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py" rel="noopener ugc nofollow" target="_blank"> keras示例</a>，该示例声称在原始MNIST数据集上达到99.25%的准确率。</p><p id="1e30" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">模型架构如下所示:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nb"><img src="../Images/5eba12ae6b60719949f298fb1ef23672.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*Wa6YoI28PpuRqt9IbUwqjg.png"/></div></div></figure><p id="e04e" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">由于MNIST手写数字相对简单，因此只有2个卷积层和最大池用于特征减少和空间不变性。退学用于转正。平坦/密集图层用于要素交互。</p><p id="b718" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">有60k MNIST图像数据，其中54k用于训练，6k用于验证，10k用于测试。测试数据在最后一步只使用一次。</p><p id="45a4" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">验证动态如下所示。我们可以看到，验证准确度稳定在大约50%的准确度。并且最终的一次性测试准确率在100个历元时为<strong class="kn ir"> 50.87% </strong>(由于每个训练图像为100x100，所以在Tesla K80 GPU服务器中的总训练时间需要几个小时)。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nc"><img src="../Images/0d3a34b7b0bec44fcb35a0c88a3424a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rCxAhtGiLSy55Mq0jznYoA.png"/></div></div></figure><h2 id="f78e" class="mc jo iq bd jp md me dn jt mf mg dp jx kw mh mi kb la mj mk kf le ml mm kj mn bi translated">目标方法:重复注意模型(RAM)</h2><p id="60de" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了更好地解决上述问题，谷歌在2014年发布了一个非常简洁和酷的想法，请参考论文[2]。</p><p id="69e4" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> I </span> <strong class="kn ir"> <em class="nm">灵感<br/> </em> </strong>大意是从人眼的工作原理，即视网膜中获取灵感，如下图所示。我们的眼睛可以捕捉到一个非常广阔的世界，然而，我们倾向于“扫视”全景，只关注视图的特定区域，而其他部分则有点“模糊不清”。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nn"><img src="../Images/748ed63000d28df537e5318627aeb375.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vfFr0dSwDMzAb5xj."/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">source: <a class="ae na" href="https://en.wikipedia.org/wiki/Visual_perception" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Visual_perception</a></figcaption></figure><p id="9eed" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">视觉注意力模型试图利用这一想法，让神经网络能够将其“注意力”集中在图像的有趣部分，在那里它可以获得大部分信息，而在其他地方给予较少的“注意”。</p><p id="cc1a" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">这种方法的优点是:<br/> (1)模型可以更多地关注图像的相关区域<br/> (2)因此降低了所需的图像处理能力<br/> (3)“离焦”模糊区域仍然捕捉到正在发生的事情的一般概念</p><p id="f6b8" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">这种直觉可能有助于我们的增强MNIST数据集挑战，其中只有手指周围的图像区域需要更多的关注。</p><p id="41ef" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> A </span> <strong class="kn ir"> <em class="nm">架构<br/> </em> </strong>整体架构中组件很少。</p><p id="945b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> <em class="nm">惊鸿传感器<br/> </em> </strong>惊鸿传感器是视网膜的实现，如下图所示:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/6f61735becfade6a66130e92195a3f82.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*4Ip1oL5zJqoEAzqFgnDgGQ.png"/></div></figure><p id="dc63" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">这个想法是让我们的网络“看一眼”给定位置周围的图像，称为一瞥，然后提取这一瞥并将其调整为不同比例的图像作物，但每个比例都使用相同的分辨率。例如，上述示例中的glimpse包含3个不同的刻度，每个刻度具有相同的分辨率(也称为传感器带宽)，例如12x12。因此，中间最小比例的作物最清晰，而外环最大的作物最模糊。总之，Glimpse传感器拍摄全尺寸图像和位置，输出给定位置周围图像的“类似视网膜”的表示。</p><p id="59ce" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"><em class="nm">Glimpse Network</em></strong><br/>一旦我们定义了glimpse sensor，Glimpse Network就是一个简单的环绕Glimpse Sensor，拍摄全尺寸图像和位置，通过Glimpse Sensor提取图像的视网膜表示，展平，然后使用隐藏层和ReLU将提取的视网膜表示与Glimpse位置组合，发出单个矢量g。该矢量包含“什么”(我们的视网膜表示)和“哪里”(图像内的聚焦位置)的信息。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/93daab716275626b2f49da225db4d084.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*n8V7ObNtU85oJupqfTD_sA.png"/></div></figure><p id="e442" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> <em class="nm">递归网络</em> </strong> <br/>递归网络从Glimpse网络获取特征向量输入，通过其隐藏状态(和记忆单元)记忆有用信息。</p><p id="9504" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> <em class="nm">位置网络</em> </strong> <br/>位置网络将递归网络中的隐藏状态作为输入，并尝试预测下一个要查看的位置。该位置预测将在展开的递归网络中的下一个时间步中成为Glimpse网络的输入。位置网络是整个想法中的关键组成部分，因为它直接决定了在下一个时间步骤中要注意的地方。为了最大化这个位置网络的性能，本文引入了一个随机过程(即高斯分布)来产生下一个位置，并使用强化学习技术进行学习。它也被称为“硬”注意，因为这个随机过程是不可微的(与“软”注意相比)。随机性背后的直觉是平衡开发(利用历史预测未来)和探索(尝试前所未有的东西)。请注意，这种随机性使得组件不可微，这将在反向传播期间引发问题。并采用强化梯度策略算法来解决这一问题，具体在强化学习部分讨论。</p><p id="1124" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> <em class="nm">激活网络</em> </strong> <br/>激活网络将递归网络中的隐藏状态作为输入，并尝试预测位数。此外，预测结果用于生成奖励点，奖励点用于训练位置网络(因为随机性使其不可微)。</p><p id="60d5" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> <em class="nm">架构组合</em> </strong> <br/>结合以上所述的所有元素，我们就有了下面的网络架构。f_g是瞥见网络，f_h是循环网络，f_l是位置网络，f_a是激活网络。下图是为说明目的而展开的2个时间步长的递归。特别是，时间步数=每张图片的扫视次数</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nu"><img src="../Images/9627366f4939a22e73b7cccb825fd529.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*71KTu5p-USzQPSTMPFTZzA.png"/></div></div></figure><p id="d34b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> R </span>强化学习<br/>由于位置网络是不可微的，所以采用强化学习，具体来说就是策略梯度法来训练网络的这一特殊部分。首先让我们看一下强化学习的概述。</p><p id="de2d" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> <em class="nm">概述<br/> </em> </strong>强化学习就是试错。强化学习的概述如下图所示。我们有以下组件:</p><ul class=""><li id="8406" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li lt lu lv lw bi translated">代理人:大脑，也就是我们正在建模的神经网络。</li><li id="226d" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li lt lu lv lw bi translated">环境:地球，是我们可以与之互动的未知世界。默认情况下，我们对环境一无所知。</li><li id="5adb" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li lt lu lv lw bi translated">相互作用:红色箭头，是代理和环境之间的相互作用。它可以是行动(将改变环境的代理输出)、观察(作为代理行动的结果的环境变化的结果)和奖励(代表代理行动“有多好”的一些标量值)。代理的目标是最大化它收集的报酬。</li></ul><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/9cdec82cc99f4a4c4e2516705990455a.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/0*71d7JALfaEwIWmUn."/></div><figcaption class="no np gj gh gi nq nr bd b be z dk">source: <a class="ae na" href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" rel="noopener ugc nofollow" target="_blank">http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html</a></figcaption></figure><p id="920a" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">强化学习的各种方法取决于我们试图优化的目标，分类如下:</p><ul class=""><li id="f5d7" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li lt lu lv lw bi translated">政策:从状态到行动的映射。给定我们所处的位置(即状态)，执行哪个操作</li></ul><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/ffc3ed85ac17c0b5fa30758cdcfa0995.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/0*SjB7gStAB99cDl1d."/></div></figure><ul class=""><li id="9b74" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li lt lu lv lw bi translated">价值:评价一个状态有多好。处于某个状态有多好</li></ul><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/0cdc4b588ad32263bc3a69bd5793725a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/0*IHfiiyzToYl6OOKZ."/></div></figure><ul class=""><li id="046e" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li lt lu lv lw bi translated">模型:预测环境会怎样。了解敌人有助于赢得战争。</li></ul><p id="e2cf" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">关于RL的更详细和全面的解释可以在<!-- -->这里找到<!-- -->。本文选择政策梯度作为RL方法，属于上述第一类。</p><p id="8658" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> <em class="nm">应用到我们的问题<br/> </em> </strong>回到我们的问题，既然我们在用政策梯度来解决我们的问题，那我们就来谈谈“政策”本身。在我们的问题中,“政策”决定了我们如何选择下一个瞥见的地点。我们的答案(即策略)是，通过从参数为μ和σ的高斯分布中抽样，其中μ是均值，σ是标准差。这个高斯分布就是我们的随机过程。在这个实现中，我们将σ固定为网络超参数，只尝试学习μ。</p><p id="6c13" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">为了说明随机网络的训练过程，下图显示了一个高级概念。蓝色箭头代表向前传球，红色箭头代表向后传球。我们的过程从将输入图像传入我们的网络开始。可微分网络将正常工作(例如XW + b)，表示为机器人头部。然后，随机网络(在我们的情况下是位置网络)将应用随机过程(在我们的情况下是高斯分布)来生成结果(在我们的情况下是下一次扫视位置的预测)。它被表示为抛硬币，以表示一个随机过程。然后由环境评估位置预测(以及使用glance的分类结果),现在我们有了开始反向传播的奖励。从概念上讲，通过随机网络的反向传播可以被认为是我们使我们的硬币更偏向于未来会给我们带来更多回报的方向，换句话说，我们学习高斯分布参数。这一步被描绘成一把锤子砸在一枚硬币上，来表示我们想要“锻造”对我们有利的硬币。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ny"><img src="../Images/9657176b39dc27bd3f87a135154c42f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BuhOGBJTjjz8lxzaiYBzzQ.png"/></div></div></figure><p id="46c6" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">那么如何锤我们的硬币呢？我们来看看政策梯度的推导。假设我们有一个函数f(x ),它可以告诉我们，如果我们有一个样本点x，我们会得到多少回报，也就是一个得分/回报函数</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/b390e259b23d74bbb909580b3e17195b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/0*i1Z-RhKYePCQzlH6."/></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Source: <a class="ae na" href="http://karpathy.github.io/2016/05/31/rl/" rel="noopener ugc nofollow" target="_blank">http://karpathy.github.io/2016/05/31/rl/</a></figcaption></figure><p id="e516" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">上面告诉我们，如果我们有一个样本点x，为了在下一轮有更高的得分，我们应该“锻造”我们硬币的方式是得分函数的梯度方向(方程的左手边)，这与样本点x的对数似然最大化的方向相同，具有f(x)本身的振幅(方程的右手边)。</p><p id="1646" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">正式地说，我们“敲打”硬币的方式是增强算法，它代表<strong class="kn ir">RE</strong>ward<strong class="kn ir">I</strong>ncrement =<strong class="kn ir">N</strong>on negative<strong class="kn ir">F</strong>actor times<strong class="kn ir">O</strong>ffset<strong class="kn ir">R</strong>E enforcement times<strong class="kn ir">C</strong>character istic<strong class="kn ir">E</strong>ligility(有人非常努力地拼出“增强”…)。原文参见[6]</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi oa"><img src="../Images/bc03e7d98e812b34103c56a289734a29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UlT5LDDxAilaHkNO."/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Source: <a class="ae na" href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" rel="noopener ugc nofollow" target="_blank">http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html</a></figcaption></figure><p id="e45f" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">安德烈·卡帕西的博客有一个更好的解释:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ob"><img src="../Images/7847efefcb1a39b9f515a0cc6059ed1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BRXBhq5ZznYaJE8j."/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">A visualization of the score function gradient estimator. <strong class="bd oc">Left</strong>: A gaussian distribution and a few samples from it (blue dots). On each blue dot we also plot the gradient of the log probability with respect to the gaussian’s mean parameter. The arrow indicates the direction in which the mean of the distribution should be nudged to increase the probability of that sample. <strong class="bd oc">Middle</strong>: Overlay of some score function giving -1 everywhere except +1 in some small regions (note this can be an arbitrary and not necessarily differentiable scalar-valued function). The arrows are now color coded because due to the multiplication in the update we are going to average up all the green arrows, and the <em class="od">negative</em> of the red arrows. <strong class="bd oc">Right</strong>: after parameter update, the green arrows and the reversed red arrows nudge us to left and towards the bottom. Samples from this distribution will now have a higher expected score, as desired.</figcaption></figure><p id="fb63" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">现在我们知道如何计算随机网络的梯度。然而，在实践中，tensorflow计算图将默认自动计算梯度。因此，为了实现如REINFORCE所述的定制梯度更新，有两种方法可以做到:<br/> (1)设置<code class="fe oe of og oh b">tf.stop_gradient</code>将梯度直接传递到可微分网络，然后使用混合损失函数仅训练可微分网络作为近似。这里的论点是，由于我们固定了高斯分布的std，并且仅试图“学习”均值作为分布参数，所以锤打硬币本身将大致等同于锤打我们的可微分网络参数，以便从可微分网络发出我们期望的均值。参考<a class="ae na" href="https://github.com/zhongwen/RAM" rel="noopener ugc nofollow" target="_blank">本回购</a>和<a class="ae na" href="https://github.com/jlindsey15/RAM" rel="noopener ugc nofollow" target="_blank">本回购</a> <br/> (2)用优化器构建一个单独的计算图，并使用<code class="fe oe of og oh b">tf.gradients</code>具体计算所需的梯度w.r.t相关参数，然后使用<code class="fe oe of og oh b">optimizer.apply_gradients</code>仅更新这些参数。参考<a class="ae na" href="https://github.com/yanji84/deep-recurrent-attention-model" rel="noopener ugc nofollow" target="_blank">本回购</a></p><p id="3e7e" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di">T</span><strong class="kn ir"><em class="nm">raining Methodology</em></strong><br/>作为上面讨论的实现细节，在本练习中，在实现中使用了混合损耗，方法(1)如上。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi oi"><img src="../Images/f7674beede7a471828e469eb2a903c7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pZWai5XO0qinKbhkfVV2QQ.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">R = actual reward, b = score function, b_freeze = tf.stop_gradients(b)</figcaption></figure><p id="deda" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">由于plus gate在反向传播过程中充当梯度分配器，因此我们仅使用以下3个具有相同权重的目标来有效地优化我们的可微分网络:(1)用于预测正确性的交叉熵(2)用于回归最优μ作为随机网络的参数输入的MLE)用于将分数函数回归到实际回报的分数函数(因此分数函数更准确)。</p><p id="b121" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">另一个技巧是蒙特卡罗抽样。由于我们在网络中有随机过程，我们可以复制相同的图像10次(由于随机性，这将产生10个略有不同的结果)，然后将它们平均作为我们对训练和测试的预测。</p><p id="6376" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">训练参数如下所示。只比较了两种情况。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nc"><img src="../Images/f13395bcad0e2faa77d62c88e874f58c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VlyM88b3xyMaBTSVANXM4A.png"/></div></div></figure><p id="7299" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">培训动态如下所示。上表中的训练时间是使用Tesla K80 GPU服务器进行基准测试的。训练准确率(每批平均)稳定在80%，最终一次测试准确率为<strong class="kn ir"> 79.68% </strong>，与基准方法<strong class="kn ir"> 50% </strong>相比有显著提高。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi oj"><img src="../Images/904470bcac01507d93116a32a1f230c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*V759ECxy3mNRh7Zc."/></div></div></figure><p id="822a" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> L </span> <strong class="kn ir"> <em class="nm">仿<br/> </em> </strong>本节讨论的RAM方法的局限性包括:</p><p id="b735" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">(1) Glimpse传感器使用扁平化+致密层。对于MNIST特征可能是足够的，然而，为了适合真实世界的图像，可以使用卷积层</p><p id="716b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">(2)递归网络使用单层RNN单元。这个RNN细胞应该学习图像特征(为了预测数字标签)和位置特征(为了预测下一个扫视位置)。这种责任混合可能会导致一些内部问题。</p><p id="9250" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">(3)在展开RNN的初始步骤，位置网络随机选择一个位置聚焦其扫视作为起点。这可以改进为具有“更少的随机”开始。</p><p id="ec00" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">谷歌在参考文献[3]中发表的后续论文解决了上述所有限制。本文将在下一节中作为处理SVHN数据集的目标架构进行讨论。</p><h1 id="d3e3" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">SVHN数据集</h1><p id="ec10" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">SVHN数据集是真实世界的街景门牌号数据集。如下图所示:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/f01992295e347457de7748e76df4b8f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/0*h7T9SwepLu7chv0G."/></div><figcaption class="no np gj gh gi nq nr bd b be z dk">source: reference [1] paper</figcaption></figure><p id="0fef" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">在SVHN数据集中，提供了以下信息:<br/> (1)位数的长度<br/> (2)每个位数<br/> (3)位数的最大长度是5</p><p id="11eb" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">SVHN数据集是我们的增强MNIST数据集挑战的扩展，从某种意义上说:<br/> (1)图像中有噪声和模糊效果<br/> (2)有数字的转换<br/> (3)在我们的增强MNIST数据集中，它是有序的数字序列，而不是单个数字</p><h2 id="f238" class="mc jo iq bd jp md me dn jt mf mg dp jx kw mh mi kb la mj mk kf le ml mm kj mn bi translated"><strong class="ak"> <em class="od">数据预处理</em> </strong></h2><p id="c9a3" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">对于图像，进行以下预处理:</p><ul class=""><li id="5ec9" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li lt lu lv lw bi translated">从训练(和测试)数据中获取边界框位置</li><li id="f3ff" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li lt lu lv lw bi translated">裁剪边界框的联合，以便将图像缩小到最大</li><li id="c643" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li lt lu lv lw bi translated">调整到32x32</li><li id="9c14" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li lt lu lv lw bi translated">转换为灰度</li><li id="ac8b" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li lt lu lv lw bi translated">在[0，1]之间归一化</li></ul><p id="675a" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">下图显示了一个示例图像:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/c41fa8b71c1d7af0572ac3f31ee20783.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*e_3NNG9IVk8Dgy8T7m6ftw.png"/></div></figure><p id="83d4" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">对于标签，进行以下预处理:</p><ul class=""><li id="4281" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li lt lu lv lw bi translated">0–9代表数字，10代表结束标记(或空标记，如果有多个)</li><li id="7308" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li lt lu lv lw bi translated">将最大序列长度设置为5</li><li id="34e4" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li lt lu lv lw bi translated">使用结束/空标记10填充</li><li id="0942" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li lt lu lv lw bi translated">丢弃长度超过5位数的数据</li></ul><p id="94b8" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">例如，上面的图像标签将是:<code class="fe oe of og oh b">[1, 0, 5, 10, 10]</code></p><h2 id="603b" class="mc jo iq bd jp md me dn jt mf mg dp jx kw mh mi kb la mj mk kf le ml mm kj mn bi translated"><strong class="ak"> <em class="od">简介</em> </strong></h2><p id="aa8d" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">研究了以下两种方法。</p><p id="6261" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> (1)一种“仅CNN”的方法</strong>。主要思想是同时查看多个数字，并且如果该数字丢失，目标是以固定长度的数字顺序用空白填充来“分类”数字序列。这一思想借用了文献[1]中发表的论文。然而，为了快速建立比较基准，实现在一定程度上不同于本文。</p><p id="62f8" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> (2)一种“RNN + CNN”的深度循环注意模式方法</strong>。其主要思想是引入深度视觉注意模型(DRAM ),参考文献[3]以扩展他们先前工作[2]中的循环注意模型(RAM)。其中提出了两层LSTM来分离扫视位置预测和图像特征处理。</p><h2 id="fbb2" class="mc jo iq bd jp md me dn jt mf mg dp jx kw mh mi kb la mj mk kf le ml mm kj mn bi translated">基线方法:仅CNN</h2><p id="8425" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kn ir"> <em class="nm">问题描述<br/> </em> </strong>门牌号转写问题有以下几个因素需要我们注意:</p><ol class=""><li id="4639" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li om lu lv lw bi translated">存在多个数字(我们需要识别所有数字)</li><li id="df73" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li om lu lv lw bi translated">所有的数字都是有序的(我们需要识别序列)</li><li id="39df" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li om lu lv lw bi translated">有一个特定长度的数字序列(序列的长度不同)</li></ol><p id="0dab" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">设P表示概率，S表示输出数字序列，L表示数字序列的长度，X表示输入图像数据。我们的目标可以解释为最大化以下内容:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi on"><img src="../Images/e1d51e68dfbf853824a15d5629f08aca.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*dXbdFIJWnx384UcPiCO3wg.png"/></div></figure><p id="85bb" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">在测试时，我们的预测是上述模型的argmax:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/d532f7933ff4d44c9ab1e8a992d542b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*c7zQoUco7izcjmKLVWfv4Q.png"/></div></figure><p id="720e" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">这个模型包含了上面提到的所有3个因素。在本练习中，为了快速形成基线，实施了上述模型的一个小变化，但仍保留了以下3个因素:</p><ol class=""><li id="a1b1" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li om lu lv lw bi translated">长度大于5的门牌号将被丢弃</li><li id="bf95" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li om lu lv lw bi translated">该模型将5个数字按顺序分类，每个数字的范围从0到10。0–9代表数字，10代表空白填充。例如，门牌号“258”将导致正确的标签序列<code class="fe oe of og oh b">[2,5,8,10,10]</code></li><li id="33e4" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li om lu lv lw bi translated">没有使用长度，因为空白填充意味着长度信息</li></ol><p id="8624" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> <em class="nm">方法<br/> </em> </strong>本练习采用的总体思路是在架构上有两个网络:卷积网络和分类网络。</p><p id="4a72" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">卷积网络用于从馈送图像中提取门牌号数字的特征，然后是分类网络，该分类网络使用5个独立的密集层来共同分类5个数字的有序序列，其中0–9表示数字，10表示空白填充。</p><p id="8696" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我们期望分类网络通过反向传播来学习数字布局的空间信息，使得每个密集层分别只拾取序列中的一个数字。</p><p id="15d8" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> <em class="nm">网络架构<br/> </em> </strong>原论文采用8卷积层的网络架构。在本练习中，为了快速形成基线，使用了一个更简单的网络(同时仍保留图层类型)，如下所示:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi op"><img src="../Images/427a89a9895074b93fe7ff76611bb044.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6AqltShKFXQz9KBnFAe5eA.png"/></div></div></figure><p id="471f" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">请注意，在分类网络中，5个独立的密集层负责将现有要素分类为0-10类标签，其中0-9表示数字标签，10表示空白填充。</p><p id="3ca5" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> <em class="nm">训练方法<br/> </em> </strong>本文在SVHN数据集上取得了96.03%的转录准确率，模型性能最好。在本练习中，随着模型、图像预处理和网络架构的变化，准确率达到了87.64%，参见<a class="ae na" href="https://github.com/ritchieng/NumNum/blob/master/NumNum/report/report.pdf" rel="noopener ugc nofollow" target="_blank">本文</a></p><p id="a77a" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> <em class="nm">限制<br/> </em> </strong>理想情况下，图像预处理步骤应仅适用于训练数据(例如，裁剪掉边界框的并集)，其中保持验证/测试数据不变。然而，在实施中，参考<a class="ae na" href="https://github.com/ritchieng/NumNum/" rel="noopener ugc nofollow" target="_blank">本报告</a>，验证/测试数据也在边界框周围裁剪。原始论文提到在图像预处理阶段首先定位数字周围的包围盒矩形。然而，它没有提到执行这种定位的确切方法。</p><p id="ceda" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> TODO </strong>:或者，仅使用裁剪训练数据执行另一个基准</p><h2 id="1f04" class="mc jo iq bd jp md me dn jt mf mg dp jx kw mh mi kb la mj mk kf le ml mm kj mn bi translated">目标方法:深度循环注意模型(DRAM)</h2><p id="67c7" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">除了以前在循环注意模型(RAM)中的工作，让我们扩展以修复限制并应用于SVHN数据集。这个想法被称为深度循环注意模型(DRAM)。</p><p id="a27d" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> <em class="nm">架构<br/></em></strong>DRAM的架构与RAM类似，除了:</p><ul class=""><li id="1878" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li lt lu lv lw bi translated">位置网络→发射网络</li><li id="62eb" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li lt lu lv lw bi translated">提出了两层RNN单元:专用于预测下一个扫视位置位置RNN(表示为r上标2)，以及专用于预测数字标签的分类RNN(表示为r上标1)。</li><li id="ecfb" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li lt lu lv lw bi translated">引入上下文网络，利用下采样的粗糙图像设置位置RNN的隐藏状态。想法是将图像的一般上下文馈送到位置RNN，以便它生成对聚焦扫视的第一位置的良好猜测(与RAM方法中开始的随机位置相比)。</li></ul><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/46a5a748f74666098572fd9a9b253ad8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/0*L52vgshbTP6f7G6S."/></div></figure><p id="c4bc" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> <em class="nm">顺序分类<br/> </em> </strong>为了扩展RAM的思想并申请顺序分类，提出了以下工作。</p><p id="393f" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> M </span> <strong class="kn ir"> <em class="nm"> onte Carlo采样<br/> </em> </strong>它与RAM的想法相同，通过多次复制相同的图像，然后取平均值作为预测(文中提到的取对数平均值给出最佳性能)</p><p id="692f" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> C </span>通过这种方式，网络将更专注于对具有迫近误差的有序序列进行分类。</p><p id="754b" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> A </span> <strong class="kn ir"> <em class="nm">累积奖励<br/> </em> </strong>为了简化多对象分类，使用累积奖励，即与正确预测的标签成比例的奖励。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi or"><img src="../Images/7fecd795d1abd5068e8d9f5463cd0d43.png" data-original-src="https://miro.medium.com/v2/resize:fit:314/format:webp/1*C2Gj_U-2-T5oozflU3gr7w.png"/></div></figure><p id="d636" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> S </span> <strong class="kn ir"> <em class="nm">序列对数似然<br/> </em> </strong>序列对数似然呈现在以下目标函数中:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi os"><img src="../Images/2e9226741af7384fa31f7563f9f7d8df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*MsOt9BVdqZMi1Yk8v8uxuQ.png"/></div></figure><p id="671d" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">该目标函数是MLE，其合并了来自发射网络(与RAM中的位置网络相同)的位置概率和来自分类网络(与RAM中的动作网络相同)的分类概率。</p><p id="250d" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> F </span>这里的解决方案是采用相同的训练数据，但让网络预测数字的反向序列，然后取平均值作为最终预测。这种方法提高了准确性。</p><p id="ca28" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><strong class="kn ir"> <em class="nm">结果<br/> </em> </strong> DRAM在这个练习中没有实现(至少没有成功)。</p><p id="69c7" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di">A</span><strong class="kn ir"><em class="nm">ccuracy<br/></em></strong>参考论文，下表报告了DRAM在SVHN数据集上的准确率:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/caaee6067bd2893facc53d2c84642170.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*3SGHs2U6LLydAaxnCAJeHg.png"/></div></figure><p id="d100" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">相对于我们的11层CNN的基线方法(3.96%的错误率)，这不是一个显著的改进(3.9%的错误率)。然而，这种改进更多的是在计算开销上。</p><p id="7429" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi nd translated"><span class="l ne nf ng bm nh ni nj nk nl di"> C </span> <strong class="kn ir"> <em class="nm">计算成本<br/> </em> </strong>计算成本如下图所示:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ou"><img src="../Images/b47bc4b04f6825695c7352756ef6a310.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*swguGZTl6_gTspj1mMYRQQ.png"/></div></div></figure><p id="9036" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">正如所观察到的，就所使用的参数数量和浮点操作数量而言，DRAM明显更好，这是因为它采用了用于视觉注意力的一瞥的想法。</p><h1 id="e940" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">还有一件事:空间变压器网络</h1><p id="17a2" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我觉得有义务提一下这篇论文(太受欢迎就不提了)。它以一种全新的不同方式解决这个问题。这个想法不是使用“硬”注意力，远离强化学习，而是建立一个完全可区分的“软”注意力模型。详情请参考文献[5]。</p><p id="5958" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">直觉是，既然注意力都是关于选择性地裁剪图像的一部分作为“注意力”，为什么不使用仿射变换，它以完全可微分的方式处理裁剪、平移、旋转、(各向同性)缩放和倾斜。神经网络需要做的唯一事情是学习这些仿射变换参数。因此，下图展示了一个很酷的想法。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/5ba86fab1d21750d84b09b3ce27c361d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/0*0bm4l5o-O27uwRrO."/></div></figure><p id="b375" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">u是我们的原始输入图像。它首先被传递到定位网络，定位网络是具有可学习参数θ的仿射变换，例如如下所示。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/b17129c7bc6fbf2d39151a45b4940c66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/0*sYwc4cY56WMbfv4J."/></div></figure><p id="4232" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">然后，采样器将对变换图像的输出进行采样，以提供原始输入图像的“校正和调整大小”版本。通常，采样过程是双线性插值，这也是一个可微分的过程，如下所示。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/481917941dd906104a37f71505d250e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/0*oyYtqbp2pXLVSz8E."/></div></figure><p id="1afc" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">这样，原始图像将被仿射变换(或处理)成校正后的输出图像，如下所示:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/b870dcb2ec22eb914475c78a3c62fe3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/0*AjM5Sfzs8nKkIPY-."/></div></figure><p id="778f" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated"><a class="ae na" href="https://goo.gl/qdEhUu" rel="noopener ugc nofollow" target="_blank">这个视频</a>展示了空间转换器的效果，令人印象深刻。</p><h1 id="449e" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结论</h1><p id="7f28" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">总之，我们已经讨论了以下方法来解决增广的MNIST和SVHN问题:</p><p id="e780" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">对于MNIST: <br/> (1)使用经典的2层CNN，参考keras例子<br/> (2)使用“硬”注意力模型RAM，参考论文【2】</p><p id="37a3" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">对于SVHN: <br/> (1)使用11层CNN，参考文献[1] <br/> (2)使用DRAM作为RAM的扩展，参考文献[3]</p><p id="e7b0" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">最后但同样重要的是，空间转换网络，作为“软”注意力解决方案</p><h1 id="8793" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">关于数据集</h1><h2 id="8f44" class="mc jo iq bd jp md me dn jt mf mg dp jx kw mh mi kb la mj mk kf le ml mm kj mn bi translated">MNIST</h2><p id="cd0b" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">原始的MNIST数据集可以从这里获得:<a class="ae na" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank">http://yann.lecun.com/exdb/mnist/</a></p><h2 id="8f5d" class="mc jo iq bd jp md me dn jt mf mg dp jx kw mh mi kb la mj mk kf le ml mm kj mn bi translated">SVHN</h2><p id="4d24" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">谷歌街景门牌号图片(SVHN)，可从这里获得:<a class="ae na" href="http://ufldl.stanford.edu/housenumbers/" rel="noopener ugc nofollow" target="_blank">http://ufldl.stanford.edu/housenumbers/</a></p><ul class=""><li id="985b" class="lo lp iq kn b ko lj ks lk kw lq la lr le ls li lt lu lv lw bi translated">10类，每个数字一类。数字“1”的标签为1，“9”的标签为9，“0”的标签为10。</li><li id="9cf4" class="lo lp iq kn b ko lx ks ly kw lz la ma le mb li lt lu lv lw bi translated">73257位用于训练，26032位用于测试，以及531131个额外的、难度稍低的样本，用作额外的训练数据</li></ul><h1 id="8f78" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">参考</h1><p id="ab13" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">[1]使用深度卷积神经网络从街景图像中识别多位数。Ian J. Goodfellow、Yaroslav Bulatov、Julian Ibarz、Sacha Arnoud和Vinay Shet (2013年)。<a class="ae na" href="https://arxiv.org/abs/1312.6082" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1312.6082</a></p><p id="1590" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">[2]视觉注意的循环模型，沃洛季米尔·姆尼，尼古拉斯·赫斯，亚历克斯·格雷夫斯，科雷·卡武克库奥卢，<a class="ae na" href="https://arxiv.org/abs/1406.6247" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1406.6247</a></p><p id="f70e" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">[3]视觉注意下的多物体识别，吉米·巴，沃洛季米尔·姆尼，柯雷·卡武克库奥格鲁，<a class="ae na" href="https://arxiv.org/abs/1412.7755" rel="noopener ugc nofollow" target="_blank"/></p><p id="8316" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">[4]用无监督的特征学习读取自然图像中的数字，尤瓦尔·内策尔、王涛、亚当·科茨、亚历山德罗·比萨科、吴波、安德鲁·y·Ng在2011年NIPS深度学习和无监督的特征学习研讨会上发表。<a class="ae na" href="http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf" rel="noopener ugc nofollow" target="_blank">http://ufldl . Stanford . edu/house numbers/nips 2011 _ house numbers . pdf</a></p><p id="a5fc" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">[5]空间变换网络，<a class="ae na" href="https://arxiv.org/find/cs/1/au:+Jaderberg_M/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank">马克斯·贾德伯格</a>，<a class="ae na" href="https://arxiv.org/find/cs/1/au:+Simonyan_K/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank">卡伦·西蒙扬</a>，<a class="ae na" href="https://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank">安德鲁·齐塞曼</a>，<a class="ae na" href="https://arxiv.org/find/cs/1/au:+Kavukcuoglu_K/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank">科雷·卡武科库格卢</a>，<a class="ae na" href="https://arxiv.org/abs/1506.02025" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1506.02025</a></p><p id="987e" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">[6]联结主义强化学习的简单统计梯度跟踪算法，Williams等，<a class="ae na" href="http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf" rel="noopener ugc nofollow" target="_blank">http://www-anw . cs . umass . edu/~ barto/courses/cs 687/Williams 92 Simple . pdf</a></p><p id="c608" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">[7] <a class="ae na" href="https://github.com/tianyu-tristan/Visual-Attention-Model" rel="noopener ugc nofollow" target="_blank"> Github回购</a></p></div></div>    
</body>
</html>