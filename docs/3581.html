<html>
<head>
<title>Machine Learning for Vehicle Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于车辆检测的机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-for-vehicle-detection-fd0f968995cf?source=collection_archive---------4-----------------------#2018-05-27">https://towardsdatascience.com/machine-learning-for-vehicle-detection-fd0f968995cf?source=collection_archive---------4-----------------------#2018-05-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="c744" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我训练了一个支持向量机(SVM)模型来检测道路上的移动车辆。这是<a class="ae kl" href="https://eu.udacity.com/course/self-driving-car-engineer-nanodegree--nd013" rel="noopener ugc nofollow" target="_blank"> udacity 自动驾驶汽车工程师课程</a>的第五个项目。</p><p id="879a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个项目的代码可以在:<a class="ae kl" href="https://github.com/Moataz-E/machine-learning-vehicle-detection" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。<br/>这篇文章也可以在我的网站<a class="ae kl" href="http://www.moatazelmasry.com/projects/machine-learning-vehicle-detection/" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="4d5b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该项目包括以下几个阶段:</p><ol class=""><li id="af3f" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">对数据集执行要素工程。</li><li id="0d2d" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">在提取的特征上训练 SVM 分类器。</li><li id="21cb" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">实现滑动窗口技术来检测图像中车辆。</li><li id="ee42" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">使用热图过滤非车辆窗口，并在车辆周围绘制边界框。</li><li id="bd9e" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">产生一个管道，并生成结果的视频。</li></ol><p id="2010" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本项目的训练数据集由以下样本中的车辆和非车辆图像组成:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi la"><img src="../Images/34271ad926d79fb35f7d3f229791c241.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*XqdNjP87IGh58TNoIzOHOA.png"/></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">Figure 1. Sample vehicle and non-vehicle images from training dataset</figcaption></figure><p id="47dc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">总的来说，训练集包含 8，793 幅车辆图像和 8，968 幅非车辆图像。</strong></p><h1 id="2450" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">特征工程</h1><p id="5dbc" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">项目的第一步是对训练数据集执行<a class="ae kl" href="https://en.wikipedia.org/wiki/Feature_engineering" rel="noopener ugc nofollow" target="_blank">特征工程</a>，以确定要使用的理想特征描述符。考虑了三个特征描述符:<a class="ae kl" href="https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients" rel="noopener ugc nofollow" target="_blank">方向梯度直方图(HOG) </a>特征、<a class="ae kl" href="https://en.wikipedia.org/wiki/Data_binning" rel="noopener ugc nofollow" target="_blank">空间宁滨</a>特征和<a class="ae kl" href="https://en.wikipedia.org/wiki/Color_histogram" rel="noopener ugc nofollow" target="_blank">颜色直方图</a>特征。</p><p id="5308" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">研究人员 Navneet Dalal 和 Bill Triggs 在他们的论文《人类检测的梯度方向直方图》中普及了 HOG 特征描述符。HOG 计算图像局部的梯度方向分布。以下是图像三个颜色通道中每一个的图像样本上的 HOG 特征的可视化:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/e8b392bb72c74f6621c124fcdd69e890.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*scj51Z08MBrcJ77mLRrBwA.png"/></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">Figure 2. Visualization of HOG features for different colour channels.</figcaption></figure><p id="aea8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如何计算 HOG 的详细描述可以在这篇文章中找到。</p><p id="c0e8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用的第二个特征描述符是空间宁滨；为了计算这个特征描述符，使用了 OpenCV 的<a class="ae kl" href="https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#resize" rel="noopener ugc nofollow" target="_blank"> resize </a>函数。缩小图像时，resize 函数执行线性插值空间宁滨运算。</p><p id="72a2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用的第三个特征描述符是颜色分布(直方图)。计算图像中每个颜色通道的直方图，然后将三个直方图组合起来产生一个特征向量。</p><p id="84d2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">实验表明，图像最初被转换到<a class="ae kl" href="https://en.wikipedia.org/wiki/YCbCr" rel="noopener ugc nofollow" target="_blank"> YCbCr </a>色彩空间，这是在预测过程中获得最高准确度的理想色彩空间。然后，从三个特征描述符中的每一个构建每幅图像的组合特征向量。该组合的特征向量是用于训练预测模型的特征向量。</p><h1 id="8b7a" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">SVM 培训</h1><p id="1d6f" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">随着我们的特征工程的完成，下一步是实现一个预测模型，该模型能够计算出特征向量是属于车辆还是非车辆。</p><p id="b2de" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">选择线性<a class="ae kl" href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html" rel="noopener ugc nofollow" target="_blank">支持向量机(SVM) </a>模型作为预测算法。我摆弄了一下模型的超参数；C 值为 0.001，最大迭代次数为 10，000，可获得约 98%的高精度。以下是用于实现该模型的代码:</p><figure class="lb lc ld le gt lf"><div class="bz fp l di"><div class="mq mr l"/></div></figure><p id="5405" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该模型需要大约 12 分钟来训练，这对于机器学习模型来说是相对较短的时间。</p><h1 id="0350" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">滑动窗口搜索</h1><p id="00d3" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">为了在视频源上使用我们的预测模型，我们需要提出一种合适且一致的分割算法，让我们能够搜索我们的视频源图像。搜索算法应该从图像中返回子图像，然后将这些子图像输入到我们的模型中进行预测。一种这样的搜索算法是滑动窗口搜索技术。</p><p id="d8be" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">滑动窗口搜索根据预先选择的比例将搜索区域分割成较小的相同大小的重叠区域。在我们的例子中，我们需要不同比例的滑动窗口区域来说明这样一个事实，即远处的汽车看起来较小，而近处的汽车看起来较大。以下是滑动窗口搜索的四种不同组合，最后一幅图像中的最终组合窗口:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/6e2bd36ed8a0fad04d8006c74298ba2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*xgSCTokoBlYul0YBc0PlbQ.png"/></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">Figure 3. Sliding-window search technique with different scale combinations. Final image is of all sliding-window search areas combined.</figcaption></figure><p id="61a9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上述滑动窗口搜索被应用于视频帧中的每个图像。<strong class="jp ir">总共有 697 个窗口被输入到每个图像的模型中。</strong></p><h1 id="4e74" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">热图阈值</h1><p id="f18e" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">当我们将提取的窗口输入预测模型时，结果是检测到车辆的窗口列表(各种比例)，如下图所示:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/90cd62e7ddb9101a44ebc17eef068b94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*zlyhajAdgu3zWnZj8TIwug.png"/></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">Figure 4. Sample image with positive windows identified as containing a vehicle.</figcaption></figure><p id="ea0e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在考虑到 SVM 模型的简单性，我们预计有些检测是假阳性的。为了过滤掉这些不正确的检测，一种方法是对我们的正窗口进行阈值处理，使得我们只挑选多于一个窗口重叠的区域。本质上，我们正在生成正窗口的热图。</p><p id="6988" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下图显示了应用于搜索图像的热图阈值:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mu"><img src="../Images/c124dfde0865b434175eaa582a117294.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oOfoJzEHvQnC1E5P9iZPIA.png"/></div></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">Figure 5. Heatmap thresholding applied to images with positive detections.</figcaption></figure><p id="7d8e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，使用生成的热图，我们可以使用距离热图中心最远的像素位置来计算检测到的对象上的边界框。这些边界框用于根据上图最后一列中的一组图像直观地识别我们检测到的汽车。</p><p id="2943" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下图显示了显示在检测到的车辆顶部的边界框:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="gh gi mz"><img src="../Images/e087a310f403fab4c4ba730bca81b3d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XGp0ZKrm36QqWsHmsk22MQ.png"/></div></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">Figure 6. Display of bounding boxes around positively detected vehicles.</figcaption></figure><h1 id="48b4" class="lm ln iq bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">最终管道</h1><p id="d2bd" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">最终结果是，对于提要中的每个图像，管道如下所示:</p><ol class=""><li id="45c0" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">从图像中提取所有搜索窗口。</li><li id="daf4" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">将每个窗口图像转换到 YCbCr 颜色空间并提取特征。</li><li id="016b" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">将每个特征输入 SVM 模型，过滤掉非正匹配(非车辆)。</li><li id="e64a" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">将热图阈值应用于正匹配并绘制边界框。</li></ol><p id="a2f8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">管道是在汽车行驶的录像上运行的。下面是一段演示管道运行的视频:</p><figure class="lb lc ld le gt lf"><div class="bz fp l di"><div class="na mr l"/></div></figure></div></div>    
</body>
</html>