<html>
<head>
<title>Machine learning and visual search: Who is getting it right?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习和视觉搜索:谁是正确的？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-and-visual-search-who-is-getting-it-right-e889d0a9a25f?source=collection_archive---------9-----------------------#2017-09-28">https://towardsdatascience.com/machine-learning-and-visual-search-who-is-getting-it-right-e889d0a9a25f?source=collection_archive---------9-----------------------#2017-09-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div class="gh gi io"><img src="../Images/50466fcd077b2dcdf2214a7eac991455.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*FQLwUvNwALxf8pUxSMKKVQ.png"/></div></figure><div class=""/><blockquote class="ju jv jw"><p id="529a" class="jx jy jz ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">“我语言的极限意味着我世界的极限”——路德维希·维特斯坦根</p></blockquote><p id="3cc0" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">从历史上看，搜索中的输入输出关系一直由文本主导。即使输出变得更加多样化(例如视频和图像结果)，输入也是基于文本的。这限制和塑造了搜索引擎的潜力，因为它们试图从相对静态的关键字数据集中提取更多的上下文含义。</p><p id="9cbf" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">视觉搜索引擎正在重新定义我们语言的界限，开辟了人与计算机之间交流的新途径。如果我们将语言视为一个流动的符号和标志系统，而不是一套固定的口语或书面语，我们会对搜索的未来有一个更加引人注目和深刻的了解。</p><p id="4ac2" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">我们的文化是视觉的，这是视觉搜索引擎急于利用的事实。</p><p id="0ef8" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">具体的电子商务视觉搜索技术已经比比皆是:亚马逊、沃尔玛和ASOS都在行动。这些公司的应用程序将用户的智能手机摄像头变成了一个视觉发现工具，可以根据帧中的任何内容搜索类似的项目。然而，这只是一个用例，视觉搜索的潜力远远大于直接的电子商务交易。</p><p id="4572" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">经过大量的试验和错误，这项技术正在走向成熟。处于视觉搜索核心的无监督机器学习系统只是这个过程的结果。</p><p id="56c3" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">我们现在正处于精确、实时视觉搜索的风口浪尖，由机器学习和人工智能驱动。</p><p id="37f3" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">下面，本文将回顾这个行业的三个主要参与者:Pinterest、Google和Bing取得的进展。</p><h1 id="2504" class="kz la ix bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">拼趣</h1><figure class="ly lz ma mb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi lx"><img src="../Images/30cbf16a6abc6a94ac3cdd93d0310d92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J8CgqQZEng2KTDAaDjz4eQ.png"/></div></div></figure><p id="5c7d" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">Pinterest的视觉搜索技术旨在为探索搜索开辟一个必去之地。他们宣称的目标呼应了这篇文章的开篇引言:“当你找不到描述它们的词语时，帮助你找到它们。”</p><p id="1554" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">Pinterest没有直接与谷歌对抗，而是决定向用户和广告商提供一些微妙不同的东西。人们去Pinterest发现新想法，创建情绪板，获得灵感。因此，Pinterest敦促其2亿用户“跳出框框搜索”，这可以被解读为对谷歌无处不在的搜索栏的温和嘲讽。</p><p id="5bc4" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">所有这些都是由<a class="ae mg" href="https://searchenginewatch.com/2017/03/16/test-driving-pinterest-lens-how-does-pinterests-new-visual-search-tool-stack-up/" rel="noopener ugc nofollow" target="_blank"> Pinterest Lens </a>驱动的，这是一个复杂的视觉搜索工具，它使用智能手机摄像头扫描物理世界，识别物体，并返回相关结果。它可以通过智能手机应用程序使用，但Pinterest的视觉搜索功能也可以通过谷歌Chrome扩展在桌面上使用。</p><figure class="ly lz ma mb gt is gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/a79a79c8fba03a8e92d286e4419198b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*J6U5abmvVv390M2j."/></div></figure><p id="5b30" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">Pinterest超过1000亿个pin的庞大数据集为机器学习应用提供了完美的训练材料。因此，物理世界和数字世界之间形成了新的联系，使用图形处理单元(GPU)来加速这一过程。</p><figure class="ly lz ma mb gt is gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/729939de01db4bf54c092ced3f77100e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*MmtKlghqzHNDG-FL."/></div></figure><p id="a2d4" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">在实践中，Pinterest Lens运行得非常好，并且随着时间的推移变得越来越好。图像检测令人印象深刻的准确和相关引脚的建议是相关的。</p><p id="43c0" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">以下是使用Pinterest和Samsung visual search搜索时选择的相同对象:</p><figure class="ly lz ma mb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi mj"><img src="../Images/79277c5052894aad266ee893467a0407.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FjyranDh06U155qJeBHPuw.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">Image created by author</figcaption></figure><p id="e398" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">结果的差异很能说明问题。</p><p id="be8c" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">在左边，Pinterest识别物体的形状、材料、用途以及设计的定义特征。这允许比直接搜索另一个黑色马克杯更深入的结果。Pinterest知道，不太明显的风格细节才是真正吸引用户的。因此，我们看到不同颜色的杯子的结果，但风格相似。</p><p id="622f" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">在右边，三星的Bixby助手可以识别物体、颜色和用途。三星的搜索结果由亚马逊提供支持，与Pinterest提供的选项相比，它们没有那么鼓舞人心。图像变成了对[黑咖啡杯]的关键字搜索，这使得视觉搜索元素有点多余。</p><p id="f1d2" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">当视觉搜索引擎为我们表达一些我们难以用语言表达的东西时，它们工作得最好。Pinterest比大多数人更了解并兑现这一承诺。</p><h1 id="8941" class="kz la ix bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">Pinterest视觉搜索:关键事实</h1><ul class=""><li id="aa43" class="mo mp ix ka b kb mq kf mr kw ms kx mt ky mu kv mv mw mx my bi translated">每月用户超过2亿</li><li id="c93f" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">侧重于搜索的“发现”阶段</li><li id="d45b" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">Pinterest Lens是中央视觉搜索技术</li><li id="2ac1" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">零售商的绝佳平台，具有明显的盈利可能性</li><li id="f546" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">付费搜索广告是该公司的核心增长领域</li><li id="cb3f" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">越来越有效的视觉搜索结果，尤其是更深层次的审美</li></ul><h1 id="f9e9" class="kz la ix bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">谷歌</h1><figure class="ly lz ma mb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi ne"><img src="../Images/ff50add64554e5bee6cd5fdee883277e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b-NsOsmNMGifeKG11UQxFA.png"/></div></div></figure><p id="27a7" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">随着谷歌眼镜的推出，谷歌在视觉搜索领域掀起了早期浪潮。这款安卓应用于2010年推出，允许用户使用智能手机摄像头进行搜索。例如，它在著名的地标上工作得很好，但是它在相当长的时间内没有显著更新。</p><p id="1fbe" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">谷歌似乎不太可能在视觉搜索上保持长时间的沉默，今年的I/O开发揭示了这个搜索巨头一直在后台进行的工作。</p><p id="3975" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">谷歌镜头将通过照片应用和谷歌助手提供，这将是对早期谷歌护目镜计划的重大改革。</p><p id="d6e9" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">任何与Pinterest产品在命名上的相似之处都可能不仅仅是巧合。谷歌最近悄悄升级了它的图像和视觉搜索引擎，推出了类似Pinterest格式的搜索结果:</p><figure class="ly lz ma mb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi nf"><img src="../Images/7a8ace810d9397c5dd692a5422968d30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6KSt1ghpyi3Ns1mWCwBtNA.png"/></div></div></figure><figure class="ly lz ma mb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi ng"><img src="../Images/3277aa6f5590b625e70776bba26e273b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ngxPNKPg83j2HoAxXBJvOA.png"/></div></div></figure><p id="b746" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">谷歌的“类似商品”产品是利用搜索发现阶段的又一举措，展示相关结果可能会进一步激起消费者的好奇心。</p><p id="3df8" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">Google Lens将提供对象检测技术，在一个强大的视觉搜索引擎中将所有这些链接在一起。在测试版中，Lens提供了以下视觉搜索类别:</p><ul class=""><li id="757a" class="mo mp ix ka b kb kc kf kg kw nh kx ni ky nj kv mv mw mx my bi translated">全部</li><li id="5593" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">衣服</li><li id="f012" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">鞋子</li><li id="8fd0" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">手提包</li><li id="7fcf" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">太阳镜</li><li id="d26e" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">条形码</li><li id="e09b" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">制品</li><li id="43cf" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">地方</li><li id="3125" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">猫</li><li id="3b1d" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">狗</li><li id="a49b" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">花</li></ul><p id="9ade" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">一些开发人员有机会尝试Lens的早期版本，许多人报告了不同的结果:</p><figure class="ly lz ma mb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi nk"><img src="../Images/777307f2956b6fbfc16919df110764cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gl76rwk0xFQnV-iZvBHB8Q.png"/></div></div></figure><p id="7be4" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated"><em class="jz">貌似谷歌不认自己家的智能中枢……(来源:</em> <a class="ae mg" href="https://www.xda-developers.com/exclusive-hands-on-with-googles-visual-search-for-android/" rel="noopener ugc nofollow" target="_blank"> <em class="jz"> XDA开发者</em> </a> <em class="jz"> ) </em></p><p id="0d91" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">对于Google Lens来说，现在还是非常早期的阶段，因此我们可以期待这项技术在从错误和成功中学习的过程中会有显著的进步。</p><p id="58c5" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">当它这样做时，谷歌处于独特的位置，使视觉搜索成为用户和广告商的强大工具。在线零售商通过付费搜索获得的机会是不言而喻的，但实体零售商也有巨大的潜力利用超本地搜索。</p><p id="c283" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">尽管Pinterest取得了令人印象深刻的进步，但它不具备像谷歌那样渗透到用户生活方方面面的生态系统。随着一款新的Pixel智能手机的研发，谷歌可以在语音搜索的同时使用视觉搜索来整合其软件和硬件。对于使用DoubleClick管理搜索和显示广告的广告商来说，这是一个非常诱人的前景。</p><p id="2aee" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">我们还应该预计，谷歌将在不久的将来进一步发展这种视觉搜索技术。</p><p id="a6c4" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">谷歌将向所有开发者开放其ARCore产品，这将为增强现实带来无限可能。ARCore是苹果ARKit的直接竞争对手，它可以提供释放视觉搜索全部潜力的钥匙。我们也不应该排除进军可穿戴设备市场的可能性，可能会推出新版谷歌眼镜。</p><h1 id="2e5e" class="kz la ix bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">谷歌视觉搜索:关键事实</h1><ul class=""><li id="5f85" class="mo mp ix ka b kb mq kf mr kw ms kx mt ky mu kv mv mw mx my bi translated">谷歌眼镜于2010年推出，是视觉搜索市场的早期进入者</li><li id="85a5" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">护目镜在一些地标上仍能很好地工作，但很难在拥挤的画面中分离出物体</li><li id="ec5e" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">谷歌眼镜计划于今年晚些时候(日期待定)推出，作为对护目镜的全面改造</li><li id="1ee7" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">Lens将把视觉搜索与谷歌搜索和谷歌地图联系起来</li><li id="8ebf" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">物体检测还不完善，但是产品还在测试阶段</li><li id="a106" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">一旦技术的准确性提高，谷歌最适合围绕其视觉搜索引擎开发广告产品</li></ul><h1 id="627a" class="kz la ix bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">堆</h1><p id="74dc" class="pw-post-body-paragraph jx jy ix ka b kb mq kd ke kf mr kh ki kw nl kl km kx nm kp kq ky nn kt ku kv ij bi translated">自2012年推出必应视觉搜索产品以来，微软在这方面一直非常低调。它从未真正起飞，也许大众对视觉搜索引擎的胃口还不太大。</p><p id="2e48" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">最近，Bing有趣地重新加入了这场争论，宣布了一个完全改进的视觉搜索引擎:</p><figure class="ly lz ma mb gt is"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="8474" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">这种策略的改变是由人工智能的进步导致的，人工智能可以自动扫描图像并隔离项目。</p><p id="526c" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">这种搜索功能的早期版本需要用户输入，在图像的特定区域周围画出方框，以便进一步检查。Bing <a class="ae mg" href="https://blogs.bing.com/search-quality-insights/2017-09/Object-Detection-in-Visual-Search" rel="noopener ugc nofollow" target="_blank">最近</a>宣布，这将不再需要，因为技术已经发展到自动化这一过程。</p><p id="dff7" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">Bing上视觉搜索结果的布局与Pinterest惊人地相似。如果模仿是最真诚的奉承形式，Pinterest现在应该已经被奉承淹没了。</p><figure class="ly lz ma mb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi nq"><img src="../Images/7f912f08ced457563751a50b3c47f531.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7uIS3tgLgmjgaGA53F-n_Q.png"/></div></div></figure><p id="dc79" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">视觉搜索技术可以锁定大多数图像中的对象，然后进一步建议用户可能感兴趣的项目。目前这仅在桌面上可用，但很快将添加移动支持。</p><p id="168e" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">结果在某些地方是不完整的，但是当探测到一个物体时，就会给出相关的建议。在下面的例子中，使用西装图片进行搜索会导致热门的可购物链接:</p><figure class="ly lz ma mb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi nr"><img src="../Images/14eab98304f7e043d54f4ea8f6af2e60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*knQILtFeZeO4b4fuJRatow.png"/></div></div></figure><p id="4b9f" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">然而，它没有考虑衬衫或领带——唯一可搜索的方面是西装。</p><p id="f536" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">使用拥挤的图片进行搜索，事情变得更加不完整。使用图片搜索客厅装饰创意会带来一些相关的结果，但不会总是专注于特定的项目。</p><p id="afcf" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">就像所有的机器学习技术一样，这个产品将继续改进，目前来看，Bing在这方面领先谷歌一步。尽管如此，从长远来看，微软缺乏用户基础和移动硬件来对视觉搜索市场发起真正的攻击。</p><p id="6652" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">视觉搜索因数据而繁荣；在这方面，谷歌和Pinterest都抢在了必应的前面。</p><h1 id="27ce" class="kz la ix bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">必应视觉搜索:关键事实</h1><ul class=""><li id="7380" class="mo mp ix ka b kb mq kf mr kw ms kx mt ky mu kv mv mw mx my bi translated">最初于2009年推出，但由于缺乏接受度，于2012年取消</li><li id="512f" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">于2017年7月重新推出，由人工智能支持，以识别和分析物体</li><li id="714d" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">广告商可以使用Bing视觉搜索来放置可购买的图片</li><li id="588a" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">这项技术还处于起步阶段，但物体识别相当准确</li><li id="166b" class="mo mp ix ka b kb mz kf na kw nb kx nc ky nd kv mv mw mx my bi translated">目前仅限于桌面，但手机很快就会跟上</li></ul><h1 id="7fff" class="kz la ix bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">那么，谁拥有最好的可视化搜索引擎呢？</h1><p id="47ef" class="pw-post-body-paragraph jx jy ix ka b kb mq kd ke kf mr kh ki kw nl kl km kx nm kp kq ky nn kt ku kv ij bi translated">目前来看，Pinterest。数十亿个数据点和一些经验丰富的图像搜索专业人士推动着这项技术，它提供了最流畅和最准确的体验。它还通过抓住物体的风格特征，而不仅仅是它们的形状或颜色，做出了一些独特的事情。因此，它改变了我们可以使用的语言，扩展了搜索的范围。</p><p id="7d4a" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">Bing最近在这一领域取得了巨大的进步，但是它缺少一个足以吸引谷歌搜索者的杀手级应用。Bing视觉搜索准确且功能强大，但不能像Pinterest那样创建与相关项目的联系。</p><p id="569a" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated">谷歌眼镜的推出肯定也会彻底撼动这个市场。如果谷歌能够确定自动物体识别(它无疑会做到)，谷歌眼镜可能会成为将传统搜索与增强现实联系起来的产品。从长远来看，谷歌拥有的资源和产品套件使其成为可能的赢家。</p></div><div class="ab cl ns nt hu nu" role="separator"><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx ny"/><span class="nv bw bk nw nx"/></div><div class="ij ik il im in"><p id="6ad0" class="pw-post-body-paragraph jx jy ix ka b kb kc kd ke kf kg kh ki kw kk kl km kx ko kp kq ky ks kt ku kv ij bi translated"><em class="jz">最初发表于</em><a class="ae mg" href="https://searchenginewatch.com/2017/09/28/pinterest-google-or-bing-who-has-the-best-visual-search-engine/" rel="noopener ugc nofollow" target="_blank"><em class="jz">【searchenginewatch.com】</em></a><em class="jz">。</em></p></div></div>    
</body>
</html>