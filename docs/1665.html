<html>
<head>
<title>Why does gradient descent work?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">梯度下降为什么有效？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-does-gradient-descent-work-128713588136?source=collection_archive---------6-----------------------#2017-10-02">https://towardsdatascience.com/why-does-gradient-descent-work-128713588136?source=collection_archive---------6-----------------------#2017-10-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b3c3" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">你可能明白，但你见过吗？</h2></div><p id="c806" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">我)何苦呢</strong></p><p id="c76f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，让我们把房间里的大象弄走。你为什么要读这个博客？首先，因为它有很棒的动画，如下图1所示。你不想知道这张照片里发生了什么吗？</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lb"><img src="../Images/2018e4218efedc910ffdb9afd90b61c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*uOIj-VW5PhEO__XOFFT0DQ.gif"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Figure 1: A plane with its gradient. Created by author using: <a class="ae ln" href="https://github.com/ryu577/pyray" rel="noopener ugc nofollow" target="_blank">https://github.com/ryu577/pyray</a></figcaption></figure><p id="1bc0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第二，因为优化非常非常重要。我不管你是谁，那应该是真的。我的意思是，这是寻找最好的科学。它让你选择你对“最好”的定义，然后不管那可能是什么，告诉你你能做什么来实现它。就这么简单。<br/>此外，尽管最优化——作为一门完整的科学——有很多深度，但它有一个基本的一阶技术，叫做“梯度下降”,非常容易理解。事实证明，这项技术实际上是实践中应用最广泛的。至少在机器学习中，随着模型变得越来越复杂，使用复杂的优化算法变得越来越困难。所以大家就用梯度下降。换句话说，学习梯度下降，你就学会了最简单，但也是最优化中最广泛使用的技术。那么，让我们非常直观地理解这个技巧。</p><p id="77a1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> II)优化要点</strong></p><p id="e98b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如我在上一节提到的，优化是非常棒的。它包括取一个单一的数字——例如，你银行账户里的钱的数量，或者你床上的臭虫的数量——并告诉你如何使它尽可能好(如果你像大多数人一样，第一种情况下高，第二种情况下低)。让我们称这个东西为我们试图优化的z. <br/>当然这里隐含的假设是，我们可以以某种方式控制我们想要优化的东西。假设它依赖于某个变量(比如x，它在我们的控制之内。所以，在x的每一个值上，都有z的某个值(我们想找到使z最好的x)。可能有一些等式可以描述这个图。假设f(x，z) = 0。但是在最优化的背景下，我们需要用以下形式来表示:z= f(x)(假设原方程有利于这样分离z和x)。然后，我们可以问——“x的什么值对应最佳z？”。如果我们有一个很好的连续函数，那么有一点我们可以肯定的说，在这个特殊的x处，z= f(x)的导数(一般用f'(x)表示)将为零。</p><p id="e0a8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> III)什么是梯度</strong></p><p id="77de" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我们要优化的东西依赖于不止一个变量时，导数的概念就延伸到了梯度。所以，如果上面的z依赖于x和y，我们可以把它们收集到一个单独的向量u = [x，y]。因此，当z= f(x，y) = f(u)时，z的梯度变为:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lo"><img src="../Images/16b2ea39de4abf353e4caa1327d26527.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/0*GoAPyhOuZ7SeDJBR.png"/></div></div></figure><p id="4553" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就像导数一样，我们可以确定，优化z的u值，会使梯度的两个分量都等于零。<br/>顺便提一下，梯度在任何光滑、可微函数的泰勒级数展开中起着重要作用:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/83b1baaf943e537fcd38bf252b92c2ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/0*4ZI5WS5erB7AAp2j.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Equation (1)</figcaption></figure><p id="224e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如你所见，右边的前两项只涉及u，没有平方、立方或更高的幂(那些在后面的项中出现)。前两项恰好也是u=a附近函数的最佳线性近似。下面我们展示简单抛物面(z = x + y)的线性近似。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lu"><img src="../Images/f4b9c1a2460599fb429200efa4148d3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*rp76FYNMOhZjVoBeoD6PQA.gif"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Figure 2: The best approximation of a paraboloid (pink) by a plane (purple) at various points. Created for this blog using: <a class="ae ln" href="https://github.com/ryu577/pyray" rel="noopener ugc nofollow" target="_blank">https://github.com/ryu577/pyray</a></figcaption></figure><p id="a880" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> IV)线性函数</strong></p><p id="ec2e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们在上一节中看到，梯度可以用线性函数很好地表示。因此，我们将限制讨论线性函数。对于一个线性函数的方程，我们只需要知道它与轴的交点。<br/>如果我们只有一个维度(x轴),相交发生在x=a，我们可以这样描述</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/299b66aad85d14b3a5ce9ca8c3f42c09.png" data-original-src="https://miro.medium.com/v2/resize:fit:136/format:webp/0*cT_D6Gc_DJRve16y.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Equation (2)</figcaption></figure><p id="5ef7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们有两个维度(x轴和y轴),并且直线在x=a处与x轴相交，在y=b处与y轴相交，则等式变为</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/771d40bc0f201f1132ec68f7c11c9407.png" data-original-src="https://miro.medium.com/v2/resize:fit:246/format:webp/0*xnwl3j55iuLQdI_o.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Equation (3)</figcaption></figure><p id="a981" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当y=0时，我们得到x/a=1，和上面的等式一样。<br/>如果我们有三维空间会怎么样？我想你知道这是怎么回事</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/0e9586a9ad1e8b829742c90c9911669c.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/format:webp/0*1VzDpfAXRgWCaRFk.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Equation (4)</figcaption></figure><p id="7f7f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以此类推(顺便说一下，这就是你在上面的图1中看到的红色飞机)。<br/>现在，我们可以看到上面所有的方程在x，y，z等方向上都是对称的。然而，在优化的上下文中，它们中的一个具有特殊的地位。这是我们寻求优化的变量。假设这个特殊变量是z，在我们想把这个表示成一个优化问题的时候，需要把方程表示成z=f(x)。如果我们对等式(4)这样做，我们得到的是</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/ef32a3ebf195a783811e97817610478b.png" data-original-src="https://miro.medium.com/v2/resize:fit:412/format:webp/0*SNREcYJUI90lhFFw.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Equation (5)</figcaption></figure><p id="8861" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我想增加我的线性函数。我应该去哪里？</p><p id="e2e6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是这个博客的中心问题。你有上面方程描述的线性函数，x和y在你的控制之下。你发现自己处于(x，y)的某个值。为了简单起见，我们假设在当前点z=0。你可以沿着任何方向走1个单位的一步。问题变成了，你应该朝哪个方向迈出这一步？下面的图3展示了这个难题，展示了你可以走的无限的方向。每个方向以不同的量改变目标函数z。因此，其中一个将最大程度地增加z，而另一个将最大程度地减少z(取决于我们想要最大化还是最小化它的天气)。<br/>请注意，如果我们的控制中只有一个变量(比如x ),这就容易多了。只有两个方向可供选择(增加x或减少x)。然而，一旦我们有了两个或更多的自由变量，选择的数量就会从两个跳到无穷大。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi lu"><img src="../Images/e2f03c47d67f1afe1cfdabba59bb7061.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*xH1C-m7xmn-puTu9RS0i5A.gif"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Figure 3: The infinite directions we can move along. Which one should we choose? Created for this blog using: <a class="ae ln" href="https://github.com/ryu577/pyray" rel="noopener ugc nofollow" target="_blank">https://github.com/ryu577/pyray</a></figcaption></figure><p id="9df2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们想找出z变化最大的方向。所以我们反其道而行之(说，因为我们有点疯狂？).我们来寻找z完全不变的方向。如果你仔细观察上图，你会发现当绿色箭头与橙色线(绿色网格和红色平面相交的线)对齐时会发生这种情况。如果你继续盯着看，你可能会注意到当绿色箭头垂直于橙色线时，z变化最大。因此，这条橙色的线似乎可以让我们对这个问题有所了解。那么橙色线是什么？很明显，这是我们的平面与代表x-y平面的绿色网格(我们可以沿着它移动的网格)相交的地方。x-y平面的方程是什么？它将是z=0。换句话说，z在上面不变。所以，既然橙线完全位于网格上，那么它也一定在网格上处处都有z=0。难怪当我们的绿色箭头使我们简单地沿着橙色线移动时，z拒绝改变。</p><p id="aea0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">至于橙色线的方程，就是平面的方程-</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/bcd11c14f6271809f8de7a124f951bd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/format:webp/0*Ds90GYAwmE6Jbh_4.png"/></div></figure><p id="fc89" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">和x-y网格；z=0同时得到满足。这给了我们</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/31b2a4ba2246452205dbc259e5edac40.png" data-original-src="https://miro.medium.com/v2/resize:fit:246/format:webp/0*aHuhJ9LEykNGaPAo.png"/></div></figure><p id="7da4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，从上面橙色线的方程可以清楚地看出，当y=0时，x=a .所以，它与x轴相交的点的位置向量为o_x : [a，0] (o代表橙色)。同样，它与y轴相交的点是o_y : [0，b]。现在我们有了直线上两点的位置向量，我们减去它们得到一个沿直线的向量(o)。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/83bd7c5699edf22828bb56598ccbaa0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/0*xNpuM4SPiKYpsbEg.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Equation (6)</figcaption></figure><p id="79e2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，如果我们能证明梯度垂直于这个向量，我们就完成了。这将给我们一些直觉，为什么梯度变化z最大。</p><p id="4e5c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> VI)平面的倾斜度</strong></p><p id="ff25" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将第三节中梯度的定义应用于上方平面的方程(x/a+y/b+z/c=1 ),我们得到-</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/03bf75ec12685a8f33c4efe8f426b700.png" data-original-src="https://miro.medium.com/v2/resize:fit:182/format:webp/0*ZLOqEO_IMT5lz7ve.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Equation (7)</figcaption></figure><p id="c9e0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这使得梯度:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/563fdb30f284aa8d426ea224445ee5d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:250/format:webp/0*UDYUZsneRxfjRe3R.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Equation (8)</figcaption></figure><p id="7414" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们知道两个向量要正交，它们的点积必须为零。取点积或平面的梯度(来自等式(7))和沿着橙色线的矢量(来自等式(6))，我们得到，</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/1af2d2699151e6b331cf8179a682ae35.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/0*oRpKadcGCyEm9EyO.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Equation (9)</figcaption></figure><p id="4c85" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们知道了，梯度与垂直于橙线的方向一致，所以，它改变z最大。事实证明，沿梯度方向增加z最多，而沿相反方向(注意，这两个方向都与橙色线正交)减少z最多。</p><p id="e0a3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我将留给你们这个可视化的演示，当我们改变平面时，梯度继续顽固地指向改变它最大的方向。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lb"><img src="../Images/aa2806a0ef1c81a46d7f6e942ce99611.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/1*UD7cddf93_1EziOGDlqGTg.gif"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Figure 4: As we change the plane, the gradient always aligns itself with the direction that changes it the most. Crated for this blog using: <a class="ae ln" href="https://github.com/ryu577/pyray" rel="noopener ugc nofollow" target="_blank">https://github.com/ryu577/pyray</a></figcaption></figure></div></div>    
</body>
</html>