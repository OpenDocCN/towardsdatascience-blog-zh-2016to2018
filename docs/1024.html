<html>
<head>
<title>Classifying Crisis Reports</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">危机报告分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/classifying-crisis-reports-17464661221d?source=collection_archive---------6-----------------------#2017-07-21">https://towardsdatascience.com/classifying-crisis-reports-17464661221d?source=collection_archive---------6-----------------------#2017-07-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="9afc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇文章描述了我对日益增长的不稳定性的解决方案:由英国科技部、军情五处和军情六处组织的危机报告分类挑战。该解决方案在579个竞争对手中获得第三名。 <a class="ae km" href="https://www.datasciencechallenge.org/challenges/2/growing-instability" rel="noopener ugc nofollow" target="_blank"> <em class="kl">链接到最终排行榜</em> </a> <em class="kl">。</em></p><h1 id="e1dd" class="kn ko iq bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">任务描述</h1><p id="4953" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">文本分类是给一段文本分配一个类别或范畴的任务。它是自然语言处理领域的一个分支，在情感分析、垃圾邮件检测和标签等方面都有应用。在这个挑战中，目标是用危机标签对《卫报》的文章进行分类。标签的几个例子是“澳大利亚安全和反恐”，“集束炸弹”，“埃博拉”，“法国火车袭击”，“美国枪支控制”。</p><p id="0ebc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">挑战提供了一个训练集和一个测试集。训练集包括从1999年到2014年的所有新闻文章及其标签。大约有160万篇文章。测试集由2015年和2016年的文章样本组成。主题词典提供了所有的危机标签。主题词典中共有160个标签。标签可以分为两种类型:</p><ul class=""><li id="f0e2" class="lq lr iq jp b jq jr ju jv jy ls kc lt kg lu kk lv lw lx ly bi translated">围绕特定事件的话题。例如“里约20地球峰会”、“突尼斯袭击2015”。与这些主题相关的文章通常只在某一段时间内(一个月或一年)出现</li><li id="8ff2" class="lq lr iq jp b jq lz ju ma jy mb kc mc kg md kk lv lw lx ly bi translated">围绕概念的话题。例如“伦理”、“印度”、“德国”。与这些主题相关的文章在大多数年份都有。但是，内容每年都不一样。</li></ul><p id="8b7a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">任务的评估指标是微观平均F1分数。这是通过对测试示例的每个单独决策的真阳性、假阳性和假阴性求和来获得的，以产生其中每个测试示例(文档)被同等加权的全局平均值。</p><p id="2c65" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">F1得分= 2×TP / (2×TP + FP + FN)</p><h1 id="d0f8" class="kn ko iq bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">数据集探索和基线</h1><p id="7777" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">大多数文章的标签不在主题词典中。训练集中大约有235，000篇文章具有出现在主题词典中的标签。我们使用这个子集进行开发和验证。</p><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi me"><img src="../Images/6f0922701a1a98d7de167299f5ec9063.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*S-8SdcnH7qaQ-z5nh1yrhA.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">Fig 1: Number of articles per topic</figcaption></figure><p id="c630" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一些主题如“英国犯罪”、“伊拉克”、“宗教”和“移民”有大量的文章(超过15000)。大多数题目至少有100个例子。有趣的部分是12个主题没有任何文章。分别是'布鲁塞尔袭击'、'巴士底日卡车袭击'、'寨卡病毒'、'奥兰多恐怖袭击'、'柏林圣诞市场袭击'、'查理周刊袭击'、'突尼斯袭击2015 '、'圣贝纳迪诺枪击案'、'巴黎袭击'、'和平与和解'、'土耳其政变企图'、'法国火车袭击'、'激进主义'、'慕尼黑枪击案'。这些主题大多是发生在2015年和2016年的事件(除了“和平与和解”和“激进主义”)，因此没有关于它们的培训数据。</p><p id="dd2e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个挑战是一个多标签分类的例子，其中多个标签可以分配给每件商品。我把标签编码成一个160维的热向量。我尝试的两个基线是单词包和平均单词向量。在前一种情况下，我将文章转换成一袋单字和双字，并使用它们的频率作为特征。在后者中，我首先使用训练集来训练300维的单词嵌入。然后我把每篇文章转换成一个300 dim的均值嵌入。前一个特征集是稀疏向量，而后一个是密集向量。我在这两个特征集上应用的两个机器学习算法是前馈神经网络和梯度推进决策树。F1的最佳基线得分为0.38。</p><h1 id="6cb5" class="kn ko iq bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">体系结构</h1><p id="ef97" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">我在这次挑战中使用了两种方法:</p><ul class=""><li id="d258" class="lq lr iq jp b jq jr ju jv jy ls kc lt kg lu kk lv lw lx ly bi translated">在训练集中有文章的主题的监督学习。这让我在公开数据上的F1分数达到了0.64左右。</li><li id="100c" class="lq lr iq jp b jq lz ju ma jy mb kc mc kg md kk lv lw lx ly bi translated">用于在训练集中没有文章的主题的规则引擎，其在公开数据上将上述分数提高到0.6626 F1分数。</li></ul><p id="4d6d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于监督学习部分，这里是我实验的算法。所有模型都是用Keras实现的:</p><ul class=""><li id="c7f7" class="lq lr iq jp b jq jr ju jv jy ls kc lt kg lu kk lv lw lx ly bi translated"><strong class="jp ir">卷积神经网络:</strong>CNN是用于文本分类的常用模型之一。Kim Yoon关于用于句子分类的<a class="ae km" href="http://www.aclweb.org/anthology/D14-1181" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a>的论文是一个很好的起点。我通过修改过滤器的数量、池大小和过滤器大小来试验不同的架构。我还用预先训练的手套向量、谷歌新闻向量和输入数据上训练的嵌入进行了实验。对我有用的架构是使用在输入上训练的嵌入。随后是5个卷积层，滤波器尺寸为3、5、7、9和11。在这之后，有一个合并层，然后依次是3个卷积，池和辍学层。最后一层是尺寸为160的softmax层。<br/>模型的最后一部分是确定每个主题的阈值。最初，我尝试将所有主题的阈值设为0.5。然而，为每个主题选择不同的阈值有相当大的提升。阈值是在验证集上学习的。最好的成绩是F1得分0.615。</li></ul><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi mq"><img src="../Images/fbfcca2753a622219b9ccc4c7facfc14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1bvcGSs6wiGFVUqUzUeL6Q.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">Fig 2: CNN architecture diagram Source: <a class="ae km" href="http://www.aclweb.org/anthology/D14-1181" rel="noopener ugc nofollow" target="_blank">http://www.aclweb.org/anthology/D14-1181</a></figcaption></figure><ul class=""><li id="02bc" class="lq lr iq jp b jq jr ju jv jy ls kc lt kg lu kk lv lw lx ly bi translated"><strong class="jp ir">具有softmax层的双向LSTM:</strong>这是另一种用于文本分类的通用架构。基本层是单词嵌入，接着是双向LSTM层和softmax层。在对这个模型做了一点试验后，我意识到它有两个缺点。首先，与CNN模型相比，它在每个时期花费了大约3倍的时间(所有训练都是在AWS p2.xlarge中完成的，其中有Tesla k80 GPU)。二是性能比CNN机型差很多。最好的F1成绩是0.52。因此，我决定不再继续这种模式。</li></ul><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/c9582d23e80f4388798db96b999eb957.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*v0dEBhoU5loa8GfDg_dijw.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">Fig 3: LSTM network for classification Source: <a class="ae km" href="http://deeplearning.net/tutorial/lstm.html" rel="noopener ugc nofollow" target="_blank">http://deeplearning.net/tutorial/lstm.html</a></figcaption></figure><ul class=""><li id="ead5" class="lq lr iq jp b jq jr ju jv jy ls kc lt kg lu kk lv lw lx ly bi translated"><strong class="jp ir">关注GRU网络:</strong>我试验的下一个模型是GRU网络上的关注层。gru在某种意义上类似于LSTMs，它们使用门控机制来学习长期依赖性。然而，它们具有较少的门(它们没有输出门)，因此具有较少的参数。他们的训练速度相当快，F1分数为0.621。</li><li id="c816" class="lq lr iq jp b jq lz ju ma jy mb kc mc kg md kk lv lw lx ly bi translated"><strong class="jp ir">分层注意模型:</strong>该体系结构首先由杨等人在论文【用于文档分类的分层注意网络】中提出。艾尔。这个模型的独特之处在于，它有两个层次的注意机制，既适用于单词，也适用于句子。这有助于它有区别地识别更多和更少的重要内容。我在这里使用了Richard Liao实现的模型<a class="ae km" href="https://richliao.github.io/supervised/classification/2016/12/26/textclassifier-HATN/" rel="noopener ugc nofollow" target="_blank"/>。这个模型的优点是，当我们查看给定文本的注意力权重时，我们可以了解哪些单词和句子对标签有贡献。这对于调试非常有用。这也被证明是最佳的单一网络模型，F1值为0.626。</li></ul><figure class="mf mg mh mi gt mj gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/519a32b74e17460291ab2070f140fa11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*iLcGWHwIWDUorLXCtVX3yA.png"/></div></figure><ul class=""><li id="3baf" class="lq lr iq jp b jq jr ju jv jy ls kc lt kg lu kk lv lw lx ly bi translated"><strong class="jp ir">以上模型的叠加:</strong>在检查了这些模型的输出后，我意识到，对于很多题目来说，输出并不是高度相关的。这为堆叠这些模型提供了机会。我使用开发集的交叉验证，从每个模型中创建了一个160维的特征向量。这导致了一个640维的特征向量，我通过一个前馈网络。该网络有两个隐层，分别为480和320个单元。这给了我最好的F1成绩0.6415。</li></ul><p id="21a3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">到目前为止，我对没有训练数据的主题的预测为零。由于许多话题都是欧洲的重大恐怖袭击，我预计《卫报》会有大量报道。我试验的最初模型是检查文章中是否存在主题字符串。例如，对于主题“巴黎袭击”，将所有具有字符串“巴黎袭击”的文章标记为真。但是这个模型导致了召回率的损失，并且没有特别高的精度(与《查理周刊》袭击事件相关的文章也有‘巴黎袭击’这个短语)。该模型的下一次迭代涉及使用主题字符串中所有标记的计数作为特征，并使用手动阈值进行区分。然而，选择最佳阈值是困难的，我没有取得任何重大进展。</p><p id="b6f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">到目前为止，我还没有在任何文章中使用过的一个特性是文章的日期。这在这里很有用，因为在袭击发生之前不会有关于“巴黎袭击”的文章。另一个认识是，在攻击后的几天内，它的主题标签和攻击位置的主题标签有很高的相关性。例如，在巴黎袭击之后，标签“法国”和“巴黎”与“巴黎袭击”有很强的相关性。我使用这种相关性来创建一个种子文章集，这些文章极有可能属于新标签。考虑作为种子集一部分的文章是在攻击当天到攻击后一周内发表的文章(对于覆盖范围更大的攻击，这可能会增加)。然后，我建立了一个命名实体袋监督学习模型，以在结束后对文章进行分类(我最初尝试使用单词袋，但它给出的结果比命名实体袋差)。对于模型的反面例子，我使用了该日期之前文章的随机样本。这在实践中效果很好，我能够在公共数据集上获得0.6626的分数。</p><h1 id="770d" class="kn ko iq bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">未来的工作</h1><p id="3963" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">我很想在未来探索一些想法，但是没有足够的带宽:</p><ul class=""><li id="b9cd" class="lq lr iq jp b jq jr ju jv jy ls kc lt kg lu kk lv lw lx ly bi translated">为每个主题标签建立一个模型，而不是一个统一的模型。</li><li id="b465" class="lq lr iq jp b jq lz ju ma jy mb kc mc kg md kk lv lw lx ly bi translated">将所有的CNN、RNN和注意力模型合并成一个大的神经网络，而不是堆叠。</li><li id="4c91" class="lq lr iq jp b jq lz ju ma jy mb kc mc kg md kk lv lw lx ly bi translated">探索没有训练数据的主题的替代模型。</li><li id="c72c" class="lq lr iq jp b jq lz ju ma jy mb kc mc kg md kk lv lw lx ly bi translated">更好地利用日期特性进行分类。直觉上，一篇1999年的文章和一篇2014年的文章权重相同是没有意义的。</li></ul><p id="edb2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">不幸的是，作为竞赛协议的一部分，我们不得共享数据和代码。但是，希望这篇文章对所有文本分类从业者有用。</em></p></div></div>    
</body>
</html>