<html>
<head>
<title>Review: VDSR (Super Resolution)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回顾:VDSR(超分辨率)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-vdsr-super-resolution-f8050d49362f?source=collection_archive---------6-----------------------#2018-10-30">https://towardsdatascience.com/review-vdsr-super-resolution-f8050d49362f?source=collection_archive---------6-----------------------#2018-10-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="8fab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi kl translated"><span class="l km kn ko bm kp kq kr ks kt di"> T </span>他的时代，<strong class="jp ir"> VDSR </strong> <strong class="jp ir">(极深超分辨率)</strong>回顾。VDSR 是一种用于放大图像的深度学习方法。它有<strong class="jp ir"> 20 个权重层</strong>，比只有 3 层的 SRCNN 要深得多。</p><blockquote class="ku kv kw"><p id="6fd2" class="jn jo kx jp b jq jr js jt ju jv jw jx ky jz ka kb kz kd ke kf la kh ki kj kk ij bi translated">有时，我们只得到一个很差的图像，我们想进行数字放大(放大)，但当放大时图像变得模糊。这是因为常规的插值或放大把一幅小图像变成一幅大图像，会得到很差的图像质量。使用 VDSR，我们可以从低分辨率(LR)图像获得高质量的高分辨率(HR)图像。</p></blockquote><p id="1914" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是两个例子。</p><p id="d423" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">VDSR 是经典的最先进的 SR 方法之一，在我撰写本文时，发表在<strong class="jp ir"> 2016 CVPR </strong>上，被引用约<strong class="jp ir"> 800 次</strong>。(<a class="lb lc ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----f8050d49362f--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ld"><img src="../Images/168a07e3dec11ab33f94fca02f6a8bc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8VUw8qTc-bGXMUIMoX4nDQ.png"/></div></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk"><strong class="bd lt">Much Clear Image after Enlargement Using VDSR (Edges are much clearer)</strong></figcaption></figure><figure class="le lf lg lh gt li"><div class="bz fp l di"><div class="lu lv l"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk"><strong class="ak">Some More Amazing Results</strong></figcaption></figure><p id="77d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">结果很惊人！！那么，让我们来看看它是如何工作的。</p></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h1 id="bf0c" class="md me iq bd mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na bi translated">涵盖哪些内容</h1><ol class=""><li id="9e57" class="nb nc iq jp b jq nd ju ne jy nf kc ng kg nh kk ni nj nk nl bi translated"><strong class="jp ir"> VDSR 网络架构</strong></li><li id="c502" class="nb nc iq jp b jq nm ju nn jy no kc np kg nq kk ni nj nk nl bi translated"><strong class="jp ir">关于培训的一些细节</strong></li><li id="d6f2" class="nb nc iq jp b jq nm ju nn jy no kc np kg nq kk ni nj nk nl bi translated"><strong class="jp ir">结果</strong></li></ol></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h1 id="bb87" class="md me iq bd mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na bi translated"><strong class="ak"> 1。VDSR 网络架构</strong></h1><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nr"><img src="../Images/f2b106e267a25096cf0ca625cf3eefed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1JbheZVd8ixUPXm1ilQu3Q.png"/></div></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk"><strong class="bd lt">VDSR Network Architecture</strong></figcaption></figure><p id="1bb0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">VDSR 架构如上图所示:</p><ol class=""><li id="a29c" class="nb nc iq jp b jq jr ju jv jy ns kc nt kg nu kk ni nj nk nl bi translated">将<strong class="jp ir"> LR 图像插值为 ILR 图像</strong>并输入到网络。</li><li id="45f3" class="nb nc iq jp b jq nm ju nn jy no kc np kg nq kk ni nj nk nl bi translated">ILR 图像经过<strong class="jp ir"> (D-1)次 Conv 和 ReLU 层</strong>。</li><li id="959b" class="nb nc iq jp b jq nm ju nn jy no kc np kg nq kk ni nj nk nl bi translated">然后后面跟着一个<strong class="jp ir"> D-th Conv </strong> (Conv。图中的 d(残差)。</li><li id="71e3" class="nb nc iq jp b jq nm ju nn jy no kc np kg nq kk ni nj nk nl bi translated">最后，<strong class="jp ir">输出与 ILR 图像相加，得到 HR 图像</strong>。</li></ol><p id="ad78" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些是<strong class="jp ir"> 64 个大小为 3×3 的过滤器，用于每个 conv 层</strong>。(VGGNet 已经解决了连续的<strong class="jp ir"> </strong> 3×3 滤波器的问题，这有助于获得更大的感受野，因此我们不需要任何大的滤波器，例如 5×5 和 7×7。<a class="ae nv" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener">如果有兴趣，请阅读我的 VGGNet 评论。</a>)</p><p id="45f2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如我们所见，ILR 被添加到网络的输出中，以恢复 HR 图像，损失函数变为:</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi nw"><img src="../Images/3d9ff472043cd378d0fda9ccb828bf5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:238/format:webp/1*arQN5YPUOxO8RLaOL0M_cg.png"/></div></div></figure><p id="8318" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中<strong class="jp ir"> r=y-x </strong>。因此，<strong class="jp ir">网络正在学习输出和输入之间的残差</strong>，而不是像 SRCNN 一样直接学习 HR 输出。</p><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/b70fc05569a371acf70643ee27590c5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*CouDISyQgcuppBYywNwJog.png"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk"><strong class="bd lt">Residual vs Non-Residual with Different Learning Rate</strong></figcaption></figure><p id="8335" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">有了残差学习，收敛比无残差学习快得多</strong>。在第 10 时段，残差已经达到 36 dB 以上，而非残差仍然只有 27-34 dB。</p></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h1 id="1014" class="md me iq bd mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na bi translated"><strong class="ak"> 2。关于培训的一些细节</strong></h1><h2 id="c96c" class="ny me iq bd mf nz oa dn mj ob oc dp mn jy od oe mr kc of og mv kg oh oi mz oj bi translated">2.1 可调渐变剪辑</h2><p id="c2ac" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy ok ka kb kc ol ke kf kg om ki kj kk ij bi translated"><strong class="jp ir">梯度被剪裁到[-θ/γ；θ/γ ] </strong>，其中γ表示当前的学习速率。并且<strong class="jp ir"> θ被调整得很小，以避免在高学习率状态下爆发梯度</strong>。</p><p id="7b73" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当 D= 20 时，20 层网络训练在 4 小时内完成，而 3 层 SRCNN 需要几天来训练。</p><h2 id="e9dd" class="ny me iq bd mf nz oa dn mj ob oc dp mn jy od oe mr kc of og mv kg oh oi mz oj bi translated">2.2 多尺度训练</h2><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi on"><img src="../Images/8d94839863a9a585413ea58c2c4e0079.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*2Xw3XaP7NGWTrJCZeKDbdQ.png"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk"><strong class="bd lt">Mutli-Scale Training Results</strong></figcaption></figure><p id="5460" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当使用单尺度图像时，网络只能在测试期间对相同尺度工作良好，对于其他尺度的测试，PSNR 甚至比传统的双三次插值更差。</p><p id="6027" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">通过使用×2、×3、×4 尺度的图像进行训练，在测试过程中所有尺度都获得了最高的峰值信噪比。</strong></p><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi oo"><img src="../Images/a7dbba672bc76995a73d40f7fce06c08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UR4lm3QGxFQgGX2dDYFKiA.png"/></div></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk"><strong class="bd lt">Multi-Scale VDSR (Top), Single-Scale Dong’s [5] (Bottom)</strong></figcaption></figure><p id="a24f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">单尺度 Dong 的[5]获得模糊的图像，而 VDSR 具有更清晰的边缘。</p></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h1 id="9031" class="md me iq bd mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na bi translated">3.结果</h1><figure class="le lf lg lh gt li gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi op"><img src="../Images/4ddcb9249eab305c72764a298a67dbec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ExEkRTq4hhG66O75gS4FAw.png"/></div></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk"><strong class="bd lt">Comparison with State-of-the-art Results (Red: The best, Blue: 2nd Best)</strong></figcaption></figure><figure class="le lf lg lh gt li gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/b27b992d10789a976864cd7f3855ac8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*BZ2uyWdxwmLR40TFU5yBDQ.png"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk"><strong class="bd lt">VDSR is much faster than SRCNN</strong></figcaption></figure><p id="a9a9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上表显示<strong class="jp ir"> t VDSR 用最少的测试时间</strong>获得了最好的结果。</p></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><p id="104c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">随着人工智能芯片组在未来变得流行，VDSR 或其他最先进的方法可以实时应用于图像放大，甚至应用于视频。</p></div><div class="ab cl lw lx hu ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ij ik il im in"><h1 id="0c04" class="md me iq bd mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na bi translated">参考</h1><ol class=""><li id="702b" class="nb nc iq jp b jq nd ju ne jy nf kc ng kg nh kk ni nj nk nl bi translated">【2016 CVPR】【VDSR】<br/><a class="ae nv" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Kim_Accurate_Image_Super-Resolution_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank">使用极深度卷积网络的精确图像超分辨率</a></li></ol><h1 id="a581" class="md me iq bd mf mg or mi mj mk os mm mn mo ot mq mr ms ou mu mv mw ov my mz na bi translated">我的相关评论</h1><p id="8939" class="pw-post-body-paragraph jn jo iq jp b jq nd js jt ju ne jw jx jy ok ka kb kc ol ke kf kg om ki kj kk ij bi translated">[<a class="ae nv" href="https://medium.com/coinmonks/review-srcnn-super-resolution-3cb3a4f67a7c" rel="noopener">Sr CNN</a>][<a class="ae nv" rel="noopener" target="_blank" href="/review-fsrcnn-super-resolution-80ca2ee14da4">fsr CNN</a>][<a class="ae nv" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener">VGGNet</a>]</p></div></div>    
</body>
</html>