<html>
<head>
<title>Lumiere London 2018 (Part 3): Computer Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">琉米爱尔伦敦 2018(第三部分):计算机视觉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/lumiere-london-2018-part-3-computer-vision-d4918effff4?source=collection_archive---------18-----------------------#2018-12-21">https://towardsdatascience.com/lumiere-london-2018-part-3-computer-vision-d4918effff4?source=collection_archive---------18-----------------------#2018-12-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="07c5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">第三部分:用计算机视觉分析 5000 张 Flickr 图片</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/cf4b3cc94bc1cd1b16fbd18e5527f23b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KYIr3NOq3IUJ0F-gsskvvQ@2x.png"/></div></div></figure><h2 id="2e58" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">介绍</h2><p id="6c20" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">在这一系列的最后一篇博客文章中，我应用计算机视觉技术来理解 5000 张关于琉米爱尔伦敦 2018 的 Flickr 图像，这是今年 1 月初在伦敦举行的一场大型灯光节。</p><p id="75d8" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">在 2018 年伦敦琉米爱尔展期间，53 位艺术家的 50 多件公共艺术品在伦敦的六个区展出，为期四天，从 1 月 18 日星期四到 1 月 21 日星期日，超过 100 万人参加了这个节日！</p><p id="b815" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">在本系列的<a class="ae mo" rel="noopener" target="_blank" href="/analyzing-the-lumiere-london-2018-light-festival-part-2-98eb3769e267?source=friends_link&amp;sk=f4e161cc63042e8128658700163f4bbd">第二部分</a>和<a class="ae mo" rel="noopener" target="_blank" href="/analyzing-the-lumiere-london-2018-light-festival-part-1-eb0284d317c7?source=friends_link&amp;sk=6636c299230848b95d4c4fc43c7d5ba4">第一部分</a>中，我展示了自然语言处理和对 11000 条关于这个节日的推文的探索性数据分析。</p><p id="ad13" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">本文的目的是使用计算机视觉分析来理解我从 Flickr 上传的 5000 张图片，并把它们放在上下文中。</p><p id="f09a" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">请向下滚动查看分析！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/641fa686259cb53638fa777fcccec6e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*ShPRkGRZt3gHc5liQGsC1w.jpeg"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">An image of Lumiere London 2018. Source: Flickr</figcaption></figure><h2 id="f1f5" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">数据和方法</h2><p id="8485" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">使用<a class="ae mo" href="https://www.flickr.com/services/api/" rel="noopener ugc nofollow" target="_blank"> Flickr API </a>，它使用起来相当简单，我收集了包含文本“琉米爱尔伦敦”的图像，这些图像是在 2018 年 1 月 1 日至 4 月 1 日之间上传到 Flickr 上的。总共有 5047 张图片。</p><p id="ba0b" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">然后，使用<a class="ae mo" href="https://cloud.google.com/vision/docs/" rel="noopener ugc nofollow" target="_blank">谷歌云的视觉 API </a>提取每张图像的标签。Cloud Vision API 利用“谷歌庞大的机器学习专业知识网络”(g <a class="ae mo" href="https://medium.com/@srobtweets/exploring-the-cloud-vision-api-1af9bcf080b8" rel="noopener"> reat article </a>作者<a class="mu mv ep" href="https://medium.com/u/7f2ab73b39f8?source=post_page-----d4918effff4--------------------------------" rel="noopener" target="_blank"> Sara Robinson </a>)来检测图像的特征和标签。总共，5047 张图片被赋予了 487 个不同的标签。</p><p id="3c2c" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">被称为<strong class="ls iu">特征提取</strong>和<strong class="ls iu">反向图像搜索</strong>的机器学习技术然后使用<a class="ae mo" href="http://ml4a.github.io/ml4a/" rel="noopener ugc nofollow" target="_blank">基因科岗的代码</a>来基于视觉相似性找到图像。首先，使用预训练的卷积神经网络来提取每幅图像的“特征”，然后，计算这些特征的<a class="ae mo" href="https://en.wikipedia.org/wiki/Cosine_similarity" rel="noopener ugc nofollow" target="_blank">余弦相似度</a>，以“搜索”少量与查询图像相似的图像。</p><p id="6bf6" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">特征在计算机视觉中的主要作用是“<a class="ae mo" href="https://medium.com/machine-learning-world/feature-extraction-and-similar-image-search-with-opencv-for-newbies-3c59796bf774" rel="noopener">将视觉信息转换到向量空间</a>”。相似的图像应该产生相似的特征，我们可以利用这些特征进行信息检索。基于这些特征，我们还可以通过使用<a class="ae mo" href="https://medium.com/@luckylwk/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b" rel="noopener">一种叫做 t-SNE </a>的方法来对图像进行相似性聚类。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/62de025b2c41e9ad6404a53b2d6892a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*Ke5AqPKg360ePYyh61I4-Q.jpeg"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">An image of Lumiere London 2018. Source: Flickr</figcaption></figure><h2 id="7da5" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">图像分析</h2><p id="756c" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">在这一节中，我将展示我的计算机视觉分析的结果。下面，我报告以下三个指标:</p><ol class=""><li id="8a5e" class="mx my it ls b lt mj lw mk ld mz lh na ll nb mi nc nd ne nf bi translated">图像的标签检测；</li><li id="41aa" class="mx my it ls b lt ng lw nh ld ni lh nj ll nk mi nc nd ne nf bi translated">基于视觉相似性的图像搜索:</li><li id="78eb" class="mx my it ls b lt ng lw nh ld ni lh nj ll nk mi nc nd ne nf bi translated">基于视觉相似性的图像聚类。</li></ol><h2 id="9970" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated"><strong class="ak">标签检测</strong></h2><p id="190e" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">每张照片的标签都是使用<a class="ae mo" href="https://cloud.google.com/vision/" rel="noopener ugc nofollow" target="_blank">谷歌云视觉 API </a>生成的。这背后的想法是将图片分类，这样我就可以识别相似的图片。下面的条形图显示了 5，000 幅图像的前 10 个标签。</p><p id="6618" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">我们看到“夜”和“光”出现的次数最多。这些标签很有意义，因为这是一个灯光装置的夜晚节日！然而，它们没有明确描述艺术品本身，这突出了一些标签检测技术的缺点。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">Figure 1: label count of 5,000 images of Lumiere London 2018. Source: Flickr</figcaption></figure><p id="3a42" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">为图像生成标签在各种其他应用程序中非常有用，例如训练机器学习模型或构建推荐系统，但对于这篇文章来说，它们没有那么有用。</p><p id="fa30" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">不可否认，我没有最大限度地使用 vision API 这篇由 Sara Robinson 撰写的文章突出了 API 的许多伟大特性——这可能是因为调用 API 是有成本的！</p><h2 id="1d1d" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated"><strong class="ak">图像搜索—视觉相似度</strong></h2><p id="437d" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">我们可以通过编程让计算机学习图像之间的视觉相似性，而不是使用标签来理解图像。一种叫做<strong class="ls iu">特征提取</strong>和<strong class="ls iu">反向图像搜索</strong>的技术就是这样做的。</p><p id="7d53" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">使用在<a class="ae mo" href="https://www.tensorflow.org/guide/keras" rel="noopener ugc nofollow" target="_blank"> TensorFlow 后端</a>上运行的<a class="ae mo" href="https://keras.io/applications/#vgg16" rel="noopener ugc nofollow" target="_blank"> Keras VGG16 </a>神经网络模型，我首先为数据集中的每张图像提取了一个特征。一个特征是每个图像的 4096 元素的数字数组。我们的期望是“该特征形成图像的非常好的表示，使得相似的图像将具有相似的特征”(<a class="ae mo" href="http://ml4a.github.io/ml4a/convnets/" rel="noopener ugc nofollow" target="_blank">吉恩·科岗，2018 </a>)。</p><p id="0136" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">然后使用主成分分析(PCA)降低特征的维度，以创建一个<a class="ae mo" href="https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture" rel="noopener ugc nofollow" target="_blank">嵌入</a>，然后计算一个图像的 PCA 嵌入到另一个图像的距离<a class="ae mo" href="https://en.wikipedia.org/wiki/Cosine_similarity" rel="noopener ugc nofollow" target="_blank">余弦距离</a>。我终于能够向计算机发送随机查询图像，它选择并返回数据集中具有相似特征向量的五个其他图像。</p><p id="8576" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">下面是三个例子:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/ea6c6dea8148f7c3b444099321a565dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YvxxUUDxRoZkFlaz4Z4q6g@2x.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">A reverse image search for Reflecktor by Studio Roso at Lumiere London 2018</figcaption></figure><div class="kj kk kl km gt ab cb"><figure class="no kn np nq nr ns nt paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/fd65a255c6c3daccfaf6197c42dceb16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*-A7DcttwBgRjpezyFrgV_A@2x.png"/></div></figure><figure class="no kn np nq nr ns nt paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/d61e3e88cde2b39ec270856cad8e369e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*dEDrQ06KQsd5W5OkCBXJbA@2x.png"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk nu di nv nw">A reverse image search for Illumaphanium by Michael David and Cosmoscope by Simeon Nelson at Lumiere London 2018</figcaption></figure></div><p id="e1ea" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">当试图从一个有一百万张图片的相册中找到相似的图片时，这种技术非常有用！</p><h2 id="73b8" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">图像聚类—相似性</h2><p id="3c91" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">既然我们在向量空间中嵌入了每个图像，我们可以使用一种流行的叫做 t-SNE 的机器学习可视化算法来聚类，然后在二维空间中可视化向量空间。</p><blockquote class="nx"><p id="9de2" class="ny nz it bd oa ob oc od oe of og mi dk translated">“tSNE 的目标是聚集相似数据点的小“邻域”,同时减少数据的整体维度，以便更容易可视化”(谷歌人工智能博客，2018 年)</p></blockquote><p id="9785" class="pw-post-body-paragraph lq lr it ls b lt oh ju lv lw oi jx ly ld oj ma mb lh ok md me ll ol mg mh mi im bi translated">下面我们看到基于视觉相似性的聚类形成。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/32b96e862c2403d6f06d7ad084dbbceb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*upjXPCfUEuX9hVyYVCmMkw@2x.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">The clustering of images of Lumiere London 2018. Source: Flickr</figcaption></figure><p id="dd50" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">在下图中，我重点展示了三件艺术品——圣詹姆斯教堂的克里斯·普兰特的<em class="on"> Harmonic Portal，粮仓广场的金奎大·鲁斯加德</em>的<em class="on"> Waterlicht，威斯敏斯特教堂的帕特里斯·沃伦纳</em>的<em class="on">The Light of The Spirit</em>——以及它们的集群剖面。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/c0341d3c654dd0a67ba99a9f1df7f7da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*85RosOwiwV7lVMXuf0uQfw@2x.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">The clustering of images of three art installations at Lumiere London 2018. Source: Flickr</figcaption></figure><h2 id="3c0e" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">结论</h2><p id="5f16" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">所以你有它！我只是刚刚涉足计算机视觉的奇妙世界。还有很多东西需要我去学习，但这对我来说是很好的第一步。</p><p id="f4f3" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">我的发现表明，使用机器学习和计算机视觉技术来理解和联系琉米爱尔伦敦 2018 灯光节的图像是可能的。</p><p id="c72c" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">对我来说，下一步显然是计算在数据集中出现了多少艺术装置，以衡量“受欢迎程度”。我将继续研究这个数据集。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/5fb66830682071a52224a67efc2e4310.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*TM3Din5G4R2uMoN1ooj05A.jpeg"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">An image of Lumiere London 2018. Source: Flickr</figcaption></figure><h2 id="7928" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">结束了！</h2><p id="b791" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">这是我关于琉米爱尔伦敦 2018 系列博客的结尾！这个系列是我正在进行的关于使用数据科学来理解和衡量城市文化影响的长期讨论的一部分。</p><p id="43c2" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">明年，我将开始新的项目，在那里我将主要使用 JavaScript。敬请期待！</p><p id="a77e" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">感谢阅读！</p><p id="17b6" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated">Vishal</p><p id="5ecd" class="pw-post-body-paragraph lq lr it ls b lt mj ju lv lw mk jx ly ld ml ma mb lh mm md me ll mn mg mh mi im bi translated"><a class="ae mo" href="https://vishalkumar.london/" rel="noopener ugc nofollow" target="_blank"> <em class="on"> Vishal </em> </a> <em class="on">是伦敦 UCL</em><a class="ae mo" href="https://www.ucl.ac.uk/bartlett/" rel="noopener ugc nofollow" target="_blank"><em class="on">The Bartlett</em></a><em class="on">的文化数据科学家和研究生。他对城市文化的经济和社会影响感兴趣。</em></p></div></div>    
</body>
</html>