<html>
<head>
<title>Automatic feature engineering using deep learning and Bayesian inference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习和贝叶斯推理的自动特征工程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automatic-feature-engineering-using-deep-learning-and-bayesian-inference-application-to-computer-7b2bb8dc7351?source=collection_archive---------4-----------------------#2018-02-09">https://towardsdatascience.com/automatic-feature-engineering-using-deep-learning-and-bayesian-inference-application-to-computer-7b2bb8dc7351?source=collection_archive---------4-----------------------#2018-02-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5b10" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">计算机视觉和综合金融交易数据的应用</h2></div><p id="eaf8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将探索深度学习和贝叶斯推理在自动特征工程中的应用，特别是自动编码器。这个想法是从潜在的有噪声的原始数据中自动学习一组特征，这些数据在监督学习任务中是有用的，例如在计算机视觉和保险中。以这种方式，我们通过自动学习一组特征，即表示学习，避免了手工制作的特征工程的手动过程，这可以帮助解决某些任务，例如图像识别和保险损失风险预测。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/80422ed0b4872bb8fada8557b8ce2e62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ezaQYecN8-N3ID7369U17w@2x.jpeg"/></div></div></figure><h1 id="162a" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">计算机视觉</h1><p id="ebd5" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">为此，我们将使用MNIST数据集，其中原始数据是每个图像的像素强度的二维张量。图像是我们的分析单位:我们将预测每个图像的每个类别的概率。这是一个多类分类任务，我们将使用准确度分数来评估模型在测试折叠中的性能。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mk"><img src="../Images/9be87d246e4736d8703970413246c7df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p0gc8rqYFWyWqog-vxqYLw@2x.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">2 dimensional tensor of pixel intensities per image.</figcaption></figure><p id="6c1e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">计算机视觉任务的手工特征工程的一些例子可能使用Gabor滤波器。</p><h1 id="1380" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">保险</h1><p id="2976" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">我们将使用合成数据集，其中原始数据是每个保单期组合的历史保单级别信息的二维张量:每个单位将是一个4x 3维张量，即4个历史时间段和3种交易类型。保单-期间组合是我们的分析单位:我们将预测未来期间5的损失概率—将此视为保单的潜在续保，我们需要预测它是否会为我们带来损失，从而影响我们是否决定续保和/或调整续保保费以考虑额外风险。这是一个二元类分类任务，我们将使用AUROC分数来评估模型性能。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi mp"><img src="../Images/98d0ce870ce04c222b11b29b168f29b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nEM9tvC7AHx_9kT_HakWMQ@2x.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">2 dimensional tensor of transaction values per policy-period combination.</figcaption></figure><p id="4202" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">保险任务的手工特征工程的一些例子可能使用列或行平均值。</p><p id="81fa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">合成保险金融交易数据集是用r编写的，其余的工作都是用Python完成的。</p><p id="f802" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意计算机视觉任务的原始数据和保险任务的原始数据之间的相似之处。我们在这里的主要目标是通过深度学习和贝叶斯推理，使用自动特征工程来学习这种原始数据的良好表示。</p><h1 id="8815" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">Scikit-learn、Keras和TensorFlow</h1><p id="48f0" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">我们将使用Python机器学习库scikit-learn进行数据转换和分类任务。请注意，我们将自动编码器编码为scikit-learn转换器，以便scikit-learn管道可以随时使用它们。深度学习者将使用Keras和TensorFlow后端进行编码。我们还在MacBook Pro上使用了外部GPU，即GTX 1070。</p><h1 id="d0e3" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">MNIST:没有自动编码器</h1><p id="e1be" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">我们在不使用自动编码器的情况下运行MNIST数据集。MNIST图像的每个图像的像素强度的2维张量是28乘28的维度。我们将它们重塑为每个图像784维的1维张量。因此，对于每幅图像的监督学习任务，我们有784个特征。</p><h1 id="9f6c" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="9bc6" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">没有自动编码器的MNIST分类任务的准确度分数:<strong class="kh ir"> 92.000000% </strong>。</p></blockquote><h1 id="240b" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">MNIST:认证机构</h1><p id="6491" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">我们使用主成分分析过滤器，挑选出能够解释99%变异的成分数量。</p><h1 id="f1e4" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="cbaf" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">使用主成分分析的MNIST分类任务的正确率得分:<strong class="kh ir"> 91.430000% </strong>。</p></blockquote><h1 id="e1c1" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">MNIST:普通自动编码器</h1><p id="d0f0" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">自动编码器是一种无监督学习技术，其目标是学习一组可用于重构输入数据的特征。</p><p id="669c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的输入数据是<em class="mt"> X </em>。编码器功能<em class="mt"> E </em>将其映射到一组<em class="mt"> K </em>特征。解码器功能<em class="mt"> D </em>使用一组<em class="mt"> K </em>特征来重构输入数据。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/22f4d7152029869f579b0d7cfbea91cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*5KwZxLGNqJ5hB1zk2L0qRw@2x.png"/></div></figure><p id="d61a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们将重建的数据表示如下。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi my"><img src="../Images/c085828c6a7877df4e8972faeed575f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*dBO2KoxP6JLX_uKHBXU2_w@2x.png"/></div></figure><p id="f6c5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">目标是学习编码和解码功能，使输入数据和重构数据之间的差异最小化。这个任务的目标函数的一个例子可以是均方误差(MSE)。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/72be6143bc08d24a1be7289a7660099d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*rm9-rZVdfkAQXNXn_FzHnQ@2x.png"/></div></figure><p id="2216" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们通过使用定义编码和解码函数的参数最小化MSE来学习编码和解码函数:使用链式法则(即反向传播)来计算MSE相对于参数的梯度，并将其用于通过诸如随机梯度下降(SGD)的优化算法来更新参数。</p><p id="b61f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设我们有一个单层自动编码器，它使用指数线性单元(ELU)激活函数、批量归一化、丢失和自适应矩(Adam)优化算法。<em class="mt"> B </em>是批量，<em class="mt"> K </em>是特性数。</p><ul class=""><li id="04f9" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated"><strong class="kh ir">指数线性单元:</strong>激活函数处处平滑，避免了输入为负时输出呈现负值的消失梯度问题。</li></ul><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nj"><img src="../Images/a11f67f288f918a3634bcf6fe1d24e32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RakZxhD-Pg7T0r-x9TYJZA@2x.png"/></div></div></figure><ul class=""><li id="1514" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated"><strong class="kh ir">批量标准化:</strong>这个想法是把输入转换成一个隐藏层的激活函数。我们首先在每个特征的基础上使用均值和方差参数进行标准化或规范化，然后在转换数据的每个特征的基础上学习一组缩放和移动参数。下面的等式简洁地描述了这一层。</li></ul><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nk"><img src="../Images/0028cd70f0d08a2b014274d85069ddb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E0gaxhU-_G4rLEq6TwMpOw@2x.png"/></div></div></figure><ul class=""><li id="1e8c" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated"><strong class="kh ir">丢弃:</strong>这种正则化技术简单地以一定的概率(比如50%)丢弃来自输入和隐藏单元的输出。</li><li id="2dab" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la nf ng nh ni bi translated"><strong class="kh ir"> Adam优化算法:</strong>这种自适应算法结合了Momentum和RMSProp优化算法的思想。目标是对过去的梯度有一些记忆，这可以指导将来的参数更新。下面的算法方程简明地描述了这种方法。</li></ul><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nq"><img src="../Images/c49b46fef4b54b88c945177cfcd7036c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3p9uIpNHtzl0U6L6RR6E9A@2x.png"/></div></div></figure><h1 id="2494" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="aac0" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">使用自动编码器的MNIST分类任务的准确度分数:<strong class="kh ir"> 96.940000% </strong>。</p></blockquote><h1 id="692c" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">MNIST:去噪自动编码器</h1><p id="010a" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">这里的想法是向数据添加一些噪声，并尝试学习一组稳健的特征，这些特征可以从有噪声的数据中重建无噪声的数据。MSE目标函数如下。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nr"><img src="../Images/77476ee3938f9b0af965eb4107154476.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZGx9BOHGKQl4IQbkOIJ0Gw@2x.png"/></div></div></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/22f4d7152029869f579b0d7cfbea91cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*5KwZxLGNqJ5hB1zk2L0qRw@2x.png"/></div></figure><h1 id="e869" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="2811" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">使用去噪自动编码器的MNIST分类任务的准确度分数:<strong class="kh ir"> 96.930000% </strong>。</p></blockquote><h1 id="23d1" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">MNIST:一维卷积自动编码器</h1><p id="6ad7" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">到目前为止，我们使用的是扁平化或整形的原始数据。每个图像的像素强度的这种1维张量可能没有考虑2维张量可能包含的有用的空间特征。为了克服这个问题，我们引入卷积滤波器的概念，首先考虑它们的一维版本，然后考虑它们的二维版本。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ns"><img src="../Images/6cbde731acdfddd3dbe4e5a73c1ef07b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0pClYLst9yaFM2JvDepF7Q@2x.png"/></div></div></figure><p id="ca37" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">卷积滤波器背后的思想与手工特征工程密切相关:人们可以将手工特征简单地视为预定义卷积滤波器的结果，即没有基于手边的原始数据学习的卷积滤波器。</p><p id="d704" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设我们有每个分析单位的原始交易数据，即抵押贷款，这可能有助于我们将一个单位分类为违约或未违约。我们将保持这个例子简单，只允许交易值为$100或$0。每单位的原始数据跨越5个时间段，而默认标签用于下一个时间段，即时间段6。以下是一个特定单位的原始数据示例:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nt"><img src="../Images/4824451bc9ded7d7d882af10b97307f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mUiwBODeFa0n3_vBI0x39g@2x.png"/></div></div></figure><p id="f144" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">进一步假设，如果平均交易价值为20美元，那么我们将在第6期看到该特定抵押贷款单位的违约。除此之外，我们不会看到第6期出现违约。平均交易价值是手工制作的特征的一个例子:预先定义的手工制作的特征，没有以任何方式学习。它是通过信贷风险领域的知识得出的。将其表示为<em class="mt"> H(x) </em>。</p><p id="0328" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">学习这种特征的想法是一维卷积滤波器的一个例子。如下所示:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nu"><img src="../Images/6ddd772b9168922029dc406aa158f34e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IkucXM8hgryQTJbWgNo5LQ@2x.png"/></div></div></figure><p id="982b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设<em class="mt"> H(x) </em>是该监督学习任务的原始数据的正确表示，则通过用于上述定义的卷积滤波器的监督学习，或者可能是无监督学习，然后被转移到监督学习任务，即转移学习，学习的最佳参数集是[0.2，0.2，0.2，0.2，0.2]:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nv"><img src="../Images/4f752d8ddf087dd70b1ac2eeb5846a5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OYrY7Ov2C0YoKp662n5jWg@2x.png"/></div></div></figure><p id="57a3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是一个简单的例子，但是这清楚地说明了使用深度学习进行自动特征工程或表示学习背后的原理。以无监督的方式学习这种表示的主要好处之一是，相同的表示可以用于多个监督学习任务:迁移学习。这是从原始数据中学习表示的一种原则性方式。</p><p id="e2a1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">总结一下，对于我们的简单示例，一维卷积滤波器定义为:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/0942f61a1925bf55bbb601dbd69f0218.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*CrIit2ai0g9hwZyYYQGhbQ@2x.png"/></div></figure><ul class=""><li id="fd94" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated"><em class="mt"> x </em>为输入。</li><li id="b8cd" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la nf ng nh ni bi translated">𝛼是内核。</li><li id="89d2" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la nf ng nh ni bi translated">输出<em class="mt"> x </em> * 𝛼被称为特征图，而*是卷积算子或滤波器。这是普通神经网络和卷积神经网络之间的主要区别:我们用卷积算子代替矩阵乘法算子。</li><li id="61b1" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la nf ng nh ni bi translated">根据手头的任务，我们可以有不同类型的卷积滤波器。</li><li id="9177" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la nf ng nh ni bi translated">内核大小可以改变。在我们的例子中，内核大小是5。</li><li id="ecfb" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la nf ng nh ni bi translated">步幅大小可以改变。在我们的示例中，我们没有步长大小，但是假设步长大小为1，内核大小为2，即𝛼 = [𝛼 <em class="mt"> </em>，𝛼 <em class="mt"> </em> ]，那么我们将在输入开始时应用内核𝛼，即[ <em class="mt"> x </em>，<em class="mt"> x </em> ] * [𝛼 <em class="mt"> </em>，𝛼 <em class="mt"> </em> ]，并将内核移动到输入的下一个区域，即[ <em class="mt"> <em class="mt">x</em>]*【𝛼<em class="mt"/>、𝛼 <em class="mt"> </em> ]等等，直到我们得到由4个实数值组成的特征图。 这被称为有效卷积，而填充卷积，也就是说用零值填充卷积，将给出与输入大小相同的特征映射，即，在我们的例子中是5个实值。</em></li><li id="5d4f" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la nf ng nh ni bi translated">我们可以将激活函数应用于特征地图，例如前面提到的ELU。</li><li id="8436" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la nf ng nh ni bi translated">最后，我们可以通过在特征图的定义部分取最大值或平均值来总结特征图中包含的信息。例如，如果在使用有效卷积后，我们得到大小为4的特征图，然后应用大小为4的最大汇集操作，那么我们将取该特征图的最大值。结果是另一个特征图。</li></ul><p id="150d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这自动化了特征工程，但是引入了架构工程，其中由各种卷积滤波器、激活函数、批量标准化层、丢弃层和汇集操作符组成的不同架构可以在流水线中堆叠在一起，以便学习原始数据的良好表示。人们通常创建这样的体系结构的集合。</p><p id="e2c4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">卷积自动编码器的目标是使用卷积滤波器、激活函数、批量标准化层、丢弃层和汇集运算符来创建一个编码器函数，它将学习我们原始数据的良好表示。解码器还将使用与编码器类似的一组层来重建原始数据，但有一个例外:它将使用上采样运算符，而不是使用池运算符。上采样操作符背后的基本思想是将一个元素重复一定的次数，比如大小为4:可以将其视为池操作符的逆操作符。池操作符本质上是一个下采样操作符，而上采样操作符在某种意义上只是它的逆操作。</p><h1 id="6613" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="3c16" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">使用一维卷积自动编码器的MNIST分类任务的准确度分数:<strong class="kh ir"> 97.570000% </strong>。</p></blockquote><h1 id="bfc9" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">MNIST:序列到序列自动编码器</h1><p id="f40e" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">鉴于我们的抵押贷款违约例子，一个潜在的更有用的深度学习架构可能是递归神经网络(RNN)，特别是他们的最先进的变体长期短期记忆(LSTM)网络。目标是明确考虑原始数据的顺序性质。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ns"><img src="../Images/6cbde731acdfddd3dbe4e5a73c1ef07b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0pClYLst9yaFM2JvDepF7Q@2x.png"/></div></div></figure><p id="b188" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">RNN中的梯度取决于为模型定义的参数矩阵。简单地说，这些参数矩阵可能会被多次相乘，从而导致学习的两个主要问题:爆炸和消失梯度。如果参数矩阵的谱半径，即矩阵特征值的最大绝对值，大于1，那么梯度可能变得足够大，即值爆炸，使得学习发散，并且类似地，如果谱半径小于1，那么梯度可能变小，即值消失，使得参数的下一个最佳转变不能被可靠地计算。梯度的适当计算对于估计定义机器学习方法的最佳参数集是重要的，并且LSTM网络在普通RNN中克服了这些问题。我们现在将LSTM网络定义为1个时间步长，即1个存储单元。</p><p id="cf92" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们计算输入门的值，在时间段<em class="mt"> t </em>的存储单元状态的值，其中<em class="mt"> f(x) </em>是某个激活函数，以及遗忘门的值:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nx"><img src="../Images/9f8be355774fcad5ad531d4150cd78b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PTfZLlN1jdp5EvcjaLlk2g@2x.png"/></div></div></figure><p id="e92b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">遗忘门控制LSTM记忆的量，即在时间段<em class="mt"> t-1 </em>的存储单元状态的值，其中⨂是哈达玛乘积:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ny"><img src="../Images/a8e4fc8a1e9f1f959d589b3b2e5739a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pUbYgBrxFl-AuHQAbIGLjA@2x.png"/></div></div></figure><p id="23d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">利用存储单元的更新状态，我们计算输出门的值，并最终计算输出值本身:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nz"><img src="../Images/e00b411ea9b4e02a259d1dd4e320f7b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cmL40YKFOxX1BqGKI8th1w@2x.png"/></div></div></figure><p id="ac97" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以有各种各样的LSTM架构，例如卷积LSTM，注意，我们用卷积运算符*替换输入门、存储单元状态的初始估计、遗忘门和输出门中的矩阵乘法运算符:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi oa"><img src="../Images/39f40dcb1ba8cf035715c54b6df5f8cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f-UkL95_KSALyeX7l5joog@2x.png"/></div></div></figure><p id="7068" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一个流行的变体是窥视孔LSTM，其中允许门窥视存储单元的状态:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ob"><img src="../Images/1c183308d54ae030215cc83456a5fb02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9kN1wiDsQvNdG6mJNSuCGg@2x.png"/></div></div></figure><p id="82ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">序列到序列自动编码器的目标是使用LSTM作为编码器来创建原始数据的表示。这种表示将是从原始数据向量序列中学习的向量序列。表示的最后一个向量是我们的编码表示，也称为上下文向量。该上下文向量被重复与序列长度一样多的次数，使得它可以被用作解码器的输入，该解码器又是另一个LSTM。解码器LSTM将使用该上下文向量来重建原始数据向量序列。如果上下文向量在重建任务中有用，那么它可以进一步用于其他任务，如预测违约风险，如我们的示例中所给出的。</p><h1 id="c25d" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="4a8e" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">使用序列对序列自动编码器的MNIST分类任务的准确度分数:<strong class="kh ir"> 97.600000% </strong>。</p></blockquote><h1 id="ae34" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">MNIST:可变自动编码器</h1><p id="4b3b" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">我们现在通过使用变分推理来训练自动编码器，从而将贝叶斯推理与深度学习相结合。这使我们转向了生成模型，它可以在半监督学习中有进一步的用例。使用贝叶斯推理进行训练的另一个好处是，我们可以对更高能力的深度学习者更加鲁棒。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/22f4d7152029869f579b0d7cfbea91cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*5KwZxLGNqJ5hB1zk2L0qRw@2x.png"/></div></figure><ul class=""><li id="9830" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated">假设<em class="mt"> X </em>是我们的原始数据，而<em class="mt"> Z </em>是我们学习过的表示。</li><li id="9735" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la nf ng nh ni bi translated">我们对学习到的表征有一个先验的信念:</li></ul><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/f7827e80f617d1d98a103dc156bbc67a.png" data-original-src="https://miro.medium.com/v2/resize:fit:288/format:webp/1*XcLZ4i59fXI1WqGe9qoRZw@2x.png"/></div></figure><ul class=""><li id="d8fb" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated">我们学习到的表征的后验分布是:</li></ul><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi od"><img src="../Images/87270f3cb2b84036ccc1837bf96ff303.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RmCchzcBIPmHGzcdyiCWuA@2x.png"/></div></div></figure><ul class=""><li id="a135" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated">边际可能性<em class="mt"> p(X) </em>通常是难以处理的，导致后验分布<em class="mt"> p(Z|X) </em>难以处理:</li></ul><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi oe"><img src="../Images/3a6dd0799b692f4f6310eb38d451b210.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gSCmlUWnbe77Y1NwW6oCPg@2x.png"/></div></div></figure><ul class=""><li id="0429" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated">因此，我们需要一个近似的后验分布，通过变分推理，可以处理棘手的问题。这另外还提供了处理大规模数据集的好处，因为通常马尔可夫链蒙特卡罗(MCMC)方法不太适合大规模数据集。人们也可以考虑拉普拉斯近似来近似后验分布，但是我们将坚持变分推理，因为与拉普拉斯近似相比，它允许更丰富的近似集。拉普拉斯近似简单地等同于找到增强似然优化的最大后验(MAP)估计，在MAP估计处取Hessian逆的负值以估计方差-协方差矩阵，并且最后使用具有多变量高斯分布或一些其他适当的多变量分布的方差-协方差矩阵。</li><li id="35d0" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la nf ng nh ni bi translated">假设我们的近似后验分布，也是我们的概率编码器，给出如下:</li></ul><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi of"><img src="../Images/2ed0f7b3228f04a214ed42f6915308e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/1*tCbqzFX7v3cwsJWOoTzubQ@2x.png"/></div></figure><ul class=""><li id="218b" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated">我们的概率解码器由下式给出:</li></ul><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi og"><img src="../Images/8e38c445d1173a6c9c7dd72def36f715.png" data-original-src="https://miro.medium.com/v2/resize:fit:456/format:webp/1*Az7sH8vEHgf2XYw6hG9JeA@2x.png"/></div></figure><ul class=""><li id="14fb" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated">给定以上关于编码器和解码器的设置，现在让我们写下优化问题:</li></ul><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi oh"><img src="../Images/a843d6f13ae25f4316f874146274fc40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H8pEIsc6-0AjcCI6LDPiWA@2x.png"/></div></div></figure><ul class=""><li id="3073" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated">请注意，KL背离是非负的，因此这使得ELBO成为边际可能性的下限:</li></ul><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi oi"><img src="../Images/8db36a8c8eecc07ecfd8a4cb1f98e3c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t62vnuHRUS3NCyk9LG3KmQ@2x.png"/></div></div></figure><ul class=""><li id="48e9" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated">因此，我们可以改变优化问题，只关注ELBO:</li></ul><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi oj"><img src="../Images/14e5cae22f0155ca7104100f1cdb8a03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JyBSGlem8Sgz15-Mp4XiZw@2x.png"/></div></div></figure><ul class=""><li id="27f9" class="na nb iq kh b ki kj kl km ko nc ks nd kw ne la nf ng nh ni bi translated">上述积分问题可以通过蒙特卡罗积分来解决，因为正则化项不是难以处理的。假设概率编码器是具有对角方差-协方差矩阵的多元高斯，我们使用重新参数化技巧从该分布中采样，比如说<em class="mt"> M </em>次，以便计算ELBO优化问题中的期望项。这种特殊情况下的重新参数化技巧相当于从标准高斯分布中采样<em class="mt"> M </em>次，将样本乘以𝞼并将<strong class="kh ir"> μ </strong>加到样本上。</li><li id="b057" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la nf ng nh ni bi translated"><strong class="kh ir"> μ </strong>是我们用于原始数据重建的学习表示。如果学习到的表征是有用的，那么它也可以用于其他任务。</li><li id="5c44" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la nf ng nh ni bi translated">这是一种将贝叶斯推理与深度学习相结合的强大方式。以这种方式使用的变分推理可以应用于各种深度学习架构，并且与生成对抗网络(GAN)有进一步的联系。我们在另一篇论文中探讨了对抗性学习在表征学习中的应用。</li></ul><h1 id="d94a" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="8ec4" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">使用可变自动编码器的MNIST分类任务的准确度分数:<strong class="kh ir"> 96.520000% </strong>。</p></blockquote><h1 id="01cc" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">MNIST:二维卷积自动编码器</h1><p id="40de" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">对于2维卷积滤波器，其思想与1维卷积滤波器相似。我们将坚持我们前面提到的银行例子来说明这一点。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ok"><img src="../Images/da3e65c99f1d7afae59f9d7e6533b196.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MDsvqmRo70yC05ChP4XTRg@2x.png"/></div></div></figure><p id="dbd2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在原始交易数据的二维张量中，现在我们有5个历史时间段，即行，和3个不同的交易类型，即列。我们将使用大小为2乘3的核从原始数据中提取有用的特征。选择这样一个内核意味着我们有兴趣找到一个跨越所有3种事务类型和2个历史时间段的特性图。我们将使用步长1和有效的卷积来提取原始数据的不同片上的特征。下面将说明这一点。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ol"><img src="../Images/ce36ceca14d5ad13d68ce0b29ac719b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DR8BTtvcF6K9n7tv9vhXcA@2x.png"/></div></div></figure><p id="cf38" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些原理和思想适用于2维卷积滤波器，因为它们适用于1维卷积滤波器，这里我们不再重复。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ns"><img src="../Images/6cbde731acdfddd3dbe4e5a73c1ef07b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0pClYLst9yaFM2JvDepF7Q@2x.png"/></div></div></figure><h1 id="dbdd" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="9a7b" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">使用二维卷积自动编码器的MNIST分类任务的准确度分数:<strong class="kh ir"> 98.860000% </strong>。</p></blockquote><h1 id="3092" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">保险:没有自动编码器</h1><p id="0ceb" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">我们现在开始运行保险模型，没有任何手工制作或基于深度学习的特征工程:只有原始数据。</p><h1 id="998a" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="f6f0" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">没有自动编码器的保险分类任务的AUROC分数:<strong class="kh ir"> 92.206261% </strong>。</p></blockquote><h1 id="d0cb" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">保险:PCA</h1><p id="4bef" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">我们现在继续运行保险模型，没有任何手工或基于深度学习的特征工程，但是使用PCA过滤器来挑选解释99%变化的组件数量。</p><h1 id="4648" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="3d0f" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">使用PCA的保险分类任务的AUROC分数:<strong class="kh ir"> 91.128859% </strong>。</p></blockquote><h1 id="4689" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">保险:手工制作的功能</h1><p id="70f7" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">在这种情况下，我们创建了一些手工制作的特征，我们认为这些特征为保险模型的原始数据提供了有用的表示。</p><h1 id="70b7" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="e404" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">具有手工特征的保险分类任务的AUROC分数:<strong class="kh ir"> 93.610635% </strong>。</p></blockquote><h1 id="5b45" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">保险:手工制作的功能和PCA</h1><p id="164f" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">我们使用前面提到的手工制作的特征和PCA过滤器，该过滤器挑选解释99%的变化的组件的数量。</p><h1 id="93c5" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="d0bd" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">具有手工特征和PCA的保险分类任务的AUROC分数:<strong class="kh ir"> 93.160377% </strong>。</p></blockquote><h1 id="4dbf" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">保险:普通自动编码器</h1><p id="cdc5" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">在这种情况下，我们使用普通的自动编码器来学习原始数据的良好表示，以便我们可以根据AUROC获得监督学习任务的提升。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi om"><img src="../Images/40b05cfbdd785e7139868c976dfbc75c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*j6gHvSfrmiP6yXZuYO6kfQ@2x.png"/></div></figure><h1 id="b9f4" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="5854" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">使用自动编码器的保险分类任务的AUROC分数:<strong class="kh ir"> 93.932247% </strong>。</p></blockquote><h1 id="0723" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">保险:去噪自动编码器</h1><p id="3565" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">在这种情况下，我们使用去噪自动编码器来学习原始数据的良好表示，从而我们可以根据AUROC获得监督学习任务的提升。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi om"><img src="../Images/40b05cfbdd785e7139868c976dfbc75c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*j6gHvSfrmiP6yXZuYO6kfQ@2x.png"/></div></figure><h1 id="fe79" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="b662" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">使用去噪自动编码器的保险分类任务的AUROC分数:<strong class="kh ir"> 93.712479% </strong>。</p></blockquote><h1 id="f698" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">保险:序列到序列自动编码器</h1><p id="a17d" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">在这种情况下，我们使用序列对自动编码器进行排序，考虑原始交易数据的时间序列性质，即序列性质，以学习原始数据的良好表示，从而我们可以获得监督学习任务在AUROC方面的提升。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi on"><img src="../Images/7db2765968c4555a300a8b95c54b98be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*pQ7Y6EAtmJW7rOK_dlsVHA@2x.png"/></div></figure><h1 id="68a3" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="b4e1" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">使用序列对序列自动编码器的保险分类任务的AUROC分数:<strong class="kh ir"> 91.418310% </strong>。</p></blockquote><h1 id="574d" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">保险:一维卷积自动编码器</h1><p id="1974" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">在这种情况下，我们使用1维卷积自动编码器来学习原始数据的良好表示，以便我们可以获得AUROC方面的提升，用于监督学习任务。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi on"><img src="../Images/7db2765968c4555a300a8b95c54b98be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*pQ7Y6EAtmJW7rOK_dlsVHA@2x.png"/></div></figure><h1 id="1af2" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="ef12" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">使用一维卷积自动编码器的保险分类任务的AUROC分数:<strong class="kh ir"> 91.509434% </strong>。</p></blockquote><h1 id="7d73" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">保险:二维卷积自动编码器</h1><p id="391e" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">在这种情况下，我们使用二维卷积自动编码器来学习原始数据的良好表示，以便我们可以获得AUROC方面的提升，用于监督学习任务。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi on"><img src="../Images/7db2765968c4555a300a8b95c54b98be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*pQ7Y6EAtmJW7rOK_dlsVHA@2x.png"/></div></figure><h1 id="fba8" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="593a" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">使用二维卷积自动编码器的保险分类任务的AUROC分数:<strong class="kh ir"> 92.645798% </strong>。</p></blockquote><h1 id="79f8" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">保险:可变自动编码器</h1><p id="f0bb" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">在这种情况下，我们使用变分自动编码器来学习原始数据的良好表示，以便我们可以根据AUROC获得监督学习任务的提升。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi om"><img src="../Images/40b05cfbdd785e7139868c976dfbc75c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*j6gHvSfrmiP6yXZuYO6kfQ@2x.png"/></div></figure><h1 id="cd9d" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><blockquote class="mq mr ms"><p id="c247" class="kf kg mt kh b ki kj jr kk kl km ju kn mu kp kq kr mv kt ku kv mw kx ky kz la ij bi translated">使用可变自动编码器的保险分类任务的AUROC分数:<strong class="kh ir"> 90.871569% </strong>。</p></blockquote><h1 id="773d" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">MNIST结果:准确性得分</h1><p id="71c6" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">正如所料，这里达到的最好成绩是由一个二维卷积自动编码器。</p><p id="8ad9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">没有自动编码器:<strong class="kh ir"> 92.000000% </strong>。</p><p id="58d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">主成分分析:<strong class="kh ir"> 91.430000% </strong>。</p><p id="35f9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">自动编码器:<strong class="kh ir"> 96.940000% </strong>。</p><p id="f320" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">去噪自动编码器:<strong class="kh ir"> 96.930000% </strong>。</p><p id="b4dd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">1维卷积自动编码器:<strong class="kh ir"> 97.570000% </strong>。</p><p id="53c1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">序列间自动编码器:<strong class="kh ir"> 97.600000% </strong>。</p><p id="7564" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">变分自动编码器:<strong class="kh ir"> 96.520000% </strong>。</p><p id="016f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2维卷积自动编码器:<strong class="kh ir"> <em class="mt"> 98.860000% </em> </strong>。</p><h1 id="27d7" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">保险结果:AUROC分数</h1><p id="5b8c" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">在这项任务上取得的最好成绩是由一个普通的自动编码器。这突出了通过深度学习实现特征工程的自动化:我相信伊恩·古德费勒说过，学习的表示比手工制作的表示更好。</p><p id="c6bb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，序列到序列和卷积自动编码器在这项任务中表现不佳，仅仅是因为我生成合成事务数据的方式:如果数据来自更适合序列到序列或卷积自动编码器的过程，这些架构很可能会表现得更好。</p><p id="b54a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不带自动编码器:<strong class="kh ir"> 92.206261% </strong>。</p><p id="36f3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">主成分分析:<strong class="kh ir"> 91.128859% </strong>。</p><p id="836d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">手工特色:<strong class="kh ir"> 93.610635% </strong>。</p><p id="6f80" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">手工特征和主成分分析:<strong class="kh ir"> 93.160377% </strong>。</p><p id="a783" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">自动编码器:<strong class="kh ir"> <em class="mt"> 93.932247% </em> </strong>。</p><p id="8bad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">去噪自动编码器:<strong class="kh ir"> 93.712479% </strong>。</p><p id="408b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">序列到序列自动编码器:<strong class="kh ir"> 91.418310% </strong>。</p><p id="bbd5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">1维卷积自动编码器:<strong class="kh ir"> 91.509434% </strong>。</p><p id="802c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2维卷积自动编码器:<strong class="kh ir"> 92.645798% </strong>。</p><p id="718f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">变分自动编码器:<strong class="kh ir"> 90.871569% </strong>。</p><h1 id="8c03" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">GitHub上的代码</h1><p id="aad2" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">我为本文写的代码可以在我的GitHub上找到:https://github.com/hamaadshah/autoencoders_keras<a class="ae oo" href="https://github.com/hamaadshah/autoencoders_keras" rel="noopener ugc nofollow" target="_blank"/></p><h1 id="aa49" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结论</h1><p id="d2b5" class="pw-post-body-paragraph kf kg iq kh b ki mf jr kk kl mg ju kn ko mh kq kr ks mi ku kv kw mj ky kz la ij bi translated">我们已经展示了如何使用深度学习和贝叶斯推理来学习原始数据的良好表示，即，每个分析单位的1或2维张量，其然后可能被用于计算机视觉和保险领域中的监督学习任务。这使我们从手工制作的特征工程转向自动特征工程，即表示学习。这确实引入了架构工程，然而，也可以通过使用遗传算法或强化学习来实现自动化——这可能是另一篇论文的主题。</p><p id="7026" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我想强调的是，用于解决计算机视觉任务的代码也用于解决保险任务。在这两项任务中，通过深度学习的自动特征工程具有最佳性能，尽管事实上我们并没有明确地寻找艺术架构的最佳状态。这为我们提供了一种端到端自动化机器学习任务的强大方法。</p><h1 id="b033" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">参考</h1><ol class=""><li id="debb" class="na nb iq kh b ki mf kl mg ko op ks oq kw or la os ng nh ni bi translated">古德费勒，我，本吉奥，y和库维尔(2016)。深度学习(麻省理工出版社)。</li><li id="9bb1" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la os ng nh ni bi translated">Geron，A. (2017)。使用Scikit-Learn &amp; tensor flow(O ' Reilly)进行机器学习实践。</li><li id="984f" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la os ng nh ni bi translated">金玛博士和韦林博士(2014年)。自动编码变分贝叶斯(<a class="ae oo" href="https://arxiv.org/abs/1312.6114" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1312.6114</a>)。</li><li id="18e7" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la os ng nh ni bi translated">Hosseini，s .，Lee，S. H .和Cho，N. I. (2018年)。为增强卷积神经网络的性能输入手工制作的特征(【https://arxiv.org/abs/1801.07848】T2)。</li><li id="58b9" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la os ng nh ni bi translated">【http://scikit-learn.org/stable/# T4】</li><li id="f7d0" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la os ng nh ni bi translated"><a class="ae oo" rel="noopener" target="_blank" href="/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1">https://towards data science . com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f 433990 D1</a></li><li id="7731" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la os ng nh ni bi translated"><a class="ae oo" href="https://stackoverflow.com/questions/42177658/how-to-switch-backend-with-keras-from-tensorflow-to-theano" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/42177658/how-to-switch-back end-with-keras-from-tensor flow-to-the ano</a></li><li id="e649" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la os ng nh ni bi translated"><a class="ae oo" href="https://blog.keras.io/building-autoencoders-in-keras.html" rel="noopener ugc nofollow" target="_blank">https://blog.keras.io/building-autoencoders-in-keras.html</a></li><li id="5448" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la os ng nh ni bi translated"><a class="ae oo" href="https://keras.io" rel="noopener ugc nofollow" target="_blank"> https://keras.io </a></li><li id="8f9b" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la os ng nh ni bi translated"><a class="ae oo" href="https://www.cs.cornell.edu/courses/cs1114/2013sp/sections/S06_convolution.pdf" rel="noopener ugc nofollow" target="_blank">https://www . cs . Cornell . edu/courses/cs 1114/2013 sp/sections/S06 _ convolution . pdf</a></li><li id="846a" class="na nb iq kh b ki nl kl nm ko nn ks no kw np la os ng nh ni bi translated"><a class="ae oo" href="http://deeplearning.net/tutorial/lstm.html" rel="noopener ugc nofollow" target="_blank">http://deeplearning.net/tutorial/lstm.html</a></li></ol></div></div>    
</body>
</html>