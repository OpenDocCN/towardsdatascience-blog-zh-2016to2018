<html>
<head>
<title>Analyzing the Lumiere London 2018 light festival (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解析琉米爱尔伦敦 2018 灯光节(下)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/analyzing-the-lumiere-london-2018-light-festival-part-2-98eb3769e267?source=collection_archive---------28-----------------------#2018-11-19">https://towardsdatascience.com/analyzing-the-lumiere-london-2018-light-festival-part-2-98eb3769e267?source=collection_archive---------28-----------------------#2018-11-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="07c5" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">第二部分:11，000 条推文的自然语言处理</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ec6cdd732f2fe09460719b1b1b9e4f72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-TegillXSvx1EE70vlWZWw.png"/></div></div></figure><h2 id="a0c9" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">介绍</h2><p id="6d83" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">在本系列的第 1 部分中，我展示了一份关于琉米爱尔伦敦 2018 的 11，000 条推文的探索性数据分析，这是今年 1 月早些时候在伦敦举行的一个大型灯光节。</p><p id="c4f4" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">从 1 月 18 日(星期四)到 1 月 21 日(星期日)的四天时间里，53 位艺术家的 50 多件公共艺术品在伦敦的六个区展出，超过 100 万人参加了此次艺术节！</p><p id="ac1a" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">本文的目的是展示我的<strong class="ls iu">自然语言处理分析</strong>对这 11，000 条推文的研究结果，以了解人们对 2018 年琉米爱尔伦敦奥运会的看法。</p><p id="acf7" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">请向下滚动，通过交互式数据可视化查看我的分析！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mp"><img src="../Images/a68e90bc7838ca9617c0d46667fcb04d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AlC7bF9q7PWEk5TL60Kn1A@2x.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">Control No Control by Daniel Iregul at Whitfield Gardens in Fitzrovia — my photo</figcaption></figure><h2 id="88a0" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">数据和方法</h2><p id="ead4" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">这一事件的官方标签是#LumiereLDN。在通过 Twitter API 在<a class="ae mj" rel="noopener" target="_blank" href="/access-data-from-twitter-api-using-r-and-or-python-b8ac342d3efe">事件发生时收集了 11000 条包含这个标签的推文之后，我首先在 Python 笔记本中预处理和清理了文本数据。</a></p><p id="536a" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">然后，我使用谷歌的<a class="ae mj" href="https://code.google.com/archive/p/language-detection/" rel="noopener ugc nofollow" target="_blank"> <em class="mu"> langdetect 库</em> </a>过滤掉非英语推文，并从 NLP 分析中删除所有转发，这样就不会出现重复。经过这些步骤，我剩下了 4600 条独特的推文。接下来，我使用<a class="ae mj" href="https://cloud.google.com/natural-language/" rel="noopener ugc nofollow" target="_blank">谷歌云自然语言 API </a>来获取每条推文的情感。</p><p id="0b17" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">最后，我使用<a class="ae mj" href="https://radimrehurek.com/gensim/models/word2vec.html" rel="noopener ugc nofollow" target="_blank"> gensim 库的 Word2Vec 模型</a>来获取整个 tweets 语料库中与单词“LumiereLDN”相关的每个单词的单词嵌入向量。Word2Vec 用于从大型文本语料库中计算单词之间的相似度— <a class="mv mw ep" href="https://medium.com/u/cd869a6dee38?source=post_page-----98eb3769e267--------------------------------" rel="noopener" target="_blank"> Kavita Ganesan </a>的<a class="ae mj" href="https://medium.freecodecamp.org/how-to-get-started-with-word2vec-and-then-how-to-make-it-work-d0a2fca9dad3" rel="noopener ugc nofollow" target="_blank">文章</a>是一个很好的解释。</p><p id="9f4d" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">一旦我有了每个单词的向量，我就使用<a class="ae mj" href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html" rel="noopener ugc nofollow" target="_blank"> scikitlearn 库</a>来执行主成分分析(PCA)以进行降维，并绘制出与“LumiereLDN”最相似的单词(最近邻)。</p><p id="feae" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">你可以在这里查看<a class="ae mj" href="https://www.kaggle.com/vishalkumarlondon/lumiere-london-2018-nlp-analysis?scriptVersionId=7535520" rel="noopener ugc nofollow" target="_blank">我的 Kaggle 内核对这篇文章的所有分析。</a></p><h2 id="6bfb" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">分析</h2><p id="f696" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">在这一节中，我将展示我的自然语言处理(NLP)分析的发现。下面，我报告以下三个指标:</p><ol class=""><li id="3311" class="mx my it ls b lt mk lw ml ld mz lh na ll nb mi nc nd ne nf bi translated">每日推文的情感分析；</li><li id="b037" class="mx my it ls b lt ng lw nh ld ni lh nj ll nk mi nc nd ne nf bi translated">词频和标签频率分析；</li><li id="a616" class="mx my it ls b lt ng lw nh ld ni lh nj ll nk mi nc nd ne nf bi translated">Word2Vec 模型的输出:主成分分析(PCA)和最近邻分析。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mp"><img src="../Images/b5fd4bfc3bc26f129393513fbcf40184.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZxMKMngNj_2huxl1h-KIwg@2x.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">A lady looking very happy at Lumiere London! Illumaphonium by Michael David, at Mount Street in Mayfair</figcaption></figure><h2 id="aab8" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">情感分析</h2><p id="a796" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">每条推文的情绪是使用谷歌的云 NLP API 计算的。下面的条形图显示了每天推文的平均情绪，其中-1 表示非常消极的情绪，+1 表示非常积极的情绪。</p><p id="ce48" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">我们看到，琉米爱尔伦敦 2018 年奥运会开始时情绪相对较高，然后在 1 月 17 日星期三下降，直到再次达到良好的情绪；我将不得不检查推文进一步了解下降。总体而言，琉米爱尔全天的平均情绪为 0.47。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">Figure 1: Line chart showing the average sentiment of the tweets per day</figcaption></figure><p id="5c3f" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">下表显示了按情感分类的前五条(绿色)和后五条(红色)推文。你可以通过左边的推文清楚地看到，积极的语言被云 NLP API 检测到，类似地，负面的推文在右边。</p><p id="4282" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">一些人表示灯光“不太优雅”，而另一些人则认为它们是“灯光和声音的有力庆祝”，并将其描述为“辉煌”和“令人印象深刻”。云 NLP API 做的很好！</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nn nm l"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">Table 1: Tabel showing the top five (left) and bottom five (right) tweets by sentiment score</figcaption></figure><h2 id="64f9" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">文本频率分析</h2><p id="c52c" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">下面的条形图显示了一个词出现的次数，还有一个标签出现在所有推文中，分别在左边和右边。不出所料，“卢米埃尔登”出现的次数最多。</p><p id="9101" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">然而，这些结果在告诉我们人们对事件的真实想法方面并不十分有用，因为标签的频率显然是单词频率的一个<a class="ae mj" href="https://en.wikipedia.org/wiki/Confounding" rel="noopener ugc nofollow" target="_blank">混淆变量</a>。在未来的分析中，我将尝试从文本频率分析中删除 hashtag word。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">Figure 2: Bar graphs showing the count of words and hashtags appearing in all the tweets</figcaption></figure><h2 id="5eba" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">最近的邻居</h2><p id="a107" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated"><a class="ae mj" href="https://en.wikipedia.org/wiki/Word2vec" rel="noopener ugc nofollow" target="_blank"> Word2Vec </a>是一个神经语言机器学习模型。它将大量文本(在本例中，来自 11，000 条推文的文本)作为输入，并产生一个向量空间，通常有数百个维度，每个唯一的单词对应于空间中的一个向量——单词嵌入。</p><p id="ef9b" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">重要的是，它用于计算和捕捉 11，000 条推文中单词之间的相似性和关系。具体来说，空间中距离较近的物体意味着它们是相似的——被称为最近邻。我的目标是找到所有与“<em class="mu"> LumiereLDN </em>”紧密相关的单词。</p><p id="5414" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">主成分分析用于将 Word2Vec 空间的维度降低到<em class="mu"> x </em>和<em class="mu"> y </em>坐标，其输出显示在下面的散点图中。似乎有一些聚类，但是，很乱，很难找到与“<em class="mu"> LumiereLDN </em>”紧密相关的词。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">Figure 3: PCA output of the words embedding vector space from the Word2Vec model</figcaption></figure><p id="63c4" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">我们需要进一步放大。</p><p id="d9ad" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">最近邻是来自 Word2Vec 模型的少数几个基于余弦度量相似性得分与“<em class="mu"> LumiereLDN </em>”最相似的单词。下面的散点图显示了“<em class="mu"> LumiereLDN </em>”的最近邻居。</p><p id="e739" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">拉近镜头，我们发现伦敦的区域——“<em class="mu">维多利亚</em>”、“<em class="mu">梅菲尔</em>”、“<em class="mu">菲茨罗维亚</em>”、<em class="mu">国王十字</em>”——这些艺术品被安装的地方，似乎就在附近。</p><p id="6a76" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">但重要的是，“<em class="mu">神奇的</em>”、“<em class="mu">奇妙的</em>”和“<em class="mu">好玩的</em>”这些词也近在咫尺。一个非常积极的结果！统计表明，这些词最能代表人们在推特上谈论琉米爱尔伦敦 2018 时的感受。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nl nm l"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">Figure 4: PCA output of the nearest neighbours of #LumiereLDN from the Word2Vec model</figcaption></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mp"><img src="../Images/81859eefe07267decb14a3007cb5b3f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CMwRv8fXKu3yIqEG6ZByUw@2x.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">Love Motion by Rhys Coren at The Royal Academy in the West End— my photo</figcaption></figure><h2 id="0fb6" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">结论</h2><p id="2acc" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">所以你有它！我已经在 11000 条关于琉米爱尔伦敦 2018 灯光节的推文中展示了我的 NLP 的发现。尽管有一些关于琉米爱尔伦敦的负面推文和情绪，但 Word2Vec 模型的输出显示人们对该活动持积极态度。</p><p id="b25c" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">如果你有任何想法或建议，请在下面或在我的 Kaggle 内核上留下评论——非常感谢你对 Kaggle 的支持:)</p><p id="e285" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">有这么多 NLP 库，很可能以后我会用<a class="ae mj" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank"> GloVe </a>、<a class="ae mj" href="https://www.tensorflow.org/tutorials/representation/word2vec" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>或者<a class="ae mj" href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html" rel="noopener ugc nofollow" target="_blank"> Bert </a>重新审视这个分析。</p><h2 id="fac8" class="ku kv it bd kw kx ky dn kz la lb dp lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">下次…</h2><p id="b791" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly ld lz ma mb lh mc md me ll mf mg mh mi im bi translated">在我的下一篇文章(第 3 部分)中，我将展示我的计算机视觉分析的发现。期待看到哪些艺术品出现的次数最多。敬请关注。</p><p id="a48f" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">感谢阅读！</p><p id="1f48" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">Vishal</p><p id="5ecd" class="pw-post-body-paragraph lq lr it ls b lt mk ju lv lw ml jx ly ld mm ma mb lh mn md me ll mo mg mh mi im bi translated">Vishal 是一名文化数据科学家，也是伦敦 UCL 学院<a class="ae mj" href="https://www.ucl.ac.uk/bartlett/" rel="noopener ugc nofollow" target="_blank"><em class="mu"/></a><em class="mu">的研究生。他对城市文化的经济和社会影响感兴趣。</em></p></div></div>    
</body>
</html>