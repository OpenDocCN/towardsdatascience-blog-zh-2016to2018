<html>
<head>
<title>!!! DOGS VS CATS IMAGE CLASSIFIER !!!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">！！！DOGS VS CATS 图像分类器！！！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fast-ai-season-1-episode-2-1-e9cc80d81a9d?source=collection_archive---------8-----------------------#2018-08-15">https://towardsdatascience.com/fast-ai-season-1-episode-2-1-e9cc80d81a9d?source=collection_archive---------8-----------------------#2018-08-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="96b5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">建立一个最先进的图像分类器</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/9e32842bcf8caba548ae3b5f04e0bda6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*yHPzBvszeS_VIyHIGkszig.jpeg"/></div></figure><p id="350e" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">几个月来我一直在浏览 fast.ai。我不得不承认在这个过程中我学到了很多东西和很棒的技术。我会确保更新我博客中的所有内容。感谢<a class="ae lj" href="https://twitter.com/jeremyphoward" rel="noopener ugc nofollow" target="_blank"><strong class="kp ir"/></a>和<a class="ae lj" href="https://twitter.com/math_rachel" rel="noopener ugc nofollow" target="_blank"> <strong class="kp ir">瑞秋·托马斯</strong> </a>为 AI 民主化所做的努力。感谢牛逼的<a class="ae lj" href="https://twitter.com/fastdotai" rel="noopener ugc nofollow" target="_blank"> <strong class="kp ir"> fast.ai </strong> </a>社区的所有快速帮助。</p><p id="e238" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">下图描绘了我到目前为止的旅程，这使它成为一个有趣的旅程。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/2741823201fdf8e55acbb07674b03ccd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*aerQId-PH-ERKcwIBVZkRA.jpeg"/></div><figcaption class="ll lm gj gh gi ln lo bd b be z dk"><a class="ae lj" href="https://www.jborden.com/wp-content/uploads/2015/08/bestlaidplans.jpg" rel="noopener ugc nofollow" target="_blank">Image</a></figcaption></figure><p id="538a" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了充分利用这个博客系列，请按照以下顺序随意探索这个系列的第一部分</p><ol class=""><li id="6fb6" class="lp lq iq kp b kq kr kt ku kw lr la ls le lt li lu lv lw lx bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-1-e9cc80d81a9d">狗 Vs 猫图像分类</a></li><li id="a627" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60">犬种图像分类</a></li><li id="fac6" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889">多标签图像分类</a></li><li id="95e1" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-4-1-time-series-analysis-a23217418bf1">使用神经网络的时间序列分析</a></li><li id="369f" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" href="https://geneashis.medium.com/nlp-sentiment-analysis-on-imdb-movie-dataset-fb0c4d346d23" rel="noopener">IMDB 电影数据集上的自然语言处理情感分析</a></li><li id="94be" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-1-movie-recommendation-using-fastai-a53ed8e41269">电影推荐系统的基础</a></li><li id="f4bf" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-2-collaborative-filtering-from-scratch-1877640f514a">从零开始协同过滤</a></li><li id="96fc" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-3-collaborative-filtering-using-neural-network-48e49d7f9b36">使用神经网络的协同过滤</a></li><li id="864d" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" href="https://geneashis.medium.com/fast-ai-season-1-episode-6-1-write-philosophy-like-nietzsche-using-rnn-8fe70cfb923c" rel="noopener">像尼采一样写哲学</a></li><li id="b540" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" href="https://geneashis.medium.com/fast-ai-season-1-episode-7-1-performance-of-different-neural-networks-on-cifar-10-dataset-c6559595b529" rel="noopener">不同神经网络在 Cifar-10 数据集上的性能</a></li><li id="f74d" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" href="https://medium.com/hackernoon/single-object-detection-e65a537a1c31" rel="noopener">检测图像中最大物体的 ML 模型 Part-1 </a></li><li id="d836" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" href="https://medium.com/hackernoon/single-object-detection-part-2-2deafc911ce7" rel="noopener">检测图像中最大物体的 ML 模型 Part-2 </a></li></ol><p id="33d2" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">所以，振作起来，专注于 Fastai 课程的第一部分第二课。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="md me l"/></div></figure><h1 id="ddc9" class="mf mg iq bd mh mi mj mk ml mm mn mo mp jw mq jx mr jz ms ka mt kc mu kd mv mw bi translated"><strong class="ak">狗 VS 猫分类器:</strong></h1><p id="af4f" class="pw-post-body-paragraph kn ko iq kp b kq mx jr ks kt my ju kv kw mz ky kz la na lc ld le nb lg lh li ij bi translated">这篇博文讨论了狗和猫的分类模型。这是杰瑞米·霍华德在 FastAI 课程第一部分第二课中讲授的。</p><p id="b14a" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">导入将在此模型中使用的如下所有库。</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="9153" class="nh mg iq nd b gy ni nj l nk nl">!pip install fastai==0.7.0<br/>!pip install torchtext==0.2.3</span><span id="d55e" class="nh mg iq nd b gy nm nj l nk nl">!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl <br/>!pip3 install torchvision</span><span id="6a06" class="nh mg iq nd b gy nm nj l nk nl">import fastai<br/>from matplotlib import pyplot as plt</span><span id="48c6" class="nh mg iq nd b gy nm nj l nk nl"># Put these at the top of every notebook, to get automatic reloading # and inline plotting<br/>%reload_ext autoreload<br/>%autoreload 2<br/>%matplotlib inline</span><span id="f286" class="nh mg iq nd b gy nm nj l nk nl"># This file contains all the main external libs we'll use<br/># from fastai.imports import *</span><span id="c993" class="nh mg iq nd b gy nm nj l nk nl">from fastai.transforms import *<br/>from fastai.conv_learner import *<br/>from fastai.model import *<br/>from fastai.dataset import *<br/>from fastai.sgdr import *<br/>from fastai.plots import *</span></pre><p id="fa44" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">使用以下命令检查 GPU 是否已启用:-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/fcb6f6d3c90ec7765ca4146252f7d726.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*RltAHKeJ71s4Y5xUH-GmBg.png"/></div></figure><p id="bb83" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上述命令的输出应该返回 True。</p><p id="1602" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在深入研究之前，我想提几个可能有用 Linux 命令。</p><p id="1fc9" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">使用前缀为“！”的命令马克。</p><ol class=""><li id="099c" class="lp lq iq kp b kq kr kt ku kw lr la ls le lt li lu lv lw lx bi translated"><code class="fe no np nq nd b">!ls</code>是一个列出当前目录中文件的命令。</li><li id="b01c" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><code class="fe no np nq nd b">!pwd</code>代表打印工作目录。将打印工作目录的路径</li><li id="5a1a" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><code class="fe no np nq nd b">!cd </code>代表变更目录。</li></ol><p id="437d" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">以上三个命令有助于在目录间导航。</p><p id="7dd1" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">使用以下命令下载了狗和猫的图像。</p><p id="c3c7" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">&lt;&lt; !wget <a class="ae lj" href="http://files.fast.ai/data/dogscats.zip" rel="noopener ugc nofollow" target="_blank">http://files.fast.ai/data/dogscats.zip</a>&gt;&gt;</p><p id="26d2" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">文件夹的结构应该如下所示</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/a16a690452301622f7d0cfcf0be3b35c.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*CVdcnoX05--2tQVqKMsrBg.png"/></div></figure><p id="7c3f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">设置存储数据的路径</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="80bc" class="nh mg iq nd b gy ni nj l nk nl">PATH = "data/dogscats/"<br/>sz=224</span></pre><p id="f32a" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">使用以下命令检查文件是否已经下载</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi ns"><img src="../Images/28a96bd5e94abcc3cc713d8693eb0c7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iQbJLCxkFcxt3BWvnYKXXg.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi nx"><img src="../Images/690f4700ea0981a56119f64461db64e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ksHCjXD9Ay6GrPBYsZeP5Q.png"/></div></div></figure><p id="857c" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上面的<code class="fe no np nq nd b">f ’ </code>代表 f 弦。这是一种在 Python 中格式化字符串的新方法。想了解更多关于 f 弦的信息，请点击 realpython.com 的<a class="ae lj" href="https://realpython.com/python-f-strings/" rel="noopener ugc nofollow" target="_blank">链接。</a></p><p id="75fd" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">分类任务将利用预训练模型。预训练模型是已经由其他人对类似类型的数据进行了训练的模型。因此，不是从头开始训练模型，而是使用已经在 ImageNet 上训练过的模型。ImageNet 是由 120 万幅图像和 1000 个类组成的数据集。<code class="fe no np nq nd b">ResNet34 </code>是将要使用的模型版本。这是一种特殊类型的卷积神经网络。<code class="fe no np nq nd b">ResNet34 </code>获得 2015 年 ImageNet 大赛冠军。ResNet 的细节将在即将发布的博文中讨论。</p><p id="8ffe" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">下面几行代码显示了如何使用 fastai 训练模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi ny"><img src="../Images/b4f3ee4de97936542a6f37ad3fd02ecb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*azKOGIqnwtD5Y3Y6X4Srgg.png"/></div></div></figure><p id="8ec6" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">使用的架构<code class="fe no np nq nd b">resnet34 </code>已经保存在 arch 变量中。数据保存在数据变量中，因为它在前面指定的路径中查找数据。<code class="fe no np nq nd b">tfms </code>是数据扩充的一部分，稍后将详细讨论。</p><p id="c7f2" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><code class="fe no np nq nd b">pre-trained</code>方法从 arch 模型(<code class="fe no np nq nd b">resnet34</code>)创建新的神经网络。拟合方法使用学习率和指定的时期数来训练模型。并且已经获得了<code class="fe no np nq nd b">0.9895</code>的精度。</p><p id="1717" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">梯度下降</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi nz"><img src="../Images/8e300eb897bd1eaae8fa84279add969d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p5oMtaJYknvAzqO8-aNBGA.png"/></div></div></figure><p id="7100" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我来解释一下上面的图像。最初选择的参数是随机的。此时的损失很大。高损失表明在训练期间,“结果/预测值”和“目标值/标签”之间的差异更大。因此，应该遵循一种方法，使用这种方法应该使这种差异最小。收敛或达到局部最小值意味着此时损失最小，因此结果和目标值/标签之间的差异最小。这个过程被称为<strong class="kp ir">梯度下降。</strong></p><p id="ac6a" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">学习率:- </strong></p><p id="bb47" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上述拟合函数中的<strong class="kp ir">学习率(LR) </strong>是最重要的参数之一，应仔细选择，以使模型快速有效地达到最优解。基本上说的是如何快速到达函数中的最优点。如果 LR 很低，则过程很慢，如果 LR 太高，则很有可能超过最小值。因此，必须仔细选择 LR，以确保收敛(达到局部最小值)以有效的方式发生。下图描述了上述概念。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi nz"><img src="../Images/2daf937f8ce495e854ac25fd5b629909.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XQFr08TTx8_lfBi1hx_udw.png"/></div></div></figure><p id="06cd" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">如何选择最佳学习率？</strong></p><p id="eb4f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">！！！别担心，杰瑞米·霍华德会支持你的。杰里米提到了一个很好的方法来计算学习率，它被称为</p><p id="4c62" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">学习率查找器。</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oa me l"/></div></figure><p id="49a3" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">请检查下面的代码。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi ob"><img src="../Images/9c6946039be1e17e0882779dd2a19668.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N2xiF6ireC_2Mnskp2bx4w.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/b0d1094605e96dbf5b72a721585ad82e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*hz2nHRdUMpHKZBqCM7oIjg.png"/></div></figure><p id="0d1d" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">使用<code class="fe no np nq nd b">lr_find()</code>可以获得最佳学习率。如学习率与迭代图所示，LR 在每次小批量后增加，并呈指数增加。在第二个图中，即损耗对学习率，观察到损耗随着学习率的增加而减少一段时间，当学习率为 0.1 时，损耗处于最小值，之后它开始再次上升(这意味着 LR 如此之高，以至于它已经超过最小值，损耗变得更糟)。</p><p id="046f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">选择最佳学习率</strong>，步骤如下:-</p><ol class=""><li id="b617" class="lp lq iq kp b kq kr kt ku kw lr la ls le lt li lu lv lw lx bi translated">确定上面损失与学习率图表中的最低点(即 0.1)</li><li id="8539" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated">后退 1 级(即 0.01)，选择该值作为学习率。</li></ol><p id="1bbb" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">后退 1 级背后的概念:- </strong></p><p id="9547" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">虽然在这一点上损失最小，但是在这一点上选择的学习速率太高，并且继续使用这一学习速率将不会收敛。请查看下图进行解释。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi od"><img src="../Images/7eefe53b2b9e0f42039d121b1e2f040c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*2Mm3-O6cXSOfl0Ykt-MiuQ.png"/></div></div></figure><p id="33f6" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">注意:- </strong>学习率查找器是最重要的超参数之一，如果调整/选择得当，将会产生最佳效果。</p><p id="7543" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">改进模型</strong></p><p id="42c7" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">改进模型的一个方法是给它更多的数据。因此，我们使用数据增强。<strong class="kp ir">等等，但是</strong> <strong class="kp ir">为什么要数据增强？</strong></p><p id="7a49" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们的模型通常有几百万个参数，当训练更多的数时，有很大的可能性，它可能开始过度拟合。过度拟合意味着模型过度学习训练数据集中图像的特定细节，并且它可能无法在验证数据集或测试数据集上很好地概括。换句话说，当验证数据集的精度小于训练数据集的精度时(或者在训练数据集上计算的损失远小于在验证数据集上计算的损失)，就发生了过拟合。因此<strong class="kp ir">过度拟合</strong>可以通过向模型提供更多数据来避免，因此使用数据扩充。</p><p id="5754" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">注意:- </strong>数据增强并不是创造新的数据，而是让卷积神经网络从一个非常不同的角度学习如何识别狗或猫。</p><p id="24ec" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">对于数据扩充，我们在<code class="fe no np nq nd b">tfms_from_model()</code>函数中将<code class="fe no np nq nd b">transforms_side_on</code>传递给<code class="fe no np nq nd b">aug_tfms</code>。<code class="fe no np nq nd b">transforms_side_on </code>通过水平翻转将给出不同版本的图像。它让神经网络看到图像，就好像它是从侧面角度拍摄的一样，少量旋转它们，稍微改变它们的对比度、亮度，稍微放大一点，移动一点。这些变化可以在下图中看到。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi oe"><img src="../Images/00ec83e076fa915e2db0aa4e4d7c55ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SZbJplmmebG0EgflPd02dA.png"/></div></div></figure><p id="f4b2" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">要进行数据扩充，请编写以下代码</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="6437" class="nh mg iq nd b gy ni nj l nk nl">tfms = tfms_from_model(resnet34, sz, aug_tfms=transforms_side_on, max_zoom=1.1)<br/>data = ImageClassifierData.from_paths(PATH, tfms=tfms)</span></pre><p id="c63c" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">虽然为数据扩充创造了空间，但是数据扩充不起作用，因为它最初被设置为<code class="fe no np nq nd b">precompute=True .</code></p><p id="e3a7" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">让我详细解释以下代码及其与上述语句的关系:-</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="dc3f" class="nh mg iq nd b gy ni nj l nk nl">data = ImageClassifierData.from_paths(PATH, tfms=tfms)<br/>learn = ConvLearner.pretrained(arch, data, precompute=True)<br/>learn.fit(1e-2, 1)</span></pre><p id="095f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">当使用<code class="fe no np nq nd b">ConvLearner.pretrained(…) </code>声明架构时，<strong class="kp ir">预计算</strong>被设置为真，这表示实现来自预训练网络的激活。预训练网络是已经学会识别某些事物的网络。对于我们的狗与猫的研究，使用的预训练网络已经学会了对 ImageNet 数据集中 120 万张图像的 1000 个类别进行分类。因此，采取倒数第二层(因为这是一层，有所有必要的信息来计算出图像是什么)，并保存这些激活。为每个图像保存这些激活，这些被称为<strong class="kp ir">预计算激活。</strong>现在，当创建新的分类器时，利用这些预先计算的激活，并基于这些激活快速训练模型。因此要实现这个 set <strong class="kp ir"> precompute=True。</strong></p><p id="ebc1" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">注意:- </strong>当<code class="fe no np nq nd b"><strong class="kp ir">precompute=True</strong></code> <strong class="kp ir"> </strong>时，数据扩充不起作用，因为它当前使用的是特定版本的扩充 cat，或者换句话说，即使每次显示的是不同版本的 cat，特定版本 cat 的激活已经预先计算好了。第一次运行时，预计算激活需要一两分钟。</p><p id="4b1a" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">当使用预计算激活训练时，精确度是<code class="fe no np nq nd b">98.8%</code> :-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/1bcc2a5a38b02ddaa4a5d266d023578f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*zU8coP8SuDAIMqjqMBoi1g.png"/></div></figure><p id="4be2" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">要进行数据扩充，设置<code class="fe no np nq nd b"><strong class="kp ir">precompute=False</strong></code> <strong class="kp ir"> </strong>并检查准确性。在下面的代码中<code class="fe no np nq nd b"><strong class="kp ir">cycle_len</strong></code> <strong class="kp ir"> </strong>是一个重要的参数，将在本文后面详细讨论。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/f2433eae21ad4e36287b21e3284430e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*bUW5Cc3d-I-7vDQE9JXzXg.png"/></div></figure><p id="39d3" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">精确度增加了一点到<code class="fe no np nq nd b">99.1% </code>，好消息是，它没有过度拟合，训练损失进一步减少。为了进一步改进模型，让我们关注:-</p><p id="740f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> SGDR(重启随机梯度下降)</strong></p><p id="ba16" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">SGDR 说，当我们越来越接近最小值时，让我们降低学习率。随着我们的训练(即更多的迭代次数)降低学习率的想法被称为学习率退火。有步进式和余弦退火。在这个过程中，杰瑞米·霍华德使用余弦退火。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/b9840143e90a02bf5992b3f5813b270e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*GQXXcI00EYoUlPHcVDeyjw.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/a845dc5cfff96ff576ca5d2f90a94761.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*DSJGbq8DCfjNCatqILILlw.png"/></div></figure><p id="770b" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在余弦退火中，当不在最小值附近时，我们使用较高的学习率进行训练。当接近局部最小值时，切换到较低的学习速率，并在此基础上进行几次迭代。</p><p id="0cfa" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上图显示了一个简单的损失函数。实际上，数据集是在一个非常高维的空间中表示的，有许多相当平坦的点，这些点不是局部极小值。假设我们的表面看起来像下面的图表</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi oj"><img src="../Images/33d84f74c68ca29e6ca00aac9bc3b1af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H6Hx_-mR6uT9FddKUSL3BA.png"/></div></div></figure><p id="5171" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">从 1 号红点开始，达到了 2 号红点所示的全局最小值，但是这里不能很好地概括。如果使用这种解决方案，在稍微不同的数据集的情况下，它不会导致好的结果。另一方面，红点 3 将在稍微不同的数据集的情况下很好地概括。我们的<strong class="kp ir">标准学习率退火方法</strong>将下降到一个点，在高维度中有很大的机会陷入尖峰区域，在那里它不会更好地概括，因此不是一个好的解决方案。相反，可以部署一个<strong class="kp ir">学习速率调度器</strong>，它将重置并执行余弦退火，然后再次跳转，这样它将从点 2 跳转到点 3，以此类推，直到它到达一个泛化能力非常好的点。</p><blockquote class="ok ol om"><p id="cfe9" class="kn ko on kp b kq kr jr ks kt ku ju kv oo kx ky kz op lb lc ld oq lf lg lh li ij bi translated">每次学习率被重置，它将再次增加学习率，这将导致离开表面的讨厌的尖峰部分，并最终跳到一个漂亮光滑的碗，这将更好地概括。</p></blockquote><p id="e602" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上述过程被称为<strong class="kp ir"> SGDR </strong>(重启随机梯度下降)。这个 SGDR 最好的部分是一旦达到一个“像表面一样光滑的曲线”,它就不会再开始了。它实际上是在空间的这个好地方逗留，然后不断变得更善于找到合理的好位置。请检查下图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi oj"><img src="../Images/b99dc4f78a15f5687dc8ceeeaa6fa468.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XzJyyHgMT0wSyUmGFT-DHA.png"/></div></div></figure><p id="f0ee" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">使用<strong class="kp ir"> SGDR </strong>和<strong class="kp ir">学习率查找器</strong>会给我们更好的结果。从学习率搜索器中，试着视觉上找到一个好的学习率，否则在 SGDR 它不会跳到一个平滑的表面上。借助<code class="fe no np nq nd b"><strong class="kp ir">cycle_len</strong></code> <strong class="kp ir"> </strong>参数重置学习率。这基本上意味着在每 1 个时期后重置学习率。下图显示了重置是如何发生的</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/bf0c75566f16d2cdb2bec282b8007eba.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*PvDmvuXas3V9UdQH-RBVxg.png"/></div></figure><p id="6566" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">注意:- </strong>学习率的重置发生在每一个时期之后，因为<code class="fe no np nq nd b">cycle_len=1</code>和学习率在每一个小批量之后保持变化。y 轴是学习率，其中 0.010 是我们从学习率查找器获得的学习率。所以 SGDR 会在 0 到 0.010 之间调整学习率。</p><p id="0556" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">建议在中间步骤继续保存模型。为此，请使用以下命令:-</p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="f942" class="nh mg iq nd b gy ni nj l nk nl">learn.save('224_lastlayer')<br/>learn.load('224_lastlayer')</span></pre><p id="f5f4" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">该模型保存在<strong class="kp ir"> dogscats </strong>文件夹下的 models 文件夹中，如下所示</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/53af75f89692e0b294c5d0e2efee0f4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:486/format:webp/1*7x1UkIbjWD_XuwNtA2DbMA.png"/></div></figure><p id="7898" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">所有预计算的激活都保存在<code class="fe no np nq nd b">tmp </code>文件夹中。因此，如果出现奇怪的错误，可能是由于半完成预计算激活或其他方式，继续删除<code class="fe no np nq nd b">tmp </code>文件夹，并检查错误是否已经消失。这是快速开关它的方法。</p><p id="8ceb" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">注意:- </strong>预计算激活不需要任何培训。这些是预训练模型用我们下载的重量创建的。</p><p id="d3c7" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">我们还能做些什么来让模型变得更好？</strong></p><p id="0345" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">到目前为止，预训练激活已经下载并直接使用。CNN 内核中预先训练的激活或预先计算的权重保持不变(即，尚未进行预先计算的权重的重新训练)。预先训练的模型已经知道如何在早期阶段找到边缘、曲线、梯度，然后找到重复的模式，最终找到主要特征。到目前为止，只有新的层被添加到顶部，模型学会了如何混合和匹配预先训练的功能。如果在 Imagenet 上训练的模型被扩展到诸如“卫星图像分类”的情况，其中特征完全不同，则需要重新训练大多数层，因为特征完全不同。因此，需要探索一个新概念，命名为:-</p><p id="3add" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">微调和差分学习率</strong></p><p id="2c2d" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">要学习一套不同的功能或告诉学习者卷积滤波器需要改变，只需<code class="fe no np nq nd b"><strong class="kp ir">unfreeze </strong></code>所有层。<strong class="kp ir">冻结的</strong>层是其权重没有被训练或更新的层。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ot me l"/></div></figure><p id="3434" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><em class="on">！！！好吧好吧艾尔莎，我会让它去解冻层！！！</em>😍 😍</p><p id="331e" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">解冻图层将使图层权重对训练或更新开放。但是与后面的层相比，最初的层需要很少或任何训练。这普遍适用，因为初始层的工作是学习边缘和曲线，而后面的层学习重要的特征。因此，对于不同的层集合，学习速率被设置为不同的。这个概念被称为<strong class="kp ir">差异学习率。</strong></p><pre class="kg kh ki kj gt nc nd ne nf aw ng bi"><span id="9161" class="nh mg iq nd b gy ni nj l nk nl">learn.unfreeze()<br/>lr=np.array([1e-4,1e-3,1e-2])</span></pre><p id="7199" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">进行必要的更改后，按如下所示训练模型。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/3b1d393967923dfaa90ade980da66028.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*nJN0_T4qJzh01QU44i-9XA.png"/></div></figure><p id="ff2d" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">前面讨论了<code class="fe no np nq nd b">cycle_len=1 </code>和<code class="fe no np nq nd b">number_of_cycles=3</code>参数。再次提醒一下，<code class="fe no np nq nd b">cycle_len=1 </code>是历元的数量，<code class="fe no np nq nd b">number_of_cycles=3 </code>表示学习者将做 3 个周期，每个周期 1 个历元。现在一个新的参数被引入，命名为<code class="fe no np nq nd b">cycle_mult=2</code>。此<code class="fe no np nq nd b">cycle_mult </code>参数在每次循环后乘以每次循环的长度。这里的倍增因子是 2。于是<code class="fe no np nq nd b">(1+2*1 +2*2 )epoch</code> = <code class="fe no np nq nd b">7 epoch</code>。也就是说，如果周期长度太短，它开始下降，找到一个合理的好点，然后弹出，再次下降，弹出。它实际上从来没有找到一个好点，这既是一个很好的最小值，也是一个很好的概括。这是一个机会的问题。它没有探索表面。所以要探索地表更要设定<code class="fe no np nq nd b">cycle_mult=2</code>。现在，图表看起来更具探索性</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/f7140e9bab8d8e810320241fe88d5f10.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*EsBWbS5ZZ9EzuKXob7EVMw.png"/></div></figure><p id="66ff" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">据观察，到目前为止，精度已经提高到<code class="fe no np nq nd b">99.0% </code>，损耗也大幅降低。还有最后一个方法可以让模型变得更好。它被称为</p><p id="89b9" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">测试时间增加(TTA) </strong></p><p id="7acb" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在验证/测试数据集上，所有输入都必须是正方形。这有助于 GPU 快速处理。如果验证数据集中的输入图像具有不同的维度，则处理速度不会很快。为了保持一致，在中间画出正方形。如下例所示:-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/d90b9d6e71403f13ae39648a82b0c002.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*Li0l2DTG9WMGrNNpKJiaqg.png"/></div></figure><p id="2199" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如果上面的图片在中间是方形的，模型将很难预测它是狗还是猫，因为它是唯一进入验证数据集的身体。为此(<strong class="kp ir">测试时间增加</strong>)使用了 TTA。它将随机进行四次数据增强，以及未经增强的原始中心裁剪图像。然后取所有这些图像上所有预测的平均值。这是我们最后的预测。</p><p id="4f36" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">注:- </strong>仅适用于测试和验证数据集。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/5de2106061d1454c2e936bb55030f0ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*URumYO75VRL5IJn2ZA2fXw.png"/></div></figure><p id="78dd" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如上所示，应用 TTA 后的精度为<code class="fe no np nq nd b">99.35%</code>。</p><p id="5306" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了得到我们的分类器的概要，画一个混淆矩阵。混淆矩阵用于分类，以了解有多少预测正确或不正确，如下图所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="nt nu di nv bf nw"><div class="gh gi oy"><img src="../Images/d4a4a39b422598ea0f3b0cdabf36dae7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*Tj9iy1ZeLdljiiOaJDgvgQ.png"/></div></div></figure><p id="c5cd" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">混淆矩阵的解释:- </strong></p><p id="d845" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">混淆矩阵说明了我们的分类器有多好。如上所述，深蓝色区域已经被正确分类。996 张猫图片已被分类为猫，993 张狗图片已被正确分类为狗。7 张狗图片被归类为猫，4 张猫图片被归类为狗。因此，我们的分类器做得非常好。</p></div><div class="ab cl oz pa hu pb" role="separator"><span class="pc bw bk pd pe pf"/><span class="pc bw bk pd pe pf"/><span class="pc bw bk pd pe"/></div><div class="ij ik il im in"><p id="8798" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">希望这篇文章对你有所帮助。在我未来的博客文章中，我们将深入探讨。因为涵盖了很多重要的概念，你现在可能会有这种感觉。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="pg me l"/></div></figure><p id="805f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">！！坚持住，更多有趣的东西即将到来。直到那时再见😉！！</p><p id="a730" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><em class="on">附注——如果你有兴趣，请在这里</em>  <em class="on">查看代码</em> <a class="ae lj" href="https://github.com/CaptainAshis/Deep_Learning-Experiment/blob/master/Dog%20Vs%20Cats/dogs%20vs%20cats.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="on">。</em></a></p><p id="b9af" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">甲乙丙</strong> - <em class="on">一直在鼓掌。</em> <strong class="kp ir"> <em class="on">👏 👏👏👏👏</em>😃😃😃😃😃😃😃😃😃<em class="on">👏 👏👏👏👏 👏</em> </strong></p><p id="a7f2" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">编辑 1:-TFW·杰瑞米·霍华德同意你的帖子。😃😃😃😃😃😃</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ph me l"/></div></figure><p id="0699" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了充分利用这个博客系列，请按照以下顺序随意探索这个系列的第一部分</p><ol class=""><li id="fd69" class="lp lq iq kp b kq kr kt ku kw lr la ls le lt li lu lv lw lx bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-1-e9cc80d81a9d">狗 Vs 猫图像分类</a></li><li id="7bde" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60">犬种图像分类</a></li><li id="5285" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889">多标签图像分类</a></li><li id="3018" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-4-1-time-series-analysis-a23217418bf1">利用神经网络进行时间序列分析</a></li><li id="3324" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" href="https://geneashis.medium.com/nlp-sentiment-analysis-on-imdb-movie-dataset-fb0c4d346d23" rel="noopener">对 IMDB 电影数据集的 NLP 情感分析</a></li><li id="4f31" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-1-movie-recommendation-using-fastai-a53ed8e41269">电影推荐系统的基础</a></li><li id="ae97" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-2-collaborative-filtering-from-scratch-1877640f514a">从零开始协同过滤</a></li><li id="7401" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-3-collaborative-filtering-using-neural-network-48e49d7f9b36">使用神经网络的协同过滤</a></li><li id="e0c5" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" href="https://geneashis.medium.com/fast-ai-season-1-episode-6-1-write-philosophy-like-nietzsche-using-rnn-8fe70cfb923c" rel="noopener">像尼采一样写哲学</a></li><li id="aeca" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" href="https://geneashis.medium.com/fast-ai-season-1-episode-7-1-performance-of-different-neural-networks-on-cifar-10-dataset-c6559595b529" rel="noopener">不同神经网络在 Cifar-10 数据集上的性能</a></li><li id="4438" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" href="https://medium.com/hackernoon/single-object-detection-e65a537a1c31" rel="noopener">检测图像中最大物体的 ML 模型 Part-1 </a></li><li id="c5a1" class="lp lq iq kp b kq ly kt lz kw ma la mb le mc li lu lv lw lx bi translated"><a class="ae lj" href="https://medium.com/hackernoon/single-object-detection-part-2-2deafc911ce7" rel="noopener"> ML 模型检测图像中最大的物体 Part-2 </a></li></ol></div></div>    
</body>
</html>