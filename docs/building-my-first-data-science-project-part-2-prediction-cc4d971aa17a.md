# 预测患者存活率:预测

> 原文：<https://towardsdatascience.com/building-my-first-data-science-project-part-2-prediction-cc4d971aa17a?source=collection_archive---------7----------------------->

![](img/deca7284f039e5d93c25786de041bad5.png)

## 构建我的第一个数据科学项目

得到数据后，很容易立即尝试拟合几个模型并评估它们的性能。然而，首先要做的是探索性数据分析(EDA)，它允许我们探索数据的结构，并理解控制变量的关系。任何 EDA 都应该包括创建和分析几个图，并创建汇总统计数据，以考虑我们的数据集中存在的模式。

*如果你想知道，我是如何为这个特定的项目执行 EDA 的，你可以阅读这个* [*以前的帖子*](https://medium.com/@meinzaugarat/building-my-first-data-science-project-part-1-exploratory-analysis-9112684badcd) *。*

从这个项目的 EDA 中，我们了解了数据集的一些重要特性。首先，当一个类别中的观察值总数明显低于另一个类别中的观察值时，不会出现 ***类别不平衡****。此外，我们的一些变量显示了偏斜度，在对它们进行对数转换后，偏斜度得到了固定，并且没有变量
显示出与其他变量的完美线性关系，尽管在其中一些变量中，我们可以观察到相互作用的趋势。*

# ***机器学习预测***

*执行机器学习时要做出的一个主要决定是选择适合我们正在处理的当前问题的适当算法。*

***监督学习**指的是从带标签的训练数据集中推断出一个函数的任务。我们将模型拟合到带标签的训练集，主要目标是找到最佳参数，这些参数将预测测试数据集中包含的新示例的未知标签。有两种主要类型的监督学习:回归，其中我们希望预测一个实数标签，以及分类，其中我们希望预测一个分类标签。
在我们的例子中，我们有一个带标签的数据集，我们想使用分类算法在分类值 0 和 1 中找到标签。*

*我们可以找到许多分类监督学习算法，一些简单但有效，如线性分类器或逻辑回归，另一些更复杂但功能强大，如决策树和 k-means。*

*在这种情况下，我们将选择**随机森林**算法。随机森林是最常用的机器学习算法之一，因为它非常简单、灵活和易于使用，但产生可靠的结果。*

*简而言之，随机森林创建了多个决策树的森林和*，并集合它们以获得更准确的预测。随机森林相对于决策树的优势在于，单个模型的组合改善了整体结果，并且通过从特征的随机子集创建更小的树来防止过度拟合。**

*因此，我们将首先从 scikit 加载包——了解我们需要执行随机森林，然后还要评估模型。我们还将使用 0 或 1 或`NaN`替换分类值，并将所有变量转换为浮点型，并对变量进行对数转换以固定偏斜度，就像我们在 EDA 中所做的那样。我们将再次检查每个变量中缺失值的总数:*

*在 EDA 中，我们丢弃了所有的`NaN`值。这里，我们需要评估处理它们的最佳方法是什么。
***处理缺失数据有几种方法*** 但没有一种是完美的。第一步是了解数据丢失的原因。在我们的例子中，我们可以猜测分类变量中缺失的值可能是由于缺少特征，而不是作为`no`输入为空，或者没有进行测试。此外，连续变量中的缺失值可能是由于缺乏对该特定患者进行的生化研究，或者是因为参数在正常范围内且没有记录下来。*

*在这两种情况下，我们都有可能在出现**时随机缺失**值(该值缺失的事实与假设值无关)或**时不随机缺失**值(该缺失值取决于假设值)。如果是第一种情况，我们可以安全地删除`NaN`值，而在最后一种情况下，删除它是不安全的，因为这个丢失的值告诉我们一些关于假设值的信息。所以在我们的例子中，一旦我们要训练我们的模型，我们将估算缺失值的值。*

*特征缩放或数据归一化，一种用来标准化自变量范围的方法，也是训练很多分类器之前非常重要的一步。如果数据不在同一范围内，一些模型的性能会很差。随机森林的另一个优点是不需要这一步。*

***将数据集分为训练数据集和测试数据集***

*为了训练和测试我们的模型，我们需要将我们的数据集分成子数据集， ***训练和测试数据集*** 。该模型将从训练数据集中学习，以推广到其他数据；测试数据集将用于“测试”模型在训练和拟合步骤中学到了什么。
常用 **80%-20%** 的规则对原始数据集进行拆分。使用可靠的方法分割数据集以避免数据泄漏是很重要的；这是存在于测试集中的例子，它们也存在于训练集中，并且可能导致过度拟合。*

*首先，我们将把除因变量(“Class”)之外的所有列分配给变量 X，把列“Class”分配给变量 Y。
，然后我们将从 scikit-learn 库中`train_test_split`把它们分成 X_train、X_test、Y_train 和 Y_test。添加`random_state`很重要，因为这将允许我们在每次运行代码时得到相同的结果。*

**注意:*训练/测试分割有一些缺点，因为一些模型需要调整超参数，在这种情况下，也在训练集中完成。避免这种情况的一种方法是创建一个规则为 60/20/20%的训练/验证/测试数据集。有几种有效的方法可以做到这一点，我们将在下面看到。*

***训练随机森林***

*现在很容易估算缺失值(使用`Imputer`)，使用 Scikit-learn 软件包创建和训练基本随机森林模型。我们将开始应用`.ravel()`到 ***Y_train*** 和 ***Y_test*** 来展平我们的数组，因为不这样做将会引起我们模型的警告。*

*然后，我们将使用函数`Imputer`和策略`most_frequent`来估算缺失值，这将替换列(轴= 0)中最频繁出现的值的缺失值。值得注意的是，这样做可能会引入错误和偏见，但当然，正如我们之前所述，没有完美的方法来处理缺失数据。*

*我们的基本模型现在已经被训练，并且已经学习了我们的自变量和目标变量之间的关系。现在，我们可以通过对测试集进行预测来检查我们的模型有多好。然后，我们可以将预测与我们已知的标签进行比较。*

*我们将再次估算测试集中的缺失值，并使用函数`predict`和指标`accuracy_score`来评估我们模型的性能。*

*正如我们在上面看到的，我们的基本模型有 74.19%的准确率，这告诉我们它还需要进一步改进。*

***超参数调整***

*有几种方法可以改进我们的模型:收集更多的数据，调整模型的超参数或选择其他模型。我们将选择第二个，我们现在将调整我们的随机森林分类器的超参数。*

*模型参数通常在训练期间学习；然而，超参数必须在训练前手动设置。对于随机森林，超参数包括:*

*   *n_estimators:森林中的树木数量*
*   *max_features:每个树中的最大特征数*
*   *max_depth:所有树的最大分割数*
*   *bootstrap:是否实现 bootstrap 来构建树*
*   *标准:评估决策树的停止标准*

*当然，当我们实现基本的随机森林时，Scikit-learn 实现了一组默认的超参数，但是我们不确定这些参数对于我们的特定问题是否是最优的。*

*在这一点上，我们需要考虑两个概念:欠拟合和过拟合。 ***欠拟合*** 发生在模型过于简单，与数据拟合不太好的时候:方差小，偏差大。另一方面， ***过拟合*** 发生在模型对训练集调整得太好而在新的例子中表现不佳的时候。如果我们调整训练数据集中的超参数，我们可能会使随机森林分类器过拟合。因此，我们将回到之前提到的:交叉验证*。**

**交叉验证的方法有很多，最著名的有: **K 重交叉验证**和**留一交叉验证。**在我们的例子中，我们将使用第一个:我们将把我们的数据分成 K 个不同的子集，使用 k-1 个子集作为我们的训练集，最后一个子集作为我们的测试数据。为了调整我们的超参数，我们将对 K-子集交叉验证执行多次迭代，但每次使用不同的模型设置。然后，我们比较所有的模型，选择最好的一个；然后，我们将在完整的训练集中训练最好的模型，并在测试集上对其进行评估。我们将利用 Scikit-learn 中的 *GridSearchCV* 包来执行这项任务。**

**我们将确定想要优化的参数和值，然后执行 GridSearchCV，并将获得的最佳参数设置为我们的模型。**

**正如我们在上面看到的，GridSearchCV 将我们的准确率从 74%提高到了 77%。尽管这不是一个很大的改进，但据报道，使用这个数据集，其他研究仅达到 80%的准确率。因此，考虑到这一点以及数据集有许多缺失数据且不大(只有 155 个样本)的事实，我们可以继续分析其他模型指标。**

****测试集指标****

**既然我们已经优化了超参数，我们将继续评估我们的模型。首先，我们将创建一个混淆矩阵，它将根据我们的预测值告诉我们真阴性、假阳性、假阴性和真阳性值，并使用 seaborn heatmap 绘制它:**

**真阴性(TN)|假阳性(FP)
—————
假阴性(FN)|真阳性(TP)**

**分析混淆矩阵，我们可以预期我们的模型显示出比精确度(TP/TP+FP)更高的召回率(TP/TP+FN ),但是两个参数都将高于精确度(TP+TN)/总数。根据我们认为我们的模型需要解决的问题，可以考虑这三个参数。我们稍后将回到这些问题上。**

**我们可以使用 ROC 曲线并计算曲线下的面积来进一步研究假阳性率和真阳性率，曲线下的面积也是我们模型的预测能力的度量(如果该值更接近 1，则意味着我们的模型在将随机样本区分为两类方面做得很好)。**

**从 ROC 曲线中，我们了解到我们的模型在区分两个类别方面做得不好，因为 **auc** 是 0.60。我们可以通过收集更多的数据并添加到模型中来改善这个问题。**

**最后，我们可以分析精确-回忆曲线:**

**我们可以观察到，对于不同的值，精度-召回率关系是相当恒定的，表明我们的模型具有良好的精度和召回率。这是因为与真阴性、假阳性和假阴性相比，真阳性值相当高。重要的是要记住，由于召回率和精确度的公式，当一个高，另一个低，推动我们找到一个平衡，两者对我们的模型都足够高。**

****解读结果****

**在完成我们的项目之前，我们可以做的最后一件事是评估变量的重要性，也就是量化每个变量对我们的模型有多有用。**

**我们可以观察到年龄、蛋白时间、alk_phosphate、胆红素、不适、腹水是我们模型的一些最重要的变量。这反映了我们之前在 EDA 中看到的情况，并强调了在开始机器学习算法之前执行这种探索性分析的重要性。**

****总结****

**因此，在将随机森林应用于我们的数据集后，我们可以得出结论，我们的最佳模型能够预测肝炎患者的存活率，准确率为 77%，精确度和召回率约为 80%。这不是最好的情况，因为我们希望我们的模型表现得更好，特别是在这种涉及患者生存的情况下。然而，中等的好结果可能是由于数据库小和大量的缺失值。**