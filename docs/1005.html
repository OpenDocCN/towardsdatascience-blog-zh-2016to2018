<html>
<head>
<title>Clone a human driver’s behavior and mimic it for autonomous vehicle applications</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">克隆人类驾驶员的行为，并将其应用于自动驾驶汽车</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/clone-a-human-drivers-behavior-and-mimic-it-to-let-a-vehicle-drive-autonomously-e2930a61b42c?source=collection_archive---------10-----------------------#2017-07-19">https://towardsdatascience.com/clone-a-human-drivers-behavior-and-mimic-it-to-let-a-vehicle-drive-autonomously-e2930a61b42c?source=collection_archive---------10-----------------------#2017-07-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="137c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如何克隆人类司机的行为？嗯，首先，我们需要去兜兜风，同时采集一些数据。听起来不错。让我们开始吧。没那么快。你会问为什么？因为我车里没有设备来完成这件事。好吧，我会退而求其次:一个由 Udacity 创建的模拟环境，它服务于我的目的:在模拟环境中驾驶汽车并捕捉数据。听起来像是轻而易举的事，但我不知道我的游戏技能充其量也就是一般水平。我试了 20 多次才让这辆车在跑道上行驶而不撞车。现在我有了一些数据，我需要建立一个卷积神经网络(CNN)，并训练它模仿我捕捉的数据。如果一切顺利，CNN 模型将学习模仿驾驶行为，并克隆学习自己驾驶。如果你只对最终结果感兴趣，就跳到这个<a class="ae kl" href="https://youtu.be/ap68tlotoPk" rel="noopener ugc nofollow" target="_blank"> <em class="km">视频</em> </a> <em class="km">。关于详细的讨论，请继续阅读。</em></p><p id="78ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">希望一切顺利，我建立了模型，训练了它，并在模拟器上焦急地测试它，以查看结果:当我的车可以自主游泳和越野时，谁想模仿我的驾驶！看看下面的视频，你就会明白我在说什么了。在那一瞬间，我觉得我的冒险车是最酷的！它可以越野行驶，也可以游泳。直到它翻转过来的那一刻😒。回到基础，我去了。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="ks kt l"/></div></figure><p id="2da6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第一步:收集和探索数据</strong></p><p id="b8aa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我最初捕捉到的训练数据是在赛道上跑一圈多一点。我需要更多的数据和更好的模型。为了获取更多的数据，我没有重新使用我糟糕的视频游戏技能，而是选择用 Udacity 提供的额外数据来扩充我的数据。模拟器有一辆带有三个捕捉图像的前置摄像头的汽车:左视图、中间视图和右视图各一个。它还输出一个包含以下六列数据的 CSV 文件:第 1 列:中间图像的图像路径，第 2 列:左侧图像的图像路径，第 3 列:右侧图像的图像路径，第 4 列:转向角度，第 5 列:油门，第 6 列:刹车</p><p id="4051" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我在专栏 1-3 中使用了所有三张图片，因为它们提供了道路的不同视角。然而，左和右相机图像的转向角需要通过校正因子来调整，以考虑相机位置。我绘制了转向角的直方图(图 1)以探索数据的分布，并发现许多数据集中在零附近，即直线行驶。这是有意义的，因为赛道上有很多直线行驶，这将导致模型中直线行驶的偏差。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ku"><img src="../Images/14b24d4512b5720cfeff8e078f238cd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*B_hDwhDUMz8sie1KHwzbxA.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Fig 1: Histogram of Steering Angles distribution</figcaption></figure><p id="67ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第二步:处理和扩充数据</strong></p><p id="8e79" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了解决驾驶偏向直线的问题，我删除了一些接近零转向角的数据点，并使它们下降，以便分布均匀。当我绘制这些数据的直方图(图 2)时，它看起来确实更加一致。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ku"><img src="../Images/828d8efa0691c40d35c0eb9c6ba60094.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*-5YXGlhBy8nORY3nzAyyBQ.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Fig 2: Histogram of Steering Angles distribution after removing biases</figcaption></figure><p id="e49d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">图像大小为 160x320x3(图 3)。然而，顶部图像的三分之一是与模型无关的数据:地平线以上的天空和树木等。底部的 25 个像素也无关紧要，因为它有汽车的引擎盖。我裁剪了图像，去掉了这些区域，使图像尺寸缩小到 70x320x3。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lb"><img src="../Images/8eb02f7311c345a80d8b305a58b98ea0.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/0*_XnptHKLQaw3KbZJ.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Fig 3: Sample image of the input dataset</figcaption></figure><p id="168f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于树木的原因，图像中似乎有阴影，我想确保汽车可以在不同的照明条件下行驶。所以，我用随机的阴影和亮度增强来处理一些受这篇<a class="ae kl" href="https://chatbotslife.com/using-augmentation-to-mimic-human-driving-496b569760a9" rel="noopener ugc nofollow" target="_blank">帖子</a>启发的图片。随机亮度&amp;阴影增强的结果如图 4 &amp; 5 所示。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi lc"><img src="../Images/1c77bb33f6517e84ff2c985fc53216aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kTl7RFnGS2c5r6511hZXHQ.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Fig 4: Images with varying brightness</figcaption></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi lc"><img src="../Images/a8e8cbade5bfd2b3a29ae9d0a1b39c01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u6eDMp0CfFMF1fDUPMIQyQ.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Fig 5: Images with random shadows</figcaption></figure><p id="18b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">模拟器轨道也有许多左转，这些数据会导致模型偏向于向左行驶。为了解决这个问题，我将一半的图像随着转向角度翻转，以生成向右行驶的图像。现在，我相信我已经有了一个平衡的数据集，可以将模型推广到各种情况下的驾驶，图 2 中的直方图证实了这一点。</p><p id="87b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第三步:建立一个 CNN 模型</strong></p><p id="0ca2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我在这个项目中使用了<a class="ae kl" href="https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf" rel="noopener ugc nofollow" target="_blank">英伟达的 CNN 模型</a>的改编版，因为它是为自动驾驶而设计的。我用 Keras 建立了这个模型。经过实验(步骤 4)，我用 L2 正则化和 ELU 激活对模型进行了微调，得到了图 6 中的架构。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="gh gi lh"><img src="../Images/a856c683ed793cdfbbfb8d985c0b3b2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K4CbRV5jT_jn5TpG0Lv0Jg.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Fig 6: Network Architecture Details</figcaption></figure><p id="6210" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第四步:训练和微调模型</strong></p><p id="0487" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我以 85/15 的比例将输入数据集分成训练和验证数据集，并训练 CNN 模型。与<a class="ae kl" href="https://medium.com/@techreigns/traffic-signs-classification-with-a-convolutional-neural-network-75911a1904" rel="noopener">交通标志分类</a>问题不同，该项目的目标是预测转向角，这可以通过线性回归实现。我使用 Adam 优化器来获得预测转向角的最佳均方误差(MSE)值。我用 10 个历元进行训练，批量为 64 个。为了提高内存效率，我没有将预处理过的数据一次性存储在内存中，而是使用了生成器函数来提取数据片段，并根据需要动态处理它们。模型训练的结果总结以及训练和验证损失如图 7 所示。由于 AWS 的处理能力，这些训练运行非常快(大约 7 分钟)。我不认为如果这些运行需要很长时间，我会用不同的设置做很多实验，因为如果我在我的本地计算机上运行，他们会这样做。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi li"><img src="../Images/889783e4651f0b6cb2954fc4602bf7d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*UQUaSsMjh3HZ_t7m3qw93g.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Fig 7: Model training results</figcaption></figure><p id="dc05" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第五步:在模拟器上测试模型</strong></p><p id="53da" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我拿着经过训练的模型，启动模拟器来测试我的模型，看看它在自主模式下表现如何。经过多次实验，我终于能够让汽车在稳定的基础上自动驾驶。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="lj kt l"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Results Video of a car driving autonomously</figcaption></figure><p id="3b6d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">总结:</strong></p><p id="f2e0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一个非常有趣和令人兴奋的项目。从一辆会游泳的车，到一辆能在赛道上自主驾驶的车，我走过了漫长的道路。在许多领域都有改进的空间，我想在时间允许的情况下重新审视这个项目，让这个模型很好地推广到不同的赛道，在有车道的赛道上驾驶，最终在车流中驾驶。多亏了论坛、其他学生的建议和 Udacity 的资源，我能够测试许多想法，并挑选出最适合我的项目的想法。</p><p id="0521" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个项目的代码可以在我的<a class="ae kl" href="https://github.com/uppala75/CarND-Behavioral-Cloning-P3" rel="noopener ugc nofollow" target="_blank"> GitHub 库</a>中找到。</p></div></div>    
</body>
</html>