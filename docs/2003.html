<html>
<head>
<title>How to Find Wally with a Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用神经网络找到沃利</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-find-wally-neural-network-eddbb20b0b90?source=collection_archive---------1-----------------------#2017-12-02">https://towardsdatascience.com/how-to-find-wally-neural-network-eddbb20b0b90?source=collection_archive---------1-----------------------#2017-12-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="fa18" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何训练一个模型来解决沃利难题的指南</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/456260e3bdcbf9c5f7f02c54085a3710.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*KKEiafrP-Y9LqsabOkEuPA.gif"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Process of a Neural Network learning to find Wally from start to finish</figcaption></figure><p id="a611" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">深度学习提供了另一种方法来解决 Wally 在哪里的难题。但与传统的图像处理计算机视觉方法不同，它只使用少数几个带标签的例子，包括沃利在图像中的位置。</p><blockquote class="ln"><p id="785f" class="lo lp iq bd lq lr ls lt lu lv lw lm dk translated">如果神经网络可以为你做这件事，为什么还要去找沃利呢？</p></blockquote><p id="ad22" class="pw-post-body-paragraph kr ks iq kt b ku lx jr kw kx ly ju kz la lz lc ld le ma lg lh li mb lk ll lm ij bi translated">带有评估图像和检测脚本的最终训练模型发布在 my <a class="ae mc" href="https://github.com/tadejmagajna/HereIsWally" rel="noopener ugc nofollow" target="_blank"> Github repo </a>上。</p><p id="717c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这篇文章描述了使用 Tensorflow 对象检测 API 训练神经网络的过程，并使用围绕它构建的 Python 脚本来找到 Wally。它由以下步骤组成:</p><ul class=""><li id="eaf2" class="md me iq kt b ku kv kx ky la mf le mg li mh lm mi mj mk ml bi translated"><strong class="kt ir">通过创建一组带标签的训练图像准备数据集</strong>，其中标签代表 Wally 在图像中的 x-y 位置</li><li id="6da9" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated"><strong class="kt ir">获取并配置模型</strong>以与 Tensorflow 对象检测 API 一起使用</li><li id="07ff" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated">在我们的数据集上训练模型</li><li id="2168" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated"><strong class="kt ir">使用导出的图表在评估图像</strong>上测试模型</li></ul><p id="80ec" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">启动前，请确保按照<a class="ae mc" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md" rel="noopener ugc nofollow" target="_blank">说明</a>安装 Tensorflow 对象检测 API。</p><h1 id="7992" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated">准备数据集</h1><p id="5f7f" class="pw-post-body-paragraph kr ks iq kt b ku nj jr kw kx nk ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">虽然处理神经网络是深度学习中最值得注意的过程，但令人遗憾的是，数据科学家花费最多时间的步骤是准备和格式化训练数据。</p><p id="510f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最简单的机器学习问题的目标值通常是标量(如数字检测器)或分类字符串。Tensorflow 对象检测 API 训练数据使用两者的组合。它由一组图像组成，并附有所需对象的标签以及它们在图像中出现的位置。位置由两个点定义，因为(在 2d 空间中)两个点足以在对象周围绘制边界框。</p><p id="95d3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，为了创建训练集，我们需要提供一组 Wally 在哪里的拼图图片，以及 Wally 出现的位置。</p><p id="7a53" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">虽然我可以花几个星期的时间用注释工具如<a class="ae mc" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank"> LabelImg </a>手工标记图像来解决 Wally 谜题，但我发现了一个<a class="ae mc" href="https://github.com/vc1492a/Hey-Waldo" rel="noopener ugc nofollow" target="_blank">已经解决的训练集</a>Wally 谜题在哪里。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi no"><img src="../Images/4babba355479cbcb0f4f17ff2d08cafa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vlFJMBGRj-m73torNkpqSg.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Where’s Wally training dataset with last four columns describing where Wally appears in an image</figcaption></figure><p id="6148" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">准备数据集的最后一步是将标签(保存为<code class="fe nt nu nv nw b">.csv</code>)和图像(<code class="fe nt nu nv nw b">.jpeg</code>)打包成一个二进制<code class="fe nt nu nv nw b">.tfrecord</code>文件。这样做的过程在这里<a class="ae mc" href="http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/" rel="noopener ugc nofollow" target="_blank">解释</a>，但是你可以找到 train 和 eval Wally 在哪里。<code class="fe nt nu nv nw b">tfecord</code>我的<a class="ae mc" href="https://github.com/tadejmagajna/HereIsWally" rel="noopener ugc nofollow" target="_blank"> Github 回购</a>上的文件。</p><h1 id="1fdf" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated"><strong class="ak">准备模型</strong></h1><p id="1e4e" class="pw-post-body-paragraph kr ks iq kt b ku nj jr kw kx nk ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">Tensorflow 对象检测 API 提供了一组在几个公共数据集上训练的具有不同性能(通常是速度-精度权衡)的预训练模型。</p><p id="b7c4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">虽然该模型可以从随机初始化的网络权重开始从头开始训练，但这一过程可能需要数周时间。相反，我们使用了一种叫做迁移学习的方法。<br/>它包括采用一个通常被训练来解决一般问题的模型，并对其进行再训练来解决我们的问题。迁移学习背后的想法是，我们可以使用预训练模型中获得的知识，并将其转移到我们的新模型中，而不是通过从头开始训练我们的模型来重新发明轮子。这为我们节省了大量时间，因此我们可以将花在培训上的时间用于获取针对我们问题的知识。</p><p id="c635" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们使用了<a class="ae mc" href="http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2017_11_08.tar.gz" rel="noopener ugc nofollow" target="_blank"> RCNN 和在 COCO 数据集上训练的 Inception v2 模型</a>以及<a class="ae mc" href="https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/ssd_inception_v2_coco.config" rel="noopener ugc nofollow" target="_blank">它的管道配置文件</a>。该模型包括一个检查点<code class="fe nt nu nv nw b">.ckpt</code>文件，我们可以用它来开始训练。</p><blockquote class="nx ny nz"><p id="a331" class="kr ks oa kt b ku kv jr kw kx ky ju kz ob lb lc ld oc lf lg lh od lj lk ll lm ij bi translated">下载配置文件后，请确保用指向您的检查点文件、培训和评估的路径替换“PATH_TO_BE_CONFIGURED”字段。tfrecord 文件和标签映射文件。</p></blockquote><p id="5bbb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">需要配置的最后一个文件是<code class="fe nt nu nv nw b">labels.txt</code>地图文件，它包含了我们所有不同对象的标签。因为我们只寻找一种类型的对象，所以我们的标签文件看起来像这样</p><pre class="kg kh ki kj gt oe nw of og aw oh bi"><span id="6c1d" class="oi ms iq nw b gy oj ok l ol om">item {<br/>  id: 1<br/>  name: 'waldo'<br/>}</span></pre><p id="205c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后，我们应该以下列内容结束:</p><ul class=""><li id="4cb1" class="md me iq kt b ku kv kx ky la mf le mg li mh lm mi mj mk ml bi translated">带有<code class="fe nt nu nv nw b">.ckpt</code>检查点文件的预训练模型</li><li id="e3df" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated">训练和评估<code class="fe nt nu nv nw b">.tfrecord</code>数据集</li><li id="65bc" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated">标签映射文件</li><li id="46b6" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated">指向上述文件的管道配置文件</li></ul><p id="6836" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们准备开始训练。</p><h1 id="7882" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated"><strong class="ak">培训</strong></h1><p id="ee8c" class="pw-post-body-paragraph kr ks iq kt b ku nj jr kw kx nk ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">Tensorflow 对象检测 API 提供了一个简单易用的 Python 脚本来本地重新训练我们的模型。它位于<code class="fe nt nu nv nw b">models/research/object_detection</code>中，可以运行:</p><p id="2c75" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe nt nu nv nw b">python train.py --logtostderr --pipeline_config_path= PATH_TO_PIPELINE_CONFIG --train_dir=PATH_TO_TRAIN_DIR</code></p><p id="ac57" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">其中<code class="fe nt nu nv nw b">PATH_TO_PIPELINE_CONFIG</code>是我们的管道配置文件的路径，<code class="fe nt nu nv nw b">PATH_TO_TRAIN_DIR</code>是新创建的目录，我们的新检查点和模型将存储在这里。</p><p id="d5f9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe nt nu nv nw b">train.py</code>的输出应该是这样的:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi on"><img src="../Images/53c885bbbe8c23c50d8fb8b2c0fb6377.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yUn-Z_Cxxl5ApGsTMrkbHQ.png"/></div></div></figure><p id="2d03" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">寻找最重要的信息是损失。它是训练集或验证集中每个例子的错误总和。当然，您希望它尽可能低，这意味着如果它缓慢下降，这意味着您的模型正在学习(…或过度拟合您的训练数据)。</p><p id="3e05" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">还可以使用 Tensorboard 更详细地显示训练数据。</p><p id="05fc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">该脚本会在完成一定数量的步骤后自动存储一个检查点文件，这样您就可以在学习时随时恢复您保存的检查点，以防您的计算机崩溃。</p><p id="769f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这意味着当您想要完成模型的训练时，您可以终止脚本。</p><p id="ff26" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">但是什么时候停止学习呢？</strong>关于何时停止训练的一般规则是当我们的评估集上的损失停止减少或通常非常低时(在我们的示例中低于 0.01)。</p><h1 id="cdec" class="mr ms iq bd mt mu mv mw mx my mz na nb jw nc jx nd jz ne ka nf kc ng kd nh ni bi translated">测试</h1><p id="f0cb" class="pw-post-body-paragraph kr ks iq kt b ku nj jr kw kx nk ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">现在，我们可以通过在一些示例图像上测试来实际使用我们的模型。</p><p id="a31c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，我们需要使用<code class="fe nt nu nv nw b">models/research/object_detection</code>中的脚本从存储的检查点(位于我们的火车目录中)导出一个推理图:</p><pre class="kg kh ki kj gt oe nw of og aw oh bi"><span id="3e7b" class="oi ms iq nw b gy oj ok l ol om">python export_inference_graph.py — pipeline_config_path PATH_TO_PIPELINE_CONFIG --trained_checkpoint_prefix PATH_TO_CHECPOINT --output_directory OUTPUT_PATH</span></pre><p id="9082" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">导出的推理图现在是我们的 Python 脚本可以用来查找 Wally 的。</p><p id="e9b6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我写了几个简单的 Python 脚本(基于 Tensorflow 对象检测 API ),您可以使用它们在您的模型上执行对象检测，并在检测到的对象周围绘制框或暴露它们。</p><p id="84c8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe nt nu nv nw b"><a class="ae mc" href="https://github.com/tadejmagajna/HereIsWally/blob/master/find_wally.py" rel="noopener ugc nofollow" target="_blank">find_wally.py</a></code>和<code class="fe nt nu nv nw b"><a class="ae mc" href="https://github.com/tadejmagajna/HereIsWally/blob/master/find_wally_pretty.py" rel="noopener ugc nofollow" target="_blank">find_wally_pretty.py</a></code>都可以在我的<a class="ae mc" href="https://github.com/tadejmagajna/HereIsWally" rel="noopener ugc nofollow" target="_blank"> Github repo </a>中找到，并且可以简单地运行</p><pre class="kg kh ki kj gt oe nw of og aw oh bi"><span id="3441" class="oi ms iq nw b gy oj ok l ol om">python find_wally.py</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi oo"><img src="../Images/3c17d6adb6b58b15f70018e5f2b668f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BrMnX72P2kqBJ5qMJMCEpw.png"/></div></div></figure><p id="b988" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">或者</p><pre class="kg kh ki kj gt oe nw of og aw oh bi"><span id="bf4a" class="oi ms iq nw b gy oj ok l ol om">python find_wally_pretty.py</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="np nq di nr bf ns"><div class="gh gi op"><img src="../Images/9d05ba61df8350cb3779f50cc8b882c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5T5SY-UWeR2ZraIUmA6tEA.png"/></div></div></figure><p id="a3f3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在您自己的模型或评估图像上使用脚本时，请确保修改<code class="fe nt nu nv nw b">model_path</code>和<code class="fe nt nu nv nw b">image_path</code>变量。</p></div><div class="ab cl oq or hu os" role="separator"><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov ow"/><span class="ot bw bk ou ov"/></div><div class="ij ik il im in"><h1 id="ac5e" class="mr ms iq bd mt mu ox mw mx my oy na nb jw oz jx nd jz pa ka nf kc pb kd nh ni bi translated">最后的想法</h1><p id="1ab1" class="pw-post-body-paragraph kr ks iq kt b ku nj jr kw kx nk ju kz la nl lc ld le nm lg lh li nn lk ll lm ij bi translated">在我的<a class="ae mc" href="https://github.com/tadejmagajna/HereIsWally" rel="noopener ugc nofollow" target="_blank"> Github repo </a>上发布的模型表现得出奇的好。</p><p id="1f63" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">它设法在评估图片中找到了 Wally，并在网上找到了一些额外的随机例子。它没能在沃利真正大的地方找到他，凭直觉这应该比在他真正小的地方找到他更容易解决。这表明我们的模型可能过度拟合我们的训练数据，主要是因为只使用了少量的训练图像。</p><p id="323e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">任何希望通过手动标记一些来自网络的额外图片来提高模型性能的人，都可以在我的<a class="ae mc" href="https://github.com/tadejmagajna/HereIsWally" rel="noopener ugc nofollow" target="_blank"> Github repo </a>上提交 PR，并帮助改进训练集。</p></div></div>    
</body>
</html>