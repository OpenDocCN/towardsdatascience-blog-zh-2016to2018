<html>
<head>
<title>R-CNN, Fast R-CNN, Faster R-CNN, YOLO — Object Detection Algorithms</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">R-CNN，快速 R-CNN，更快 R-CNN，YOLO —目标检测算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e?source=collection_archive---------1-----------------------#2018-07-09">https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e?source=collection_archive---------1-----------------------#2018-07-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="54c2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解对象检测算法</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/542220003fbf2158b7a4c4c5a6bfee7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PpYSe5EbqFtAEfVVEOAMlg.jpeg"/></div></div></figure><h1 id="0b59" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">介绍</h1><p id="31ce" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">计算机视觉是一个跨学科领域，近年来(自 CNN 以来)获得了巨大的牵引力，自动驾驶汽车占据了中心舞台。计算机视觉的另一个组成部分是对象检测。目标检测有助于姿态估计、车辆检测、监视等。对象检测算法和分类算法之间的区别在于，在检测算法中，我们试图在感兴趣的对象周围绘制一个边界框，以在图像中定位它。此外，在对象检测情况下，您可能不一定只绘制一个边界框，可能有许多边界框表示图像中感兴趣的不同对象，并且您事先不知道有多少个边界框。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mf"><img src="../Images/2d8f5c9e6e694e73801d05b699202fc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*95lJePt-70PH3PoVfz2yYQ.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mg"><img src="../Images/4ed19047adad1e20cc06d4e49463c5c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tqbGt2zj-9OP_rjR57r8Zg.png"/></div></div></figure><p id="9c49" class="pw-post-body-paragraph lj lk iq ll b lm mh jr lo lp mi ju lr ls mj lu lv lw mk ly lz ma ml mc md me ij bi translated">您无法通过构建一个标准卷积网络，然后构建一个全连接层来解决这个问题的主要原因是，输出层的长度是可变的，而不是恒定的，这是因为感兴趣对象的出现次数是不固定的。解决这个问题的简单方法是从图像中提取不同的感兴趣区域，并使用 CNN 对该区域中物体的存在进行分类。这种方法的问题是感兴趣的对象在图像中可能具有不同的空间位置和不同的纵横比。因此，你将不得不选择大量的区域，这可能会在计算上爆炸。因此，像 R-CNN、YOLO 等算法已经被开发来寻找这些事件并快速找到它们。</p><h1 id="bbfe" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">R-CNN</h1><p id="bb92" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">为了绕过选择大量区域的问题，<a class="ae mm" href="https://arxiv.org/pdf/1311.2524.pdf" rel="noopener ugc nofollow" target="_blank"> Ross Girshick 等人</a>。提出了一种方法，我们使用选择性搜索从图像中提取 2000 个区域，他称之为区域建议。因此，现在，你可以只处理 2000 个区域，而不是试图对大量的区域进行分类。这 2000 个区域建议是使用下面写的选择性搜索算法生成的。</p><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="ab9e" class="ms ks iq mo b gy mt mu l mv mw">Selective Search:<br/>1. Generate initial sub-segmentation, we generate many candidate     regions<br/>2. Use greedy algorithm to recursively combine similar regions into larger ones <br/>3. Use the generated regions to produce the final candidate region proposals </span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mx"><img src="../Images/55a15130fecc68e8e0791f318e213f5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*REPHY47zAyzgbNKC6zlvBQ.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">R-CNN</figcaption></figure><p id="f356" class="pw-post-body-paragraph lj lk iq ll b lm mh jr lo lp mi ju lr ls mj lu lv lw mk ly lz ma ml mc md me ij bi translated">要了解更多关于选择性搜索算法的信息，请点击此<a class="ae mm" href="https://ivi.fnwi.uva.nl/isis/publications/2013/UijlingsIJCV2013/UijlingsIJCV2013.pdf" rel="noopener ugc nofollow" target="_blank">链接</a>。这 2000 个候选区域提议被扭曲成正方形，并被馈送到卷积神经网络，该网络产生 4096 维特征向量作为输出。CNN 充当特征提取器，输出密集层由从图像中提取的特征组成，提取的特征被馈送到<a class="ae mm" rel="noopener" target="_blank" href="/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47"> SVM </a>中，以对候选区域提议中的对象的存在进行分类。除了预测区域提议内对象的存在之外，该算法还预测四个偏移值，以提高边界框的精度。例如，给定一个区域提议，该算法将预测到一个人的存在，但是该区域提议中的那个人的脸可能已经被切成两半。因此，偏移值有助于调整区域提议的边界框。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/aced0f78dde4ce3d142c7a648396a57e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*NX5yYTi-eQjP0pMWs3UbUg.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk">R-CNN</figcaption></figure><h2 id="f965" class="ms ks iq bd kt nd ne dn kx nf ng dp lb ls nh ni ld lw nj nk lf ma nl nm lh nn bi translated">R-CNN 的问题</h2><ul class=""><li id="e8fe" class="no np iq ll b lm ln lp lq ls nq lw nr ma ns me nt nu nv nw bi translated">训练网络仍然需要大量的时间，因为你必须对每幅图像的 2000 个区域提议进行分类。</li><li id="d227" class="no np iq ll b lm nx lp ny ls nz lw oa ma ob me nt nu nv nw bi translated">它不能实时实现，因为每个测试图像需要大约 47 秒。</li><li id="a31a" class="no np iq ll b lm nx lp ny ls nz lw oa ma ob me nt nu nv nw bi translated">选择性搜索算法是一种固定算法。因此，在那个阶段没有学习发生。这可能导致产生坏的候选区域提议。</li></ul><h1 id="7143" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">快速 R-CNN</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/19a5bea6053335915b8591c7baebaa5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0pMP3aY8blSpva5tvWbnKA.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">Fast R-CNN</figcaption></figure><p id="bd0d" class="pw-post-body-paragraph lj lk iq ll b lm mh jr lo lp mi ju lr ls mj lu lv lw mk ly lz ma ml mc md me ij bi translated">前一篇论文(R-CNN)的同一作者解决了 R-CNN 的一些缺点，以建立更快的对象检测算法，它被称为快速 R-CNN。该方法类似于 R-CNN 算法。但是，我们不是将区域建议提供给 CNN，而是将输入图像提供给 CNN，以生成卷积特征图。从卷积特征图中，我们确定建议的区域，并将其扭曲成正方形，通过使用 RoI 池层，我们将它们重新调整为固定大小，以便可以将其输入到完全连接的层。根据 RoI 特征向量，我们使用 softmax 层来预测建议区域的类别以及边界框的偏移值。</p><p id="aa6c" class="pw-post-body-paragraph lj lk iq ll b lm mh jr lo lp mi ju lr ls mj lu lv lw mk ly lz ma ml mc md me ij bi translated">“快速 R-CNN”比 R-CNN 更快的原因是，你不必每次都向卷积神经网络馈送 2000 个区域提议。相反，每个图像只进行一次卷积运算，并从中生成特征图。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/5e94026f1f87efc7ff0fbfc12166f53f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m2QO_wbUPA05mY2q4v7mjg.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">Comparison of object detection algorithms</figcaption></figure><p id="cc91" class="pw-post-body-paragraph lj lk iq ll b lm mh jr lo lp mi ju lr ls mj lu lv lw mk ly lz ma ml mc md me ij bi translated">从上面的图表中，您可以推断出快速 R-CNN 在训练和测试会话中明显快于 R-CNN。当您在测试期间查看快速 R-CNN 的性能时，与不使用区域建议相比，包含区域建议会显著降低算法的速度。因此，区域建议成为影响快速 R-CNN 算法性能的瓶颈。</p><h1 id="2927" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">更快的 R-CNN</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/5883bce30189793a303558ab2070515b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pSnVmJCyQIRKHDPt3cfnXA.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">Faster R-CNN</figcaption></figure><p id="2fb1" class="pw-post-body-paragraph lj lk iq ll b lm mh jr lo lp mi ju lr ls mj lu lv lw mk ly lz ma ml mc md me ij bi translated">上述两种算法(R-CNN 和快速 R-CNN)都使用选择性搜索来找出区域建议。选择性搜索是一个缓慢而耗时的过程，会影响网络的性能。因此，<a class="ae mm" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank">任等人</a>。提出了一种对象检测算法，消除了选择性搜索算法，并让网络学习区域建议。</p><p id="25de" class="pw-post-body-paragraph lj lk iq ll b lm mh jr lo lp mi ju lr ls mj lu lv lw mk ly lz ma ml mc md me ij bi translated">类似于快速 R-CNN，图像作为输入被提供给卷积网络，该网络提供卷积特征图。不是在特征图上使用选择性搜索算法来识别区域提议，而是使用单独的网络来预测区域提议。然后，使用 RoI 池层对预测的区域提议进行整形，然后使用 RoI 池层对提议区域内的图像进行分类，并预测边界框的偏移值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/345bfdbb61a737f45fce3d728d7183cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4gGddZpKeNIPBoVxYECd5w.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">Comparison of test-time speed of object detection algorithms</figcaption></figure><p id="09ae" class="pw-post-body-paragraph lj lk iq ll b lm mh jr lo lp mi ju lr ls mj lu lv lw mk ly lz ma ml mc md me ij bi translated">从上面的图表中，你可以看到更快的 R-CNN 比它的前辈快得多。因此，它甚至可以用于实时物体检测。</p><h1 id="acab" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">YOLO——你只能看一次</h1><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure><p id="0585" class="pw-post-body-paragraph lj lk iq ll b lm mh jr lo lp mi ju lr ls mj lu lv lw mk ly lz ma ml mc md me ij bi translated">所有先前的对象检测算法都使用区域来定位图像中的对象。网络不会看到完整的图像。取而代之的是图像中包含物体的概率较高的部分。YOLO 或你只看一次是一个对象检测算法，与上面看到的基于区域的算法有很大不同。在 YOLO，单个卷积网络预测边界框和这些框的类别概率。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oi"><img src="../Images/f70489b3ab4175a48eb46e2d517f6cf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JniWRt-ceWLNlkOULjhdpg.png"/></div></div><figcaption class="my mz gj gh gi na nb bd b be z dk">YOLO</figcaption></figure><p id="71cd" class="pw-post-body-paragraph lj lk iq ll b lm mh jr lo lp mi ju lr ls mj lu lv lw mk ly lz ma ml mc md me ij bi translated">YOLO 的工作原理是，我们把一幅图像分割成一个 SxS 网格，在每个网格中我们取 m 个边界框。对于每个边界框，网络输出该边界框的类概率和偏移值。具有高于阈值的分类概率的边界框被选择并用于定位图像内的对象。</p><p id="533c" class="pw-post-body-paragraph lj lk iq ll b lm mh jr lo lp mi ju lr ls mj lu lv lw mk ly lz ma ml mc md me ij bi translated">YOLO 比其他物体检测算法快几个数量级(每秒 45 帧)。YOLO 算法的局限性在于它会与图像中的小对象进行斗争，例如它可能难以检测到一群鸟。这是由于算法的空间限制。</p><h1 id="b8ce" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">结论</h1><p id="d0ec" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">计算机视觉会议每年都在观察新的激进概念，我想我们正一步一步地走向人工智能令人瞠目结舌的表现(如果还没有的话！).只会变得更好。我希望这些概念在这篇文章中变得清晰，谢谢:)</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oj oh l"/></div></figure><h1 id="ee0e" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">参考</h1><ol class=""><li id="56ad" class="no np iq ll b lm ln lp lq ls nq lw nr ma ns me ok nu nv nw bi translated">https://arxiv.org/pdf/1311.2524.pdf<a class="ae mm" href="https://arxiv.org/pdf/1311.2524.pdf" rel="noopener ugc nofollow" target="_blank"/></li><li id="b51a" class="no np iq ll b lm nx lp ny ls nz lw oa ma ob me ok nu nv nw bi translated">【https://arxiv.org/pdf/1504.08083.pdf T4】</li><li id="3ea0" class="no np iq ll b lm nx lp ny ls nz lw oa ma ob me ok nu nv nw bi translated"><a class="ae mm" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1506.01497.pdf</a></li><li id="0fe3" class="no np iq ll b lm nx lp ny ls nz lw oa ma ob me ok nu nv nw bi translated"><a class="ae mm" href="https://arxiv.org/pdf/1506.02640v5.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1506.02640v5.pdf</a></li><li id="b31a" class="no np iq ll b lm nx lp ny ls nz lw oa ma ob me ok nu nv nw bi translated"><a class="ae mm" href="http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture11.pdf" rel="noopener ugc nofollow" target="_blank">http://cs 231n . Stanford . edu/slides/2017/cs 231n _ 2017 _ lecture 11 . pdf</a></li></ol></div></div>    
</body>
</html>