<html>
<head>
<title>Classification Techniques On Life Expectancy Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预期寿命数据的分类技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/classification-techniques-on-life-expectancy-data-118e6f22a877?source=collection_archive---------15-----------------------#2018-08-07">https://towardsdatascience.com/classification-techniques-on-life-expectancy-data-118e6f22a877?source=collection_archive---------15-----------------------#2018-08-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="bfe4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">大陆分类法</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/aa55eca7738c8fc0a4e39e20277fe765.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RT9utVAErFARy3Td"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@chuttersnap?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">chuttersnap</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="d4f9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们人类被赋予了分类的概念。我们对所有东西进行分类，从衣柜里所有的牛仔裤放在一个架子下，所有的衬衫放在另一个专为衬衫准备的架子上，到手机上的应用程序和电脑上的文件，每种文件或应用程序都有单独的文件夹。</p><p id="560f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，分类的一个更“数据科学”的定义是，它是一种数据分析形式，提取描述重要数据类别的模型或预测分类变量(类别或目标)值的任务。基本上，找出一个新的观察将属于哪一组预定义的类别。一个非常常见的例子是，我们希望将某些邮件归类为垃圾邮件，而将其他邮件归类为非垃圾邮件。机器能够通过从已知类别的训练数据中学习来完成这项任务。</p><p id="7c51" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">只有当我们有离散标签作为输出时，才能使用分类算法。像上面的例子中，电子邮件是否被分类为垃圾邮件，只有两种可能的结果，这种情况被称为二元分类。</p><p id="cbdf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一种类型是多标签分类。在多标签分类中，可以将多个标签分配给一个实例。这主要用于音视频分类、文本分类、情感分析中的情感分类等。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="a01e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">无论如何，这是继续阅读本文所需的基础知识和先决条件。</p><p id="512b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文中，我们将对各大洲进行分类，这是标签，将在<a class="ae kv" href="https://www.kaggle.com/amansaxena/lifeexpectancy" rel="noopener ugc nofollow" target="_blank">预期寿命数据集</a>中用作一个类别。</p><p id="12fa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是一个非常小的数据集，有 6 列 223 行，每个国家一行。栏目分别是排名、国家、整体生活、男性生活、女性生活和大洲。</p><p id="db64" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了执行这种分类，我们将使用 5 种不同的分类技术和算法，计算每种算法的精确度和准确度，并对它们进行比较。这 5 种分类算法是:</p><ul class=""><li id="01be" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated"><strong class="ky ir"> KNN </strong> — K 近邻算法使用类似距离函数(distance measures)的相似性度量对经过训练后的新数据点进行分类。</li><li id="5eee" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated"><strong class="ky ir"> SVM </strong> —支持向量机是一种监督学习算法，它将创建一个模型，使用训练集将新的点分配到一个或另一个类别。根据问题，分配可以是线性的或非线性的。</li><li id="a1af" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated"><strong class="ky ir"> OneR </strong> — OneR 基本上是一个规则算法，这个算法为数据中的每个预测器生成一个规则，然后选择误差最小的规则作为答案。尽管这看起来是一个非常简单的算法，因为它只生成一个规则，但它比一些更复杂的分类算法执行得更好。</li><li id="9b31" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated"><strong class="ky ir"> RIPPER </strong> —RIPPER 是一个基于规则的学习器，它建立了一套识别类的规则，同时最小化了错误的数量。误差由被规则错误分类的训练样本的数量来定义。这是执行基于规则的分类的直接方式。</li><li id="79a2" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated"><strong class="ky ir"> C 4.5 </strong> — C4.5 是一个统计分类器，因为它生成决策树。它像 ID3 一样从训练数据中构建决策树，并在树的每个节点上选择数据的属性，该属性最有效地将其样本集分成富含一个类或另一个类的子集。这是一种间接的基于规则的分类方法。</li></ul></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="6a0f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在让我们从使用 R 编程的分析开始，让我们看看哪个分类器执行得最好。</p><p id="7271" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将在整个代码中使用以下库/包:e1071、class、caret、rJava、RWeka。</p><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="4fdb" class="ms mt iq mo b gy mu mv l mw mx">#loading libraries<br/>library("e1071")<br/>library(class)<br/>library(caret)<br/>library(rJava)<br/>library(RWeka)</span></pre><h1 id="3e0c" class="my mt iq bd mz na nb nc nd ne nf ng nh jw ni jx nj jz nk ka nl kc nm kd nn no bi translated">数据预处理</h1><ol class=""><li id="deec" class="lz ma iq ky b kz np lc nq lf nr lj ns ln nt lr nu mf mg mh bi translated">数据预处理的第一步包括以下内容:</li></ol><ul class=""><li id="fc4b" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated">使用<em class="nv"> read.csv() </em>函数导入 R 中的数据集。</li><li id="6e25" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">通过查看数据集执行一些可视化的描述性分析，并使用<em class="nv"> summary()和 str() </em>函数获得数据集的摘要。</li><li id="2505" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">通过分解将类别标签 continental 转换为分类变量。</li><li id="37a3" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">一些不相关的列也将被删除，这些列不会在分析中使用。像第一个，秩列。</li></ul><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="c3cf" class="ms mt iq mo b gy mu mv l mw mx">#importing csv file in R<br/>dataset &lt;- read.csv(file.choose())</span><span id="a982" class="ms mt iq mo b gy nw mv l mw mx">#displaying head(first five) elements<br/>head(dataset) <br/>str(dataset)<br/>#dimentions<br/>dim(dataset) </span><span id="61f5" class="ms mt iq mo b gy nw mv l mw mx">#Converting Continent to factor<br/>dataset[c("Continent")]&lt;- lapply(dataset[c("Continent")], factor)</span><span id="9ac2" class="ms mt iq mo b gy nw mv l mw mx">#removing the first (irrelevant) coulmn<br/>dataset &lt;- dataset[,-1]</span><span id="155f" class="ms mt iq mo b gy nw mv l mw mx">str(dataset)<br/>summary(dataset)</span></pre><p id="526b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">输出</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/42d7795890df826957f534d21415f5eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*43DFFKJd2UKCPQ9PKmZXlA.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">head(), str(), dim() functions</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/8bf78f78d1d1cd325686426ae1e5568c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kMMQUxynudu6EDnI5NQ5wQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">str(), summary() functions after the removal of the first column and the factor converstion</figcaption></figure><p id="1d9b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">观察</strong></p><p id="a11f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">尽管 Continent 列已经是 factor 数据类型，但我们仍然运行命令使其成为 factor。有了这个数据视图，我们可以清楚地了解数据的样子，<em class="nv"> head() </em>函数可以做到这一点。汇总函数向我们展示了一些重要的描述性信息。最重要的是，我们可以看到有多少国家位于哪个洲，这将有助于我们以后检查准确性。我们还可以观察整体、男性和女性预期寿命的均值，分别为 72.49、70.04 和 75.02。还可以观察中间值、四分位数、混合值和最大值。</p><p id="efbe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2.对于数据预处理的第二部分，我们将:</p><ul class=""><li id="830e" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated">通过使用样本方法生成训练和测试元素的随机排列，将数据集以 80:20 的比例划分为训练集和测试集。</li><li id="881e" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">将训练和测试样本保存在输出变量的列表中。</li><li id="d100" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">我们可以通过打印输出变量来查看训练和测试样本。</li></ul><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="1de1" class="ms mt iq mo b gy mu mv l mw mx">#sampling 80% training data<br/>traindata &lt;- sample(seq_len(nrow(dataset)), size = floor(0.80 * nrow(dataset)))<br/>data_train &lt;- dataset[traindata, ]<br/>data_test &lt;- dataset[-traindata,]<br/>t_train &lt;- dataset$Continent[traindata]<br/>t_test &lt;- dataset$Continent[-traindata]</span><span id="5978" class="ms mt iq mo b gy nw mv l mw mx">output&lt;-list(data_train,data_test,t_train,t_test)</span><span id="a0a1" class="ms mt iq mo b gy nw mv l mw mx">#a view of the devided data(into train and test)<br/>print(output)</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="119e" class="my mt iq bd mz na nz nc nd ne oa ng nh jw ob jx nj jz oc ka nl kc od kd nn no bi translated">KNN-K 最近邻算法</h1><p id="b9c2" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf oe lh li lj of ll lm ln og lp lq lr ij bi translated">KNN 分类将在预处理和训练方法的帮助下执行，可在 caret 包中获得。训练方法中的隧道长度将根据拟合模型结果选择为 20，这将帮助我们自动选择最佳值。</p><p id="55fa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们的例子中，K 被选择为 5。此外，精确度用于选择使用最大值的最佳模型。</p><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="a4bb" class="ms mt iq mo b gy mu mv l mw mx">#KNN</span><span id="4595" class="ms mt iq mo b gy nw mv l mw mx">#setting seed<br/>set.seed(12345)</span><span id="3cdb" class="ms mt iq mo b gy nw mv l mw mx">knn_train_test&lt;-output<br/>let_train&lt;-knn_train_test[[1]]<br/>let_test&lt;-knn_train_test[[2]]</span><span id="6122" class="ms mt iq mo b gy nw mv l mw mx">#Preprocessing and training<br/>trainX &lt;- let_train[,names(let_train) != "Continent"]<br/>preProcValues &lt;- preProcess(x = trainX,method = c("center", "scale"))<br/>print(preProcValues)</span><span id="332c" class="ms mt iq mo b gy nw mv l mw mx">#Fit Model- Using Caret's train model to find best k<br/>ctrl &lt;- trainControl(method="repeatedcv",repeats = 3)<br/>knnFit &lt;- train(Continent~., data = let_train, method = "knn", <br/>                trControl = ctrl,preProcess = c("center","scale"), <br/>                tuneLength = 20)<br/>print(knnFit)<br/>plot(knnFit)</span><span id="be38" class="ms mt iq mo b gy nw mv l mw mx">#Make predictions<br/>knnPredict &lt;- predict(knnFit,newdata = let_test )<br/>knnPredict</span><span id="f551" class="ms mt iq mo b gy nw mv l mw mx">#Confusion Matrix<br/>confusionMatrix(knnPredict, let_test$Continent )</span><span id="eb0a" class="ms mt iq mo b gy nw mv l mw mx">#Accuracy<br/>knnoutput&lt;-mean(knnPredict== let_test$Continent)<br/>knnoutput</span></pre><p id="a6e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">输出</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/59a3d313dedfa75a5ed4dd70ac406697.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*NTMumJCXmQfzAaSLehM1fw.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">preprocessing using the caret package and finding the knn fit i.e. value of K</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/bed6a098f1bb321c906bc1710911cadf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*9bYtB2rK5eaTZt8NiTErSQ.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">plot depicting the choice of the value of K by using accuracy</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/a2ed1dbee032098354ca737f8df7e633.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/1*pM9QDp8xjM6aXy4XNgEx3A.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">prediction, confusion matrix and accuracy</figcaption></figure><p id="82f9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">观察</strong></p><ul class=""><li id="7824" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated">首先，我们观察到，通过查看最高精度(通过重复交叉验证)，K 的最佳值被选择为 5。</li><li id="3fd3" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">该图还显示 K=5 时的最高精度值为 0.562，K=17 时的精度为 0.559。</li><li id="0860" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">KNN 的<strong class="ky ir">准确率是 44%。</strong></li></ul></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="0f44" class="my mt iq bd mz na nz nc nd ne oa ng nh jw ob jx nj jz oc ka nl kc od kd nn no bi translated">SVM —支持向量机</h1><p id="3b0e" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf oe lh li lj of ll lm ln og lp lq lr ij bi translated">SVM 分类功能将借助调整方法并使用 e1071 软件包进行部署。通过从调整方法中选择核为线性且成本为 1 来调整 svm 拟合分类。</p><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="e36d" class="ms mt iq mo b gy mu mv l mw mx">#SVM </span><span id="863e" class="ms mt iq mo b gy nw mv l mw mx">#setting seed<br/>set.seed(12345)</span><span id="20a7" class="ms mt iq mo b gy nw mv l mw mx">train_test&lt;- output<br/>let_train&lt;-train_test[[1]]<br/>let_test&lt;-train_test[[2]]</span><span id="bbfd" class="ms mt iq mo b gy nw mv l mw mx">#Fit model<br/>svmfit &lt;- svm(Continent ~., data = let_train, kernel = "linear", scale = FALSE)<br/>svmfit<br/>svm</span><span id="8a73" class="ms mt iq mo b gy nw mv l mw mx">#Tune to check best performance<br/>tuned &lt;- tune(svm, Continent ~., data = let_train, kernel = "linear", ranges = list(cost=c(0.001,0.01,.1,1,10,100)))<br/>summary(tuned)</span><span id="a3a2" class="ms mt iq mo b gy nw mv l mw mx">#Make predictions<br/>p &lt;- predict(svmfit, let_test, type="class")<br/>length(let_test$Continent)<br/>table(p, let_test$Continent)</span><span id="5b93" class="ms mt iq mo b gy nw mv l mw mx">#Analyse results<br/>#Confusion matrix<br/>confusionMatrix(p, let_test$Continent )</span><span id="524d" class="ms mt iq mo b gy nw mv l mw mx">#Accuracy<br/>#print(mean(p== let_test$Continent))<br/>svmoutput&lt;-mean(p== let_test$Continent)<br/>svmoutput</span></pre><p id="ea11" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">输出</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/1dc18be699514c32f8708099c21dd0f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*IID2SQPONoSNdQGU2fRlXA.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">fitting the model using svmfit()</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/2ca0efd4f737b6b2cf4fcf16dad534b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*VF0zwMrzS0Rl9PsM8V4z4w.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">tuning to check for the best performance and predicting the classes</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/b2a0ebae050b9a1e2e823a3db50daa52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*qOqEYrm4SxdBhtGExtw49A.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">creating the confusion matrix and calculating the accuracy</figcaption></figure><p id="d2df" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">观察</strong></p><ul class=""><li id="63e5" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated">我们观察到 SVM 的准确率为 55%</li></ul></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="853d" class="my mt iq bd mz na nz nc nd ne oa ng nh jw ob jx nj jz oc ka nl kc od kd nn no bi translated"><strong class="ak"> OneR —一个规则算法</strong></h1><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="1328" class="ms mt iq mo b gy mu mv l mw mx">#OneR</span><span id="413f" class="ms mt iq mo b gy nw mv l mw mx">#setting seed<br/>set.seed(12345)</span><span id="f2f5" class="ms mt iq mo b gy nw mv l mw mx">oner_train_test&lt;- output<br/>let_train&lt;-oner_train_test[[1]]<br/>let_test&lt;-oner_train_test[[2]]</span><span id="d58d" class="ms mt iq mo b gy nw mv l mw mx">#Fitting model<br/>model &lt;- OneR(Continent~.,let_train)<br/>model</span><span id="6287" class="ms mt iq mo b gy nw mv l mw mx">#prediction<br/>pred &lt;- predict(model, let_test)<br/>pred</span><span id="2971" class="ms mt iq mo b gy nw mv l mw mx">table(pred,let_test$Continent)<br/>summary(model)</span><span id="9e58" class="ms mt iq mo b gy nw mv l mw mx">#confusion matrix <br/>confusionMatrix(pred, let_test$Continent)</span><span id="002c" class="ms mt iq mo b gy nw mv l mw mx">#Accuracy<br/>acc&lt;-mean(pred==let_test$Continent)<br/>acc</span></pre><p id="d1a1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">输出</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/541c08294d528ef7ca200ff69ef0926e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nqy-uy3K4K49cS27EyjizQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">model 1/2</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/9f3a93ed26f895f6d0a8cf4de6d2d8cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3SIBsI2lyhT0Rr64Kfdxjg.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">model 2/2</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/8f3bb4cb3ecbc8be737eff7da9c5a3d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*Tx1YnJB6La-ZwCCmUgjVBA.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">prediction() function, table and summary of the model</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/1fc5e2a4f56dc1bc8b4a0ff8da978bb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*ATu9S4Qx4EE6NNHSXbGpiQ.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">confusion matrix and accuracy</figcaption></figure><p id="820e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">观察</strong></p><ul class=""><li id="cb84" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated">我们观察了使用训练数据映射的 178 个实例的建模。</li><li id="4129" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">当使用测试数据进行预测时，只有 38 个正确分类的实例，而 140 个错误分类的实例，因为非洲被作为一个规则。</li><li id="2605" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">这使得 OneR 算法的<strong class="ky ir">准确率只有 20%。</strong></li></ul></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="9c75" class="my mt iq bd mz na nz nc nd ne oa ng nh jw ob jx nj jz oc ka nl kc od kd nn no bi translated">RIPPER —重复增量修剪以产生误差减少算法</h1><p id="5e21" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf oe lh li lj of ll lm ln og lp lq lr ij bi translated">Ripper 分类功能将借助 RWeka 包中的 JRip 方法进行部署。</p><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="6f51" class="ms mt iq mo b gy mu mv l mw mx">#RIPPER Algorithm</span><span id="b8a3" class="ms mt iq mo b gy nw mv l mw mx">#setting seed<br/>set.seed(12345)</span><span id="7a87" class="ms mt iq mo b gy nw mv l mw mx">ripper_train_test&lt;- output<br/>let_train&lt;-ripper_train_test[[1]]<br/>let_test&lt;-ripper_train_test[[2]]</span><span id="8eb5" class="ms mt iq mo b gy nw mv l mw mx">#fitting model using Weka control function of JRip<br/>model1 &lt;- JRip(Continent~., data=let_train) <br/>model1</span><span id="d6c3" class="ms mt iq mo b gy nw mv l mw mx">#prediction<br/>pred1 &lt;- predict(model1, let_test)<br/>pred1</span><span id="a2c5" class="ms mt iq mo b gy nw mv l mw mx">table(pred1, let_test$Continent)<br/>summary(model1)</span><span id="de99" class="ms mt iq mo b gy nw mv l mw mx">#confusion matrix<br/>confusionMatrix(pred1, let_test$Continent)</span><span id="3576" class="ms mt iq mo b gy nw mv l mw mx">#Accuracy<br/>acc&lt;-mean(pred1==let_test$Continent)<br/>acc</span></pre><p id="995d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">输出</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi or"><img src="../Images/60a6e2025948f27c0efff87451a815ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lstGwR-ONxFojeV0QG8Keg.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">modeling, prediction, tabulation of the prediction and summary</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi os"><img src="../Images/904d4eedb6e8bb2cf0d1576a9f5a7897.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*QL9PxRle2ruA9zgiAK6IYQ.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">confusion matrix and accuracy</figcaption></figure><p id="79ac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">观察</strong></p><ul class=""><li id="d473" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated">当使用测试数据进行预测时，95 个实例被正确分类，而 83 个被错误分类。</li><li id="649c" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">混乱矩阵清楚地显示了哪个大陆被归类为什么。</li><li id="8e52" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated"><strong class="ky ir">使用 RIPPER 算法可以观察到 48%的精度</strong>。</li></ul></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="a938" class="my mt iq bd mz na nz nc nd ne oa ng nh jw ob jx nj jz oc ka nl kc od kd nn no bi translated">C 4.5 算法</h1><p id="6387" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf oe lh li lj of ll lm ln og lp lq lr ij bi translated">借助 RWeka 包中的 J48 方法部署了 C4.5 分类功能。</p><pre class="kg kh ki kj gt mn mo mp mq aw mr bi"><span id="4d85" class="ms mt iq mo b gy mu mv l mw mx">#C.45 Algorithm</span><span id="9c11" class="ms mt iq mo b gy nw mv l mw mx">#setting seed<br/>set.seed(12345)</span><span id="fcd2" class="ms mt iq mo b gy nw mv l mw mx">c45_train_test&lt;- output<br/>let_train&lt;-c45_train_test[[1]]<br/>let_test&lt;-c45_train_test[[2]]</span><span id="006d" class="ms mt iq mo b gy nw mv l mw mx"># fit model-Using Weka Control function of J48<br/>fit &lt;- J48(Continent~., data=let_train)</span><span id="0f77" class="ms mt iq mo b gy nw mv l mw mx"># summarize the fit<br/>summary(fit)</span><span id="de25" class="ms mt iq mo b gy nw mv l mw mx"># make predictions<br/>c45predictions &lt;- predict(fit, let_test)</span><span id="9138" class="ms mt iq mo b gy nw mv l mw mx"># summarize accuracy<br/>tb&lt;-table(c45predictions, let_test$Continent)</span><span id="0523" class="ms mt iq mo b gy nw mv l mw mx">#Confusion Matrix<br/>confusionMatrix(c45predictions, let_test$Continent )</span><span id="bdb2" class="ms mt iq mo b gy nw mv l mw mx">#Accuracy<br/>#print(mean(c45predictions== let_test$Continent))<br/>c45output&lt;-mean(c45predictions== let_test$Continent)<br/>c45output</span></pre><p id="ddf1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">输出</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ot"><img src="../Images/85c0258f45a87664b6ebe0c51c5c53df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*Su74g_RhdYYLEevaJm5YKw.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">summary of the fit, confusion matrix and accuracy</figcaption></figure><p id="c53a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">观察</strong></p><ul class=""><li id="2b3c" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated">通过总结拟合度，我们可以看到 138 个实例被正确分类，而 40 个被错误分类。</li><li id="f6ad" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated"><strong class="ky ir">使用 C4.5 算法得到的准确率为 48% </strong>。</li><li id="695d" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">精确度与 RIPPER 算法非常相似。</li></ul></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="d091" class="my mt iq bd mz na nz nc nd ne oa ng nh jw ob jx nj jz oc ka nl kc od kd nn no bi translated">结论</h1><p id="9893" class="pw-post-body-paragraph kw kx iq ky b kz np jr lb lc nq ju le lf oe lh li lj of ll lm ln og lp lq lr ij bi translated">最后，让我们列出本文中使用的各种分类器的所有精度值。</p><p id="11d7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">精度值——由分类器</strong>确定</p><ul class=""><li id="c42f" class="lz ma iq ky b kz la lc ld lf mb lj mc ln md lr me mf mg mh bi translated">KNN——44%</li><li id="4e13" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">SVM——55%</li><li id="d094" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">OneR — 20%</li><li id="93c2" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">裂土器— 48%</li><li id="84e7" class="lz ma iq ky b kz mi lc mj lf mk lj ml ln mm lr me mf mg mh bi translated">C4.5 — 48%</li></ul><p id="1c96" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">显然，SVM 的表现远远超过了所有其他分类技术。RIPPER 和 C4.5 是最接近的，都显示出 48%的准确率，这是非常令人印象深刻的。OneR 算法表现最差，只有 20%的准确率。</p></div></div>    
</body>
</html>