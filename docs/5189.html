<html>
<head>
<title>5 Types of Regressions for your Machine Learning Toolbox</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习工具箱的 5 种回归类型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/five-regression-types-b07483813b33?source=collection_archive---------11-----------------------#2018-10-02">https://towardsdatascience.com/five-regression-types-b07483813b33?source=collection_archive---------11-----------------------#2018-10-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/948718a5848c8be0f44187eb129d6384.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lu_xzeoHmNJIi-_r"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk"><a class="ae jd" href="https://unsplash.com/@siora18?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Siora Photography</a> on <a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><p id="b407" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">机器学习领域发展迅速。然而，一些经验丰富的技术仍然存在。最重要的是回归技术。2017 年，60%的 KDNuggets 调查受访者将它们列为他们前一年使用的技术:</p><div class="ip iq gp gr ir lb"><a href="https://www.kdnuggets.com/2017/12/top-data-science-machine-learning-methods.html" rel="noopener  ugc nofollow" target="_blank"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd jh gy z fp lg fr fs lh fu fw jf bi translated">2017 年使用的顶级数据科学和机器学习方法</h2><div class="li l"><h3 class="bd b gy z fp lg fr fs lh fu fw dk translated">最新的 KDnuggets 民意调查询问:在过去 12 个月中，您使用了哪些数据科学/机器学习方法和工具…</h3></div><div class="lj l"><p class="bd b dl z fp lg fr fs lh fu fw dk translated">www.kdnuggets.com</p></div></div><div class="lk l"><div class="ll l lm ln lo lk lp ix lb"/></div></div></a></div><p id="44fc" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">只要这个数字一样高，你在机器学习生涯中就会遇到退步。即使你自己不使用它们，了解不同的味道和它们解决的问题也是很重要的。</p><p id="6365" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我为你提供了五个不同回归的快速概述。我还添加了一些链接和提示来帮助您迈出第一步。</p><h2 id="8413" class="lq lr jg bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated">1.逻辑回归</h2><p id="c4c6" class="pw-post-body-paragraph kd ke jg kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">逻辑回归对二元目标进行分类。如果您想将它应用于您的分类问题，请花些时间仔细看看<em class="mo"> sklearn </em>  <em class="mo"> </em>中的<a class="ae jd" href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">实现。基本的想法很简单，但是有很多方法可以微调这个方法。</a></p><blockquote class="mp mq mr"><p id="ba0c" class="kd ke mo kf b kg kh ki kj kk kl km kn ms kp kq kr mt kt ku kv mu kx ky kz la ij bi translated"><strong class="kf jh">提示:</strong>默认情况下，逻辑回归——和许多其他变量一样——假设所有特征对结果变量都有独立的(也称为加性的)线性影响。如果这个假设在你的用例中不成立，考虑交互效果或者其他方法来包含特性之间的复杂关系。</p></blockquote><h2 id="39b1" class="lq lr jg bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated">2.有序逻辑回归</h2><p id="5717" class="pw-post-body-paragraph kd ke jg kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">如果你有一个排序目标变量的机器学习问题，使用有序逻辑回归。例如星级评定或小规模调查。通常的做法是将这些情况建模为度量或多类问题。然而，这些替代方案淡化了目标的序数特征。只是用有序逻辑回归代替。这种回归技术不太为人所知，但却非常强大。如果你想试试的话，可以看看 Python 中的<a class="ae jd" href="https://pythonhosted.org/mord/index.html" rel="noopener ugc nofollow" target="_blank">mord 包</a>。</p><blockquote class="mp mq mr"><p id="16ce" class="kd ke mo kf b kg kh ki kj kk kl km kn ms kp kq kr mt kt ku kv mu kx ky kz la ij bi translated"><strong class="kf jh">提示:</strong>与逻辑回归相比，有序逻辑回归的输出看起来相似。然而，对结果的解释更加困难。特别是优势比在这里可能会产生很大的误导。</p></blockquote><h2 id="2bf4" class="lq lr jg bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated">3.普通最小二乘法</h2><p id="1ff9" class="pw-post-body-paragraph kd ke jg kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">对度量变量使用普通最小二乘法(OLS)。该模型以及对结果的解释都很简单。Python 的实现在<a class="ae jd" href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html" rel="noopener ugc nofollow" target="_blank"> <em class="mo"> sklearn </em> </a>和<a class="ae jd" href="https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html" rel="noopener ugc nofollow" target="_blank"> <em class="mo"> statsmodels </em> </a>中都可用。</p><blockquote class="mp mq mr"><p id="cd67" class="kd ke mo kf b kg kh ki kj kk kl km kn ms kp kq kr mt kt ku kv mu kx ky kz la ij bi translated">提示: OLS 依赖于几个真实数据经常违反的假设。结果的后果可能是巨大的。<a class="ae jd" href="http://statisticsbyjim.com/regression/ols-linear-regression-assumptions/" rel="noopener ugc nofollow" target="_blank">查看这里对最重要的假设</a>的详细解释。</p></blockquote><h2 id="0e0a" class="lq lr jg bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated">4.计数数据回归</h2><p id="73da" class="pw-post-body-paragraph kd ke jg kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">计数数据回归是一组处理目标变量的方法，这些变量的值总是正数和整数。由此产生的数据通常是非常不准确的。参见这篇关于各种选项的精彩文章:</p><div class="ip iq gp gr ir lb"><a href="https://www.theanalysisfactor.com/poisson-or-negative-binomial-using-count-model-diagnostics-to-select-a-model/" rel="noopener  ugc nofollow" target="_blank"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd jh gy z fp lg fr fs lh fu fw jf bi translated">泊松还是负二项式？使用计数模型诊断来选择模型</h2><div class="li l"><h3 class="bd b gy z fp lg fr fs lh fu fw dk translated">选择适当的盘点模型来分析离散盘点结果的关键标准之一是相对值…</h3></div><div class="lj l"><p class="bd b dl z fp lg fr fs lh fu fw dk translated">www.theanalysisfactor.com</p></div></div><div class="lk l"><div class="mv l lm ln lo lk lp ix lb"/></div></div></a></div><blockquote class="mp mq mr"><p id="220d" class="kd ke mo kf b kg kh ki kj kk kl km kn ms kp kq kr mt kt ku kv mu kx ky kz la ij bi translated"><strong class="kf jh">提示</strong>:底层发行版的选择至关重要。确保您使用了可用的测试来选择正确的测试。</p></blockquote><h2 id="41e7" class="lq lr jg bd ls lt lu dn lv lw lx dp ly ko lz ma mb ks mc md me kw mf mg mh mi bi translated">5.正则化技术</h2><p id="2571" class="pw-post-body-paragraph kd ke jg kf b kg mj ki kj kk mk km kn ko ml kq kr ks mm ku kv kw mn ky kz la ij bi translated">正则化是防止过度拟合的一种方法。在回归技术的背景下，有两种正则化:L1 和 L2。如果你使用 L1，你是在应用所谓的套索回归。如果你使用 L2，你是在使用岭回归。在第一种情况下，模型倾向于将系数设置为零。在第二种情况下，它试图在整个范围内保持较小的系数。在弹性网中还实现了两种技术的组合。</p><p id="f0e4" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正则化本身是一个话题，但是由于 sklearn 中的实现，它们很容易使用。关于 L1 和 L2 的详细解释，请看这里:</p><div class="ip iq gp gr ir lb"><a rel="noopener follow" target="_blank" href="/l1-and-l2-regularization-methods-ce25e7fc831c"><div class="lc ab fo"><div class="ld ab le cl cj lf"><h2 class="bd jh gy z fp lg fr fs lh fu fw jf bi translated">L1 和 L2 正则化方法</h2><div class="li l"><h3 class="bd b gy z fp lg fr fs lh fu fw dk translated">机器学习</h3></div><div class="lj l"><p class="bd b dl z fp lg fr fs lh fu fw dk translated">towardsdatascience.com</p></div></div></div></a></div><blockquote class="mp mq mr"><p id="9f96" class="kd ke mo kf b kg kh ki kj kk kl km kn ms kp kq kr mt kt ku kv mu kx ky kz la ij bi translated">提示:了解每种方法会产生什么类型的输出是至关重要的。例如，如果你有两个相关的特征，套索随机选择其中一个，而弹性网选择两个。</p></blockquote></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><p id="e0cb" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你用什么回归，为什么？请在评论中或在<a class="ae jd" href="https://twitter.com/TimoBohm" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上告诉我。我也很乐意在 LinkedIn 上联系。<strong class="kf jh">感谢阅读，留点👏🏻如果这对你有帮助，让我们继续学习吧！</strong></p></div></div>    
</body>
</html>