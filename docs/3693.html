<html>
<head>
<title>Introduction to Bayesian Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯网络简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-bayesian-networks-81031eeed94e?source=collection_archive---------1-----------------------#2018-06-08">https://towardsdatascience.com/introduction-to-bayesian-networks-81031eeed94e?source=collection_archive---------1-----------------------#2018-06-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div class="gh gi jq"><img src="../Images/9338719b58f8eb1156a7558f0cfaaeca.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*P9PzWUBv7RsNexqZWVXNcA.png"/></div></figure><p id="bdd4" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated"><strong class="jz iu">贝叶斯网络</strong>是一种概率图形模型，使用贝叶斯推理进行概率计算。贝叶斯网络旨在通过用有向图中的边来表示条件依赖，从而对条件依赖以及因果关系进行建模。通过这些关系，人们可以通过使用因子有效地对图中的随机变量进行推断。</p></div><div class="ab cl kv kw hx kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="im in io ip iq"><h2 id="d8b2" class="lc ld it bd le lf lg dn lh li lj dp lk ki ll lm ln km lo lp lq kq lr ls lt lu bi translated">可能性</h2><p id="4397" class="pw-post-body-paragraph jx jy it jz b ka lv kc kd ke lw kg kh ki lx kk kl km ly ko kp kq lz ks kt ku im bi translated">在深入到底什么是贝叶斯网络之前，首先回顾一下概率论是很有用的。</p><p id="17a8" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">先记住随机变量 A_0，A_1，…，A_n 的联合概率分布，记为 P(A_0，A_1，…，A_n)，由概率的<a class="ae ma" href="https://en.wikipedia.org/wiki/Chain_rule_(probability)" rel="noopener ugc nofollow" target="_blank">链式法则，等于 P(A_1 | A_2，…，A_n) * P(A_2 | A_3，…，A_n) * … * P(A_n)。我们可以认为这是分布的<strong class="jz iu">分解</strong>表示，因为它是局部概率的 N 个因子的乘积。</a></p><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/271a83e2d2364b3ea4362fa7d24c3316.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/1*8bEBhwcRQ9lgaiECv3WFmQ.png"/></div></figure><p id="c41c" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">接下来回想一下两个随机变量 A 和 B 之间的<strong class="jz iu">条件独立</strong>给定另一个随机变量 C，等价于满足以下性质:P(A，B|C) = P(A|C) * P(B|C)。换句话说，只要 C 的值已知且固定，A 和 B 就是独立的。另一种表述方式是 P(A|B，C) = P(A|C ),我们稍后会用到。</p></div><div class="ab cl kv kw hx kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="im in io ip iq"><h2 id="0208" class="lc ld it bd le lf lg dn lh li lj dp lk ki ll lm ln km lo lp lq kq lr ls lt lu bi translated">贝叶斯网络</h2><p id="7d0d" class="pw-post-body-paragraph jx jy it jz b ka lv kc kd ke lw kg kh ki lx kk kl km ly ko kp kq lz ks kt ku im bi translated">使用我们的贝叶斯网络指定的关系，我们可以通过利用条件独立性来获得联合概率分布的紧凑、分解的表示。</p><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/02461163e68bf2dda279ed1ac59a7b81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*9OsQV0PqM2juaOtGqoRISw.jpeg"/></div></figure><p id="c239" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">贝叶斯网络是一个<strong class="jz iu">有向无环图</strong>，其中每条边对应一个条件依赖，每个节点对应一个唯一的随机变量。形式上，如果连接随机变量 A 和 B 的图中存在一条边(A，B ),则意味着 P(B|A)是联合概率分布中的一个<strong class="jz iu">因子</strong>,所以我们必须知道 B 和 A 的所有值的 P(B|A ),才能进行推断。在上面的示例中，由于 Rain 具有进入 WetGrass 的边，这意味着 P(WetGrass|Rain)将是一个因子，其概率值在条件概率表中 WetGrass 节点的旁边指定。</p><p id="c8f4" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">贝叶斯网络满足<strong class="jz iu">局部马尔可夫性质</strong>，该性质声明给定其父节点，节点有条件地独立于其非后代。在上面的例子中，这意味着 P(洒水喷头|多云，雨)= P(洒水喷头|多云)，因为洒水喷头有条件地独立于它的非后代，雨，给定多云。这一性质使我们能够将上一节中使用链式法则得到的联合分布简化为更小的形式。简化后，贝叶斯网络的联合分布等于所有节点的 P(node|parents(node))的乘积，如下所示:</p><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/80929a920446eb0fe6e131b5a10f62a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*YfhbkEJaSBduQHoYoXnmKg.png"/></div></figure><p id="cdad" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">在较大的网络中，这一特性使我们能够大大减少所需的计算量，因为一般来说，相对于网络的整体规模，大多数节点的父节点很少。</p></div><div class="ab cl kv kw hx kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="im in io ip iq"><h2 id="670a" class="lc ld it bd le lf lg dn lh li lj dp lk ki ll lm ln km lo lp lq kq lr ls lt lu bi translated">推理</h2><p id="74d4" class="pw-post-body-paragraph jx jy it jz b ka lv kc kd ke lw kg kh ki lx kk kl km ly ko kp kq lz ks kt ku im bi translated">贝叶斯网络上的推理有两种形式。</p><p id="2c38" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">第一种是简单地评估网络中每个变量(或子集)的特定赋值的联合概率。为此，我们已经有了联合分布的分解形式，所以我们简单地使用提供的条件概率来评估该产品。如果我们只关心变量的子集，我们将需要边缘化那些我们不感兴趣的变量。在许多情况下，这可能导致下溢，因此通常取该乘积的对数，这相当于将乘积中每一项的单独对数相加。</p><p id="6512" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">第二，更有趣的推理任务，是找到 P(x|e)，或者，在给定其他变量赋值的情况下，找到变量子集(x)的某个赋值的概率(我们的证据，e)。在上面的示例中，可以找到 P(sprayer，WetGrass | Cloudy ),其中{ Sprinkler，WetGrass}是我们的 x，而{Cloudy}是我们的 e。为了计算这一点，我们使用了 P(x|e) = P(x，e) / P(e) = αP(x，e)这一事实，其中α是归一化常数，我们将在最后计算该常数，使得 P(x|e) + P( x | e) = 1。为了计算 P(x，e ),我们必须将没有出现在 x 或 e 中的变量的联合概率分布边缘化，我们将它们表示为 y。</p><figure class="mc md me mf gt ju gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/d5e09df4766ae76a2966c11339307f4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*gOMdG6vEYjXCfKmtgBIRZg.png"/></div></figure><p id="0d1f" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">对于给定的示例，我们可以如下计算 P(洒水喷头，湿草|多云):</p><figure class="mc md me mf gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="gh gi mj"><img src="../Images/d8e41394554d24a46758571e2e8b524d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sI8uNUUcXPTlIcqJItJCYA.png"/></div></div></figure><p id="da62" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">我们将以同样的方式计算 P( x | e ),只是将 x 中变量的值设置为 false 而不是 true。一旦 P( x | e)和 P(x | e)都计算出来，我们就可以解出α，它等于 1 / (P(x | e) + P( x | e))。</p><p id="3651" class="pw-post-body-paragraph jx jy it jz b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku im bi translated">请注意，在较大的网络中，Y 很可能相当大，因为大多数推理任务将只直接使用变量的一个小子集。在这种情况下，如上所示的精确推理计算量非常大，因此必须使用一些方法来减少计算量。一种更有效的精确推断方法是通过<a class="ae ma" href="https://en.wikipedia.org/wiki/Variable_elimination" rel="noopener ugc nofollow" target="_blank">变量消除</a>，它利用了每个因素只涉及少量变量的事实。这意味着求和可以重新排列，以便在该变量的边缘化中只使用涉及给定变量的因子。或者，许多网络甚至对于这种方法来说都太大了，所以使用近似推理方法，例如<a class="ae ma" href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo" rel="noopener ugc nofollow" target="_blank">MCMC</a>；这些提供的概率估计比精确推断方法需要更少的计算。</p></div></div>    
</body>
</html>