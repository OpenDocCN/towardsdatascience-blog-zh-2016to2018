<html>
<head>
<title>Build a Handwritten Text Recognition System using TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 TensorFlow 构建手写文本识别系统</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/build-a-handwritten-text-recognition-system-using-tensorflow-2326a3487cd5?source=collection_archive---------1-----------------------#2018-06-15">https://towardsdatascience.com/build-a-handwritten-text-recognition-system-using-tensorflow-2326a3487cd5?source=collection_archive---------1-----------------------#2018-06-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8634" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><strong class="ak">可在 CPU 上训练的最小神经网络实现</strong></h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/2342526c2087e4b9c1412b2b5bfa2d97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ozO04QLClSzCaPgFDi6RYw.jpeg"/></div></div></figure><p id="29dd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">离线手写文本识别(HTR)系统将包含在扫描图像中的文本转录成数字文本，图 1 中示出了一个例子。我们将建立一个神经网络(NN ),它是根据来自 IAM 数据集的单词图像进行训练的。由于文字图像的输入层(以及所有其他层)可以保持较小，因此 NN 训练在 CPU 上是可行的(当然，GPU 会更好)。这个实现是 HTR 使用 TF 所需的最低要求。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/903ac6c73300b23e69156f685e5555fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*6cEKOYqHG27tYwhQVvJqPQ.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Fig. 1: Image of word (taken from IAM) and its transcription into digital text.</figcaption></figure><h1 id="9306" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">获取代码和数据</h1><ol class=""><li id="a616" class="mn mo it kw b kx mp la mq ld mr lh ms ll mt lp mu mv mw mx bi translated">你需要安装 Python 3，TensorFlow 1.3，numpy 和 OpenCV</li><li id="2189" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp mu mv mw mx bi translated">从 GitHub 获取实现:要么采用本文所基于的<a class="ae nd" href="https://github.com/githubharald/SimpleHTR/tree/97c2512f593760b14669b37a159ead2f1e54961b" rel="noopener ugc nofollow" target="_blank">代码版本</a>，要么采用<a class="ae nd" href="https://github.com/githubharald/SimpleHTR" rel="noopener ugc nofollow" target="_blank">最新的代码版本</a>，如果你可以接受文章和代码之间的一些不一致</li><li id="e271" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp mu mv mw mx bi translated">更多说明(如何获取 IAM 数据集、命令行参数等)可以在自述文件中找到</li></ol><h1 id="6069" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">模型概述</h1><p id="2619" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">我们使用神经网络来完成我们的任务。它由卷积神经网络(CNN)层、递归神经网络(RNN)层和最终的连接主义者时间分类(CTC)层组成。图 2 显示了我们的 HTR 系统的概况。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/1f6fbe9c2c8440dcc3cd44c5b2966284.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*P4UW-wqOMSpi82KIcq11Pw.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Fig. 2: Overview of the NN operations (green) and the data flow through the NN (pink).</figcaption></figure><p id="a172" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们也可以用一种更正式的方式把神经网络看作一个函数(见等式)。1)它将大小为 W×H 的图像(或矩阵)M 映射到长度在 0 和 l 之间的字符序列(c1，c2，…)。正如您所看到的，文本是在字符级别上被识别的，因此未包含在训练数据中的单词或文本也可以被识别(只要单个字符被正确分类)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/c46c40e5129c89cee61eba3ae32aca57.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*tjy5KJVpbw7tmce2b3bavg.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Eq. 1: The NN written as a mathematical function which maps an image M to a character sequence (c1, c2, …).</figcaption></figure><h2 id="a850" class="nj lw it bd lx nk nl dn mb nm nn dp mf ld no np mh lh nq nr mj ll ns nt ml nu bi translated">操作</h2><p id="766f" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated"><strong class="kw iu"> CNN </strong>:输入图像被送入 CNN 层。这些层被训练以从图像中提取相关特征。每一层由三个操作组成。首先是卷积运算，它在前两层中应用大小为 5×5 的滤波器核，在后三层中应用大小为 3×3 的滤波器核。然后，应用非线性 RELU 函数。最后，汇集层汇总图像区域并输出输入的缩小版本。当图像高度在每层中缩小 2 倍时，添加特征图(通道)，使得输出特征图(或序列)具有 32×256 的大小。</p><p id="9aef" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> RNN </strong>:特征序列每个时间步包含 256 个特征，RNN 通过这个序列传播相关信息。使用流行的长短期记忆(LSTM)实现的 RNNs，因为它能够通过更长的距离传播信息，并且提供比普通 RNN 更健壮的训练特征。RNN 输出序列被映射到大小为 32×80 的矩阵。IAM 数据集由 79 个不同的字符组成，CTC 操作还需要一个额外的字符(CTC 空白标签)，因此 32 个时间步长中的每一个都有 80 个条目。</p><p id="5d34" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> CTC </strong>:在训练 NN 时，CTC 得到 RNN 输出矩阵和地面真实文本，它计算<strong class="kw iu">损失值</strong>。在推断时，CTC 仅获得矩阵，并将其解码为<strong class="kw iu">最终文本</strong>。基本事实文本和识别文本的长度最多为 32 个字符。</p><h2 id="aad8" class="nj lw it bd lx nk nl dn mb nm nn dp mf ld no np mh lh nq nr mj ll ns nt ml nu bi translated">数据</h2><p id="e211" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated"><strong class="kw iu">输入</strong>:大小为 128×32 的灰度图像。通常，数据集中的图像没有这个大小，因此我们调整它的大小(没有失真),直到它的宽度为 128 或高度为 32。然后，我们将该图像复制到大小为 128×32 的(白色)目标图像中。这个过程如图 3 所示。最后，我们归一化图像的灰度值，这简化了神经网络的任务。通过将图像复制到随机位置，而不是将其向左对齐或随机调整图像大小，可以轻松集成数据扩充。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/8bf6e804cf5f141bd57f29d95b96f8eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*oyMRDZZqRjTlo-yGrCbZCA.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Fig. 3: Left: an image from the dataset with an arbitrary size. It is scaled to fit the target image of size 128×32, the empty part of the target image is filled with white color.</figcaption></figure><p id="4df6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> CNN 输出</strong>:图 4 示出了长度为 32 的 CNN 层的输出。每个条目包含 256 个特征。当然，这些特征由 RNN 层进一步处理，然而，一些特征已经显示出与输入图像的某些高级属性的高度相关性:存在与字符(例如“e”)或者与重复字符(例如“tt”)或者与诸如循环(包含在手写“l”或“e”中)的字符属性高度相关的特征。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nw"><img src="../Images/c248ad46c1b429e3719defa5b1a78a7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w2QeZ7CkQiQOuVjBz-DQ0A.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Fig. 4: Top: 256 feature per time-step are computed by the CNN layers. Middle: input image. Bottom: plot of the 32nd feature, which has a high correlation with the occurrence of the character “e” in the image.</figcaption></figure><p id="8ea1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> RNN 输出</strong>:图 5 示出了包含文本“little”的图像的 RNN 输出矩阵的可视化。最上面的图表中显示的矩阵包含字符的得分，包括作为其最后一个(第 80 个)条目的 CTC 空白标签。其他矩阵条目从上到下对应于以下字符:“！”# &amp; '()*+，-。/0123456789:;？ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz”。可以看出，在大多数情况下，字符是在它们出现在图像中的位置被准确预测的(例如，比较“I”在图像和图形中的位置)。只有最后一个字符“e”没有对齐。但是这是可以的，因为 CTC 操作是无分段的，并且不关心绝对位置。从显示字符“l”、“I”、“t”、“e”和 CTC 空白标签的分数的最下面的图中，文本可以很容易地被解码:我们只是从每个时间步中取出最可能的字符，这形成了所谓的最佳路径，然后我们丢弃重复的字符，最后是所有的空白:“l-ii-t-t-l-…-e”→“l-I-t-t-…-e”→“little”。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nx"><img src="../Images/e5516c85d53de6a31d2b7d16a4aca7d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*it1IYO2aUqATjUqEO6B6vg.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Fig. 5: Top: output matrix of the RNN layers. Middle: input image. Bottom: Probabilities for the characters “l”, “i”, “t”, “e” and the CTC blank label.</figcaption></figure><h1 id="15c5" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">使用 TF 实现</h1><p id="aa33" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">实施由 4 个模块组成:</p><ol class=""><li id="f612" class="mn mo it kw b kx ky la lb ld ny lh nz ll oa lp mu mv mw mx bi translated">SamplePreprocessor.py:从 IAM 数据集中为 NN 准备图像</li><li id="d602" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp mu mv mw mx bi translated">py:读取样本，将它们放入批处理中，并提供一个迭代器接口来遍历数据</li><li id="0a8d" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp mu mv mw mx bi translated">py:如上所述创建模型，加载并保存模型，管理 TF 会话，并为训练和推理提供接口</li><li id="79a8" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp mu mv mw mx bi translated">将前面提到的所有模块放在一起</li></ol><p id="0b4c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们只看 Model.py，因为其他源文件涉及基本文件 IO (DataLoader.py)和图像处理(SamplePreprocessor.py)。</p><h2 id="39d4" class="nj lw it bd lx nk nl dn mb nm nn dp mf ld no np mh lh nq nr mj ll ns nt ml nu bi translated">美国有线新闻网；卷积神经网络</h2><p id="7989" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">对于每个 CNN 层，创建一个 k×k 大小的核，用于卷积运算。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="4f67" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后，将卷积的结果输入 RELU 运算，然后再次输入大小为 px×py、步长为 sx×sy 的池层。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="3632" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对 for 循环中的所有层重复这些步骤。</p><h2 id="85bd" class="nj lw it bd lx nk nl dn mb nm nn dp mf ld no np mh lh nq nr mj ll ns nt ml nu bi translated">RNN</h2><p id="5351" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">创建并堆叠两个 RNN 层，每层 256 个单位。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="8f98" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后，从它创建一个双向 RNN，这样输入序列从前到后遍历，反之亦然。结果，我们得到大小为 32×256 的两个输出序列 fw 和 bw，我们随后沿着特征轴将它们连接起来以形成大小为 32×512 的序列。最后，它被映射到大小为 32×80 的输出序列(或矩阵),该输出序列(或矩阵)被馈送到 CTC 层。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><h2 id="1775" class="nj lw it bd lx nk nl dn mb nm nn dp mf ld no np mh lh nq nr mj ll ns nt ml nu bi translated">同ＣIＴＹ ＴＥＣＨＮＯＬＯＧＹ ＣＯＬＬＥＧＥ</h2><p id="16ec" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">对于损失计算，我们将基础事实文本和矩阵输入到操作中。基本事实文本被编码为稀疏张量。输入序列的长度必须传递给两个 CTC 操作。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><p id="ed50" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们现在有了创建丢失操作和解码操作的所有输入数据。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><h2 id="6d23" class="nj lw it bd lx nk nl dn mb nm nn dp mf ld no np mh lh nq nr mj ll ns nt ml nu bi translated">培养</h2><p id="a5c4" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">批次元素损失值的平均值用于训练神经网络:它被输入到优化器中，如 RMSProp。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="ob oc l"/></div></figure><h2 id="033c" class="nj lw it bd lx nk nl dn mb nm nn dp mf ld no np mh lh nq nr mj ll ns nt ml nu bi translated">改进模型</h2><p id="47e2" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">如果你想输入完整的文本行，如图 6 所示，而不是文字图像，你必须增加神经网络的输入大小。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/d66b24c029db9d3a0b8bbb1db872eee7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-uo57VDtO0Buwq4qGq6jmw.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Fig. 6: A complete text-line can be fed into the NN if its input size is increased (image taken from IAM).</figcaption></figure><p id="84b2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果您想提高识别准确性，可以遵循以下提示之一:</p><ul class=""><li id="961c" class="mn mo it kw b kx ky la lb ld ny lh nz ll oa lp oe mv mw mx bi translated">数据扩充:通过对输入图像应用进一步的(随机)变换来增加数据集的大小</li><li id="9068" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp oe mv mw mx bi translated">去除输入图像中的草书书写风格(参见<a class="ae nd" href="https://github.com/githubharald/DeslantImg" rel="noopener ugc nofollow" target="_blank">去除草书风格</a>)</li><li id="5c74" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp oe mv mw mx bi translated">增加输入大小(如果神经网络的输入足够大，可以使用完整的文本行)</li><li id="0226" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp oe mv mw mx bi translated">添加更多 CNN 图层</li><li id="3e09" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp oe mv mw mx bi translated">用 2D-LSTM 取代 LSTM</li><li id="213a" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp oe mv mw mx bi translated">解码器:使用令牌传递或字束搜索解码(参见<a class="ae nd" href="https://github.com/githubharald/CTCWordBeamSearch" rel="noopener ugc nofollow" target="_blank"> CTCWordBeamSearch </a>)将输出限制为字典单词</li><li id="15a3" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp oe mv mw mx bi translated">文本更正:如果识别的单词不在字典中，则搜索最相似的单词</li></ul><h1 id="62c3" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">结论</h1><p id="da02" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">我们讨论了一种能够识别图像中文本的神经网络。NN 由 5 个 CNN 和 2 个 RNN 层组成，输出一个字符概率矩阵。该矩阵或者用于 CTC 丢失计算，或者用于 CTC 解码。提供了一个使用 TF 的实现，并给出了部分重要的代码。最后，给出了提高识别准确率的建议。</p><h1 id="4909" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">常见问题解答</h1><p id="349e" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">关于展示的模型有一些问题:</p><ol class=""><li id="b275" class="mn mo it kw b kx ky la lb ld ny lh nz ll oa lp mu mv mw mx bi translated">如何识别样品/数据集中的文本？</li><li id="39bf" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp mu mv mw mx bi translated">如何识别行/句中的文本？</li><li id="751d" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp mu mv mw mx bi translated">如何计算识别文本的置信度得分？</li></ol><p id="e176" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我在<a class="ae nd" href="https://medium.com/@harald_scheidl/27648fb18519" rel="noopener">的 FAQ 文章</a>中讨论了它们。</p><h1 id="0a57" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">参考资料和进一步阅读</h1><p id="cf23" class="pw-post-body-paragraph ku kv it kw b kx mp ju kz la mq jx lc ld ne lf lg lh nf lj lk ll ng ln lo lp im bi translated">源代码和数据可从以下网址下载:</p><ul class=""><li id="0066" class="mn mo it kw b kx ky la lb ld ny lh nz ll oa lp oe mv mw mx bi translated"><a class="ae nd" href="https://github.com/githubharald/SimpleHTR" rel="noopener ugc nofollow" target="_blank">呈现 NN 的源代码</a></li><li id="48ba" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp oe mv mw mx bi translated"><a class="ae nd" href="http://www.fki.inf.unibe.ch/databases/iam-handwriting-database" rel="noopener ugc nofollow" target="_blank"> IAM 数据集</a></li></ul><p id="7cbb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这些文章更详细地讨论了文本识别的某些方面:</p><ul class=""><li id="82f1" class="mn mo it kw b kx ky la lb ld ny lh nz ll oa lp oe mv mw mx bi translated"><a class="ae nd" href="https://medium.com/@harald_scheidl/27648fb18519" rel="noopener">常见问题解答</a></li><li id="0779" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp oe mv mw mx bi translated"><a class="ae nd" rel="noopener" target="_blank" href="/6c04864b8a98">文本识别系统实际看到的内容</a></li><li id="13c9" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp oe mv mw mx bi translated"><a class="ae nd" rel="noopener" target="_blank" href="/3797e43a86c">CTC 简介</a></li><li id="b1b5" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp oe mv mw mx bi translated"><a class="ae nd" rel="noopener" target="_blank" href="/5a889a3d85a7">普通波束搜索解码</a></li><li id="b3e4" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp oe mv mw mx bi translated"><a class="ae nd" rel="noopener" target="_blank" href="/b051d28f3d2e">字束搜索解码</a></li></ul><p id="632e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这些出版物中可以找到更深入的介绍:</p><ul class=""><li id="d02e" class="mn mo it kw b kx ky la lb ld ny lh nz ll oa lp oe mv mw mx bi translated"><a class="ae nd" href="https://repositum.tuwien.at/retrieve/10807" rel="noopener ugc nofollow" target="_blank">关于历史文献中手写文本识别的论文</a></li><li id="2a45" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp oe mv mw mx bi translated"><a class="ae nd" href="https://repositum.tuwien.at/retrieve/1835" rel="noopener ugc nofollow" target="_blank">字束搜索解码</a></li><li id="69eb" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp oe mv mw mx bi translated"><a class="ae nd" href="https://arxiv.org/abs/1507.05717" rel="noopener ugc nofollow" target="_blank">卷积递归神经网络</a></li><li id="6fca" class="mn mo it kw b kx my la mz ld na lh nb ll nc lp oe mv mw mx bi translated"><a class="ae nd" href="http://www.tbluche.com/scan_attend_read.html" rel="noopener ugc nofollow" target="_blank">识别页面级文本</a></li></ul><p id="3bb8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，概述一下我的<a class="ae nd" href="https://harald-scheidl.medium.com/c4683d776120" rel="noopener">其他媒体文章</a>。</p></div></div>    
</body>
</html>