<html>
<head>
<title>Reading Traffic Signs with Human Like Accuracy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">像人类一样准确地阅读交通标志</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/traffic-signs-classification-for-self-driving-car-67ce57877c33?source=collection_archive---------4-----------------------#2017-06-19">https://towardsdatascience.com/traffic-signs-classification-for-self-driving-car-67ce57877c33?source=collection_archive---------4-----------------------#2017-06-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="b942" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">用数据做酷事</em></p><p id="6c85" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">自动驾驶汽车将不得不实时解读我们道路上的所有交通标志，并在驾驶中考虑这些因素。在这篇博客中，我们使用深度学习来训练汽车以93%的准确率对交通标志进行分类。</p><p id="179d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我已经用Python分享了我的<a class="ae km" href="https://github.com/priya-dwivedi/CarND/blob/master/CarND-Traffic-Sign-Classifier-P2/Traffic_Sign_Classifier_pd.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir"> GitHub </strong> </a>的链接和全部代码。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi kn"><img src="../Images/b9fcb5b02d11ecb5d4cc8f8fdf400b2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*2cFdBkLkXTkuMfMD9txPWw.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Traffic Signs!</figcaption></figure><h2 id="a955" class="kz la iq bd lb lc ld dn le lf lg dp lh jy li lj lk kc ll lm ln kg lo lp lq lr bi translated"><strong class="ak">数据集</strong></h2><p id="9e30" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">这个练习使用的数据集(可以从<a class="ae km" href="http://benchmark.ini.rub.de/?section=gtsrb&amp;subsection=dataset" rel="noopener ugc nofollow" target="_blank">这里</a>下载)由德国道路上看到的43个不同的交通标志组成。交通标志图像是从实际道路图像中裁剪出来的，因此处于不同的光照条件下，如下所示。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/4aed4f21f39e1e55a3738b0b2da1fa7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*2zvD1Mk-Fbb3Fb2TQUoMaw.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Cropping stop sign from actual road images</figcaption></figure><p id="c731" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它总共有5万张图片。图像为32x32像素，并且是彩色的。</p><p id="c5aa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">理解数据</strong></p><p id="d081" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">任何建模练习的第一步都应该是熟悉所涉及的数据。这里有43个不同的交通标志。如下图所示，数据分布不均匀。一些标志只有200张图片，而另一些有超过1200张图片。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/661012e19884c0bf59083e31a5a4f5f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*j2oNToGlkQlkBrkW8AZaZw.png"/></div></figure><p id="ab88" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如下图所示，可视化数据集中的图像，我们可以看到图像很小，具有不同的亮度，有些图像很模糊。此外，交通标志并不总是在图像的中心。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/483217810a317bf276a0cac4b9c2066e.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*V5Co-oZc3QeKvlH6f2ph3w.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Traffic Sign images from the dataset</figcaption></figure><p id="e2e0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">数据预处理</strong></p><p id="bed0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在将图像输入神经网络之前，我对图像进行了归一化处理，使像素值介于0和0.5之间。我这样做是通过将所有像素值除以255。这样做是因为当原始数据在0和1之间时，神经网络表现得更好。我决定使用彩色交通标志，而不是将其转换为灰色，因为人类使用标志的颜色进行分类，所以机器也可以受益于这些额外的信息。最后，我将数据集分为训练集、验证集和测试集。测试集是模型永远看不到的30%的样本。</p><h2 id="61ce" class="kz la iq bd lb lc ld dn le lf lg dp lh jy li lj lk kc ll lm ln kg lo lp lq lr bi translated"><strong class="ak">模型架构</strong></h2><p id="2def" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">对于这个项目，我决定使用LeNet架构，这是一个简单的卷积神经网络(CNN)，在MNIST数据集上表现良好。如下所示，该模型有两个卷积层，后跟两个最大池层。第一个卷积层使用5x5的面片大小和深度为6的过滤器。第二个卷积层也使用5x5的面片大小，但深度为16的过滤器。在卷积之后，我们展平输出，然后使用两个完全连接的层。第一个有120个神经元，第二个有84个神经元。在所有层之间使用RELU激活。最后，我们有一个输出层，它使用Softmax将图像分为43类。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/2a4bff63f65c8f785c8dd22be24a3e5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*uOe-Uzme0etgx6Yix-JsNg.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">LeNet Architecture</figcaption></figure><p id="c012" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">LeNet架构在这个问题上表现得非常好，在30个时期内，我们在验证样本上获得了98%以上的准确率。请参见下面的准确度和损失图:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/4750c18eceda9d38e2742e279c196a6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*iIAuc8G2rUdbc2vQN03GSA.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Model training using LeNet Architecture</figcaption></figure><p id="b064" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从未接触过该模型的测试样本的准确度约为93%,这是相当可靠的。</p><p id="c993" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果我们使用图像增强——亮度、旋转、平移等方面的变化，精确度可以进一步提高。增加样本量。</p><h2 id="0715" class="kz la iq bd lb lc ld dn le lf lg dp lh jy li lj lk kc ll lm ln kg lo lp lq lr bi translated"><strong class="ak">可视化神经网络</strong></h2><p id="100d" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">虽然神经网络可以是一个很好的学习设备，但它们通常被称为黑盒。我们可以通过绘制其特征图来了解神经网络正在学习什么——这是过滤器的输出。从这些绘制的特征地图中，可以看出网络对图像的哪些特征感兴趣。对于标志，内部网络要素地图可能会对标志的边界轮廓或标志的着色符号中的对比度做出高度激活的反应。</p><p id="1813" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">查看这个<a class="ae km" href="https://cs231n.github.io/understanding-cnn/" rel="noopener ugc nofollow" target="_blank">链接</a>，了解更多关于可视化神经网络的信息。</p><p id="820d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们看看第一个卷积层的6个不同的过滤器如何响应“请勿进入”的标志。这里亮点反映了神经元被激活的地方。可以看出，网络集中在圆形标志和中间的扁平线上。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/88fffb126f182584789b556f13ed4fdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:226/format:webp/1*7DFTMoZjoklyBzlERz8izg.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Do Not Enter Sign</figcaption></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi md"><img src="../Images/ec4f03189fb97a1c02eca84df35904c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mtEjyC_qQXFetmfBoF5jUA.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Feature map — Do Not Enter Sign</figcaption></figure><p id="f558" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">相比之下，我们从没有交通标志的天空图像来看特征图。大多数过滤器是黑色的，这意味着神经网络无法识别该图像中的任何明显特征。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/682c8f5f4744ece220feaaf0d255958a.png" data-original-src="https://miro.medium.com/v2/resize:fit:236/format:webp/1*QCcmcjj8aS3yJp2gRG2LmA.png"/></div></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi mj"><img src="../Images/04c870cf8a037e1ac5486c70095a7a3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nalQe_x2tQSP_VT-YpzfaQ.png"/></div></div></figure><p id="5ba2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这不是超级有趣吗！</p><p id="870c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">其他著述</strong>:<a class="ae km" href="https://medium.com/@priya.dwivedi/" rel="noopener">https://medium.com/@priya.dwivedi/</a></p><p id="7437" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">PS:我住在多伦多，我希望将职业生涯转向深度学习。如果你喜欢我的帖子，并能把我联系到任何人，我将不胜感激:)。我的电子邮件是priya.toronto3@gmail.com</p><p id="38c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">参考文献:</strong></p><p id="375a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae km" href="https://www.udacity.com/" rel="noopener ugc nofollow" target="_blank"> Udacity </a>无人驾驶汽车Nano Degree——感谢Udacity和巴斯蒂安·特龙给我机会成为他们新的无人驾驶汽车项目的一部分。这是一次非常有趣的旅程。我使用的大部分代码都是在课堂讲课中建议的。这里的图片和视频参考也在讲座中分享</p><p id="9bae" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">德国交通标志数据集:<a class="ae km" href="http://benchmark.ini.rub.de/?section=gtsrb&amp;subsection=dataset" rel="noopener ugc nofollow" target="_blank">http://benchmark.ini.rub.de/?section=gtsrb&amp;分部=数据集</a></p></div></div>    
</body>
</html>