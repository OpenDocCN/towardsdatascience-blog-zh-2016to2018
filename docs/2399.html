<html>
<head>
<title>Deep Learning for Image Recognition: why it’s challenging, where we’ve been, and what’s next</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图像识别的深度学习:为什么它具有挑战性，我们已经走过的路，以及下一步</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-for-image-classification-why-its-challenging-where-we-ve-been-and-what-s-next-93b56948fcef?source=collection_archive---------1-----------------------#2018-01-21">https://towardsdatascience.com/deep-learning-for-image-classification-why-its-challenging-where-we-ve-been-and-what-s-next-93b56948fcef?source=collection_archive---------1-----------------------#2018-01-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><blockquote class="jq jr js"><p id="200a" class="jt ju jv jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr im bi translated">想获得灵感？快来加入我的<a class="ae ks" href="https://www.superquotes.co/?utm_source=mediumtech&amp;utm_medium=web&amp;utm_campaign=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="jw iu">超级行情快讯</strong> </a>。😎</p></blockquote><p id="2f76" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">在过去几年里，深度学习绝对<strong class="jw iu">统治了</strong>计算机视觉，在许多任务及其相关竞赛中取得了最高分。这些计算机视觉竞赛中最受欢迎和最知名的是<a class="ae ks" href="https://en.wikipedia.org/wiki/ImageNet" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>。ImageNet竞赛要求研究人员创建一个模型，最准确地对数据集中的给定图像进行分类。</p><p id="c75b" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">在过去的几年里，深度学习技术使这项比赛取得了快速进展，甚至超过了人类的表现。今天，我们将回顾这一进展，以深入了解这些进步是如何伴随深度学习而来的，我们可以从中学习到什么，以及我们可以从这里走向何方。</p><h1 id="04fe" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">ImageNet的挑战</h1><p id="a83f" class="pw-post-body-paragraph jt ju it jw b jx lu jz ka kb lv kd ke kt lw kh ki ku lx kl km kv ly kp kq kr im bi translated">那么ImageNet挑战赛有什么难的呢？让我们先看一下数据。ImageNet分类任务的数据是从Flickr和其他搜索引擎收集的，由人工标记，每张图像属于1000个对象类别中的一个。下表显示了数据集的分布情况。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi lz"><img src="../Images/e9b9af4b50c6eb26fd6aff6150f2ad46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Aop7q3LHExN1YKQXb3rn-Q.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">ImageNet Dataset</figcaption></figure><p id="05d8" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">到2012年，ImageNet拥有近<em class="jv">130万</em>张训练图片。如此大规模的图像分类任务的主要挑战是图像的<strong class="jw iu">多样性</strong>。这里我们可以看几个例子。</p><p id="4130" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">看看下面的图片。在左边，我们看到一些来自另一个图像分类挑战的示例图像:<strong class="jw iu"> PASCAL </strong>。在帕斯卡挑战中，只有大约20，000幅训练图像和20个对象类别。这个挑战有非常通用的类别，如“鸟”、“狗”和“猫”，如下所示。转移到ImageNet挑战，这是一个全新的游戏。ImageNet没有一个包含所有种类狗的名为“dog”的通用类，而是为每种狗都提供了类。事实上，不同于帕斯卡的“狗”类别，ImageNet有120个不同品种的狗的类别！因此，我们用于这项任务的任何模型/算法必须能够处理这些非常<strong class="jw iu">细粒度的</strong>和<strong class="jw iu">特定的</strong> <strong class="jw iu">类</strong>，即使它们看起来非常相似并且难以区分。</p><p id="c4d8" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">用更专业的术语来说，我们希望最大化<strong class="jw iu">类间可变性。</strong>这意味着我们希望两张包含不同种类鸟类的图像在我们的模型中看起来非常不同，因为尽管它们都是鸟类，但在我们的数据集中它们属于不同的类别。看看下面的插图。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi mp"><img src="../Images/e0e8f431b4376b95cfd55d94d725b82c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vtgCMP4QH4RMzxQ_Twz8jQ.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">Inter-class Variability</figcaption></figure><p id="bd59" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">ImageNet的另一个具有挑战性的特性是:同一类<strong class="jw iu"/><strong class="jw iu"/>的对象看起来会有很大的不同。让我们看看下面的图片。左边的两个都来自“橘子”班，右边的两个都来自“台球桌”班。然而，每一对图像看起来非常不同！作为人类，我们可以看到一个橙子被切开，而另一个没有；我们还可以看到，台球桌的一张照片被放大了，另一张没有。这叫做<strong class="jw iu">类内变异性</strong>。我们希望<strong class="jw iu">最小化</strong>这种可变性，因为我们希望同一类的两幅图像看起来非常类似于我们的深度学习模型，也就是说，在数量上。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/9d02534132dabff2d8d5b459ee6fc87e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*_mtijNj6SG4qx3rMsnMIBQ.png"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">Intra-class Variability</figcaption></figure><p id="25cf" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">知道了这些图像分类挑战，让我们回顾一下深度学习是如何在这项任务上取得巨大进展的。</p><h1 id="957e" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">图像分类深度学习的快速进展</h1><p id="7ef6" class="pw-post-body-paragraph jt ju it jw b jx lu jz ka kb lv kd ke kt lw kh ki ku lx kl km kv ly kp kq kr im bi translated">自2012年以来，几乎每年都让我们在为图像分类任务开发深度学习模型方面取得重大突破。由于其大规模和具有挑战性的数据，ImageNet挑战已成为衡量进展的主要基准。在这里，我们将看看深度学习在这项任务上的进展，以及使这一进展成为可能的一些主要架构。</p><h2 id="ccfd" class="mr kx it bd ky ms mt dn lc mu mv dp lg kt mw mx lk ku my mz lo kv na nb ls nc bi translated">开始这一切的人:AlexNet</h2><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nd"><img src="../Images/26f6c766a7d6961a927d87016bba70cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fnCMdaczkW-kYpfta3JLdA.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">AlexNet Architecture</figcaption></figure><p id="a51a" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">早在2012年，多伦多大学的一篇论文发表在NIPS上，这真是令人震惊。那篇论文是<a class="ae ks" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank"> ImageNet用深度卷积网络分类</a> <em class="jv">。</em>它在ImageNet挑战赛中实现了近50%的错误率降低，这在当时是前所未有的进步，随后成为该领域最具<strong class="jw iu">影响力的</strong> <strong class="jw iu">论文之一。论文中AlexNet的神经网络架构如上所示。</strong></p><p id="ab89" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">本文提出使用深度卷积神经网络(CNN)来完成图像分类的任务。与现在使用的相比，它相对简单。这篇论文的主要贡献是:</p><ul class=""><li id="3009" class="ne nf it jw b jx jy kb kc kt ng ku nh kv ni kr nj nk nl nm bi translated">第一个成功地使用deep进行大规模图像分类。这之所以成为可能，是因为来自ImageNet的标记为 <strong class="jw iu">的<strong class="jw iu">的<strong class="jw iu">大量</strong> <strong class="jw iu">数据</strong>，以及使用两个GPU上的并行计算来训练模型。</strong></strong></li><li id="c41c" class="ne nf it jw b jx nn kb no kt np ku nq kv nr kr nj nk nl nm bi translated">他们将<strong class="jw iu"> ReLU </strong>用于<strong class="jw iu">非</strong> - <strong class="jw iu">线性</strong> <strong class="jw iu">激活</strong> <strong class="jw iu">功能</strong>，发现它们相对于tanh功能表现更好，并减少了训练时间。ReLU非线性现在倾向于成为深度网络的默认激活功能。</li><li id="b937" class="ne nf it jw b jx nn kb no kt np ku nq kv nr kr nj nk nl nm bi translated">他们使用<strong class="jw iu">数据</strong> <strong class="jw iu">增强</strong>技术，包括图像平移、水平反射和均值减法。如今，这些技术被广泛用于许多计算机视觉任务。</li><li id="2c84" class="ne nf it jw b jx nn kb no kt np ku nq kv nr kr nj nk nl nm bi translated">为了解决<strong class="jw iu">超过</strong> - <strong class="jw iu">拟合</strong>训练数据的问题，他们使用了<strong class="jw iu">剔除</strong>层。</li><li id="6797" class="ne nf it jw b jx nn kb no kt np ku nq kv nr kr nj nk nl nm bi translated">他们提出的风格是让<strong class="jw iu">连续</strong> <strong class="jw iu">卷积</strong>和<strong class="jw iu">汇集</strong> <strong class="jw iu">层</strong>，然后是<strong class="jw iu">完全</strong> - <strong class="jw iu">连接最后的</strong>层，这仍然是今天许多先进网络的基础。</li></ul><p id="6b44" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">基本上，AlexNet设置了标杆，提供了使用CNN完成计算机视觉任务的基线和默认技术！</p><h2 id="976b" class="mr kx it bd ky ms mt dn lc mu mv dp lg kt mw mx lk ku my mz lo kv na nb ls nc bi translated">让我们更深入:VGGNet</h2><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/bf14e8e28334a24a8ae22c55a4e1de6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*3-TqqkRQ4rWLOMX-gvkYwA.png"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">VGGNet Architecture</figcaption></figure><p id="63f2" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">VGGNet论文“<a class="ae ks" href="https://arxiv.org/pdf/1409.1556.pdf" rel="noopener ugc nofollow" target="_blank">用于大规模图像识别的极深度卷积神经网络</a>”于2014年问世，进一步扩展了使用具有许多卷积和ReLUs的深度网络的思想。论文中VGGNet的神经网络架构如上所示。他们的主要想法是，你真的不需要任何花哨的技巧来获得高精度。只要一个有很多3×3小卷积和非线性的深度网络就可以了！上图中相同大小的重复块的堆叠是使用3x3s堆叠的直接结果！VGGNets的主要贡献是:</p><ul class=""><li id="1c14" class="ne nf it jw b jx jy kb kc kt ng ku nh kv ni kr nj nk nl nm bi translated">仅使用<strong class="jw iu">3x 3大小的过滤器，而不是AlextNet中使用的11x11。他们表明，两个连续的3×3卷积具有等同于单个5×5卷积的<strong class="jw iu">接收</strong> <strong class="jw iu">场</strong>或“视野”(即它看到的像素)；同样，三个连续的3×3卷积相当于一个7×7卷积。这样做的好处是，它模拟了一个更大的滤波器，同时保留了较小滤波器的优点。较小滤波器的第一个好处是减少了参数数量。第二个是能够在每个卷积之间使用ReLU函数，这将更多的<strong class="jw iu">非</strong> - <strong class="jw iu">线性</strong>引入网络，这使得<strong class="jw iu">决策</strong> <strong class="jw iu">函数</strong>更具<strong class="jw iu">辨别能力</strong>。</strong></li><li id="d363" class="ne nf it jw b jx nn kb no kt np ku nq kv nr kr nj nk nl nm bi translated">随着每一层的输入体积的空间大小减小(作为汇集层的结果)，体积的深度增加。这背后的想法是，随着空间信息的减少(从通过最大池的向下采样)，它应该被编码为更具<strong class="jw iu">区分度的</strong> <strong class="jw iu">特征</strong>，以用于精确和高区分度的分类。因此，特征图的数量随着深度而增加，以便能够捕捉这些特征用于分类。</li><li id="8abd" class="ne nf it jw b jx nn kb no kt np ku nq kv nr kr nj nk nl nm bi translated">它引入了一种新的数据扩充方式:标度抖动。</li><li id="822b" class="ne nf it jw b jx nn kb no kt np ku nq kv nr kr nj nk nl nm bi translated">用Caffe工具箱建立模型。在这一点上，深度学习库变得越来越受欢迎。</li></ul><h2 id="56c2" class="mr kx it bd ky ms mt dn lc mu mv dp lg kt mw mx lk ku my mz lo kv na nb ls nc bi translated">更深入:GoogLeNet和Inception模块</h2><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/4092171de7bfb2166c7b9f486cda6ba9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*AybOfiQjJFVY2azsVyV2vQ.png"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">Inception Module from GoogLeNet</figcaption></figure><p id="c407" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">GoogLeNet架构是第一个真正解决<strong class="jw iu">计算</strong> <strong class="jw iu">资源</strong>以及<strong class="jw iu">多</strong> - <strong class="jw iu">规模</strong> <strong class="jw iu">处理</strong>的问题的，在论文“<a class="ae ks" href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf" rel="noopener ugc nofollow" target="_blank">用卷积</a>走得更深”。随着我们不断地让我们的分类网络越来越深，我们到达了一个耗尽大量内存的点。此外，过去已经提出了不同的计算滤波器大小:从1x1到11x11你如何决定哪一个？inception模块和GoogLeNet通过以下贡献解决了所有这些问题:</p><ul class=""><li id="0522" class="ne nf it jw b jx jy kb kc kt ng ku nh kv ni kr nj nk nl nm bi translated">通过在每个3x3和5x5之前使用1x1卷积，初始模块减少了通过每层的<strong class="jw iu">特征</strong> <strong class="jw iu">映射</strong>的数量，从而减少了计算和内存消耗！</li><li id="aee2" class="ne nf it jw b jx nn kb no kt np ku nq kv nr kr nj nk nl nm bi translated">初始模块有1x1、3x3和5x5个卷积，都在<strong class="jw iu">并行</strong>中。这背后的想法是让网络通过训练来决定学习和使用什么信息。它还允许<strong class="jw iu">多</strong> - <strong class="jw iu">尺度</strong> <strong class="jw iu">处理</strong>:该模型既可以通过较小的卷积恢复<strong class="jw iu">局部</strong> <strong class="jw iu">特征</strong>，也可以通过较大的卷积恢复<strong class="jw iu">高</strong> <strong class="jw iu">抽象</strong> <strong class="jw iu">特征</strong>。厉害！</li><li id="dff6" class="ne nf it jw b jx nn kb no kt np ku nq kv nr kr nj nk nl nm bi translated">GoogLeNet是第一个引入CNN层不必总是按顺序堆叠的想法的模型之一。这篇论文的作者表明，你还可以增加网络宽度以获得更好的性能，而不仅仅是深度。</li></ul><h2 id="5e64" class="mr kx it bd ky ms mt dn lc mu mv dp lg kt mw mx lk ku my mz lo kv na nb ls nc bi translated">使用快捷方式跳过:ResNet</h2><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nu"><img src="../Images/33fa2e7ad5be5125dff2836953f30000.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*upRhCyZ_sKgRcdQpzIt4xA.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">Residual block from ResNet</figcaption></figure><p id="216e" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">自从2015年首次发表论文“<a class="ae ks" href="https://arxiv.org/pdf/1512.03385.pdf" rel="noopener ugc nofollow" target="_blank">图像识别的深度剩余学习</a>”以来，ResNets已经在许多计算机视觉任务的准确性方面取得了重大进步。ResNet架构是第一个在ImageNet上通过人类水平性能的架构，他们对<strong class="jw iu">残差</strong> <strong class="jw iu">学习</strong>的主要贡献通常默认用于当今许多最先进的网络:</p><ul class=""><li id="cb53" class="ne nf it jw b jx jy kb kc kt ng ku nh kv ni kr nj nk nl nm bi translated">显示出一个<strong class="jw iu">幼稚的</strong> <strong class="jw iu">层层叠加</strong>让网络变得很深并不总是有帮助，实际上还会让事情变得更糟。</li><li id="6c22" class="ne nf it jw b jx nn kb no kt np ku nq kv nr kr nj nk nl nm bi translated">为了解决上述问题，他们引入了跳过连接的剩余学习。其思想是通过使用附加的<strong class="jw iu">跳过</strong> <strong class="jw iu">连接作为快捷方式</strong>，深层具有从先前层直接<strong class="jw iu">访问</strong> <strong class="jw iu">到</strong> <strong class="jw iu">特征</strong>。允许功能信息更容易地通过网络传播。这也有助于训练，因为梯度也可以更有效地反向传播。</li><li id="9f5a" class="ne nf it jw b jx nn kb no kt np ku nq kv nr kr nj nk nl nm bi translated">第一个“<strong class="jw iu">超</strong> <strong class="jw iu">深</strong>”网络，通常使用超过100-200层。</li></ul><h2 id="73fb" class="mr kx it bd ky ms mt dn lc mu mv dp lg kt mw mx lk ku my mz lo kv na nb ls nc bi translated">走极端的捷径:DenseNet</h2><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nv"><img src="../Images/90ed8fa00d0a5cf58e63c3361b1daed7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m8LpfrnNS-bVUC8gil9eVw.jpeg"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">DenseNet visualization</figcaption></figure><p id="5d43" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">随着论文“<a class="ae ks" href="https://arxiv.org/pdf/1608.06993.pdf" rel="noopener ugc nofollow" target="_blank">密集连接的卷积网络</a>”中DenseNets的引入，快捷连接被发挥到了极致。DenseNets扩展了快捷连接的概念，但具有比ResNet更密集的连接:</p><ul class=""><li id="c813" class="ne nf it jw b jx jy kb kc kt ng ku nh kv ni kr nj nk nl nm bi translated">DenseNets以前馈方式将每一层与每一层连接起来。这允许每个层使用在 <strong class="jw iu">层</strong>之前的<strong class="jw iu">所有</strong> <strong class="jw iu">的所有特征图作为输入，并且它自己的特征图被用作所有后续层的输入。</strong></li><li id="d104" class="ne nf it jw b jx nn kb no kt np ku nq kv nr kr nj nk nl nm bi translated">这是通过<strong class="jw iu">连接</strong>完成的，而不是在ResNets中使用的加法，这样原始特征直接通过层。</li><li id="1d79" class="ne nf it jw b jx nn kb no kt np ku nq kv nr kr nj nk nl nm bi translated">显示出<strong class="jw iu">执行</strong> <strong class="jw iu">比ResNets</strong>更好。DenseNets有助于缓解消失梯度问题，加强特征传播，鼓励特征重用，并大大减少参数的数量。</li></ul><p id="96a5" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">这些是在过去几年中形成图像分类进展的主干的主要体系结构。已经取得了很大的进展，这是令人兴奋的，因为它允许使用这种新技术来解决许多现实世界的问题。只剩下一个问题…..</p><h1 id="074f" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">我们将何去何从</h1><p id="a420" class="pw-post-body-paragraph jt ju it jw b jx lu jz ka kb lv kd ke kt lw kh ki ku lx kl km kv ly kp kq kr im bi translated">正如我们刚刚回顾的，针对图像分类的深度学习研究一直在蓬勃发展！我们已经在改进这项任务的方法上迈出了巨大的步伐，甚至超越了人类水平的表现。深度神经网络现在广泛用于许多企业对图像进行分类，甚至是许多新启动技术的基础。</p><p id="e866" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">很高兴看到所有这些进步，但我们必须一直努力改进。深度学习模型在图像分类方面仍然存在许多挑战。如果我们想要前进，这些挑战是必须解决的。在这里，我将回顾其中一些我认为重要的、研究人员正在积极尝试解决的问题:</p><h2 id="20c5" class="mr kx it bd ky ms mt dn lc mu mv dp lg kt mw mx lk ku my mz lo kv na nb ls nc bi translated">从监督学习到非监督学习</h2><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi nw"><img src="../Images/03e7b41606828733a7b9791aeafd2262.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6mPnd6tEA4EsYD1f72hGkA.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">An example of Supervised vs Unsupervised learning</figcaption></figure><p id="b735" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">目前，大多数应用于计算机视觉任务的深度学习方法都是由<strong class="jw iu">监督的</strong>。这意味着我们需要大量的<strong class="jw iu">标记的</strong>训练数据。获取这些数据既繁琐又昂贵。想想看:ImageNet挑战赛有<em class="jv">130万</em>个训练样本，而这仅仅是针对1000个不同的类别！一个人需要得到所有的数据，浏览每一幅图像，并给它贴上标签；好多<strong class="jw iu">手动</strong>T20】工作！</p><p id="4033" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">大多数情况下，当企业想要为自己的特定应用应用图像分类网络时，他们必须使用<strong class="jw iu">迁移学习</strong>来微调预先训练的ImageNet网络。为了进行这种微调，他们仍然需要收集大量自己的数据并对其进行标记；<strong class="jw iu">繁琐</strong>和<strong class="jw iu">昂贵</strong>退一步说。</p><p id="621e" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">研究人员正在积极努力解决这个问题并取得进展。像<strong class="jw iu">快速</strong>和<strong class="jw iu">有效</strong> <strong class="jw iu">转移</strong> <strong class="jw iu">学习</strong><strong class="jw iu">半</strong> - <strong class="jw iu">监督</strong> <strong class="jw iu">学习</strong>和<strong class="jw iu">一次</strong> - <strong class="jw iu">射击</strong> <strong class="jw iu">学习</strong>这样的事情越来越多。我们可能不会直接跳到无监督学习，但这些方法的研究是朝着正确方向迈出的有力一步</p><h2 id="760a" class="mr kx it bd ky ms mt dn lc mu mv dp lg kt mw mx lk ku my mz lo kv na nb ls nc bi translated">抵御我们的敌人</h2><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/fedb70467a323b8ccf93520683e508e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*Nj_toOwx_Hc5NLn97Jv-ww.png"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">Adversarial images can cause major problems</figcaption></figure><p id="38f5" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">使用<strong class="jw iu">生成</strong> <strong class="jw iu">对抗</strong> <strong class="jw iu">网络</strong> (GANs)的日益流行，揭示了图像分类的新挑战:<strong class="jw iu">对抗</strong> <strong class="jw iu">图像</strong>。简而言之，敌对图像的类别对人类来说显而易见，但在深层网络中会导致<strong class="jw iu">大量</strong> <strong class="jw iu">故障</strong>。看看上面的图片。仅仅有一点点扭曲(看起来)，一个深层网络的图像分类就从熊猫变成了长臂猿！</p><p id="06ef" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">对我们人类来说，很明显这个图像仍然是一只熊猫，但出于某种原因，它导致深层网络无法完成任务。这在<strong class="jw iu">真实</strong> - <strong class="jw iu">世界</strong> <strong class="jw iu">应用</strong>中可能是非常危险的:如果你的自动驾驶汽车没有认出一个行人，而是从他们身上碾过去怎么办？部分问题可能源于这样一种想法，即我们并不完全了解我们的网络内部发生了什么。无论如何，研究人员正在积极研究这个具有挑战性的问题。</p><h2 id="12da" class="mr kx it bd ky ms mt dn lc mu mv dp lg kt mw mx lk ku my mz lo kv na nb ls nc bi translated"><strong class="ak">加快进程</strong></h2><figure class="ma mb mc md gt me gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi ny"><img src="../Images/51c5f5e9eebce77a9bce9109e07a8b99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XeJGMg7siqgjI6kQ3gke9A.png"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">MobileNets benchmarking</figcaption></figure><p id="826e" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">深度学习的许多进展都是由硬件的改进推动的，特别是GPU。GPU允许高速处理可以并行完成的计算。由于<strong class="jw iu">矩阵</strong>运算<strong class="jw iu">运算</strong>，深度网络需要大量的乘加运算；GPU擅长执行这些操作。这是一个了不起的进步，但是我们并不是到处都有GPU！</p><p id="0c41" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">许多最先进的网络，包括上面讨论过的网络，只能在高端GPU上以合理的速度运行。<strong class="jw iu">移动</strong> <strong class="jw iu">设备</strong>是一个巨大的市场，采取措施为该市场服务非常重要。此外，随着网络越来越深，它们往往需要更多的内存，从而限制更多的设备运行网络！</p><p id="13ba" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">这一领域的研究最近实际上有了很大进展。<a class="ae ks" href="https://arxiv.org/pdf/1704.04861.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="jw iu"> MobileNets </strong> </a>是一个体系结构家族，已经流行于直接在移动设备上运行深度网络。他们使用不同风格的卷积来减少内存消耗和推理时间。</p><h1 id="1b16" class="kw kx it bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">把一切都包起来</h1><p id="aafa" class="pw-post-body-paragraph jt ju it jw b jx lu jz ka kb lv kd ke kt lw kh ki ku lx kl km kv ly kp kq kr im bi translated">这是一个总结！我们看到了对图像进行分类有多么困难，并回顾了使用深度学习在该领域取得的惊人进展。我们也看到了未来的一些挑战。但是用新的科学和工程来应对这些挑战是技术令人兴奋的地方。</p></div><div class="ab cl nz oa hx ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="im in io ip iq"><h1 id="3e53" class="kw kx it bd ky kz og lb lc ld oh lf lg lh oi lj lk ll oj ln lo lp ok lr ls lt bi translated">喜欢学习？</h1><p id="6b56" class="pw-post-body-paragraph jt ju it jw b jx lu jz ka kb lv kd ke kt lw kh ki ku lx kl km kv ly kp kq kr im bi translated">在<a class="ae ks" href="https://twitter.com/GeorgeSeif94" rel="noopener ugc nofollow" target="_blank">推特</a>上关注我，我会在那里发布所有最新最棒的人工智能、技术和科学！也在LinkedIn 上与我联系！</p></div></div>    
</body>
</html>