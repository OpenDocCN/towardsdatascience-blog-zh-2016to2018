<html>
<head>
<title>Sentiment Analysis of Tweets using Multinomial Naive Bayes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于多项式朴素贝叶斯的微博情感分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sentiment-analysis-of-tweets-using-multinomial-naive-bayes-1009ed24276b?source=collection_archive---------3-----------------------#2018-09-01">https://towardsdatascience.com/sentiment-analysis-of-tweets-using-multinomial-naive-bayes-1009ed24276b?source=collection_archive---------3-----------------------#2018-09-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/82ee77cab04dda58cb370c9b0574e1a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BfwLZAQTqe15mG37cn-Neg.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Based on illustration from <a class="ae kc" href="http://eppsnet.com/2018/05/reflecting-on-mathematical-techniques/" rel="noopener ugc nofollow" target="_blank">http://eppsnet.com/2018/05/reflecting-on-mathematical-techniques/</a>.</figcaption></figure><p id="4fcb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Web 2.0 的普及显著增加了在线交流。因此，它引发了自然语言处理领域，特别是情感分析领域的快速发展研究。信息过载以及评论和消息数量的增长促进了对高性能自动处理方法的需求。</p><p id="dd64" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文致力于使用具有多项式分布的朴素贝叶斯分类器进行二元情感分析。我们简要概述了从概率模型构建分类器，然后进入数据预处理、训练和超参数优化阶段。我们将使用 Jupyter Notebook 用 Python 编写我们的脚本。</p><h1 id="ed01" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">它是如何工作的</h1><p id="acd1" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated"><strong class="kf ir">多项式朴素贝叶斯</strong>分类算法趋向于<strong class="kf ir">情感分析任务的一个基线解</strong>。朴素贝叶斯技术的基本思想是通过使用词和类别的联合概率来找到分配给文本的类别的概率。让我们简单看一下数学。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi me"><img src="../Images/28edce208c4144efe55ca01a9b921ccf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Q7rPID4LsuJ7_6VZ2yU9w.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Bayes’ theorem spelt out in blue neon at the offices of Autonomy in Cambridge.</figcaption></figure><p id="d00d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">给定从属特征向量<strong class="kf ir"> <em class="mj"> (x₁，…，xn) </em> </strong>和类<strong class="kf ir"> <em class="mj"> Ck </em> </strong>。贝叶斯定理在数学上表述为以下关系:</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mk"><img src="../Images/67d614a1a4f033cb565eabab60c0f208.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r438cDWHJNYeQxCFDMe-aQ.jpeg"/></div></div></figure><p id="e13e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据“天真”的条件独立性假设，对于给定的类<strong class="kf ir"> <em class="mj"> Ck </em> </strong>矢量<em class="mj"> </em> <strong class="kf ir"> <em class="mj"> xi </em> </strong>的每个特征都是有条件独立于其他每个特征<strong class="kf ir"><em class="mj">XJ</em></strong>for<strong class="kf ir"><em class="mj">I≠j</em></strong>..</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mk"><img src="../Images/642ca3ba4871ed3b622d5c53fcc0a201.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OejD52tGpuD7GuwdgdVOcg.jpeg"/></div></div></figure><p id="b822" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，该关系可以简化为</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mk"><img src="../Images/74a6fcd808b694817997e4fbd1cb15a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4lDptZbOh7I3_m2C1ZBQdQ.jpeg"/></div></div></figure><p id="9e7f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于<strong class="kf ir"><em class="mj">【p(x₁，…，xn) </em> </strong>是常数，如果特征变量的值是已知的，可以使用下面的分类规则:</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mk"><img src="../Images/01c17fbe0d01a55f7a0e07e12a97fca5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QQSD455fMcX0Hr-Rqw2vYg.jpeg"/></div></div></figure><p id="25de" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了避免下溢，可以使用对数概率。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mk"><img src="../Images/f82c0749fdd940d1b388f4c4db5a40a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J6-E-qNfRqLvE1PUewPUHg.jpeg"/></div></div></figure><p id="c36a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">各种朴素贝叶斯分类器之间的主要区别在于它们对<strong class="kf ir"> <em class="mj"> P(xi|Ck) </em> </strong>的分布所做的假设，而<strong class="kf ir"> <em class="mj"> P(Ck) </em> </strong>通常被定义为训练数据集中类<strong class="kf ir"> <em class="mj"> Ck </em> </strong>的相对频率。</p><p id="9544" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">多项式分布由针对每个类别<strong class="kf ir"><em class="mj">【Ck】</em></strong>的向量<strong class="kf ir"> <em class="mj"> θk=(θk1，…，θkn) </em> </strong>来参数化，其中<strong class="kf ir"> <em class="mj"> n </em> </strong>是特征的数量(即，词汇的大小)，并且<strong class="kf ir"> <em class="mj"> θki </em> </strong>是特征<strong class="kf ir"> <em class="mj">的概率<strong class="kf ir"> <em class="mj"> P(xi|Ck) </em> </strong></em></strong></p><p id="71cc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">参数<strong class="kf ir"> <em class="mj"> θk </em> </strong>通过最大似然的平滑版本，即相对频率计数来估计:</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mk"><img src="../Images/7eca095d0bbc4bccf6a965af08f6d067.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HHTk-uk5og-2fzFa-jlvGw.jpeg"/></div></div></figure><p id="8b4c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<strong class="kf ir"> <em class="mj"> Nki </em> </strong>是特征<strong class="kf ir"> <em class="mj"> i </em> </strong>出现在训练集<strong class="kf ir"> <em class="mj"> T </em> </strong>中类<strong class="kf ir"> <em class="mj"> k </em> </strong>的样本中的次数，而<strong class="kf ir"> <em class="mj"> Ny </em> </strong>是类<strong class="kf ir"> <em class="mj"> Ck </em> </strong>的所有特征的总数。平滑先验<strong class="kf ir"> <em class="mj"> α≥0 </em> </strong>考虑了学习样本中不存在的特征，并防止了进一步计算中的零概率。设置<strong class="kf ir"> <em class="mj"> α=1 </em> </strong>称为拉普拉斯平滑，而<strong class="kf ir"> <em class="mj"> α &lt; 1 </em> </strong>称为李德斯通平滑。</p><p id="4973" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，最终决策规则定义如下:</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mk"><img src="../Images/4bddf45b32dc665cc5806a1e99a6541e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*moXv55OX3pywaabBdudd9w.jpeg"/></div></div></figure><h1 id="ed2c" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">加载情感数据</h1><p id="e846" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">俄语推文的情感数据集[1]可在<a class="ae kc" href="http://study.mokoron.com/" rel="noopener ugc nofollow" target="_blank">http://study.mokoron.com/</a>获得。文件 positive.csv 和 negative.csv 分别包含带正标签和带负标签的推文。</p><pre class="mf mg mh mi gt ml mm mn mo aw mp bi"><span id="0faf" class="mq lc iq mm b gy mr ms l mt mu">import pandas as pd<br/>import numpy as np</span><span id="cf9f" class="mq lc iq mm b gy mv ms l mt mu"># Read the data from CSV files<br/>n = ['id', 'date','name','text','typr','rep','rtw','faw','stcount','foll','frien','listcount']<br/>data_positive = pd.read_csv('positive.csv', sep=';',error_bad_lines=False, names=n, usecols=['text'])<br/>data_negative = pd.read_csv('negative.csv', sep=';',error_bad_lines=False, names=n, usecols=['text'])</span><span id="d1ae" class="mq lc iq mm b gy mv ms l mt mu"># Create balanced dataset<br/>sample_size = min(data_positive.shape[0], data_negative.shape[0])<br/>raw_data = np.concatenate((data_positive['text'].values[:sample_size], <br/>                           data_negative['text'].values[:sample_size]), axis=0) <br/>labels = [1]*sample_size + [0]*sample_size</span></pre><h1 id="747c" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">预处理数据</h1><p id="c475" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">社交媒体网站中由人类生成的文本包含大量噪声，这些噪声会显著影响情感分类过程的结果。此外，根据特征生成方法的不同，每个新术语似乎都给特征空间增加了至少一个新的维度。这使得特征空间更加稀疏和高维。因此，分类器的任务变得更加复杂。</p><p id="c009" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了准备消息，在该程序中使用了文本预处理技术，如用关键字替换 URL 和用户名、删除标点符号以及转换成小写字母。</p><pre class="mf mg mh mi gt ml mm mn mo aw mp bi"><span id="6384" class="mq lc iq mm b gy mr ms l mt mu">import re</span><span id="32b6" class="mq lc iq mm b gy mv ms l mt mu">def preprocess_text(text):<br/>    text = re.sub('((www\.[^\s]+)|(https?://[^\s]+))','URL', text)<br/>    text = re.sub('@[^\s]+','USER', text)<br/>    text = text.lower().replace("ё", "е")<br/>    text = re.sub('[^a-zA-Zа-яА-Я1-9]+', ' ', text)<br/>    text = re.sub(' +',' ', text)<br/>    return text.strip()</span><span id="a1dc" class="mq lc iq mm b gy mv ms l mt mu">data = [preprocess_text(t) for t in raw_data]cc</span></pre><h1 id="7615" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">训练多项式朴素贝叶斯</h1><p id="3278" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">管道类用于使矢量器= &gt;转换器= &gt;分类器更容易使用。诸如 n-grams 范围、IDF 使用、TF-IDF 规范化类型和朴素贝叶斯 alpha 之类的超参数使用网格搜索来调整。所选超参数的性能是在模型训练步骤中未使用的测试集上测量的。</p><pre class="mf mg mh mi gt ml mm mn mo aw mp bi"><span id="0333" class="mq lc iq mm b gy mr ms l mt mu">from sklearn.pipeline import Pipeline<br/>from sklearn.naive_bayes import MultinomialNB<br/>from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer<br/>from sklearn.model_selection import train_test_split, GridSearchCV</span><span id="2d2f" class="mq lc iq mm b gy mv ms l mt mu">text_clf = Pipeline([('vect', CountVectorizer()),<br/>                     ('tfidf', TfidfTransformer()),<br/>                     ('clf', MultinomialNB())])</span><span id="05d9" class="mq lc iq mm b gy mv ms l mt mu">tuned_parameters = {<br/>    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],<br/>    'tfidf__use_idf': (True, False),<br/>    'tfidf__norm': ('l1', 'l2'),<br/>    'clf__alpha': [1, 1e-1, 1e-2]<br/>}</span></pre><p id="d7b4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据集被分成训练和测试子集。</p><pre class="mf mg mh mi gt ml mm mn mo aw mp bi"><span id="8009" class="mq lc iq mm b gy mr ms l mt mu">x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.33, random_state=42)</span></pre><p id="ea7e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后启动了 10 重交叉验证的网格搜索。</p><pre class="mf mg mh mi gt ml mm mn mo aw mp bi"><span id="eda8" class="mq lc iq mm b gy mr ms l mt mu">from sklearn.metrics import classification_report</span><span id="43d1" class="mq lc iq mm b gy mv ms l mt mu">clf = GridSearchCV(text_clf, tuned_parameters, cv=10, scoring=score)<br/>clf.fit(x_train, y_train)<br/><br/>print(classification_report(y_test, clf.predict(x_test), digits=4))</span></pre><p id="1bff" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">测试数据集的分类报告如下所示。</p><pre class="mf mg mh mi gt ml mm mn mo aw mp bi"><span id="4c1f" class="mq lc iq mm b gy mr ms l mt mu">precision    recall  f1-score   support<br/><br/>          0     0.7397    0.7941    0.7659     37078<br/>          1     0.7759    0.7183    0.7460     36792<br/><br/>avg / total     0.7577    0.7564    0.7560     73870</span></pre><p id="cbd8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据网格搜索结果，在开发集上找到的最佳参数集如下:<code class="fe mw mx my mm b">clf__alpha=1</code>、<code class="fe mw mx my mm b">tfidf__norm=l2</code>、<code class="fe mw mx my mm b">tfidf__use_idf=True</code>、<code class="fe mw mx my mm b">vect__ngram_range=(1, 2)</code>。</p><h1 id="8508" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结果</h1><p id="c4cd" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">在开发集上训练的模型在评估集上展示了<strong class="kf ir"> <em class="mj"> F₁=0.765 </em> </strong>。通过使用词干化、规范化、句法和语义特征等技术，分类度量可能会得到更大的提高。</p><p id="d0b4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Github 提供了源代码。</p><div class="mz na gp gr nb nc"><a href="https://github.com/sismetanin/sentiment-analysis-of-tweets-in-russian/blob/master/Sentiment%20Analysis%20of%20Tweets%20in%20Russian%20using%20Multinomial%20Naive%20Bayes.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab fo"><div class="ne ab nf cl cj ng"><h2 class="bd ir gy z fp nh fr fs ni fu fw ip bi translated">俄语推文情感分析</h2><div class="nj l"><h3 class="bd b gy z fp nh fr fs ni fu fw dk translated">使用嵌入 Word2Vec 的卷积神经网络(CNN)对俄语推文进行情感分析。…</h3></div><div class="nk l"><p class="bd b dl z fp nh fr fs ni fu fw dk translated">github.com</p></div></div><div class="nl l"><div class="nm l nn no np nl nq jw nc"/></div></div></a></div><h1 id="7607" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">参考</h1><ol class=""><li id="417f" class="nr ns iq kf b kg lz kk ma ko nt ks nu kw nv la nw nx ny nz bi translated">Y.Rubtsova，“为情感分类训练构建语料库”，《软件与系统》，第 109 卷，第 1 期，第 72–78 页，2015 年。</li><li id="07b4" class="nr ns iq kf b kg oa kk ob ko oc ks od kw oe la nw nx ny nz bi translated">《朴素贝叶斯》，scikit-learn.org，2018 年。【在线】。可用:<a class="ae kc" href="http://scikit-learn.org/stable/modules/naive_bayes.html" rel="noopener ugc nofollow" target="_blank">http://scikit-learn.org/stable/modules/naive_bayes.html</a>。[访问日期:2018 年 8 月 26 日]。</li><li id="5531" class="nr ns iq kf b kg oa kk ob ko oc ks od kw oe la nw nx ny nz bi translated">“使用文本数据”，scikit-learn.org，2018 年。【在线】。可用:<a class="ae kc" href="http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/tutorial/text _ analytics/working _ with _ text _ data . html</a>。[访问日期:2018 年 8 月 26 日]。</li></ol></div></div>    
</body>
</html>