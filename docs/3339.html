<html>
<head>
<title>Deep Learning for Named Entity Recognition #1: Public Datasets and Annotation Methods</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">命名实体识别的深度学习#1:公共数据集和标注方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-for-ner-1-public-datasets-and-annotation-methods-8b1ad5e98caf?source=collection_archive---------1-----------------------#2018-05-04">https://towardsdatascience.com/deep-learning-for-ner-1-public-datasets-and-annotation-methods-8b1ad5e98caf?source=collection_archive---------1-----------------------#2018-05-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/78c3510dbdb9463233317ef238c9aa8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hm2rIVW6fNGstDKhjfYAHQ.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="dffd" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">欢迎来到我的“命名实体识别的深度学习”系列的第一篇文章——让我们从访问高质量数据集开始！🚀</h2></div><figure class="kr ks kt ku gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi kq"><img src="../Images/e6f4d659dca2f95496e4530f423d9d90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SUtifer99j7Quir20uOvBQ.png"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Need for data: Deep Learning for NER requires thousands of training points to achieve reasonable accuracy.</figcaption></figure><p id="bb05" class="pw-post-body-paragraph kz la jb lb b lc ld kc le lf lg kf lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">在撰写关于使用深度学习进行命名实体识别(NER)的硕士论文时，我将在一系列帖子中分享我的学习成果。主题包括如何以及在哪里找到有用的数据集(本帖！)，最先进的实现以及今年晚些时候一系列深度学习模型的利弊。</p></div><div class="ab cl lv lw hu lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="ij ik il im in"><h1 id="7f67" class="mc md jb bd me mf mg mh mi mj mk ml mm kh mn ki mo kk mp kl mq kn mr ko ms mt bi translated"><strong class="ak">公共数据集</strong></h1><p id="58fd" class="pw-post-body-paragraph kz la jb lb b lc mu kc le lf mv kf lh li mw lk ll lm mx lo lp lq my ls lt lu ij bi translated">与任何深度学习模型一样，你需要<em class="mz">大量</em>数据。高质量的数据集是任何深度学习项目的基础。幸运的是，有几个带注释的、公开的、大部分免费的数据集。</p><h2 id="80a6" class="na md jb bd me nb nc dn mi nd ne dp mm li nf ng mo lm nh ni mq lq nj nk ms nl bi translated">CoNLL 2003</h2><p id="40b1" class="pw-post-body-paragraph kz la jb lb b lc mu kc le lf mv kf lh li mw lk ll lm mx lo lp lq my ls lt lu ij bi translated">这个<a class="ae nm" href="https://www.clips.uantwerpen.be/conll2003/ner/" rel="noopener ugc nofollow" target="_blank">数据集</a>包括1393篇英语和909篇德语新闻文章。英语语料库是免费的，但不幸的是，德语语料库要75美元。这是本帖中唯一有价值的语料库。为了建立英语语料库，你需要RCV1 <a class="ae nm" href="https://trec.nist.gov/data/reuters/reuters.html" rel="noopener ugc nofollow" target="_blank">路透社语料库</a>。您将在提交组织和个人协议几天后免费获得访问权限。</p><p id="927f" class="pw-post-body-paragraph kz la jb lb b lc ld kc le lf lg kf lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">实体标注有<strong class="lb jc"> LOC </strong>(位置)<strong class="lb jc"> ORG </strong>(组织)<strong class="lb jc"> PER </strong>(人员)和<strong class="lb jc"> MISC </strong>(其他)。这是一个例句，每行由[单词][词性标签][组块标签] [NER标签]组成:</p><blockquote class="nn no np"><p id="3062" class="kz la mz lb b lc ld kc le lf lg kf lh nq lj lk ll nr ln lo lp ns lr ls lt lu ij bi translated"><em class="jb">联合国</em> NNP I-NP I-ORG <br/> <em class="jb">官方</em> NN I-NP O <br/> <em class="jb">埃克乌斯</em> NNP I-NP I-PER <br/> <em class="jb">首脑</em> VBZ I-VP O <br/> <em class="jb">为I-PP O <br/> <em class="jb">巴格达</em> NNP I-NP I-LOC <br/> <em class="jb">。</em>。哦哦</em></p></blockquote><p id="f6f4" class="pw-post-body-paragraph kz la jb lb b lc ld kc le lf lg kf lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">这里有一个<a class="ae nm" href="https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html" rel="noopener ugc nofollow" target="_blank">POS标签代表什么的综合列表</a>。这是官方的2003年CoNLL介绍文件和GitHub wiki的SOTA排名。</p><h2 id="48f5" class="na md jb bd me nb nc dn mi nd ne dp mm li nf ng mo lm nh ni mq lq nj nk ms nl bi translated">onto notes 5.0/2012年</h2><p id="2a52" class="pw-post-body-paragraph kz la jb lb b lc mu kc le lf mv kf lh li mw lk ll lm mx lo lp lq my ls lt lu ij bi translated">OntoNotes版由1，745，000，000，000，000，000，000，000，000，000，000，000，000，000，000，000，000，000，000，000，000，000，000，000，000，000，000，000，000，000，0000个阿拉伯文本数据组成，这些数据来自一系列来源:电话交谈，新闻专线，广播新闻，广播，广播，广播对话和网络博客。实体标注有<strong class="lb jc">人</strong>、<strong class="lb jc">组织</strong>、<strong class="lb jc">地点</strong>等类别(此处18个类别<a class="ae nm" href="https://catalog.ldc.upenn.edu/docs/LDC2013T19/OntoNotes-Release-5.0.pdf" rel="noopener ugc nofollow" target="_blank">的完整列表，第21页)。通过你的大学/系获得访问权是最容易的——当你在这里</a>注册<a class="ae nm" href="https://catalog.ldc.upenn.edu/signup" rel="noopener ugc nofollow" target="_blank">时检查。</a></p><h2 id="302c" class="na md jb bd me nb nc dn mi nd ne dp mm li nf ng mo lm nh ni mq lq nj nk ms nl bi translated">i2b2挑战</h2><p id="6787" class="pw-post-body-paragraph kz la jb lb b lc mu kc le lf mv kf lh li mw lk ll lm mx lo lp lq my ls lt lu ij bi translated">整合生物学和床边信息学(i2b2)中心发布了大量NER的<a class="ae nm" href="https://www.i2b2.org/NLP/DataSets/Download.php" rel="noopener ugc nofollow" target="_blank">临床数据集</a>。特别是2009年(提取药物)，2012年(提取问题，治疗等。)和2014年(提取疾病、危险因素、用药等。)挑战是非常相关的，包括<a class="ae nm" href="https://www.i2b2.org/NLP/DataSets/Main.php" rel="noopener ugc nofollow" target="_blank">记录良好的最先进的实施</a>。获得访问权是免费的——它需要签署一份<a class="ae nm" href="https://www.i2b2.org/NLP/DataSets/AgreementAR.php" rel="noopener ugc nofollow" target="_blank">协议</a>，声明你基本上是以体谅的态度对待数据的。i2b2回复很快！</p><h2 id="183a" class="na md jb bd me nb nc dn mi nd ne dp mm li nf ng mo lm nh ni mq lq nj nk ms nl bi translated">更多数据</h2><p id="9fe3" class="pw-post-body-paragraph kz la jb lb b lc mu kc le lf mv kf lh li mw lk ll lm mx lo lp lq my ls lt lu ij bi translated">我没有详细查看其他数据集，但它们可能对您的应用程序仍然有用:<a class="ae nm" href="http://www.nactem.ac.uk/tsujii/GENIA/ERtask/report.html" rel="noopener ugc nofollow" target="_blank"> NLPBA 2004 </a>标记有蛋白质/DNA/RNA/细胞系/细胞类型(2,404 MEDLINE摘要)和<a class="ae nm" href="http://www.cs.cmu.edu/~enron/" rel="noopener ugc nofollow" target="_blank"> Enron电子邮件</a>标记有姓名/日期/时间(大约500 K条消息)。</p><h1 id="9d14" class="mc md jb bd me mf nt mh mi mj nu ml mm kh nv ki mo kk nw kl mq kn nx ko ms mt bi translated">注释方法</h1><p id="4c9b" class="pw-post-body-paragraph kz la jb lb b lc mu kc le lf mv kf lh li mw lk ll lm mx lo lp lq my ls lt lu ij bi translated">了解不同的注释模式需要一些时间。有许多框架，从标记方法(类似HTML)到键值对。</p><h2 id="eb76" class="na md jb bd me nb nc dn mi nd ne dp mm li nf ng mo lm nh ni mq lq nj nk ms nl bi translated">标记(例如OntoNotes 5.0)</h2><p id="bf64" class="pw-post-body-paragraph kz la jb lb b lc mu kc le lf mv kf lh li mw lk ll lm mx lo lp lq my ls lt lu ij bi translated">这种注释方法使用带有尖括号的标记标签来定义命名实体，例如组织:</p><blockquote class="nn no np"><p id="6f09" class="kz la mz lb b lc ld kc le lf lg kf lh nq lj lk ll nr ln lo lp ns lr ls lt lu ij bi translated">迪士尼是一个全球品牌。</p></blockquote><h2 id="0d7a" class="na md jb bd me nb nc dn mi nd ne dp mm li nf ng mo lm nh ni mq lq nj nk ms nl bi translated">IOB(如CoNLL 2003)</h2><p id="3519" class="pw-post-body-paragraph kz la jb lb b lc mu kc le lf mv kf lh li mw lk ll lm mx lo lp lq my ls lt lu ij bi translated">IOB(或BIO)代表<strong class="lb jc"> B </strong>内，<strong class="lb jc"> I </strong>内，<strong class="lb jc"> O </strong>外。用O标记的单词在命名实体之外，而<em class="mz"> I-XXX </em>标记用于类型为<em class="mz"> XXX </em>的命名实体内的单词。每当两个类型为<em class="mz"> XXX </em>的实体彼此紧邻时，第二个实体的第一个单词将被标记为<em class="mz"> B-XXX </em>以突出显示它开始另一个实体。下面是一个例句，每行由[单词][词性标签] [NER标签]组成:</p><blockquote class="nn no np"><p id="f42b" class="kz la mz lb b lc ld kc le lf lg kf lh nq lj lk ll nr ln lo lp ns lr ls lt lu ij bi translated"><em class="jb">我们</em>PRP B-NP<br/>T17】看见了VBD O<br/>T20】那个DT B-NP<br/>T23】黄JJ I-NP<br/>T26】狗 NN I-NP</p></blockquote><h2 id="badc" class="na md jb bd me nb nc dn mi nd ne dp mm li nf ng mo lm nh ni mq lq nj nk ms nl bi translated">北京生物工程学院</h2><p id="631f" class="pw-post-body-paragraph kz la jb lb b lc mu kc le lf mv kf lh li mw lk ll lm mx lo lp lq my ls lt lu ij bi translated">一种更复杂的注释方法区分命名实体和单个实体的结尾。这种方法被称为内侧、<strong class="lb jc">B、</strong>n、<strong class="lb jc"> O、</strong>n、<strong class="lb jc"> E、</strong>d、<strong class="lb jc"> S、</strong>S。上述数据集都没有使用现成的BIOES，但它显示出比BIO有相当大的性能改进(例如<em class="mz"> Chiu和Nichols，2016 </em>)。</p><h2 id="6a68" class="na md jb bd me nb nc dn mi nd ne dp mm li nf ng mo lm nh ni mq lq nj nk ms nl bi translated">更多方法和细节</h2><p id="2cf1" class="pw-post-body-paragraph kz la jb lb b lc mu kc le lf mv kf lh li mw lk ll lm mx lo lp lq my ls lt lu ij bi translated">这里有一篇<a class="ae nm" href="https://lingpipe-blog.com/2009/10/14/coding-chunkers-as-taggers-io-bio-bmewo-and-bmewo/" rel="noopener ugc nofollow" target="_blank">很棒的博文</a>关于进一步的注释方法及其复杂性。</p></div><div class="ab cl lv lw hu lx" role="separator"><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma mb"/><span class="ly bw bk lz ma"/></div><div class="ij ik il im in"><p id="7001" class="pw-post-body-paragraph kz la jb lb b lc ld kc le lf lg kf lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">第一篇帖子到此结束。理解可用的数据以及如何对其进行注释，为您以后构建可靠的统计模型提供了良好的基础。让我知道你是否找到了其他有用的数据来源！👋</p></div></div>    
</body>
</html>