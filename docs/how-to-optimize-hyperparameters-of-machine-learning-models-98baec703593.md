# 如何优化机器学习模型的超参数

> 原文：<https://towardsdatascience.com/how-to-optimize-hyperparameters-of-machine-learning-models-98baec703593?source=collection_archive---------9----------------------->

![](img/a4bd2aed0da8f7c0451697514da17ac0.png)

Photo by [Todd Quackenbush](https://unsplash.com/@toddquackenbush?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

寻找超参数的最佳组合是许多机器学习应用的核心。在这篇文章中，我将给你一个简要的概述和三个主要方法的示例。

在我最近的一个项目中，我发现自己处于一个太熟悉的情况。我获得了一组漂亮的数据。我完成了数据清理和特征工程的第一次迭代。最后，我准备好释放我们作为数据科学家向世界承诺的所有潜力。经过几次初步实验后，我们选定了梯度推进算法。但是，如何找到超参数的最佳配置呢？这就是这篇博文的内容。

在这篇文章中，我将带你看一个基本的例子，并对它应用三种不同的方法。我的目标是为你提供一个坚实的直觉，作为进一步调查的基础。如果你想做一些自己的实验，或者如果你需要一个地方开始你的优化之旅，所有的细节和必要的代码都可以作为一个 [Jupyter 笔记本](https://github.com/timo-boehm/material_blog_posts)获得。

# 如何预测成功的众筹项目？

我的一个朋友正在准备一个 Kickstarter 活动，所以我决定用这个地区作为这篇文章的例子。多亏了[米卡埃尔·穆莱](https://www.kaggle.com/kemical)，在 [Kaggle](https://www.kaggle.com/kemical/kickstarter-projects) 上有一个精彩的数据集。我抽样了 1000 个项目，其中大约 36%是成功的。我的目标是根据以下信息预测活动是否成功:

*   项目的类别(一般和更具体)，例如“电影”或“书籍”。
*   项目来源国(美国占 77%)。
*   以美元为单位的筹资目标。幸运的是，这个转换已经包含在数据集中了。

我将类别和国家转换成虚拟变量，所以最终大约有 200 个可用的特性。

> **免责声明 1:** 我说明性地使用数据，而不是你在实际应用中应该如何处理它。对于这个帖子，我采用了数据，并将其视为干净可靠的。我也没有任何特征工程等。

和项目类似，我用的是梯度提升算法(这里是 sklearn 的[gradientboostingclassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html))。这组算法有许多超参数，但我专注于其中的两个以保持简洁明了:学习速率和特征的数量。

学习率调整算法更新的速度。如果太高，算法会快速跳转，可能会错过最佳解决方案。如果太低，算法可能需要很长时间才能最终稳定下来。诚然，这是一个粗略的总结，但希望表明，找到最佳点是至关重要的。

特征的数量决定了底层关系允许有多复杂。太复杂会导致过度拟合。另一方面，缺乏复杂性阻止了算法检测特征和目标之间的有用关系。

总之，我们已经准备好了数据集，确定了算法，并决定了我们想要优化的两个超参数。现在怎么办？在我们回到玩具的例子之前，让我们考虑三个选择。

# 选项 1:尝试所有组合

我们生活在一个计算能力无限的时代，对吗？如果这是真的，让我们尝试所有可能的配置，在测试集上比较它们的性能，并选择最佳配置。这就是**网格搜索**建立的目的。这种方法并不意味着精确或高效；这是一把猎枪。如果您有一组参数的完美组合可以隐藏的地方，网格搜索会瞄准所有这些地方并返回最佳选择。

让我们假设我定义了五个不同的学习率，以及五个不同的模型允许使用的最大特征数的值。然后，grid search 训练 25 个(5 * 5)不同的模型，评估所有模型，并返回在我选择的度量中得分最高的超参数配置。到目前为止一切顺利。

然而，正如您已经预料到的，这种方法的运行时间可能会很长。如果要检查三个超参数的十个不同值，网格搜索需要计算 10 * 10 * 10，也就是 1000(！)模特。让我们添加 3 重交叉验证，我们需要训练 3000 个模型！虽然对于网格搜索何时不再可行没有客观的阈值，但是这种方法的缺点是显而易见的。

# 选项 2:尝试尽可能多的组合

我不确定这是否会随着量子计算而改变，但目前，我必须在有限的计算能力下工作。因此，我无法测试所有可能的超参数组合。相反，我想尽可能多地测试它们，我将使用**随机搜索**来完成这项工作。由于我不知道最佳配置，所以这种方法随机选择一组组合并测试它们。

与网格搜索相比，有两个主要优势:

1.  我可以定义迭代次数，即搜索算法测试的可能组合的数量。通过这样做，我可以决定我可用的计算预算。也许它很小，因为下一次结果的展示就要开始了。也许我的预算很重要，因为我周末离开，同时可以让我的机器保持运转。关键是，我现在控制了局面。
2.  由于组合的选择是随机的，所以我可以使用分布来代替固定的一组值。对于网格搜索，我需要定义一组不同的最大特征，例如[1，10，30，50]。在随机搜索中，我可以定义特征的最大数量必须在 1 到 50 之间，并且中间的每个整数的概率相等。

这两点都改进了网格搜索。然而，让我们来解决房间里的大象:如果组合的选择是随机的，我找到最佳模型(或者至少是合理接近它的模型)的可能性有多大？好在答案是:很有可能。明确地说:如果我的网格包括 1000 种组合，而我只随机选择了其中的 10 种，我就有麻烦了。然而，一篇研究论文显示，如果网格中 5%的组合导致最佳结果，60 次随机搜索迭代足以有超过 95%的把握找到这些点中的一个(参见[此处](http://www.jmlr.org/papers/v13/bergstra12a.html)获得实际论文，以及[此处](https://www.oreilly.com/ideas/evaluating-machine-learning-models/page/5/hyperparameter-tuning)获得额外解释)。

要点:网格搜索是有时间/资源和非理性高度风险厌恶的人可能会尝试的。然而，随机搜索是所有实际数据科学问题的首选算法。

如果你和我一样，你还是不满足。原因是*这个词随机化了*。现在有很多关于人工智能的讨论，因此必须有一种更智能的方法来选择超参数组合。如果我们使用一种算法来学习看哪里，那不是很好吗？

# 选项 3:尝试最有希望的组合

我坚持我对每个超参数的可能值范围的想法。然而，这一次，该算法不会测试所有的组合(网格搜索)或随机选择其中的一些组合(随机搜索)，而是反复重新评估下一步在哪里寻找。从概念上讲，我们现在正在进入**知情搜索**的领域。

> **免责声明 2** :我在这里讨论贝叶斯优化，但是，尽管这是一个流行的选择，它只是一个有根据的搜索算法的例子。在我看来，这是最容易从概念上理解的，但这并不意味着它一定是最好的选择。有关方法和实现的更多细节，请查看此处的[和此处的](/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a)和。

要理解这个想法，请跟着我看一个基本的例子。假设我用随机选择的超参数值计算了第一个模型。其准确率为 67%。现在我用另一组超参数计算一个模型，它产生的准确率只有 64%。贝叶斯方法降低了为第二模型选择的值是最优解的一部分的概率。现在，它使用更新的概率为每个超参数选择一组新值，查看它是提高还是降低了模型的质量，并更新概率。换句话说，该算法更有可能为下一轮选择与较高模型性能相关的值，而不是那些不太有效的替代值。

关注更新概率的概念是至关重要的。有希望的值更有可能被选中，但仍有一些随机性。这个过程确保算法对新的可能性保持开放。如果想深入挖掘这个问题，谷歌“探索 vs 剥削”。

# 那么这些 Kickstarter 活动呢？

在我回到我的玩具例子之前，这里是关于三个选项的最关键点:

*   **网格搜索**是一种强力方法，它测试超参数的所有组合，以找到最佳模型。它的运行时随着要测试的值(及其组合)的数量而爆炸。
*   **随机搜索**通过将自己限制在限定数量的组合中进行尝试来减少运行时间。因为这种方法可能找到接近最佳的解决方案，所以比网格搜索更可取。
*   **知情搜索**(贝叶斯优化作为其实现之一)通过反复重新评估寻找最佳位置增加了一些额外的开销。这种开销可以通过更有效的搜索来平衡。这种方法经常出现在 Kaggle 比赛中是有原因的。

现在，让我们看看 Kickstarter 项目(再次，见[这里](https://github.com/timo-boehm/material_blog_posts)一个 Jupyter 笔记本)。如上所述，我只调整学习率(在 0.005 和 0.2 之间)和最大特征数(在一个和所有可用特征之间)来对数据训练梯度推进模型。以下是我们三个选项的结果:

1.  **网格搜索**:我使用 *numpy* 为两个超参数定义了五个均匀间隔的值，总共有 25 个组合要测试。达到 **0.626** 的 [AUC 分数](http://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics)花费了大约 **8 秒**。
2.  **随机搜索:**这次我用了一个 *scipy* 函数，让特征数量的选择更加灵活。一个特征和所有特征之间的所有值被选择的可能性是相等的。为了增加难度，我只允许 12 次迭代。大约 **4 秒**后得到的 AUC 分数为 **0.617。**比网格搜索略差。
3.  **Informed Search**:*hyperopt*提供了一些非常有用的函数来模拟超参数的分布。对于学习率，我使用了一个使较小值比大值更有可能的分布。我决定用 25 次迭代。在大约 **7 秒**之后，该模型获得了 **0.635** 的 AUC 分数。

我想说清楚:这是一个用于说明目的的玩具示例。请按照我在这篇博文中提供的链接进行比较和评估。尽管如此，我希望这篇介绍能在两个方面帮助你。首先，让您可以方便地访问主题和一些可以在项目中使用的代码片段。第二，激励你更深入地挖掘超参数优化的主题。

**感谢阅读！**如果您有任何反馈或想告诉我您在超参数优化方面的体验，我很高兴收到您的来信！你可以在推特[和领英](https://twitter.com/TimoBohm)上找到我。让我们继续学习吧！