<html>
<head>
<title>“COLLABORATIVE FILTERING FROM SCRATCH”</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">“从零开始的协作过滤”</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fast-ai-season-1-episode-5-2-collaborative-filtering-from-scratch-1877640f514a?source=collection_archive---------14-----------------------#2018-10-24">https://towardsdatascience.com/fast-ai-season-1-episode-5-2-collaborative-filtering-from-scratch-1877640f514a?source=collection_archive---------14-----------------------#2018-10-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="74aa" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">从头开始构建电影推荐的协同过滤</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/fb87e1172ac8dd7059a16bb6837ab4dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*RL0nsiB2ntI3xooIRf6jmQ.jpeg"/></div></figure><p id="4127" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">欢迎来到第五集<a class="ae lj" href="http://www.fast.ai/" rel="noopener ugc nofollow" target="_blank"> Fastdotai </a>的第二部分，我们将从零开始讲述<strong class="kp ir">协同过滤——一种广泛应用于推荐系统的技术</strong>。在我们开始之前，我想感谢<a class="ae lj" href="https://twitter.com/jeremyphoward" rel="noopener ugc nofollow" target="_blank"> <strong class="kp ir">【杰瑞米·霍华德】</strong> </a>和<a class="ae lj" href="https://twitter.com/math_rachel" rel="noopener ugc nofollow" target="_blank"> <strong class="kp ir">雷切尔·托马斯</strong> </a>为民主化人工智能所做的努力。</p><p id="3640" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了充分利用这个博客系列，请按照以下顺序随意探索这个系列的第一部分</p><ol class=""><li id="4bf2" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-1-e9cc80d81a9d">狗 Vs 猫图像分类</a></li><li id="6c08" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60">犬种图像分类</a></li><li id="33c2" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889">多标签图像分类</a></li><li id="cdb5" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-4-1-time-series-analysis-a23217418bf1">使用神经网络的时间序列分析</a></li><li id="f7a8" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/nlp-sentiment-analysis-on-imdb-movie-dataset-fb0c4d346d23" rel="noopener">IMDB 电影数据集上的自然语言处理情感分析</a></li><li id="0790" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-1-movie-recommendation-using-fastai-a53ed8e41269">电影推荐系统的基础</a></li><li id="25b8" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-2-collaborative-filtering-from-scratch-1877640f514a">从零开始协同过滤</a></li><li id="4481" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-3-collaborative-filtering-using-neural-network-48e49d7f9b36">使用神经网络的协同过滤</a></li><li id="10e3" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/fast-ai-season-1-episode-6-1-write-philosophy-like-nietzsche-using-rnn-8fe70cfb923c" rel="noopener">像尼采一样写哲学</a></li><li id="841f" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/fast-ai-season-1-episode-7-1-performance-of-different-neural-networks-on-cifar-10-dataset-c6559595b529" rel="noopener">不同神经网络在 Cifar-10 数据集上的性能</a></li><li id="f934" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://medium.com/hackernoon/single-object-detection-e65a537a1c31" rel="noopener">检测图像中最大物体的 ML 模型 Part-1 </a></li><li id="94d1" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://medium.com/hackernoon/single-object-detection-part-2-2deafc911ce7" rel="noopener">检测图像中最大物体的 ML 模型 Part-2 </a></li></ol><p id="563d" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">网飞背后的原因和寒意。</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ly lz l"/></div></figure><p id="c5fc" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">首先，让我们导入所有需要的包。</p><pre class="kg kh ki kj gt ma mb mc md aw me bi"><span id="cc78" class="mf mg iq mb b gy mh mi l mj mk">%reload_ext autoreload<br/>%autoreload 2<br/>%matplotlib inline</span><span id="b5ae" class="mf mg iq mb b gy ml mi l mj mk">from fastai.learner import *<br/>from fastai.column_data import *</span></pre><p id="93d5" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">设置路径的位置</p><ul class=""><li id="4a6f" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mm lq lr ls bi translated">输入数据被存储。</li><li id="b7fd" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mm lq lr ls bi translated">将存储临时文件。(可选-在 kaggle 内核中使用)</li><li id="9bb3" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mm lq lr ls bi translated">模型重量将被存储。(可选-在 kaggle 内核中使用)</li></ul><pre class="kg kh ki kj gt ma mb mc md aw me bi"><span id="bcc2" class="mf mg iq mb b gy mh mi l mj mk">path='../input/'<br/>tmp_path='/kaggle/working/tmp/'<br/>models_path='/kaggle/working/models/'</span></pre><ul class=""><li id="5c4b" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mm lq lr ls bi translated">数据的读取。</li></ul><pre class="kg kh ki kj gt ma mb mc md aw me bi"><span id="3233" class="mf mg iq mb b gy mh mi l mj mk">ratings = pd.read_csv(path+'ratings.csv')<br/>ratings.head()<br/># This contains the userid , the movie that the userid watched , the time that movie has been watched , the ratings that has provided by the user .</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mn"><img src="../Images/4e0fa89868273e0a19138e8384c77750.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*-zd8HFQHTWbOEXtGanvk0Q.png"/></div></div></figure><pre class="kg kh ki kj gt ma mb mc md aw me bi"><span id="34ba" class="mf mg iq mb b gy mh mi l mj mk">movies = pd.read_csv(path+'movies.csv')<br/>movies.head()<br/># This table is just for information purpose and not intended for         # modelling purpose</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/ba816f35341110482f3c34d6a5adc4a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*wquV6nC2fwUgVMjBmT7g4A.png"/></div></figure><pre class="kg kh ki kj gt ma mb mc md aw me bi"><span id="d4b6" class="mf mg iq mb b gy mh mi l mj mk">u_uniq = ratings.userId.unique() <br/>user2idx = {o:i for i,o in enumerate(u_uniq)}<br/># Take every unique user id and map it to a contiguous user .<br/>ratings.userId = ratings.userId.apply(lambda x: user2idx[x])<br/># Replace that userid with contiguous number.</span><span id="5059" class="mf mg iq mb b gy ml mi l mj mk"># Similarly, we do it for the movies. <br/>m_uniq = ratings.movieId.unique()<br/>movie2idx = {o:i for i,o in enumerate(m_uniq)}<br/>ratings.movieId = ratings.movieId.apply(lambda x: movie2idx[x])<br/></span></pre><p id="2306" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">将 movieId 和 userId 转换成连续的整数有助于我们决定嵌入矩阵。这些 userId 和 movieID 的值在开始时不连续。它可能从 100 万开始，并且不会是连续的。因此，如果我们使用这些值来决定我们的嵌入矩阵，那么嵌入矩阵的大小将会太大，这可能会导致缓慢的处理或过拟合。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/c4222c3c56db7fc06ac41937df7c2ac7.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*97-tdnBwqO0kh__4xC-ymQ.png"/></div></figure><pre class="kg kh ki kj gt ma mb mc md aw me bi"><span id="ebe3" class="mf mg iq mb b gy mh mi l mj mk">class EmbeddingDot(nn.Module):<br/>    def __init__(self, n_users, n_movies):<br/>        super().__init__()<br/>        self.u = nn.Embedding(n_users, n_factors)<br/>        self.m = nn.Embedding(n_movies, n_factors)<br/>        self.u.weight.data.uniform_(0,0.05)<br/>        self.m.weight.data.uniform_(0,0.05)<br/>        <br/>    def forward(self, cats, conts):<br/>        users,movies = cats[:,0],cats[:,1]<br/>        u,m = self.u(users),self.m(movies)<br/>        return (u*m).sum(1).view(-1, 1)</span><span id="5cbd" class="mf mg iq mb b gy ml mi l mj mk">model = EmbeddingDot(n_users, n_movies).cuda() # Class Instantiation</span></pre><p id="7e7f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上述代码中涉及到 OOPs 的概念。所以我来详细解释一下。</p><ul class=""><li id="c256" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mm lq lr ls bi translated"><code class="fe mu mv mw mb b">self </code>是一个参考变量，当对象(即模型)被创建时，存储该对象。</li><li id="0db3" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mm lq lr ls bi translated"><code class="fe mu mv mw mb b">def __init__(self, n_users, n_movies):</code>是一个神奇的功能。每当为该类创建对象时，都会自动调用它。这种类型的函数被称为构造函数。</li><li id="c44a" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mm lq lr ls bi translated"><code class="fe mu mv mw mb b">model = EmbeddingDot(n_users, n_movies).cuda()</code>。这里创建了对象。随着它的创建，构造函数被自动调用。</li><li id="b53b" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mm lq lr ls bi translated">但是物体是什么？一个对象(即模型)是一个具有一些属性和行为的实体。</li><li id="db8d" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mm lq lr ls bi translated">这些行为是嵌入的形状和值，如下所示。</li></ul><pre class="kg kh ki kj gt ma mb mc md aw me bi"><span id="fc83" class="mf mg iq mb b gy mh mi l mj mk">self.u = nn.Embedding(n_users, n_factors) # User Embeddings<br/>self.m = nn.Embedding(n_movies, n_factors) # Movie Embeddings<br/>self.u.weight.data.uniform_(0,0.05) # Values for User Embeddings<br/>self.m.weight.data.uniform_(0,0.05) # Values for Movie Embeddings</span></pre><ul class=""><li id="6351" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mm lq lr ls bi translated">为了获得这些嵌入的值，我们使用了从<code class="fe mu mv mw mb b">nn.Module </code>继承而来的<code class="fe mu mv mw mb b">nn.Embedding </code>，使用了 OOP 的<code class="fe mu mv mw mb b">Inheritance </code>概念，使用了下面这行代码:- <code class="fe mu mv mw mb b">super().__init__()</code>。</li><li id="5814" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mm lq lr ls bi translated"><code class="fe mu mv mw mb b">self.u</code>设置为嵌入类的实例。它有一个包含实际嵌入矩阵的<code class="fe mu mv mw mb b"> .weight</code>属性。嵌入矩阵是一个变量。变量和张量一样，它会自动微分。</li><li id="333b" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mm lq lr ls bi translated">要访问张量使用，<code class="fe mu mv mw mb b">self.u.weight.data</code>属性。</li><li id="e181" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mm lq lr ls bi translated"><code class="fe mu mv mw mb b">self.u.weight.data.uniform_</code> :-末尾的下划线符号表示它是一个就地操作。<code class="fe mu mv mw mb b">self.u.weight.data.uniform_</code>表示这个张量的适当大小的均匀随机数，不返回它，而是在适当的位置填充矩阵。</li><li id="acd0" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mm lq lr ls bi translated">当我们稍后进行拟合时，前进功能开始起作用。但是，让我们来详细了解一下当调用 forward 函数时会发生什么。</li></ul><pre class="kg kh ki kj gt ma mb mc md aw me bi"><span id="adbd" class="mf mg iq mb b gy mh mi l mj mk">def forward(self, cats, conts):<br/>        users,movies = cats[:,0],cats[:,1]<br/>        u,m = self.u(users),self.m(movies)<br/>        return (u*m).sum(1).view(-1, 1)</span></pre><ul class=""><li id="d7c3" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mm lq lr ls bi translated"><code class="fe mu mv mw mb b">users,movies = cats[:,0],cats[:,1]</code> :-抓取用户和电影的迷你批次。</li><li id="623e" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mm lq lr ls bi translated"><code class="fe mu mv mw mb b">u,m = self.u(users),self.m(movies)</code> :-对于小批量的用户和电影，使用<code class="fe mu mv mw mb b">self.u(users),self.m(movies)</code>查找用户和电影的嵌入矩阵。</li><li id="73ff" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mm lq lr ls bi translated">在得到用户和电影的嵌入后，我们将这两者进行叉积，得到一个数字，这就是预测的收视率。</li></ul><pre class="kg kh ki kj gt ma mb mc md aw me bi"><span id="15b0" class="mf mg iq mb b gy mh mi l mj mk">x = ratings.drop(['rating', 'timestamp'],axis=1)<br/># The x contain movies and users from the dataframe. Independent     # variables.</span><span id="ba8d" class="mf mg iq mb b gy ml mi l mj mk">y = ratings['rating'].astype(np.float32)<br/># The y contains the dependent Variable i.e the ratings.</span><span id="08ff" class="mf mg iq mb b gy ml mi l mj mk">data = ColumnarModelData.from_data_frame(path, val_idxs, x, y, ['userId', 'movieId'], 64)</span><span id="1ee3" class="mf mg iq mb b gy ml mi l mj mk">1# path :- path of the file.<br/>2# val_idxs :- Validation data<br/>3# x, y :- Described above as independent and dependent variable.<br/>4# ['userId', 'movieId'] :- List of categorical variables.<br/>5# 64 :- batch size.</span><span id="151c" class="mf mg iq mb b gy ml mi l mj mk">wd=1e-5 # Regularization parameter<br/><br/>opt = optim.SGD(model.parameters(), 1e-1, weight_decay=wd, momentum=0.9)<br/># Optimizer to be used to update the weights or model.parameters().<br/># model.parameters() is derived from nn.Module which gives list of all   # the weights that are needed to be updated and hence passed to optimizer # along with learning rate, weight decay and momentum.</span></pre><p id="5f32" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了拟合我们的数据，也就是为了训练，早先我们使用了<code class="fe mu mv mw mb b">learner</code>，它是 fast.ai 的一部分，但是现在我们将使用 PyTorch 功能。当执行下面的<code class="fe mu mv mw mb b">fit </code>命令时，检查 fastai 文件夹中的<code class="fe mu mv mw mb b">model.py </code>文件，以了解 fit 命令的底层。基本上它做的是:-</p><ul class=""><li id="5a2f" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li mm lq lr ls bi translated">通过调用正向函数<code class="fe mu mv mw mb b">def forward(self, cats, conts):</code>进行正向传递</li><li id="da4d" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li mm lq lr ls bi translated">以及更新嵌入的反向传递，这是 PyTorch 的功能。</li></ul><p id="ef00" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><code class="fe mu mv mw mb b">fit(model, data, 3, opt, F.mse_loss)</code></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/2dd0d8a97bd5f24193433358df02b620.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*AIsAiz4LhqC29TZxv6JAxA.png"/></div></figure><p id="a3f2" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这里我们不会得到 SGDR 的功能，因此手动重置学习率，并检查损失。</p><p id="bf54" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><code class="fe mu mv mw mb b">set_lrs(opt, 0.01)</code></p><p id="894a" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><code class="fe mu mv mw mb b">fit(model, data, 3, opt, F.mse_loss)</code></p><p id="6bb1" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">虽然我们的模型表现良好，但由于我们没有正确实施 SGDR，因此我们的损失比以前更高。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi my"><img src="../Images/d40a67191e7aa66fb518f69f1630c842.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*LAgArKFpbApDRJDA_pkEGg.png"/></div></figure><p id="31e4" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">如何进一步完善模型？？</strong></p><p id="a321" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在我们将考虑偏见。会有一些用户非常热情，平均来说会给所有的电影更高的评价。因此，我们将为电影和用户添加一个常量。这个常数被称为偏差。</p><pre class="kg kh ki kj gt ma mb mc md aw me bi"><span id="d4b2" class="mf mg iq mb b gy mh mi l mj mk">min_rating,max_rating = ratings.rating.min(),ratings.rating.max()<br/>min_rating,max_rating</span><span id="9e7c" class="mf mg iq mb b gy ml mi l mj mk">def get_emb(ni,nf): <br/># Input is #User,#Factors i.e Embedding Dimensionality<br/>    e = nn.Embedding(ni, nf) # Creation of Embedding matrix<br/>    e.weight.data.uniform_(-0.01,0.01)<br/> # Fill it with randomly initialized values between (-0.01,0.01)<br/>    return e</span><span id="0e1c" class="mf mg iq mb b gy ml mi l mj mk">class EmbeddingDotBias(nn.Module):<br/>    def __init__(self, n_users, n_movies):<br/>        super().__init__()<br/># Creating an embedding for User (self.u) , Movies (self.m), <br/># User bias (self.ub), Movie bias (self.mb) by calling get_emb().</span><span id="f23b" class="mf mg iq mb b gy ml mi l mj mk">(self.u, self.m, self.ub, self.mb) = [get_emb(*o) for o in [<br/>            (n_users, n_factors), (n_movies, n_factors), (n_users,1), (n_movies,1)<br/>        ]]<br/>        <br/>    def forward(self, cats, conts):<br/>        users,movies = cats[:,0],cats[:,1]<br/>        um = (self.u(users)* self.m(movies)).sum(1)<br/>        res = um + self.ub(users).squeeze() + self.mb(movies).squeeze()<br/># Add in user bias and movie bias. Using .squeeze() does a broadcasting.</span><span id="9c63" class="mf mg iq mb b gy ml mi l mj mk">        res = F.sigmoid(res) * (max_rating-min_rating) + min_rating<br/># This is gonna squish the value between 1 and 5 . What it does is if its # a good movie then it will get a really high number else a low number.<br/>#  F.sigmoid(res) is gonna squish it between 0 and 1.</span><span id="4747" class="mf mg iq mb b gy ml mi l mj mk"><br/>        return res.view(-1, 1)</span><span id="c05c" class="mf mg iq mb b gy ml mi l mj mk">wd=2e-4<br/>model = EmbeddingDotBias(cf.n_users, cf.n_items).cuda()<br/>opt = optim.SGD(model.parameters(), 1e-1, weight_decay=wd, momentum=0.9)<br/>fit(model, data, 3, opt, F.mse_loss)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/1fbf1b25f25c3d4a01c36b391676d12a.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*czmce2kZbX48z8danvOa0w.png"/></div></figure><pre class="kg kh ki kj gt ma mb mc md aw me bi"><span id="8f9d" class="mf mg iq mb b gy mh mi l mj mk">set_lrs(opt, 1e-2)<br/>fit(model, data, 3, opt, F.mse_loss)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/6ce6e8e629eddd4dd9cb7685add70270.png" data-original-src="https://miro.medium.com/v2/resize:fit:598/format:webp/1*D6F1I52yn-wM3j4Ld1tXdA.png"/></div></figure><p id="9209" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">最后，我们达到了 0.8 的损失，这相当不错。</p><p id="26b0" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><em class="nb">如果你喜欢，那么</em><strong class="kp ir"><em class="nb">ABC</em></strong><em class="nb">(</em><strong class="kp ir"><em class="nb">永远被击节</em> </strong> <em class="nb">。</em> <strong class="kp ir"> <em class="nb">👏 👏👏👏👏</em>😃😃😃😃😃😃😃😃😃<em class="nb">👏 👏👏👏👏👏</em> </strong> <em class="nb"> ) </em></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nc lz l"/></div></figure><p id="d488" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如果您有任何问题，请随时联系<a class="ae lj" href="http://forums.fast.ai/" rel="noopener ugc nofollow" target="_blank"> fast.ai 论坛</a>或 Twitter:<a class="ae lj" href="https://twitter.com/ashiskumarpanda" rel="noopener ugc nofollow" target="_blank">@ ashiskumarpanda</a></p><p id="4325" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">注:随着我继续学习其他课程，这篇博文将会更新和改进。更多有趣的东西，可以随时查看我的<a class="ae lj" href="https://github.com/CaptainAshis" rel="noopener ugc nofollow" target="_blank"><em class="nb">Github</em></a><em class="nb">账号。</em></p><p id="5076" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了充分利用这个博客系列，请按照以下顺序随意探索这个系列的第一部分:- <a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-1-e9cc80d81a9d">狗与猫的图像分类</a></p><ol class=""><li id="3c15" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60">犬种图像分类</a></li><li id="ec86" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889">多标签图像分类</a></li><li id="2e1f" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-4-1-time-series-analysis-a23217418bf1">使用神经网络的时间序列分析</a></li><li id="67d4" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/nlp-sentiment-analysis-on-imdb-movie-dataset-fb0c4d346d23" rel="noopener">对 IMDB 电影数据集的 NLP 情感分析</a></li><li id="5e9c" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-1-movie-recommendation-using-fastai-a53ed8e41269">电影推荐系统的基础</a></li><li id="5574" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-2-collaborative-filtering-from-scratch-1877640f514a">从零开始协同过滤</a></li><li id="2f82" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-3-collaborative-filtering-using-neural-network-48e49d7f9b36">使用神经网络的协同过滤</a></li><li id="6c67" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/fast-ai-season-1-episode-6-1-write-philosophy-like-nietzsche-using-rnn-8fe70cfb923c" rel="noopener">像尼采一样写哲学</a></li><li id="a3d1" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/fast-ai-season-1-episode-7-1-performance-of-different-neural-networks-on-cifar-10-dataset-c6559595b529" rel="noopener">不同神经网络在 Cifar-10 数据集上的性能</a></li><li id="61ac" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://medium.com/hackernoon/single-object-detection-e65a537a1c31" rel="noopener"> ML 模型检测图像中最大的物体 Part-1 </a></li><li id="241a" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://medium.com/hackernoon/single-object-detection-part-2-2deafc911ce7" rel="noopener"> ML 模型检测图像中最大的物体 Part-2 </a></li></ol><p id="b679" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">编辑 1:-TFW·杰瑞米·霍华德同意你的帖子。💖💖 🙌🙌🙌 💖💖。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nd lz l"/></div></figure></div></div>    
</body>
</html>