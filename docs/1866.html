<html>
<head>
<title>Predict Employee Turnover With Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python预测员工流动率</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predict-employee-turnover-with-python-da4975588aa3?source=collection_archive---------0-----------------------#2017-11-06">https://towardsdatascience.com/predict-employee-turnover-with-python-da4975588aa3?source=collection_archive---------0-----------------------#2017-11-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/deca1750371e56b095f8ef608c481360.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EZk40FSSOPa6ddDVG-1dJg.jpeg"/></div></div></figure><p id="ef5d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">“大数据可以让公司识别出预测自己队伍中人员流动的变量。”《哈佛商业评论》2017年8月</em>T3】</strong></p><p id="489c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">“员工流失分析是评估员工流动率的过程，旨在预测未来并减少员工流失。”福布斯2016年3月</em> </strong></p><h1 id="c865" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">介绍</h1><p id="b15e" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">本文展示了一个员工离职分析项目的参考实现，该项目是使用Python的Scikit-Learn库构建的。在本文中，我们介绍了逻辑回归，随机森林和支持向量机。我们还测量通过使用机器学习建立的模型的准确性，并评估进一步发展的方向。我们将用Python来完成以上所有的工作。我们开始吧！</p><h1 id="e354" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">数据预处理</h1><p id="47d3" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">数据是从<a class="ae ma" href="https://www.kaggle.com/ludobenistant/hr-analytics/data" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载的。这很简单。每行代表一名员工，每列包含员工属性:</p><ul class=""><li id="73ce" class="mb mc iq ka b kb kc kf kg kj md kn me kr mf kv mg mh mi mj bi translated">满意度_级别(0–1)</li><li id="95a1" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">last_evaluation(自上次评估以来的时间，以年为单位)</li><li id="f70a" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">number_projects(工作时完成的项目数)</li><li id="b7b9" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">平均每月小时数(工作场所平均每月小时数)</li><li id="46c1" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">time_spend_company(在公司工作的时间，以年为单位)</li><li id="a1df" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">工作事故(员工是否发生工作场所事故)</li><li id="92ad" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">离开(无论员工是否离开工作场所(1或0))</li><li id="3651" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">promotion_last_5years(员工在过去五年中是否得到晋升)</li><li id="65d1" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">销售(他们工作的部门)</li><li id="d880" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">工资(相对工资水平)</li></ul><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="7e43" class="my ky iq mu b gy mz na l nb nc">import pandas as pd<br/>hr = pd.read_csv('HR.csv')<br/>col_names = hr.columns.tolist()<br/>print("Column names:")<br/>print(col_names)</span><span id="5a9f" class="my ky iq mu b gy nd na l nb nc">print("\nSample data:")<br/>hr.head()</span></pre><p id="864d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">栏目名称:<br/> ['满意度_等级'，'上次_评估'，'人数_项目'，'平均_月_小时'，'时间_花费_公司'，'工作_事故'，'离职'，'促销_上次_ 5年'，'销售'，'薪资'] </em> </strong></p><p id="d443" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">样本数据:</em> </strong></p><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ne"><img src="../Images/475a6e18bb8128e11839b738e2e4b16f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fRKbHuYOB0Jl8tv4429YsQ.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 1</figcaption></figure><p id="2726" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">将列名从“销售”重命名为“部门”</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="dda9" class="my ky iq mu b gy mz na l nb nc">hr=hr.rename(columns = {'sales':'department'})</span></pre><p id="b000" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">列的类型如下所示:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="2cd9" class="my ky iq mu b gy mz na l nb nc">hr.dtypes</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/567de8e6b90adf5971da38887ba4a76e.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*ksK7FgSf7hLczVKIPIcv_A.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 2</figcaption></figure><p id="f694" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们的数据非常干净，没有缺失值</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="e911" class="my ky iq mu b gy mz na l nb nc">hr.isnull().any()</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/ff44f340d9bd5daeac78c32134e1987b.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*zNjjNmpLcQUGG4AjMl_DMQ.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 3</figcaption></figure><p id="cf95" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该数据包含14，999名员工和10项功能</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="3045" class="my ky iq mu b gy mz na l nb nc">hr.shape</span></pre><p id="ef07" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw"> (14999，10) </em> </strong></p><p id="8aeb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">“左”列是记录1和0的结果变量。1为离职员工，0为未离职员工。</p><p id="095c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">数据集的部门列有许多类别，为了更好地建模，我们需要减少类别。“部门”列有以下类别:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="f196" class="my ky iq mu b gy mz na l nb nc">hr['department'].unique()</span></pre><p id="08e9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">数组(['销售'，'会计'，'人力资源'，'技术'，'支持'，'管理'，【T25 '，' IT '，'产品_mng '，'营销'，' RandD']，dtype =对象)</em> </strong></p><p id="31db" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们将“技术”、“支持”和“IT”结合在一起，称之为“技术”。</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="b1b7" class="my ky iq mu b gy mz na l nb nc">import numpy as np<br/>hr['department']=np.where(hr['department'] =='support', 'technical', hr['department'])<br/>hr['department']=np.where(hr['department'] =='IT', 'technical', hr['department'])</span></pre><p id="8442" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">更改后，部门类别的外观如下:</p><p id="d8a3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">【'销售' '会计' '人力资源' '技术' '管理' '产品_ mng '】<br/>【市场营销' '随机】】</em> </strong></p><h1 id="7751" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">数据探索</h1><p id="1e64" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">首先，让我们找出离开公司和没有离开公司的员工人数:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="25f0" class="my ky iq mu b gy mz na l nb nc">hr['left'].value_counts()</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/6c135e375846fdde10145c2b49c52f80.png" data-original-src="https://miro.medium.com/v2/resize:fit:422/format:webp/1*Hg1Qck1yN6veNbpGlSEVjQ.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 4</figcaption></figure><p id="205a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">剩下3571名员工，11428名员工留在我们的数据中。</p><p id="6f47" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们来了解一下这两个类别的数字:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="875f" class="my ky iq mu b gy mz na l nb nc">hr.groupby('left').mean()</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nm"><img src="../Images/a120ff8015f57ec3316fc234e5bc5d50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SOPZWu0FBgJ3m4VnXgEMGA.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 5</figcaption></figure><p id="8cfd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">几种观察:</em> </strong></p><ul class=""><li id="ee0a" class="mb mc iq ka b kb kc kf kg kj md kn me kr mf kv mg mh mi mj bi translated">留在公司的员工的平均满意度高于离开公司的员工。</li><li id="d6a0" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">离开公司的员工平均每月工作时间比留下来的员工多。</li><li id="a407" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">发生工伤事故的员工比没有发生工伤事故的员工更不容易离职。</li><li id="39c2" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">与过去五年中没有获得晋升的员工相比，过去五年中获得晋升的员工离职的可能性更小。</li></ul><p id="55f5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们可以计算分类变量(如部门和工资)的分类平均值，以获得更详细的数据，如下所示:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="af9e" class="my ky iq mu b gy mz na l nb nc">hr.groupby('department').mean()</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nn"><img src="../Images/64711f606fdf622a3ebb0bc4cf811b7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pmd4GQ5OIPQ_g4cAZBmMuw.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 6</figcaption></figure><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="cb66" class="my ky iq mu b gy mz na l nb nc">hr.groupby('salary').mean()</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi no"><img src="../Images/8373e85019476f8451eb9d1af20daf68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UIvPqeAgER8MA0ISioH7mg.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 7</figcaption></figure><h1 id="ebbf" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">数据可视化</h1><p id="0938" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">让我们将数据可视化，以便更清楚地了解数据和重要特征。</p><p id="5eb9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">条形图为部门员工工作争取和离职频率</em> </strong></p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="aaef" class="my ky iq mu b gy mz na l nb nc">%matplotlib inline<br/>import matplotlib.pyplot as plt<br/>pd.crosstab(hr.department,hr.left).plot(kind='bar')<br/>plt.title('Turnover Frequency for Department')<br/>plt.xlabel('Department')<br/>plt.ylabel('Frequency of Turnover')<br/>plt.savefig('department_bar_chart')</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/2b078bc137d714ada84d501005885350.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*-CkM3rnT0dSd4jLwydhrqQ.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 8</figcaption></figure><p id="ef2b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">很明显，员工流动的频率在很大程度上取决于他们工作的部门。因此，部门可以很好地预测结果变量。</p><p id="d7fb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">员工薪资水平和离职频率条形图</em> </strong></p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="ae84" class="my ky iq mu b gy mz na l nb nc">table=pd.crosstab(hr.salary, hr.left)<br/>table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)<br/>plt.title('Stacked Bar Chart of Salary Level vs Turnover')<br/>plt.xlabel('Salary Level')<br/>plt.ylabel('Proportion of Employees')<br/>plt.savefig('salary_bar_chart')</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/e2935305a829f12831eadcd7c0afcfe5.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*VjWK9SxkKUYyn7OTj3uyNg.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 9</figcaption></figure><p id="d985" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">员工流动的比例在很大程度上取决于他们的工资水平；因此，工资水平可以是预测结果的一个很好的预测因素。</p><p id="c360" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在探索阶段，直方图通常是我们可以用于数值变量的最有用的工具之一。</p><p id="d13c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">数值变量直方图</em> </strong></p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="0c81" class="my ky iq mu b gy mz na l nb nc">num_bins = 10</span><span id="75a5" class="my ky iq mu b gy nd na l nb nc">hr.hist(bins=num_bins, figsize=(20,15))<br/>plt.savefig("hr_histogram_plots")<br/>plt.show()</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nq"><img src="../Images/a8dd595b42bb6e45c93f37e95a4f6cb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l3eWfwShDmnAHC_vjELwEA.png"/></div></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 10</figcaption></figure><h1 id="824b" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">为分类变量创建虚拟变量</h1><p id="ee29" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">数据集中有两个分类变量(部门、薪水),它们需要转换成虚拟变量才能用于建模。</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="7b7c" class="my ky iq mu b gy mz na l nb nc">cat_vars=['department','salary']<br/>for var in cat_vars:<br/>    cat_list='var'+'_'+var<br/>    cat_list = pd.get_dummies(hr[var], prefix=var)<br/>    hr1=hr.join(cat_list)<br/>    hr=hr1</span></pre><p id="405f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一旦创建了虚拟变量，就需要删除实际的分类变量。</p><p id="4165" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为分类变量创建虚拟变量后的列名:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="8d5a" class="my ky iq mu b gy mz na l nb nc">hr.drop(hr.columns[[8, 9]], axis=1, inplace=True)<br/>hr.columns.values</span></pre><p id="b826" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">数组(['满意度_等级'，'上次_评价'，'人数_项目'，<br/>'平均_月_小时'，'时间_花费_公司'，<br/>'离职'，'晋升_最近_ 5年'，'部门_随机'，<br/>'部门_会计'，'部门_人力资源'，'部门_管理'，【T26'部门_营销'，<br/>'部门_产品_管理'，【部门_销售'，【部门_技术】，【薪资_高】，<br/>'薪资_薪资</em></strong></p><p id="06d8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">结果变量为“左”，其他变量均为预测变量。</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="7c29" class="my ky iq mu b gy mz na l nb nc">hr_vars=hr.columns.values.tolist()<br/>y=['left']<br/>X=[i for i in hr_vars if i not in y]</span></pre><h1 id="ab32" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">特征选择</h1><p id="94ac" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated"><a class="ae ma" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html" rel="noopener ugc nofollow" target="_blank">递归特征消除(RFE) </a>的工作原理是递归地移除变量，并在剩余的变量上建立模型。它使用模型精度来确定哪些变量(和变量组合)对预测目标属性贡献最大。</p><p id="5cea" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们使用特征选择来帮助我们决定哪些变量是重要的，可以非常准确地预测员工流动率。X总共有18列，选10列怎么样？</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="7e73" class="my ky iq mu b gy mz na l nb nc">from sklearn.feature_selection import RFE<br/>from sklearn.linear_model import LogisticRegression</span><span id="d814" class="my ky iq mu b gy nd na l nb nc">model = LogisticRegression()</span><span id="fb10" class="my ky iq mu b gy nd na l nb nc">rfe = RFE(model, 10)<br/>rfe = rfe.fit(hr[X], hr[y])<br/>print(rfe.support_)<br/>print(rfe.ranking_)</span></pre><p id="5788" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">【真真假假真真假假真真假假真真假假<br/><br/>【1 1 3 9 1 1 1 1 1 1 1 5 1 1 6 8 7 4 1 1 2】</em></strong></p><p id="6c13" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您可以看到RFE为我们选择了10个变量，它们在<em class="kw"> support_ </em>数组中标记为True，在<em class="kw"> ranking_ </em>数组中标记为choice“1”。它们是:</p><p id="ed26" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw"> ['满意度_等级'，'上次_评价'，'时间_花费_公司'，'工作_事故'，'晋升_最近_ 5年'，'部门_随机'，'部门_人力资源'，'部门_管理'，'薪资_高'，'薪资_低'] </em> </strong></p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="3d53" class="my ky iq mu b gy mz na l nb nc">cols=['satisfaction_level', 'last_evaluation', 'time_spend_company', 'Work_accident', 'promotion_last_5years', <br/>      'department_RandD', 'department_hr', 'department_management', 'salary_high', 'salary_low'] <br/>X=hr[cols]<br/>y=hr['left']</span></pre><h1 id="aaaf" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">逻辑回归模型</h1><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="9164" class="my ky iq mu b gy mz na l nb nc">from sklearn.cross_validation import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)</span><span id="06e9" class="my ky iq mu b gy nd na l nb nc">from sklearn.linear_model import LogisticRegression<br/>from sklearn import metrics<br/>logreg = LogisticRegression()<br/>logreg.fit(X_train, y_train)</span></pre><p id="d24c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"><em class="kw">LogisticRegression(C = 1.0，class_weight=None，dual=False，fit_intercept=True，intercept_scaling=1，max_iter=100，multi_class='ovr '，n_jobs=1，penalty='l2 '，random_state=None，solver='liblinear '，tol=0.0001，verbose=0，warm_start=False) </em> </strong></p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="d5bb" class="my ky iq mu b gy mz na l nb nc">from sklearn.metrics import accuracy_score<br/>print('Logistic regression accuracy: {:.3f}'.format(accuracy_score(y_test, logreg.predict(X_test))))</span></pre><p id="905d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">逻辑回归精度:0.771 </em> </strong></p><h1 id="3d55" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">随机森林</h1><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="ca8d" class="my ky iq mu b gy mz na l nb nc">from sklearn.ensemble import RandomForestClassifier<br/>rf = RandomForestClassifier()<br/>rf.fit(X_train, y_train)</span></pre><p id="9dce" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"><em class="kw">RandomForestClassifier(bootstrap = True，class_weight=None，criterion='gini '，max_depth=None，max_features='auto '，max_leaf_nodes=None，min _ infinity _ split = 1e-07，min_samples_leaf=1，min_samples_split=2，min_weight_fraction_leaf=0.0，n _ estimators = 10，n_jobs=1，oob_score=False，random_state=None，verbose=0，warm _ start = False)【T24</em></strong></p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="f081" class="my ky iq mu b gy mz na l nb nc">print('Random Forest Accuracy: {:.3f}'.format(accuracy_score(y_test, rf.predict(X_test))))</span></pre><p id="35b9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">随机森林精度:0.978 </em> </strong></p><h1 id="a44a" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">支持向量机</h1><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="62bf" class="my ky iq mu b gy mz na l nb nc">from sklearn.svm import SVC<br/>svc = SVC()<br/>svc.fit(X_train, y_train)</span></pre><p id="a265" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw"> SVC(C=1.0，cache_size=200，class_weight=None，coef0=0.0，<br/>decision _ function _ shape = None，degree=3，gamma='auto '，kernel='rbf '，<br/> max_iter=-1，probability=False，random_state=None，shrinking=True，<br/> tol=0.001，verbose=False) </em> </strong></p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="ac89" class="my ky iq mu b gy mz na l nb nc">print('Support vector machine accuracy: {:.3f}'.format(accuracy_score(y_test, svc.predict(X_test))))</span></pre><p id="6a22" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">支持向量机精度:0.909 </em> </strong></p><p id="93f2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">获胜者<strong class="ka ir"> <em class="kw"> </em> </strong>是… <strong class="ka ir"> <em class="kw">随机森林</em> </strong>对吧？</p><h1 id="2302" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">交互效度分析</h1><p id="15dc" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">交叉验证试图避免过度拟合，同时仍然为每个观察数据集生成预测。我们使用10重交叉验证来训练我们的随机森林模型。</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="b807" class="my ky iq mu b gy mz na l nb nc">from sklearn import model_selection<br/>from sklearn.model_selection import cross_val_score<br/>kfold = model_selection.KFold(n_splits=10, random_state=7)<br/>modelCV = RandomForestClassifier()<br/>scoring = 'accuracy'<br/>results = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)<br/>print("10-fold cross validation average accuracy: %.3f" % (results.mean()))</span></pre><p id="8496" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">十重交叉验证平均准确率:0.977 </em> </strong></p><p id="4deb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">平均精度保持非常接近随机森林模型精度；因此，我们可以得出结论，该模型具有良好的通用性。</p><h1 id="99d7" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">精确度和召回率</h1><p id="4947" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">我们构建混淆矩阵来可视化分类器做出的预测，并评估分类的准确性。</p><p id="1db1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">随机森林</strong></p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="2199" class="my ky iq mu b gy mz na l nb nc">from sklearn.metrics import classification_report<br/>print(classification_report(y_test, rf.predict(X_test)))</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/dcb03d3ec0e3b49d0695f4bedf6480d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*S5cAUzCA2Dj_tEykMdTswQ.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 11</figcaption></figure><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="1037" class="my ky iq mu b gy mz na l nb nc">y_pred = rf.predict(X_test)<br/>from sklearn.metrics import confusion_matrix<br/>import seaborn as sns<br/>forest_cm = metrics.confusion_matrix(y_pred, y_test, [1,0])<br/>sns.heatmap(forest_cm, annot=True, fmt='.2f',xticklabels = ["Left", "Stayed"] , yticklabels = ["Left", "Stayed"] )<br/>plt.ylabel('True class')<br/>plt.xlabel('Predicted class')<br/>plt.title('Random Forest')<br/>plt.savefig('random_forest')</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/906fa8fac6f0c431714ceecc172b63aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*R40KSibTumT1bNmA5jZQ2Q.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 12</figcaption></figure><p id="e439" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">逻辑回归</strong></p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="2639" class="my ky iq mu b gy mz na l nb nc">print(classification_report(y_test, logreg.predict(X_test)))</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/2b8e34c65c3b8cbd247d32c6352e626e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*0uMu0ewj5xAu9fMjPA0Kug.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 13</figcaption></figure><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="0207" class="my ky iq mu b gy mz na l nb nc">logreg_y_pred = logreg.predict(X_test)<br/>logreg_cm = metrics.confusion_matrix(logreg_y_pred, y_test, [1,0])<br/>sns.heatmap(logreg_cm, annot=True, fmt='.2f',xticklabels = ["Left", "Stayed"] , yticklabels = ["Left", "Stayed"] )<br/>plt.ylabel('True class')<br/>plt.xlabel('Predicted class')<br/>plt.title('Logistic Regression')<br/>plt.savefig('logistic_regression')</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/3c5d00c05bce9ef7ffae2fa75e75d49c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*wkbDHE7leqfLVaTo6Zrezg.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 14</figcaption></figure><p id="7edf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">支持向量机</strong></p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="8c31" class="my ky iq mu b gy mz na l nb nc">print(classification_report(y_test, svc.predict(X_test)))</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/52cd9cf56eb7ad7dd7e97b95434569ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*fpNh32sZHlMa80sd4jrFYQ.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 15</figcaption></figure><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="7cfe" class="my ky iq mu b gy mz na l nb nc">svc_y_pred = svc.predict(X_test)<br/>svc_cm = metrics.confusion_matrix(svc_y_pred, y_test, [1,0])<br/>sns.heatmap(svc_cm, annot=True, fmt='.2f',xticklabels = ["Left", "Stayed"] , yticklabels = ["Left", "Stayed"] )<br/>plt.ylabel('True class')<br/>plt.xlabel('Predicted class')<br/>plt.title('Support Vector Machine')<br/>plt.savefig('support_vector_machine')</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/154e618c53b143e4a5116ef3e131707b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*DMRSS3E55ipb4Bpfw2ga_g.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 16</figcaption></figure><p id="88c4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当一名员工离职时，我的分类器多久能正确预测一次？这种测量被称为“召回”，快速浏览这些图表可以证明随机森林显然最适合这一标准。在所有的周转案例中，random forest在1038个案例中正确检索了991个案例。这转化为约95% (991/1038)的周转“召回”，远好于逻辑回归(26%)或支持向量机(85%)。</p><p id="6d7d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当一个分类器预测一个员工将离开时，这个员工实际上多久离开一次？这种测量称为“精度”。随机森林再次以大约95%的精度(1045中的991)优于其他两个，逻辑回归为大约51%(540中的273)，支持向量机为大约77%(1150中的890)。</p><h1 id="dc60" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">ROC曲线</h1><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="0fc1" class="my ky iq mu b gy mz na l nb nc">from sklearn.metrics import roc_auc_score<br/>from sklearn.metrics import roc_curve</span><span id="fc4f" class="my ky iq mu b gy nd na l nb nc">logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))<br/>fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])</span><span id="fa10" class="my ky iq mu b gy nd na l nb nc">rf_roc_auc = roc_auc_score(y_test, rf.predict(X_test))<br/>rf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, rf.predict_proba(X_test)[:,1])</span><span id="6c14" class="my ky iq mu b gy nd na l nb nc">plt.figure()<br/>plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)<br/>plt.plot(rf_fpr, rf_tpr, label='Random Forest (area = %0.2f)' % rf_roc_auc)<br/>plt.plot([0, 1], [0, 1],'r--')<br/>plt.xlim([0.0, 1.0])<br/>plt.ylim([0.0, 1.05])<br/>plt.xlabel('False Positive Rate')<br/>plt.ylabel('True Positive Rate')<br/>plt.title('Receiver operating characteristic')<br/>plt.legend(loc="lower right")<br/>plt.savefig('ROC')<br/>plt.show()</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/006778e06da229b363ac3b4f2e310670.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*YymdPMtp73ATlu_CwWWvPA.png"/></div><figcaption class="nf ng gj gh gi nh ni bd b be z dk">Figure 17</figcaption></figure><p id="424d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae ma" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener ugc nofollow" target="_blank">受试者操作特征(ROC) </a>曲线是二进制分类器使用的另一个常用工具。虚线代表纯随机分类器的ROC曲线；一个好的分类器尽可能远离那条线(朝向左上角)。</p><h1 id="871d" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">随机森林模型的特征重要性</h1><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="a30a" class="my ky iq mu b gy mz na l nb nc">feature_labels = np.array(['satisfaction_level', 'last_evaluation', 'time_spend_company', 'Work_accident', 'promotion_last_5years', <br/>      'department_RandD', 'department_hr', 'department_management', 'salary_high', 'salary_low'])<br/>importance = rf.feature_importances_<br/>feature_indexes_by_importance = importance.argsort()<br/>for index in feature_indexes_by_importance:<br/>    print('{}-{:.2f}%'.format(feature_labels[index], (importance[index] *100.0)))</span></pre><p id="5e33" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="kw">晋升_最后_ 5年-0.20% <br/>部门_管理-0.22% <br/>部门_人力资源-0.29% <br/>部门_随机-0.34% <br/>薪资_高-0.55% <br/>薪资_低-1.35% <br/>工作_意外-1.46% <br/>最后_评估-19.19% <br/>时间_花费_公司-25.77</em></strong></p><p id="4cc9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">根据我们的随机森林模型，上面以升序显示了影响员工是否会离开公司的最重要的特征。</p><h1 id="d5b9" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">摘要</h1><p id="ab01" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">这就把我们带到了文章的结尾。我不打算打印出模型预测他们可能会辞职的员工名单。这不是本分析的目的。记住我们不可能有一个适用于所有人的算法。员工离职分析可以帮助指导决策，但不能做出决策。<a class="ae ma" href="https://www.entrepreneur.com/article/271753#" rel="noopener ugc nofollow" target="_blank">小心使用分析以避免法律问题和员工的不信任，并结合员工反馈使用它们，以做出最佳决策。</a></p><p id="37fc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">创建这篇文章的源代码可以在<a class="ae ma" href="https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Employee_Turnover.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。我将很高兴收到关于上述任何反馈或问题。</p></div></div>    
</body>
</html>