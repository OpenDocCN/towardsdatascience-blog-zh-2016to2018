<html>
<head>
<title>Denoising Autoencoders explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">降噪自动编码器解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/denoising-autoencoders-explained-dbb82467fc2?source=collection_archive---------2-----------------------#2017-07-17">https://towardsdatascience.com/denoising-autoencoders-explained-dbb82467fc2?source=collection_archive---------2-----------------------#2017-07-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="e0bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上个月，我写了关于<a class="ae kl" href="https://medium.com/@dmonn/what-are-variational-autoencoders-a-simple-explanation-ea7dccafb0e3" rel="noopener">变型自动编码器</a>和它们的一些用例。这次，我将看看另一种类型的自动编码器:去噪自动编码器，它能够重建损坏的数据。</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><p id="f6ec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">自动编码器是通常用于特征选择和提取的神经网络。然而，当隐藏层中的节点多于输入时，网络冒着学习所谓的“恒等函数”(也称为“空函数”)的风险，这意味着输出等于输入，标志着自动编码器无用。</p><p id="0ec4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">去噪自动编码器通过随机将一些输入值归零来故意破坏数据，从而解决了这个问题。通常，被设置为零的输入节点的百分比约为 50%。其他资料显示，这个数字可能更低，比如 30%。这取决于您拥有的数据量和输入节点。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi kt"><img src="../Images/2ee9365fe3c649f5b274b4a254323bed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ygqA1Rxp0oq-wewzn_XqyA.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Architecture of a DAE. Copyright by Kirill Eremenko (<a class="ae kl" href="https://www.udemy.com/deeplearning" rel="noopener ugc nofollow" target="_blank">Deep Learning A-Z™: Hands-On Artificial Neural Networks</a>)</figcaption></figure><p id="fb1a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">计算损失函数时，重要的是将输出值与原始输入进行比较，而不是与损坏的输入进行比较。这样，就消除了学习身份函数而不是提取特征的风险。</p><p id="cbd5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">opendeep.org<a class="ae kl" href="http://www.opendeep.org/v0.0.5/docs/tutorial-your-first-model" rel="noopener ugc nofollow" target="_blank">发布了一个很棒的实现，他们使用 Theano 构建了一个非常基本的去噪自动编码器，并在 MNIST 数据集上训练它。OpenDeep 文章非常基础，是为初学者编写的。因此，即使您没有太多关于神经网络的经验，这篇文章也绝对值得一读！</a></p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi lj"><img src="../Images/59b01f7dac02f4739dfbc52a1c6f6f1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*ZyXnDR8yWrKvaVhDczx0VQ.png"/></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Original input, corrupted data and reconstructed data. Copyright by <a class="ae kl" href="http://www.opendeep.org/v0.0.5/docs/tutorial-your-first-model" rel="noopener ugc nofollow" target="_blank">opendeep.org</a>.</figcaption></figure><p id="c23c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">去噪自动编码器是特征选择和提取的重要和关键工具，现在你知道它是什么了吧！享受并感谢阅读！</p></div></div>    
</body>
</html>