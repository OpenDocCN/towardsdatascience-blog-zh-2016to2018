<html>
<head>
<title>Hands on Apache Beam, building data pipelines in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Beam 实践，用 Python 构建数据管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/hands-on-apache-beam-building-data-pipelines-in-python-6548898b66a5?source=collection_archive---------3-----------------------#2018-11-05">https://towardsdatascience.com/hands-on-apache-beam-building-data-pipelines-in-python-6548898b66a5?source=collection_archive---------3-----------------------#2018-11-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/d69475e8ea0a804745b8c578dc4cd423.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DFCo7QbiH8Nce3rVSyLkOg.jpeg"/></div></div></figure><p id="d023" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Apache Beam 是一个开源 SDK，它允许您从基于批处理或流的集成中构建多个数据管道，并以直接或分布式的方式运行它。您可以在每个管道中添加各种转换。但是 Beam 的真正强大之处在于它不基于特定的计算引擎，因此是平台无关的。您声明您想要使用哪个“跑步者”来计算您的变换。默认情况下，它使用您的本地计算资源，但是您可以指定一个 Spark 引擎或云数据流…</p><p id="83f3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在本文中，我将创建一个接收 csv 文件的管道，计算历史 S&amp;P500 数据集的打开和关闭列的平均值。这里的目标不是给出一个关于 Beam 特性的详细教程，而是给你一个总体的概念，告诉你可以用它做什么，以及它是否值得你更深入地使用 Beam 构建定制管道。虽然我只写批处理，但是流管道是 Beam 的一个强大特性！</p><p id="a945" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Beam 的 SDK 可以用于各种语言，Java，Python…但是在本文中我将重点介绍 Python。</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi kw"><img src="../Images/020bcc2072607fda54f680f8de902260.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*kBQv5-3eva_tgz2qZ0oICg.png"/></div></figure><h1 id="bd46" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">装置</h1><p id="66ec" class="pw-post-body-paragraph jy jz iq ka b kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv ij bi translated">在本文发表时，Apache Beam (2.8.1)只与 Python 2.7 兼容，但是 Python 3 版本应该很快就会推出。如果你安装了 python-snappy，Beam 可能会崩溃。这个问题是已知的，将在 Beam 2.9 中修复。</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="789f" class="mj lc iq mf b gy mk ml l mm mn">pip install apache-beam</span></pre><h1 id="70da" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">创建接收 CSV 的基本管道</h1><h1 id="cc69" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">数据</h1><p id="fe64" class="pw-post-body-paragraph jy jz iq ka b kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv ij bi translated">在本例中，我们将使用包含标准普尔 500 历史值的 csv。数据看起来是这样的:</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="8a33" class="mj lc iq mf b gy mk ml l mm mn">Date,Open,High,Low,Close,Volume<br/>03–01–00,1469.25,1478,1438.359985,1455.219971,931800000<br/>04–01–00,1455.219971,1455.219971,1397.430054,1399.420044,1009000000</span></pre><h1 id="3839" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">基本管道</h1><p id="0985" class="pw-post-body-paragraph jy jz iq ka b kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv ij bi translated">要创建管道，我们需要实例化管道对象，最终传递一些选项，并声明管道的步骤/转换。</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="d37e" class="mj lc iq mf b gy mk ml l mm mn">import apache_beam as beam<br/>from apache_beam.options.pipeline_options import PipelineOptions</span><span id="f4cf" class="mj lc iq mf b gy mo ml l mm mn">options = PipelineOptions()<br/>p = beam.Pipeline(options=options)</span></pre><p id="df41" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">根据梁文档:</p><blockquote class="mp mq mr"><p id="f77c" class="jy jz ms ka b kb kc kd ke kf kg kh ki mt kk kl km mu ko kp kq mv ks kt ku kv ij bi translated">使用管道选项来配置管道的不同方面，例如将执行管道的管道流道，以及所选流道所需的任何特定于流道的配置。您的管道选项可能包括诸如项目 ID 或文件存储位置等信息。</p></blockquote><p id="0442" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">上面的 PipelineOptions()方法是一个命令行解析器，它将读取通过以下方式传递的任何标准选项:</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="fdb5" class="mj lc iq mf b gy mk ml l mm mn">--&lt;option&gt;=&lt;value&gt;</span></pre><h1 id="860c" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">自定义选项</h1><p id="06e4" class="pw-post-body-paragraph jy jz iq ka b kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv ij bi translated">您还可以构建自己的自定义选项。在这个例子中，我为我的管道设置了一个输入和一个输出文件夹:</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="cc31" class="mj lc iq mf b gy mk ml l mm mn"><strong class="mf ir">class</strong> <strong class="mf ir">MyOptions</strong>(PipelineOptions):</span><span id="42c4" class="mj lc iq mf b gy mo ml l mm mn">@classmethod<br/>  <strong class="mf ir">def</strong> <strong class="mf ir">_add_argparse_args</strong>(cls, parser):<br/>    parser<strong class="mf ir">.</strong>add_argument('--input',<br/>                        help<strong class="mf ir">=</strong>'Input for the pipeline',<br/>                        default<strong class="mf ir">=</strong>'./data/')<br/>    parser<strong class="mf ir">.</strong>add_argument('--output',<br/>                        help<strong class="mf ir">=</strong>'Output for the pipeline',<br/>                        default<strong class="mf ir">=</strong>'./output/')</span></pre><h1 id="3442" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">转变原则</h1><p id="cd37" class="pw-post-body-paragraph jy jz iq ka b kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv ij bi translated">在 Beam 中，数据被表示为一个<strong class="ka ir"><em class="ms">p 集合</em> </strong>对象。因此，为了开始接收数据，我们需要从 csv 中读取并将其存储为一个<strong class="ka ir"><em class="ms">p 集合</em> </strong>，然后我们可以对其应用转换。读取操作被视为一种转换，并遵循所有转换的语法:</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="1a2c" class="mj lc iq mf b gy mk ml l mm mn">[Output PCollection] <strong class="mf ir">=</strong> [Input PCollection] <strong class="mf ir">|</strong> [Transform]</span></pre><p id="8f04" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这些转换可以像这样链接起来:</p><p id="9f32" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><code class="fe mw mx my mf b">[Final Output PCollection] <strong class="ka ir">=</strong> ([Initial Input PCollection] <strong class="ka ir">|</strong> [First Transform]<br/> <strong class="ka ir">|</strong> [Second Transform]<br/> <strong class="ka ir">|</strong> [Third Transform])</code></p><p id="90bb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该管道相当于一个<em class="ms">应用</em>方法。</p><p id="f85f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">输入和输出 p 集合以及每个中间 p 集合都被视为单独的数据容器。这允许对同一 PCollection 应用多个转换，因为初始 PCollection 是不可变的。例如:</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="a75b" class="mj lc iq mf b gy mk ml l mm mn">[Output PCollection 1] <strong class="mf ir">=</strong> [Input PCollection] <strong class="mf ir">|</strong> [Transform 1]<br/>[Output PCollection 2] <strong class="mf ir">=</strong> [Input PCollection] <strong class="mf ir">|</strong> [Transform 2]</span></pre><h1 id="61af" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">读取输入数据和写入输出数据</h1><p id="b7f9" class="pw-post-body-paragraph jy jz iq ka b kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv ij bi translated">因此，让我们首先使用提供的一个阅读器来阅读我们的 csv，不要忘记跳过标题行:</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="eecf" class="mj lc iq mf b gy mk ml l mm mn">csv_lines = (p | ReadFromText(input_filename, skip_header_lines=1) |   ...</span></pre><p id="0eaf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在管道的另一端，我们希望输出一个文本文件。所以让我们使用标准编写器:</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="b63a" class="mj lc iq mf b gy mk ml l mm mn">... <strong class="mf ir">|</strong> beam<strong class="mf ir">.</strong>io<strong class="mf ir">.</strong>WriteToText(output_filename)</span></pre><h1 id="37ef" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">转换</h1><p id="4418" class="pw-post-body-paragraph jy jz iq ka b kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv ij bi translated">现在我们想对用 Reader 函数创建的 PCollection 应用一些转换。变换分别应用于 PCollection 的每个元素。</p><p id="31d6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">根据您选择的工作者，您的转换可以是分布式的。然后在每个节点上执行转换的实例。</p><blockquote class="mp mq mr"><p id="bd51" class="jy jz ms ka b kb kc kd ke kf kg kh ki mt kk kl km mu ko kp kq mv ks kt ku kv ij bi translated">运行在每个 worker 上的用户代码生成输出元素，这些元素最终被添加到转换生成的最终输出<code class="fe mw mx my mf b"><em class="iq">PCollection</em></code>中。</p></blockquote><p id="f3f8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Beam 有核心方法(ParDo，Combine ),允许应用自定义转换，但也有预写的转换，称为<a class="ae mz" href="https://beam.apache.org/documentation/programming-guide/#composite-transforms" rel="noopener ugc nofollow" target="_blank">复合转换</a>。在我们的例子中，我们将使用 ParDo 变换来应用我们自己的函数。</p><p id="ef67" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们已经将 csv 读入到一个<strong class="ka ir"><em class="ms">p 集合</em> </strong>中，所以让我们将其拆分，以便我们可以访问日期并关闭项目:</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="b0be" class="mj lc iq mf b gy mk ml l mm mn">… beam.ParDo(Split()) …</span></pre><p id="3b5a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">并定义我们的 split 函数，这样我们只保留日期，然后关闭并将其作为 dictionnary 返回:</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="a3d4" class="mj lc iq mf b gy mk ml l mm mn">class Split(beam.DoFn):<br/>    def process(self, element):<br/>        Date,Open,High,Low,Close,Volume = element.split(“,”)<br/>        return [{<br/>            ‘Open’: float(Open),<br/>            ‘Close’: float(Close),<br/>        }]</span></pre><p id="54e5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们有了需要的数据，我们可以使用一个<a class="ae mz" href="https://beam.apache.org/releases/pydoc/2.6.0/_modules/apache_beam/transforms/combiners.html#Mean" rel="noopener ugc nofollow" target="_blank">标准组合器</a>来计算整个 p 集合的平均值。</p><p id="e366" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">要做的第一件事是将数据表示为一个元组，这样我们就可以按键分组，然后将组合值与它所期望的相结合。为此，我们使用一个自定义函数“CollectOpen()”，它返回一个包含(1，<open_value>)的元组列表。</open_value></p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="0d09" class="mj lc iq mf b gy mk ml l mm mn">class CollectOpen(beam.DoFn):<br/>    def process(self, element):<br/>        # Returns a list of tuples containing Date and Open value<br/>        result = [(1, element[‘Open’])]<br/>        return result</span></pre><p id="2a16" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">元组的第一个参数是固定的，因为我们想要计算整个数据集的平均值，但是您可以使它动态地只在由该键定义的子集上执行下一个转换。</p><p id="a8aa" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">GroupByKey 函数允许创建所有元素的 PCollection，对于这些元素，键(即元组的左侧)是相同的。</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="6b1d" class="mj lc iq mf b gy mk ml l mm mn">mean_open = (<br/>    csv_lines | beam.ParDo(CollectOpen()) |<br/>    "Grouping keys Open" &gt;&gt; beam.GroupByKey() |<br/>    "Calculating mean for Open" &gt;&gt; beam.CombineValues(<br/>        beam.combiners.MeanCombineFn()<br/>    )<br/>)</span></pre><p id="c60a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当你给一个转换分配一个标签时，确保它是唯一的，否则 Beam 将抛出一个错误。</p><p id="9359" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果我们想链接所有东西，我们的最终管道可能是这样的:</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="3b16" class="mj lc iq mf b gy mk ml l mm mn">csv_lines = (<br/>    p | beam.io.ReadFromText(input_filename) | <br/>    beam.ParDo(Split()) |<br/>    beam.ParDo(CollectOpen()) |<br/>    "Grouping keys Open" &gt;&gt; beam.GroupByKey() |<br/>    "Calculating mean" &gt;&gt; beam.CombineValues(<br/>        beam.combiners.MeanCombineFn()<br/>    ) | <!-- -->beam<strong class="mf ir">.</strong>io<strong class="mf ir">.</strong>WriteToText(output_filename)<br/>)</span></pre><p id="4347" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但是我们也可以用一种允许在 splitted PCollection 上添加未来变换的方式来编写它(例如像 close 的平均值):</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="9d18" class="mj lc iq mf b gy mk ml l mm mn">csv_lines = (<br/>    p | beam.io.ReadFromText(input_filename) |<br/>    beam.ParDo(Split())<br/>)</span><span id="0066" class="mj lc iq mf b gy mo ml l mm mn">mean_open = (<br/>    csv_lines | beam.ParDo(CollectOpen()) |<br/>    "Grouping keys Open" &gt;&gt; beam.GroupByKey() |<br/>    "Calculating mean for Open" &gt;&gt; beam.CombineValues(<br/>        beam.combiners.MeanCombineFn()<br/>    )<br/>)</span><span id="fea2" class="mj lc iq mf b gy mo ml l mm mn">output = (<br/>    mean_open | <!-- -->beam<strong class="mf ir">.</strong>io<strong class="mf ir">.</strong>WriteToText(output_filename)<br/>)<!-- --> </span></pre><h1 id="a9e0" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">同一 PCollection 上的多个转换</h1><p id="60d4" class="pw-post-body-paragraph jy jz iq ka b kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv ij bi translated">如果我想在 csv_lines PCollection 上添加另一个转换操作，我将获得第二个“转换的 PCollection”。Beam 以“分支”变换的形式很好地代表了它:</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi na"><img src="../Images/dfae86b413733c4d54a81dfc650d525f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*RRxNdNFG-e9t6w_EO2cPgA.png"/></div></figure><p id="fe44" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">要应用不同的变换，我们需要:</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="ef48" class="mj lc iq mf b gy mk ml l mm mn">csv_lines = (<br/>    p | beam.io.ReadFromText(input_filename) |<br/>    beam.ParDo(Split())<br/>)</span><span id="8540" class="mj lc iq mf b gy mo ml l mm mn">mean_open = (<br/>    csv_lines | beam.ParDo(CollectOpen()) |<br/>    "Grouping keys Open" &gt;&gt; beam.GroupByKey() |<br/>    "Calculating mean for Open" &gt;&gt; beam.CombineValues(<br/>        beam.combiners.MeanCombineFn()<br/>    )<br/>)</span><span id="a684" class="mj lc iq mf b gy mo ml l mm mn">mean_close = (<br/>    csv_lines | beam.ParDo(CollectClose()) |<br/>    "Grouping keys Close" &gt;&gt; beam.GroupByKey() |<br/>    "Calculating mean for Close" &gt;&gt; beam.CombineValues(<br/>        beam.combiners.MeanCombineFn()<br/>    )<br/>)</span></pre><p id="b31f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但是现在我们有两个 PCollections: mean_open 和 mean_close，作为转换的结果。我们需要合并/连接这些结果，以获得一个可以用 writer 写入文件的集合。Beam 的<code class="fe mw mx my mf b">CoGroupByKey</code>就是这么做的。我们的输出将如下所示:</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="46a4" class="mj lc iq mf b gy mk ml l mm mn">output= ( <br/>    { <br/>        ‘Mean Open’: mean_open,<br/>        ‘Mean Close’: mean_close<br/>    } | <br/>    apache_beam.CoGroupByKey() | <br/>    WriteToText(output_filename))<br/>)</span></pre><p id="4508" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们现在已经定义了端到端的管道。您可以使用我们之前定义的自定义参数通过命令行运行它:</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="fd8f" class="mj lc iq mf b gy mk ml l mm mn">python test_beam.py <strong class="mf ir">--</strong>input ./data/sp500.csv <strong class="mf ir">--</strong>output ./output/result.txt<!-- --> </span></pre><p id="b803" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">文件中的最终结果如下所示:</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="205e" class="mj lc iq mf b gy mk ml l mm mn">(1, {‘Mean Close’: [1482.764536822227], ‘Mean Open’: [1482.5682959997862]})</span></pre><h1 id="caca" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">光束读取器和写入器</h1><p id="fb2b" class="pw-post-body-paragraph jy jz iq ka b kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv ij bi translated">在这个例子中，我们只使用了 csv 阅读器和文本编写器，但是 Beam 有更多的连接器(不幸的是，大多数连接器都适用于 Java 平台，但是还有一些 Python 连接器正在开发中)。您可以在以下位置找到可用连接器的列表及其文档:</p><div class="nb nc gp gr nd ne"><a href="https://beam.apache.org/documentation/io/built-in/" rel="noopener  ugc nofollow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd ir gy z fp nj fr fs nk fu fw ip bi translated">内置 I/O 转换</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">Apache Beam 是一个开源、统一的模型和一组特定于语言的 SDK，用于定义和执行数据…</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">beam.apache.org</p></div></div><div class="nn l"><div class="no l np nq nr nn ns jw ne"/></div></div></a></div><p id="cdf6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你足够勇敢，你也可以找到一个指南来编写你自己的连接器:</p><div class="nb nc gp gr nd ne"><a href="https://beam.apache.org/documentation/io/authoring-overview/" rel="noopener  ugc nofollow" target="_blank"><div class="nf ab fo"><div class="ng ab nh cl cj ni"><h2 class="bd ir gy z fp nj fr fs nk fu fw ip bi translated">创作 I/O 转换-概述</h2><div class="nl l"><h3 class="bd b gy z fp nj fr fs nk fu fw dk translated">Apache Beam 是一个开源、统一的模型和一组特定于语言的 SDK，用于定义和执行数据…</h3></div><div class="nm l"><p class="bd b dl z fp nj fr fs nk fu fw dk translated">beam.apache.org</p></div></div><div class="nn l"><div class="nt l np nq nr nn ns jw ne"/></div></div></a></div><h1 id="49c9" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">创建数据管道时的一般逻辑</h1><p id="1317" class="pw-post-body-paragraph jy jz iq ka b kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv ij bi translated">每当需要实现数据管道时，我们都希望清楚管道/转换的需求和最终目标。在 Beam 文档中，我找到了这个小摘录，我认为它是开始用 Beam 构建管道时应该如何推理的核心:</p><blockquote class="mp mq mr"><p id="fdbe" class="jy jz ms ka b kb kc kd ke kf kg kh ki mt kk kl km mu ko kp kq mv ks kt ku kv ij bi translated"><strong class="ka ir">你输入的数据储存在哪里？</strong>你有几组输入数据？这将决定您需要在管道的开始应用哪种类型的<code class="fe mw mx my mf b">Read</code>转换。</p><p id="b9ce" class="jy jz ms ka b kb kc kd ke kf kg kh ki mt kk kl km mu ko kp kq mv ks kt ku kv ij bi translated"><strong class="ka ir">您的数据是什么样的？</strong>它可能是明文、格式化的日志文件或数据库表中的行。一些波束转换专门作用于键/值对的<code class="fe mw mx my mf b">PCollection</code>;您需要确定您的数据是否以及如何被键控，以及如何在您的管道的<code class="fe mw mx my mf b">PCollection</code>中最好地表示它。</p><p id="a4d8" class="jy jz ms ka b kb kc kd ke kf kg kh ki mt kk kl km mu ko kp kq mv ks kt ku kv ij bi translated"><strong class="ka ir">您希望如何处理您的数据？</strong>Beam SDK 中的核心转换是通用的。了解您需要如何更改或操作您的数据将决定您如何构建核心转换，如<a class="ae mz" href="https://beam.apache.org/documentation/programming-guide/#pardo" rel="noopener ugc nofollow" target="_blank"> ParDo </a>，或者您何时使用 Beam SDKs 中包含的预先编写的转换。</p><p id="75ed" class="jy jz ms ka b kb kc kd ke kf kg kh ki mt kk kl km mu ko kp kq mv ks kt ku kv ij bi translated"><strong class="ka ir">你的输出数据是什么样的，应该放在哪里？</strong>这将决定你需要在你的管道末端应用什么类型的<code class="fe mw mx my mf b">Write</code>转换。</p></blockquote><h1 id="2b07" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">使用分布式转轮</h1><p id="4690" class="pw-post-body-paragraph jy jz iq ka b kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv ij bi translated">如前所述，您可以使用 Spark 之类的分布式计算引擎，而不是使用本地计算能力(DirectRunner)。您可以通过为管道选项设置以下选项来实现这一点(在命令行参数或选项列表中):</p><pre class="kx ky kz la gt me mf mg mh aw mi bi"><span id="9623" class="mj lc iq mf b gy mk ml l mm mn">--runner SparkRunner  --sparkMaster spark://host:port</span></pre><p id="a871" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">更多选项可用<a class="ae mz" href="https://beam.apache.org/documentation/runners/spark/" rel="noopener ugc nofollow" target="_blank">这里</a>，但这两个是基本的。</p><h1 id="e2a6" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论</h1><p id="b607" class="pw-post-body-paragraph jy jz iq ka b kb lz kd ke kf ma kh ki kj mb kl km kn mc kp kq kr md kt ku kv ij bi translated">在编写定制转换时，Beam 是非常低级的，它提供了用户可能需要的灵活性。它速度很快，可以处理云/分布式环境。如果你看一个更高级的 API/SDK，一些像 tf.transform 这样的库实际上是建立在 Beam 之上的，在编码更少的情况下为你提供强大的功能。权衡在于您所寻求的灵活性。</p><p id="d7f0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这篇文章的代码可以在 GitHub <a class="ae mz" href="https://github.com/vincentteyssier/apache-beam-tutorial" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="1a32" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我希望你喜欢这篇文章。如果你看到了，欢迎鼓掌或关注我:)</p></div></div>    
</body>
</html>