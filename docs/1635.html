<html>
<head>
<title>Building A Logistic Regression in Python, Step by Step</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Python中逐步构建逻辑回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8?source=collection_archive---------0-----------------------#2017-09-29">https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8?source=collection_archive---------0-----------------------#2017-09-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/9bb2dc4ce97a38f931f0b9940954f3c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LrA_HrggXM_BDfippYTVxQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo Credit: Scikit-Learn</figcaption></figure><p id="2213" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><a class="ae la" href="https://en.wikipedia.org/wiki/Logistic_regression" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ir">逻辑回归</strong> </a>是一种机器学习分类算法，用于预测分类因变量的概率。在逻辑回归中，因变量是一个二元变量，包含编码为1的数据(是，成功，等等)。)或0(否，失败等。).换句话说，逻辑回归模型预测P(Y=1)是x的函数。</p><h1 id="fc5e" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">逻辑回归假设</h1><ul class=""><li id="4422" class="lz ma iq ke b kf mb kj mc kn md kr me kv mf kz mg mh mi mj bi translated">二元逻辑回归要求因变量是二元的。</li><li id="baf4" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz mg mh mi mj bi translated">对于二元回归，因变量的因子水平1应该代表期望的结果。</li><li id="e92e" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz mg mh mi mj bi translated">应该只包括有意义的变量。</li><li id="e96d" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz mg mh mi mj bi translated">自变量应该是相互独立的。也就是说，模型应该很少或没有多重共线性。</li><li id="e9c2" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz mg mh mi mj bi translated">自变量与对数概率呈线性相关。</li><li id="7945" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz mg mh mi mj bi translated">逻辑回归需要相当大的样本量。</li></ul><p id="ef45" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">记住上面的假设，让我们看看我们的数据集。</p><h1 id="050e" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">数据</h1><p id="f41d" class="pw-post-body-paragraph kc kd iq ke b kf mb kh ki kj mc kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">数据集来自<a class="ae la" href="http://archive.ics.uci.edu/ml/index.php" rel="noopener ugc nofollow" target="_blank"> UCI机器学习库</a>，它与一家葡萄牙银行机构的直接营销活动(电话)有关。分类的目标是预测客户是否会订阅(1/0)定期存款(变量y)。数据集可以从<a class="ae la" href="https://raw.githubusercontent.com/madmashup/targeted-marketing-predictive-engine/master/banking.csv" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="60f8" class="nb lc iq mx b gy nc nd l ne nf">import pandas as pd<br/>import numpy as np<br/>from sklearn import preprocessing<br/>import matplotlib.pyplot as plt <br/>plt.rc("font", size=14)<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.model_selection import train_test_split<br/>import seaborn as sns<br/>sns.set(style="white")<br/>sns.set(style="whitegrid", color_codes=True)</span></pre><p id="ec51" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">数据集提供了银行客户的信息。它包括41，188条记录和21个字段。</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ng"><img src="../Images/7d9085ef1929461a7edd56056479d8e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*44Iy8WNW4bIsvdII5agj7Q.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 1</figcaption></figure><p id="5a67" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">输入变量</strong></p><ol class=""><li id="8b86" class="lz ma iq ke b kf kg kj kk kn nh kr ni kv nj kz nk mh mi mj bi translated">年龄(数字)</li><li id="94b4" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">工作:工作类型(分类:"行政人员"、"蓝领工人"、"企业家"、"女佣"、"管理人员"、"退休人员"、"自营职业者"、"服务人员"、"学生"、"技术人员"、"失业人员"、"未知人员")</li><li id="2875" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">婚姻:婚姻状况(分类:“离婚”、“已婚”、“单身”、“未知”)</li><li id="da2f" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">教育(分类:"基础. 4y "、"基础. 6y "、"基础. 9y "、"高中"、"文盲"、"专业.课程"、"大学.学位"、"未知")</li><li id="30ec" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">违约:有信用违约？(分类:“否”、“是”、“未知”)</li><li id="bbf0" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">住房:有住房贷款吗？(分类:“否”、“是”、“未知”)</li><li id="f874" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">贷款:有个人贷款？(分类:“否”、“是”、“未知”)</li><li id="0df0" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">联系人:联系人通信类型(分类:“手机”、“电话”)</li><li id="dcbf" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">月份:一年中的最后一个联系月份(分类:“一月”、“二月”、“三月”、“十一月”、“十二月”)</li><li id="724b" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">星期几:一周的最后一个联系日(分类:“星期一”、“星期二”、“星期三”、“星期四”、“星期五”)</li><li id="0021" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">duration:上次联系持续时间，以秒为单位(数字)。重要注意事项:该属性对输出目标有很大影响(例如，如果duration=0，则y='no ')。在执行呼叫之前，持续时间是未知的，同样，在呼叫结束之后，y显然是已知的。因此，这种输入应该仅用于基准目的，如果目的是得到一个现实的预测模型，则应该丢弃</li><li id="2ff3" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">活动:在此活动期间为此客户执行的联系次数(数字，包括最后一次联系)</li><li id="ee66" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">pdays:从上一个活动中最后一次联系客户后经过的天数(数字；999表示之前没有联系过客户)</li><li id="4c1f" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">上一次:在此活动之前为此客户执行的联系次数(数字)</li><li id="b2f4" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">poutcome:先前营销活动的结果(分类:“失败”、“不存在”、“成功”)</li><li id="54c6" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">员工变动率:员工变动率—(数字)</li><li id="bb45" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">cons.price.idx:消费者价格指数—(数字)</li><li id="6a78" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">消费者信心指数—(数字)</li><li id="18d3" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">euribor 3m:3个月euribor利率—(数字)</li><li id="3897" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">受雇人数:雇员人数—(数字)</li></ol><p id="2d64" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">预测变量(期望目标):</strong></p><p id="53c0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">y —客户是否认购了定期存款？(二进制:“1”表示“是”，“0”表示“否”)</p><p id="2ccd" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">数据集的教育列有许多类别，为了更好地建模，我们需要减少类别。“教育”栏有以下类别:</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nl"><img src="../Images/8cb438d3920aded8c0e190048bf86f54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0eYxMGZ7r_OMqZc4P_pbsw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 2</figcaption></figure><p id="927d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">让我们把“基本. 4y”、“基本. 9y”、“基本. 6y”组合在一起，称之为“基本”。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="e191" class="nb lc iq mx b gy nc nd l ne nf">data['education']=np.where(data['education'] =='basic.9y', 'Basic', data['education'])<br/>data['education']=np.where(data['education'] =='basic.6y', 'Basic', data['education'])<br/>data['education']=np.where(data['education'] =='basic.4y', 'Basic', data['education'])</span></pre><p id="d297" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">分组后，这是列:</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/99e7e87d77f680cd9a646cb7c4c24451.png" data-original-src="https://miro.medium.com/v2/resize:fit:1172/format:webp/1*PV6Se8HwUVH3N7W8mpkNYA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 3</figcaption></figure><h1 id="a448" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">数据探索</h1><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/fa9c87caebcf5d8c3bcf992f962f67bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*4qHCg1FiJicOLELR3EF_kw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 4</figcaption></figure><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="ea64" class="nb lc iq mx b gy nc nd l ne nf">count_no_sub = len(data[data['y']==0])<br/>count_sub = len(data[data['y']==1])<br/>pct_of_no_sub = count_no_sub/(count_no_sub+count_sub)<br/>print("percentage of no subscription is", pct_of_no_sub*100)<br/>pct_of_sub = count_sub/(count_no_sub+count_sub)<br/>print("percentage of subscription", pct_of_sub*100)</span></pre><p id="5bed" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> <em class="no">无认购百分比为88.73288821988</em></strong></p><p id="6e5b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> <em class="no">认购百分比11.265417111780131 </em> </strong></p><p id="37d4" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们的类是不平衡的，非订阅实例和订阅实例的比例是89:11。在我们继续平衡这些类之前，让我们做一些更多的探索。</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi np"><img src="../Images/c6d0bc5938ed8128a5ca3f7da97ba71a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c1NF9dyzUm768_Jqpa5AVA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 5</figcaption></figure><p id="0c5e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> <em class="no">观察值</em> </strong>:</p><ul class=""><li id="896f" class="lz ma iq ke b kf kg kj kk kn nh kr ni kv nj kz mg mh mi mj bi translated">购买定期存款的客户的平均年龄高于没有购买的客户。</li><li id="4766" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz mg mh mi mj bi translated">对于购买该产品的客户来说，pdays(自上次联系客户后的天数)更短是可以理解的。时间越短，对最后一次通话的记忆就越好，因此成交的机会就越大。</li><li id="9677" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz mg mh mi mj bi translated">令人惊讶的是，对于购买定期存款的客户来说，营销活动(在当前营销活动中联系或致电的次数)更少。</li></ul><p id="81eb" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们可以计算其他分类变量(如教育和婚姻状况)的分类平均值，以获得更详细的数据。</p><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nq"><img src="../Images/99508051fd76ab9718b423d812103845.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hjGEaLT6Dn_ZuA6PzXITFQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 6</figcaption></figure><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nr"><img src="../Images/a5a62cfa675b9a22dd50d0f625b86bcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FJ_BZzxgBYahrRCGwKl6aw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 7</figcaption></figure><h1 id="1016" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">形象化</h1><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="df73" class="nb lc iq mx b gy nc nd l ne nf">%matplotlib inline<br/>pd.crosstab(data.job,data.y).plot(kind='bar')<br/>plt.title('Purchase Frequency for Job Title')<br/>plt.xlabel('Job')<br/>plt.ylabel('Frequency of Purchase')<br/>plt.savefig('purchase_fre_job')</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/0b59b08fab88b441637988cfd67b929c.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*sjEwYzHtLR4M7Rs54Q7BFA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 8</figcaption></figure><p id="f407" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">购买存款的频率在很大程度上取决于职位。因此，职称可以很好地预测结果变量。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="e69c" class="nb lc iq mx b gy nc nd l ne nf">table=pd.crosstab(data.marital,data.y)<br/>table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)<br/>plt.title('Stacked Bar Chart of Marital Status vs Purchase')<br/>plt.xlabel('Marital Status')<br/>plt.ylabel('Proportion of Customers')<br/>plt.savefig('mariral_vs_pur_stack')</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/48b03b8efb8af0936f7e653b911a926b.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*vSRMnyoqpSJiQzb35F5WDw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 9</figcaption></figure><p id="5e85" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">婚姻状况似乎不是结果变量的强有力的预测因素。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="a94c" class="nb lc iq mx b gy nc nd l ne nf">table=pd.crosstab(data.education,data.y)<br/>table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)<br/>plt.title('Stacked Bar Chart of Education vs Purchase')<br/>plt.xlabel('Education')<br/>plt.ylabel('Proportion of Customers')<br/>plt.savefig('edu_vs_pur_stack')</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/9f38266bfcf2a9f95d31de42ef48f9b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*5bTK1pR0leRXWAEMoYvHOg.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 10</figcaption></figure><p id="3aff" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">教育似乎是结果变量的一个很好的预测器。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="93ba" class="nb lc iq mx b gy nc nd l ne nf">pd.crosstab(data.day_of_week,data.y).plot(kind='bar')<br/>plt.title('Purchase Frequency for Day of Week')<br/>plt.xlabel('Day of Week')<br/>plt.ylabel('Frequency of Purchase')<br/>plt.savefig('pur_dayofweek_bar')</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nt"><img src="../Images/8f27653b88bd4d5cbda9fb236e333f7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DX3lON5sfqfvUmnxprE0_g.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 11</figcaption></figure><p id="a170" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">星期几可能不是预测结果的好方法。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="875c" class="nb lc iq mx b gy nc nd l ne nf">pd.crosstab(data.month,data.y).plot(kind='bar')<br/>plt.title('Purchase Frequency for Month')<br/>plt.xlabel('Month')<br/>plt.ylabel('Frequency of Purchase')<br/>plt.savefig('pur_fre_month_bar')</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nu"><img src="../Images/ae9ae64854506e13701ec3173a0ece79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vr11Kd8P1IPaaj3K6SIrEQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 12</figcaption></figure><p id="6755" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">月份可能是结果变量的一个很好的预测因子。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="91b6" class="nb lc iq mx b gy nc nd l ne nf">data.age.hist()<br/>plt.title('Histogram of Age')<br/>plt.xlabel('Age')<br/>plt.ylabel('Frequency')<br/>plt.savefig('hist_age')</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/5fcd7d02144baea494271b7b3966bb55.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*TtFhHfm6qV1gfDjad6OA8A.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 13</figcaption></figure><p id="7e84" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在这个数据集中，银行的大多数客户年龄在30-40岁之间。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="c8ab" class="nb lc iq mx b gy nc nd l ne nf">pd.crosstab(data.poutcome,data.y).plot(kind='bar')<br/>plt.title('Purchase Frequency for Poutcome')<br/>plt.xlabel('Poutcome')<br/>plt.ylabel('Frequency of Purchase')<br/>plt.savefig('pur_fre_pout_bar')</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nv"><img src="../Images/0f1fcd7bbbb16a697a86589041613ed4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9K90MT_6rWKJtpR3Sb_SXQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 14</figcaption></figure><p id="3479" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">Poutcome似乎是一个很好的预测结果变量。</p><h1 id="d94f" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak">创建虚拟变量</strong></h1><p id="501c" class="pw-post-body-paragraph kc kd iq ke b kf mb kh ki kj mc kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">也就是只有两个值的变量，0和1。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="5c55" class="nb lc iq mx b gy nc nd l ne nf">cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']<br/>for var in cat_vars:<br/>    cat_list='var'+'_'+var<br/>    cat_list = pd.get_dummies(data[var], prefix=var)<br/>    data1=data.join(cat_list)<br/>    data=data1</span><span id="f5d7" class="nb lc iq mx b gy nw nd l ne nf">cat_vars=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']<br/>data_vars=data.columns.values.tolist()<br/>to_keep=[i for i in data_vars if i not in cat_vars]</span></pre><p id="d738" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们的最终数据列将是:</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="204e" class="nb lc iq mx b gy nc nd l ne nf">data_final=data[to_keep]<br/>data_final.columns.values</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/58acd1d131f1d1c0018c42c99a07b949.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*2nViJsWQ0pIR0n0iXD8bag.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 15</figcaption></figure><h1 id="435f" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak">使用SMOTE进行过采样</strong></h1><p id="e0fb" class="pw-post-body-paragraph kc kd iq ke b kf mb kh ki kj mc kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">有了我们创建的训练数据，我将使用<a class="ae la" href="https://arxiv.org/pdf/1106.1813.pdf" rel="noopener ugc nofollow" target="_blank"> SMOTE算法</a>(合成少数过采样技术)对非订阅进行上采样。在高水平上，击打:</p><ol class=""><li id="432f" class="lz ma iq ke b kf kg kj kk kn nh kr ni kv nj kz nk mh mi mj bi translated">通过从minor类(无订阅)创建合成样本而不是创建副本来工作。</li><li id="5d0d" class="lz ma iq ke b kf mk kj ml kn mm kr mn kv mo kz nk mh mi mj bi translated">随机选择k个最近邻中的一个，并使用它来创建类似的、但随机调整的新观察值。</li></ol><p id="38b7" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们要用Python 实现<a class="ae la" href="http://imbalanced-learn.org/en/stable/over_sampling.html#smote-variants" rel="noopener ugc nofollow" target="_blank"> SMOTE。</a></p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="97d5" class="nb lc iq mx b gy nc nd l ne nf">X = data_final.loc[:, data_final.columns != 'y']<br/>y = data_final.loc[:, data_final.columns == 'y']</span><span id="a566" class="nb lc iq mx b gy nw nd l ne nf">from imblearn.over_sampling import SMOTE</span><span id="5d45" class="nb lc iq mx b gy nw nd l ne nf">os = SMOTE(random_state=0)<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)<br/>columns = X_train.columns</span><span id="27ad" class="nb lc iq mx b gy nw nd l ne nf">os_data_X,os_data_y=os.fit_sample(X_train, y_train)<br/>os_data_X = pd.DataFrame(data=os_data_X,columns=columns )<br/>os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])<br/># we can Check the numbers of our data<br/>print("length of oversampled data is ",len(os_data_X))<br/>print("Number of no subscription in oversampled data",len(os_data_y[os_data_y['y']==0]))<br/>print("Number of subscription",len(os_data_y[os_data_y['y']==1]))<br/>print("Proportion of no subscription data in oversampled data is ",len(os_data_y[os_data_y['y']==0])/len(os_data_X))<br/>print("Proportion of subscription data in oversampled data is ",len(os_data_y[os_data_y['y']==1])/len(os_data_X))</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ny"><img src="../Images/bc1a24878c7009bb0e217c418e6ff4d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LYBUjNFrbR8DYoVj664rZQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 16</figcaption></figure><p id="3b48" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在我们有了一个完美的平衡数据！您可能已经注意到，我只对训练数据进行了过采样，因为通过只对训练数据进行过采样，测试数据中的任何信息都不会用于创建合成观察，因此，没有任何信息会从测试数据流入模型训练。</p><h1 id="9fad" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak">递归特征消除</strong></h1><p id="0903" class="pw-post-body-paragraph kc kd iq ke b kf mb kh ki kj mc kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated"><a class="ae la" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html" rel="noopener ugc nofollow" target="_blank">递归特征消除(RFE) </a>基于重复构建模型并选择最佳或最差性能特征的思想，将该特征放在一边，然后对其余特征重复该过程。此过程将一直应用到数据集中的所有要素都用完为止。RFE的目标是通过递归地考虑越来越小的特征集来选择特征。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="1b6c" class="nb lc iq mx b gy nc nd l ne nf">data_final_vars=data_final.columns.values.tolist()<br/>y=['y']<br/>X=[i for i in data_final_vars if i not in y]</span><span id="674a" class="nb lc iq mx b gy nw nd l ne nf">from sklearn.feature_selection import RFE<br/>from sklearn.linear_model import LogisticRegression</span><span id="0c90" class="nb lc iq mx b gy nw nd l ne nf">logreg = LogisticRegression()</span><span id="56f4" class="nb lc iq mx b gy nw nd l ne nf">rfe = RFE(logreg, 20)<br/>rfe = rfe.fit(os_data_X, os_data_y.values.ravel())<br/>print(rfe.support_)<br/>print(rfe.ranking_)</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nz"><img src="../Images/20a4050ceaf9e5acc9d000ed66a25356.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S-AAN0cUVIhIuGQRDCXq7A.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 16</figcaption></figure><p id="fada" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">RFE帮助我们选择了以下特征:“euribor3m”、“job _蓝领”、“job _女佣”、“婚姻_未知”、“教育_文盲”、“默认_否”、“默认_未知”、“联系人_手机”、“联系人_电话”、“month_apr”、“month_aug”、“month_dec”、“month_jul”、“month_jun”、“month_mar”、“month_may”、“month_nov”、“month_oct”、“poutcome_failure”、“poutcome_success”。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="fa4b" class="nb lc iq mx b gy nc nd l ne nf">cols=['euribor3m', 'job_blue-collar', 'job_housemaid', 'marital_unknown', 'education_illiterate', 'default_no', 'default_unknown', <br/>      'contact_cellular', 'contact_telephone', 'month_apr', 'month_aug', 'month_dec', 'month_jul', 'month_jun', 'month_mar', <br/>      'month_may', 'month_nov', 'month_oct', "poutcome_failure", "poutcome_success"] <br/>X=os_data_X[cols]<br/>y=os_data_y['y']</span></pre><h1 id="648f" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">实施模型</h1><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="3880" class="nb lc iq mx b gy nc nd l ne nf">import statsmodels.api as sm<br/>logit_model=sm.Logit(y,X)<br/>result=logit_model.fit()<br/>print(result.summary2())</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oa"><img src="../Images/46244f96c6fb9ddd879cf237d5db24e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R8inm4HfqfPe6kmNJk15fw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 17</figcaption></figure><p id="8dfb" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">除了四个变量，大多数变量的p值都小于0.05，因此，我们将删除它们。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="4aa5" class="nb lc iq mx b gy nc nd l ne nf">cols=['euribor3m', 'job_blue-collar', 'job_housemaid', 'marital_unknown', 'education_illiterate', <br/>      'month_apr', 'month_aug', 'month_dec', 'month_jul', 'month_jun', 'month_mar', <br/>      'month_may', 'month_nov', 'month_oct', "poutcome_failure", "poutcome_success"] <br/>X=os_data_X[cols]<br/>y=os_data_y['y']</span><span id="7de2" class="nb lc iq mx b gy nw nd l ne nf">logit_model=sm.Logit(y,X)<br/>result=logit_model.fit()<br/>print(result.summary2())</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ob"><img src="../Images/87c2861190b138b6e6ff33ee5a8b908a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PZmf6y9sxuzAzJU83YEMdQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 18</figcaption></figure><h1 id="3970" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">逻辑回归模型拟合</h1><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="a4a6" class="nb lc iq mx b gy nc nd l ne nf">from sklearn.linear_model import LogisticRegression<br/>from sklearn import metrics</span><span id="8d8c" class="nb lc iq mx b gy nw nd l ne nf">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)<br/>logreg = LogisticRegression()<br/>logreg.fit(X_train, y_train)</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oc"><img src="../Images/f3bc88b752f207c21ff65f6b64835355.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QMY92XrVTePSf_RfVzDDVQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 19</figcaption></figure><p id="b891" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">预测测试集结果并计算准确度</strong></p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="b3bf" class="nb lc iq mx b gy nc nd l ne nf">y_pred = logreg.predict(X_test)<br/>print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))</span></pre><p id="a354" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> <em class="no">逻辑回归分类器在测试集上的准确率:0.74 </em> </strong></p><h1 id="89d4" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">混淆矩阵</h1><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="f774" class="nb lc iq mx b gy nc nd l ne nf">from sklearn.metrics import confusion_matrix<br/>confusion_matrix = confusion_matrix(y_test, y_pred)<br/>print(confusion_matrix)</span></pre><p id="7bae" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"><em class="no">【6124 1542】</em></strong></p><p id="52c7" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"><em class="no">【2505 5170】]</em></strong></p><p id="1067" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">结果告诉我们，我们有<strong class="ke ir"> <em class="no"> 6124+5170 </em> </strong>正确的预测和<strong class="ke ir"> <em class="no"> 2505+1542 </em> </strong>不正确的预测。</p><h1 id="0f57" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak">计算精度、召回、F-测量和支持</strong></h1><p id="bbee" class="pw-post-body-paragraph kc kd iq ke b kf mb kh ki kj mc kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">引用<a class="ae la" href="http://scikit-learn.org/stable/index.html" rel="noopener ugc nofollow" target="_blank"> Scikit Learn </a>的话:</p><p id="41b9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">精度是tp / (tp + fp)的比值，其中tp是真阳性的数量，fp是假阳性的数量。精确度直观上是分类器在样本为阴性时不将其标记为阳性的能力。</p><p id="4e89" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">召回率是tp / (tp + fn)的比值，其中tp是真阳性的数量，fn是假阴性的数量。召回直观上是分类器找到所有肯定样本的能力。</p><p id="2ca6" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">F-beta分数可以解释为精确度和召回率的加权调和平均值，其中F-beta分数在1时达到其最佳值，在0时达到最差分数。</p><p id="fb93" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">F-beta分数通过beta因子对召回率的加权大于对精确度的加权。beta = 1.0意味着召回率和准确率同等重要。</p><p id="e481" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">支持度是y_test中每个类的出现次数。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="9f95" class="nb lc iq mx b gy nc nd l ne nf">from sklearn.metrics import classification_report<br/>print(classification_report(y_test, y_pred))</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi od"><img src="../Images/8e4b931db8ef7f46d2d63fdfe431b2c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-cFgi6FW4h_ab9eUexLEsA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 20</figcaption></figure><p id="fb12" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">解读</strong>:在整个测试集中，74%的推广定期存款是客户喜欢的定期存款。在整个测试集中，74%的客户首选定期存款得到了推广。</p><h1 id="d7f8" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">受试者工作特征曲线</h1><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="3659" class="nb lc iq mx b gy nc nd l ne nf">from sklearn.metrics import roc_auc_score<br/>from sklearn.metrics import roc_curve<br/>logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))<br/>fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])<br/>plt.figure()<br/>plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)<br/>plt.plot([0, 1], [0, 1],'r--')<br/>plt.xlim([0.0, 1.0])<br/>plt.ylim([0.0, 1.05])<br/>plt.xlabel('False Positive Rate')<br/>plt.ylabel('True Positive Rate')<br/>plt.title('Receiver operating characteristic')<br/>plt.legend(loc="lower right")<br/>plt.savefig('Log_ROC')<br/>plt.show()</span></pre><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oe"><img src="../Images/1bc386d0bb46c23aa67e543ef4b5ce10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uVLP3Wn0LN60E2GK2trVPQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 21</figcaption></figure><p id="1551" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><a class="ae la" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener ugc nofollow" target="_blank">受试者工作特性(ROC) </a>曲线是二元分类器使用的另一个常用工具。虚线代表纯随机分类器的ROC曲线；一个好的分类器尽可能远离那条线(朝向左上角)。</p><p id="97bd" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">用来写这篇文章的Jupyter笔记本可以在<a class="ae la" href="https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Logistic%20Regression%20balanced.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。我将很高兴收到关于上述任何反馈或问题。</p><p id="a5b3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">参考:<a class="ae la" href="https://books.google.com/books/about/Learning_Predictive_Analytics_with_Pytho.html?id=Ia5KDAAAQBAJ&amp;printsec=frontcover&amp;source=kp_read_button#v=onepage&amp;q&amp;f=false" rel="noopener ugc nofollow" target="_blank">使用Python书籍学习预测分析</a></p></div></div>    
</body>
</html>