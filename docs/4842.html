<html>
<head>
<title>Content-Based Recommender for NYT Articles</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于内容的 NYT 文章推荐系统</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/content-based-recommender-for-nyt-articles-5a54f57dd531?source=collection_archive---------16-----------------------#2018-09-10">https://towardsdatascience.com/content-based-recommender-for-nyt-articles-5a54f57dd531?source=collection_archive---------16-----------------------#2018-09-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="83ab" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">数据产品。数据科学。自然语言处理</h2></div><h1 id="1e26" class="ki kj it bd kk kl km kn ko kp kq kr ks jz kt ka ku kc kv kd kw kf kx kg ky kz bi translated">介绍</h1><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi la"><img src="../Images/e456abc29a901bffb38440a4cc98bd5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w34KHCKcuUgBUJeMZU8Pqw.jpeg"/></div></div></figure><p id="e9c3" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我们将为纽约时报的文章创建一个基于内容的推荐器。这个推荐器是一个非常简单的数据产品的例子。</p><p id="2f31" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我们将根据用户当前阅读的文章推荐他们应该阅读的新文章。我们将通过基于那篇文章的文本数据推荐类似的文章来做到这一点。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><p id="e412" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">查看我的 Github 个人资料上的代码。</p><div class="mp mq gp gr mr ms"><a href="https://github.com/DataBeast03/DataBeast/blob/master/NYT_Recommender/Content_Based_Recommendations.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="mt ab fo"><div class="mu ab mv cl cj mw"><h2 class="bd iu gy z fp mx fr fs my fu fw is bi translated">数据广播 03/数据广播</h2><div class="mz l"><h3 class="bd b gy z fp mx fr fs my fu fw dk translated">数据科学投资组合。通过在 GitHub 上创建一个帐户，为 databast 03/databast 开发做出贡献。</h3></div><div class="na l"><p class="bd b dl z fp mx fr fs my fu fw dk translated">github.com</p></div></div><div class="nb l"><div class="nc l nd ne nf nb ng lk ms"/></div></div></a></div></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="bd1d" class="ki kj it bd kk kl nh kn ko kp ni kr ks jz nj ka ku kc nk kd kw kf nl kg ky kz bi translated">检查数据</h1><p id="3a37" class="pw-post-body-paragraph lm ln it lo b lp nm ju lr ls nn jx lu lv no lx ly lz np mb mc md nq mf mg mh im bi translated">以下是我们数据集中第一篇 NYT 文章的摘录。显然，我们正在处理文本数据。</p><pre class="lb lc ld le gt nr ns nt nu aw nv bi"><span id="3f4c" class="nw kj it ns b gy nx ny l nz oa">'TOKYO —  State-backed Japan Bank for International Cooperation [JBIC.UL] will lend about 4 billion yen ($39 million) to Russia\'s Sberbank, which is subject to Western sanctions, in the hope of advancing talks on a territorial dispute, the Nikkei business daily said on Saturday, [...]"</span></pre><p id="620f" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">所以我们必须回答的第一个问题是，我们应该如何对它进行矢量化？我们如何着手设计新的特征，如词类、N-grams、情感分数或命名实体？！</p><p id="db89" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">显然 NLP 隧道很深，我们可以花几天时间来试验不同的选项。但是所有好的科学都是从尝试最简单可行的解决方案开始，然后迭代到更复杂的方案。</p><p id="0c1b" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">在本文中，我们将实现一个简单可行的解决方案。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><p id="15b9" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated"><strong class="lo iu">分割您的数据</strong></p><p id="ca97" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">首先，我们需要确定数据集中哪些特征是我们感兴趣的，对它们进行洗牌，然后将数据分成训练集和测试集——所有这些都是标准的数据预处理。</p><pre class="lb lc ld le gt nr ns nt nu aw nv bi"><span id="eadd" class="nw kj it ns b gy nx ny l nz oa"># move articles to an array<br/>articles = df.body.values</span><span id="ee8b" class="nw kj it ns b gy ob ny l nz oa"># move article section names to an array<br/>sections = df.section_name.values</span><span id="624b" class="nw kj it ns b gy ob ny l nz oa"># move article web_urls to an array<br/>web_url = df.web_url.values</span><span id="7678" class="nw kj it ns b gy ob ny l nz oa"># shuffle these three arrays <br/>articles, sections, web_ur = shuffle(articles, sections, web_url, random_state=4)</span><span id="923a" class="nw kj it ns b gy ob ny l nz oa"># split the shuffled articles into two arrays<br/>n = 10</span><span id="e91f" class="nw kj it ns b gy ob ny l nz oa"># one will have all but the last 10 articles -- think of this as your training set/corpus <br/>X_train = articles[:-n]<br/>X_train_urls = web_url[:-n]<br/>X_train_sections = sections[:-n]</span><span id="d9b4" class="nw kj it ns b gy ob ny l nz oa"># the other will have those last 10 articles -- think of this as your test set/corpus <br/>X_test = articles[-n:]<br/>X_test_urls = web_url[-n:]<br/>X_test_sections = sections[-n:]</span></pre></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="6516" class="nw kj it bd kk oc od dn ko oe of dp ks lv og oh ku lz oi oj kw md ok ol ky om bi translated">文本矢量器</h2><p id="153f" class="pw-post-body-paragraph lm ln it lo b lp nm ju lr ls nn jx lu lv no lx ly lz np mb mc md nq mf mg mh im bi translated">我们可以从几个不同的文本矢量器中进行选择，比如<strong class="lo iu">单词袋</strong>(BoW)<strong class="lo iu">Tf-Idf</strong>、<strong class="lo iu"> Word2Vec </strong>等等。</p><p id="ed25" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">以下是我们<em class="on">应该</em>选择 Tf-Idf 的一个原因:</p><p id="8a34" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">与 BoW 不同，Tf-Idf 不仅通过文本频率，还通过逆文档频率来识别单词的重要性。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi oo"><img src="../Images/f1e318a60bef31746a221499110c8c32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UYh1WtN5IoQnmjYd8ecpCw.jpeg"/></div></div></figure><p id="458b" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">因此，举例来说，如果像“奥巴马”这样的词在一篇文章中只出现几次(不像停用词“a”或“the ”,它们不传达太多信息),但在几篇不同的文章中出现，那么它将被给予较高的权重。</p><p id="dcda" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">这是有道理的，因为“奥巴马”不是一个停用词，也不是在没有充分理由的情况下被提及(即，它与文章的主题高度相关)。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="a629" class="nw kj it bd kk oc od dn ko oe of dp ks lv og oh ku lz oi oj kw md ok ol ky om bi translated">相似性度量</h2><p id="09cd" class="pw-post-body-paragraph lm ln it lo b lp nm ju lr ls nn jx lu lv no lx ly lz np mb mc md nq mf mg mh im bi translated">当选择相似性度量时，我们有几个不同的选项，例如<strong class="lo iu"> Jacard </strong>和<strong class="lo iu"> Cosine </strong>来命名一对。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi op"><img src="../Images/e9417037f44fabdb566ce02b85db429a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*asSv0pf972FGoXf9_1v0FA.png"/></div></div></figure><p id="ff97" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">Jacard 通过比较两个不同的集合并选择重叠的元素来工作。考虑到我们已经选择使用 Tf-Idf 作为矢量器，Jacard 相似性作为选项没有意义；如果我们选择 BoWs 矢量化，使用 Jacard 可能更有意义。</p><p id="34e5" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我们<em class="on">应该</em>选择余弦作为我们的相似性度量的原因是因为它作为选择 Tf-Idf 作为我们的矢量器的选项是有意义的。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/b0d74ae6244a9e0da7a0db6190bb53ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*r4nmnORdxrv6Ylz_AvpO5A.png"/></div></figure><p id="09e7" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">由于 Tf-Idf 为每篇文章中的每个令牌提供了权重，因此我们可以计算不同文章的令牌的权重之间的点积。</p><p id="b141" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">如果文章 A 对于像“Obama”和“White House”这样的标记具有高权重，文章 B 也是如此，那么与文章 B 对于那些相同的标记具有低权重的情况相比，它们的产品将产生更大的相似性得分(为了简单起见，假设所有其他标记权重都被认为是同意的)。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="72a2" class="nw kj it bd kk oc od dn ko oe of dp ks lv og oh ku lz oi oj kw md ok ol ky om bi translated">构建推荐器</h2><p id="62cc" class="pw-post-body-paragraph lm ln it lo b lp nm ju lr ls nn jx lu lv no lx ly lz np mb mc md nq mf mg mh im bi translated">这部分是神奇发生的地方！</p><p id="6568" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">在这里，您将构建一个函数，根据用户当前阅读的文章与语料库中所有其他文章之间的相似性得分(即“训练”数据)，输出前 N 篇文章推荐给用户。</p><pre class="lb lc ld le gt nr ns nt nu aw nv bi"><span id="ad15" class="nw kj it ns b gy nx ny l nz oa">def get_top_n_rec_articles(X_train_tfidf, X_train, test_article, X_train_sections, X_train_urls, n = 5):<br/>    '''This function calculates similarity scores between a document and a corpus<br/>    <br/>       INPUT: vectorized document corpus, 2D array<br/>              text document corpus, 1D array<br/>              user article, 1D array<br/>              article section names, 1D array<br/>              article URLs, 1D array<br/>              number of articles to recommend, int<br/>              <br/>       OUTPUT: top n recommendations, 1D array<br/>               top n corresponding section names, 1D array<br/>               top n corresponding URLs, 1D array<br/>               similarity scores bewteen user article and entire corpus, 1D array<br/>              '''<br/>    # calculate similarity between the corpus (i.e. the "test" data) and the user's article<br/>    similarity_scores = X_train_tfidf.dot(test_article.toarray().T)</span><span id="1434" class="nw kj it ns b gy ob ny l nz oa">    # get sorted similarity score indices  <br/>    sorted_indicies = np.argsort(similarity_scores, axis = 0)[::-1]</span><span id="26b3" class="nw kj it ns b gy ob ny l nz oa">    # get sorted similarity scores<br/>    sorted_sim_scores = similarity_scores[sorted_indicies]</span><span id="3955" class="nw kj it ns b gy ob ny l nz oa">    # get top n most similar documents<br/>    top_n_recs = X_train[sorted_indicies[:n]]</span><span id="cd81" class="nw kj it ns b gy ob ny l nz oa">    # get top n corresponding document section names<br/>    rec_sections = X_train_sections[sorted_indicies[:n]]</span><span id="a230" class="nw kj it ns b gy ob ny l nz oa">    # get top n corresponding urls<br/>    rec_urls = X_train_urls[sorted_indicies[:n]]<br/>    <br/>    # return recommendations and corresponding article meta-data<br/>    return top_n_recs, rec_sections, rec_urls, sorted_sim_scores</span></pre><p id="2ab9" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">上述函数按以下顺序工作</p><ol class=""><li id="055d" class="or os it lo b lp lq ls lt lv ot lz ou md ov mh ow ox oy oz bi translated">计算用户文章和我们语料库的相似度</li><li id="cb72" class="or os it lo b lp pa ls pb lv pc lz pd md pe mh ow ox oy oz bi translated">从最高相似度到最低相似度排序分数</li><li id="7bbb" class="or os it lo b lp pa ls pb lv pc lz pd md pe mh ow ox oy oz bi translated">获取前 N 篇最相似的文章</li><li id="f3d9" class="or os it lo b lp pa ls pb lv pc lz pd md pe mh ow ox oy oz bi translated">获取相应的前 N 篇文章部分名称和 URL</li><li id="e7a5" class="or os it lo b lp pa ls pb lv pc lz pd md pe mh ow ox oy oz bi translated">返回前 N 篇文章、版块名称、URL 和分数</li></ol></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="a1de" class="ki kj it bd kk kl nh kn ko kp ni kr ks jz nj ka ku kc nk kd kw kf nl kg ky kz bi translated">验证结果</h1><p id="ca9f" class="pw-post-body-paragraph lm ln it lo b lp nm ju lr ls nn jx lu lv no lx ly lz np mb mc md nq mf mg mh im bi translated">既然我们已经为用户推荐了阅读的文章(基于他们当前正在阅读的内容),检查一下结果是否有意义。</p><p id="136d" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">我们来对比一下用户的文章和对应的版块名与推荐的文章和对应的版块名。</p><p id="bc3d" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">首先让我们来看看相似性得分。</p><pre class="lb lc ld le gt nr ns nt nu aw nv bi"><span id="3f48" class="nw kj it ns b gy nx ny l nz oa"># similarity scores<br/>sorted_sim_scores[:5]<br/># OUTPUT:<br/># 0.566<br/># 0.498<br/># 0.479<br/># .<br/># . </span></pre><p id="eb6b" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">分数不是很高(注意余弦相似度从 0 到 1)。我们如何改进它们？我们可以选择不同的矢量器，比如 Doc2Vec。我们还可以探索不同的相似性度量。即便如此，我们还是来看看结果吧。</p><pre class="lb lc ld le gt nr ns nt nu aw nv bi"><span id="7a0c" class="nw kj it ns b gy nx ny l nz oa"># user's article's section name<br/>X_test_sections[k]<br/># OUTPUT:<br/>'U.S'</span><span id="52fb" class="nw kj it ns b gy ob ny l nz oa"># corresponding section names for top n recs <br/>rec_sections<br/># OUTPUT:<br/>'World'<br/>'U.S'<br/>'World'<br/>'World'<br/>'U.S.'</span></pre><p id="d696" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">好的，所以推荐的版块名称看起来很合适。那就好！</p><pre class="lb lc ld le gt nr ns nt nu aw nv bi"><span id="e3d2" class="nw kj it ns b gy nx ny l nz oa"># user's article<br/>X_test[k]</span><span id="2b92" class="nw kj it ns b gy ob ny l nz oa">'LOS ANGELES —  The White House says President Barack Obama has told the Defense Department that it must ensure service members instructed to repay enlistment bonuses are being treated fairly and expeditiously.\nWhite House spokesman Josh Earnest says the president only recently become aware of Pentagon demands that some soldiers repay their enlistment bonuses after audits revealed overpayments by the California National Guard.  If soldiers refuse, they could face interest charges, wage garnishments and tax liens.\nEarnest says he did not believe the president was prepared to support a blanket waiver of those repayments, but he said "we\'re not going to nickel and dime" service members when they get back from serving the country. He says they should not be held responsible for fraud perpetrated by others.'</span></pre><p id="2c31" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">好吧，用户的文章是关于支付给国民警卫队成员的超额报酬。</p><p id="4b41" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">现在让我们来看看前 N 篇推荐文章中的一些摘录:</p><pre class="lb lc ld le gt nr ns nt nu aw nv bi"><span id="458e" class="nw kj it ns b gy nx ny l nz oa"># article one<br/>'WASHINGTON —  House Speaker Paul Ryan on Tuesday called for the Pentagon to immediately suspend efforts to recover enlistment bonuses paid to thousands of soldiers in California, [...]'</span><span id="b10c" class="nw kj it ns b gy ob ny l nz oa"># article two<br/>'WASHINGTON —  The Latest on enlistment bonuses the Pentagon is ordering California National Guard soldiers to repay [...]'</span><span id="8e4b" class="nw kj it ns b gy ob ny l nz oa"># article three<br/>'SACRAMENTO, Calif. —  Nearly 10,000 California National Guard soldiers have been ordered to repay huge enlistment bonuses a decade after signing up to serve in Iraq and Afghanistan [...]'</span><span id="2af4" class="nw kj it ns b gy ob ny l nz oa"># article four<br/>'WASHINGTON —  The Pentagon worked Wednesday to stave off a public relations nightmare, suspending efforts to force California National Guard troops who served in Iraq and Afghanistan to repay their enlistment bonuses [...]'</span><span id="3d40" class="nw kj it ns b gy ob ny l nz oa"># article five <br/>'SACRAMENTO, Calif. —  The Latest on enlistment bonuses the Pentagon is ordering California National Guard soldiers to repay [...]'</span></pre><p id="da5e" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">好啊好啊！看来我们的推荐人确实很成功。所有前五名推荐的文章都与读者当前阅读的内容完全相关。还不错。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="1c6a" class="ki kj it bd kk kl nh kn ko kp ni kr ks jz nj ka ku kc nk kd kw kf nl kg ky kz bi translated">关于验证的说明</h1><p id="8852" class="pw-post-body-paragraph lm ln it lo b lp nm ju lr ls nn jx lu lv no lx ly lz np mb mc md nq mf mg mh im bi translated">我们比较推荐文本和节名的特别验证过程表明，我们的推荐器如我们所愿地工作。</p><p id="5320" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">手动梳理结果对于我们的目的来说很好，但是我们最终想要做的是创建一个完全自动化的验证过程，以便我们可以在生产中移动我们的推荐器，并让它进行自我验证。</p><p id="ba54" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">将这个推荐器投入生产超出了本文的范围。本文旨在展示如何在真实数据集上构建这样一个推荐器的原型。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="f082" class="ki kj it bd kk kl nh kn ko kp ni kr ks jz nj ka ku kc nk kd kw kf nl kg ky kz bi translated">结论</h1><p id="dd0a" class="pw-post-body-paragraph lm ln it lo b lp nm ju lr ls nn jx lu lv no lx ly lz np mb mc md nq mf mg mh im bi translated">在本文中，我们展示了如何为纽约时报的文章构建一个简单的基于内容的推荐器。我们看到，我们只需要选择一个文本矢量器和相似性度量来构建一个。然而，我们选择哪种矢量器和相似性度量会极大地影响性能。</p><p id="9fb0" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated">你可能已经注意到，在我们的推荐器中没有任何实际的机器学习。我们真正拥有的是记忆和相似分数的排序。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="f6a9" class="ki kj it bd kk kl nh kn ko kp ni kr ks jz nj ka ku kc nk kd kw kf nl kg ky kz bi translated"><strong class="ak">附加资源</strong></h1><p id="4c92" class="pw-post-body-paragraph lm ln it lo b lp nm ju lr ls nn jx lu lv no lx ly lz np mb mc md nq mf mg mh im bi translated"><a class="ae pf" href="http://infolab.stanford.edu/~ullman/mmds/ch9.pdf" rel="noopener ugc nofollow" target="_blank">标准的推荐系统信息实验室文档</a></p><p id="2bf2" class="pw-post-body-paragraph lm ln it lo b lp lq ju lr ls lt jx lu lv lw lx ly lz ma mb mc md me mf mg mh im bi translated"><a class="ae pf" href="http://benanne.github.io/2014/08/05/spotify-cnns.html" rel="noopener ugc nofollow" target="_blank"> Spotify 的深度学习音乐推荐器</a></p></div></div>    
</body>
</html>