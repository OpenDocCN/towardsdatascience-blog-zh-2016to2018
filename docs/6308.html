<html>
<head>
<title>Review: RoR — ResNet of ResNet / Multilevel ResNet (Image Classification)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回顾:RoR—ResNet/多级 ResNet(图像分类)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-ror-resnet-of-resnet-multilevel-resnet-image-classification-cd3b0fcc19bb?source=collection_archive---------15-----------------------#2018-12-06">https://towardsdatascience.com/review-ror-resnet-of-resnet-multilevel-resnet-image-classification-cd3b0fcc19bb?source=collection_archive---------15-----------------------#2018-12-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="fd17" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">残差网络的一种改进形式</h2></div><p id="1d8e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi lb translated"><span class="l lc ld le bm lf lg lh li lj di">在</span>这个故事里，<strong class="kh ir">【残网】</strong>是短暂的回顾。ResNet 作为一种先进的深度学习方法获得成功并赢得众多的识别竞赛后，有许多研究致力于如何推广或改进<a class="ae lk" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"> ResNet </a>，如<a class="ae lk" rel="noopener" target="_blank" href="/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e">预激活 ResNet </a>、ResNet (RiR)中的<a class="ae lk" href="https://medium.com/@sh.tsang/review-rir-resnet-in-resnet-image-classification-be4c79fde8ba" rel="noopener">ResNet</a>、具有随机深度(SD)的<a class="ae lk" rel="noopener" target="_blank" href="/review-stochastic-depth-image-classification-a4e225807f4a">ResNet</a>、<a class="ae lk" rel="noopener" target="_blank" href="/review-wrns-wide-residual-networks-image-classification-d3feb3fb2004">宽残差网络(WRN) </a>。RoR 是另一篇改进 ResNet 的论文，他们引入了一个概念，即一组 ResNet 块也可以有一个快捷连接。这使得一个网络成为<strong class="kh ir">多级分层 ResNet </strong>。这是一篇 2016 年在 ResNet 之后首次出现，2017 年被接受，最近终于发表在<strong class="kh ir"> 2018 TCSVT </strong>上的论文，已经被引用了几十次。(<a class="ll lm ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----cd3b0fcc19bb--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="b55b" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">涵盖哪些内容</h1><ol class=""><li id="5d0b" class="mm mn iq kh b ki mo kl mp ko mq ks mr kw ms la mt mu mv mw bi translated"><strong class="kh ir">RoR 概念(残差网络中的残差网络)</strong></li><li id="56e6" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la mt mu mv mw bi translated"><strong class="kh ir"> RoR- <em class="nc"> m </em>:级别编号<em class="nc">m</em>T31】</strong></li><li id="536a" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la mt mu mv mw bi translated"><strong class="kh ir">不同版本的 RoR </strong></li><li id="1593" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la mt mu mv mw bi translated"><strong class="kh ir">结果</strong></li></ol></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="154a" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated"><strong class="ak"> 1。RoR 概念(残差网络的残差网络)</strong></h1><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi nd"><img src="../Images/66617926a509d73fa450dc2947335ad7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yAdGUSpgPaciiCx3nLuykQ.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk"><strong class="bd nt">Original ResNet (Left), RoR (Right)</strong></figcaption></figure><p id="1f64" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae lk" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"> <strong class="kh ir">原 ResNet </strong> </a> <strong class="kh ir"> </strong>如左上所示，无数的残差块级联在一起，形成了一个非常深的网络。</p><p id="b9a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在残差块中，有两条路径:</p><ul class=""><li id="174c" class="mm mn iq kh b ki kj kl km ko nu ks nv kw nw la nx mu mv mw bi translated"><strong class="kh ir">卷积路径</strong>执行卷积以提取特征</li><li id="b07a" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nx mu mv mw bi translated"><strong class="kh ir">快捷连接路径</strong>将输入信号直接传输到下一层。</li></ul><p id="f336" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">利用捷径连接路径，可以减少梯度消失问题，因为误差信号可以在反向传播期间更容易地传播到早期层。</p><p id="3cfb" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> RoR </strong>如右上方所示，提出我们也可以有跨越一组剩余区块的捷径连接。在此之上，我们还可以有跨越一组“剩余块组”的另一个级别的快捷连接。</p><p id="b227" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者认为:</p><ul class=""><li id="c671" class="mm mn iq kh b ki kj kl km ko nu ks nv kw nw la nx mu mv mw bi translated">RoR 把学习问题转移到<strong class="kh ir">学习剩余映射</strong>的剩余映射，比<a class="ae lk" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8">原 ResNet </a>的<strong class="kh ir">简单易学。</strong></li><li id="5943" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nx mu mv mw bi translated">并且上部块中的<strong class="kh ir">层也可以将信息传播到下部块中的层</strong>。</li></ul></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="6337" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">2.RoR- <em class="ny"> m </em>:级别号<em class="ny"> m </em></h1><p id="0ce9" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko nz kq kr ks oa ku kv kw ob ky kz la ij bi translated"><strong class="kh ir">级别编号<em class="nc">m</em>T19】介绍:</strong></p><ul class=""><li id="b80b" class="mm mn iq kh b ki kj kl km ko nu ks nv kw nw la nx mu mv mw bi translated">当<strong class="kh ir"> <em class="nc"> m </em> = 1 </strong>时，RoR 只有<strong class="kh ir">末级</strong>快捷方式，即原剩余网络。</li><li id="e3aa" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nx mu mv mw bi translated">当<strong class="kh ir"> <em class="nc"> m </em> = 2 </strong>时，RoR 只有<strong class="kh ir">根级</strong>(最外层)，以及<strong class="kh ir">末级</strong>快捷方式。</li><li id="4a89" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nx mu mv mw bi translated">当<strong class="kh ir"> <em class="nc"> m </em> = 3 </strong>时，RoR 有<strong class="kh ir">根级</strong>、<strong class="kh ir">中层</strong>、<strong class="kh ir">末级</strong>快捷方式。</li></ul><p id="d0ec" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于中层快捷方式，每个快捷方式将跨越具有相同大小的特征图的剩余块。</p><p id="e478" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">并且也测试了 m = 4 和 5，但是在论文中没有关于它的任何细节。尽管如此，与 m<em class="nc">m</em>= 3 相比，结果还是不够好。</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="f70b" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">3.不同版本的 RoR</h1><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi oc"><img src="../Images/7b2c96c004ea4123a9d6c43e24c2a0dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PkfJNKdGEYyKT2DVZT7bwA.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk"><strong class="bd nt">RoR-3 Using Original ResNet (Left), RoR-3 Using Pre-Activation ResNet or WRN (Right)</strong></figcaption></figure><p id="2e2e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如上所示，RoR 适用于 ResNet 的不同版本。</p><ul class=""><li id="0906" class="mm mn iq kh b ki kj kl km ko nu ks nv kw nw la nx mu mv mw bi translated"><strong class="kh ir"> RoR-3 </strong> : RoR 使用<a class="ae lk" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8">原装 ResNet </a>带<em class="nc"> m </em> =3</li><li id="de69" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nx mu mv mw bi translated"><strong class="kh ir">预 RoR-3 </strong> : RoR 使用<a class="ae lk" rel="noopener" target="_blank" href="/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e">预激活 ResNet </a>，其中<em class="nc"> m </em> =3</li><li id="62a4" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nx mu mv mw bi translated"><strong class="kh ir"> RoR-3-WRN </strong> : RoR 用<a class="ae lk" rel="noopener" target="_blank" href="/review-wrns-wide-residual-networks-image-classification-d3feb3fb2004"> WRN 用</a>m= 3</li></ul><p id="0c80" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">简单来说，RoR-3 使用 Conv-BN-ReLU。前 RoR-3 使用 BN-ReLU-Conv，而<a class="ae lk" rel="noopener" target="_blank" href="/review-wrns-wide-residual-networks-image-classification-d3feb3fb2004"> WRN </a>是前 RoR-3 的更宽更浅的版本。(如果有兴趣，请阅读我对<a class="ae lk" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8">原创 ResNet </a>、<a class="ae lk" rel="noopener" target="_blank" href="/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e">预激活 ResNet </a>、<a class="ae lk" rel="noopener" target="_blank" href="/review-wrns-wide-residual-networks-image-classification-d3feb3fb2004"> WRN </a>的评论。)</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="3b96" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">4.结果</h1><h2 id="b9ce" class="od lv iq bd lw oe of dn ma og oh dp me ko oi oj mg ks ok ol mi kw om on mk oo bi translated"><strong class="ak"> 4.1。CIFAR-10、CIFAR-100、SVHN </strong></h2><ul class=""><li id="668a" class="mm mn iq kh b ki mo kl mp ko mq ks mr kw ms la nx mu mv mw bi translated"><strong class="kh ir"> CIFAR-10 </strong> : 10 级数据集</li><li id="a373" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nx mu mv mw bi translated"><strong class="kh ir"> CIFAR-100 </strong> : 100 级数据集</li><li id="1c5b" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nx mu mv mw bi translated"><strong class="kh ir"> SVHN </strong>:街景门牌号数据集</li></ul><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div role="button" tabindex="0" class="nj nk di nl bf nm"><div class="gh gi op"><img src="../Images/b43ee035644e47403b9fb8bc83b08c74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LSl7H0rUfFI-kYU8UUF5Uw.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk"><strong class="bd nt">Test Error (%) on CIFAR-10, CIFAR-100, SVHN Dataset</strong></figcaption></figure><ul class=""><li id="19e8" class="mm mn iq kh b ki kj kl km ko nu ks nv kw nw la nx mu mv mw bi translated"><strong class="kh ir"> RoR-3-164 </strong>:通过<strong class="kh ir">将 RoR 应用于 164 层</strong> <a class="ae lk" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"> <strong class="kh ir">原始 ResNet </strong> </a>，<strong class="kh ir"> 4.86% </strong>，<strong class="kh ir"> 22.47% </strong> (+SD 表示使用<a class="ae lk" rel="noopener" target="_blank" href="/review-stochastic-depth-image-classification-a4e225807f4a">随机深度</a>，以减少过拟合)分别得到 CIFAR-10 和 CIFAR-100 数据集的测试误差。(164 是模型深度。)</li><li id="061f" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nx mu mv mw bi translated"><strong class="kh ir"> Pre-RoR-3-164+SD </strong>:通过<strong class="kh ir">将 RoR 替换为</strong> <a class="ae lk" rel="noopener" target="_blank" href="/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e"> <strong class="kh ir">预激活 ResNet </strong> </a>，<strong class="kh ir"> 4.51% </strong>和<strong class="kh ir"> 21.94% </strong>分别得到 CIFAR-10 和 CIFAR–100 数据集的测试误差。</li><li id="8bff" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nx mu mv mw bi translated"><strong class="kh ir">RoR-3–wrn 40–4+SD</strong>:通过<strong class="kh ir">将</strong> <a class="ae lk" rel="noopener" target="_blank" href="/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e"> <strong class="kh ir">预激活 ResNet </strong> </a> <strong class="kh ir">替换为更宽的 40 层</strong><a class="ae lk" href="http://WRN" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir">wrn 40–4</strong></a><strong class="kh ir">4.09%</strong>和<strong class="kh ir"> 20.11% </strong>得到 CIFAR-10 和 CIFAR–100 数据集的测试误差</li><li id="3ce6" class="mm mn iq kh b ki mx kl my ko mz ks na kw nb la nx mu mv mw bi translated"><strong class="kh ir">RoR-3–wrn 58–4+SD</strong>:用<strong class="kh ir">更深的 58 层</strong><a class="ae lk" href="http://WRN" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir">【WRN-58–4</strong></a><strong class="kh ir">3.77%</strong><strong class="kh ir">19.73%</strong>分别得到了 CIFAR-10 和 CIFAR–100 数据集的测试误差。</li></ul><h2 id="a5d2" class="od lv iq bd lw oe of dn ma og oh dp me ko oi oj mg ks ok ol mi kw om on mk oo bi translated">4.2.ImageNet</h2><p id="b9a7" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko nz kq kr ks oa ku kv kw ob ky kz la ij bi translated">ImageNet:ils vrc 中的 1000 级大规模数据集。</p><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/63a83e2e4cef5157fc9fde29db5cb740.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*Swz3v0R765qWStj_.jpg"/></div></figure><figure class="ne nf ng nh gt ni gh gi paragraph-image"><div class="gh gi or"><img src="../Images/2c6ae5582f5fa30a4f2823f2e1199f05.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*BPOdh0rQUVXjxh2r_CMEYw.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk"><strong class="bd nt">10-Crop Testing of Validation Error (%) on ImageNet Dataset</strong></figcaption></figure><p id="d2a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">RoR-3 的不同层版本始终优于 ResNet 的不同层版本。</p><p id="7c68" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">文中有详细的烧蚀实验。如果有兴趣，请访问该文件。</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><p id="9f86" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用长短跳跃连接的类似方法也已经应用于生物医学图像分割。希望我也能报道它。</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h2 id="f119" class="od lv iq bd lw oe of dn ma og oh dp me ko oi oj mg ks ok ol mi kw om on mk oo bi translated">参考</h2><p id="be3d" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko nz kq kr ks oa ku kv kw ob ky kz la ij bi translated">【2018 TCSVT】【RoR】<br/><a class="ae lk" href="https://arxiv.org/abs/1608.02908" rel="noopener ugc nofollow" target="_blank">残差网络残差网络:多级残差网络</a></p><h2 id="55a4" class="od lv iq bd lw oe of dn ma og oh dp me ko oi oj mg ks ok ol mi kw om on mk oo bi translated">我对图像分类的相关综述</h2><p id="d3f2" class="pw-post-body-paragraph kf kg iq kh b ki mo jr kk kl mp ju kn ko nz kq kr ks oa ku kv kw ob ky kz la ij bi translated">[<a class="ae lk" href="https://medium.com/@sh.tsang/paper-brief-review-of-lenet-1-lenet-4-lenet-5-boosted-lenet-4-image-classification-1f5f809dbf17" rel="noopener">LeNet</a>][<a class="ae lk" href="https://medium.com/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160" rel="noopener">AlexNet</a>][<a class="ae lk" href="https://medium.com/coinmonks/paper-review-of-zfnet-the-winner-of-ilsvlc-2013-image-classification-d1a5a0c45103" rel="noopener">ZFNet</a>][<a class="ae lk" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener">VGGNet</a>][<a class="ae lk" href="https://medium.com/coinmonks/review-sppnet-1st-runner-up-object-detection-2nd-runner-up-image-classification-in-ilsvrc-906da3753679" rel="noopener">SPPNet</a>][<a class="ae lk" href="https://medium.com/coinmonks/review-prelu-net-the-first-to-surpass-human-level-performance-in-ilsvrc-2015-image-f619dddd5617" rel="noopener">PReLU-Net</a>][<a class="ae lk" href="https://medium.com/coinmonks/paper-review-of-googlenet-inception-v1-winner-of-ilsvlc-2014-image-classification-c2b3565a64e7" rel="noopener">Google Net/Inception-v1</a>][<a class="ae lk" href="https://medium.com/@sh.tsang/review-batch-normalization-inception-v2-bn-inception-the-2nd-to-surpass-human-level-18e2d0f56651" rel="noopener">BN-Inception/Inception-v2</a>][<a class="ae lk" href="https://medium.com/@sh.tsang/review-inception-v3-1st-runner-up-image-classification-in-ilsvrc-2015-17915421f77c" rel="noopener">Inception-v3</a>][<a class="ae lk" rel="noopener" target="_blank" href="/review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification-5e8c339d18bc">Inception-v4</a><a class="ae lk" rel="noopener" target="_blank" href="/review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification-5e8c339d18bc"/></p></div></div>    
</body>
</html>