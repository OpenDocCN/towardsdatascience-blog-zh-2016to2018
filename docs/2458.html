<html>
<head>
<title>Real Time Object Detection with TensorFlow Detection Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于张量流检测模型的实时目标检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/real-time-object-detection-with-tensorflow-detection-model-e7fd20421d5d?source=collection_archive---------3-----------------------#2018-01-28">https://towardsdatascience.com/real-time-object-detection-with-tensorflow-detection-model-e7fd20421d5d?source=collection_archive---------3-----------------------#2018-01-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="d33c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最近，我完成了<a class="ae kl" href="https://www.coursera.org/specializations/deep-learning" rel="noopener ugc nofollow" target="_blank"> deeplearning.ai </a>通过<a class="ae kl" href="https://www.google.co.in/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjW5K2ys-7YAhUMpJQKHXZ0BzkQFggoMAA&amp;url=https%3A%2F%2Fwww.coursera.org%2F&amp;usg=AOvVaw1_A8hEzXvBhSqZAjuapKcN" rel="noopener ugc nofollow" target="_blank"> Coursera </a>提供的课程 4，“<a class="ae kl" href="https://www.coursera.org/learn/convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">卷积神经网络</strong>”</a>作为“<strong class="jp ir">深度学习专业化</strong>”的一部分。<a class="ae kl" href="http://www.andrewng.org/" rel="noopener ugc nofollow" target="_blank">吴恩达</a>、<a class="ae kl" href="https://www.linkedin.com/in/kiankatan" rel="noopener ugc nofollow" target="_blank">基安·卡坦弗什</a>和<a class="ae kl" href="https://www.linkedin.com/in/younes-bensouda-mourri-8749b9a9" rel="noopener ugc nofollow" target="_blank">尤尼斯·本苏达·莫里</a>在这一专业领域提供了大量的实践和理论知识。因此，我强烈推荐任何想获得深度学习经验的人。</p><p id="99ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">自从我开始学习以来，我就对 CNN 的潜力充满了雄心和好奇，在那门课程的一周中，我学习了在图像分类中实现的思想如何对具有定位的图像分类有用，以及从定位中学到的思想如何对检测有用。嗯，在完成完全基于物体探测的第三周之后，一些事情困扰着我。</p><p id="e026" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是，在深入探讨困扰我的细节之前。我先简单解释一下什么是图像分类，我提到带定位的图像分类是什么意思。首先，让我们看看下面的图片，我知道这些狗太可爱了，所以我亲爱的读者，不要失去你的焦点:)。因此，我所说的图像分类是指每当一种算法看到这张图片[图 1]时，可能会做出反应并说这是一只狗，这意味着它能够将图像分类为一只狗的图像。</p><p id="0892" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">和[图 2]，显示了该算法如何在图像中狗的位置周围放置一个边界框或绘制一个蓝色矩形。因此，这被称为定位分类，术语定位指的是计算出狗在照片中的哪个位置被检测到。</p><p id="eb3a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以及[图 3]示出了该算法如何检测和定位图像中的不止一个而是多个对象。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi km"><img src="../Images/96b14a4de222659d68e7f0c8fb928203.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*DuNdn6qIvGt-Wv65UwpQ_Q.jpeg"/></div></figure><p id="56da" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这个简洁的解释之后，我应该把你的注意力集中到我反复提到的“事物”的问题上。我脑海中的问题是，是否存在比<a class="ae kl" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank">你只看一次(YOLO) </a>更准确的物体检测方法，以及比<a class="ae kl" href="https://arxiv.org/abs/1506.01497" rel="noopener ugc nofollow" target="_blank">更快的 R-CNNs </a>更快的每秒帧数(FPS)。除此之外，我甚至开始寻找可以在没有高计算能力或没有利用 Nvidia GPU 能力的设备上运行的网络架构，如 Titan X 或 Jetson。</p><p id="e097" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">俗话说“<strong class="jp ir">为了发现任何东西，你必须寻找某些东西</strong>”。因此，我花了几个小时的时间进行研究，找到了“<a class="ae kl" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank"> TensorFlow 对象检测 API </a>”，这是一个基于 TensorFlow 构建的开源框架，可以轻松构建、训练和部署对象检测模型，并且它还提供了一系列在<a class="ae kl" href="http://mscoco.org/" rel="noopener ugc nofollow" target="_blank"> COCO 数据集</a>、<a class="ae kl" href="http://www.cvlibs.net/datasets/kitti/" rel="noopener ugc nofollow" target="_blank"> Kitti 数据集</a>和<a class="ae kl" href="https://github.com/openimages/dataset" rel="noopener ugc nofollow" target="_blank">开放图像数据集</a>上预先训练的检测模型。众多检测模型中的一种是<strong class="jp ir"> </strong> <a class="ae kl" href="https://arxiv.org/abs/1512.02325" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">单次检测器(SSD)</strong></a>和<a class="ae kl" href="https://arxiv.org/abs/1704.04861" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir"> MobileNets </strong> </a>架构的组合，其快速、高效且不需要巨大的计算能力来完成对象检测任务，其示例可在下图中看到。所以，简而言之，我的每一个问题都通过 SSDs 和 MobileNets 模型的结合得到了回答。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ku"><img src="../Images/28a827bff1e160256668b32fa6ddb538.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZeDQGWRoERxO9dW9Sqgc_w.jpeg"/></div></div></figure><p id="d4f5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在向大家介绍了计算机视觉领域中经常使用的各种术语并自我回答了我的问题之后，现在我应该跳到实践部分，告诉大家如何通过使用<a class="ae kl" href="https://www.google.co.in/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiTz_nav_DYAhVDs48KHe3WBsUQFggoMAA&amp;url=https%3A%2F%2Fopencv.org%2F&amp;usg=AOvVaw0nLWFztJIlbNMAYoheT9Qm" rel="noopener ugc nofollow" target="_blank"> OpenCV </a>和<a class="ae kl" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>以及 ssd_mobilenet_v1 模型[<a class="ae kl" href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">SSD _ mobilenet _ v1 _ COCO</strong>】在 COCO[上下文中的常见对象]数据集上训练，我能够使用一个 7 美元的网络摄像头和一台笔记本电脑进行实时对象检测。</a></p><p id="b8b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">那么，不多说了，让我们开始吧</p><ol class=""><li id="35f3" class="kz la iq jp b jq jr ju jv jy lb kc lc kg ld kk le lf lg lh bi translated">首先到达这个<a class="ae kl" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">链接</strong> </a>，在目录下，设置部分，点击安装子部分。</li><li id="7fc2" class="kz la iq jp b jq li ju lj jy lk kc ll kg lm kk le lf lg lh bi translated">基本上，安装部分由 TensorFlow 对象检测 API 所依赖的库列表组成。因此，在前进之前安装每一个依赖项。</li><li id="8a90" class="kz la iq jp b jq li ju lj jy lk kc ll kg lm kk le lf lg lh bi translated">在所有的库中，你需要再安装一个库，就是<a class="ae kl" href="https://github.com/google/protobuf/releases" rel="noopener ugc nofollow" target="_blank"> Protobuf 2.6 </a>。由于我用的是 Windows 10【你可以根据你用的操作系统下载 zip 文件】我下载并解压了这个文件<a class="ae kl" href="https://github.com/google/protobuf/releases/download/v3.5.1/protoc-3.5.1-win32.zip" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">protocol-3 . 5 . 1-win32 . zip</strong></a><strong class="jp ir">。</strong></li><li id="7d25" class="kz la iq jp b jq li ju lj jy lk kc ll kg lm kk le lf lg lh bi translated">安装好所有要求后，就该下载模型了，你可以在这里 找到<a class="ae kl" href="https://github.com/tensorflow/models" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">。这完全取决于你是想克隆还是下载这个库。做好决定后，解压<a class="ae kl" href="https://github.com/tensorflow/models.git" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">文件</strong> </a>，确保你的协议和模型文件在同一个文件夹里。</strong></a></li><li id="d23d" class="kz la iq jp b jq li ju lj jy lk kc ll kg lm kk le lf lg lh bi translated">然后，我们需要将模型主文件夹的名称更改为模型，如果您在模型文件夹中查找研究文件夹，然后在研究文件夹中查找对象检测文件夹，在对象检测文件夹中查找 protos 文件夹。</li><li id="d0e4" class="kz la iq jp b jq li ju lj jy lk kc ll kg lm kk le lf lg lh bi translated">一旦你打开它，你会发现没有像 box.predictor_pb2.py，faster_rcnn_box_coder_pb2.py 这样命名的文件，为了得到这些文件，我们需要编译 Protobuf 库。</li><li id="fb5d" class="kz la iq jp b jq li ju lj jy lk kc ll kg lm kk le lf lg lh bi translated">因此，为了编译 Protobuf 库，打开 Anaconda 提示符，将目录更改为保存这两个文件夹的位置，然后执行[change directory]CD models/research，然后给出这个命令，该命令包含您的 protoc.exe 文件所在的完整路径，后跟[protoc object _ detection/protos/*。proto — python_out=。].</li><li id="2e80" class="kz la iq jp b jq li ju lj jy lk kc ll kg lm kk le lf lg lh bi translated">例如，[C:/Users/ADMIN/TF _ obj _ det/protoc-3 . 4 . 0-win32/bin/protoc object _ detection/protos/*。proto — python_out=。]，这里 tf_obj_det 是我解压后保存模型和协议文件的文件夹。</li><li id="b61e" class="kz la iq jp b jq li ju lj jy lk kc ll kg lm kk le lf lg lh bi translated">现在，完成编译部分后，只需在 Anaconda 提示符/ Anaconda 终端上键入 jupyter notebook，然后一旦 jupyter notebook 打开，您就可以为实时对象检测编写代码了。</li><li id="5d96" class="kz la iq jp b jq li ju lj jy lk kc ll kg lm kk le lf lg lh bi translated">你可以使用我的资源库中的这个项目的代码，这个资源库在“参考资料”一节中提到，我还包括了 YouTube 视频的链接，它实际上演示了我的网络摄像头如何检测一帧中的每个对象，你可以在下图中体验。</li></ol><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/a99763b58f59dd44b02a24f008328c54.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/1*mB7LlyxXRioEi5AAHez_CA.gif"/></div></figure><p id="8c18" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后一件事… <br/>如果你喜欢这篇文章，请点击👏下面，并与他人分享，这样他们也可以享受它。</p><p id="9ccd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">参考资料:</p><ol class=""><li id="7671" class="kz la iq jp b jq jr ju jv jy lb kc lc kg ld kk le lf lg lh bi translated">这个项目代码的 GitHub 库链接可以在<a class="ae kl" href="https://github.com/ElephantHunters/Real_time_object_detection_using_tensorflow" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</li><li id="35e2" class="kz la iq jp b jq li ju lj jy lk kc ll kg lm kk le lf lg lh bi translated">为了了解更多关于物体探测的信息，你可以点击<a class="ae kl" href="https://en.wikipedia.org/wiki/Object_detection" rel="noopener ugc nofollow" target="_blank">这里</a>。</li><li id="e89a" class="kz la iq jp b jq li ju lj jy lk kc ll kg lm kk le lf lg lh bi translated">为了了解更多关于卷积神经网络的知识，你可以点击<a class="ae kl" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">这里</a>。</li><li id="f733" class="kz la iq jp b jq li ju lj jy lk kc ll kg lm kk le lf lg lh bi translated">最后但同样重要的是，你可以在这里查看 YouTube 视频<a class="ae kl" href="https://youtu.be/Ic2zxAzioNQ" rel="noopener ugc nofollow" target="_blank"/>。</li></ol></div></div>    
</body>
</html>