<html>
<head>
<title>I trained a Word2Vec model on a strict diet of Fox News broadcasts</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我训练了一个严格按照福克斯新闻频道广播饮食的 Word2Vec 模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/i-trained-a-word2vec-model-on-a-strict-diet-of-fox-news-broadcasts-14da0b174b11?source=collection_archive---------7-----------------------#2017-05-26">https://towardsdatascience.com/i-trained-a-word2vec-model-on-a-strict-diet-of-fox-news-broadcasts-14da0b174b11?source=collection_archive---------7-----------------------#2017-05-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="2879" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是它对世界的看法。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/588127e33ad8f725d4a7b273240f0d19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GWYp9kUDE0yUEARQECZVfg.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Screenshot of my attempt at a visually representing word embeddings. See the original <a class="ae lb" href="http://truediggs.com/presdev/neww2v.html" rel="noopener ugc nofollow" target="_blank">here.</a></figcaption></figure><h1 id="a175" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">背景</h1><p id="4927" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">几个月前，我第一次开始尝试 Word2Vec，当时我在 NYU 大学为一门文本分析课程做项目。该项目是一种概念验证，包括收集和分析数百万西班牙语 YouTube 评论，试图检测和测量政治导向的言论。</p><p id="b2ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">虽然 Word2Vec 实际上不是我们在本课程中学习的模型之一，但它捕捉单词之间微妙关系的能力给我留下了深刻的印象。</p><p id="8776" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">分析用户生成的西班牙语文本的一个主要问题是拼写——尽管有很大程度上的音位拼写，我发现到处都有拼写和语法错误。</p><p id="bc88" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不幸的是，目前可用的停用词词典只包括单词的正式拼写，这实际上比某些术语的错误拼写更不常见。更糟糕的是，拼写错误如此之多，以至于无法通过调整词频或缩减采样来消除。</p><p id="5cc9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Word2Vec 来救援！通过选取一个常见的拼写错误，并在模型中查询 50 个最相似的单词，我能够构建一个全面的停用词字典来过滤它们。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mg"><img src="../Images/83e420a9270c8140c3709dc001209c68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ukgrWaP2Xydf_n-oYv-NpA.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Fifty common but not super-common variations on the word “haha”? Not funny!</figcaption></figure><h1 id="09eb" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">那么，为什么是福克斯新闻频道？</h1><p id="ae0b" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">上面的实验真正说明了 Word2Vec 揭开语言“个性”的真正力量。我想:如果我训练一个 Word2Vec 语言模型，它以一种非常微妙的方式只代表现实的一种视觉，会怎么样？我唯一能想到的英语候选人是福克斯新闻频道。</p><h1 id="3354" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">挑战</h1><h2 id="9489" class="mh ld iq bd le mi mj dn li mk ml dp lm jy mm mn lq kc mo mp lu kg mq mr ly ms bi translated">获取文本</h2><p id="05d8" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">虽然福克斯新闻频道实际上在其网站上制作书面文本，但我想要一个考虑到整个福克斯体验的语料库:嘉宾评论、即兴评论、主持人之间的戏谑等。</p><p id="df03" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我家里没有有线电视，所以我建立了一个网络抓取器，提取了当时福克斯新闻频道网站上所有视频的音频——大约 1150 个剪辑，长度从 1 分钟到 20 分钟不等。虽然一些视频可以追溯到 2015 年，但绝大多数是在过去六个月发布的。</p><p id="ae22" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了转换音频，我使用了谷歌的语音识别 API，因为它产生的结果比任何其他服务都好得多(加上他们给你 300 美元的免费积分)。我在这里解释我是如何做到这一点的<a class="ae lb" href="https://medium.com/towards-data-science/tutorial-asynchronous-speech-recognition-in-python-b1215d501c64" rel="noopener">。</a></p><h2 id="1fd3" class="mh ld iq bd le mi mj dn li mk ml dp lm jy mm mn lq kc mo mp lu kg mq mr ly ms bi translated">哦，标点符号…</h2><p id="5263" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">语音识别模型的一个不幸之处是，它们返回的文本实际上没有任何标点符号。这在使用 Word2Vec 时特别烦人，因为您需要向它输入标记化的句子(需要标点)。</p><p id="775c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">幸运的是，奥托卡·提尔克已经掩护了我。他训练了一个双向递归神经网络模型，可以恢复英语文本中的标点符号。最棒的是，这个了不起的人还创造了一个<a class="ae lb" href="http://bark.phon.ioc.ee/punctuator" rel="noopener ugc nofollow" target="_blank"> API </a>，你可以很容易地从 Python 中查询。</p><h2 id="12b3" class="mh ld iq bd le mi mj dn li mk ml dp lm jy mm mn lq kc mo mp lu kg mq mr ly ms bi translated">唐纳德卡车在房子里！</h2><p id="4e8c" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">没错。谷歌并非完美无瑕。有时它会误解某些单词和短语，尤其是当人们互相谈论的时候。例如，与<a class="ae lb" href="https://en.wikipedia.org/wiki/Michael_T._Flynn" rel="noopener ugc nofollow" target="_blank">迈克尔·弗林</a>相关的最常见术语之一是“律师”，但“锦标赛”一词也出现在前 20 名中。</p><p id="5e38" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我最初的策略是尝试使用变音编码和模糊字符串匹配来发现这些错误。然而，事实证明这比我原先预计的要花更多的时间，所以我搁置了这个想法。</p><p id="7b8a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最终，我能够调整<a class="ae lb" href="https://radimrehurek.com/gensim/models/word2vec.html" rel="noopener ugc nofollow" target="_blank"> Word2Vec </a>模型的参数，以最小化不正确术语的影响。</p><h1 id="b045" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">结果</h1><p id="0b39" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">该模型接受了约 50 万个术语的训练——对于 Word2Vec 来说，这不是一个庞大的语料库，但结果仍然非常有趣。我列出了大约 24 个与当前事件或政治问题相关的术语，找到了与它们最相关的词，并将它们添加到(蹩脚的)D3js 图中。</p><p id="2a58" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不幸的是，Medium 不允许我嵌入 JavaScript vizualiations，所以你必须<a class="ae lb" href="http://truediggs.com/presdev/neww2v.html" rel="noopener ugc nofollow" target="_blank">在这里</a>查看。</p><p id="4793" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一如既往，我希望听到您的反馈或建议。此外，如果你对我是如何做上述任何事情感到好奇，不要犹豫，伸出手来！</p></div></div>    
</body>
</html>