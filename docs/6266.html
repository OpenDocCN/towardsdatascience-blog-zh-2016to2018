<html>
<head>
<title>How to deploy Jupyter notebooks as components of a Kubeflow ML pipeline (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何将 Jupyter 笔记本部署为 Kubeflow ML 管道的组件(第 2 部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-deploy-jupyter-notebooks-as-components-of-a-kubeflow-ml-pipeline-part-2-b1df77f4e5b3?source=collection_archive---------10-----------------------#2018-12-04">https://towardsdatascience.com/how-to-deploy-jupyter-notebooks-as-components-of-a-kubeflow-ml-pipeline-part-2-b1df77f4e5b3?source=collection_archive---------10-----------------------#2018-12-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="16c0" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在 Kubernetes 集群上运行 Jupyter 笔记本的简单方法</h2></div><p id="3260" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在第 1 部分中，我向您展示了如何使用 Docker 组件创建和部署 Kubeflow ML 管道。在第 2 部分中，我将向您展示如何让 Jupyter 笔记本成为 Kubeflow ML 管道的一个组件。Docker 组件是为操作机器学习模型的人准备的，能够在任意硬件上运行 Jupyter 笔记本更适合数据科学家。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/7448100a3506d6995eab1ec7319e7a32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q70VJ5n6MbVHmA6sxmCC6g.jpeg"/></div></div><figcaption class="lo lp gj gh gi lq lr bd b be z dk">In this article, I show you an easy way to run your Jupyter notebook as a container in Kubernetes. (Photo by <a class="ae lb" href="https://unsplash.com/photos/QtETdXXR7gs?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Cameron Venti</a> on <a class="ae lb" href="https://unsplash.com/search/photos/container?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a>)</figcaption></figure><p id="68da" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我将假设您已经有了一个 Kubeflow 管道集群，并按照上一篇文章中的解释运行。通常，“ML 平台团队”(IT 部门的一部分)将管理供数据科学家团队使用的集群。</p><h2 id="9610" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">第一步。启动 JupyterHub</h2><p id="76d8" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated"><em class="mq">注意:当我写这篇文章时，您必须在集群本身上运行笔记本。不过，现在更好的方法是使用人工智能平台笔记本，并远程向集群提交代码。遵循本自述文件中的说明，确保启动 TensorFlow 1.10 笔记本电脑虚拟机。跳过这一步，从第 2 步开始。</em></p><p id="36e9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从 Kubeflow pipelines 用户界面(http://localhost:8085/pipeline，如果您遵循了上一篇文章中的说明)，单击笔记本的链接:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/7807d573bdf4189908ec6070ca7537dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:366/format:webp/1*3OOQWDkIlGqYOxrGf0fJHA.png"/></div><figcaption class="lo lp gj gh gi lq lr bd b be z dk">Click on the notebooks link from Kubeflow pipelines to start JupyterHub on the cluster and start working with notebooks</figcaption></figure><p id="fbf2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果这是第一次，这将提示您启动 JupyterHub。使用您的 GCP 用户名/密码登录。然后，选择所需的 Tensorflow 版本:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/32ad842850d777a5aec0abe3eb526d10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*eM-VbrhoQQiMgTpC-c4Epw.png"/></div><figcaption class="lo lp gj gh gi lq lr bd b be z dk">Choose the version of TensorFlow</figcaption></figure><p id="a156" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我在一个 cpu 上选择了 TensorFlow v1.10。</p><h2 id="745c" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">第二步。克隆 git repo</h2><p id="9973" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">然后，打开一个终端窗口，git 克隆我的 repo:</p><pre class="ld le lf lg gt mt mu mv mw aw mx bi"><span id="98c7" class="ls lt iq mu b gy my mz l na nb">git clone https://github.com/GoogleCloudPlatform/data-science-on-gcp</span></pre><p id="ef5c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">切换回 Jupyter 笔记本列表，导航到 data-science-on-GCP/updates/cloud ml，打开<a class="ae lb" href="https://github.com/GoogleCloudPlatform/data-science-on-gcp/blob/master/updates/cloudml/flights_model.ipynb" rel="noopener ugc nofollow" target="_blank"> flights_model.ipynb </a>。</p><h2 id="b263" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">第三步。用张量流预测航班延误</h2><p id="4dba" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">实际的 TensorFlow 代码(参见这里的完整笔记本:<a class="ae lb" href="https://github.com/GoogleCloudPlatform/data-science-on-gcp/blob/master/updates/cloudml/flights_model.ipynb" rel="noopener ugc nofollow" target="_blank"> flights_model.ipynb </a>)并不重要，但是我希望您注意一些事情。一个是，我开发这款笔记本电脑时，大部分时间都是在急切模式下进行的，以便于调试:</p><pre class="ld le lf lg gt mt mu mv mw aw mx bi"><span id="250d" class="ls lt iq mu b gy my mz l na nb">if EAGER_MODE:<br/>    dataset = load_dataset(TRAIN_DATA_PATTERN)<br/>    for n, data in enumerate(dataset):<br/>      numpy_data = {k: v.numpy() for k, v in data.items()} # .numpy() works only in eager mode<br/>      print(numpy_data)<br/>      if n&gt;3: break</span></pre><p id="35fa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我对模型进行了几个步骤的训练，并指定了更多的步骤(如果“不在开发模式中”:</p><pre class="ld le lf lg gt mt mu mv mw aw mx bi"><span id="78da" class="ls lt iq mu b gy my mz l na nb">num_steps = 10 if DEVELOP_MODE else (1000000 // train_batch_size)</span></pre><p id="5982" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我将其作为 web 服务部署到 Cloud ML Engine:</p><pre class="ld le lf lg gt mt mu mv mw aw mx bi"><span id="37ad" class="ls lt iq mu b gy my mz l na nb">gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version 1.10</span></pre><p id="156f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">并确保我可以将 JSON 发送到已部署的模型:</p><pre class="ld le lf lg gt mt mu mv mw aw mx bi"><span id="29cd" class="ls lt iq mu b gy my mz l na nb">{"dep_delay": 14.0, "taxiout": 13.0, "distance": 319.0, "avg_dep_delay": 25.863039, "avg_arr_delay": 27.0, "carrier": "WN", "dep_lat": 32.84722, "dep_lon": -96.85167, "arr_lat": 31.9425, "arr_lon": -102.20194, "origin": "DAL", "dest": "MAF"}<br/>{"dep_delay": -9.0, "taxiout": 21.0, "distance": 301.0, "avg_dep_delay": 41.050808, "avg_arr_delay": -7.0, "carrier": "EV", "dep_lat": 29.984444, "dep_lon": -95.34139, "arr_lat": 27.544167, "arr_lon": -99.46167, "origin": "IAH", "dest": "LRD"}</span></pre><p id="fe5e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了返回，对于每个实例，航班将晚点的概率。</p><h2 id="3800" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">第四步。将笔记本电脑部署为组件</h2><p id="9c80" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">所以，我有一个完全成熟的笔记本电脑，可以完成一些 ML 工作流程。我能把它作为 Kubeflow 管道的一部分来执行吗？回想一下<a class="ae lb" rel="noopener" target="_blank" href="/how-to-create-and-deploy-a-kubeflow-machine-learning-pipeline-part-1-efea7a4b650f"> <em class="mq">第 1 部分</em> </a>中的内容，一个组件所需要的只是一个自包含的容器，它接受几个参数并将输出写到文件中，或者在 Kubeflow 集群上，或者在云存储上。</p><p id="54a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了将 flights_model 笔记本部署为一个组件:</p><ul class=""><li id="4ea4" class="nc nd iq kh b ki kj kl km ko ne ks nf kw ng la nh ni nj nk bi translated">我的笔记本顶部有一个单元格，它的标签是“参数”。在这个单元格中，我定义了我想要用来重新执行笔记本的任何变量。特别是，我设置了一个名为 DEVELOP_MODE 的变量。在开发模式下，我将读取小数据集；在非开发模式下，我将在完整数据集上进行训练。因为我希望您能够轻松地更改它们，所以我还将 PROJECT(要计费)和 BUCKET(要存储输出)作为参数。</li><li id="04c3" class="nc nd iq kh b ki nl kl nm ko nn ks no kw np la nh ni nj nk bi translated">然后，我构建一个能够执行我的笔记本的 Docker 映像。为了执行一个笔记本，我将使用 Python 包 papermill。我的笔记本用的是 Python3，gcloud，tensorflow。所以我的 docker 文件捕获了<a class="ae lb" href="https://github.com/GoogleCloudPlatform/data-science-on-gcp/blob/master/updates/cloudml/submitnotebook/Dockerfile" rel="noopener ugc nofollow" target="_blank">docker 文件</a>中的所有依赖项</li></ul><pre class="ld le lf lg gt mt mu mv mw aw mx bi"><span id="20ef" class="ls lt iq mu b gy my mz l na nb">FROM <strong class="mu ir">google/cloud</strong>-sdk:latest</span><span id="86ec" class="ls lt iq mu b gy nq mz l na nb">RUN apt-get update -y &amp;&amp; apt-get install --no-install-recommends -y -q ca-certificates <strong class="mu ir">python3-dev</strong> python3-setuptools python3-pip</span><span id="6119" class="ls lt iq mu b gy nq mz l na nb">RUN python3 -m pip install <strong class="mu ir">tensorflow==1.10 jupyter papermill</strong></span><span id="5017" class="ls lt iq mu b gy nq mz l na nb">COPY run_notebook.sh ./</span><span id="714e" class="ls lt iq mu b gy nq mz l na nb">ENTRYPOINT ["bash", "./run_notebook.sh"]</span></pre><ul class=""><li id="222b" class="nc nd iq kh b ki kj kl km ko ne ks nf kw ng la nh ni nj nk bi translated">Docker 映像的入口点是<a class="ae lb" href="https://github.com/GoogleCloudPlatform/data-science-on-gcp/blob/master/updates/cloudml/submitnotebook/run_notebook.sh" rel="noopener ugc nofollow" target="_blank"> run_notebook.sh </a>，它使用 papermill 来执行笔记本:</li></ul><pre class="ld le lf lg gt mt mu mv mw aw mx bi"><span id="b799" class="ls lt iq mu b gy my mz l na nb">gsutil cp $IN_NB_GCS  input.ipynb<br/>gsutil cp $PARAMS_GCS params.yaml<br/><strong class="mu ir">papermill input.ipynb output.ipynb -f params.yaml --log-output</strong><br/>gsutil cp output.ipynb $OUT_NB_GCS</span></pre><ul class=""><li id="f348" class="nc nd iq kh b ki kj kl km ko ne ks nf kw ng la nh ni nj nk bi translated">实际上，该脚本将要运行的笔记本从 Google 云存储复制到 Kubeflow pod，用 papermill 运行笔记本，并将结果输出复制回 Google 云存储。</li><li id="914a" class="nc nd iq kh b ki nl kl nm ko nn ks no kw np la nh ni nj nk bi translated">但是 params.yaml？params.yaml 是什么？这些是笔记本电脑的可配置参数。例如，它可以是:</li></ul><pre class="ld le lf lg gt mt mu mv mw aw mx bi"><span id="9a94" class="ls lt iq mu b gy my mz l na nb">---<br/>BUCKET: cloud-training-demos-ml<br/>PROJECT: cloud-training-demos<br/>DEVELOP_MODE: False</span></pre><ul class=""><li id="b3f5" class="nc nd iq kh b ki kj kl km ko ne ks nf kw ng la nh ni nj nk bi translated">就是这样！当这个 Docker 映像运行时，它将执行提供的笔记本并复制输出笔记本(标绘了图形，训练了模型等)。)到 GCS。</li></ul><h2 id="3955" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">第五步。作为管道的一部分启动笔记本组件</h2><p id="b9ff" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">将笔记本作为管道中的一个步骤来运行的意义在于，它可以在其他管道中进行编排和重用。但是，为了向您展示如何做到这一点，您应该这样创建一个仅执行该笔记本的管道:</p><pre class="ld le lf lg gt mt mu mv mw aw mx bi"><span id="010a" class="ls lt iq mu b gy my mz l na nb">import kfp.components as comp<br/>import kfp.dsl as dsl</span><span id="7cd4" class="ls lt iq mu b gy nq mz l na nb"># a single-op pipeline that runs the flights pipeline on the pod<br/><a class="ae lb" href="http://twitter.com/dsl" rel="noopener ugc nofollow" target="_blank">@dsl</a>.pipeline(<br/>   name='FlightsPipeline',<br/>   description='Trains, deploys flights model'<br/>)<br/>def flights_pipeline(<br/>   inputnb=dsl.PipelineParam('inputnb'),<br/>   outputnb=dsl.PipelineParam('outputnb'),<br/>   params=dsl.PipelineParam('params')<br/>):<br/>    notebookop = dsl.ContainerOp(<br/>      name='flightsmodel',<br/>      image='gcr.io/cloud-training-demos/<strong class="mu ir">submitnotebook</strong>:latest',<br/>      arguments=[<br/>        <strong class="mu ir">inputnb,<br/>        outputnb,<br/>        params</strong><br/>      ]<br/>    )</span></pre><p id="0f04" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">没什么特别的——我正在创建一个容器，告诉它使用我的图像，它有 TensorFlow、papermill 等。并给它输入和输出笔记本和参数。随着管道的运行，日志流传输到管道日志，并将显示在 Stackdriver 中:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nr"><img src="../Images/c652b1c12efb89c2a66f8dec6eb9e1b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wBsQaweaVN7nOlq4x4D0NQ.png"/></div></div><figcaption class="lo lp gj gh gi lq lr bd b be z dk">As the pipeline executes, the notebook cells’ outputs get streamed to Stackdriver</figcaption></figure><p id="37c4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我的 GitHub repo 中，创建和部署管道显示在<a class="ae lb" href="https://github.com/GoogleCloudPlatform/data-science-on-gcp/blob/master/updates/cloudml/launcher.ipynb" rel="noopener ugc nofollow" target="_blank"> launcher.ipynb </a>中。</p><h2 id="07c8" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">尝试一下</h2><p id="720c" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated"><em class="mq">如果您还没有这样做，请阅读并浏览如何使用 Docker 映像</em>  <em class="mq">创建和部署 Kubeflow ML 管道的第 1 部分</em> <a class="ae lb" rel="noopener" target="_blank" href="/how-to-create-and-deploy-a-kubeflow-machine-learning-pipeline-part-1-efea7a4b650f"> <em class="mq">。</em></a></p><p id="e0ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尝试这篇关于如何在 Kubeflow 管道中部署 Jupyter 笔记本作为组件的文章:</p><ol class=""><li id="967c" class="nc nd iq kh b ki kj kl km ko ne ks nf kw ng la ns ni nj nk bi translated">按照第 1 部分中的说明启动一个集群</li><li id="44ea" class="nc nd iq kh b ki nl kl nm ko nn ks no kw np la ns ni nj nk bi translated">在集群上，打开<a class="ae lb" href="https://github.com/GoogleCloudPlatform/data-science-on-gcp/blob/master/updates/cloudml/flights_model.ipynb" rel="noopener ugc nofollow" target="_blank"> flights_model.ipynb </a>，将项目和 BUCKET 更改为您自己的东西，并运行笔记本，确保它可以工作。</li><li id="f6f3" class="nc nd iq kh b ki nl kl nm ko nn ks no kw np la ns ni nj nk bi translated">打开<a class="ae lb" href="https://github.com/GoogleCloudPlatform/data-science-on-gcp/blob/master/updates/cloudml/launcher.ipynb" rel="noopener ugc nofollow" target="_blank"> launcher.ipynb </a>并完成运行 flights_model.ipynb 和作为 Kubeflow 管道组件的步骤。</li></ol><p id="d1fe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">启动器笔记本还包括在深度学习虚拟机上启动 flights_model 笔记本的能力，但现在忽略它——我将在本系列的第 3 部分中介绍它。</p><p id="7657" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">笔记本可以是可组合性和可重用性的一个单元——但是为了实现这一点，你必须小心编写小的、单一用途的笔记本。我在这篇文章中所做的——一个巨大的单片笔记本——并不是一个好主意。权衡的结果是，如果您使用较小的笔记本，依赖性跟踪会变得困难。</p><h2 id="3c3a" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">什么时候用什么</h2><ul class=""><li id="a0fb" class="nc nd iq kh b ki ml kl mm ko nt ks nu kw nv la nh ni nj nk bi translated">如果你是一个小团队，并且没有人为你维护像 Kubeflow clusters 这样的 ML 基础设施，那么使用<a class="ae lb" href="https://cloud.google.com/deep-learning-vm/" rel="noopener ugc nofollow" target="_blank">深度学习 VM </a>进行开发和自动化。我将在本系列的第 3 部分中讨论这个问题。</li><li id="9cdf" class="nc nd iq kh b ki nl kl nm ko nn ks no kw np la nh ni nj nk bi translated">如果您在一个大型组织中工作，其中有一个独立的 ML 平台团队管理您的 ML 基础设施(即 Kubeflow 集群)，本文(第 2 部分)将向您展示如何在 Jupyter 笔记本中开发并部署到 Kubeflow 管道。(如果您向 IT 团队展示这篇文章，他们可能会帮助您完成 Docker 部分)。</li><li id="0823" class="nc nd iq kh b ki nl kl nm ko nn ks no kw np la nh ni nj nk bi translated">虽然笔记本会帮助你变得敏捷，但是你也会积累大量的技术债务。单体笔记本很难重用，单一用途的笔记本很难跟踪依赖性。第二，即使你的日志会转到 GCP 的日志平台(Stackdriver)，它们也可能是非结构化的单元输出。这使得很难监控管道和对故障做出反应。因此，计划将成熟的代码和模型从笔记本转移到单独的管道组件中，每个组件都是一个容器。这是我在<a class="ae lb" rel="noopener" target="_blank" href="/how-to-create-and-deploy-a-kubeflow-machine-learning-pipeline-part-1-efea7a4b650f"> <em class="mq">第一部</em> </a>里给你看的。</li></ul><p id="e3b6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">换句话说，对小团队使用深度学习 VM，对实验工作使用 Jupyter 组件，对成熟模型使用容器操作</p></div></div>    
</body>
</html>