<html>
<head>
<title>Implementing T-SNE in Tensorflow [ Manual Back Prop in TF ]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Tensorflow 中实现 T-SNE[TF 中的手动回柱]</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-t-sne-in-tensorflow-manual-back-prop-in-tf-b08c21ee8e06?source=collection_archive---------2-----------------------#2018-07-23">https://towardsdatascience.com/implementing-t-sne-in-tensorflow-manual-back-prop-in-tf-b08c21ee8e06?source=collection_archive---------2-----------------------#2018-07-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/69fe0abc1a7a7746194e09b79196c3cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*OjaduSHs6Q_FlWwfFfPVvA.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">GIF from this <a class="ae jy" href="https://giphy.com/gifs/star-universe-galaxy-l0Exm2Wa4TermgtJC" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="06fa" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">今天，我只是想研究一下 t 分布随机邻居嵌入(t-SNE)，并想在 tensorflow 中实现它，同时创建一些可视化。下面是我们要比较的案例。</p><p id="712b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="kx">案例 A)纯 T-SNE 降维到 2D <br/>案例 B)全连接网络作为 T-SNE 降维到 2D <br/>案例 C)卷积神经网络作为 T-SNE 降维到 2D <br/>案例 D)全连接网络作为 T-SNE 降维到 3D <br/>案例 E)卷积神经网络作为 T-SNE 降维到 3D </em> </strong></p><blockquote class="ky kz la"><p id="b8be" class="jz ka kx kb b kc kd ke kf kg kh ki kj lb kl km kn lc kp kq kr ld kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="iq">请注意这篇帖子是为了我未来的自己，回顾如何在 tensorflow 中实现 T-SNE。</em>T11】</strong></p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="lp lq l"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Original SNE paper from this <a class="ae jy" href="https://cs.nyu.edu/~roweis/papers/sne_final.pdf" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="lp lq l"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">TSNE paper from this <a class="ae jy" href="http://www.cs.toronto.edu/~hinton/absps/tsne.pdf" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="98d8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果有人感兴趣，T-SNE 最初是基于辛顿教授发明的随机邻居嵌入(SNE)。我链接了原始的 SNE 论文和 T-SNE 论文。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="8964" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">T-SNE 比 PCA 做得更好的案例</strong></p><div class="ll lm ln lo gt ab cb"><figure class="lr jr ls lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/a77f16db5e4073ef504f68a3d105dda0.png" data-original-src="https://miro.medium.com/v2/resize:fit:386/format:webp/1*suMzRvAR5ZwwE3tcaQF8Dg.png"/></div></figure><figure class="lr jr mb lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/020a2b692f7df9581da799513b47e55d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1616/format:webp/1*qTKSfwPlnbYnd20SrgkC2A.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk mc di md me">Image from this <a class="ae jy" href="https://www.analyticsvidhya.com/blog/2017/01/t-sne-implementation-r-python/" rel="noopener ugc nofollow" target="_blank">website</a> and this <a class="ae jy" href="https://www.youtube.com/watch?v=RJVL80Gg3lA" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure></div><p id="6591" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">已经有不同的方法来执行降维，但是传统方法存在局限性。例如，主成分分析(PCA)以线性方式降低维度，并且在一些情况下，更高维度的几何形状是以非线性方式。它没有捕捉到关键信息。更多更好更深入的解释请阅读这篇<a class="ae jy" href="https://www.quora.com/What-advantages-does-the-t-SNE-algorithm-have-over-PCA" rel="noopener ugc nofollow" target="_blank">博文</a>或观看下面的视频。</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="mf lq l"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Video from <a class="ae jy" href="https://www.youtube.com/channel/UCtXKDgv1AVoG88PLl8nGXmw" rel="noopener ugc nofollow" target="_blank">GoogleTechTalks</a></figcaption></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="b333" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">一些有用的知识(我不得不学)</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mg"><img src="../Images/e9966476b1387a413e64f12e9f0337d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sCZQb2-LYh0jMXBuCUlrhA.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image from this <a class="ae jy" href="https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="b784" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对我来说，在深入研究 T-SNE 之前，了解一些额外的东西是个好主意，比如指数归一化技巧，(或者<a class="ae jy" href="http://cs231n.github.io/linear-classify/#softmax" rel="noopener ugc nofollow" target="_blank">稳定的 softmax 函数</a>)或者对二分搜索法的回顾。</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="mf lq l"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">video from <br/><a class="ae jy" href="https://www.youtube.com/channel/UCBVCi5JbYmfG3q5MEuoWdOw" rel="noopener ugc nofollow" target="_blank">Udacity</a></figcaption></figure><p id="ee1e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">此外，它有助于审查二分搜索法，一般来说，它的运行时间为 O(登录)，这是很好的。对于 T-SNE，它用于搜索最佳西格玛值，以匹配我们想要的困惑。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mh"><img src="../Images/29b5b6cfd48f1ed57bb19c6919f89405.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4gTdFEk9FckkQZW8goFAow.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image from this <a class="ae jy" href="https://distill.pub/2016/misread-tsne/" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="71d8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最后，来自 Distill 的一份出版物是一个令人惊奇的在线资源，可以让你更深入地了解 T-SNE 及其成功的原因。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="1dcf" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">张量流中的纯 T-SNE</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mi"><img src="../Images/68b742c5bf9adc69cc301557a9c54415.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nzNdOvY0DITQhg6yPXBJaA.png"/></div></div></figure><p id="8b14" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">遵循这里完成的 Numpy 实现<a class="ae jy" href="https://nlml.github.io/in-raw-numpy/in-raw-numpy-t-sne/" rel="noopener ugc nofollow" target="_blank">，</a>并将其转换成 tensorflow 并不难。(liam schoneveld 也出色地解释了每个函数背后的数学原理。).此外，我们可以使纯 SNE 霸王龙成为 SNE 霸王龙层，如上图所示。并分配前馈操作以及反向传播。剩下要做的唯一的事情是连接到完全连接的层以及卷积层到这个 T-SNE 层。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/0308382fbba49cd1bf1588c723ac56ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*bNi_HniYcl31JHnqz43pXg.png"/></div></figure><p id="1e7d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这一点也不难，我们已经实现了全连接层/卷积层，我们可以做类似上面的事情来建立连接。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="c8dd" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="kx">结果:案例 A)纯 T-SNE 退化为 2D </em> </strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/0544371c87e69cc06275dd59e43568ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*bRmB5iGsZDDPFm69QYsI2w.gif"/></div></figure><p id="9b6f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">上面的 gif 显示了每个星团是如何通过历元数形成的。最终的聚类如下图所示。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi ml"><img src="../Images/33838b010c7ef7849ac67cdbe9d08260.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d03fjbAwhk2xre2wbDHuHA.png"/></div></div></figure><p id="5db6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，我们注意到算法很好地将数字分成不同的簇，但是，我们仍然可以注意到一些随机点属于不正确的点。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi ml"><img src="../Images/7e40de704fe1cc82f9110795cba4b296.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-pMQvrkwiBVgZv20nQ8bLg.png"/></div></div></figure><p id="73f5" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在红色区域，我们可以观察到一些 0/5 位于错误的位置。正如在天蓝色区域看到的一样，四和九之间没有明显的区别。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="f1c0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="kx">结果:情况 B)全连通网络为 T-SNE 简化为 2D </em> </strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/6bb3ba333100ce0738942884301bce49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*pBrfAQra326QSoLnTYLu-A.gif"/></div></figure><p id="4a2b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">由于我们在最后一层使用 ELU()激活函数，我们可以注意到轴点是正数。此外，似乎大部分聚类都是在培训的开始阶段完成的。(具体来说，5000)。剩下的用于重新定位每个数据点。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi ml"><img src="../Images/281ecdc4d1ae961f67fb58ab9e4f2a93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ewzCf0fczi8aVNoNQsXt3A.png"/></div></div></figure><p id="5775" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">首先，我们可以注意到，大多数的零都很好地聚集在一起。(与纯 SNE 霸王龙的情况相比，要好得多。).然而，四和九之间的区别仍然不是很清楚…</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="d5a5" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="kx">结果:情况 C)卷积神经网络为 T-SNE 简化为 2D </em> </strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/bbef462b1a8766b6a187f149335c2965.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*xsSgElGxvcLci0Mk-f5nJw.gif"/></div></figure><p id="9ff6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于全连接网络的卷积神经网络，我们可以看到部分数据点粘在 Y 轴上。但我个人认为四九分开比其他任何情况都好。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi ml"><img src="../Images/da4cddaf1414c0c1dc291be73dcca698.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e31Jkwz1xLz3QFOkcvtXag.png"/></div></div></figure><p id="33cb" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">以上是最终结果，在最右边的点，我们可以看到 4 和 9 之间的分离比其他的更好，因为 4 聚集在最右边。(但是需要分开得多。)</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="2dd3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">使用 Sklearn T-SNE 进行比较</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi ml"><img src="../Images/43747728d73bf1e24d66e577d27bf2e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TS_781QdbAN4XQbogPYnKA.png"/></div></div></figure><p id="0163" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我想将我的结果与 sklearn 的 TSNE 进行比较，如果我使用相同的学习速率和相同的超参数，我会得到上面的结果。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi ml"><img src="../Images/2833126ba6792faec8f7ec41d7945da5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z8u44pvZLJ7knkTql3GZQw.png"/></div></div></figure><p id="56ea" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">然而，通过一些超参数调整，我能够得到上述结果。四个和九个之间仍然存在着不清楚的分离，但是每个星团之间的距离却更远了。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="3f2a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="kx">结果:案例 D)全连通网络为 T-SNE 简化为 3D </em> </strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/06c8495c32aaed9a9e1005b74a8ffbed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/1*sorTwPF6PWk2IU7nfshiUw.gif"/></div></figure><p id="2b7d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">上面的 gif 展示了 MNIST 数据集降维为 2 的聚类过程，总体来说做得不错。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mn"><img src="../Images/e5f94a378fc6d83ed5dfdc55fa5c8f3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*nBrXUaXhbQOVmFfO7WFrMw.gif"/></div></div></figure><p id="7c71" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">上面的 gif 显示了最终的聚类。然而，与其他数字相比，4 和 9 之间的区别并不明显。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="4eb7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="kx">结果:情况 E)卷积神经网络为 T-SNE 简化为 3D </em> </strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/d4e5c4ce796c50c9d29efb29cefb170e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/1*KYS35AQKgdyq9Tfehm1B4A.gif"/></div></figure><p id="ba9c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">上面的 gif 显示了我在连接到 T-SNE 层之前使用 CNN 时的聚类进度。下面是最终得到的 gif。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mo"><img src="../Images/c528118a768589dad62157869e8c4aeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Al7lwvgZQ7FJtTdtDP4q_Q.gif"/></div></div></figure><p id="8309" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我个人认为 CNN 在数据聚类方面做得更好，因为在处理图像时，空间信息更有用。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="fc7f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">互动码</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mp"><img src="../Images/e0f5e460917eccd661733be26334b93b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bQ-kMmHegZCMQlglu46vhQ.png"/></div></div></figure><p id="11d1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于 Google Colab，您需要一个 Google 帐户来查看代码，而且您不能在 Google Colab 中运行只读脚本，所以请在您的操场上创建一个副本。最后，我永远不会请求允许访问你在 Google Drive 上的文件，仅供参考。编码快乐！</p><p id="734a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">要访问案例 A)的代码，请<a class="ae jy" href="https://colab.research.google.com/drive/12F-PETpXiFx6bSm-kTx3XRM78CXFPHFT" rel="noopener ugc nofollow" target="_blank">点击此处。</a> <br/>要访问案例 B)的代码，请<a class="ae jy" href="https://colab.research.google.com/drive/1ESSNZMyxHSUnKgQcyG8zb7oypXpkALNP" rel="noopener ugc nofollow" target="_blank">点击此处。</a> <br/>要访问案例 C)的代码，请<a class="ae jy" href="https://colab.research.google.com/drive/19BM2ovJ1fCYnDr7Eq3N-D9lIzNlTXVHm" rel="noopener ugc nofollow" target="_blank">点击此处。</a> <br/>要访问案例 D)的代码，请<a class="ae jy" href="https://colab.research.google.com/drive/1w-4Ntl-Tu1-E8jIRIvDZSvyPePST1dqK" rel="noopener ugc nofollow" target="_blank">点击此处。</a> <br/>要访问案例 E)的代码，请<a class="ae jy" href="https://colab.research.google.com/drive/13oL19ULnt-JZaWIrbFO2LAZ6YHudbpgj" rel="noopener ugc nofollow" target="_blank">点击此处。</a> <br/>要获取案例 Z 的代码，请<a class="ae jy" href="https://colab.research.google.com/drive/13TAEHwTtCyfmhw6vYKvApMX4JwAZxFbi" rel="noopener ugc nofollow" target="_blank">点击此处。</a></p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="7075" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">奇怪的结果</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/b1cf11a3414c1bd1f066be14c70ab475.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*zEMd0-iRyQgDAJOIrdUJgw.gif"/></div></figure><p id="162a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最后，我只是觉得这是一个很酷的结果。显然聚类做得很糟糕，但还是有点酷，哈哈。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="2788" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">最后的话</strong></p><p id="d74c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">由于 t-SNE 的操作方式，对新数据点进行降维非常困难，为了克服这个问题，原始论文的作者引入了参数 T-SNE。而论文可以在下面看到。</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="lp lq l"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Paper from this <a class="ae jy" href="http://dimensionality" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="dc37" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">接下来的事情是实施上述文件，这将是我的下一个任务。(以及<a class="ae jy" href="https://github.com/lmcinnes/umap" rel="noopener ugc nofollow" target="_blank">均匀流形近似</a>和投影(UMAP))</p><p id="4a9d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 给我，如果你想看我所有写作的列表，请点击这里查看我的网站。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的推特<a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或者我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。我还实现了<a class="ae jy" href="https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec" rel="noopener">广残网，请点击这里查看博文 pos </a> t。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="b3f1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="3d08" class="mq mr iq kb b kc kd kg kh kk ms ko mt ks mu kw mv mw mx my bi translated">Tensorflow？，C. (2018)。在 Tensorflow 中不复制张量的情况下批量计算成对距离？。堆栈溢出。检索于 2018 年 7 月 21 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/37009647/compute-pairwise-distance-in-a-batch-without-replicating-tensor-in-tensorflow" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/37009647/compute-pairwise-distance-in-a-batch-without-replication-tensor-in-tensor flow</a></li><li id="1e3f" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">NumPy . set _ print options—NumPy v 1.14 手册。(2018).Docs.scipy.org。检索于 2018 年 7 月 21 日，来自<a class="ae jy" href="https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.set_printoptions.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/numpy-1 . 14 . 0/reference/generated/numpy . set _ print options . html</a></li><li id="1512" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">tf.reduce_max | TensorFlow。(2018).张量流。检索于 2018 年 7 月 21 日，来自<a class="ae jy" href="https://www.tensorflow.org/api_docs/python/tf/reduce_max" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/api_docs/python/tf/reduce_max</a></li><li id="fce8" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">tf.matrix_set_diag | TensorFlow(2018).张量流。检索于 2018 年 7 月 21 日，来自<a class="ae jy" href="https://www.tensorflow.org/api_docs/python/tf/matrix_set_diag" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/matrix _ set _ diag</a></li><li id="5432" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">tf.matrix_diag |张量流。(2018).张量流。检索于 2018 年 7 月 21 日，来自<a class="ae jy" href="https://www.tensorflow.org/api_docs/python/tf/matrix_diag" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/api_docs/python/tf/matrix_diag</a></li><li id="4437" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">tf.matrix_set_diag | TensorFlow(2018).张量流。检索于 2018 年 7 月 21 日，来自<a class="ae jy" href="https://www.tensorflow.org/api_docs/python/tf/matrix_set_diag" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/matrix _ set _ diag</a></li><li id="4625" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">学习？，H. (2018)。logit 最大值的减法如何提高学习？。交叉验证。检索于 2018 年 7 月 21 日，来自<a class="ae jy" href="https://stats.stackexchange.com/questions/338285/how-does-the-subtraction-of-the-logit-maximum-improve-learning" rel="noopener ugc nofollow" target="_blank">https://stats . stack exchange . com/questions/338285/how-the-subtraction-of-the-logit-maximum-improve-learning</a></li><li id="6f0e" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">使用 t-SNE 可视化数据。(2018).YouTube。检索于 2018 年 7 月 21 日，来自 https://www.youtube.com/watch?v=RJVL80Gg3lA<a class="ae jy" href="https://www.youtube.com/watch?v=RJVL80Gg3lA" rel="noopener ugc nofollow" target="_blank"/></li><li id="e505" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">Quora.com(2018)。<em class="kx">t-SNE 算法相比 PCA 有什么优势？— Quora </em>。[在线]可从以下网址获取:<a class="ae jy" href="https://www.quora.com/What-advantages-does-the-t-SNE-algorithm-have-over-PCA" rel="noopener ugc nofollow" target="_blank">https://www . quora . com/What-advantages-the-t-SNE 算法优于 PCA</a>【2018 年 7 月 21 日获取】。</li><li id="a449" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">Python 中的 lambda、map 和 filter—RUP esh mis HRA—Medium。(2017).中等。检索于 2018 年 7 月 21 日，来自<a class="ae jy" href="https://medium.com/@happymishra66/lambda-map-and-filter-in-python-4935f248593" rel="noopener">https://medium . com/@ happymishra 66/lambda-map-and-filter-in-python-4935 f 248593</a></li><li id="7f01" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">德斯莫斯图表。(2018).德斯莫斯图形计算器。检索于 2018 年 7 月 21 日，来自<a class="ae jy" href="https://www.desmos.com/calculator" rel="noopener ugc nofollow" target="_blank">https://www.desmos.com/calculator</a></li><li id="76b3" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">类，P. (2018)。Python 调用类中的函数。堆栈溢出。检索于 2018 年 7 月 23 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/5615648/python-call-function-within-class" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/5615648/python-call-function-within-class</a></li><li id="4377" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">二分搜索法。(2018).YouTube。检索于 2018 年 7 月 23 日，来自<a class="ae jy" href="https://www.youtube.com/watch?v=0VN5iwEyq4c" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=0VN5iwEyq4c</a></li><li id="b2f2" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">(2018).Cs.nyu.edu。检索于 2018 年 7 月 23 日，来自<a class="ae jy" href="https://cs.nyu.edu/~roweis/papers/sne_final.pdf" rel="noopener ugc nofollow" target="_blank">https://cs.nyu.edu/~roweis/papers/sne_final.pdf</a></li><li id="17bc" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">(2018).Cs.toronto.edu。检索于 2018 年 7 月 23 日，来自<a class="ae jy" href="http://www.cs.toronto.edu/~hinton/absps/tsne.pdf" rel="noopener ugc nofollow" target="_blank">http://www.cs.toronto.edu/~hinton/absps/tsne.pdf</a></li><li id="b601" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">用于视觉识别的 CS231n 卷积神经网络。(2018).cs 231n . github . io . 2018 年 7 月 23 日检索，来自<a class="ae jy" href="http://cs231n.github.io/linear-classify/#softmax" rel="noopener ugc nofollow" target="_blank">http://cs231n.github.io/linear-classify/#softmax</a></li><li id="2e73" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">[副本]，D. (2018)。双竖线。数学栈交换。检索于 2018 年 7 月 23 日，来自<a class="ae jy" href="https://math.stackexchange.com/questions/1918317/double-vertical-bars" rel="noopener ugc nofollow" target="_blank">https://math . stack exchange . com/questions/1918 317/double-vertical-bars</a></li><li id="ca20" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">只有 Numpy:(为什么我做手动反向传播)实现多通道/层卷积神经…(2018).中等。2018 年 7 月 23 日检索，来自<a class="ae jy" href="https://medium.com/swlh/only-numpy-why-i-do-manual-back-propagation-implementing-multi-channel-layer-convolution-neural-7d83242fcc24" rel="noopener">https://medium . com/swlh/only-numpy-why-I-do-manual-back-propagation-implementing-multi-channel-layer-convolution-neural-7d 83242 FCC 24</a></li><li id="5086" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">Schoneveld，L. (2017 年)。原始数字:t-SNE。nlml。检索于 2018 年 7 月 23 日，来自 https://nlml.github.io/in-raw-numpy/in-raw-numpy-t-sne/#eq1<a class="ae jy" href="https://nlml.github.io/in-raw-numpy/in-raw-numpy-t-sne/#eq1" rel="noopener ugc nofollow" target="_blank"/></li><li id="7d50" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">奥雷利媒体/t-SNE-教程。(2018).GitHub。检索于 2018 年 7 月 23 日，来自<a class="ae jy" href="https://github.com/oreillymedia/t-SNE-tutorial" rel="noopener ugc nofollow" target="_blank">https://github.com/oreillymedia/t-SNE-tutorial</a></li><li id="c601" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">tf.clip_by_value |张量流。(2018).张量流。检索于 2018 年 7 月 23 日，来自<a class="ae jy" href="https://www.tensorflow.org/api_docs/python/tf/clip_by_value" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/api_docs/python/tf/clip_by_value</a></li><li id="5219" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">tf.random_gamma |张量流。(2018).张量流。检索于 2018 年 7 月 23 日，来自<a class="ae jy" href="https://www.tensorflow.org/api_docs/python/tf/random_gamma" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/api_docs/python/tf/random_gamma</a></li><li id="cb1d" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">Matplotlib . py plot . text-Matplotlib 2 . 2 . 2 文档。(2018).Matplotlib.org。检索于 2018 年 7 月 23 日，来自<a class="ae jy" href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.text.html" rel="noopener ugc nofollow" target="_blank">https://matplotlib . org/API/_ as _ gen/matplotlib . py plot . text . html</a></li><li id="fc74" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">变，m. (2018)。matplotlib 艺术家动画:标题或文本不变。堆栈溢出。检索于 2018 年 7 月 23 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/47421486/matplotlib-artist-animation-title-or-text-not-changing" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/47421486/matplotlib-artist-animation-title-or-text-not-changing</a></li><li id="4943" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">matplotlib，3。(2018).使用 matplotlib 的 3D 动画。堆栈溢出。检索于 2018 年 7 月 23 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/38118598/3d-animation-using-matplotlib" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/38118598/3d-animation-using-matplotlib</a></li><li id="0a08" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">Wattenberg，m .，Viégas，f .，&amp; Johnson，I. (2016 年)。如何有效地使用 t-SNE？蒸馏，1(10)。doi:10.23915</li><li id="0bb1" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">sk learn . manifold . tsne—sci kit-learn 0 . 19 . 2 文档。(2018).Scikit-learn.org。检索于 2018 年 7 月 23 日，来自<a class="ae jy" href="http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/modules/generated/sk learn . manifold . tsne . html</a></li><li id="4210" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">动画示例代码:simple _ 3d anim . py—Matplotlib 2 . 0 . 2 文档。(2018).Matplotlib.org。检索于 2018 年 7 月 23 日，来自<a class="ae jy" href="https://matplotlib.org/examples/animation/simple_3danim.html" rel="noopener ugc nofollow" target="_blank">https://matplotlib . org/examples/animation/simple _ 3d anim . html</a></li><li id="ae7a" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">何时使用 cla()，c. (2018)。什么时候使用 cla()、clf()或 close()来清除 matplotlib 中的绘图？。堆栈溢出。2018 年 7 月 23 日检索，来自<a class="ae jy" href="https://stackoverflow.com/questions/8213522/when-to-use-cla-clf-or-close-for-clearing-a-plot-in-matplotlib" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/8213522/when-to-use-cla-clf-or-close-for-clearing-a-plot-in-matplotlib</a></li><li id="6d11" class="mq mr iq kb b kc mz kg na kk nb ko nc ks nd kw mv mw mx my bi translated">何时使用 cla()，c. (2018)。什么时候使用 cla()、clf()或 close()来清除 matplotlib 中的绘图？。堆栈溢出。检索于 2018 年 7 月 23 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/8213522/when-to-use-cla-clf-or-close-for-clearing-a-plot-in-matplotlib" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/8213522/when-to-use-cla-clf-or-close-for-clearing-a-plot-in-matplotlib</a></li></ol></div></div>    
</body>
</html>