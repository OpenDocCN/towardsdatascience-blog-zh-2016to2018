<html>
<head>
<title>Scalable methods for explaining machine learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解释机器学习的可扩展方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scalable-methods-for-explaining-machine-learning-f28f2b8f9f13?source=collection_archive---------8-----------------------#2018-09-09">https://towardsdatascience.com/scalable-methods-for-explaining-machine-learning-f28f2b8f9f13?source=collection_archive---------8-----------------------#2018-09-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/0f49382a43d3dbf6b87c34afd38bf296.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EMw0UhuPJk0xUQBU999EDQ.jpeg"/></div></div></figure><p id="f757" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">机器学习通常被称为人工智能的一部分。然而，越来越多的人感到不安，我们并不真正理解它为什么如此有效。还有对<a class="ae kw" href="https://www.amazon.com/Weapons-Math-Destruction-Increases-Inequality/dp/0553418815" rel="noopener ugc nofollow" target="_blank">算法失控</a>的担忧。这些批评并不完全公平。设计了一些最成功的算法的该领域的中坚分子<a class="ae kw" href="https://www.facebook.com/yann.lecun/posts/10154938130592143" rel="noopener ugc nofollow" target="_blank">确实明白事情为什么会这样。然而，这是一种既模糊又深刻的理解形式。机器学习算法很复杂，</a><a class="ae kw" href="https://techcrunch.com/2018/06/14/the-problem-with-explainable-ai/" rel="noopener ugc nofollow" target="_blank">解释复杂的对象从来都不容易</a>。但是，随着机器学习作为一个领域的成熟，并在软件中变得无处不在，也许是时候谈论更多有形的理解和解释形式了。</p><p id="aa6c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这篇文章中，我将讨论为什么我们传统的理解方法对机器学习不是很有用。然后我会讨论另一种理解方法，这种方法可能更适合机器学习的特定环境。我在这篇文章中讨论的东西都不是新的。对于经验丰富的从业者来说，这应该是非常熟悉的。这只是我试图把这个领域中一些隐含的智慧表达出来。</p><h1 id="686b" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">复杂系统中的决策</h1><p id="df8e" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">机器学习对于复杂系统中的决策问题最为有用。目标是在给定的特定环境下预测最合适的行动，以引出最理想的反应。在现实生活中，问题几乎从来不用可观察量来表述。因此，第一步是用可观测的量来表述这个问题。这远不是微不足道的，但这不是机器学习的一步。无论你选择哪种解决问题的方法，你都需要采取这一步。</p><p id="53c0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一旦你用可观察的形式描述了这个问题，下一步就是发展一个解决方案的数学形式。解总是被公式化为描述复杂系统的数学函数。这个函数被称为系统的模型。</p><p id="6716" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">模型的输入和输出将取决于你的公式。例如，输入可以是上下文动作对，输出是预期反应，或者输入可以是上下文，输出是最佳动作和预期反应，或者您可以选择概率公式，在这种情况下，输入可以是上下文动作反应三元组，输出是这种三元组出现的概率。没有选择配方的通用指南。哪一种方法最有效在很大程度上取决于问题的具体情况。</p><p id="3dcf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一旦你选择了你的数学公式，那么你剩下的核心任务就是确定模型。该模型必须与我们对复杂系统的感知一致。我们的感知可以分为两个部分:假设和数据驱动的洞察力。</p><p id="c11a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">假设是你对系统做出的独立于任何可用数据的陈述。假设可以进一步分为两个部分:已知的事实和猜测。众所周知的事实是每个人都同意的关于系统的事实，不需要争论。猜测是那些对你来说特定的假设，可以被质疑。猜测可能来自您以前使用类似系统的经验，在这种情况下，它们将是有根据的猜测，并且是可以辩护的。它们也可能仅仅来自你的直觉，在这种情况下，它们很可能是错误的猜测，也很可能不那么有说服力。</p><p id="6dd8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当谈到数据驱动的洞察力时，概括地说，有两种方法可以从数据中提取洞察力:手动和自动。人工方式主要包括分析数据趋势，以确定变量之间的函数关系。人工洞察的质量在很大程度上取决于获得这些洞察的人的能力和偏见。但它们确实有更容易解释的好处，因为获得洞见的人应该能够陈述获得所述洞见的逻辑步骤。自动化方式主要包括使用数学优化来确定变量之间的函数关系。给定优化目标的选择，自动洞察的质量独立于任何人。但这也使它们更难解释，因为人们不知道优化方法为获得这些见解所采取的确切逻辑步骤；如果人们知道确切的步骤，那么就不需要自动化的方法，人们可以简单地手动推导它们。手动和自动模式之间没有明显的分界线。相反，在一端完全手动和另一端完全自动化之间有一个连续体。</p><p id="a5d4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一般来说，你的假设越强、越多，数据驱动的洞察力在确定模型时的作用就越小。如果你想减少一个或几个特定的人对你的模型的影响，那么你会想减少猜测和人工洞察提取的作用。让我们先来看看这个程序的两个极端:无数据区和无理论区。</p><p id="1b45" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在无数据区，你将完全摆脱对数据的依赖，并根据已知事实做出决策。为了能够做到这一点，已知的真理本身应该能够提供一个复杂系统的完整描述。换句话说，你需要一个复杂系统的完整的实用理论。在有趣的现实生活问题中，从来不会出现这种情况——要么我们没有完整的系统理论，要么即使我们有，我们也没有办法计算上述理论的结果。</p><p id="2ff3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在无理论区，你可以完全抛弃假设，只根据数据构建模型。从数学上来说，这意味着你需要模型所有可能的输入和输出数据。除了这种数据永远不可用这一事实之外，这完全违背了建立模型的初衷。您可能希望构建一个模型，以便它可以从一个样本推广到整个人群。如果你有整个人口的数据，那么就没有必要建立一个模型。</p><p id="d3f0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，仅仅基于假设或仅仅基于数据建立模型既不可行也没有用。机器学习的价值在于从决策过程中完全消除猜测和手动洞察的作用，并提供完全基于已知事实和全自动数据驱动洞察的解决方案。不幸的是，我们还没有到那一步。此时，每个机器学习模型都会包含一些猜测和人工数据驱动的洞察。</p><p id="a938" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">正如我们所讨论的，已知的真理不需要解释。猜测和人工洞察相对容易解释。解释机器学习的关键在于解释自动化数据驱动的见解。这种解释意味着什么？一个解释与期望的概念密切相关。通常，如果我们能以某种方式表明某件事的行为与我们的预期一致，我们就说我们对这件事有了解释。因此，解释取决于能否形成预期。</p><p id="cd5c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了解释机器学习模型，我们需要能够形成对它的期望，独立于用于构建它的过程。此外，这种形成预期的方法应该比构建模型的过程更简单，否则我们将需要另一种方法来解释预期形成方法——这将违背解释的全部目的。这立即排除了精确和全面预期的可能性。如果我们确实有一个更简单的方法，可以用来准确预测模型在所有可能场景中的行为，那么我们将简单地使用该方法来构建模型，而不是原来的方法。因此，我们能达到的最好目标是近似的和/或部分的解释。</p><h1 id="7515" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">如何不解释</h1><p id="89a2" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">在我们讨论一个可能行得通的解释方法之前，让我们先讨论一些几乎肯定行不通的解释方法。我们可以把这些方法看作后验方法。换句话说，这些方法以某种方式试图将最终优化的模型分解成部分，并解释这些部分。例如，我们可能希望将模型的输出视为以某种方式独立地受到具有某些权重的输入的影响。对于强相关系统来说，这是非常危险和完全错误的。这里很好地解释了为什么在机器学习模型中基于特征权重来判断变量重要性不是一个好主意。因此，如果输入变量是相关的，这种方法根本不起作用。</p><p id="69d7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">另一种选择是用小块拼出模型的区域，这样在每个小块上，你可以用一个简单的函数得到模型的精确的局部近似。然后，我们可以将整个模型想象成这些简单的局部近似的拼凑，并询问这些局部近似的行为是否与我们的预期一致。这种方法非常类似于使用<a class="ae kw" href="https://en.wikipedia.org/wiki/Equivalence_partitioning" rel="noopener ugc nofollow" target="_blank">等价类划分</a>来理解和测试传统软件的方式。</p><p id="c0f4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">问题是我们认为什么是简单函数？对大多数人来说，很难想象三维空间以外的情况，这意味着一个简单的函数最多只能有两个独立变量。此外，我们会发现很难对具有一个或两个以上极值的函数进行推理。当我们将这些约束强加到一个简单函数的定义中时，我们将会看到，所需的面片数量随着输入变量的数量和模型极值的数量呈指数增长。</p><p id="b298" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果我们在操作上将函数的复杂性定义为输入的数量、极值的数量和变量之间的相关性的强度的某种组合，那么上述解释方法就不起作用，因为它们在复杂性方面不能很好地扩展。这些方法没有规模，因为它们试图建立一个后验还原近似。一个可伸缩的方法不需要考虑最终的模型，而是优化方法本身。为了扩大规模，它需要为如何做出决策建立全局近似，而不是为每个单独的决策建立近似。</p><h1 id="c5a0" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">从对称性开始</h1><p id="f21a" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">首先，我们需要阐述我们的术语。在机器学习中，人们从已知的真相、猜测和人工数据驱动的见解开始。这些在数学上表示为部分定义的多元函数，称为算法。除了输入和输出，算法还将有一组未确定的参数。通过用数据训练算法来固定参数。训练算法本质上是以自动化的方式从数据中提取洞察力，它通常涉及解决优化问题。用数据训练算法的结果是一个完全定义的函数，称为训练模型。到目前为止，我们讨论的模型都是经过训练的模型。优化的目标函数以这样的方式设置，即最小化它将意味着训练的模型捕获与该特定问题相关的数据中的稳定模式。</p><p id="fc80" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">解释的第一步是清晰。在我们解释任何事情之前，我们需要明确起点。在机器学习中，起点是已知的真相、猜测和人工数据驱动的见解。对于任何给定的问题，我们只能在给定这些出发点的情况下提供一个解释。因此，需要非常清楚和全面地陈述它们。</p><p id="9ad6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">问题几乎总是用领域的语言来表述。然后你可以用一种表示法把它转化成一个数学问题。当你做这个翻译时，问题的复杂性就显现出来了。任何解释如果能够根据问题领域的期望来提供，而不是根据为解决方案选择的特定表示来提供，那么它也将具有更高的效力。因此，起点有更好的机会随着复杂性扩展，并且如果它们按照领域的语言而不是表示的语言来陈述，它们将具有更高的解释能力。</p><p id="3de4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但是，当我们说应该用领域的语言来陈述起点时，我们到底是什么意思呢？在机器学习的情况下，起点通常是关于什么与问题相关的陈述。让我们考虑机器学习最成功的应用之一的例子:图像识别。深度学习是机器学习的一种，已经被证明在分类图像方面非常成功。不仅如此，我们实际上对深度学习为什么对图像识别如此有效有了相当好的理解。这种成功和理解的主要原因之一是我们设计了将图像域的相关对称性编码到相关算法(深度神经网络)中的方法。在这种情况下，对称本质上是一种不改变结果的变换。对于图像，这些对称性是分辨率、旋转、平移等的变化。卷积神经网络本质上是神经网络语言中这些对称性的编码。</p><p id="6bc4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对称是以一种整体的方式陈述我们关于相关性的知识的最经济的方式。对称告诉你什么是不相关的。除此之外，其他一切都可能是相关的。它们使我们能够以独立于数据的方式识别对于给定领域什么是相关的，什么是不相关的。他们对算法的函数形式进行约束，而不是对模型的局部行为进行陈述。为任务选择的算法类别必须足够强大，以适应域的对称性。如果训练数据具有足够高的质量和数量，那么模型行为不当的主要原因将是错误的对称性被无意中编码到算法中。</p><p id="046f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于图像识别，我们有一个清楚的例子，当对称性被用作它们的基础时，产生的算法是成功的和可理解的。毫无疑问，形式化一个领域的相关对称性并将其编码到机器学习算法中是非常重要的。图像识别是一个“简单”的例子，因为我们对图像的对称性非常熟悉。然而，我认为对称性对于理解机器学习至关重要。只要有可能，一个算法的起点应该被表述为定义域的对称性。</p><h1 id="4fca" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">逐次全局逼近法</h1><p id="916f" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">对称性会对算法的参数空间施加一些限制。剩余的参数欠定将通过训练来消除。我们现在需要一条将对称性连接到模型的路径。这相当于在施加对称性和模型中完全定义的参数之后，找到连接算法中部分确定的参数的路径。我们将使用的方法是逐次全局逼近法。</p><p id="ab47" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我举个例子说明一下。假设您请求一个地图服务(如 Google maps)来查找一个城市中两个位置之间在旅行时间方面的最佳路线。为了节省时间，地图服务的算法通常会生成一条包含许多转弯的路径。如果你手边没有地图服务，如果你像大多数人一样，那么你可能会选择最少混乱的路线，即转弯次数最少的路线。本质上，您是在解决地图服务算法问题的一个受限版本。您首先要检查是否有一条完全没有转弯的路线。如果是这样的话，你会选择这条路线。如果这样的路线不存在，那么你将寻找一个转弯的路线。如果这样的路由存在并且是唯一的，那么您将选择该路由。如果有多条这样的路线，那么你会选择花费最少时间的一条。如果没有这样的路线，那么你可以尝试一条有两个转弯的路线，以此类推。</p><p id="b481" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">理解地图服务生成的路径的一种方法是继续上述过程，直到到达地图服务生成的路径。假设您的解决方案有两个转弯，而地图服务生成的解决方案有五个转弯。你现在可以尝试依次寻找三圈、四圈、五圈和六圈的解决方案。在每种情况下，你都可以看到增加一个转弯节省了多少时间。当从五个转到六个转时，你应该能够看到增加一个转并不能节省更多的时间，也许还会增加旅行时间。</p><p id="77ab" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">注意，在上面的方法中，我们并没有试图孤立地理解地图服务产生的每个转弯。相反，我们着重于把整个解决方案理解为一系列近似的终点。一般来说，人类的大脑还不能很好地从整体上把握复杂功能的行为。但它相当擅长理解基于两个复变函数之间差异的“有效理论”。这就是为什么上面的方法是理解的有用工具的原因。</p><p id="5a53" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在研究复杂系统的许多不同学科中也使用了类似的方法。事实上，即使在机器学习中，我们在针对基线模型对模型进行基准测试时也使用类似的想法。例如，当试图确定一个分类器有多好时，人们会将其性能与随机分类器的性能进行比较。基准模型只不过是优化问题的解决方案，附加的约束条件使解决方案“更简单”。我们可以通过显式地构建连续的基准作为约束优化问题的解决方案，将这种基准测试方法转变为一种解释方法，其中在每个连续的步骤中，我们移除一些约束。换句话说，我们将优化的解决方案解释为一系列逐次逼近的最终结果。</p><p id="dca2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">面对复杂性，逐次逼近的次数应该是可伸缩的，这在上下文中意味着该次数应该是独立的，或者在最坏的情况下弱依赖于算法中参数的数量。确保这一点的一种方法是将导致近似的约束框定在与参数的表示相邻的表示中——广义傅立叶空间。逐次逼近可以看作是在解中逐渐包含高阶波动。</p><p id="d967" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">与对称性相似，构造连续的全局近似并不容易。一个人需要有非常深厚的专业知识，才能对一个复杂的系统进行全局而非局部的思考。但是复杂系统之所以被称为复杂是有原因的，如果认为我们能够理解它们，并在没有必要的专业知识的情况下以解释的形式传达这种理解，那就太天真了。</p><p id="2347" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">机器学习是游戏规则的改变者。它已经被证明是非常成功的，毫无疑问，它是我们目前所知的为复杂系统构建软件的最强大的方法。但是，成功之后一定会有智慧。我们理解软件的传统方法不足以理解机器学习软件，因为它们不能很好地适应复杂性。另一方面，对称性和连续的全局近似确实与复杂性成比例。我试图讨论当一起使用时，它们如何能够提供一种可扩展的方法来解释机器学习。</p></div></div>    
</body>
</html>