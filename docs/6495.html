<html>
<head>
<title>Simple House Price Predictor using ML through TensorFlow in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过 Python 中的 TensorFlow 使用 ML 进行简单的房价预测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/simple-house-price-predictor-using-ml-through-tensorflow-in-python-cbd2b637904b?source=collection_archive---------6-----------------------#2018-12-16">https://towardsdatascience.com/simple-house-price-predictor-using-ml-through-tensorflow-in-python-cbd2b637904b?source=collection_archive---------6-----------------------#2018-12-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/d604dc422348e7cd41a684c106a29ac8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*set6ukW_WRIq-TajGRj1MA.jpeg"/></div></div></figure><p id="59ea" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现实职业正在进入 21 世纪，正如你可以想象的那样，房屋清单充斥着互联网。如果你曾经考虑过买房、租房，或者只是想看看城里最贵的房子是什么样的(我们都去过)，那么你很可能去过 Zillow、Realtor.com、Readfin 或 Homesnap。如果你去 Zillow 网站搜索你附近的房子，你会看到这样的列表:</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi kw"><img src="../Images/30598ee237b12b78ba1acebf3c9dfee5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mNC7SlsS4JqELD3_znFOHA.png"/></div></div></figure><p id="5e8b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这肯定是一个审美清单，像所有分类广告一样，它有一个要价；在这种情况下，379，900 美元。但是如果你继续向下滚动，你会看到一个标题为“家庭价值”的标签，展开窗口会给你一个“Zestimate”</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lb"><img src="../Images/d71d61af431f006b2d78b827d82f2094.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e5sNJ8vwWih0-x8WZc0Wgw.png"/></div></div></figure><p id="040c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Zestimate 是 Zillow 预测的房子的价值；这是他们最好的猜测。Zillow 给出了这个定义，“Zestimate 住宅估价是 Zillow 的估计市场价值。这不是评估。用它作为一个起点来确定一个家的价值。</p><p id="f8ce" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但是 Zillow 是怎么把价格猜的这么准的？要价和 Zestimate 的差价只有 404 美元。但这肯定不是手动完成的，对吗？Zillow 的数据库中有超过 1.1 亿套住房(并非目前全部在市场上)，手工进行这些估算是不可行的。你可能会认为这是某种形式的算法，你可能是对的。但考虑到房屋估价的复杂性，即使是传统的算法也可能表现不佳，而且复杂得不可思议。房屋价值取决于位置、浴室数量、面积、楼层数、车库、游泳池、邻近价值等。我想你明白了。这就是本文主题发挥作用的地方，机器学习！</p><p id="45c4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这篇文章中，我将带你使用 python 中的神经网络构建一个简单的房价预测工具。喝杯咖啡，打开一个新的 Google Colab 笔记本，让我们开始吧！</p><h1 id="d9bd" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">步骤 1:选择模型</h1><p id="efc3" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">在我们开始告诉计算机做什么之前，我们需要决定我们将使用什么样的模型。我们需要首先问自己目标是什么。在这种情况下，我们有一些关于房子的输入(位置、浴室数量、条件等)，我们需要产生一个输出:价格。这是一个数字输出，这意味着我们可以在一个连续的尺度上表达它(稍后会详细介绍)。给定这些参数，我们可以选择利用神经网络来执行回归。谷歌机器学习框架 Tensorflow 是一个很好的基础，可以在其上建立这样一个模型。</p><p id="b1fc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你不熟悉神经网络是如何工作的，这将有助于理解这里发生的事情，简单地谷歌一下或找到一个 YouTube 视频，有一个很好的资源。</p><h1 id="7bce" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated"><strong class="ak">第二步:收集数据</strong></h1><p id="ad72" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">我们将要使用的数据集来自 Kaggle.com。如果你不熟悉 Kaggle，这是一个很好的机会去那里看看！本质上，它是一个存放数据科学应用数据集以及举办竞赛(通常有可观的现金奖励)的网站。事实上，Zillow 举办了一场比赛来帮助改进 Zestimate。当我告诉你奖金是 120 万美元时，我不是在开玩笑。有一天…</p><p id="757a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">无论如何，去 Kaggle.com 创建一个账户，只需要几秒钟，而且是免费的。找到“编辑配置文件”并向下导航到“创建新的 API 令牌”这将创建一个名为“kaggle.json”的文件，您可以下载该文件。这是一个包含你的用户名和 API 密匙的文件，所以不要把它给任何人，也不要编辑它的内容(如果你不小心丢失了它或者改变了它，你可以让旧的过期，换一个新的)。</p><p id="fe6e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">导航到 Kaggle 的“竞争”标签，搜索“房价:高级回归技术”您将看到有一个“Data”选项卡，我们将从这里提取数据。</p><p id="467a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">旁注:你需要接受与比赛相关的条款和条件来下载数据，但这并不需要参与比赛，不用担心。</p><p id="a165" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们有了得到这个面包所需要的一切…我指的是数据。</p><h1 id="e109" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated"><strong class="ak">第三步:建立模型</strong></h1><p id="cc8a" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">我们将要构建这个模型的环境是 Google Colab，一个免费的在线 python 笔记本环境。在浏览器中输入 colab.research.google.com，开始一个新的 Python 3 笔记本。</p><p id="5818" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于以前没有使用过笔记本的人来说，在移动下一个单元格之前，您可以通过点击 run 来编译每个单元格。</p><p id="1913" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们从安装和导入依赖项开始:</p><pre class="kx ky kz la gt mg mh mi mj aw mk bi"><span id="56fc" class="ml le iq mh b gy mm mn l mo mp">import tensorflow as tf<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from sklearn.preprocessing import MinMaxScaler</span></pre><p id="2283" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Tensorflow 是我们将使用的机器学习框架，pandas 将作为我们的数据框架，numpy 将协助数据操作，matplotlib 是我们的数据可视化工具，sklearn 将为我们提供一种扩展数据的方法。</p><p id="39b5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下一个命令将安装 Kaggle API，我们将结合 kaggle.json 文件使用它来将数据直接导入到环境中。</p><pre class="kx ky kz la gt mg mh mi mj aw mk bi"><span id="507b" class="ml le iq mh b gy mm mn l mo mp">!pip install kaggle</span></pre><p id="9540" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下一行使用内置的 Colab 文件工具，它允许我们将“kaggle.json”上传到笔记本。只需执行下面的命令，并使用出现的按钮上传文件。</p><pre class="kx ky kz la gt mg mh mi mj aw mk bi"><span id="48d9" class="ml le iq mh b gy mm mn l mo mp">from google.colab import files<br/>files.upload()</span></pre><p id="8bd9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Kaggle API 需要该文件位于特定的位置，以便进行身份验证。这次就相信我吧。执行此命令创建目录并放置文件。</p><pre class="kx ky kz la gt mg mh mi mj aw mk bi"><span id="09af" class="ml le iq mh b gy mm mn l mo mp">!mkdir -p ~/.kaggle<br/>!cp kaggle.json ~/.kaggle/</span><span id="6cbf" class="ml le iq mh b gy mq mn l mo mp">!chmod 600 ~/.kaggle/kaggle.json</span></pre><p id="b8c9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们已经准备好使用 API 导入数据了！转到 Kaggle 竞赛页面上的数据选项卡并按下以下按钮，这会将您需要的特定命令直接复制到您的剪贴板:</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mr"><img src="../Images/efb2457f5659317b9e3171daae160a81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fwD4BrlQOiz7o42zrGXpAA.png"/></div></div></figure><p id="d258" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当然，你可以复制下面的代码，但这是你从不同的数据集/比赛中获取数据的方式。重要提示:您需要放置“！”在 Colab 中的命令前面，如果您在本地运行，就不需要这样做。</p><pre class="kx ky kz la gt mg mh mi mj aw mk bi"><span id="ddef" class="ml le iq mh b gy mm mn l mo mp">!kaggle competitions download -c house-prices-advanced-regression-techniques</span></pre><p id="0ed3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果您运行该行并收到“错误 403:禁止”，那么您可能不接受 Kaggle 竞争的条款和条件。</p><p id="1fe4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">执行以下命令，查看当前目录中文件的名称(我们刚刚下载的内容):</p><pre class="kx ky kz la gt mg mh mi mj aw mk bi"><span id="5a11" class="ml le iq mh b gy mm mn l mo mp">!ls</span></pre><p id="95b1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在来看一大段代码。下一个单元格正在读取。csv 文件并构建一个数据框架来存放它们。我们可以使用这个数据框架与我们的数据进行交互。这段代码获取数据帧，删除这里不需要的“Id”列，然后将数据分成两个独立的数据帧:一个用于分类值，另一个用于连续值。</p><pre class="kx ky kz la gt mg mh mi mj aw mk bi"><span id="6179" class="ml le iq mh b gy mm mn l mo mp">#Build the dataframe for train data<br/>train=pd.read_csv('train.csv',encoding='utf-8')<br/>train.drop(['Id'], axis=1)<br/>train_numerical = train.select_dtypes(exclude=['object'])<br/>train_numerical.fillna(0,inplace = True)<br/>train_categoric = train.select_dtypes(include=['object'])<br/>train_categoric.fillna('NONE',inplace = True)<br/>train = train_numerical.merge(train_categoric, left_index = True, right_index = True)</span></pre><p id="3cf9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">那么，我们为什么要将数据分成数字列和分类列呢？这是因为它们是两种不同的数据类型。一个由连续谱上的数字数据组成，另一个包含与类别相关联的字符串。我们需要区别对待他们。</p><p id="c080" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">附注:如果您想查看数据帧的内容以帮助可视化，只需调用 head()函数，如下所示。</p><pre class="kx ky kz la gt mg mh mi mj aw mk bi"><span id="8399" class="ml le iq mh b gy mm mn l mo mp">train.head()</span></pre><p id="5972" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">运行以下命令来隔离异常变量。Sklearn 将帮助我们去除数据中的异常值。这将使那些更准确地代表非异常情况的数据点的学习过程更容易。</p><pre class="kx ky kz la gt mg mh mi mj aw mk bi"><span id="5bee" class="ml le iq mh b gy mm mn l mo mp">from sklearn.ensemble import IsolationForest</span><span id="e9f4" class="ml le iq mh b gy mq mn l mo mp">clf = IsolationForest(max_samples = 100, random_state = 42)<br/>clf.fit(train_numerical)<br/>y_noano = clf.predict(train_numerical)<br/>y_noano = pd.DataFrame(y_noano, columns = ['Top'])<br/>y_noano[y_noano['Top'] == 1].index.values</span><span id="2629" class="ml le iq mh b gy mq mn l mo mp">train_numerical = train_numerical.iloc[y_noano[y_noano['Top'] == 1].index.values]<br/>train_numerical.reset_index(drop = True, inplace = True)</span><span id="35ab" class="ml le iq mh b gy mq mn l mo mp">train_categoric = train_categoric.iloc[y_noano[y_noano['Top'] == 1].index.values]<br/>train_categoric.reset_index(drop = True, inplace = True)</span><span id="2089" class="ml le iq mh b gy mq mn l mo mp">train = train.iloc[y_noano[y_noano['Top'] == 1].index.values]<br/>train.reset_index(drop = True, inplace = True)</span></pre><p id="162b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下一段代码获取数据帧，将其转换为矩阵，并应用所谓的最小最大缩放器。该过程将值缩小到指定的范围，以使训练更容易。例如，从 100 到 1000 的数字列表可以转换为 0 到 1 的范围，其中 0 表示 100，1 表示 1000。</p><pre class="kx ky kz la gt mg mh mi mj aw mk bi"><span id="f6ea" class="ml le iq mh b gy mm mn l mo mp">col_train_num = list(train_numerical.columns)<br/>col_train_num_bis = list(train_numerical.columns)</span><span id="b264" class="ml le iq mh b gy mq mn l mo mp">col_train_cat = list(train_categoric.columns)</span><span id="64c8" class="ml le iq mh b gy mq mn l mo mp">col_train_num_bis.remove('SalePrice')</span><span id="323a" class="ml le iq mh b gy mq mn l mo mp">mat_train = np.matrix(train_numerical)<br/>mat_new = np.matrix(train_numerical.drop('SalePrice',axis = 1))<br/>mat_y = np.array(train.SalePrice)</span><span id="080d" class="ml le iq mh b gy mq mn l mo mp">prepro_y = MinMaxScaler()<br/>prepro_y.fit(mat_y.reshape(1314,1))</span><span id="7273" class="ml le iq mh b gy mq mn l mo mp">prepro = MinMaxScaler()<br/>prepro.fit(mat_train)</span><span id="9fd5" class="ml le iq mh b gy mq mn l mo mp">prepro_test = MinMaxScaler()<br/>prepro_test.fit(mat_new)</span><span id="81e6" class="ml le iq mh b gy mq mn l mo mp">train_num_scale = pd.DataFrame(prepro.transform(mat_train),columns = col_train_num)<br/>train[col_train_num] = pd.DataFrame(prepro.transform(mat_train),columns = col_train_num)</span></pre><p id="4e13" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下面的代码将把分类特征散列成我们的模型可以理解的数字输入。哈希是另一篇文章的主题，如果你感兴趣，可以在谷歌上搜索一下。</p><pre class="kx ky kz la gt mg mh mi mj aw mk bi"><span id="0602" class="ml le iq mh b gy mm mn l mo mp">from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import MinMaxScaler<br/>COLUMNS = col_train_num<br/>FEATURES = col_train_num_bis<br/>LABEL = "SalePrice"</span><span id="a4bc" class="ml le iq mh b gy mq mn l mo mp">FEATURES_CAT = col_train_cat</span><span id="ed66" class="ml le iq mh b gy mq mn l mo mp">engineered_features = []</span><span id="eaf5" class="ml le iq mh b gy mq mn l mo mp">for continuous_feature in FEATURES:<br/>    engineered_features.append(<br/>        tf.contrib.layers.real_valued_column(continuous_feature))</span><span id="7dd3" class="ml le iq mh b gy mq mn l mo mp">for categorical_feature in FEATURES_CAT:<br/>    sparse_column = tf.contrib.layers.sparse_column_with_hash_bucket(<br/>        categorical_feature, hash_bucket_size=1000)</span><span id="34df" class="ml le iq mh b gy mq mn l mo mp">engineered_features.append(tf.contrib.layers.embedding_column(sparse_id_column=sparse_column, dimension=16,combiner="sum"))</span></pre><p id="c6f3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，我们将隔离输入和输出变量，然后将它们分成测试集和训练集。创建测试序列时要使用的经验法则是 80%测试和 20%训练，我已经在下面完成了(test_size=0.2)。这里的结果是测试和训练的输入和输出集</p><pre class="kx ky kz la gt mg mh mi mj aw mk bi"><span id="38d4" class="ml le iq mh b gy mm mn l mo mp"># Build the training set and the prediction set<br/>training_set = train[FEATURES + FEATURES_CAT]<br/>prediction_set = train.SalePrice</span><span id="423c" class="ml le iq mh b gy mq mn l mo mp"># Split the train and prediction sets into test train sets<br/>x_train, x_test, y_train, y_test = train_test_split(training_set[FEATURES + FEATURES_CAT] ,<br/>                                                    prediction_set, test_size=0.2, random_state=42)<br/>y_train = pd.DataFrame(y_train, columns = [LABEL])<br/>training_set = pd.DataFrame(x_train, columns = FEATURES + FEATURES_CAT).merge(y_train, left_index = True, right_index = True)</span><span id="db72" class="ml le iq mh b gy mq mn l mo mp">y_test = pd.DataFrame(y_test, columns = [LABEL])<br/>testing_set = pd.DataFrame(x_test, columns = FEATURES + FEATURES_CAT).merge(y_test, left_index = True, right_index = True)</span></pre><p id="0ec9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，我们可以将连续和分类特征重新组合在一起，然后通过调用 DNNRegressor 函数并传入特征、隐藏层和所需的激活函数来构建模型框架。这里我们使用了三层，每层的节点数量都在减少。激活函数是“relu”但是尝试使用“leaky relu”或者“tanh”看看你是否得到更好的结果！</p><pre class="kx ky kz la gt mg mh mi mj aw mk bi"><span id="3d33" class="ml le iq mh b gy mm mn l mo mp">training_set[FEATURES_CAT] = training_set[FEATURES_CAT].applymap(str)<br/>testing_set[FEATURES_CAT] = testing_set[FEATURES_CAT].applymap(str)</span><span id="c335" class="ml le iq mh b gy mq mn l mo mp">def input_fn_new(data_set, training = True):<br/>    continuous_cols = {k: tf.constant(data_set[k].values) for k in FEATURES}<br/>    <br/>    categorical_cols = {k: tf.SparseTensor(<br/>        indices=[[i, 0] for i in range(data_set[k].size)], values = data_set[k].values, dense_shape = [data_set[k].size, 1]) for k in FEATURES_CAT}</span><span id="9d61" class="ml le iq mh b gy mq mn l mo mp"># Combines the dictionaries of the categorical and continuous features<br/>    feature_cols = dict(list(continuous_cols.items()) + list(categorical_cols.items()))<br/>    <br/>    if training == True:<br/>        # Converts the label column into a constant Tensor.<br/>        label = tf.constant(data_set[LABEL].values)</span><span id="a46e" class="ml le iq mh b gy mq mn l mo mp"># Outputs the feature columns and labels<br/>        return feature_cols, label<br/>    <br/>    return feature_cols</span><span id="6ae7" class="ml le iq mh b gy mq mn l mo mp"># Builds the Model Framework<br/>regressor = tf.contrib.learn.DNNRegressor(feature_columns = engineered_features, <br/>                                          activation_fn = tf.nn.relu, hidden_units=[250, 100, 50])</span><span id="0c7c" class="ml le iq mh b gy mq mn l mo mp">categorical_cols = {k: tf.SparseTensor(indices=[[i, 0] for i in range(training_set[k].size)], values = training_set[k].values, dense_shape = [training_set[k].size, 1]) for k in FEATURES_CAT}</span></pre><p id="afb2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">执行以下功能将开始训练过程！这需要几分钟的时间，所以伸个懒腰吧！</p><h1 id="a9dc" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">步骤 5:训练模型</h1><pre class="kx ky kz la gt mg mh mi mj aw mk bi"><span id="80f1" class="ml le iq mh b gy mm mn l mo mp">regressor.fit(input_fn = lambda: input_fn_new(training_set) , steps=10000)</span></pre><p id="663c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们把结果可视化吧！这段代码将导入我们的数据可视化工具，计算预测值，获取实际值，然后将它们绘制成图表。</p><h1 id="4149" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">步骤 6:评估模型并可视化结果</h1><pre class="kx ky kz la gt mg mh mi mj aw mk bi"><span id="7fe6" class="ml le iq mh b gy mm mn l mo mp">import matplotlib.pyplot as plt<br/>import matplotlib</span><span id="fdfb" class="ml le iq mh b gy mq mn l mo mp">ev = regressor.evaluate(input_fn=lambda: input_fn_new(testing_set, training = True), steps=1)<br/>loss_score = ev["loss"]<br/>print("Final Loss on the testing set: {0:f}".format(loss_score))</span><span id="8016" class="ml le iq mh b gy mq mn l mo mp">import matplotlib.pyplot as plt<br/>import matplotlib<br/>import itertools</span><span id="83ec" class="ml le iq mh b gy mq mn l mo mp">ev = regressor.evaluate(input_fn=lambda: input_fn_new(testing_set, training = True), steps=1)<br/>loss_score = ev["loss"]<br/>print("Final Loss on the testing set: {0:f}".format(loss_score))<br/>reality = pd.DataFrame(prepro.inverse_transform(testing_set.select_dtypes(exclude=['object'])), columns = [COLUMNS]).SalePrice</span><span id="b76c" class="ml le iq mh b gy mq mn l mo mp">y = regressor.predict(input_fn=lambda: input_fn_new(testing_set))<br/>predictions = list(itertools.islice(y, testing_set.shape[0]))<br/>predictions = pd.DataFrame(prepro_y.inverse_transform(np.array(predictions).reshape(263,1)))</span><span id="8ef9" class="ml le iq mh b gy mq mn l mo mp">matplotlib.rc('xtick', labelsize=30) <br/>matplotlib.rc('ytick', labelsize=30)</span><span id="b34a" class="ml le iq mh b gy mq mn l mo mp">fig, ax = plt.subplots(figsize=(15, 12))<br/>plt.style.use('ggplot')<br/>plt.plot(predictions.values, reality.values, 'ro')<br/>plt.xlabel('Predictions', fontsize = 30)<br/>plt.ylabel('Reality', fontsize = 30)<br/>plt.title('Predictions x Reality on dataset Test', fontsize = 30)<br/>ax.plot([reality.min(), reality.max()], [reality.min(), reality.max()], 'k--', lw=4)<br/>plt.show()</span></pre><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ms"><img src="../Images/8321546f0f0877b2222c3879b1f1b94e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dx-9OVAvCf4gviggFZIOww.png"/></div></div></figure><p id="d3db" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">还不错！要获得更好的结果，请尝试更改激活函数、层数或层的大小。或许完全使用另一种模式。这不是一个庞大的数据集，所以我们受到信息量的限制，但这些技术和原理可以转移到更大的数据集或更复杂的问题上。</p><p id="d807" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如有任何疑问、意见、担忧或建议，请随时联系我。</p><p id="8def" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我也想给朱利安·海杜克大声喊出来，他的模型是。点击这里查看他的视频:<a class="ae mt" href="https://www.kaggle.com/zoupet" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/zoupet</a></p></div></div>    
</body>
</html>