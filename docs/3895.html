<html>
<head>
<title>[ ICLR 2017 / Paper Summary ] Designing Neural Network Architectures using Reinforcement Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">[ ICLR 2017 /论文摘要]使用强化学习设计神经网络架构</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/iclr-2017-paper-summary-designing-neural-network-architectures-using-reinforcement-learning-e6f099bcf2ec?source=collection_archive---------13-----------------------#2018-06-28">https://towardsdatascience.com/iclr-2017-paper-summary-designing-neural-network-architectures-using-reinforcement-learning-e6f099bcf2ec?source=collection_archive---------13-----------------------#2018-06-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/a37791b3e0ede932e2dafa7490d7f234.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/1*q7eMf2XaV-qVZ9UGK2Z0nQ.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">GIF from this <a class="ae jy" href="https://giphy.com/gifs/Q1LPV0vs7oKqc" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="45f8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">仅仅从名字你就已经知道这种纸有多酷了。</p><blockquote class="kx ky kz"><p id="476a" class="jz ka la kb b kc kd ke kf kg kh ki kj lb kl km kn lc kp kq kr ld kt ku kv kw ij bi translated"><strong class="kb ir">请注意，这个姿势是为了我未来的自己回顾和复习这篇论文上的材料，而不是从头再看一遍。</strong></p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="lp lq l"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Paper from this <a class="ae jy" href="https://arxiv.org/pdf/1611.02167.pdf" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="c201" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">摘要</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lr"><img src="../Images/aeabecdba59b02b33b529b0e80234353.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pQlTzMyNNK1xRITZDCyZVA.png"/></div></div></figure><p id="d42b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">设计新的网络架构不仅需要人类的专业知识，还需要劳动时间。本文的作者介绍了一种可以设计高性能卷积神经网络的代理。并且使用 Q-learning 和 e-greedy 探索策略和经验重放来训练代理。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="d4c6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">简介</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lw"><img src="../Images/1e0f18370223a44ed1b1bb0702e2ed5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g_8u2Vyj7FmdMtFnf8lCHw.png"/></div></div></figure><p id="4f05" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">CNN 多年来取得了巨大的成功，典型的 CNN 由卷积层、池层和全连接层组成。(同样由于所有的选项，搜索空间相当大。).本文的作者制作了一个代理，旨在无需人工干预的情况下创建新的卷积神经网络架构。(代理正在对以何种顺序放置何种层做出顺序决策。)最后，他们在 MNIST 和 CIFAR 10 等图像分类数据集上测试了创建的网络。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="9524" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">相关工作</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lx"><img src="../Images/9f44b07fd64554e0b7e12508fd4e1a02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IiHE0VgsjUuOhfQ7yp4soQ.png"/></div></div></figure><p id="162d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">创建新网络架构的自动化在学术界并不是一个新概念，一些相关的作品是“<a class="ae jy" href="https://arxiv.org/pdf/1606.02492.pdf" rel="noopener ugc nofollow" target="_blank">卷积神经结构</a>”和“<a class="ae jy" href="https://ieeexplore.ieee.org/document/273950/" rel="noopener ugc nofollow" target="_blank">遗传算法和神经网络的组合:技术发展水平的调查</a>”。然而，不幸的是，通常情况下，手工制作的网络比生成的网络性能更好。最近在强化学习和深度学习的交叉领域有很多工作。其中，Q-learning、e-greedy 策略和经验重放取得了巨大的成功。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="1dbd" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">背景</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ly"><img src="../Images/13ea0040dc232ce5fd6052c082d95ecd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9CDvJyu-ugNe92-sT6VMHg.png"/></div></div></figure><p id="23e6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在这一部分，作者很好地解释了马尔可夫决策过程，贴现报酬函数，以及它们是如何结合在一起的。关于这个话题的更简单的解释可以在<a class="ae jy" href="https://www.youtube.com/watch?v=2pWv7GOvuf0&amp;list=PLweqsIcZJac7PfiyYMvYiHfOFPg9Um82B" rel="noopener ugc nofollow" target="_blank">这里</a>找到。此外，如果您希望了解更多关于贝尔曼方程的信息，请点击<a class="ae jy" href="https://www.youtube.com/watch?v=b1GvQcjDwBU" rel="noopener ugc nofollow" target="_blank">此处</a>。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="dd8a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">利用 Q-learning 设计神经网络架构</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lz"><img src="../Images/9e4f4cc6f9941061a7f32a8c2d72c617.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KyyiguSDHJvJr2RPUy6uEw.png"/></div></div></figure><p id="e59e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">作者为智能体选择的任务是依次选择神经网络层。其中 C(n，f，l)对应于滤波器的数量、感受野大小和步幅，P(f，l)对应于具有相同符号的池层。当代理完成生成不同类型的网络架构时，(换句话说，到达终端状态)，生成的网络得到训练。并且验证准确性充当代理的奖励值，网络体系结构也被存储在代理的重放存储器中，并且经验被周期性地从重放存储器中采样以更新 Q 值。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ma"><img src="../Images/d99f450c9fcf5cba24f393e6bb1bbb00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4ioo3vevOOkElE4nlVlzng.png"/></div></div></figure><p id="3839" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">作者描述了每个状态空间、动作空间和 Q-Learning 训练过程的实现/配置细节。其中状态空间通过所有相关层参数的元组来定义。(每个参数的细节可以在上面看到。).对于动作空间，它们限制了完全连接层的数量，并使代理能够在任何给定的时间点移动到终止状态。最后，ε递减时间表如下所示。(Q 学习率为 0.01)。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mb"><img src="../Images/8dff05169158495e7c2d4c7e946b9d28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PUB5oDiAXxqnAeuMK2Cyxw.png"/></div></div></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="42c2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">实验细节</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mc"><img src="../Images/1efb41cd324784edd56e79ed37b36031.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JnI5UQebpQdSxdSNt0HVQw.png"/></div></div></figure><p id="29c0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在这里，作者给出了他们在训练网络时选择的超参数的详细描述，以及他们添加了退出层的事实。一个有趣的事实是，如果他们的学习速度不是他们的最佳选择，网络有 5 次机会重新开始他们的训练。(如果他们不能学习，学习率就会降低。而且用了 10 个 nvidia GPU 用了 10 天。)最后，作者描述了他们如何为每个数据集优化超参数。(MNIST、CIFAR 10 和 SVHN。)</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="e61e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi md"><img src="../Images/4a931fa624b0fb231a6428c79d9738d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rGzzbY5Y2gT5GOnnLHHWVw.png"/></div></div></figure><p id="4870" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，随着代理从探索阶段进入开发阶段，每个数据集的模型的准确性开始增加。(特别是对于 SVHN，它从 52%增加到 88%。).一个有趣的事实是，代理通常选择 C(n，1，1)类型的卷积层作为第一层，这作为预处理步骤(即，将 RGB 图像转换为 YUV 图像)。).</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi me"><img src="../Images/a6ca235999b1e2f81154663fabfc7a6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C4DLSEx4VV47z_IGlmya6g.png"/></div></div></figure><p id="3cf7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，我们可以注意到，与类似类型的网络(没有更高级的池层等)相比，代理生成的网络表现良好。甚至当比较由更复杂的网络结构组成的不同网络时，我们可以观察到由代理生成的网络仍然是有竞争力的。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mf"><img src="../Images/ad16adfe082d4bdbf88d4e19c7eee0b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*df6LKORryq6VsjleLQXFSw.png"/></div></div></figure><p id="79a6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最后，作者还对 MetaQNN 的迁移学习能力做了一些实验。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="73c0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结束语</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ma"><img src="../Images/166310eaf71d61ce658fee99b47c8943.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pn5_IldYLth2TKJXwbLf9w.png"/></div></div></figure><p id="486e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">总之，为不同的用例设计网络架构是一项耗时的任务。这篇论文的作者提出了一种新的解决方案，他们训练了一个代理，该代理可以对下一步放置什么层做出顺序决策，以设计一个卷积神经网络。此外，作者指出了在未来更优化版本的代理的可能性。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="e502" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">遗言</strong></p><p id="6a9f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">创建不同类型网络的非常酷的方法。</p><p id="cfba" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 给我，如果你希望看到我所有写作的列表，请<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">在这里查看我的网站</a>。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的推特<a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，并访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。我也实现了<a class="ae jy" href="https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec" rel="noopener">广残网，请点击这里查看博文 pos </a> t。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="8847" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="be14" class="mg mh iq kb b kc kd kg kh kk mi ko mj ks mk kw ml mm mn mo bi translated">b .贝克、o .古普塔、n .纳伊克和 r .拉斯卡尔(2016 年)。使用强化学习设计神经网络结构。Arxiv.org。检索于 2018 年 6 月 28 日，来自<a class="ae jy" href="https://arxiv.org/abs/1611.02167" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1611.02167</a></li><li id="7f63" class="mg mh iq kb b kc mp kg mq kk mr ko ms ks mt kw ml mm mn mo bi translated">遗传算法和神经网络的结合:技术现状的调查——IEEE 会议出版物。(2018).Ieeexplore.ieee.org。检索于 2018 年 6 月 28 日，来自<a class="ae jy" href="https://ieeexplore.ieee.org/document/273950/" rel="noopener ugc nofollow" target="_blank">https://ieeexplore.ieee.org/document/273950/</a></li><li id="5755" class="mg mh iq kb b kc mp kg mq kk mr ko ms ks mt kw ml mm mn mo bi translated">(2018).Arxiv.org。检索于 2018 年 6 月 28 日，来自<a class="ae jy" href="https://arxiv.org/pdf/1606.02492.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1606.02492.pdf</a></li><li id="8041" class="mg mh iq kb b kc mp kg mq kk mr ko ms ks mt kw ml mm mn mo bi translated">David Silver 的 RL 课程—第 1 讲:强化学习简介。(2018).YouTube。检索于 2018 年 6 月 28 日，来自<a class="ae jy" href="https://www.youtube.com/watch?v=2pWv7GOvuf0&amp;list=PLweqsIcZJac7PfiyYMvYiHfOFPg9Um82B" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=2pWv7GOvuf0&amp;list = plweqsiczjac 7 pfiyymvyihfpg 9um 82 b</a></li><li id="7d9f" class="mg mh iq kb b kc mp kg mq kk mr ko ms ks mt kw ml mm mn mo bi translated">贝尔曼方程-1。(2018).YouTube。检索于 2018 年 6 月 28 日，来自<a class="ae jy" href="https://www.youtube.com/watch?v=b1GvQcjDwBU" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=b1GvQcjDwBU</a></li></ol></div></div>    
</body>
</html>