<html>
<head>
<title>Scanned Numbers Recognition using k-Nearest Neighbor (k-NN)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 k-近邻的扫描数字识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scanned-digits-recognition-using-k-nearest-neighbor-k-nn-d1a1528f0dea?source=collection_archive---------3-----------------------#2018-02-04">https://towardsdatascience.com/scanned-digits-recognition-using-k-nearest-neighbor-k-nn-d1a1528f0dea?source=collection_archive---------3-----------------------#2018-02-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/0c34dfee5291ca4d64ef9cc5370575b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*HCNOpP8AkcvYoSSd4hxThA.png"/></div></figure><div class="ju jv jw jx gt ab cb"><figure class="jy jr jz ka kb kc kd paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><img src="../Images/03ca2c620aa4e3936fba7ab6809c03cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:606/format:webp/1*11P_VxV7BRKiSF-GJidG0g.png"/></div></figure><figure class="jy jr ki ka kb kc kd paragraph-image"><img src="../Images/e91e997b98429bf4f6d5a4e8ebaaa317.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*de4fAuM_-lJqP2eVz54-mQ.png"/></figure><figure class="jy jr kj ka kb kc kd paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><img src="../Images/48d281c04424355e4f251066230d5c29.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*pTMBSMiEAFcQTqIbW2QkDg.png"/></div></figure></div><p id="765c" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir"> <em class="li">标签</em> </strong> <em class="li"> : Python、scikit-image、scikit-learn、机器学习、OpenCV、ImageMagick、梯度方向直方图(HOG)。</em></p></div><div class="ab cl lj lk hu ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="ij ik il im in"><p id="e96d" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">如何在<strong class="km ir"> 2 分钟</strong>内将 500 张背景嘈杂的扫描图像上打印的数字(如下图)提取成<strong class="km ir"> 100% </strong>准确率的 excel 文件？</p><p id="67c0" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">简单的答案是:你不可能在 2 分钟内达到 100%的准确率，这需要 8 分钟。</p><figure class="ju jv jw jx gt jr gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/ebb91ff778eef765dc159fd59263248a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g8VGM5qTPY2Ct6P7Kdu0FA.jpeg"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Figure 1. Original image</figcaption></figure><p id="ec75" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">预处理图像需要<strong class="km ir"> 2 分钟</strong>，机器学习模型正确预测 98%的数字需要<strong class="km ir"> 6 分钟</strong>，人工修复 2%的不准确预测，尽管只需很少的努力。通过向用户呈现模型无法以 100%的置信度分类的数字，6 分钟成为可能，如本博客结尾的“呈现”部分所示。</p><h1 id="82f6" class="lv lw iq bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">不成功的方法</h1><p id="7055" class="pw-post-body-paragraph kk kl iq km b kn mt kp kq kr mu kt ku kv mv kx ky kz mw lb lc ld mx lf lg lh ij bi translated">在解释 k-NN 解决方案之前，我将简要回顾一下我探索过的一些不成功的提取数字的方法。</p><h2 id="95c8" class="my lw iq bd lx mz na dn mb nb nc dp mf kv nd ne mj kz nf ng mn ld nh ni mr nj bi translated">1-宇宙魔方——谷歌的光学字符识别(OCR)</h2><p id="d11c" class="pw-post-body-paragraph kk kl iq km b kn mt kp kq kr mu kt ku kv mv kx ky kz mw lb lc ld mx lf lg lh ij bi translated">尽管使用了 Tesseract 的选项将图像识别为单个文本行，并且仅识别数字，但是应用 Google 的 Tesseract 导致了低精度的数字识别。请注意，在应用 Tesseract 之前，图像的背景噪声已被去除(在本博客后面的去噪步骤中有更多内容)。</p><h2 id="2690" class="my lw iq bd lx mz na dn mb nb nc dp mf kv nd ne mj kz nf ng mn ld nh ni mr nj bi translated">2-图像模板匹配</h2><p id="623f" class="pw-post-body-paragraph kk kl iq km b kn mt kp kq kr mu kt ku kv mv kx ky kz mw lb lc ld mx lf lg lh ij bi translated">第二种方法是为 9 个数字中的每一个生成模板图像，然后检测图像中的每一个数字，并使用 openCV 的<em class="li"> matchTemplate </em>函数将其与 0 到 9 个模板中的每一个进行比较</p><pre class="ju jv jw jx gt nk nl nm nn aw no bi"><span id="5d5e" class="my lw iq nl b gy np nq l nr ns"><strong class="nl ir">import </strong>cv2</span><span id="08df" class="my lw iq nl b gy nt nq l nr ns">result = cv2.matchTemplate(roi, digitROI, cv2.TM_CCOEFF)<br/>(_, score, _, _) = cv2.minMaxLoc(result)</span></pre><p id="376e" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">由于噪音，这种方法对我们的问题不起作用。然而，这篇博客<a class="ae nu" href="https://www.pyimagesearch.com/2017/07/17/credit-card-ocr-with-opencv-and-python/" rel="noopener ugc nofollow" target="_blank">https://www . pyimagesearch . com/2017/07/17/credit-card-ocr-with-opencv-and-python/</a>成功演示了使用模板匹配来识别信用卡上的印刷数字。</p><h1 id="9056" class="lv lw iq bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">成功的方法:使用机器学习进行训练和预测</h1><p id="b9dc" class="pw-post-body-paragraph kk kl iq km b kn mt kp kq kr mu kt ku kv mv kx ky kz mw lb lc ld mx lf lg lh ij bi translated">最后一种方法是训练我自己的机器学习模型。该解决方案需要满足以下要求:</p><ul class=""><li id="93c6" class="nv nw iq km b kn ko kr ks kv nx kz ny ld nz lh oa ob oc od bi translated">从图像中挑出每个数字</li><li id="4058" class="nv nw iq km b kn oe kr of kv og kz oh ld oi lh oa ob oc od bi translated">选择适当的特征提取应用于每个数字</li><li id="eb89" class="nv nw iq km b kn oe kr of kv og kz oh ld oi lh oa ob oc od bi translated">选择多类分类器</li></ul><p id="a717" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">输入/数据预处理、特征工程和数据准备是任何基于机器学习的解决方案的核心。选择使用哪种机器学习分类器是一个重要的步骤，然而，它的成功在于上面提到的。</p><h2 id="b312" class="my lw iq bd lx mz na dn mb nb nc dp mf kv nd ne mj kz nf ng mn ld nh ni mr nj bi translated">大纲:</h2><ol class=""><li id="6509" class="nv nw iq km b kn mt kr mu kv oj kz ok ld ol lh om ob oc od bi translated">图像预处理</li><li id="7770" class="nv nw iq km b kn oe kr of kv og kz oh ld oi lh om ob oc od bi translated">数字提取和训练/测试数据准备</li><li id="8aa8" class="nv nw iq km b kn oe kr of kv og kz oh ld oi lh om ob oc od bi translated">特征抽出</li><li id="0c37" class="nv nw iq km b kn oe kr of kv og kz oh ld oi lh om ob oc od bi translated">培养</li><li id="f35b" class="nv nw iq km b kn oe kr of kv og kz oh ld oi lh om ob oc od bi translated">预测</li><li id="01e5" class="nv nw iq km b kn oe kr of kv og kz oh ld oi lh om ob oc od bi translated">介绍会；展示会</li></ol><h1 id="952c" class="lv lw iq bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">1.图像预处理</h1><p id="156b" class="pw-post-body-paragraph kk kl iq km b kn mt kp kq kr mu kt ku kv mv kx ky kz mw lb lc ld mx lf lg lh ij bi translated">弗莱德·魏因豪斯(<a class="ae nu" href="http://www.fmwconcepts.com/imagemagick/textcleaner/" rel="noopener ugc nofollow" target="_blank">http://www.fmwconcepts.com/imagemagick/textcleaner/</a>)的 TextCleaner 脚本已经被用于去除图像背景噪声，随后是图像锐化步骤。这两个步骤都需要 ImageMagick 库(【https://www.imagemagick.org】T2)。或者，我推荐使用 python 的库，如<strong class="km ir"> OpenCV </strong>或<strong class="km ir"> scikit-image </strong>来预处理图像。</p><pre class="ju jv jw jx gt nk nl nm nn aw no bi"><span id="7fca" class="my lw iq nl b gy np nq l nr ns"># text cleaner<br/>./textcleaner -g -e stretch -f 25 -o 10 -u -s 1 -T -p 10 <strong class="nl ir">input.jpg</strong> <strong class="nl ir">output_clean.jpg</strong></span><span id="59cc" class="my lw iq nl b gy nt nq l nr ns"># image sharpening<br/>convert <strong class="nl ir">output_clean.jpg</strong> -sharpen 0x10 <strong class="nl ir">output_sharp.jpg</strong></span></pre><p id="0f52" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">上面的代码产生了下面的图像</p><figure class="ju jv jw jx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi on"><img src="../Images/d3e385c3b6e0b6dba71fa33826ca69b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M-uujTVu5Q-fEshrCqCqMw.jpeg"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Image 2. De-noised image</figcaption></figure><h2 id="3f8b" class="my lw iq bd lx mz na dn mb nb nc dp mf kv nd ne mj kz nf ng mn ld nh ni mr nj bi translated">2.数字提取和数据准备</h2><p id="0bc2" class="pw-post-body-paragraph kk kl iq km b kn mt kp kq kr mu kt ku kv mv kx ky kz mw lb lc ld mx lf lg lh ij bi translated">由于噪声，使用 OpenCV 的<strong class="km ir"> findContour </strong>操作从图像中挑选出每个数字不会产生可靠的结果。对于这个特定的问题，检测数字周围的“边界框”(图像裁剪),然后从裁剪的图像中“挑出”每个数字，这是更健壮的。找到边界框后，后一步很容易，因为每个数字相对于裁剪图像的左上角都有一个固定的坐标。</p><figure class="ju jv jw jx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi on"><img src="../Images/16abf0f9c2b392d0b0de8f395e2a8eff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OHztpJAcLKZRWOYFZ0hpnQ.jpeg"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Figure 3. De-noised inverted image</figcaption></figure><p id="10fc" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><em class="li">注意:使用梯度方向直方图(HOG)进行特征提取需要反转黑/白像素。</em></p><h2 id="ca12" class="my lw iq bd lx mz na dn mb nb nc dp mf kv nd ne mj kz nf ng mn ld nh ni mr nj bi translated">2.1 检测包围盒</h2><p id="3610" class="pw-post-body-paragraph kk kl iq km b kn mt kp kq kr mu kt ku kv mv kx ky kz mw lb lc ld mx lf lg lh ij bi translated">使用第三方工具来裁剪图像的边界并不能在所有图像上很好地工作。相反，我创建了一个简单的方法来确定性地裁剪图像，并以 100%的准确度检测边界框。</p><p id="e620" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">该方法从计算矩形的白色像素开始，如图 4 所示。如果白色像素的计数超过经验设定值，则矩形的坐标是数字的上边界，并将用于裁剪图像。</p><figure class="ju jv jw jx gt jr gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/ebb1ad5ed812cbe51d10196b9058a843.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*safv0Fvhd3e-Y_SY_j8taQ.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Figure 4. Top image cropping</figcaption></figure><figure class="ju jv jw jx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi on"><img src="../Images/bf4828d93f033649db0275e9f98098e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dQrJ3paktbSDsBQai5LzpA.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Figure 5. Top image cropping</figcaption></figure><p id="7862" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">同样的技术可以用来左裁剪图像，如图 6 所示。</p><figure class="ju jv jw jx gt jr gh gi paragraph-image"><div class="gh gi op"><img src="../Images/01eb9c1ca33051bd9c6605ef7080c4a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*lEAWruyMH-Lntnxm8Lb-NQ.jpeg"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Figure 6. Left image cropping</figcaption></figure><p id="6272" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">上述操作的输出产生了以下图像:</p><figure class="ju jv jw jx gt jr gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/99b47046fca91519015ed1801d340781.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*Xz_mZe-8-9QQAYxSjKkQ3w.jpeg"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Figure 7. Cropped image</figcaption></figure><figure class="ju jv jw jx gt jr"><div class="bz fp l di"><div class="or os l"/></div></figure><h2 id="1a85" class="my lw iq bd lx mz na dn mb nb nc dp mf kv nd ne mj kz nf ng mn ld nh ni mr nj bi translated">2.2 数字提取</h2><p id="439e" class="pw-post-body-paragraph kk kl iq km b kn mt kp kq kr mu kt ku kv mv kx ky kz mw lb lc ld mx lf lg lh ij bi translated">既然检测到了边界框，应该很容易挑出每个数字，因为每个数字都有相对于裁剪图像左上角的预先固定的坐标。</p><p id="eba8" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">我将上面的代码应用于一组图像，并手动将每个数字的图像分类到标记为 0 到 9 的单独文件夹中，如下所示，以创建我的训练/测试数据集。</p><div class="ju jv jw jx gt ab cb"><figure class="jy jr ot ka kb kc kd paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><img src="../Images/c627ee461ae2760790a09ea4f94cea7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*sJxIwINstUK97wPD8k_PUA.png"/></div></figure><figure class="jy jr ou ka kb kc kd paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><img src="../Images/f6b6bdebeac976a9a47b0c0246db2574.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*88oXbR_EXDVMpue8yF3LiQ.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk ov di ow ox">Figure 8. Manually labeling datasets</figcaption></figure></div><h2 id="2abe" class="my lw iq bd lx mz na dn mb nb nc dp mf kv nd ne mj kz nf ng mn ld nh ni mr nj bi translated">3.特征抽出</h2><p id="22d6" class="pw-post-body-paragraph kk kl iq km b kn mt kp kq kr mu kt ku kv mv kx ky kz mw lb lc ld mx lf lg lh ij bi translated">特征提取或特征工程是识别输入(在我们的情况下是数字)的独特特征的过程，以使机器学习算法能够工作(在我们的情况下是聚类相似的数字)。特别令人感兴趣的是<strong class="km ir">梯度方向直方图(HOG) </strong>，它已经在许多 OCR 应用中成功用于提取手写文本。下面的代码演示了使用 skimage 的<strong class="km ir"> <em class="li"> hog </em> </strong>函数从图像中提取 HOG。</p><pre class="ju jv jw jx gt nk nl nm nn aw no bi"><span id="55c5" class="my lw iq nl b gy np nq l nr ns"><strong class="nl ir">from </strong>skimage.feature <strong class="nl ir">import </strong>hog</span><span id="8016" class="my lw iq nl b gy nt nq l nr ns">df= hog(training_digit_image, orientations=8, pixels_per_cell=(10,10), cells_per_block=(5, 5))</span></pre><p id="1317" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">在我的例子中，图像是 50x50 像素，hog 的输入参数(即<strong class="km ir"> <em class="li">像素 _ 每单元</em> </strong>和<strong class="km ir"> <em class="li">单元 _ 每块</em> </strong>)是凭经验设置的。下图说明了如何在图像上应用 HOG，生成一个包含 200 个值(即特征)的矢量。</p><figure class="ju jv jw jx gt jr gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/7f25fb6b1719a10e4a6a80067d41b443.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*g-vuqi2i1LQm_Yhf2R5egA.jpeg"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Figure 9. Illustration of Histogram of Oriented Gradients (HOG)</figcaption></figure><h2 id="cd5a" class="my lw iq bd lx mz na dn mb nb nc dp mf kv nd ne mj kz nf ng mn ld nh ni mr nj bi translated">4.培养</h2><p id="10bb" class="pw-post-body-paragraph kk kl iq km b kn mt kp kq kr mu kt ku kv mv kx ky kz mw lb lc ld mx lf lg lh ij bi translated">在前面的步骤中，我们将相似的数字提取到文件夹中，以构建我们的训练数据集。下面的代码演示了如何构建我们的训练/测试数据集。</p><figure class="ju jv jw jx gt jr"><div class="bz fp l di"><div class="or os l"/></div></figure><p id="0d17" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">既然我们已经创建了训练数据集并将其存储到了<strong class="km ir"> features </strong>和<strong class="km ir"> features_label </strong>数组中，那么我们就使用 sklearn 的函数<strong class="km ir"> train_test_split </strong>将训练集划分为训练集和测试集，并使用结果来训练 k-NN 分类器，最后保存模型，如下面的代码所示。</p><pre class="ju jv jw jx gt nk nl nm nn aw no bi"><span id="4d26" class="my lw iq nl b gy np nq l nr ns"><em class="li"># store features array into a numpy array<br/></em>features  = np.array(features_list, <strong class="nl ir">'float64'</strong>)</span><span id="b753" class="my lw iq nl b gy nt nq l nr ns"><em class="li"># split the labled dataset into training / test sets<br/></em>X_train, X_test, y_train, y_test = train_test_split(features, features_label)</span><span id="ccb6" class="my lw iq nl b gy nt nq l nr ns"><em class="li"># train using K-NN<br/></em>knn = KNeighborsClassifier(n_neighbors=3)<br/>knn.fit(X_train, y_train)</span><span id="116f" class="my lw iq nl b gy nt nq l nr ns"># get the model accuracy<br/>model_score = knn.score(X_test, y_test)<br/><br/><em class="li"># save trained model<br/></em>joblib.dump(knn, '<strong class="nl ir">/models/knn_model.pkl</strong>')</span></pre><h2 id="2a97" class="my lw iq bd lx mz na dn mb nb nc dp mf kv nd ne mj kz nf ng mn ld nh ni mr nj bi translated">5.预测</h2><p id="dc7d" class="pw-post-body-paragraph kk kl iq km b kn mt kp kq kr mu kt ku kv mv kx ky kz mw lb lc ld mx lf lg lh ij bi translated">预测新图像上的数字的过程遵循相同的步骤，即挑选出上述训练步骤中所示的数字，然后简单地应用 k-NN 的<strong class="km ir"> <em class="li">预测</em> </strong>函数，如下所示。</p><pre class="ju jv jw jx gt nk nl nm nn aw no bi"><span id="0972" class="my lw iq nl b gy np nq l nr ns">knn = joblib.load(<strong class="nl ir">'/models/knn_model.pkl'</strong>)</span><span id="903d" class="my lw iq nl b gy nt nq l nr ns"><strong class="nl ir">def </strong>feature_extraction(image):<br/>    <strong class="nl ir">return </strong>hog(color.rgb2gray(image), orientations=8, pixels_per_cell=(10, 10), cells_per_block=(5, 5))</span><span id="39ab" class="my lw iq nl b gy nt nq l nr ns"><strong class="nl ir">def </strong>predict(df):<br/>    predict = knn.predict(df.reshape(1,-1))[0]<br/>    predict_proba = knn.predict_proba(df.reshape(1,-1))<br/>    <strong class="nl ir">return </strong>predict, predict_proba[0][predict]</span><span id="5834" class="my lw iq nl b gy nt nq l nr ns">digits = []</span><span id="d9dc" class="my lw iq nl b gy nt nq l nr ns"># load your image from file</span><span id="4af7" class="my lw iq nl b gy nt nq l nr ns"># extract featuress<br/>hogs = list(map(<strong class="nl ir">lambda </strong>x: feature_extraction(x), digits))</span><span id="e6f1" class="my lw iq nl b gy nt nq l nr ns"># apply k-NN model created in previous<br/>predictions = list(map(<strong class="nl ir">lambda </strong>x: predict(x), hogs))</span></pre><p id="244f" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">k-NN 的<strong class="km ir"> <em class="li">预测</em> </strong>函数返回一个介于 0 和 9 之间的单个数字值，以表示输入图像的<em class="li">预测类别</em>。K-NN 的<strong class="km ir"><em class="li">predict _ proba</em></strong><em class="li"/>函数<em class="li"> </em>返回每个预测类关联的精度。</p><p id="74fd" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">例如，假设我们对包含数字“5”的图像应用了预测。输出的一个例子是<code class="fe oz pa pb nl b">prediction=5 and predict_proba =[[0 0 0 0 0 .8 0 0 .2 0]]</code>。这意味着 k-NN 以 80%的置信度将图像分类为“5”，以 20%的置信度将图像分类为“8”。</p><p id="65bc" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">最后，<code class="fe oz pa pb nl b">predictions = list(map(lambda x: predict(x), hogs))</code>产生以下元组向量，其中每个元组表示图像上每个数字的预测类别及其相关预测置信度。任何未以 100%置信度对输入进行分类的预测都将呈现给用户进行手动校正，如下一节所示。</p><pre class="ju jv jw jx gt nk nl nm nn aw no bi"><span id="7b2b" class="my lw iq nl b gy np nq l nr ns">[<br/>(5, 1.0), (1, 1.0), (9, 1.0), (2, 1.0), (1, 1.0), (2, 1.0), (4,1.0), (7, 1.0), (2, 1.0), (3, 1.0), (4, 1.0), (3, 1.0), (4, 1.0), <br/><strong class="nl ir">(4, 0.8)</strong>, (0, 1.0)<br/>]</span></pre><p id="fde9" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><strong class="km ir"> 6。演示文稿</strong></p><p id="27d3" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">最后一步是在 excel 文件中呈现机器学习模型的结果，如下所示。对于没有 100%准确预测的数字，我在实际预测的下面嵌入了预期数字的图像。这个微小的显示调整减少了用户 80%的时间来修正不准确的预测。此外，这项活动并不令人畏惧，因为它不需要大量的脑力劳动。用户可以在几分钟内滚动文件，并在视觉上将实际结果与预期结果相匹配。许多预测实际上是假阴性的，因此用户不需要做很多修正。</p><figure class="ju jv jw jx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="gh gi pc"><img src="../Images/d5bb97329621d1e92e76bb4d3a604c41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AlDRKo8FBTfd81BAz08WQQ.png"/></div></div></figure><h1 id="c6a8" class="lv lw iq bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">参考书目</h1><p id="9267" class="pw-post-body-paragraph kk kl iq km b kn mt kp kq kr mu kt ku kv mv kx ky kz mw lb lc ld mx lf lg lh ij bi translated"><em class="li">哈米德，不适用，&amp; Sjarif，不适用(2017)。基于 SVM、KNN 和神经网络的手写识别。arXiv 预印本 arXiv:1702.00723。</em></p><p id="2107" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">阿德里安·罗斯布鲁克的博客和书籍(【https://www.pyimagesearch.com】T2)。伟大的计算机视觉资源和许多关于数字识别的文章。</p><p id="fc9f" class="pw-post-body-paragraph kk kl iq km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated"><em class="li">帕特尔，I .，贾格塔普，v .，&amp;卡莱，O. (2014) </em>。手写数字识别的特征提取方法综述。<em class="li">国际计算机应用杂志</em>，<em class="li"> 107 期</em> (12)。</p></div></div>    
</body>
</html>