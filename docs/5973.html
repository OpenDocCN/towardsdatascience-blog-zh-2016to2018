<html>
<head>
<title>How to capture and store tweets in Real Time with Apache Spark and Apache Kafka. Using cloud Platforms such as Databricks and GCP (Part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用 Apache Spark 和 Apache Kafka 实时捕捉和存储推文？使用云平台，比如 Databricks 和 GCP(第 1 部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-capture-and-store-tweets-in-real-time-with-apache-spark-and-apache-kafka-e5ccd17afb32?source=collection_archive---------8-----------------------#2018-11-19">https://towardsdatascience.com/how-to-capture-and-store-tweets-in-real-time-with-apache-spark-and-apache-kafka-e5ccd17afb32?source=collection_archive---------8-----------------------#2018-11-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e8e8" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">包含代码和教程的可重复的端到端解决方案</h2></div><p id="311d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">大家好，借此机会我想分享一个关于如何使用云平台如<strong class="kh ir"> Databricks </strong>和<strong class="kh ir">谷歌云平台</strong>实时捕获和存储 Twitter 信息的例子<strong class="kh ir"> Spark Streaming </strong>和<strong class="kh ir"> Apache Kafka </strong>作为开源工具。</p><p id="121a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这次我们将使用 Spark 与 Twitter 进行交互，并通过 Producer 的 API 将数据带到 Kafka 主题。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="ab gu cl lg"><img src="../Images/0e44e201d7e89df10a0ee166dca9c686.png" data-original-src="https://miro.medium.com/v2/format:webp/0*6h0UYHQN_gk8sUEP.png"/></div></figure><p id="2960" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在开始开发之前，必须理解一些基本概念:</p><p id="410b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> Spark Streaming: </strong>它是 Apache Spark core API 的扩展，以可扩展的方式响应近实时(微批处理)的数据处理。Spark Streaming 可以连接不同的工具，如 Apache Kafka、Apache Flume、Amazon Kinesis、Twitter 和 IOT 传感器。</p><p id="7826" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> Apache Kafka: </strong>这是一个快速、可伸缩、持久、容错的发布订阅消息系统。Kafka 通常用于使用流数据提供实时分析的实时架构中。</p><p id="429c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lj">我们开始吧！</em></p><ol class=""><li id="6a5b" class="lk ll iq kh b ki kj kl km ko lm ks ln kw lo la lp lq lr ls bi translated"><strong class="kh ir"> Twitter 应用:</strong>要获取推文，我们必须在<a class="ae lt" href="https://apps.twitter.com/" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir">Twitter devs</strong></a><strong class="kh ir"/>注册并创建一个应用。Twitter 会给我们 4 个重要的价值观，让我们能够消费信息:</li></ol><ul class=""><li id="069f" class="lk ll iq kh b ki kj kl km ko lm ks ln kw lo la lu lq lr ls bi translated">消费者密钥(API 密钥)</li><li id="7050" class="lk ll iq kh b ki lv kl lw ko lx ks ly kw lz la lu lq lr ls bi translated">消费者秘密(API 秘密)</li><li id="b277" class="lk ll iq kh b ki lv kl lw ko lx ks ly kw lz la lu lq lr ls bi translated">访问令牌</li><li id="ad33" class="lk ll iq kh b ki lv kl lw ko lx ks ly kw lz la lu lq lr ls bi translated">访问令牌秘密</li></ul><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="ab gu cl lg"><img src="../Images/661532be4837c452f67986b269ba54c8.png" data-original-src="https://miro.medium.com/v2/format:webp/1*37MKMGVhXd18W2S9t32ALQ.png"/></div></figure><p id="3fa1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2.<strong class="kh ir">Spark data bricks:</strong>data bricks 平台允许我们创建一个免费的 Spark-Scala 集群。我们必须注册<a class="ae lt" href="https://databricks.com/signup#signup/community" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> Databricks </strong> </a>，然后创建一个 scala 笔记本，我们将在其中编写代码。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="ab gu cl lg"><img src="../Images/d12145f129a64891074739cc2e253455.png" data-original-src="https://miro.medium.com/v2/format:webp/1*SpsVV-eqbFLgrGFM5L4GGA.png"/></div></figure><p id="194a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在编写代码之前，我们必须创建一个集群并导入两个库，<a class="ae lt" href="https://mvnrepository.com/artifact/org.apache.bahir/spark-streaming-twitter_2.11/2.2.1" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir">Twitter library</strong></a><strong class="kh ir"/>将允许我们将 Twitter API 与 Spark 和<a class="ae lt" href="https://mvnrepository.com/artifact/org.apache.bahir/spark-streaming-twitter_2.11/2.2.1" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir"> KafkaLibrary </strong> </a>一起使用，这有助于我们连接 Apache Kafka。</p><p id="2a47" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里是如何使用 Maven 导入库的文档:<a class="ae lt" href="https://docs.databricks.com/user-guide/libraries.html" rel="noopener ugc nofollow" target="_blank">https://docs.databricks.com/user-guide/libraries.html</a></p><p id="6b67" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">创建集群:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi ma"><img src="../Images/41ecf97bfbdbaf66295fda22a6ee5563.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*hxY6Y-7i3_u8mZBU2iACrg.png"/></div></div></figure><p id="d14a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们必须选择选项:导入库</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="ab gu cl lg"><img src="../Images/dccbc6bb91ac4b41aff9478b1a8da3e3.png" data-original-src="https://miro.medium.com/v2/format:webp/1*cbWaGk7YPPPOOUX5zJd0bA.png"/></div></figure><p id="d5d2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们选取漫威坐标为源，写出库名:<strong class="kh ir">spark-streaming-Kafka-0–10 _ 2.11。</strong></p><p id="a4b0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">之后，我们对<strong class="kh ir">spark-streaming-Twitter _ 2.11</strong>做同样的事情</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="ab gu cl lg"><img src="../Images/28b34b5062a982924cddc56ad0d50c19.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Q4w29cDFVB_vh8vT0k7MUA.png"/></div></figure><p id="0664" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们只需要让我们的 Kafka 集群开始执行我们的开发。</p><p id="75c0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">3.<strong class="kh ir">Google 云平台中的 Apache Kafka:</strong>要创建集群，我们必须遵循以下步骤</p><p id="32a4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">a)在 GCP 创建一个实例并安装 Kafka，遵循下一个<a class="ae lt" href="https://www.datasciencecentral.com/profiles/blogs/setting-up-your-first-kafka-development-environment-in-google" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir">Kafka-Cloud</strong></a><strong class="kh ir"/>教程。</p><p id="3754" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">b)启用并创建规则以公开端口 2181(zookeeper)和 9092(kafka)。从我们虚拟机的 ssh 控制台输入以下命令:(记住要更改变量<strong class="kh ir"> NAME_VM </strong></p><pre class="lb lc ld le gt mf mg mh mi aw mj bi"><span id="0e0a" class="mk ml iq mg b gy mm mn l mo mp"><em class="lj">gcloud compute firewall-rules create rule-allow-tcp-9092 --source-ranges 0.0.0.0/0 --target-tags allow-tcp-9092 --allow tcp:9092</em></span><span id="f169" class="mk ml iq mg b gy mq mn l mo mp"><em class="lj">gcloud compute firewall-rules create rule-allow-tcp-2181 --source-ranges 0.0.0.0/0 --target-tags allow-tcp-2181 --allow tcp:2181</em></span><span id="64da" class="mk ml iq mg b gy mq mn l mo mp"><em class="lj">gcloud compute instances add-tags NAME_VM --tags allow-tcp-2181<br/>gcloud compute instances add-tags NAME_VM --tags allow-tcp-9092</em></span></pre><p id="cc79" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">c)配置 Kafka 属性文件以公开其服务，在 SSH 的下一个配置文件<strong class="kh ir"> server.properties </strong>中添加以下参数。</p><pre class="lb lc ld le gt mf mg mh mi aw mj bi"><span id="39da" class="mk ml iq mg b gy mm mn l mo mp"><em class="lj">vi /usr/local/kafka/config/server.properties</em></span><span id="8dd8" class="mk ml iq mg b gy mq mn l mo mp"><em class="lj">listeners=PLAINTEXT://your_internal_ip_vm:9092<br/>advertised.listeners=PLAINTEXT://your_external_ip_vm:9092</em></span></pre><p id="def2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">d)最后，重新启动 Kafka 服务以使所做的更改生效。</p><pre class="lb lc ld le gt mf mg mh mi aw mj bi"><span id="8cca" class="mk ml iq mg b gy mm mn l mo mp"><em class="lj">sudo /usr/local/kafka/bin/kafka-server-stop.sh</em></span><span id="2a11" class="mk ml iq mg b gy mq mn l mo mp"><em class="lj">sudo /usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties</em></span></pre><p id="ced0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我们准备消费来自 Twitter 的数据，并将其存储在 Apache Kafka 的一个主题中，走吧！</p><p id="cef9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们的笔记本中，我们输入以下代码:</p><figure class="lb lc ld le gt lf"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="4b2e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以从<a class="ae lt" href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/2128544101033400/1904549159880935/6372373427624332/latest.html" rel="noopener ugc nofollow" target="_blank"> jmgcode </a>下载完整的笔记本</p><p id="70be" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要查看 Kafka 中的消息，您可以在 GCP 环境中启动以下命令:By <strong class="kh ir"> SSH </strong></p><pre class="lb lc ld le gt mf mg mh mi aw mj bi"><span id="ddd3" class="mk ml iq mg b gy mm mn l mo mp">sudo /usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server your_internal_ip_vm:9092 --topic llamada</span></pre><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/fbc04f923e36ef0565fc65cb3c7f542a.png" data-original-src="https://miro.medium.com/v2/resize:fit:264/1*zhSDVlqLzPz7VgfosEsuag.gif"/></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk">working :)</figcaption></figure><p id="b1a5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在 Databricks 中，我们可以跟踪我们处理的推文:</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi my"><img src="../Images/a98b7759f890a425e49fc8819b549945.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*la3oX_axmvGfowTpuk0Pag.png"/></div></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk">number of tweets per second</figcaption></figure><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="gh gi mz"><img src="../Images/47c8c00cbb84a3409f692c9db84385a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*quqjHs9U4-zB4fdjj55abg.png"/></div></div></figure><p id="f96a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是目前的全部内容，在第二部分中，我们将看到如何在 rt 中对这些信息进行一些转换，并将结果存储在 Apache Hbase、Cassandra 或 Apache Kudu 等数据库中。</p><p id="b79d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下期帖子再见:)…</p><div class="na nb gp gr nc nd"><a href="https://github.com/jmendezgal/kafka-twitter-spark-streaming-cloud/blob/master/KafkaTwitterSparkStreaming.scala" rel="noopener  ugc nofollow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ir gy z fp ni fr fs nj fu fw ip bi translated">jmendezgal/卡夫卡-twitter-spark-streaming-cloud</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">通过在 GitHub 上创建帐户，为 jmendezgal/Kafka-Twitter-spark-streaming-cloud 开发做出贡献。</h3></div><div class="nl l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">github.com</p></div></div><div class="nm l"><div class="nn l no np nq nm nr lh nd"/></div></div></a></div></div></div>    
</body>
</html>