<html>
<head>
<title>BMW Machine Learning Weekly — Week 14</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">宝马机器学习周刊—第 14 周</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bmw-machine-learning-weekly-week-14-f0eae8ce33d8?source=collection_archive---------14-----------------------#2018-07-20">https://towardsdatascience.com/bmw-machine-learning-weekly-week-14-f0eae8ce33d8?source=collection_archive---------14-----------------------#2018-07-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/0df0cf73e2dc586a343ce18e05429b62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*F6GQSHoCreunXqAQ"/></div></div></figure><div class=""/><div class=""><h2 id="14d0" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">2018 年 7 月 5 日至 7 月 18 日</h2></div><p id="ebcc" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><em class="lm">关于机器学习(ML)、人工智能(AI)及相关研究领域的新闻。</em></p><h1 id="c8c6" class="ln lo jb bd lp lq lr ls lt lu lv lw lx kh ly ki lz kk ma kl mb kn mc ko md me bi translated">脸书的艾游客</h1><figure class="mg mh mi mj gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mf"><img src="../Images/f739efbe23c0dfddbe7d1b9839c9e77d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4_7NdM8nW8cyjTij"/></div></div></figure><p id="4cc0" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">如果你在纽约迷路了，没有智能手机或地图，你很可能会向当地人问路。脸书的研究人员正在训练人工智能程序做同样的事情，他们希望这最终能使他们更好地使用语言。纽约的脸书人工智能研究小组创建了两个人工智能程序:一个是在纽约迷路的“游客”，另一个是通过提供自然语言指令来帮助其同伴算法找到路的“向导”。迷路的游客看到的是真实世界的照片，而“导游”看到的是带有地标的二维地图。他们一起承担着到达特定目的地的任务。这个想法是，通过学习指令如何与现实相关，游客算法将开始找出这些东西实际上是什么。人工智能研究人员希望以这种方式教授的算法在使用语言时会更加复杂，这对人工智能来说仍然是一个巨大的挑战。</p><p id="12ee" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><a class="ae mk" href="https://www.technologyreview.com/s/611629/facebooks-ai-tourist-finds-its-way-around-new-york-city-by-asking-for-help-from-another/" rel="noopener ugc nofollow" target="_blank">继续阅读……</a></p><h1 id="9af4" class="ln lo jb bd lp lq lr ls lt lu lv lw lx kh ly ki lz kk ma kl mb kn mc ko md me bi translated">人类智能:伪人工智能</h1><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="ab gu cl ml"><img src="../Images/182a2f010192e71d4be38b4a01d36420.png" data-original-src="https://miro.medium.com/v2/format:webp/0*CIF2kGVsVrfQrlBf.jpg"/></div></figure><p id="9221" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在过去十年的大部分时间里，由智能手机主导的科技行业一直在追求一个单一的目标，即完全征服我们的眼睛，这让我们的手机屏幕越来越大。但我们似乎已经到达了一个被称为“峰值屏幕”的地方，科技巨头们开始构建一些新东西的开端:一个不那么坚持视觉化的科技世界，一个依赖语音助手、耳机、手表和其他可穿戴设备来减轻我们眼睛压力的数字景观。取决于这些技术如何发展，一个需要我们更少眼睛的数字生态系统可能对每个人都更好——更少沉浸感，更少上瘾，更有利于多任务处理。多年来，我们已经在汽车上看到了这一点:通过将内部控制放在触摸屏上，而不是触觉旋钮和开关上，汽车制造商已经使车辆变得更加令人讨厌和危险。特斯拉 Model 3 将这一点发挥到了荒谬的程度。正如几位评论家<a class="ae mk" href="https://www.edmunds.com/tesla/model-3/2017/review/" rel="noopener ugc nofollow" target="_blank">对</a>的哀叹，几乎每一个汽车控制器——包括侧镜的调节——都需要通过屏幕来操作。为了迈向“辉煌的小屏幕未来”，科技行业需要想出其他不那么身临其境的方式来与数字世界互动:语音助手。</p><p id="2f74" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><a class="ae mk" href="https://www.theguardian.com/technology/2018/jul/06/artificial-intelligence-ai-humans-bots-tech-companies" rel="noopener ugc nofollow" target="_blank">继续阅读……</a></p><h1 id="418a" class="ln lo jb bd lp lq lr ls lt lu lv lw lx kh ly ki lz kk ma kl mb kn mc ko md me bi translated">人工智能可以修复你粗糙的照片</h1><figure class="mg mh mi mj gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mm"><img src="../Images/043ebce4d3d82f42cd28504dd594bd12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/0*Nh2qVL9lEBvypAMx.jpg"/></div></div></figure><p id="7729" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">来自英伟达、阿尔托大学和麻省理工学院的研究人员开发了一种深度学习算法，该算法已经学会修复照片:删除文本和水印或修复颗粒状照片分辨率。研究人员使用特斯拉 P100 GPU 和 TensorFlow 深度学习框架来训练算法 Noise2Noise。Noise2Noise 使用图像的有噪版本和干净版本对 ImageNet 数据集的 50，0 00 多幅图像进行训练，可以消除伪像、噪声、颗粒，并自动增强您的照片，而无需查看对象的原始无噪版本。该算法不仅用于恢复颗粒状照片，还用于磁共振图像(MRI)扫描，这在医疗领域非常有益。</p><p id="cb80" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><a class="ae mk" href="https://news.developer.nvidia.com/ai-can-now-fix-your-grainy-photos-by-only-looking-at-grainy-photos/" rel="noopener ugc nofollow" target="_blank">继续阅读……</a></p><h1 id="6547" class="ln lo jb bd lp lq lr ls lt lu lv lw lx kh ly ki lz kk ma kl mb kn mc ko md me bi translated">值得注意的</h1><ul class=""><li id="c868" class="mn mo jb ks b kt mp kw mq kz mr ld ms lh mt ll mu mv mw mx bi translated"><strong class="ks jc">遇见奥斯卡垃圾桶</strong> <br/>奥斯卡来自<a class="ae mk" href="https://www.autonomous.ai/" rel="noopener ugc nofollow" target="_blank">自主</a>的人工智能垃圾桶，一家符合人体工程学的办公和游戏家具公司，为你回收。根据 Autonomous 的说法，当你把一件垃圾扔进奥斯卡的识别和分类机制时，图像识别相机会检测它是否可回收。如果 Oscar 的图像识别算法无法对物品进行分类，LED 会闪烁红光，提示用户通过“教授”物品的分类来提供帮助。<a class="ae mk" href="https://www.digitaltrends.com/home/oscar-ai-trash-can-sorts-recyclables-garbage/#/1" rel="noopener ugc nofollow" target="_blank">阅读更多… </a></li><li id="4b95" class="mn mo jb ks b kt my kw mz kz na ld nb lh nc ll mu mv mw mx bi translated">咨询公司普华永道(PwC)的一份报告预计，到 2037 年，人工智能将为英国经济增加的就业岗位(约 720 万个)将与该技术导致的失业(700 万个)一样多。<a class="ae mk" href="https://www.technologyreview.com/the-download/611663/a-new-report-says-ai-will-replace-as-many-jobs-as-it-kills-take-that-with-a-huge/" rel="noopener ugc nofollow" target="_blank">阅读更多内容……</a></li></ul></div></div>    
</body>
</html>