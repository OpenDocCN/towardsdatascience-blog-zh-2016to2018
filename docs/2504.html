<html>
<head>
<title>7 Practical Deep Learning Tips</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">7个实用的深度学习技巧</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/7-practical-deep-learning-tips-97a9f514100e?source=collection_archive---------4-----------------------#2018-02-02">https://towardsdatascience.com/7-practical-deep-learning-tips-97a9f514100e?source=collection_archive---------4-----------------------#2018-02-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><blockquote class="jq jr js"><p id="2943" class="jt ju jv jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr im bi translated">想获得灵感？快来加入我的<a class="ae ks" href="https://www.superquotes.co/?utm_source=mediumtech&amp;utm_medium=web&amp;utm_campaign=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="jw iu">超级行情快讯</strong> </a>。😎</p></blockquote><p id="5d21" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">深度学习已经成为解决许多具有挑战性的现实世界问题的首选方法。对于物体检测、语音识别和语言翻译来说，这是迄今为止性能最好的方法。许多人将深度神经网络(DNNs)视为神奇的黑匣子，我们将一堆数据放入其中，然后我们的解决方案就出来了！实际上，事情实际上会变得复杂得多…</p><p id="01a0" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">在针对特定问题设计和应用DNN时，可能会面临一系列挑战。为了达到实际应用所需的性能标准，管道中所有阶段的正确设计和执行至关重要，包括数据准备、网络设计、训练和推理。在这里，我将与你分享7个实用技巧，让你最大限度地利用你的深层神经网络。</p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi kw"><img src="../Images/ecb9710edbde0d7d51e9a0c8e7588e00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*seybwE7RkcsKCC1KNziTWw.jpeg"/></div></figure><h2 id="29ff" class="le lf it bd lg lh li dn lj lk ll dp lm kt ln lo lp ku lq lr ls kv lt lu lv lw bi translated">1 —数据，数据，数据</h2><p id="3c4f" class="pw-post-body-paragraph jt ju it jw b jx lx jz ka kb ly kd ke kt lz kh ki ku ma kl km kv mb kp kq kr im bi translated">这不是什么大秘密。一直运行良好的深度学习机器需要燃料——大量的燃料；这种燃料就是数据。我们拥有的<strong class="jw iu">标签</strong> <strong class="jw iu">数据</strong>越多，我们的模型表现就越好。更多的数据导致更好的性能的想法甚至已经被谷歌用3亿张图像的数据集进行了大规模的探索！</p><p id="3d14" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated"><a class="ae ks" href="https://arxiv.org/abs/1707.02968" rel="noopener ugc nofollow" target="_blank">重新审视深度学习时代数据的不合理有效性</a></p><p id="374c" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">当在现实世界的应用中部署深度学习模型时，你应该不断地向它提供更多的数据并进行微调，以继续提高它的性能。下图很好地说明了这将如何影响你的准确性。传统的机器学习算法达到了早期饱和点，超过这个饱和点，更多的数据就没有帮助了(蓝线)。另一方面，深度学习可以带你走得更远，获得更多数据(红线)。</p><p id="0dfb" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">喂野兽:如果你想提高你的模型的性能，获得更多的数据！</p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/9996b92662eb47fc7e9766a95b5c1f7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*3Hxt0mDknpqt6OSkRar9BQ.jpeg"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Increasing data consistently yields better performance</figcaption></figure><h2 id="dae6" class="le lf it bd lg lh li dn lj lk ll dp lm kt ln lo lp ku lq lr ls kv lt lu lv lw bi translated">2 —您应该使用哪种优化器？</h2><p id="23e8" class="pw-post-body-paragraph jt ju it jw b jx lx jz ka kb ly kd ke kt lz kh ki ku ma kl km kv mb kp kq kr im bi translated">多年来，已经开发了许多梯度下降优化算法，并且每个算法都有其优点和缺点。一些最受欢迎的包括:</p><ul class=""><li id="437c" class="mh mi it jw b jx jy kb kc kt mj ku mk kv ml kr mm mn mo mp bi translated">带动量的随机梯度下降(SGD)</li><li id="ab2d" class="mh mi it jw b jx mq kb mr kt ms ku mt kv mu kr mm mn mo mp bi translated">圣经》和《古兰经》传统中）亚当（人类第一人的名字</li><li id="c717" class="mh mi it jw b jx mq kb mr kt ms ku mt kv mu kr mm mn mo mp bi translated">RMSprop</li><li id="8a80" class="mh mi it jw b jx mq kb mr kt ms ku mt kv mu kr mm mn mo mp bi translated">阿达德尔塔</li></ul><p id="bf90" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">RMSprop、Adadelta和Adam被认为是<em class="jv">自适应</em>优化算法，因为它们<strong class="jw iu">自动</strong>更新学习率。使用SGD，您必须手动<strong class="jw iu">选择学习率和动量参数，通常学习率会随时间衰减。</strong></p><p id="b4eb" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">实际上，自适应优化器往往比SGD收敛得更快；但是，他们最后的表现通常会稍差一些。SGD通常可以获得更好的最小值，从而获得更好的最终精度，但是它可能比某些优化器花费更长的时间。它还更加依赖于一个健壮的初始化和学习率衰减时间表，这在实践中很难调整。</p><p id="e2c4" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">因此，如果你需要一些快速的结果，或者只是想测试一种新的技术，那么就使用自适应优化器。我发现Adam非常容易使用，因为它对你选择完美的学习速度并不敏感。如果你想要绝对最好的最终性能，使用SGD + Momentum并使用学习率、衰减和动量值来最大化性能。</p><p id="7662" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated"><strong class="jw iu">两全其美</strong></p><p id="3f79" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">最近的研究表明，你可以两全其美:<strong class="jw iu">通过<a class="ae ks" href="https://arxiv.org/pdf/1712.07628.pdf" rel="noopener ugc nofollow" target="_blank">从Adam切换到SGD </a>进行高速训练和顶级表现</strong>！这个想法是，训练的早期阶段实际上是SGD对参数调整和初始化非常敏感的时候。因此，我们可以通过使用Adam开始我们的训练，这将使您走得很远，而不必担心初始化和参数调整。然后，一旦亚当让我们滚动，我们可以切换到SGD +动量优化，以实现最佳性能！论文<a class="ae ks" href="https://arxiv.org/pdf/1712.07628.pdf" rel="noopener ugc nofollow" target="_blank">中的关键数字</a>如下所示，展示了如何通过这种技术来提高精确度。</p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/a072aa8add85839d76bcdf756b04325d.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*vypnUsaqDt1i0FaTbBz-pg.png"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Adam vs SGD performance. Adam performs better at the beginning due to robustness and adaptive learning rate, while SGD reaches a better global minimum in the end.</figcaption></figure><h2 id="42d8" class="le lf it bd lg lh li dn lj lk ll dp lm kt ln lo lp ku lq lr ls kv lt lu lv lw bi translated">3—如何处理不平衡的数据</h2><p id="76f6" class="pw-post-body-paragraph jt ju it jw b jx lx jz ka kb ly kd ke kt lz kh ki ku ma kl km kv mb kp kq kr im bi translated">在很多情况下，你会处理<strong class="jw iu">不平衡的</strong> <strong class="jw iu">数据</strong>，尤其是在现实世界的应用中。举一个简单但真实的例子:出于安全原因，你正在训练你的深层网络来预测视频中的某人是否持有致命武器。但是在你的训练数据里，你只有50个拿武器的人的视频，1000个没拿武器的人的视频！如果你只是用这些数据马上训练你的网络，你的模型肯定会高度偏向于预测没有人曾经拥有过武器！</p><p id="563d" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">你可以做一些事情来解决这个问题:</p><ul class=""><li id="2932" class="mh mi it jw b jx jy kb kc kt mj ku mk kv ml kr mm mn mo mp bi translated">在损失函数中使用<strong class="jw iu">类</strong> <strong class="jw iu">权重</strong>。本质上，代表不足的类别在损失函数中接收更高的权重，使得该特定类别的任何错误分类将导致损失函数中非常高的误差。</li><li id="431a" class="mh mi it jw b jx mq kb mr kt ms ku mt kv mu kr mm mn mo mp bi translated"><strong class="jw iu">过采样</strong>:重复一些包含代表性不足的类的训练示例有助于均衡分布。如果可用数据很少，这种方法效果最好。</li><li id="5fcb" class="mh mi it jw b jx mq kb mr kt ms ku mt kv mu kr mm mn mo mp bi translated"><strong class="jw iu">欠采样</strong>:您可以简单地跳过一些包含过度表示类的训练示例。如果可用数据非常大，这种方法效果最好。</li><li id="01a7" class="mh mi it jw b jx mq kb mr kt ms ku mt kv mu kr mm mn mo mp bi translated"><strong class="jw iu">少数民族阶层的数据扩充</strong>。你可以为代表性不足的班级综合创造更多的训练范例！例如，在前面检测致命武器的例子中，你可以改变视频的一些颜色和灯光，这些视频属于拥有致命武器的类别。</li></ul><h2 id="f8fe" class="le lf it bd lg lh li dn lj lk ll dp lm kt ln lo lp ku lq lr ls kv lt lu lv lw bi translated">4 —迁移学习</h2><p id="bd73" class="pw-post-body-paragraph jt ju it jw b jx lx jz ka kb ly kd ke kt lz kh ki ku ma kl km kv mb kp kq kr im bi translated">正如我们在第一个技巧中看到的，深度网络需要大量数据。不幸的是，对于许多新的应用程序来说，这些数据很难获得，而且获取成本很高。如果我们希望我们的模型表现良好，我们可能需要数万或数十万个新的训练样本来进行训练。如果一个数据集不容易得到，它必须全部收集起来并手工标记为<strong class="jw iu">。</strong></p><p id="de3b" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">这就是<a class="ae ks" href="https://arxiv.org/abs/1411.1792" rel="noopener ugc nofollow" target="_blank">迁移学习</a>发挥作用的地方。有了迁移学习，我们就不需要很多数据了！这个想法是从一个之前在数百万张图像上训练过的网络开始，比如在ImageNet上预先训练过的<a class="ae ks" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> ResNet </a>。然后，我们将通过<strong class="jw iu">只重新训练最后几层而不去管其他层</strong>来微调ResNet模型。通过这种方式，我们获得了ResNet从数百万张图像中获得的信息(图像特征),并对其进行了微调，以便我们可以将其应用于不同的任务。这是可能的，因为跨域的图像的特征信息通常非常相似，但是对这些特征的分析可以根据应用而不同。整个过程如下图所示，它展示了我们如何获取源模型的特性，并将其作为全新目标模型的起点。</p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/b23b3a7c6e6c29157a52a6a5913381e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*ovNMgv2yulRn6mnpzOSkUg.jpeg"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk">A basic transfer learning pipeline</figcaption></figure><h2 id="8f41" class="le lf it bd lg lh li dn lj lk ll dp lm kt ln lo lp ku lq lr ls kv lt lu lv lw bi translated">5 —快速简单的数据扩充，以提高性能</h2><p id="2d84" class="pw-post-body-paragraph jt ju it jw b jx lx jz ka kb ly kd ke kt lz kh ki ku ma kl km kv mb kp kq kr im bi translated">我们已经说过几次了:更多的数据=更好的性能。除了迁移学习，另一种提高模型性能的快速简单的方法是<strong class="jw iu">数据扩充</strong>。数据扩充包括通过改变来自数据集的一些原始图像，同时使用原始类别标签来生成合成训练样本。例如，图像数据扩充的常见方式包括:</p><ul class=""><li id="745e" class="mh mi it jw b jx jy kb kc kt mj ku mk kv ml kr mm mn mo mp bi translated">水平和垂直旋转和/或翻转图像</li><li id="8764" class="mh mi it jw b jx mq kb mr kt ms ku mt kv mu kr mm mn mo mp bi translated">改变图像的亮度和颜色</li><li id="d9fb" class="mh mi it jw b jx mq kb mr kt ms ku mt kv mu kr mm mn mo mp bi translated">随机模糊图像</li><li id="ac11" class="mh mi it jw b jx mq kb mr kt ms ku mt kv mu kr mm mn mo mp bi translated">从图像中随机裁剪补丁</li></ul><p id="9860" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">基本上，你可以进行任何改变图像外观的改变，但不能改变整体内容，也就是说，你可以把一张狗的图片变成蓝色，但你仍然可以清楚地看到这是一张狗的图片。下图来自<a class="ae ks" href="https://github.com/aleju/imgaug" rel="noopener ugc nofollow" target="_blank"> <strong class="jw iu"> imgaug </strong> </a>库，显示了许多你可能想要尝试的图像增强选项，以提高你的模型的准确性。</p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi mw"><img src="../Images/93172cabe7685989c84573b1f821f060.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lepw-fPiuN_FVgxpP__4rw.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Data augmentation galore!</figcaption></figure><h2 id="ae2a" class="le lf it bd lg lh li dn lj lk ll dp lm kt ln lo lp ku lq lr ls kv lt lu lv lw bi translated">6-用合奏来提升你的模型！</h2><p id="c29c" class="pw-post-body-paragraph jt ju it jw b jx lx jz ka kb ly kd ke kt lz kh ki ku ma kl km kv mb kp kq kr im bi translated">在机器学习中，<strong class="jw iu">集合训练多个模型</strong>，然后<strong class="jw iu">将它们</strong>组合在一起，以实现更高的性能。因此，想法是在相同的数据集上对相同的任务训练多个深度网络模型。然后可以通过投票方案将模型的结果结合起来，即票数最高的类别获胜。</p><p id="2449" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">为了确保所有模型都是不同的，可以使用随机权重初始化和随机数据增加。众所周知，集合通常比单个模型更精确，这是由于使用了多个模型，因此从不同的角度处理任务。在现实世界的应用中，尤其是挑战或比赛，几乎所有的顶级模型都使用系综。集成的一般要点如下所示，其中3个不同分类模型的输出被组合在一起。</p><figure class="kx ky kz la gt lb gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/329cc461f384236f70cdc040e60b74b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*pCk0-MhJigPqIvbjMZkxMA.jpeg"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Ensemble models</figcaption></figure><h2 id="370f" class="le lf it bd lg lh li dn lj lk ll dp lm kt ln lo lp ku lq lr ls kv lt lu lv lw bi translated">7 —通过修剪加快速度</h2><p id="18b3" class="pw-post-body-paragraph jt ju it jw b jx lx jz ka kb ly kd ke kt lz kh ki ku ma kl km kv mb kp kq kr im bi translated">我们知道模型精度随着深度增加，但是速度呢？层数越多意味着参数越多，参数越多意味着计算越多，内存消耗越大，速度越慢。理想情况下，我们希望在提高速度的同时保持高精度。我们可以通过<strong class="jw iu">修剪</strong>来做到这一点。</p><p id="ddaa" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">这个想法是，在网络的许多参数中，有些参数是冗余的，对输出没有太大贡献。如果你可以根据神经元的贡献大小对网络中的神经元进行排序，那么你就可以从网络中移除排序较低的神经元，从而形成一个更小、更快的网络。可以根据神经元权重的L1/L2均值、它们的平均激活度、某个验证集上神经元不为零的次数以及其他创造性方法来进行排序。获得更快/更小的网络对于在移动设备上运行深度学习网络很重要。</p><p id="972b" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">修剪网络的最基本方法是简单地丢弃某些卷积滤波器。这在最近的论文中做得相当成功。这项工作中的神经元排序相当简单:它是每个过滤器权重的L1范数。在每次修剪迭代中，他们对所有的过滤器进行排序，在所有层中全局地修剪m个最低排序的过滤器，重新训练并重复！</p><p id="1499" class="pw-post-body-paragraph jt ju it jw b jx jy jz ka kb kc kd ke kt kg kh ki ku kk kl km kv ko kp kq kr im bi translated">另一篇<a class="ae ks" href="https://arxiv.org/abs/1605.06431" rel="noopener ugc nofollow" target="_blank">最近发表的论文</a>提出了修剪过滤器的关键见解，该论文分析了残差网络的结构。作者表明，当删除图层时，具有残余快捷连接的网络(如ResNets)在保持良好的准确性方面远比不使用任何快捷连接的网络(如VGG或AlexNet)更强大。这一有趣的发现具有很大的实际意义，因为它告诉我们，在为部署和应用而修剪网络时，网络设计至关重要。).所以用最新最棒的方法总是好的！</p><h2 id="547d" class="le lf it bd lg lh li dn lj lk ll dp lm kt ln lo lp ku lq lr ls kv lt lu lv lw bi translated">这是一个总结！</h2><p id="7895" class="pw-post-body-paragraph jt ju it jw b jx lx jz ka kb ly kd ke kt lz kh ki ku ma kl km kv mb kp kq kr im bi translated">这就是你深度学习的7个实用技巧！</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><h1 id="4aa3" class="nj lf it bd lg nk nl nm lj nn no np lm nq nr ns lp nt nu nv ls nw nx ny lv nz bi translated">喜欢学习？</h1><p id="cabc" class="pw-post-body-paragraph jt ju it jw b jx lx jz ka kb ly kd ke kt lz kh ki ku ma kl km kv mb kp kq kr im bi translated">在<a class="ae ks" href="https://twitter.com/GeorgeSeif94" rel="noopener ugc nofollow" target="_blank">推特</a>上关注我，我会在那里发布所有最新最棒的人工智能、技术和科学！</p></div></div>    
</body>
</html>