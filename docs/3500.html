<html>
<head>
<title>A Complete Machine Learning Walk-Through in Python: Part Three</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 中完整的机器学习演练:第三部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-complete-machine-learning-walk-through-in-python-part-three-388834e8804b?source=collection_archive---------3-----------------------#2018-05-18">https://towardsdatascience.com/a-complete-machine-learning-walk-through-in-python-part-three-388834e8804b?source=collection_archive---------3-----------------------#2018-05-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/39eb03a5c14d79fd0a718cb1eb67273d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mAlyXZiMVqRSfbqohauiHw.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="6a94" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">解释机器学习模型并呈现结果</h2></div><p id="d4ac" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">机器学习模型经常被批评为<a class="ae lm" href="https://datascience.stackexchange.com/questions/22335/why-are-machine-learning-models-called-black-boxes" rel="noopener ugc nofollow" target="_blank">黑箱</a>:我们把数据放在一边，得到答案——通常是非常准确的答案——另一边没有解释。在展示完整的机器学习解决方案的本系列的第三部分中，我们将深入研究我们开发的模型，以尝试并理解它如何进行预测，以及它可以教给我们关于该问题的什么。我们将通过讨论机器学习项目中最重要的部分来结束:记录我们的工作并展示结果。</p><p id="6da1" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><a class="ae lm" rel="noopener" target="_blank" href="/a-complete-machine-learning-walk-through-in-python-part-one-c62152f39420">本系列的第一部分</a>涵盖了数据清理、探索性数据分析、特性工程和特性选择。<a class="ae lm" rel="noopener" target="_blank" href="/a-complete-machine-learning-project-walk-through-in-python-part-two-300f1f8147e2">第二部分</a>涵盖了输入缺失值、实现和比较机器学习模型、使用交叉验证的随机搜索进行超参数调整，以及评估模型。</p><p id="e036" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这个项目的所有<a class="ae lm" href="https://github.com/WillKoehrsen/machine-learning-project-walkthrough" rel="noopener ugc nofollow" target="_blank">代码都在 GitHub 上。</a><a class="ae lm" href="https://github.com/WillKoehrsen/machine-learning-project-walkthrough/blob/master/Machine%20Learning%20Project%20Part%203.ipynb" rel="noopener ugc nofollow" target="_blank">第三本 Jupyter 笔记本，对应本帖，在此</a>。我鼓励任何人分享、使用和构建这些代码！</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><p id="42b9" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">提醒一下，我们正在解决一个监督回归机器学习问题。使用<a class="ae lm" href="http://www.nyc.gov/html/gbee/html/plan/ll84_scores.shtml" rel="noopener ugc nofollow" target="_blank">纽约市建筑能源数据</a>，我们开发了一个可以预测建筑能源之星得分的模型。我们构建的最终模型是一个<a class="ae lm" href="http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/" rel="noopener ugc nofollow" target="_blank">梯度推进回归器</a>，它能够将测试数据的能源之星得分预测到 9.1 分以内(1-100 分)。</p><h1 id="8c71" class="lu lv jb bd lw lx ly lz ma mb mc md me kh mf ki mg kk mh kl mi kn mj ko mk ml bi translated">模型解释</h1><p id="00a8" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">梯度推进回归变量位于模型可解释性的<a class="ae lm" href="https://2.bp.blogspot.com/-AL1LsaTHVNQ/Wh589GDwkaI/AAAAAAAAaxc/nwpqKEUIgXokRxt75nzgzQz00IRqH68PACLcBGAs/s1600/B2G1g0UIMAEieiR.png" rel="noopener ugc nofollow" target="_blank">尺度的中间:整个模型很复杂，但它是由数百个</a><a class="ae lm" href="https://en.wikipedia.org/wiki/Decision_tree_learning" rel="noopener ugc nofollow" target="_blank">决策树</a>组成的，它们本身是很容易理解的。我们将从三个方面来理解我们的模型是如何进行预测的:</p><ol class=""><li id="6a47" class="mr ms jb ks b kt ku kw kx kz mt ld mu lh mv ll mw mx my mz bi translated"><a class="ae lm" href="http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html" rel="noopener ugc nofollow" target="_blank">特征重要性</a></li><li id="d185" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll mw mx my mz bi translated">可视化单个决策树</li><li id="efba" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll mw mx my mz bi translated"><a class="ae lm" href="https://github.com/marcotcr/lime" rel="noopener ugc nofollow" target="_blank"> LIME:局部可解释的模型不可知解释</a></li></ol><p id="8825" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">前两种方法专门针对树的集合，而第三种方法——正如你可能从名称中猜到的那样——可以应用于任何机器学习模型。LIME 是一个相对较新的包，代表了正在进行的解释机器学习预测的努力中令人兴奋的一步。</p><h2 id="0572" class="nf lv jb bd lw ng nh dn ma ni nj dp me kz nk nl mg ld nm nn mi lh no np mk nq bi translated">特征重要性</h2><p id="2913" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">特征重要性试图显示每个特征与预测目标任务的相关性。特征重要性的技术细节很复杂(它们<a class="ae lm" href="https://papers.nips.cc/paper/4928-understanding-variable-importances-in-forests-of-randomized-trees.pdf" rel="noopener ugc nofollow" target="_blank">测量平均杂质减少量</a>，或<a class="ae lm" href="https://stackoverflow.com/questions/15810339/how-are-feature-importances-in-randomforestclassifier-determined" rel="noopener ugc nofollow" target="_blank">因包含特征</a>而减少的误差)，但我们可以使用相对值来比较哪些特征最相关。在 Scikit-Learn 中，我们可以从任何基于树的学习者集合中提取特征重要性。</p><p id="ed80" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">使用<code class="fe nr ns nt nu b">model</code>作为我们的训练模型，我们可以使用<code class="fe nr ns nt nu b">model.feature_importances_ </code>找到特征重要性。然后，我们可以将它们放入熊猫数据框架中，并显示或绘制前十个最重要的:</p><figure class="nv nw nx ny gt is"><div class="bz fp l di"><div class="nz oa l"/></div></figure><div class="nv nw nx ny gt ab cb"><figure class="ob is oc od oe of og paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/c1b4ada191297cf0cc6dd835adc7c26a.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*Qn30CVyteeebyo5peqzfgw.png"/></div></figure><figure class="ob is oh od oe of og paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/97374eda4b0fc38d62ec882d69fe8cf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*GRq9i7AJheqTImh7NyR3ig.png"/></div></figure></div><p id="4d55" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><code class="fe nr ns nt nu b">Site EUI</code> ( <a class="ae lm" href="https://www.energystar.gov/buildings/facility-owners-and-managers/existing-buildings/use-portfolio-manager/understand-metrics/what-energy" rel="noopener ugc nofollow" target="_blank">)能源使用强度</a>)和<code class="fe nr ns nt nu b">Weather Normalized Site Electricity Intensity</code>是最重要的特征，占总重要性的 66%以上。在前两个特征之后，重要性显著下降，这表明我们可能不需要保留数据中的所有 64 个特征来实现高性能。(在<a class="ae lm" href="https://github.com/WillKoehrsen/machine-learning-project-walkthrough/blob/master/Machine%20Learning%20Project%20Part%203.ipynb" rel="noopener ugc nofollow" target="_blank">Jupyter 笔记本</a>中，我看了一下仅使用前 10 个功能的情况，发现该模型并不十分准确。)</p><p id="41a3" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">基于这些结果，我们终于可以回答我们最初的一个问题:建筑物能源之星得分的最重要指标是站点 EUI 和天气标准化站点电力强度。虽然我们确实希望<a class="ae lm" href="http://parrt.cs.usfca.edu/doc/rf-importance/index.html" rel="noopener ugc nofollow" target="_blank">小心不要过度解读特征重要性</a>，但它们是开始理解模型如何做出预测的有用方式。</p><h2 id="e7ab" class="nf lv jb bd lw ng nh dn ma ni nj dp me kz nk nl mg ld nm nn mi lh no np mk nq bi translated">可视化单个决策树</h2><p id="7397" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">虽然整个梯度推进回归可能难以理解，但任何一个单独的决策树都是非常直观的。我们可以使用<a class="ae lm" href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn 函数</a> <code class="fe nr ns nt nu b"><a class="ae lm" href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html" rel="noopener ugc nofollow" target="_blank">export_graphviz</a></code>来想象森林中的任何一棵树。我们首先从系综中提取一棵树，然后将其保存为点文件:</p><figure class="nv nw nx ny gt is"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="84e9" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">使用<a class="ae lm" href="https://www.graphviz.org/" rel="noopener ugc nofollow" target="_blank"> Graphviz 可视化软件</a>我们可以从命令行将点文件转换成 png 文件:</p><pre class="nv nw nx ny gt oi nu oj ok aw ol bi"><span id="1804" class="nf lv jb nu b gy om on l oo op">dot -Tpng images/tree.dot -o images/tree.png</span></pre><p id="d6bf" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">结果是一个完整的决策树:</p><figure class="nv nw nx ny gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oq"><img src="../Images/9acf7d1f5430a0725ed87324ec5c0f3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zsseqTnCZlH91j4cEL_jKg.png"/></div></div><figcaption class="or os gj gh gi ot ou bd b be z dk">Full Decision Tree in the Model</figcaption></figure><p id="b8e5" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这有点让人不知所措！尽管这棵树的深度只有 6(层数)，但还是很难理解。我们可以修改对<code class="fe nr ns nt nu b">export_graphviz</code>的调用，并将我们的树限制在更合理的深度 2:</p><figure class="nv nw nx ny gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ov"><img src="../Images/fa39e223ea202243179663908728f13b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rjQNJ8kNao-EVOjs_69OUA.png"/></div></div><figcaption class="or os gj gh gi ot ou bd b be z dk">Decision Tree Limited to a Depth of 2</figcaption></figure><p id="df62" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">树中的每个节点(框)有四条信息:</p><ol class=""><li id="57df" class="mr ms jb ks b kt ku kw kx kz mt ld mu lh mv ll mw mx my mz bi translated">这个问题问的是数据点的一个特性的值:这决定了我们是向右还是向左离开节点</li><li id="3557" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll mw mx my mz bi translated"><code class="fe nr ns nt nu b">mse</code>是节点误差的度量</li><li id="8f80" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll mw mx my mz bi translated"><code class="fe nr ns nt nu b">samples</code>是节点中实例(数据点)的数量</li><li id="5ff3" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll mw mx my mz bi translated"><code class="fe nr ns nt nu b">value</code>是节点中所有样本的目标估计值</li></ol><figure class="nv nw nx ny gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ow"><img src="../Images/0df777cbf3edafe45781136a840dabb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e-GLVi1Ss6pjDPh6l8UFCQ.png"/></div></div><figcaption class="or os gj gh gi ot ou bd b be z dk">Individual Node in Decision Tree</figcaption></figure><p id="9d85" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">(叶节点只有 2 个。–4.因为它们代表最终估计值，并且没有任何子代)。</p><p id="c76e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">决策树通过从称为根的顶部节点开始，沿着树向下工作来预测数据点。在每一个节点，数据点会被问一个是或否的问题。例如，上面节点的问题是:建筑物的场地 EUI 是否小于或等于 68.95？如果答案是肯定的，那么该建筑被放置在右边的子节点中，如果答案是否定的，那么该建筑被放置在左边的子节点中。</p><p id="bf8a" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在树的每一层重复该过程，直到数据点被放置在树的底部的叶节点中(叶节点从小树图像中被裁剪)。对叶节点中所有数据点的预测是<code class="fe nr ns nt nu b">value</code>。如果在一个叶节点中有多个数据点(<code class="fe nr ns nt nu b">samples</code>)，它们都得到相同的预测。随着树的深度增加，训练集上的误差将减少，因为有更多的叶节点，并且示例可以被更精细地划分。然而，太深的树将<a class="ae lm" rel="noopener" target="_blank" href="/overfitting-vs-underfitting-a-conceptual-explanation-d94ee20ca7f9">过度适应训练数据</a>，并且将不能推广到新的测试数据。</p><p id="c9fe" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在第二篇文章的<a class="ae lm" rel="noopener" target="_blank" href="/a-complete-machine-learning-project-walk-through-in-python-part-two-300f1f8147e2">中，我们调整了许多模型超参数，它们控制着每棵树的各个方面，比如树的最大深度和一个叶节点所需的最小样本数。这两者对欠拟合和过拟合的平衡都有重大影响，可视化单个决策树允许我们看到这些设置如何工作。</a></p><p id="5b72" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">虽然我们不能检查模型中的每一棵树，但是查看一棵树可以让我们了解每个学习者如何做出预测。这种基于流程图的方法看起来很像人类做决策的方式，一次回答一个关于单个值的问题。<a class="ae lm" href="http://scikit-learn.org/stable/modules/ensemble.html" rel="noopener ugc nofollow" target="_blank">基于决策树的集成</a>将许多单个决策树的预测结合起来，以创建一个更准确、方差更小的模型。<a class="ae lm" href="https://blog.statsbot.co/ensemble-learning-d1dcd548e936" rel="noopener ugc nofollow" target="_blank">树的集合往往非常准确</a>，并且解释起来也很直观。</p><h2 id="7efb" class="nf lv jb bd lw ng nh dn ma ni nj dp me kz nk nl mg ld nm nn mi lh no np mk nq bi translated">局部可解释的模型不可知解释(LIME)</h2><p id="4c37" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">我们将探索的试图理解我们的模型如何“思考”的最后一个工具是模型解释领域的一个新入口。<a class="ae lm" href="https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime" rel="noopener ugc nofollow" target="_blank"> LIME 旨在通过使用线性回归等简单模型在数据点附近局部创建模型的近似来解释来自任何机器学习模型</a>的单个预测。<a class="ae lm" href="https://arxiv.org/pdf/1602.04938.pdf" rel="noopener ugc nofollow" target="_blank">完整细节可在论文</a>中找到。</p><p id="b8fd" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在这里，我们将使用 LIME 来检查模型完全错误的预测，以了解它可能会告诉我们关于模型为什么会出错的信息。</p><p id="f03d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">首先，我们需要找到我们的模型最容易出错的观察结果。我们通过使用模型进行训练和预测，并提取模型误差最大的示例来实现这一点:</p><figure class="nv nw nx ny gt is"><div class="bz fp l di"><div class="nz oa l"/></div></figure><pre class="nv nw nx ny gt oi nu oj ok aw ol bi"><span id="d80d" class="nf lv jb nu b gy om on l oo op"><strong class="nu jc">Prediction: 12.8615<br/>Actual Value: 100.0000</strong></span></pre><p id="3f26" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">接下来，我们创建 LIME explainer 对象，向它传递我们的训练数据、模式、训练标签和数据中的特性名称。最后，我们要求解释者对象解释错误的预测，传递给它观察和预测函数。</p><figure class="nv nw nx ny gt is"><div class="bz fp l di"><div class="nz oa l"/></div></figure><p id="dac6" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">解释这一预测的图表如下:</p><figure class="nv nw nx ny gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ox"><img src="../Images/d6d7993fc5be5c0c167d18932bb4df99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F-Lmsk4U52Ma1hbyPXVhmg.png"/></div></div></figure><p id="d873" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">以下是解释该图的方法:y 轴上的每个条目表示一个变量的一个值，红色和绿色条显示该值对预测的影响。例如，顶部条目显示站点 EUI 大于 95.90，这从预测中减去了大约 40 个点。第二个条目说天气标准化的站点电力强度小于 3.80，这为预测增加了大约 10 分。最终预测是截距项加上这些单独贡献的总和。</p><p id="afcf" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们可以通过调用 explainer <code class="fe nr ns nt nu b">.show_in_notebook()</code>方法来查看相同的信息:</p><pre class="nv nw nx ny gt oi nu oj ok aw ol bi"><span id="eec6" class="nf lv jb nu b gy om on l oo op"># Show the explanation in the Jupyter Notebook<br/>exp.show_in_notebook()</span></pre><figure class="nv nw nx ny gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oy"><img src="../Images/a8fba5d8b9fe2458365660d8a32c8f9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vWdvPN4yqQmrOVHSEqGFRA.png"/></div></div><figcaption class="or os gj gh gi ot ou bd b be z dk">Output from LIME Explainer Object</figcaption></figure><p id="21fd" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这通过显示每个变量对预测的贡献，在左侧显示了模型的推理过程。右边的表格显示了数据点变量的实际值。</p><p id="f90f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">对于本例，模型预测值约为 12，而实际值为 100！虽然最初这一预测可能令人费解，但通过查看解释，我们可以看到这不是一个极端的猜测，而是给定数据点值的合理估计。该站点 EUI 相对较高，我们预计能源之星得分较低(因为 EUI 与得分高度负相关)，这是我们的模型得出的结论。在这种情况下，逻辑是错误的，因为该建筑的满分是 100 分。</p><p id="c4e0" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">当一个模型是错误的时候，它可能是令人沮丧的，但是诸如此类的解释帮助我们理解为什么模型是不正确的。此外，基于这一解释，我们可能想要调查为什么该建筑尽管有如此高的场地 EUI 却得到了满分。也许我们可以了解到一些新的问题，如果不研究这个模型，我们可能会忽略这些问题。诸如此类的工具并不完美，但它们对帮助我们理解模型大有帮助，这反过来可以让我们做出更好的决策。</p><h1 id="a607" class="lu lv jb bd lw lx ly lz ma mb mc md me kh mf ki mg kk mh kl mi kn mj ko mk ml bi translated">记录工作和报告结果</h1><p id="972f" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">任何技术项目中经常被忽视的部分是文档和报告。我们可以做世界上最好的分析，但是如果我们不与<a class="ae lm" href="http://blog.kaggle.com/2016/06/29/communicating-data-science-a-guide-to-presenting-your-work/" rel="noopener ugc nofollow" target="_blank">清楚地交流结果</a>，那么他们将不会有任何影响！</p><p id="8f3d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">当我们记录一个数据科学项目时，我们会将所有版本的数据和代码打包，以便其他数据科学家可以复制或构建我们的项目。重要的是要记住，代码被阅读的次数比它被编写的次数要多，我们要确保我们的工作是可以理解的<strong class="ks jc">对他人和我们自己</strong>如果我们几个月后再回来看的话。这意味着在代码中加入有用的注释，并解释你的推理。我发现 Jupyter 笔记本是一个很好的文档工具，因为它们允许一个接一个的解释和编码。</p><p id="c7f0" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">Jupyter 笔记本也是一个很好的与他人交流发现的平台。使用<a class="ae lm" href="https://github.com/ipython-contrib/jupyter_contrib_nbextensions" rel="noopener ugc nofollow" target="_blank">笔记本扩展</a>，我们可以<a class="ae lm" href="https://github.com/kirbs-/hide_code" rel="noopener ugc nofollow" target="_blank">在我们的最终报告</a>中隐藏代码，因为虽然这很难相信，但并不是每个人都想在一个文档中看到一堆 Python 代码！</p><p id="c6c2" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">就我个人而言，我很难简明扼要地总结我的工作，因为我喜欢浏览所有的细节。然而，重要的是<a class="ae lm" href="http://sites.ieee.org/pcs/communication-resources-for-engineers/audience-purpose-and-context/understand-your-audience/" rel="noopener ugc nofollow" target="_blank">在你演讲的时候理解你的听众</a>并且<a class="ae lm" href="https://hbr.org/2015/04/the-best-presentations-are-tailored-to-the-audience" rel="noopener ugc nofollow" target="_blank">相应地调整信息</a>。考虑到这一点，以下是我对这个项目的 30 秒总结:</p><ol class=""><li id="fcb6" class="mr ms jb ks b kt ku kw kx kz mt ld mu lh mv ll mw mx my mz bi translated">使用纽约市的能源数据，可以建立一个模型，将建筑物的能源之星得分预测到 9.1 分以内。</li><li id="d6f8" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll mw mx my mz bi translated">站点 EUI 和天气标准化电力强度是预测能源之星得分的最相关因素。</li></ol><p id="af70" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">最初，我被一家初创公司作为筛选工作的“任务”给了这个项目。为了期末报告，他们想看我的工作和结论，所以我做了一个 Jupyter 笔记本上交。然而，我没有在 Jupyter 中直接转换为 PDF，而是将其转换为一个<a class="ae lm" href="https://www.latex-project.org/" rel="noopener ugc nofollow" target="_blank"> Latex </a> <code class="fe nr ns nt nu b">.tex</code>文件，然后在<a class="ae lm" href="https://www.texstudio.org/" rel="noopener ugc nofollow" target="_blank"> texStudio </a>中编辑，然后渲染为用于<a class="ae lm" href="https://github.com/WillKoehrsen/machine-learning-project-walkthrough/blob/master/Building%20Data%20Report.pdf" rel="noopener ugc nofollow" target="_blank">最终版本</a>的 PDF。Jupyter 的默认 PDF 输出有一个体面的外观，但它可以通过几分钟的编辑得到显著改善。此外，Latex 是一个强大的文档准备系统，了解基础知识很有好处。</p><p id="1058" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">一天结束时，我们的工作的价值取决于它所促成的决策，而能够展示结果是一项至关重要的技能。此外，通过正确记录工作，我们允许其他人复制我们的结果，给我们反馈，以便我们可以成为更好的数据科学家，并为未来建立我们的工作。</p><h1 id="bbbb" class="lu lv jb bd lw lx ly lz ma mb mc md me kh mf ki mg kk mh kl mi kn mj ko mk ml bi translated">结论</h1><p id="8502" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">在这一系列的帖子中，我们已经走过了一个完整的端到端机器学习项目。我们从清理数据开始，进入模型构建，最后看如何解释机器学习模型。提醒一下，机器学习项目的一般结构如下:</p><ol class=""><li id="38dd" class="mr ms jb ks b kt ku kw kx kz mt ld mu lh mv ll mw mx my mz bi translated">数据清理和格式化</li><li id="842f" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll mw mx my mz bi translated">探索性数据分析</li><li id="27f8" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll mw mx my mz bi translated">特征工程和选择</li><li id="3687" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll mw mx my mz bi translated">在性能指标上比较几种机器学习模型</li><li id="dcb2" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll mw mx my mz bi translated">对最佳模型执行超参数调整</li><li id="4e45" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll mw mx my mz bi translated">评估测试集上的最佳模型</li><li id="1ca1" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll mw mx my mz bi translated">尽可能解释模型结果</li><li id="74cc" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll mw mx my mz bi translated">得出结论，写一份证据充分的报告</li></ol><p id="de65" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">虽然具体步骤因项目而异，并且机器学习通常是一个<a class="ae lm" href="https://en.wikipedia.org/wiki/Iteration" rel="noopener ugc nofollow" target="_blank">迭代而不是线性过程</a>，但本指南应该在您处理未来的机器学习项目时很好地为您服务。我希望这个系列已经给了你信心，让你能够实现你自己的机器学习解决方案，但是记住，<strong class="ks jc">我们没有一个人自己做到这一点</strong>！如果你需要任何帮助，有许多令人难以置信的支持社区，你可以在那里寻求建议。</p><p id="f80e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在我的学习过程中，我发现了一些有用的资源:</p><ul class=""><li id="c100" class="mr ms jb ks b kt ku kw kx kz mt ld mu lh mv ll oz mx my mz bi translated"><a class="ae lm" href="http://shop.oreilly.com/product/0636920052289.do" rel="noopener ugc nofollow" target="_blank">用 Scikit-Learn 和 Tensorflow 进行动手机器学习</a> ( <a class="ae lm" href="https://github.com/ageron/handson-ml" rel="noopener ugc nofollow" target="_blank">这本书的 Jupyter 笔记本</a>在线免费提供)！</li><li id="a75f" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll oz mx my mz bi translated"><a class="ae lm" href="http://www-bcf.usc.edu/~gareth/ISL/" rel="noopener ugc nofollow" target="_blank">统计学习入门</a></li><li id="0c7c" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll oz mx my mz bi translated"><a class="ae lm" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle:数据科学和机器学习之家</a></li><li id="93a9" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll oz mx my mz bi translated"><a class="ae lm" href="https://www.datacamp.com/" rel="noopener ugc nofollow" target="_blank"> Datacamp </a>:练习数据科学编码的入门教程</li><li id="67ff" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll oz mx my mz bi translated">Coursera :许多学科的免费和付费课程</li><li id="98c3" class="mr ms jb ks b kt na kw nb kz nc ld nd lh ne ll oz mx my mz bi translated"><a class="ae lm" href="https://www.udacity.com/" rel="noopener ugc nofollow" target="_blank"> Udacity </a>:付费编程和数据科学课程</li></ul><p id="ac26" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">一如既往，我欢迎反馈和讨论，可以通过 Twitter <a class="ae lm" href="https://twitter.com/koehrsen_will" rel="noopener ugc nofollow" target="_blank"> @koehrsen_will </a>联系。</p></div></div>    
</body>
</html>