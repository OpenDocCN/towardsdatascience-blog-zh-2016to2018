<html>
<head>
<title>Just another AI trying to predict the stock market: Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">只是另一个试图预测股市的人工智能:第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/just-another-ai-trying-to-predict-the-stock-market-part-2-88605f9d8e45?source=collection_archive---------3-----------------------#2018-02-11">https://towardsdatascience.com/just-another-ai-trying-to-predict-the-stock-market-part-2-88605f9d8e45?source=collection_archive---------3-----------------------#2018-02-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/9276ed13ddfd3e6b33005de5877ea239.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oIaHz-b7xdHutGGgvK_aRw.png"/></div></div></figure><div class=""/><p id="3bfc" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在本节中，我将向您展示如何使用来自<a class="ae kw" rel="noopener" target="_blank" href="/just-another-ai-trying-to-predict-the-stock-market-part-1-d0663673a30e">第1部分</a>的数据训练模型。我们挑选了一份过去50年中每天的标准普尔500指数价格清单，并对其做了一些修改。<strong class="ka jc">现在我们要训练我们的模型</strong>，让它尽可能准确地预测未来价格。</p><p id="1b7f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在上一部分中，我们使用<code class="fe kx ky kz la b">load_data</code>函数和定义为<code class="fe kx ky kz la b">df_stock</code>矩阵的价格值将数据分为训练/验证/测试。它是按如下方式完成的:</p><p id="88bd" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><code class="fe kx ky kz la b">x_train, y_train, x_valid, y_valid, x_test, y_test = load_data(df_stock, seq_len)</code>在哪里<code class="fe kx ky kz la b">seq_len = 20</code>。如果你从<a class="ae kw" rel="noopener" target="_blank" href="/just-another-ai-trying-to-predict-the-stock-market-part-1-d0663673a30e">我的上一篇文章</a>中考察<code class="fe kx ky kz la b">load_data</code>的实现，你会对<code class="fe kx ky kz la b">seq_len</code>有更好的理解。基本上，它将数据分成更大的20个元素的块。</p><h2 id="3ecc" class="lb lc jb bd ld le lf dn lg lh li dp lj kj lk ll lm kn ln lo lp kr lq lr ls lt bi translated">#1.定义超参数</h2><p id="d7b9" class="pw-post-body-paragraph jy jz jb ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">当建立机器学习模型时，需要定义一组直接反映模型性能的参数。当你自己做的时候，你可能会发现自己花了太多的时间在调整正确的组合和评估基于你的选择的模型上。在本例中，我们将浏览预定义的，但可以随意更改它们并进行实验。</p><figure class="lz ma mb mc gt is"><div class="bz fp l di"><div class="md me l"/></div></figure><ul class=""><li id="6b28" class="mf mg jb ka b kb kc kf kg kj mh kn mi kr mj kv mk ml mm mn bi translated"><code class="fe kx ky kz la b">n_steps = seq_len-1</code>:输入(训练)数据的第一维度。</li><li id="3215" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated"><code class="fe kx ky kz la b">n_inputs = 4</code>:输入(训练)数据的第二维——不同种类的价格(“开盘价”、“收盘价”、“最高价”、“最低价”)。</li><li id="5e2d" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated"><code class="fe kx ky kz la b">n_neurons = 200</code>:用于表示我们GRU单元格中隐藏状态的维度。使用隐藏层的数量和输入数据的大小来确定维度。想了解更多信息，我推荐参考这个Quora回答。</li><li id="0017" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated"><code class="fe kx ky kz la b">n_outputs = 4</code>:神经网络输出层的维度。</li><li id="980d" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated"><code class="fe kx ky kz la b">n_layers = 2</code>:我们希望我们的网络由多少个GRU细胞组成。</li><li id="97dd" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated"><code class="fe kx ky kz la b">learning_rate = 0.001</code>:当我们使用梯度下降(或另一个优化器)来最小化损失函数以校正权重和偏差时，使用该比率。</li><li id="dfed" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated">通常，在训练时，一次使用全部数据是低效的。这就是为什么我们迭代一组长度为50的批处理。</li><li id="ddaf" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated"><code class="fe kx ky kz la b">n_epochs = 100</code>:帮助确定训练迭代的次数，每个迭代使用不同的批次。</li><li id="8cff" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated"><code class="fe kx ky kz la b">train_set_size = x_train.shape[0]</code>:也有助于确定训练迭代的次数。</li></ul><h2 id="94eb" class="lb lc jb bd ld le lf dn lg lh li dp lj kj lk ll lm kn ln lo lp kr lq lr ls lt bi translated">#2.设置图表</h2><p id="6aad" class="pw-post-body-paragraph jy jz jb ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">我们的下一步是使用上面的一些参数来建立训练图。但这意味着什么呢？术语“图形”来自张量流的构造方式。基本上，用Tensorflow建立模型时，首先需要建立架构(图)，然后使用适当的训练数据运行它。</p><p id="68a5" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">首先是GRU层:</p><figure class="lz ma mb mc gt is"><div class="bz fp l di"><div class="md me l"/></div></figure><ul class=""><li id="b3cc" class="mf mg jb ka b kb kc kf kg kj mh kn mi kr mj kv mk ml mm mn bi translated">第1行:重置图形堆栈，为新的初始化做准备。</li><li id="f97f" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated">第3–4行:初始化输入和输出的张量流占位符。</li><li id="6613" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated">第6行:使用张量流GRU单元格，我们将几个单元格(基于n_layers参数)组合成一个列表。GRU单元用<code class="fe kx ky kz la b">num_units</code>和激活函数初始化，在这种情况下激活函数是<code class="fe kx ky kz la b">leaky_relu</code>。如上所述,<code class="fe kx ky kz la b">num_units</code>是隐藏状态的维度。<a class="ae kw" rel="noopener" target="_blank" href="/activation-functions-neural-networks-1cbd9f8d91d6">激活功能</a>应用于结果值。</li><li id="06f2" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated">第8–9行:将GRU细胞堆叠成一个<code class="fe kx ky kz la b">multi_layer_cell</code>并运行<a class="ae kw" href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn" rel="noopener ugc nofollow" target="_blank"> tf.nn.dynamic_rnn </a>来使用输入数据x创建递归神经网络</li><li id="5fdc" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated">第11行:重塑网络输出。</li></ul><p id="98bc" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们需要添加输出层并设置损失函数:</p><figure class="lz ma mb mc gt is"><div class="bz fp l di"><div class="md me l"/></div></figure><p id="883f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用<code class="fe kx ky kz la b">tf.layers.dense</code>添加最后一层，该层在对(输入*权重+偏差)应用激活函数后返回输出。</p><p id="435d" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您可以从第7–9行看到优化器是如何使用学习率初始化的(我们使用AdamOptimizer而不是梯度下降)。然后，我们只需最小化损失函数，在这种情况下，就是均方误差。</p><p id="16bc" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你觉得有点困惑，把上面的方程看成一个黑盒，我会推荐你略读我之前关于<a class="ae kw" rel="noopener" target="_blank" href="/learn-how-recurrent-neural-networks-work-84e975feaaf7">递归神经网络</a>的文章。如果你还有任何问题，就在评论区留下，我会跳出来讨论。</p><h2 id="6a15" class="lb lc jb bd ld le lf dn lg lh li dp lj kj lk ll lm kn ln lo lp kr lq lr ls lt bi translated">#3.开始训练</h2><p id="89da" class="pw-post-body-paragraph jy jz jb ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">现在最有趣的部分来了——训练模型。一般来说，如果你想得到一组可以做出准确预测的权重和偏差，你至少需要等几个小时。训练的速度取决于上面定义的超参数。</p><p id="61b0" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">首先，我们将定义一个简单的函数<code class="fe kx ky kz la b">get_next_batch</code>，它将使用训练数据生成一批给定大小的数据:</p><figure class="lz ma mb mc gt is"><div class="bz fp l di"><div class="md me l"/></div></figure><ul class=""><li id="3e21" class="mf mg jb ka b kb kc kf kg kj mh kn mi kr mj kv mk ml mm mn bi translated">第1–3行:从每批数据集中定义初始索引，并用0到<code class="fe kx ky kz la b">x_train.shape[0]-1</code>的值填充一个排列数组。</li><li id="aa59" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated">第6行:在已经声明的变量前使用python关键字<code class="fe kx ky kz la b">global</code>将允许我们从函数内部修改以反映全局范围。</li><li id="fec3" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated">最后，我们从<code class="fe kx ky kz la b">x_train</code>和<code class="fe kx ky kz la b">y_train</code>返回大小为<code class="fe kx ky kz la b">batch_size</code>的集合。</li></ul><p id="9e9b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在让我们运行图表来训练模型:</p><figure class="lz ma mb mc gt is"><div class="bz fp l di"><div class="md me l"/></div></figure><ul class=""><li id="6870" class="mf mg jb ka b kb kc kf kg kj mh kn mi kr mj kv mk ml mm mn bi translated">第1行:我们使用Tensorflow会话，它用于运行Tensorflow操作。</li><li id="3efe" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated">第2行:用<code class="fe kx ky kz la b">tf.global_variables_initializer()</code>我们初始化任何被声明的Tensorflow变量。在我们的例子中，我们没有任何。</li><li id="71e1" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated">第3–11行:我们通过多次迭代来训练模型——通过运行<code class="fe kx ky kz la b">training_op</code>,我们最小化了损失函数。第8-11行用于通知我们关于out培训的进度。</li><li id="c116" class="mf mg jb ka b kb mo kf mp kj mq kn mr kr ms kv mk ml mm mn bi translated">第13、14、15行:我们根据优化器模型计算输出。在第3部分，我们将比较<code class="fe kx ky kz la b">y_valid_pred</code>和<code class="fe kx ky kz la b">y_valid</code>以及<code class="fe kx ky kz la b">y_test_pred</code>和<code class="fe kx ky kz la b">y_test</code>，看看我们的模型表现如何。</li></ul><h2 id="9fa1" class="lb lc jb bd ld le lf dn lg lh li dp lj kj lk ll lm kn ln lo lp kr lq lr ls lt bi translated">在下一部分</h2><p id="ad83" class="pw-post-body-paragraph jy jz jb ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">通过以上培训，我们完成了系列的第2部分。在<a class="ae kw" href="https://medium.com/p/ee2d419e00c3/edit" rel="noopener">的最后一部分</a>，我们将使用我们的模型进行预测，看看我们是否能够破解股票市场😄。</p><h2 id="e601" class="lb lc jb bd ld le lf dn lg lh li dp lj kj lk ll lm kn ln lo lp kr lq lr ls lt bi translated">谢谢你的阅读。如果你喜欢这篇文章，给它一些掌声👏。希望你有一个伟大的一天！</h2></div></div>    
</body>
</html>