<html>
<head>
<title>Calculus in Data Science and it uses</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学中的微积分及其应用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/calculus-in-data-science-and-its-uses-3f3e1b5e5b35?source=collection_archive---------2-----------------------#2018-08-30">https://towardsdatascience.com/calculus-in-data-science-and-its-uses-3f3e1b5e5b35?source=collection_archive---------2-----------------------#2018-08-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/37cb797f18d12ba0cb5eb083ae5dbc4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JkbpPde-Pxo0GLIZhnka4Q.png"/></div></div></figure><blockquote class="jy"><p id="8849" class="jz ka iq bd kb kc kd ke kf kg kh ki dk translated">微积分是一种以纯粹形式发展起来的抽象理论。</p></blockquote><p id="628c" class="pw-post-body-paragraph kj kk iq kl b km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ki ij bi lg translated">微积分，更确切地说是分析，是数学的一个分支，研究数量的变化率(可以解释为曲线的斜率)以及物体的长度、面积和体积。微积分分为微分和积分。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/af1d146b8cbe370b58fb88de097b5dc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:158/format:webp/1*-ZBIjoNU9JkaOvmroKqasg.png"/></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Differentiation</figcaption></figure><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/7d5398b86f12987926d5f2db3a2edb70.png" data-original-src="https://miro.medium.com/v2/resize:fit:244/format:webp/1*q4hy78bqeQ8MxFhxsf5tAw.png"/></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Integration</figcaption></figure></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><blockquote class="mg mh mi"><p id="fe5d" class="kj kk mj kl b km mk ko kp kq ml ks kt mm mn kw kx mo mp la lb mq mr le lf ki ij bi translated">微积分这个词来源于拉丁语，意思是“小石头”，<br/>因为它就像通过观察小碎片来理解事物一样。</p></blockquote><p id="8e3d" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">微积分是数学的一个固有领域，尤其是在许多机器学习算法中，你不可能想到跳过这门课程来学习数据科学的本质。</p><p id="6ef7" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated"><strong class="kl ir">微分学</strong>把东西切成小块，看看它是怎么变化的。</p><p id="bb65" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated"><strong class="kl ir">积分学</strong>把小块连在一起(积分)算出有多少。</p><p id="0ce3" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">现在，我再次强烈推荐您观看来自<a class="ae ms" href="https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw" rel="noopener ugc nofollow" target="_blank"> 3blue1brown 频道</a>的《微积分精粹》视频，该视频教授数据科学中所需的一些微积分重要支柱。</p><figure class="lx ly lz ma gt jr"><div class="bz fp l di"><div class="mt mu l"/></div></figure></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><p id="406f" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">如果你有任何一种过敏或者没有通过视频学习的心情，可以参考这个。它涵盖了微积分的所有基本思想。</p><div class="mv mw gp gr mx my"><a href="https://www.mathsisfun.com/calculus/" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd ir gy z fp nd fr fs ne fu fw ip bi translated">微积分菜单</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">微积分这个词来源于拉丁语，意思是“小石头”，因为它就像通过看东西来理解一样…</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">www.mathsisfun.com</p></div></div><div class="nh l"><div class="ni l nj nk nl nh nm jw my"/></div></div></a></div><p id="f1bd" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">我希望你已经理解了微分和积分的基础知识。数据科学家几乎对每个模型都使用微积分，机器学习中微积分的一个基本但非常优秀的例子是梯度下降。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h1 id="e00f" class="nn no iq bd np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh oi oj ok bi translated">梯度下降</h1><blockquote class="jy"><p id="1b0d" class="jz ka iq bd kb kc ol om on oo op ki dk translated">梯度衡量的是，如果你稍微改变输入，函数的输出会有多大的变化。</p></blockquote><p id="c56e" class="pw-post-body-paragraph kj kk iq kl b km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf ki ij bi translated">假设你有一个球和一个碗。无论你把球滑到碗里的什么地方，它最终都会落在碗底。</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/25378805854751c28536bc31872b54d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*65qXglPZsXqrKrLIuO31Tg.gif"/></div></figure><p id="a2d3" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">正如你看到的，这个球沿着一条路径，在碗的底部结束。我们也可以说球在碗的底部下降。正如你从图像中看到的，红线是碗的坡度，蓝线是球的路径，随着球的坡度的减小，这被称为梯度下降。</p><p id="e631" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">在我们的机器学习模型中，我们的目标是降低输入数据的成本。成本函数用于监控 ML 模型预测中的误差。因此，最小化这一点，基本上意味着尽可能获得最低的误差值，或者提高模型的精度。简而言之，我们在调整模型参数(权重和偏差)的同时，通过迭代训练数据集来提高精确度。</p><p id="ad28" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">让我们考虑一下，我们有一个用户的数据集，包括他们在某些科目上的分数和他们的职业。我们的目标是通过考虑一个人的分数来预测这个人的职业。</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi or"><img src="../Images/2db72a3fb1096ee4f1f6256bcc20cbd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lb4V03ybasjGwB1UEtjMfQ.png"/></div></div></figure><p id="66f3" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">在这个数据集中，我们有约翰和夏娃的数据。有了约翰和夏娃的参考数据，我们不得不预测亚当的职业。</p><p id="838a" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">现在把学科里的分数想成一个梯度，把专业想成底层目标。你必须优化你的模型，以便它在底部预测的结果应该是准确的。使用 john 和 Eve 的数据，我们将创建梯度下降并调整我们的模型，这样，如果我们输入 John 的分数，那么它应该预测梯度底部的医生的结果，Eve 也是如此。这是我们训练过的模型。现在，如果我们给模型的主题打分，那么我们就可以很容易地预测这个职业。</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div class="gh gi os"><img src="../Images/f0f0280beedfe8f9fbdc80c9f6388935.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/1*JY0Hxv4TG6S6ZQYET07Znw.gif"/></div></figure><p id="177c" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">理论上这是梯度下降，但计算和建模，梯度下降需要微积分，现在我们可以看到微积分在机器学习中的重要性。</p><p id="fac8" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">首先让我们从你现在知道的话题开始。线性代数。让我们首先使用线性代数和它的公式为我们的模型。</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ot"><img src="../Images/2ca2a5ecd35026b787b7eba3e5ea2e6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*34dYVwi1ieVQBtwKd4xReg.gif"/></div></div></figure><p id="4a98" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">我们可以在这个模型中使用的基本公式是</p><p id="9e85" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">y = m*x +b</p><p id="eabe" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">在哪里，</p><p id="b41d" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">y =预测值，m =斜率，x =输入，b = y-截距。</p><p id="c79e" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">解决这类问题的标准方法是定义一个误差函数(也称为成本函数),用于衡量给定线的“好”程度。该函数将接受一个<code class="fe ou ov ow ox b">(m,b)</code>对，并根据直线与数据的吻合程度返回一个错误值。为了计算给定线的误差，我们将遍历数据集中的每个<code class="fe ou ov ow ox b">(x,y)</code>点，并对每个点的<code class="fe ou ov ow ox b">y</code>值和候选线的<code class="fe ou ov ow ox b">y</code>值(在<code class="fe ou ov ow ox b">mx + b</code>计算)之间的平方距离求和。传统的做法是平方这个距离，以确保它是积极的，并使我们的误差函数可微。</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/993528a7d9af9f10713b243312edd64d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*AQKoBlrYPA6kjvW8XomKUQ.png"/></div></figure><p id="d3f8" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">更适合我们的数据的线(其中更好是由我们的误差函数定义的)将产生更低的误差值。如果我们最小化这个函数，我们将得到数据的最佳线。由于我们的误差函数由两个参数(<code class="fe ou ov ow ox b">m</code>和<code class="fe ou ov ow ox b">b</code>)组成，我们可以将其视为一个二维表面。这是我们数据集的样子:</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oz"><img src="../Images/f92aa8271411ada94af42b11b0725e17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*wsBakfF2Geh1zgY4HJbwFQ.gif"/></div></div></figure><p id="9b3e" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">这个二维空间中的每个点代表一条线。函数在每一点的高度就是那条线的误差值。您可以看到，有些线产生的误差值比其他线小(例如，更符合我们的数据)。当我们运行梯度下降搜索时，我们将从这个表面上的某个位置开始，向下移动以找到误差最小的线。</p><p id="348a" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">在微积分的本质视频中，你已经看到，为了计算斜率，我们使用微分。</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/bdd593b0f5d9784698c12f73206b1ec7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*ZU4n4BDVVEXM3OKKqOmeDA.png"/></div><figcaption class="mb mc gj gh gi md me bd b be z dk">The graph of a function z=f(x,y)z=f(x,y) is a surface, and fixing y=by=b gives a curve (shown in green). The partial derivative ∂f∂x(a,b)∂f∂x(a,b) is the slope of the tangent line to this curve at the point where x=ax=a.</figcaption></figure><p id="80e4" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">为了对这个误差函数进行梯度下降，我们首先需要计算它的梯度。坡度就像指南针一样，总是指引我们下坡。为了计算它，我们需要对误差函数求导。由于我们的函数是由两个参数定义的(<code class="fe ou ov ow ox b">m</code>和<code class="fe ou ov ow ox b">b</code>)，我们需要计算每个参数的偏导数。这些衍生工具的结果是:</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/19577e56d3b84e1e2d9290eaf131c6e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*3YJx2rdqMW5ccRJZFH9v6w.png"/></div></figure><p id="b17a" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">我们现在有了运行梯度下降所需的所有工具。我们可以初始化我们的搜索，从任何一对<code class="fe ou ov ow ox b">m</code>和<code class="fe ou ov ow ox b">b</code>值(即任何一条线)开始，让梯度下降算法在我们的误差函数上朝着最佳线向下行进。每一次迭代都会将<code class="fe ou ov ow ox b">m</code>和<code class="fe ou ov ow ox b">b</code>更新为一条线，该线产生的误差比前一次迭代稍低。使用上面的两个偏导数计算每次迭代的移动方向。</p><p id="4aaa" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated"><strong class="kl ir">学习速率</strong>变量控制着我们在每次迭代中走下坡路的幅度。如果我们迈得太大，我们可能会跳过最小值。然而，如果我们采取小步骤，将需要多次迭代才能达到最小值。</p><p id="473b" class="pw-post-body-paragraph kj kk iq kl b km mk ko kp kq ml ks kt ku mn kw kx ky mp la lb lc mr le lf ki ij bi translated">虽然我们能够对学习梯度下降有所了解，但还有几个我们无法讨论的额外概念值得注意。其中一些包括:</p><ul class=""><li id="d45d" class="pc pd iq kl b km mk kq ml ku pe ky pf lc pg ki ph pi pj pk bi translated"><strong class="kl ir">凸性</strong>–在我们的线性回归问题中，只有一个最小值。我们的误差表面是凸起的。不管我们从哪里开始，我们最终都会达到绝对最小值。一般来说，情况不必如此。梯度搜索可能会陷入局部极小值。有几种方法可以减轻这种情况(例如，<a class="ae ms" href="http://en.wikipedia.org/wiki/Stochastic_gradient_descent" rel="noopener ugc nofollow" target="_blank">随机梯度搜索</a>)。</li></ul><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/0528365bdf3aeeff2fe252fdc6a089b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/1*ijPaGcQl41psa0EdNhveSg.gif"/></div></figure><ul class=""><li id="be98" class="pc pd iq kl b km mk kq ml ku pe ky pf lc pg ki ph pi pj pk bi translated"><strong class="kl ir">收敛</strong>–我们没有讨论如何确定搜索何时找到解决方案。这通常是通过寻找迭代间误差的微小变化来实现的(例如，梯度接近零的地方)。</li></ul><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/27f47a93433b6c683e51cc3609a5eecd.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/1*e88JKNWAFok3vpjeuPfHig.gif"/></div></figure><h1 id="7166" class="nn no iq bd np nq pn ns nt nu po nw nx ny pp oa ob oc pq oe of og pr oi oj ok bi translated">多元微积分</h1><p id="2a8e" class="pw-post-body-paragraph kj kk iq kl b km ps ko kp kq pt ks kt ku pu kw kx ky pv la lb lc pw le lf ki ij bi translated">现在让我们深入学习多变量微积分，这将在多变量数据中教授微积分，我们最终会在现实生活中得到这些数据。</p><div class="mv mw gp gr mx my"><a href="https://www.khanacademy.org/math/multivariable-calculus" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd ir gy z fp nd fr fs ne fu fw ip bi translated">多变量微积分|可汗学院</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">免费学习数学、艺术、计算机编程、经济学、物理学、化学、生物学、医学、金融…</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">www.khanacademy.org</p></div></div><div class="nh l"><div class="px l nj nk nl nh nm jw my"/></div></div></a></div></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><blockquote class="mg mh mi"><p id="f7f3" class="kj kk mj kl b km mk ko kp kq ml ks kt mm mn kw kx mo mp la lb mq mr le lf ki ij bi translated">要获得最新的更新、提示和任何你想要的或有问题的东西，只需在评论中发表。</p></blockquote><h2 id="92ba" class="py no iq bd np pz qa dn nt qb qc dp nx ku qd qe ob ky qf qg of lc qh qi oj qj bi translated">在那之前…</h2><h2 id="f992" class="py no iq bd np pz qa dn nt qb qc dp nx ku qd qe ob ky qf qg of lc qh qi oj qj bi translated">快乐编码:)</h2><p id="f66d" class="pw-post-body-paragraph kj kk iq kl b km ps ko kp kq pt ks kt ku pu kw kx ky pv la lb lc pw le lf ki ij bi translated">别忘了拍手拍手拍手…</p><figure class="lx ly lz ma gt jr gh gi paragraph-image"><div class="gh gi qk"><img src="../Images/45d7a04242aa09029aeae2d4ef0089eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/1*Folcnfv8OEG6GD2-YKhcEg.gif"/></div></figure></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h1 id="50b8" class="nn no iq bd np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og oh oi oj ok bi translated">参考</h1><div class="mv mw gp gr mx my"><a href="https://www.khanacademy.org/math/multivariable-calculus" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd ir gy z fp nd fr fs ne fu fw ip bi translated">多变量微积分|可汗学院</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">免费学习数学、艺术、计算机编程、经济学、物理学、化学、生物学、医学、金融…</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">www.khanacademy.org</p></div></div><div class="nh l"><div class="ql l nj nk nl nh nm jw my"/></div></div></a></div><div class="mv mw gp gr mx my"><a href="https://en.wikipedia.org/wiki/Calculus" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd ir gy z fp nd fr fs ne fu fw ip bi translated">微积分-维基百科</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">它有两个主要分支，微分学(关于瞬时变化率和曲线斜率)，和…</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">en.wikipedia.org</p></div></div><div class="nh l"><div class="qm l nj nk nl nh nm jw my"/></div></div></a></div><div class="mv mw gp gr mx my"><a href="https://brilliant.org/calculus/" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd ir gy z fp nd fr fs ne fu fw ip bi translated">练习微积分|太棒了</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">采取有指导的、基于解决问题的方法来学习微积分。这些汇编提供了独特的视角和…</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">brilliant.org</p></div></div></div></a></div></div></div>    
</body>
</html>