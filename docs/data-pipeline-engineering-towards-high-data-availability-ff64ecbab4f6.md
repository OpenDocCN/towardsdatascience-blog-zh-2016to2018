# 面向高数据可用性的数据管道工程

> 原文：<https://towardsdatascience.com/data-pipeline-engineering-towards-high-data-availability-ff64ecbab4f6?source=collection_archive---------10----------------------->

![](img/913ecda9c86079a61df5e65c6af3ea94.png)

从数据中提取见解并做出预测是我的主要目标，然而，在我从数据中获取价值之前，我首先需要从数据仓库中获取数据。通常我需要的数据并不容易获得，也没有工程师有资源来支持我，因此我沉浸在数据仓库的荒野中来建立我自己的数据管道，这也被称为 ETL(提取、转换和加载)。

真正的数据科学工作很难在必要的数据可用之前开始，因此建立数据管道以有效地提供可供分析的数据具有重要意义。根据我在工作中构建和使用数据管道的经验，我看到了支撑管道效率的三个要素，它们随后创建了一个高数据可用性的环境。

# 1.由分析单元定义的数据管道

有一天，我收到一个紧急数据请求。在听到请求细节之前，我不确定这种紧迫性是否会暂停我的其他项目。在我了解到这一需求后，我知道现有的数据管道可以满足大部分需求。我所需要的只是找到一些额外的数据元素。果然，我很快解决了这个请求。这一经历是好的数据管道带给我的众多好处之一。一个好的数据管道可能会在我的新项目到达时完成 80%，让我专注于剩下的 20%。既节省时间又让人安心(当然这里的 80%和 20%只是想象中的尺度)。

运气并不总是在身边。在一个项目中，我不得不构建一个很长的数据管道，通过从多个来源提取大量原始数据，将业务运营的全局但详细的视图放在一起。这个项目花了我很长时间才完成。即使完工，这条管道的一次通过也需要 20 多个小时。通常，我会启动管道，并在第二天收集结果。后来，我发现我们的数据工程团队已经建立了一个类似的数据管道。我决定利用他们的来缩短我的。现在，我的管道只需不到 6 个小时。在一个管道上铺设另一个管道对我来说非常有效。除了节省时间之外，还节省了大量的计算、存储和维护。

数据管道显然会带来价值。那么，如何打造有价值的数据管道呢？我认为，当管道将独立的信息汇集在一起，创建一个高度感兴趣的分析单元的丰富图片时，它往往是有价值的。例如，在信用卡支付业务中，交易是一个非常有趣的分析单元，因此一个好的数据管道是创建每个交易的端到端生命周期图的管道。使用这个管道，用户可以很容易地找到想要的细节，无论他们对交易授权还是交易争议感兴趣。在医疗保健中，患者是一个高度感兴趣的分析单位，因此一个良好的数据管道是一个包含每个患者的整个医疗保健旅程的管道，包括诊断、治疗、保险范围和再入院。人们以后可以很容易地放大到整个医疗保健过程中的一个特定部分。考虑到原始数据是如此孤立、混乱和庞大，这种方法减轻了数据科学家的负担，并使数据更容易用于分析和建模。

# 2.晚上睡觉时在管道中处理数据

当我的数据管道持续很多小时时，我遇到了“意大利面条”式的管理挑战。我无法断开我的笔记本电脑与互联网的连接，我运行的管道分散了我对其他工作的注意力，我忘记了我已经完成了哪些步骤。因此，我想让我的管道在服务器集群中运行，这样我就可以忘记它们，让我的笔记本电脑离线回家。Apache Oozie 是我发现的帮助我在 Hadoop 集群中管理管道的工具。

Oozie 采用了我的脚本和工作流设计，然后根据集群中的工作流执行我的脚本。Oozie 是 Apache 开源工具，详情请访问[http://oozie.apache.org/](http://oozie.apache.org/)。后来，我想安排我完成的管道，向我的管道添加通知并参数化我的管道，Oozie 也能够帮助满足这些需求。Oozie 几乎成了我的生产基地。使用 Oozie 让我相信，工作流管理工具(现成的或内部构建的)是数据工程师和数据科学家的必备工具，尤其是在大型项目中。除了 Oozie 之外，Airflow 是另一个非常流行的工作流管理工具，在许多公司中经常使用。

我的数据管道是 Hive、Impala、Python 和 Spark 的混合体。大多数是在蜂巢和黑斑羚。Oozie 能够促进所有这些批处理，并根据工作流规范运行它们。日志和错误会自动保存，并可用于调试和跟踪目的。当数据管道得到管理时，我可以更快、更容易地获得数据。我可以“一边睡觉一边啃大数据”。

# 3.挤压管道的一百种方法

![](img/c27adb133340d1ab47474a76a6fc537a.png)

数据管道工作似乎有一个缓慢的时钟。根据我的经验，一遍数据管道需要几个小时(数据大小以 TBs 为单位)。为了从数小时的流水线工作中挤出额外的效率，我们必须使用许多优化技术。在我的 Hive、Impala 和 Spark 管道中，我使用了一系列个人最喜欢的优化技巧，尽管可能有上百种技巧。

首先，我使用试错法来确定查询复杂性中的最佳点。复杂的查询对分布式文件系统来说是一个挑战，因此我试图避免不必要的复杂性。然而，将复杂的查询分解成较小的查询可能会导致太多的小步骤。通过反复试验，我可以找到一个既快速又易于维护的最佳点。第二，我努力更新元数据统计数据，并选择正确的连接来最小化文件移动。例如，由于系统内部工作方式的不同，当涉及到连接表排序时，我确保大表在 Hive 中排在后面，但是在 Impala 中最大的表排在前面。这样的安排让小桌子搬到大桌子，而不是相反。第三，我操纵设置来动态地将资源分配到需要的地方。在一个 Spark 步骤中，尽管集群中的内存和内核使用率较低，但我看到了缓慢的性能，我增加了该步骤的内存设置和内核设置，并很快完成了 Spark 任务。

好的优化技巧的列表非常长。当我需要额外的效率时，我会参考技术手册。这些技巧的使用还取决于集群环境和情况。一个单独的戏法在它能做的事情上是有限的，然而，将许多戏法结合在一起肯定会很有意义。

在学习环境中，我们被提供数据来建立模型和进行分析。在数据可用性的另一方面，我们必须自己搜索数据、获取数据和清理数据。我发现后一种情况更现实，因此我渴望磨练我的数据工程技能，并希望与感兴趣的读者分享我的数据管道经验。除了上面提到的技术性更强的因素，项目规划、进度文档等软性因素对数据管道的成功也有重要影响。我个人认为，每个数据科学家都部分是数据工程师，我们都应该不仅为创建模型对象而自豪，而且为创建数据管道而自豪。