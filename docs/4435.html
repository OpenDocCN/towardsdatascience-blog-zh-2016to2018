<html>
<head>
<title>How to optimize Hyperparameters of Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何优化机器学习模型的超参数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-optimize-hyperparameters-of-machine-learning-models-98baec703593?source=collection_archive---------9-----------------------#2018-08-15">https://towardsdatascience.com/how-to-optimize-hyperparameters-of-machine-learning-models-98baec703593?source=collection_archive---------9-----------------------#2018-08-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/a4bd2aed0da8f7c0451697514da17ac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qPrUhDHaxV3m7DkY"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Photo by <a class="ae jd" href="https://unsplash.com/@toddquackenbush?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Todd Quackenbush</a> on <a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><div class=""/><p id="2d1a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">寻找超参数的最佳组合是许多机器学习应用的核心。在这篇文章中，我将给你一个简要的概述和三个主要方法的示例。</p><p id="91b9" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我最近的一个项目中，我发现自己处于一个太熟悉的情况。我获得了一组漂亮的数据。我完成了数据清理和特征工程的第一次迭代。最后，我准备好释放我们作为数据科学家向世界承诺的所有潜力。经过几次初步实验后，我们选定了梯度推进算法。但是，如何找到超参数的最佳配置呢？这就是这篇博文的内容。</p><p id="4e02" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我将带你看一个基本的例子，并对它应用三种不同的方法。我的目标是为你提供一个坚实的直觉，作为进一步调查的基础。如果你想做一些自己的实验，或者如果你需要一个地方开始你的优化之旅，所有的细节和必要的代码都可以作为一个<a class="ae jd" href="https://github.com/timo-boehm/material_blog_posts" rel="noopener ugc nofollow" target="_blank"> Jupyter 笔记本</a>获得。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="28d6" class="li lj jg bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">如何预测成功的众筹项目？</h1><p id="a1ad" class="pw-post-body-paragraph kd ke jg kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">我的一个朋友正在准备一个 Kickstarter 活动，所以我决定用这个地区作为这篇文章的例子。多亏了<a class="ae jd" href="https://www.kaggle.com/kemical" rel="noopener ugc nofollow" target="_blank">米卡埃尔·穆莱</a>，在<a class="ae jd" href="https://www.kaggle.com/kemical/kickstarter-projects" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上有一个精彩的数据集。我抽样了 1000 个项目，其中大约 36%是成功的。我的目标是根据以下信息预测活动是否成功:</p><ul class=""><li id="5800" class="ml mm jg kf b kg kh kk kl ko mn ks mo kw mp la mq mr ms mt bi translated">项目的类别(一般和更具体)，例如“电影”或“书籍”。</li><li id="2607" class="ml mm jg kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated">项目来源国(美国占 77%)。</li><li id="8361" class="ml mm jg kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated">以美元为单位的筹资目标。幸运的是，这个转换已经包含在数据集中了。</li></ul><p id="2acd" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我将类别和国家转换成虚拟变量，所以最终大约有 200 个可用的特性。</p><blockquote class="mz na nb"><p id="408a" class="kd ke nc kf b kg kh ki kj kk kl km kn nd kp kq kr ne kt ku kv nf kx ky kz la ij bi translated"><strong class="kf jh">免责声明 1: </strong>我说明性地使用数据，而不是你在实际应用中应该如何处理它。对于这个帖子，我采用了数据，并将其视为干净可靠的。我也没有任何特征工程等。</p></blockquote><p id="e58c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">和项目类似，我用的是梯度提升算法(这里是 sklearn 的<a class="ae jd" href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html" rel="noopener ugc nofollow" target="_blank">gradientboostingclassifier</a>)。这组算法有许多超参数，但我专注于其中的两个以保持简洁明了:学习速率和特征的数量。</p><p id="e485" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">学习率调整算法更新的速度。如果太高，算法会快速跳转，可能会错过最佳解决方案。如果太低，算法可能需要很长时间才能最终稳定下来。诚然，这是一个粗略的总结，但希望表明，找到最佳点是至关重要的。</p><p id="28e8" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">特征的数量决定了底层关系允许有多复杂。太复杂会导致过度拟合。另一方面，缺乏复杂性阻止了算法检测特征和目标之间的有用关系。</p><p id="1289" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">总之，我们已经准备好了数据集，确定了算法，并决定了我们想要优化的两个超参数。现在怎么办？在我们回到玩具的例子之前，让我们考虑三个选择。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="d2a9" class="li lj jg bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">选项 1:尝试所有组合</h1><p id="e6d6" class="pw-post-body-paragraph kd ke jg kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">我们生活在一个计算能力无限的时代，对吗？如果这是真的，让我们尝试所有可能的配置，在测试集上比较它们的性能，并选择最佳配置。这就是<strong class="kf jh">网格搜索</strong>建立的目的。这种方法并不意味着精确或高效；这是一把猎枪。如果您有一组参数的完美组合可以隐藏的地方，网格搜索会瞄准所有这些地方并返回最佳选择。</p><p id="012f" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们假设我定义了五个不同的学习率，以及五个不同的模型允许使用的最大特征数的值。然后，grid search 训练 25 个(5 * 5)不同的模型，评估所有模型，并返回在我选择的度量中得分最高的超参数配置。到目前为止一切顺利。</p><p id="5fb9" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，正如您已经预料到的，这种方法的运行时间可能会很长。如果要检查三个超参数的十个不同值，网格搜索需要计算 10 * 10 * 10，也就是 1000(！)模特。让我们添加 3 重交叉验证，我们需要训练 3000 个模型！虽然对于网格搜索何时不再可行没有客观的阈值，但是这种方法的缺点是显而易见的。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="c792" class="li lj jg bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">选项 2:尝试尽可能多的组合</h1><p id="aaf5" class="pw-post-body-paragraph kd ke jg kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">我不确定这是否会随着量子计算而改变，但目前，我必须在有限的计算能力下工作。因此，我无法测试所有可能的超参数组合。相反，我想尽可能多地测试它们，我将使用<strong class="kf jh">随机搜索</strong>来完成这项工作。由于我不知道最佳配置，所以这种方法随机选择一组组合并测试它们。</p><p id="5b0f" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与网格搜索相比，有两个主要优势:</p><ol class=""><li id="7137" class="ml mm jg kf b kg kh kk kl ko mn ks mo kw mp la ng mr ms mt bi translated">我可以定义迭代次数，即搜索算法测试的可能组合的数量。通过这样做，我可以决定我可用的计算预算。也许它很小，因为下一次结果的展示就要开始了。也许我的预算很重要，因为我周末离开，同时可以让我的机器保持运转。关键是，我现在控制了局面。</li><li id="a839" class="ml mm jg kf b kg mu kk mv ko mw ks mx kw my la ng mr ms mt bi translated">由于组合的选择是随机的，所以我可以使用分布来代替固定的一组值。对于网格搜索，我需要定义一组不同的最大特征，例如[1，10，30，50]。在随机搜索中，我可以定义特征的最大数量必须在 1 到 50 之间，并且中间的每个整数的概率相等。</li></ol><p id="2056" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这两点都改进了网格搜索。然而，让我们来解决房间里的大象:如果组合的选择是随机的，我找到最佳模型(或者至少是合理接近它的模型)的可能性有多大？好在答案是:很有可能。明确地说:如果我的网格包括 1000 种组合，而我只随机选择了其中的 10 种，我就有麻烦了。然而，一篇研究论文显示，如果网格中 5%的组合导致最佳结果，60 次随机搜索迭代足以有超过 95%的把握找到这些点中的一个(参见<a class="ae jd" href="http://www.jmlr.org/papers/v13/bergstra12a.html" rel="noopener ugc nofollow" target="_blank">此处</a>获得实际论文，以及<a class="ae jd" href="https://www.oreilly.com/ideas/evaluating-machine-learning-models/page/5/hyperparameter-tuning" rel="noopener ugc nofollow" target="_blank">此处</a>获得额外解释)。</p><p id="8c41" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要点:网格搜索是有时间/资源和非理性高度风险厌恶的人可能会尝试的。然而，随机搜索是所有实际数据科学问题的首选算法。</p><p id="b732" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你和我一样，你还是不满足。原因是<em class="nc">这个词随机化了</em>。现在有很多关于人工智能的讨论，因此必须有一种更智能的方法来选择超参数组合。如果我们使用一种算法来学习看哪里，那不是很好吗？</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="4d6d" class="li lj jg bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">选项 3:尝试最有希望的组合</h1><p id="caa6" class="pw-post-body-paragraph kd ke jg kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">我坚持我对每个超参数的可能值范围的想法。然而，这一次，该算法不会测试所有的组合(网格搜索)或随机选择其中的一些组合(随机搜索)，而是反复重新评估下一步在哪里寻找。从概念上讲，我们现在正在进入<strong class="kf jh">知情搜索</strong>的领域。</p><blockquote class="mz na nb"><p id="2d4b" class="kd ke nc kf b kg kh ki kj kk kl km kn nd kp kq kr ne kt ku kv nf kx ky kz la ij bi translated"><strong class="kf jh">免责声明 2 </strong>:我在这里讨论贝叶斯优化，但是，尽管这是一个流行的选择，它只是一个有根据的搜索算法的例子。在我看来，这是最容易从概念上理解的，但这并不意味着它一定是最好的选择。有关方法和实现的更多细节，请查看此处的<a class="ae jd" rel="noopener" target="_blank" href="/automated-machine-learning-hyperparameter-tuning-in-python-dfda59b72f8a">和此处的</a>和<a class="ae jd" rel="noopener" target="_blank" href="/an-introductory-example-of-bayesian-optimization-in-python-with-hyperopt-aae40fff4ff0"/>。</p></blockquote><p id="7c6e" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要理解这个想法，请跟着我看一个基本的例子。假设我用随机选择的超参数值计算了第一个模型。其准确率为 67%。现在我用另一组超参数计算一个模型，它产生的准确率只有 64%。贝叶斯方法降低了为第二模型选择的值是最优解的一部分的概率。现在，它使用更新的概率为每个超参数选择一组新值，查看它是提高还是降低了模型的质量，并更新概率。换句话说，该算法更有可能为下一轮选择与较高模型性能相关的值，而不是那些不太有效的替代值。</p><p id="90bb" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">关注更新概率的概念是至关重要的。有希望的值更有可能被选中，但仍有一些随机性。这个过程确保算法对新的可能性保持开放。如果想深入挖掘这个问题，谷歌“探索 vs 剥削”。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><h1 id="d3fc" class="li lj jg bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">那么这些 Kickstarter 活动呢？</h1><p id="9e86" class="pw-post-body-paragraph kd ke jg kf b kg mg ki kj kk mh km kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">在我回到我的玩具例子之前，这里是关于三个选项的最关键点:</p><ul class=""><li id="da64" class="ml mm jg kf b kg kh kk kl ko mn ks mo kw mp la mq mr ms mt bi translated"><strong class="kf jh">网格搜索</strong>是一种强力方法，它测试超参数的所有组合，以找到最佳模型。它的运行时随着要测试的值(及其组合)的数量而爆炸。</li><li id="ed71" class="ml mm jg kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated"><strong class="kf jh">随机搜索</strong>通过将自己限制在限定数量的组合中进行尝试来减少运行时间。因为这种方法可能找到接近最佳的解决方案，所以比网格搜索更可取。</li><li id="e4fc" class="ml mm jg kf b kg mu kk mv ko mw ks mx kw my la mq mr ms mt bi translated"><strong class="kf jh">知情搜索</strong>(贝叶斯优化作为其实现之一)通过反复重新评估寻找最佳位置增加了一些额外的开销。这种开销可以通过更有效的搜索来平衡。这种方法经常出现在 Kaggle 比赛中是有原因的。</li></ul><p id="8637" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，让我们看看 Kickstarter 项目(再次，见<a class="ae jd" href="https://github.com/timo-boehm/material_blog_posts" rel="noopener ugc nofollow" target="_blank">这里</a>一个 Jupyter 笔记本)。如上所述，我只调整学习率(在 0.005 和 0.2 之间)和最大特征数(在一个和所有可用特征之间)来对数据训练梯度推进模型。以下是我们三个选项的结果:</p><ol class=""><li id="bfc6" class="ml mm jg kf b kg kh kk kl ko mn ks mo kw mp la ng mr ms mt bi translated"><strong class="kf jh">网格搜索</strong>:我使用<em class="nc"> numpy </em>为两个超参数定义了五个均匀间隔的值，总共有 25 个组合要测试。达到<strong class="kf jh"> 0.626 </strong>的<a class="ae jd" href="http://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics" rel="noopener ugc nofollow" target="_blank"> AUC 分数</a>花费了大约<strong class="kf jh"> 8 秒</strong>。</li><li id="2ab5" class="ml mm jg kf b kg mu kk mv ko mw ks mx kw my la ng mr ms mt bi translated"><strong class="kf jh">随机搜索:</strong>这次我用了一个<em class="nc"> scipy </em>函数，让特征数量的选择更加灵活。一个特征和所有特征之间的所有值被选择的可能性是相等的。为了增加难度，我只允许 12 次迭代。大约<strong class="kf jh"> 4 秒</strong>后得到的 AUC 分数为<strong class="kf jh"> 0.617。</strong>比网格搜索略差。</li><li id="99dd" class="ml mm jg kf b kg mu kk mv ko mw ks mx kw my la ng mr ms mt bi translated"><strong class="kf jh">Informed Search</strong>:<em class="nc">hyperopt</em>提供了一些非常有用的函数来模拟超参数的分布。对于学习率，我使用了一个使较小值比大值更有可能的分布。我决定用 25 次迭代。在大约<strong class="kf jh"> 7 秒</strong>之后，该模型获得了<strong class="kf jh"> 0.635 </strong>的 AUC 分数。</li></ol><p id="d59f" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我想说清楚:这是一个用于说明目的的玩具示例。请按照我在这篇博文中提供的链接进行比较和评估。尽管如此，我希望这篇介绍能在两个方面帮助你。首先，让您可以方便地访问主题和一些可以在项目中使用的代码片段。第二，激励你更深入地挖掘超参数优化的主题。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="a4d1" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">感谢阅读！</strong>如果您有任何反馈或想告诉我您在超参数优化方面的体验，我很高兴收到您的来信！你可以在推特<a class="ae jd" href="https://twitter.com/TimoBohm" rel="noopener ugc nofollow" target="_blank">和领英</a>上找到我。让我们继续学习吧！</p></div></div>    
</body>
</html>