<html>
<head>
<title>Singular Value Decomposition with Example in R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">R 中的奇异值分解及实例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/singular-value-decomposition-with-example-in-r-948c3111aa43?source=collection_archive---------7-----------------------#2018-12-20">https://towardsdatascience.com/singular-value-decomposition-with-example-in-r-948c3111aa43?source=collection_archive---------7-----------------------#2018-12-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="e355" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你熟悉矩阵和向量，那么理解什么是 SVD 不会花太多时间，但是，如果你不熟悉矩阵，我建议你先掌握它。</p><p id="d4f5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">SVD 是这样一种方法，我们用矩阵的形式表示数据，然后我们减少它的列数以表示相同的信息。为什么数据不会丢失？有人可能会问。这个问题的答案是 SVD 的本质，我们将看看它是如何工作的。</p><p id="0b7d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基本上，SVD 做的是把一个矩阵分解成三个其他的矩阵，它们被称为 u，v 和 d。</p><p id="02e1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1- A 是 m*n 元素的实矩阵。</p><p id="b791" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2- U 是具有 m*m 个元素的正交矩阵</p><p id="3f50" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3- V 是具有 n*n 个元素的正交矩阵。</p><p id="f728" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">4- D 是具有 m*n 个元素的对角矩阵。</p><p id="8d21" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正交矩阵是这样一种矩阵，如果乘以其他数，它的性质不会改变。例如，如果你有一个矩阵“X ”,你用它乘以任何其他矩阵，得到矩阵“Y ”,然后如果你从“Y”中取出“S ”,那么你得到与“X”相同的矩阵,“S”只是一个标量值，叫做特征值。</p><p id="2bb8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">X*λ = Y (1)</p><p id="489f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Y= S*X (2)</p><p id="0ff2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中λ是 X 的倍数，S 是 y 的公倍数。</p><p id="5559" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对角矩阵是指从上到下只有非零对角线数的矩阵。对角线以外的地方会有零。</p><p id="db21" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了更清楚，想象一下你在一个 3D 平面里拿着一支铅笔，现在如果你在铅笔的轴上乘以一个数，它会移动到 3D 平面的另一个地方，但是你的铅笔的长度仍然是一样的。</p><p id="e378" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">那么，我们知道 SVD 把矩阵分解成三个分量，那么它有什么用呢？用途是当我们把它们相乘时，我们得到的矩阵和之前的一样。但是请记住，我们不只是将它们相乘，而是使用这个公式——a = u * d * v^t，其中 t 表示矩阵 v 的转置</p><p id="23ae" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要记住的一件事是，你的对角矩阵 D 可能只给你一个对角线数的列表，然后你将不得不在非对角线的地方补零。此外，请记住，U 的列数将与 d 的行数相同。</p><p id="88d2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但真正的问题是，这些对我们有什么帮助？让我们看看。</p><p id="5ada" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我们将矩阵 A 分解成 U，D，V 时，所有三个矩阵中最左边的几列代表了我们恢复实际数据所需的几乎所有信息。请记住，我没有说全部，我说的是几乎全部，例如 92%的信息只存在于总列数的 5%的列中。考虑到您已经极大地减少了数据集的大小，这是一笔不错的交易。这意味着奇异值分解在矩阵 A 的所有列之间找到了某种联系，用较少的列表示相同的信息。现在，除了最左边的列之外的列被删除，因为它们被认为是错误的，并且该过程通过删除原始矩阵的几乎 90%的列来减小矩阵的大小。</p><p id="6f8f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在让我们看看它在 r 中是如何工作的。请记住，在每一段代码之后，您都会看到输出以及对该输出的一个小解释。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="6c44" class="ku kv iq kq b gy kw kx l ky kz"><strong class="kq ir">install.packages(“pixmap”,repos = “http://cran.us.r-project.org")library(pixmap)<br/> image&lt;- read.pnm(“flower.ppm”)</strong></span><span id="2651" class="ku kv iq kq b gy la kx l ky kz">image@size</span></pre><p id="9798" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi">## [1] 300 400</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="cec4" class="ku kv iq kq b gy kw kx l ky kz">str(image)</span></pre><p id="7c4b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">##具有 8 个插槽的正式类“pixmapRGB”[包“pixmap”]<br/># #..@ <strong class="jp ir"> <em class="lb">红色</em> </strong> : num [1:300，1:400]0.894 0.878 0.851 0.816 0.8…<br/># #..@ <strong class="jp ir"> <em class="lb">绿色</em> </strong> : num [1:300，1:400]0.29 0.275 0.255 0.235 0.231…<br/># #..@ <strong class="jp ir"> <em class="lb">蓝色</em> </strong> : num [1:300，1:400]0.525 0.51 0.494 0.471 0.463…<br/># #..@ channels: chr [1:3]"红色" "绿色" "蓝色"<br/> ##..@ size : int [1:2] 300 400 <br/> ##..@ cellres : num [1:2] 1 1 <br/> ##..@ bbox:num[1:4]0 400 300<br/># #..@ bbcent : logi FALSE</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="9659" class="ku kv iq kq b gy kw kx l ky kz">red.img &lt;- matrix(image@red,nrow = image@size[1], ncol = image@size[2])<br/> <br/> blue.img &lt;- matrix(image@blue,nrow = image@size[1], ncol = image@size[2])<br/> <br/> green.img &lt;- matrix(image@green,nrow = image@size[1], ncol = image@size[2])<br/> <br/> str(red.img)</span></pre><p id="06b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">## num [1:300，1:400] 0.894 0.878 0.851 0.816 0.8 …</p><p id="a203" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们看到在每种颜色矩阵中都有相同数量的行和列。</p><p id="c262" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将它们分成三种颜色的原因是因为在 R 中，这三种颜色构成了 R 中每种颜色的基础。<br/>但是在我们的例子中，我们将只使用红色，所有图像之间的差异可以在下面看到。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="29a7" class="ku kv iq kq b gy kw kx l ky kz">image(red.img)</span></pre><figure class="kl km kn ko gt ld gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/c700541ee4c6da0e790900da5593fd81.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*Yoxsdg_n9LVDG4TaPoYKzw.jpeg"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Red matrix color</figcaption></figure><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="d6bb" class="ku kv iq kq b gy kw kx l ky kz">image(green.img)</span></pre><figure class="kl km kn ko gt ld gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/dde88d636c5acf7d1bcc01fb49735e01.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*s0YroBaw-3yAP5QbZ0qNAw.jpeg"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Green matrix color</figcaption></figure><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="4ecc" class="ku kv iq kq b gy kw kx l ky kz">image(blue.img)</span></pre><figure class="kl km kn ko gt ld gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/8f538398fef8a49f96eb93033628a043.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*_JXgPm6R2SDg1ztHCA2ZpQ.jpeg"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Blue Matrix color</figcaption></figure><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="3ca4" class="ku kv iq kq b gy kw kx l ky kz">plot(image)</span></pre><figure class="kl km kn ko gt ld gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/8e0d6887213d52831e88474d9b1f270d.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*4dk4uOGxijRyv6qBWXIktw.jpeg"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Original Image</figcaption></figure><p id="2d07" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从上面给出的图片中，我取红色矩阵进行分解。</p><p id="ea76" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了获得更清晰的图片，这里是红色矩阵的快照。记住，这个矩阵很快就会分解成三个分量。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="c9ed" class="ku kv iq kq b gy kw kx l ky kz">View(red.img)</span></pre><figure class="kl km kn ko gt ld gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lk"><img src="../Images/949b20bc83aeab80357deac696aca1cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q9UBARLuPnfmy-x3e2O5Rg.png"/></div></div></figure><p id="f8ca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你会看到 R 中的“svd”命令会将红色矩阵分解成三个部分。它们是 d，u，v，给出了各自的行和列。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="3aff" class="ku kv iq kq b gy kw kx l ky kz">comp&lt;- svd(red.img)<br/> str(comp)</span></pre><p id="2adb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"># # 3 的列表<br/># # $ d:num[1:300]205.2 37.1 33.1 20.4 15.4…<br/># # $ u:num[1:300，1:300]-0.0431-0.0427-0.0421-0.0419-0.0418…<br/># # $ v:num[1:400，1:300]-0.0300</p><p id="2888" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了让下面的图片更清晰，我们也有他们每个人的快照。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="b213" class="ku kv iq kq b gy kw kx l ky kz">View(comp$v)</span></pre><figure class="kl km kn ko gt ld gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lp"><img src="../Images/84e504f629edc43351f894a7419e8d66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gv-UM9NT_jh8aDB0P1_-NA.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">v matrix</figcaption></figure><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="3cfa" class="ku kv iq kq b gy kw kx l ky kz">View(t(comp$d))</span></pre><figure class="kl km kn ko gt ld gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lq"><img src="../Images/3aeea633120ab5bee71e5fdc6fc78699.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*15iizqrTD75ld1TMIQEWuw.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Transpose of v</figcaption></figure><p id="2f42" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，您可以看到“v”矩阵的行变成了转置矩阵中的列。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="9a30" class="ku kv iq kq b gy kw kx l ky kz">View(comp$d)</span></pre><figure class="kl km kn ko gt ld gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/435723f2d51ae801a59ad4c3b2952f69.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*sxzVQGSNUHbVBiAAplBaFg.png"/></div></figure><p id="0e37" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你看到它是一个列表并且一个列表不与一个矩阵相乘，所以我们需要在它与其他组件相乘时将其转换为对角矩阵。但是，让我们来感受一下使用“diag”命令后的效果。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="5d8e" class="ku kv iq kq b gy kw kx l ky kz">d &lt;- diag(comp$d)<br/> View(d)</span></pre><figure class="kl km kn ko gt ld gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lk"><img src="../Images/b8aa6b98f3babb9ea40fcd8ea94c4cb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HzH0vJV3xQXBJ8s-vTrACQ.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">matrix ‘d’ after imputing zeros</figcaption></figure><p id="126f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是数字按对角线排列后的样子。这里需要注意的重要一点是，只有“d”中的几个起始列比其他列具有更大的权重，并且随着从左到右权重不断降低，因此我们只需要矩阵最左侧的那些列。让我们取其中的 25 个，它们可能代表了几乎 90%的信息。注意:我没有计算百分比，这只是一个假设。</p><p id="e0b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，在我们将这些矩阵的前 25 列相乘之前，我们需要知道,“u”将保持不变，但“v”必须被转置，以便遵循矩阵法则。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="0eeb" class="ku kv iq kq b gy kw kx l ky kz">compressed.image&lt;- (comp$u[,1:25] %*% diag(comp$d[1:25]) %*% t(comp$v[,1:25]))<br/> <br/> image(compressed.image)</span></pre><figure class="kl km kn ko gt ld gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/6422bb0935359447cda3b7b19b66aaa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*2cUxlPD-nzpvAP7-KbmhjA.jpeg"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk">Final Image we Recovered</figcaption></figure><p id="071f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">记住，左矩阵的列必须总是等于右矩阵的行。如果出现错误，请检查您的列和行。</p><p id="04ed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">看到这最后一个图像不像我们之前看到的那样清晰，但很明显它是一朵花的图像；但是我们已经减少了列的数量，因此与表示原始红色矩阵所需的空间相比，我们需要非常少的内存来显示该图像。</p><p id="bb86" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">参考资料:</p><h2 id="7fa6" class="ku kv iq bd ls lt lu dn lv lw lx dp ly jy lz ma mb kc mc md me kg mf mg mh mi bi translated"><a class="ae mj" href="https://www.youtube.com/channel/UCd0dc7kQA1FUpJ76o1EjLqQ" rel="noopener ugc nofollow" target="_blank">匿名</a>。(2016)."什么是特征向量？"。<a class="ae mj" href="https://www.youtube.com/channel/UCd0dc7kQA1FUpJ76o1EjLqQ" rel="noopener ugc nofollow" target="_blank">雷奥索斯</a>。【https://www.youtube.com/watch?v=ue3yoeZvt8E T4】</h2><h2 id="4091" class="ku kv iq bd ls lt lu dn lv lw lx dp ly jy lz ma mb kc mc md me kg mf mg mh mi bi translated">无名氏。“奇异值分解”。RPUBS。<a class="ae mj" href="https://rpubs.com/aaronsc32/singular-value-decomposition-r" rel="noopener ugc nofollow" target="_blank">https://rpubs.com/aaronsc32/singular-value-decomposition-r</a>。</h2><p id="ede3" class="pw-post-body-paragraph jn jo iq jp b jq mk js jt ju ml jw jx jy mm ka kb kc mn ke kf kg mo ki kj kk ij bi translated">怀特，J. (2009 年)。用 R 中的奇异值分解进行图像压缩。RBLOGGERS。<em class="lb"/><a class="ae mj" href="https://www.r-bloggers.com/image-compression-with-the-svd-in-r/" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">https://www . r-bloggers . com/image-compression-with-the-SVD-in-r/</strong></a></p></div></div>    
</body>
</html>