<html>
<head>
<title>Kafka-Python explained in 10 lines of code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卡夫卡-Python 用 10 行代码解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/kafka-python-explained-in-10-lines-of-code-800e3e07dad1?source=collection_archive---------0-----------------------#2018-08-13">https://towardsdatascience.com/kafka-python-explained-in-10-lines-of-code-800e3e07dad1?source=collection_archive---------0-----------------------#2018-08-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="fe89" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">虽然它不是 Python 提供的最新库，但很难找到关于如何将 Apache Kafka 与 Python 结合使用的全面教程。通过大约十行代码，我将解释<strong class="jp ir">Kafka 的基础以及它与 Kafka-Python </strong>的交互。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/e84361fbc0e5d4433c80eeed27a39726.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bIIzkEI5HSaVkYyxxohK2g.png"/></div></div></figure><h1 id="3eff" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">设置环境</h1><p id="3eae" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">首先你要在你的机器上安装<strong class="jp ir">卡夫卡和动物园管理员</strong>。对于 Windows 来说，有一个由 Shahrukh Aslam 编写的优秀指南，它们肯定也适用于其他操作系统。</p><p id="231e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来<strong class="jp ir">安装 Kafka-Python </strong>。如果您使用的是 Anaconda 发行版，那么您可以使用 pip 或 conda 来实现这一点。</p><pre class="km kn ko kp gt mb mc md me aw mf bi"><span id="c0ee" class="mg ky iq mc b gy mh mi l mj mk">pip install kafka-python</span><span id="ec2e" class="mg ky iq mc b gy ml mi l mj mk">conda install -c conda-forge kafka-python</span></pre><p id="1687" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在执行下面的示例代码之前，不要忘记启动 Zookeeper 服务器和 Kafka broker 。在这个例子中，我们假设 Zookeeper 在<em class="mm"> localhost:2181 </em>上运行 default，在<em class="mm"> localhost:9092 </em>上运行 Kafka。</p><p id="17c3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还使用了一个名为<em class="mm"> numtest </em>的主题。在本例中，您可以<strong class="jp ir">创建一个新主题</strong>，方法是打开一个新的命令提示符，导航到<em class="mm"> …/kafka/bin/windows </em>并执行:</p><pre class="km kn ko kp gt mb mc md me aw mf bi"><span id="7f1b" class="mg ky iq mc b gy mh mi l mj mk">kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic numtest</span></pre><h1 id="9222" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">卡夫卡是什么？</h1><p id="59fd" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">简而言之，Kafka 是一个分布式发布-订阅消息系统，它以分区和复制的主题维护消息提要。最简单的说，Kafka 生态系统中有三个参与者:生产者、主题(由经纪人管理)和消费者。</p><p id="e30c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">制作人根据他们选择的主题制作信息。可以给每个消息附加一个密钥，在这种情况下，生产者保证所有具有相同密钥的消息将到达相同的分区。</p><p id="ffa0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">主题是日志，它从生产者那里接收数据，并将它们存储在它们的分区中。生产者总是在日志的末尾写新的消息。在我们的例子中，我们可以对分区进行抽象，因为我们在本地工作。</p><p id="406c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">消费者按照自己的节奏阅读他们选择的主题的一组分区的信息。如果消费者是消费者组的一部分，即订阅相同主题的一组消费者，他们可以提交他们的补偿。如果您希望与不同的使用者并行使用一个主题，这可能很重要。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mn"><img src="../Images/2fee961b1d870c1f1f66a4312ef0e1ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ipMuwhEg-LO6wBCy1jlkpg.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">source: <a class="ae ma" href="https://www.cloudera.com/documentation/kafka/1-2-x/topics/kafka.html" rel="noopener ugc nofollow" target="_blank">https://www.cloudera.com/documentation/kafka/1-2-x/topics/kafka.html</a></figcaption></figure><p id="6e70" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">偏移量是日志中消费者最后消费或读取消息的位置</strong>。然后，用户可以提交该偏移量，使读数成为“官方”读数。偏移量提交可以在后台自动完成，也可以显式完成。在我们的示例中，我们将在后台自动提交。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/42b4c6258e4fe1beab234ae9bb729dc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*lLlVG5cFS5rchgPqEN_7bg.png"/></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">source: <a class="ae ma" href="https://www.confluent.io/blog/tutorial-getting-started-with-the-new-apache-kafka-0-9-consumer-client/" rel="noopener ugc nofollow" target="_blank">https://www.confluent.io/blog/tutorial-getting-started-with-the-new-apache-kafka-0-9-consumer-client/</a></figcaption></figure><h1 id="7933" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">让我们编码</h1><p id="8d71" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">在我们的例子中，我们将创建一个<strong class="jp ir">生产者</strong>，它发出从 1 到 1000 的数字，并将它们发送给我们的 Kafka <strong class="jp ir">经纪人</strong>。然后<strong class="jp ir">消费者</strong>将从<strong class="jp ir">代理</strong>读取数据，并将它们存储在 MongoDb 集合中。</p><p id="1b48" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用卡夫卡的好处在于，如果我们的消费者崩溃了，新的或固定的消费者会从上一个消费者停止阅读的地方继续阅读。这是一个很好的方法来确保所有的数据都输入到数据库中，没有重复或丢失的数据。</p><p id="916f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">创建一个名为<em class="mm"> producer.py </em>的新 Python 脚本，从我们全新的 Kafka-Python 库中导入<em class="mm"> json </em>、<em class="mm"> time.sleep </em>和<em class="mm"> KafkaProducer </em>开始。</p><pre class="km kn ko kp gt mb mc md me aw mf bi"><span id="b294" class="mg ky iq mc b gy mh mi l mj mk">from time import sleep<br/>from json import dumps<br/>from kafka import KafkaProducer</span></pre><p id="dca1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后<strong class="jp ir">初始化一个新的卡夫卡制作人</strong>。请注意以下参数:</p><ul class=""><li id="49a1" class="mt mu iq jp b jq jr ju jv jy mv kc mw kg mx kk my mz na nb bi translated"><em class="mm">bootstrap _ servers =[' localhost:9092 ']</em>:设置生产者应该联系的主机和端口，以引导初始集群元数据。没有必要在这里设置，因为默认设置是<em class="mm"> localhost:9092 </em>。</li><li id="3efd" class="mt mu iq jp b jq nc ju nd jy ne kc nf kg ng kk my mz na nb bi translated"><em class="mm">value _ serializer = lambda x:dumps(x)。encode('utf-8') </em>:数据在发送到代理之前应该如何序列化的函数。这里，我们将数据转换为 json 文件，并将其编码为 utf-8。</li></ul><pre class="km kn ko kp gt mb mc md me aw mf bi"><span id="d01a" class="mg ky iq mc b gy mh mi l mj mk">producer = KafkaProducer(bootstrap_servers=['localhost:9092'],<br/>                         value_serializer=lambda x: <br/>                         dumps(x).encode('utf-8'))</span></pre><p id="fb2f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们想生成从 1 到 1000 的数字。这可以通过一个 for 循环来实现，我们将每个数字作为值输入到一个只有一个键的字典中:<em class="mm"> number </em>。这不是话题键，只是我们数据的一个键。在同一个循环中，我们还将把数据发送给一个代理。</p><p id="d18a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这可以通过<strong class="jp ir">调用生成器</strong>上的 send 方法并指定主题和数据来完成。请注意，我们的值序列化程序将自动转换和编码数据。为了结束我们的迭代，我们休息 5 秒钟。如果您想确保消息被代理收到，建议包含一个回调。</p><pre class="km kn ko kp gt mb mc md me aw mf bi"><span id="0611" class="mg ky iq mc b gy mh mi l mj mk">for e in range(1000):<br/>    data = {'number' : e}<br/>    producer.send('numtest', value=data)<br/>    sleep(5)</span></pre><p id="e999" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您想测试代码，建议创建一个新主题并将数据发送到这个新主题。这样，当我们稍后一起测试生产者和消费者时，您将避免在<em class="mm"> numtest </em>主题中的重复和可能的混淆。</p><h1 id="53d2" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">消费数据</h1><p id="272b" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">在我们开始编码我们的消费者之前，创建一个新文件<em class="mm"> consumer.py </em>并从<em class="mm"> pymongo </em>导入<em class="mm"> json.loads </em>、<em class="mm"> KafkaConsumer </em>类和<em class="mm"> MongoClient </em>。我不会深入研究 PyMongo 代码，因为这超出了本文的范围。</p><p id="f1c6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，您可以用任何其他代码替换 mongo 代码。这可以是将数据输入到另一个数据库的代码，处理数据的代码或者任何你能想到的代码。关于<em class="mm"> PyMongo </em>和 MongoDb 的更多信息，请查阅<a class="ae ma" href="https://api.mongodb.com/python/current/" rel="noopener ugc nofollow" target="_blank">文档</a>。</p><pre class="km kn ko kp gt mb mc md me aw mf bi"><span id="f174" class="mg ky iq mc b gy mh mi l mj mk">from kafka import KafkaConsumer<br/>from pymongo import MongoClient<br/>from json import loads</span></pre><p id="ebe3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们<strong class="jp ir">创造我们的 KafkaConsumer </strong>并仔细看看这些论点。</p><ul class=""><li id="c34c" class="mt mu iq jp b jq jr ju jv jy mv kc mw kg mx kk my mz na nb bi translated">第一个参数是主题，在我们的例子中是<em class="mm"> numtest </em>。</li><li id="6da8" class="mt mu iq jp b jq nc ju nd jy ne kc nf kg ng kk my mz na nb bi translated"><em class="mm">bootstrap _ servers =[' localhost:9092 ']</em>:与我们的生产者相同</li><li id="ade4" class="mt mu iq jp b jq nc ju nd jy ne kc nf kg ng kk my mz na nb bi translated"><em class="mm">auto _ offset _ reset = ' earliest '</em>:最重要的参数之一。它处理消费者在故障或关闭后重新开始阅读的位置，并且可以设置为最早<em class="mm">最早</em>或最晚<em class="mm">最晚</em>。当设置为<em class="mm">最新</em>时，用户从日志末尾开始读取。当设置为<em class="mm">最早</em>时，消费者从最新提交的偏移开始读取。这正是我们想要的。</li><li id="e1b7" class="mt mu iq jp b jq nc ju nd jy ne kc nf kg ng kk my mz na nb bi translated"><em class="mm">enable _ auto _ commit = True</em>:确保消费者每隔一段时间提交一次读取偏移量。</li><li id="b211" class="mt mu iq jp b jq nc ju nd jy ne kc nf kg ng kk my mz na nb bi translated"><em class="mm">auto _ commit _ interval _ ms = 1000 ms</em>:设置两次提交的时间间隔。因为每五秒钟就有一条消息进来，所以每秒钟提交一次似乎是公平的。</li><li id="cbc3" class="mt mu iq jp b jq nc ju nd jy ne kc nf kg ng kk my mz na nb bi translated"><em class="mm"> group_id='counters' </em>:消费者所属的消费群。请记住，在介绍中，消费者需要成为消费者组的一部分，以使自动提交工作。</li><li id="3907" class="mt mu iq jp b jq nc ju nd jy ne kc nf kg ng kk my mz na nb bi translated">值反序列化器将数据反序列化为一种通用的 json 格式，与我们的值序列化器所做的相反。</li></ul><pre class="km kn ko kp gt mb mc md me aw mf bi"><span id="ec86" class="mg ky iq mc b gy mh mi l mj mk">consumer = KafkaConsumer(<br/>    'numtest',<br/>     bootstrap_servers=['localhost:9092'],<br/>     auto_offset_reset='earliest',<br/>     enable_auto_commit=True,<br/>     group_id='my-group',<br/>     value_deserializer=lambda x: loads(x.decode('utf-8')))</span></pre><p id="e619" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面的代码连接到我们的 MongoDb 数据库的<em class="mm"> numtest </em>集合(集合类似于关系数据库中的表)。</p><pre class="km kn ko kp gt mb mc md me aw mf bi"><span id="d693" class="mg ky iq mc b gy mh mi l mj mk">client = MongoClient('localhost:27017')<br/>collection = client.numtest.numtest</span></pre><p id="9fa3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以通过循环从消费者那里提取数据(消费者是可迭代的)。消费者会一直听下去，直到代理不再响应。可以使用 value 属性访问消息的值。这里，我们用消息值覆盖消息。</p><p id="13b2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下一行将数据插入我们的数据库集合。最后一行打印了一条确认消息，表明该消息已被添加到我们的集合中。注意，可以在这个循环中为所有动作添加回调。</p><pre class="km kn ko kp gt mb mc md me aw mf bi"><span id="0d5b" class="mg ky iq mc b gy mh mi l mj mk">for message in consumer:<br/>    message = message.value<br/>    collection.insert_one(message)<br/>    print('{} added to {}'.format(message, collection))</span></pre><h1 id="16a0" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">测试</h1><p id="1421" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">让我们测试我们的两个脚本。打开命令提示符，转到保存<em class="mm"> producer.py </em>和<em class="mm"> consumer.py </em>的目录。执行<em class="mm"> producer.py </em>，打开一个新的命令提示符。启动<em class="mm"> consumer.py </em>，看看它如何读取所有消息，包括新消息。</p><p id="58f2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在中断消费者，记住它是哪个号码(或者在数据库中检查它)并重新启动消费者。请注意，消费者会拾取所有错过的消息，然后继续收听新消息。</p><p id="751d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，如果您在阅读消息后 1 秒钟内关闭消费者，消息将在重新启动时再次被检索。为什么？因为我们的<em class="mm"> auto_commit_interval </em>被设置为 1 秒，记住如果偏移量没有被提交，消费者将再次读取消息(如果<em class="mm"> auto_offset_reset </em>被设置为最早)。</p><p id="a8a7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">—请随时在评论中或私信中向我指出任何不一致或错误。—</p><h1 id="3ed2" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">承认</h1><p id="0fd0" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">本文绝不是 Kafka 或 Kafka-Python 的完整指南，而是一个全面的介绍，它将使您熟悉 Kafka 的基本概念以及如何用有用的 Python 代码来转换这些概念。</p><p id="baf2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于更高级的主题，建议阅读文档。如果你想部署代码，看看 Russell Jurney 的<em class="mm"> Confluent-Kafka </em>和<a class="ae ma" href="https://blog.datasyndrome.com/a-tale-of-two-kafka-clients-c613efab49df" rel="noopener ugc nofollow" target="_blank">这篇文章</a>可能是个好主意。</p><h1 id="1bcf" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">来源</h1><p id="e9dd" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated"><a class="ae ma" href="https://kafka-python.readthedocs.io/en/master/index.html" rel="noopener ugc nofollow" target="_blank"> Kafka-Python 文档</a></p><p id="ee7c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae ma" href="https://medium.com/@mukeshkumar_46704/consume-json-messages-from-kafka-using-kafka-pythons-deserializer-859f5d39e02c" rel="noopener">使用 Kafka-Python 的反序列化器消费来自 Kafka 的 JSON 消息</a></p><p id="b154" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae ma" href="https://kafka.apache.org/documentation/" rel="noopener ugc nofollow" target="_blank">阿帕奇卡夫卡文档</a></p><p id="1c6a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae ma" href="https://www.cloudera.com/documentation/kafka/1-2-x/topics/kafka.html" rel="noopener ugc nofollow" target="_blank"> Cloudera Kafka 文档</a></p><p id="244c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae ma" href="https://www.confluent.io/blog/stream-data-platform-1/" rel="noopener ugc nofollow" target="_blank">使用 Apache Kafka:构建流媒体平台实用指南</a></p><p id="8a40" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae ma" href="https://www.confluent.io/blog/tutorial-getting-started-with-the-new-apache-kafka-0-9-consumer-client/" rel="noopener ugc nofollow" target="_blank">介绍 Kafka 消费者:开始使用新的 Apache Kafka 0.9 消费者客户端</a></p></div></div>    
</body>
</html>