<html>
<head>
<title>[ Paper Summary ] Learning deep representations by mutual information estimation and maximization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">[论文摘要]通过互信息估计和最大化学习深度表示</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/paper-summary-learning-deep-representations-by-mutual-information-estimation-and-maximization-efbe41a9f2c3?source=collection_archive---------6-----------------------#2018-11-01">https://towardsdatascience.com/paper-summary-learning-deep-representations-by-mutual-information-estimation-and-maximization-efbe41a9f2c3?source=collection_archive---------6-----------------------#2018-11-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/c13b8009d1f91475cb8e0e8a59ea2670.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BLJn8Rv0FWvyQdjpy34c4g.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo by <a class="ae kc" href="https://unsplash.com/photos/RaywecwCtMo?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Lucrezia Carnelos</a> on <a class="ae kc" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="1365" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我想彻底了解的论文之一。</p><p id="a788" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> <em class="lb">请注意，这个姿势是我自己学习用的。</em>T3】</strong></p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><figure class="lj lk ll lm gt jr"><div class="bz fp l di"><div class="ln lo l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Paper from this <a class="ae kc" href="https://arxiv.org/pdf/1808.06670.pdf" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="1da2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">摘要</strong></p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lp"><img src="../Images/668e37594a2095c6ba8e81b4b618fc86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rTGfiEJIGJ5Jlz3hv-2wwQ.png"/></div></div></figure><p id="26ef" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者的网络的目标是最大化编码器的输入和输出之间的互信息。(无监督特征学习)。对于某些下游任务来说，对表示的有用性有很大影响的一个因素是关于目标输入的位置的知识。此外，作者使用一种对立的自动编码器方法来将编码表示与一些先验分布相匹配。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="7054" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">简介</strong></p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/87b2aaac589dbd3d48027c5bf0dfe577.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OIBY_-a8xsUeTBQy8YWbbA.png"/></div></div></figure><p id="ea42" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在连续和高维空间中计算互信息是非常困难的任务，然而由于最近的进展，现在可以在连续域中高效地计算互信息。因为这个问题已经(部分)解决了，所以本文的作者需要一个函数(神经网络)来最大化给定输入和编码输出之间的互信息。作者还指出，对于特定任务(如分类)，最大化表示(编码特征)和局部区域之间的平均 MI 可能更有用。同时最大化编码特征和全局输入之间的互信息有利于重构原始输入。</p><p id="02b2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当谈到编码特征时，内容和独立性都很重要，作者以类似于 AAE 的方式训练他们的函数，以匹配他们想要强加给编码特征的统计属性。(由于这种方法与 infomax 优化原则密切相关，因此他们将其命名为 DeepInfo Max)。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="61b2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">相关工作</strong></p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lr"><img src="../Images/f474aba13a6f82b7d9e52a8358e5e030.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bk8CbsmHXGCDzv-N3zwTFA.png"/></div></div></figure><p id="991b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有许多方法旨在学习良好的表示，如独立成分分析、自组织映射、自监督方法和深度聚类。生成模型也用于学习有用的表示，并且在任务是重构原始输入的情况下，负重构误差可以与编码器中的 MI 相关，如下所示。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/bad0cd2be3aa3cbe5e205542ce507910.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*OshYb2oJBS9eISvif0RgsA.png"/></div></figure><p id="353a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">x 是给定数据，Y 是编码特征，R 是重构误差，H 是编码器输出的边际熵。这意味着重建目标对它们的中间表示中编码的信息量提供了一些保证。</p><p id="4284" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">互信息估计</em></p><p id="f194" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">互信息方法有着悠久的传统，通常许多互信息方法旨在最大化给定变量之间的互信息。(有些方法可以是非线性的)。互信息神经估计(MINE)学习连续变量的 MI 的神经估计，并且它是强一致的。这篇论文的作者受我的影响，但是他们发现没有必要使用精确的基于 KL 的配方以及具有发生器部分。基于 Jensen-Shannon 散度的简单分类器工作得和 KL 一样好，并且更稳定。此外，作者的方法可以利用输入的局部结构。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="256f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">深度信息最大值</strong></p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lt"><img src="../Images/c3ce78ed86064ed0d2562b4b2d80dd5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rwgH2QH8lBU-wZ9UEWYDQQ.png"/></div></div></figure><p id="7dac" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">训练编码器的一般方法如下所示。给定 X 和 Y 连续且(几乎处处)可微的参数函数的域和范围，作者将 E 定义为神经网络，X 定义为训练数据，P 定义为经验概率分布(数据分布), U 定义为通过神经网络推送样本诱导的边际分布。作者编码器是根据两个标准训练的。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lu"><img src="../Images/f78e025336e25c95e3e876f04deb42ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UcshCX5XPGl4a7vbW5sVVg.png"/></div></div></figure><ol class=""><li id="20d0" class="lv lw iq kf b kg kh kk kl ko lx ks ly kw lz la ma mb mc md bi translated">最大化数据 x 及其编码特征(局部或全局)之间的交互信息</li><li id="d3ee" class="lv lw iq kf b kg me kk mf ko mg ks mh kw mi la ma mb mc md bi translated">让编码的特征匹配一些先验分布(AAE 风格)。</li></ol><p id="3e4e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> <em class="lb"> a)互信息估计和最大化</em> </strong></p><p id="6a8b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">互信息神经估计(MINE)通过训练分类器来区分来自联合 J 和随机变量 X 和 Y 的边缘乘积 M 的样本来估计 MI，并且它使用基于 KL 散度的 Donsker-Varadhan 表示的 MI 的下限。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mj"><img src="../Images/7e8a52e7b6ede3ff7197c552ddbd5173.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B2z34PNaqBxN9TZuQs6Haw.png"/></div></div></figure><p id="6e3d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">t 是鉴别器网络，其参数由 w 建模并与编码器配对，它既估计又最大化互信息。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/fe26017db92e54e5b17b56feec4bcd07.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*EcaJvnLtjMdZ6hUQZNv9gA.png"/></div></figure><p id="b74f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我的网络和作者的网络之间的区别在于，首先，作者的编码器和互信息估计器共享层，因为它们优化相同的目标，其次，作者的目标是最大化 MI(不关心它的精确值),因此使用不同的估计器函数以具有有利的折衷。(注意，也可以使用噪声对比估计。)</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ml"><img src="../Images/75659968623d8f28aa098f1a52cd5014.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hpdkX_LLGS-hKvc04whWwQ.png"/></div></div></figure><p id="cda5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基于 DV、JSD 和 nce 的公式之间存在一些差异，例如 P/Phat 的期望值是出现在对数项内部还是外部。每种测量都有自己的优点和缺点，一般来说，nce 需要更多的负样本，但表现良好，而 JSD 损失相对稳健，但表现不如 NCE。</p><p id="908d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> <em class="lb"> b)局部互信息最大化</em> </strong></p><p id="3df4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据您希望承担的任务，从原始数据中最大化本地区域之间的互信息可能是一个更好的主意。(这也可以应用于语言数据，而不是最大化特征和整个文档之间的 MI，我们可以最大化特征和句子之间的 MI。).例如，最大化给定特征和局部面片之间的平均 MI 可能是个好主意。</p><p id="005c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当编码器不支持无限输出配置并且特征向量具有有限容量时，编码器必须选择将传递何种信息。但是如果编码器只传递特定于输入的本地部分的信息，这将不会增加不包含该信息的任何其他补片的 MI。因此，编码器将传递通常在输入端共享的信息。</p><p id="8dd4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">局部方法首先对输入数据进行编码，这反映了有用的结构，然后将该编码总结为全局特征，然后最大化估计的 MI 可以用如下公式表示。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mm"><img src="../Images/04eb7cb670a0838a540e4ab98c539e38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RnVmJlBI_wbQmBjYwwwa4w.png"/></div></div></figure><p id="8f3a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> <em class="lb"> c)将表征匹配到一个先验分布</em> </strong></p><p id="c4bc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我们将数据编码成某种特征向量时，信息量只是我们优化的标准之一，轴的另一个度量是统计约束。这可以通过 AAE 方法实现，目标函数如下所示。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mn"><img src="../Images/ebc370d85742a6e933b0c91c37d692e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-mJWOnR74ABY9iQHPw44VA.png"/></div></div></figure><p id="9572" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">AAE 之间的一个区别是，我们没有上述目标函数的生成器。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mo"><img src="../Images/16e4813d42a64e17fcfcc31963e66e27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x4vb2ilt-YIh0FBJu0qOOg.png"/></div></div></figure><p id="bae5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我们从上面组合所有的测量轴时，我们得到最终的目标函数，如上所示。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="1f21" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">实验</strong></p><p id="884d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者在 CIFAR10/100、Tiny ImageNet、STL-10 和 CelebA 四个不同的图像数据集上对算法进行了测试。并以一些方法与作者的方法进行了比较，分别以 VAE、AAE、甘比和噪声为目标。</p><p id="59ba" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb"> a)我们如何评估代表的质量？</em></p><p id="52ae" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管测量一个表示是好还是不好是棘手的，但是存在一些测量，例如，线性可分性通常被用作表示和类别标签之间的解纠缠和互信息(MI)或者迁移学习分类任务的代理。</p><p id="aef0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用类标签并不理想，因为当标签未知时，我们可能对表示感兴趣。(类别标签)。因此，我们可以使用 MINE 来直接测量输入和特征之间的关系。或者，我们可以使用一个鉴别器来测量表示的独立性。鉴别器被训练来估计 KL 散度，并且 KL 散度越高，因子越相关。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mp"><img src="../Images/8870078d101e9c8021f0c1d5d2c76a21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AXzOGULhNPmZusxqWlAteQ.png"/></div></div></figure><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mq"><img src="../Images/b6a5d7627b9dfbeb4fdd7a81868a2368.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IDuTr9jgpqTBWyUJUe5Qnw.png"/></div></div></figure><p id="3889" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以上是作者使用的指标的总结。</p><p id="b7a3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb"> b)跨模型的表征学习比较</em></p><p id="ac32" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作者有两个模型 DIM(G)用于全局唯一目标，DIM(L)用于局部目标，对于先验，他们选择了均匀分布。</p><div class="lj lk ll lm gt ab cb"><figure class="mr jr ms mt mu mv mw paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/67d5743128c0579ce2c9dbe09e191aac.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*FytdvseU6t2zAoCPiVtFtw.png"/></div></figure><figure class="mr jr mx mt mu mv mw paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/9c21e1513f232165b20262711a364746.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*KAaSnunZYgKb2Z0bJPhICQ.png"/></div></figure></div><p id="20b3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上表显示了不同数据集的分类精度，很明显 DIM(L)优于所有其他方法。(总之，局部模糊目标适合于提取类别信息。).</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi my"><img src="../Images/375bedfc003456423b8273fe7fa84af6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*44jZYm_iWWzt8c1CfIA5yA.png"/></div></div></figure><p id="e88c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上表显示了 CIFAR10 数据集的线性可分性、重构(MS-SSIM)、互信息和独立性(NDM)的结果。需要注意的一点是，MS-SSIM 与 MINE 提供的 MI 估计值有很好的相关性，表明编码特征与像素信息有关。一般来说，基于像 VAE 和 AAE 的方法的重建对于 MS-SSIM 具有较高的分数，并且结合局部和全局的 DIM 目标对于 DIM 具有最好的结果。</p><p id="e02c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb"> c)添加坐标信息和遮挡</em></p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/20fa0279ffcbc736f543ee4ae4e09df7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wT86-4qv8LWOrz4SEpy12g.png"/></div></div></figure><p id="3288" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，作者在计算全局特征时随机遮挡输入的一部分，但是使用全部输入来计算局部特征。通过这样做，我们鼓励模型对整个图像共享的信息进行编码。这有助于提高分类的准确性。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="e33f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">结论</strong></p><p id="d7e0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">本文的作者介绍了 Deep InfoMax，这是一种最大化互信息的学习表示方法。作者的模型可以学习在原始数据的全局或局部结构之间具有最大互信息的特征。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="8df3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">遗言</strong></p><p id="79fa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">测量相互信息似乎是非常棘手的任务。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="702f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">参考</strong></p><ol class=""><li id="722e" class="lv lw iq kf b kg kh kk kl ko lx ks ly kw lz la ma mb mc md bi translated">Hjelm，r .，费多罗夫，a .，Lavoie-Marchildon，s .，Grewal，k .，Bachman，p .，Trischler，a .，&amp; Bengio，Y. (2018)。通过互信息估计和最大化学习深度表示。Arxiv.org。检索于 2018 年 10 月 30 日，来自<a class="ae kc" href="https://arxiv.org/abs/1808.06670" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1808.06670</a></li></ol></div></div>    
</body>
</html>