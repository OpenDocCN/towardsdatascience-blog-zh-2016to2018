<html>
<head>
<title>Word Morphing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">单词变形</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/word-morphing-9f87ee577775?source=collection_archive---------6-----------------------#2018-04-28">https://towardsdatascience.com/word-morphing-9f87ee577775?source=collection_archive---------6-----------------------#2018-04-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/0667f321ea341054a3a7a9ae4aa32351.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iNIkbuuhEQP06IqItNNr-A.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Smooth image transition (morphing) from a tiger to a human (image courtesy: Google Images)</figcaption></figure><p id="7e46" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这篇文章中，我将描述我如何使用 word2vec 的嵌入和 A*搜索算法在单词之间变形。</p><p id="8778" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了执行单词变形，我们将定义一个图<em class="ld"> G </em>，其中节点集<em class="ld"> N </em>表示单词，并且有一些非负的权重函数<em class="ld">f</em>:<em class="ld">n</em>×<em class="ld">n</em>→ℝ.给定一个起始字<em class="ld"> S </em>和一个结束字<em class="ld"> E </em>，我们的目标是在图中找到一条路径，该路径最小化由<em class="ld"> f </em>导出的权重之和:</p><figure class="lf lg lh li gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi le"><img src="../Images/f17195aacc125f6ae21e9334c0d413a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KRYJIJAkajBqEXRpXdG7Tg.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Fig. 1. Optimal path with minimal cost induced by f</figcaption></figure><p id="744e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">通常当人们谈论单词变形时，他们指的是在<em class="ld"> S </em>和<em class="ld"> E </em>之间寻找一条路径，在那里单词之间只有一条边，这样一个可以通过改变一个字母从另一个获得，正如这里可以看到的<a class="ae lj" href="http://wordmorph.sarangconsulting.com/faq.php#1.2" rel="noopener ugc nofollow" target="_blank"/>。在这种情况下，当这种变化存在时，<em class="ld"> f </em> ( <em class="ld"> n </em> ₁，<em class="ld"> n </em> ₂)为 1，否则为∞。</p><p id="d2df" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这篇文章中，我将向你展示如何在语义相似的词之间变形，也就是说<em class="ld"> f </em>将与语义相关。这里有一个例子来说明这两种方法的区别:给定<em class="ld"> S </em> = <em class="ld">齿</em>，<em class="ld"> E </em> = <em class="ld">光</em>，一次改变一个字符的方法<a class="ae lj" href="http://wordmorph.sarangconsulting.com/?source=tooth&amp;target=light&amp;submit=MORPH+WORDS" rel="noopener ugc nofollow" target="_blank">可以导致</a>出现</p><p id="8d1c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><code class="fe lk ll lm ln b">tooth, booth, boots, botts, bitts, bitos, bigos, bigot, bight, light</code></p><p id="71ee" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">虽然本文将要定义的语义方法会导致</p><p id="befd" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><code class="fe lk ll lm ln b">tooth, retina, X_ray, light</code></p><p id="9af9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">你可以在这里找到完整的代码<a class="ae lj" href="https://github.com/yoel-zeldes/yoel-zeldes.github.io/blob/source/content/word%20morph/word-morph.ipynb" rel="noopener ugc nofollow" target="_blank"/>。</p></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="fec8" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">词汇语义学</h1><p id="f5d8" class="pw-post-body-paragraph kf kg it kh b ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky mx la lb lc im bi translated">为了捕捉单词语义，我们将使用预训练的 word2vec 嵌入[1]。对于那些不熟悉该算法的人，这里有一段来自维基百科的摘录:</p><blockquote class="my"><p id="4f7e" class="mz na it bd nb nc nd ne nf ng nh lc dk translated"><em class="ni"> Word2vec 将大型文本语料库作为其输入，并产生通常具有数百维的向量空间，语料库中的每个唯一单词被分配给该空间中的相应向量。单词向量被定位在向量空间中，使得语料库中共享共同上下文的单词在空间中彼此非常接近。</em></p></blockquote><p id="b2ab" class="pw-post-body-paragraph kf kg it kh b ki nj kk kl km nk ko kp kq nl ks kt ku nm kw kx ky nn la lb lc im bi translated">这意味着图中的每个节点都可以与高维空间中的某个向量相关联(在我们的例子中是 300)。因此，我们可以自然地定义每两个节点之间的距离函数。我们将使用余弦相似度，因为这是在想要对单词嵌入进行语义比较时通常使用的度量。从现在开始，我将重载一个节点符号<em class="ld"> n </em>作为其关联单词的嵌入向量。</p><p id="48bd" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了使用 word2vec 嵌入，我们将从<a class="ae lj" href="https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&amp;export=download" rel="noopener ugc nofollow" target="_blank">这里</a>下载 Google 的预训练嵌入，并使用<code class="fe lk ll lm ln b">gensim</code>包来访问它们。</p><figure class="lf lg lh li gt ju"><div class="bz fp l di"><div class="no np l"/></div></figure></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="6fd0" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">选择权重函数</h1><p id="736e" class="pw-post-body-paragraph kf kg it kh b ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky mx la lb lc im bi translated">给定余弦相似距离函数，我们可以将我们的<em class="ld"> f </em>函数定义为</p><figure class="lf lg lh li gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nq"><img src="../Images/7cd074a0962a7ca223424926e8bb1dca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OWhZq_EtzuwW9OL3sIYdRg.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Eq. 1. Definition of weight function using cosine similarity</figcaption></figure><p id="47de" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">然而，使用这种方法，我们将面临一个问题:最佳路径可能包括具有高权重的边，这将导致语义不相似的连续单词。</p><p id="7297" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">为了解决这个问题，我们可以将<em class="ld"> f </em>改为</p><figure class="lf lg lh li gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nr"><img src="../Images/848ba9cb414a37aef559aca2fac17a28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LLJp-pPk6JvVURQnUvYyxA.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Eq. 2. Definition of weight function using cosine similarity limited to nearest neighbors</figcaption></figure><p id="4a1a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">其中<em class="ld">邻居</em> ( <em class="ld"> n </em> ₁)表示在余弦相似性方面，图中距离<em class="ld"> n </em> ₁最近的节点。邻居的数量是可配置的。</p></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="52e1" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">A*搜索</h1><p id="ebc2" class="pw-post-body-paragraph kf kg it kh b ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky mx la lb lc im bi translated">现在我们已经定义了我们的图，我们将使用一个众所周知的搜索算法 A* [2]。</p><p id="d8ce" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在该算法中，每个节点都有一个由两项组成的成本-<em class="ld">g</em>(<em class="ld">n</em>)+<em class="ld">h</em>(<em class="ld">n</em>)。</p><p id="92c4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><em class="ld"> g </em> ( <em class="ld"> n </em>)是从<em class="ld"> S </em>到<em class="ld"> n </em>的最短路径的代价，<em class="ld"> h </em> ( <em class="ld"> n </em>)是估算从<em class="ld"> n </em>到<em class="ld"> E </em>的最短路径的代价的启发式方法。在我们的例子中，启发式函数将是<em class="ld"> f </em>。</p><p id="92f9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">搜索算法维护一个叫做<em class="ld">开集</em>的数据结构。最初，这个集合包含<em class="ld"> S </em>，在算法的每次迭代中，我们弹出开集中具有最小成本<em class="ld">g</em>(<em class="ld">n</em>)+<em class="ld">h</em>(<em class="ld">n</em>)的节点，并将其邻居添加到开集。当具有最小成本的节点是<em class="ld"> E </em>时，算法停止。</p><p id="9a53" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这个算法适用于我们选择的任何启发式函数。但是，为了实际找到最佳路径，启发式函数必须是可接受的，这意味着它不能高估真实成本。不幸的是，<em class="ld"> f </em>是不可接受的。然而，我们将使用<a class="ae lj" href="https://en.wikipedia.org/wiki/Cosine_similarity#Properties" rel="noopener ugc nofollow" target="_blank">观察结果</a>,即如果向量长度为 1，那么余弦相似性可以通过欧几里德距离上的单调变换来获得。这意味着这两个词在相似度排序方面是可以互换的。欧几里德距离是容许的(你可以用三角形不等式来证明它)，所以我们可以用它来代替，通过定义</p><figure class="lf lg lh li gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ns"><img src="../Images/e345d22395ea229123ff2e386a0fb890.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ukgz0ahhaN-0ncx_tmDVdA.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Eq. 3. Definition of weight function using euclidean distance</figcaption></figure><p id="3a02" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">总之，我们将标准化单词嵌入，使用欧几里得距离作为寻找语义相似的单词的手段，并使用相同的欧几里得距离来指导搜索过程，以便找到最佳路径。</p><figure class="lf lg lh li gt ju"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="4b6e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我选择了<em class="ld">邻居</em> ( <em class="ld"> n </em>)来包含它的 1000 个最近的节点。然而，为了使搜索更有效，我们可以使用 10 的<code class="fe lk ll lm ln b">dilute_factor</code>来稀释这些:我们选择最近的邻居、第 10 个最近的邻居、第 20 个邻居等等——直到我们有 100 个节点。其背后的直觉是，从某个中间节点到<em class="ld"> E </em>的最佳路径可能经过其最近的邻居。如果它不通过，可能也不会通过第二个邻居，因为第一个和第二个邻居可能几乎相同。所以为了节省一些计算，我们跳过一些最近的邻居。</p><p id="a51c" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">有趣的部分来了:</p><figure class="lf lg lh li gt ju"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="f224" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">结果是:</p><pre class="lf lg lh li gt nt ln nu nv aw nw bi"><span id="5712" class="nx lw it ln b gy ny nz l oa ob">['tooth', u'retina', u'X_ray', u'light']<br/>['John', u'George', u'Frank_Sinatra', u'Wonderful', u'perfect']<br/>['pillow', u'plastic_bag', u'pickup_truck', u'car']</span></pre></div><div class="ab cl lo lp hx lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="im in io ip iq"><h1 id="e35a" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">最后的想法</h1><p id="5dfc" class="pw-post-body-paragraph kf kg it kh b ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky mx la lb lc im bi translated">实现单词变形项目很有趣，但没有在我能想到的任何一对单词上玩这个工具有趣。我鼓励你继续前进，自己玩这个游戏。请在评论中告诉我你发现了哪些有趣和令人惊讶的变形:)</p><p id="7129" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><em class="ld">本帖原帖</em><a class="ae lj" href="http://www.anotherdatum.com" rel="noopener ugc nofollow" target="_blank"><em class="ld">www.anotherdatum.com</em></a><em class="ld">。</em></p><h2 id="1f63" class="nx lw it bd lx oc od dn mb oe of dp mf kq og oh mj ku oi oj mn ky ok ol mr om bi translated">参考</h2><p id="cc6f" class="pw-post-body-paragraph kf kg it kh b ki mt kk kl km mu ko kp kq mv ks kt ku mw kw kx ky mx la lb lc im bi translated">[1]<a class="ae lj" href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality" rel="noopener ugc nofollow" target="_blank">https://papers . nips . cc/paper/5021-distributed-presentations-of-words-and-phrases-and-they-compositivity</a><br/>【2】<a class="ae lj" href="https://www.cs.auckland.ac.nz/courses/compsci709s2c/resources/Mike.d/astarNilsson.pdf" rel="noopener ugc nofollow" target="_blank">https://www . cs . Auckland . AC . NZ/courses/compsci 709s 2 c/resources/Mike . d/astarnilsson . pdf</a></p></div></div>    
</body>
</html>