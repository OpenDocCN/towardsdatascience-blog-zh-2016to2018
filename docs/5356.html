<html>
<head>
<title>The Tale of 1001 Black Boxes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">1001 个黑盒的故事</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-tale-of-1001-black-boxes-62d12b5886aa?source=collection_archive---------18-----------------------#2018-10-12">https://towardsdatascience.com/the-tale-of-1001-black-boxes-62d12b5886aa?source=collection_archive---------18-----------------------#2018-10-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="cfd8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">或者为什么我认为亚马逊“种族主义”人工智能的故事实际上留下了乐观的空间</strong></p><p id="bc0c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你能上网，并且对人工智能感兴趣，你会偶然发现亚马逊最近的一个故事，它试图建立一个机器学习算法(或花哨的术语“人工智能”)来使<a class="ae kl" href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G" rel="noopener ugc nofollow" target="_blank">的招聘过程</a>自动化，结果发现它会惩罚包含“女性”一词的简历(例如，所有女子大学的候选人)。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="kr ks l"/></div></figure><p id="26c4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如任何季节性的“AI 变坏”新闻故事一样，首先必须打破一些神话。通常的反对意见通常有以下几种形式:<em class="kt">“如果女子学院的毕业生真的不够格，为什么惩罚她们就应该算作歧视呢？”</em></p><p id="9750" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">记住上下文在这里是至关重要的。通过使用自己的招聘记录作为训练数据，亚马逊<strong class="jp ir">没有</strong>建立一个人工智能来学习如何聘用<em class="kt">成功的</em>候选人；根据定义，它所能做的就是建立一个人工智能，模仿它当前的招聘实践。这看似琐碎，但这一点被很多人忽略了。这就是语境的作用:我们有任何理由相信亚马逊的招聘行为没有偏见吗？</p><p id="1a8b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">很久以前就已经确定，作为人类，我们的决策充满了各种各样的偏见。具体来说，在科技行业的招聘中，最常见的一种被称为“<a class="ae kl" href="https://en.wikipedia.org/wiki/Confirmation_bias" rel="noopener ugc nofollow" target="_blank">确认偏差</a>”。在早期，我们建立了一些成功的原型，我们倾向于寻找其他符合这些原型的人。当每一次“招聘”都是一项昂贵的投资时，<strong class="jp ir">科技公司倾向于“利用”他们对成功候选人的现有理解，而不是“探索”</strong>(给其他人机会，他们看起来不像典型的成功候选人，以证明他们的技能)。</p></div><div class="ab cl ku kv hu kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ij ik il im in"><p id="e370" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好的，我们已经确定了 ML 是一个黑箱，它会使我们自己的偏见永久化。这能带来什么好处呢？</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="gh gi lb"><img src="../Images/1864c1402941540b0a21fdc9bc09b60f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JRbsmGgtIWJS0g7i"/></div></div><figcaption class="li lj gj gh gi lk ll bd b be z dk">Picture from <a class="ae kl" href="https://www.pexels.com/photo/pile-of-black-shoe-box-next-to-wall-220685/" rel="noopener ugc nofollow" target="_blank">Pexels</a></figcaption></figure><p id="d4bd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我的观点是，现实世界中的人类决策过程可能比单个黑盒更糟糕。我们称之为<strong class="jp ir">“亚马逊的招聘流程”</strong>的实体由如此多的移动部分组成:它是一个由招聘人员、招聘经理和面试官组成的层级——每个人都有自己可能的偏见和怪癖——他们不一定遵循一个规定的议程。形象地说，<strong class="jp ir">是一千个黑箱</strong>。</p><p id="97db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种结构意味着试图梳理出实际歧视的证据可能具有挑战性；亚马逊做出的每一个招聘决定都是可以否认的，因为它被归因于一个“有问题的”盒子(你读过多少次“这只是 X，Y，Z；这不代表我们公司的政策吗”？).</p><p id="17a0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就是为什么戴上一副合适的眼镜，ML 的进入可以被视为塞翁失马，焉知非福。当人类决策变得“算法化”时，它<em class="kt">就变成了</em>从输入(个人)到结果(决策)的明确映射。是的，这种映射对我们人类来说似乎极其复杂——就我们所知，是一个“黑盒”——但至少它是<strong class="jp ir">的一个</strong>这样的盒子。</p><p id="740e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过对其历史招聘决策训练 ML 算法，亚马逊捕捉到了其决策过程的<em class="kt">系统</em>方面，即超越单一决策的方面。<strong class="jp ir">亚马逊实际上将其 1000 个黑匣子减少到只有一个</strong>。现在，仔细检查这个盒子(例如，通过检查通过将个人“喂入”黑盒获得的输入输出对，并观察预测的结果)可以为关于原始的、复杂的实体(即亚马逊的招聘实践)的假设提供更有力的基础。在这种情况下，它确实揭示了(或实现了推测)它的某些方面构成了明显的歧视候选人。</p><p id="5d3e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是<em class="kt">而不是</em>说我们应该在敏感领域不经意地调用机器学习。亚马逊的故事是众多证明这显然是一个坏主意的例子之一，而且有越来越多的研究人员(我非常高兴成为其中的一员)正在仔细研究这些问题。这是试图说，尽管有太多的负面结果，关于 ML 可能促成的所有“坏事”，我们应该记住有一个潜在的积极前景:<em class="kt">如果使用得当，算法化可以作为一种工具，更好地理解和改进我们自己的实践。</em></p></div></div>    
</body>
</html>