<html>
<head>
<title>Monte Carlo Tree Search</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">蒙特卡罗树搜索</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/monte-carlo-tree-search-158a917a8baa?source=collection_archive---------0-----------------------#2018-08-01">https://towardsdatascience.com/monte-carlo-tree-search-158a917a8baa?source=collection_archive---------0-----------------------#2018-08-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5588" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">每个数据科学爱好者的 MCTS</h2></div><p id="25c4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">像井字游戏、魔方游戏、数独游戏、国际象棋、围棋和许多其他游戏都有一个共同的属性，那就是可以玩的动作数量呈指数增长。随着游戏的进行，这些可能的步骤会成倍增加。理想情况下，如果你能预测未来可能发生的每一个可能的举动及其结果。可以增加自己的胜算。</p><p id="5b1a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是，由于移动呈指数增长，计算移动所需的计算能力也达到了顶点。</p><p id="fd71" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">蒙特卡洛树搜索是一种通常在游戏中使用的方法，用于预测策略应该采取的路径(移动)以达到最终的获胜解决方案。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lb"><img src="../Images/8bc6b9847e73bf3164177af827a4e52b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*LgpukIxbNKbZi9PohRh4zA.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Final output could be any one of these</figcaption></figure><p id="6dd3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们发现引导我们走向胜利的正确道路(步骤)之前。我们首先需要安排游戏当前状态的移动。这些动作连接在一起会看起来像一棵树。因此得名<em class="ln">树搜索</em>。请参见下图，了解移动的突然指数增长。</p><h2 id="73a1" class="lo lp iq bd lq lr ls dn lt lu lv dp lw ko lx ly lz ks ma mb mc kw md me mf mg bi translated"><strong class="ak">树形搜索算法</strong></h2><blockquote class="mh mi mj"><p id="4654" class="kf kg ln kh b ki kj jr kk kl km ju kn mk kp kq kr ml kt ku kv mm kx ky kz la ij bi translated">这是一种用于搜索游戏回合后可能存在的每一步棋的方法。例如:在井字游戏中，玩家有许多不同的选择，可以用树形图来表示。在下一轮将图表演变成树时，移动可以进一步增加。</p></blockquote><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mn"><img src="../Images/492a2153131cd40a69bed9ad7e2a3ed0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hQgJNK1LGYpXzFjBVxnREw.jpeg"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk"><a class="ae ms" href="http://cse3521.artifice.cc/adversarial-search.html" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="3aee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过考虑每个子移动/节点来强制指数增长树找到问题的最终解决方案需要大量的计算能力。导致极慢的输出。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><p id="e102" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">💡</strong>通过制定策略可以实现更快的树搜索——给予一些节点比其他节点更大的重要性&amp;允许首先搜索它们的子节点以获得正确的解决方案。</p><p id="ce05" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">而是如何找到最有利于在它们子节点中具有正确解的节点。让我们来看看…</p><h2 id="9b1a" class="lo lp iq bd lq lr ls dn lt lu lv dp lw ko lx ly lz ks ma mb mc kw md me mf mg bi translated">什么是蒙特卡罗树搜索？</h2><blockquote class="mh mi mj"><p id="8f3a" class="kf kg ln kh b ki kj jr kk kl km ju kn mk kp kq kr ml kt ku kv mm kx ky kz la ij bi translated">MCTS 是一种算法，它通过选择→扩展→模拟→更新树中的节点来找出一组移动中的最佳移动，以找到最终的解决方案。这个方法一直重复，直到达到解，学习到博弈的策略。</p></blockquote><h2 id="7641" class="lo lp iq bd lq lr ls dn lt lu lv dp lw ko lx ly lz ks ma mb mc kw md me mf mg bi translated">蒙特卡洛树搜索是如何工作的？</h2><p id="f7b4" class="pw-post-body-paragraph kf kg iq kh b ki na jr kk kl nb ju kn ko nc kq kr ks nd ku kv kw ne ky kz la ij bi translated">让我们逐一查看循环的各个部分。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nf"><img src="../Images/89af52955c58d35045be753084df2a67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OpJz2LcElVB_XPEYAvK87Q.jpeg"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk"><strong class="bd ng">SELECTION</strong></figcaption></figure><p id="0318" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">选择👆</strong> |此过程用于选择树上最有可能获胜的节点。例如—考虑有获胜可能性的棋<code class="fe nh ni nj nk b">2/3,</code> <code class="fe nh ni nj nk b">0/1</code> &amp; <code class="fe nh ni nj nk b">1/2</code>在第一步<code class="fe nh ni nj nk b">4/6</code>之后，节点<code class="fe nh ni nj nk b"><strong class="kh ir">2/3</strong></code>获胜的可能性最高。</p><p id="57b7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从树的当前状态中搜索选定的节点，并且选定的节点位于分支的末端。由于所选节点获胜的可能性最高，因此该路径也最有可能比树中的其他路径更快地到达解决方案。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/aa43edf0df0cec50c38f8e177c02f477.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*3FaNj57GNMpUfRgkbkq7fA.jpeg"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk"><strong class="bd ng">EXPANSION</strong></figcaption></figure><p id="f4a4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">展开— </strong>选择正确的节点后。扩展<strong class="kh ir"> </strong>用于在游戏中进一步增加选项，方法是扩展选中的节点并创建许多子节点。在这种情况下，我们只使用一个子节点。这些子节点是游戏中可以玩的未来招式。</p><p id="b38b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">暂时没有进一步展开的节点称为叶子。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi nl"><img src="../Images/0f37439c59ae37637e3d54327107be32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*B-7GJKfo5BNaCJObi_ml_g.jpeg"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk"><strong class="bd ng">SIMULATION</strong></figcaption></figure><p id="fe65" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">模拟|探索🚀因为没有人知道哪个节点是组中最好的孩子/叶子。这一步将表现最好，并导致正确的答案。但是，</strong></p><p id="065e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> <em class="ln">我们如何找到最优秀的孩子，从而引导我们找到正确的解决方案？</em> </strong></p><p id="994b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们使用强化学习在游戏中从每一个孩子节点往下随机决策。然后，奖励被给予每个子节点——通过计算他们随机决策的输出与我们赢得游戏所需的最终输出有多接近。</p><p id="b07e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">比如:</strong>井字游戏中。<strong class="kh ir"> </strong>随机决定在游戏中的前一个十字(X)旁边做十字(X)会导致赢得游戏所需的三个连续十字(X-X-X)吗？</p><blockquote class="mh mi mj"><p id="1216" class="kf kg ln kh b ki kj jr kk kl km ju kn mk kp kq kr ml kt ku kv mm kx ky kz la ij bi translated">仅供参考:这可以认为是 RL 算法的策略<code class="fe nh ni nj nk b">π</code>。了解有关政策&amp;价值网络的更多信息…</p></blockquote><div class="nm nn gp gr no np"><a rel="noopener follow" target="_blank" href="/policy-networks-vs-value-networks-in-reinforcement-learning-da2776056ad2"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd ir gy z fp nu fr fs nv fu fw ip bi translated">强化学习中的政策网络与价值网络</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">在强化学习中，代理在他们的环境中采取随机决策，并学习选择正确的决策…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">towardsdatascience.com</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od lh np"/></div></div></a></div><p id="1c90" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对每个孩子节点进行模拟，然后是他们各自的奖励。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/27d6612ca7443672d31eeb1be2b9fa67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*fb7wR8yryHJuX31WHhLaSg.jpeg"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk"><strong class="bd ng">UPDATING | BACK-PROPAGATION</strong></figcaption></figure><p id="dcde" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设节点的模拟对其未来给出了乐观的结果，并得到了 1/1 的正分数。</p><p id="dd73" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">更新|反向传播— </strong>由于环境中的新节点及其<em class="ln">正或负</em>分数。它们的父节点的总分数必须通过一个接一个地回到树上来更新。新的更新分数改变了树的状态，并且还可以改变选择过程的新的未来节点。</p></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><p id="8d4b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在更新所有节点之后，通过选择树中的最佳节点→ <em class="ln">扩展所选节点的</em>→使用 RL 进行模拟探索→ <em class="ln">反向传播</em>更新的分数→然后最终<em class="ln">选择</em>树中更靠下的新节点，这实际上是所需的最终获胜结果。</p><p id="f7ce" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">比如:解决了魔方，数独的正确解法，象棋中的杀王或者</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lb"><img src="../Images/8bc6b9847e73bf3164177af827a4e52b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*LgpukIxbNKbZi9PohRh4zA.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Final Required Solution of TIC-TAC-TOE</figcaption></figure></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h2 id="5da5" class="lo lp iq bd lq lr ls dn lt lu lv dp lw ko lx ly lz ks ma mb mc kw md me mf mg bi translated">结论</h2><p id="1439" class="pw-post-body-paragraph kf kg iq kh b ki na jr kk kl nb ju kn ko nc kq kr ks nd ku kv kw ne ky kz la ij bi translated">而不是从数百万种可能的方式中蛮力寻找正确的路径。</p><blockquote class="of"><p id="2c30" class="og oh iq bd oi oj ok ol om on oo la dk translated">蒙特卡洛树搜索算法在强化学习的帮助下，从游戏树的当前状态中选择最佳可能的移动。</p></blockquote><p id="a94c" class="pw-post-body-paragraph kf kg iq kh b ki op jr kk kl oq ju kn ko or kq kr ks os ku kv kw ot ky kz la ij bi translated">感谢您阅读这篇文章。如果你有任何疑问或者只是想谈谈数据科学，请写在下面的评论中。</p><h2 id="17ab" class="lo lp iq bd lq lr ls dn lt lu lv dp lw ko lx ly lz ks ma mb mc kw md me mf mg bi translated">鼓掌吧！分享一下！跟我来。</h2><p id="3b74" class="pw-post-body-paragraph kf kg iq kh b ki na jr kk kl nb ju kn ko nc kq kr ks nd ku kv kw ne ky kz la ij bi translated">关注我的<a class="ae ms" href="https://medium.com/@sagarsharma4244" rel="noopener"> <strong class="kh ir">中</strong> </a>和<a class="ae ms" href="https://twitter.com/SagarSharma4244" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">推特</strong> </a>获取更多类似内容。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><a href="https://twitter.com/SagarSharma4244"><div class="gh gi ou"><img src="../Images/ce2f13e1aad357cb162c5550d2fd4868.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*YnbtD8IipCsqVjNwkjtY8w.png"/></div></a></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><a href="https://medium.com/@sagarsharma4244"><div class="gh gi ou"><img src="../Images/ca235e42e4e86914843b9fd55288374d.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*dBbsLTjkdMA45vnfBMbkGQ.png"/></div></a></figure></div><div class="ab cl mt mu hu mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="ij ik il im in"><h1 id="e3b2" class="ov lp iq bd lq ow ox oy lt oz pa pb lw jw pc jx lz jz pd ka mc kc pe kd mf pf bi translated">你会喜欢的以前的故事:</h1><div class="nm nn gp gr no np"><a rel="noopener follow" target="_blank" href="/activation-functions-neural-networks-1cbd9f8d91d6"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd ir gy z fp nu fr fs nv fu fw ip bi translated">激活函数:神经网络</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">Sigmoid，tanh，Softmax，ReLU，Leaky ReLU 解释！！！</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">towardsdatascience.com</p></div></div><div class="ny l"><div class="pg l oa ob oc ny od lh np"/></div></div></a></div><div class="nm nn gp gr no np"><a rel="noopener follow" target="_blank" href="/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd ir gy z fp nu fr fs nv fu fw ip bi translated">纪元与批量大小与迭代次数</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">了解您的代码…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">towardsdatascience.com</p></div></div><div class="ny l"><div class="ph l oa ob oc ny od lh np"/></div></div></a></div><div class="nm nn gp gr no np"><a rel="noopener follow" target="_blank" href="/50-tensorflow-js-api-explained-in-5-minutes-tensorflow-js-cheetsheet-4f8c7f9cc8b2"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd ir gy z fp nu fr fs nv fu fw ip bi translated">50 tensor flow . js API 5 分钟讲解| TensorFlow.js Cheetsheet</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">TensorFlow API Cheetsheet</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">towardsdatascience.com</p></div></div><div class="ny l"><div class="pi l oa ob oc ny od lh np"/></div></div></a></div><div class="nm nn gp gr no np"><a rel="noopener follow" target="_blank" href="/tensorflow-on-mobile-tutorial-1-744703297267"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd ir gy z fp nu fr fs nv fu fw ip bi translated">手机上的 TensorFlow:教程</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">在 Android 和 iOS 上</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">towardsdatascience.com</p></div></div><div class="ny l"><div class="pj l oa ob oc ny od lh np"/></div></div></a></div><div class="nm nn gp gr no np"><a rel="noopener follow" target="_blank" href="/playing-atari-with-6-neurons-open-source-code-b94c764452ac"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd ir gy z fp nu fr fs nv fu fw ip bi translated">用 6 个神经元玩雅达利|开源代码</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">#2 研究论文解释</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">towardsdatascience.com</p></div></div><div class="ny l"><div class="pk l oa ob oc ny od lh np"/></div></div></a></div></div></div>    
</body>
</html>