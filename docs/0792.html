<html>
<head>
<title>Steering Self Driving Car without LIDAR</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无激光雷达自动驾驶汽车转向</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/steering-self-driving-car-without-lidar-a6b0a4d2e2f1?source=collection_archive---------4-----------------------#2017-06-22">https://towardsdatascience.com/steering-self-driving-car-without-lidar-a6b0a4d2e2f1?source=collection_archive---------4-----------------------#2017-06-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="6a37" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">自动驾驶汽车使用各种技术来检测周围环境，如<a class="ae kl" href="https://en.wikipedia.org/wiki/Radar" rel="noopener ugc nofollow" target="_blank">雷达</a>、<a class="ae kl" href="https://en.wikipedia.org/wiki/Lidar" rel="noopener ugc nofollow" target="_blank">激光</a>、<a class="ae kl" href="https://en.wikipedia.org/wiki/GPS" rel="noopener ugc nofollow" target="_blank"> GPS </a>、<a class="ae kl" href="https://en.wikipedia.org/wiki/Odometry" rel="noopener ugc nofollow" target="_blank">里程计</a>和<a class="ae kl" href="https://en.wikipedia.org/wiki/Computer_vision" rel="noopener ugc nofollow" target="_blank">计算机视觉</a>。S <a class="ae kl" href="https://en.wikipedia.org/wiki/Sensory_information" rel="noopener ugc nofollow" target="_blank">传感器信息</a>用于识别导航路径、障碍物和路标。自动驾驶汽车的控制系统能够分析传感数据，以区分道路上的不同汽车，检测车道线并预测转向角度</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/4b7ab713a6a668b5651c958687f89755.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DoFDxYst6-7BUaOLSK3yyw.jpeg"/></div></div></figure><p id="8d08" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">像<a class="ae kl" href="https://en.wikipedia.org/wiki/Lidar" rel="noopener ugc nofollow" target="_blank">激光雷达</a>这样的传感器很贵。激光雷达的领先制造商威力登公司以8000美元的价格出售其目前用于原型机器人汽车的机械旋转激光雷达设备。有没有可能使用简单的相机图像和其他负担得起的感官数据来让自动驾驶汽车在道路上行驶？</p><p id="687f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于行为克隆<a class="ae kl" href="https://github.com/linux-devil/behavioral-cloning" rel="noopener ugc nofollow" target="_blank">项目</a>的想法是训练一个深度神经网络来克隆驾驶行为，以预测转向角度。<a class="ae kl" href="https://www.udacity.com/" rel="noopener ugc nofollow" target="_blank"> Udacity的</a>模拟器用于收集训练数据，也用于测试模型性能。训练数据由来自不同摄像机(中央、左侧和右侧)的一系列图像以及油门、速度、转向角度和制动的相应测量值组成。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ky"><img src="../Images/1e330e4a21483b7ae040c83a4c27c44c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ev4u5K-B3Ha6FWiR1LSkwQ.jpeg"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Udacity Simulator</figcaption></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ld"><img src="../Images/2a394586aa10e2a1c81ec5033c50f984.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*Q73OJsChkvUEt2PdkYaXyg.jpeg"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Training image from simulator</figcaption></figure><p id="84ce" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于左边的图像，我们在模拟器上驾驶这辆车后记录了转向角测量值。在模拟器上记录4圈的训练数据</p><p id="16e8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">每个图像的尺寸为160×320×3(RGB图像),进一步用于训练深度神经网络以预测转向角。在我进入模型架构之前，让我给你看一下汽车在模拟器中自动驾驶的视频。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="le lf l"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Behavioral Cloning Track Simulation</figcaption></figure><p id="4bad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">我使用的CNN </a>架构的灵感来自<a class="ae kl" href="https://arxiv.org/pdf/1604.07316v1.pdf" rel="noopener ugc nofollow" target="_blank"> Nvidia的架构</a>:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lg"><img src="../Images/4ba5c732165e8e14940cf8b88f4736a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*pHFQwKzLXcz38AkKLmP6pw.png"/></div></figure><h2 id="a8ad" class="lh li iq bd lj lk ll dn lm ln lo dp lp jy lq lr ls kc lt lu lv kg lw lx ly lz bi translated">数据预处理</h2><p id="7061" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">使用模拟器160 x 320 x 3尺寸(RGB图像)获得的训练图像，因为模拟器转向角训练期间的大部分时间为零。我不得不在零转向角的情况下随机清除80%的数据。这是在预测过程中考虑偏差所必需的。并且为了更好的预测，RGB图像也被裁剪并转换到HLS颜色空间。裁剪是必要的，因为它有助于从数据中去除噪声，因为与天空和风景相比，转向角度更依赖于对道路和转弯的感知。不用说，模型在进行数据预处理后表现得更好。</p><p id="821a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当lap向任一方向(左或右)转弯时，即使训练后数据也可能有偏差。为了避免这种情况，cv2。<a class="ae kl" href="http://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html#void flip(InputArray src, OutputArray dst, int flipCode)" rel="noopener ugc nofollow" target="_blank"> flip </a>用于扩充数据并生成更多数据集。左右图像用于恢复，转向校正系数为0.20。</p><h2 id="711a" class="lh li iq bd lj lk ll dn lm ln lo dp lp jy lq lr ls kc lt lu lv kg lw lx ly lz bi translated">神经网络结构和超参数</h2><p id="53cc" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">在探索了comma.ai和Nvidia的架构之后，我决定从简单的架构开始。想法是从简单开始，如果需要，增加更多的复杂性。架构与上面张贴的图表相同。应用5%的下降以避免过度拟合，并且所有层都跟随有RELU激活，以便引入非线性。</p><p id="85ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">“MSE”用于计算优化器的损失和“adam”。我发现这个<a class="ae kl" href="http://sebastianruder.com/optimizing-gradient-descent/index.html#adam" rel="noopener ugc nofollow" target="_blank">博客</a>真的有助于理解不同的梯度下降优化算法。五个时期用于20%验证分割的训练。经过五个时期的训练后，我的训练损失大约为3 %,验证损失大约为5%。</p><h2 id="8705" class="lh li iq bd lj lk ll dn lm ln lo dp lp jy lq lr ls kc lt lu lv kg lw lx ly lz bi translated">结论和讨论</h2><p id="b96a" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated">虽然这个项目很有挑战性，但最终在模拟器中看到汽车自动驾驶的快乐让我意识到这是值得努力的。仔细收集训练数据很重要。我也不确定这种技术在弱光条件下是否有效。不用说，深度学习，或一类机器学习算法，正显示出巨大的前景，主要是因为它正在取得成果。我相信还有很多不同的技术有待探索，但这是一个很好的开始。</p><p id="41e9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是<a class="ae kl" href="https://github.com/linux-devil/behavioral-cloning" rel="noopener ugc nofollow" target="_blank">链接</a>到我的github repo与<a class="ae kl" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> keras </a>实现上面的代码并写上去。</p><h2 id="51e2" class="lh li iq bd lj lk ll dn lm ln lo dp lp jy lq lr ls kc lt lu lv kg lw lx ly lz bi translated">参考</h2><p id="0a7d" class="pw-post-body-paragraph jn jo iq jp b jq ma js jt ju mb jw jx jy mc ka kb kc md ke kf kg me ki kj kk ij bi translated"><a class="ae kl" href="https://www.udacity.com/drive" rel="noopener ugc nofollow" target="_blank"> Udacity </a>自动驾驶汽车工程师纳米学位。</p><p id="064d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">关于卷积神经网络的<a class="ae kl" href="http://cs231n.github.io/" rel="noopener ugc nofollow" target="_blank"> CS231n </a>课程和<a class="mf mg ep" href="https://medium.com/u/ac9d9a35533e?source=post_page-----a6b0a4d2e2f1--------------------------------" rel="noopener" target="_blank">安德烈·卡帕西</a>的<a class="ae kl" href="https://www.youtube.com/watch?v=g-PvXUjD6qg&amp;list=PLlJy-eBtNFt6EuMxFYRiNRS07MCWN5UIA" rel="noopener ugc nofollow" target="_blank">视频讲座</a>。</p><p id="b6fa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我的github回购:<a class="ae kl" href="https://github.com/linux-devil/behavioral-cloning" rel="noopener ugc nofollow" target="_blank">https://github.com/linux-devil/behavioral-cloning</a></p><p id="d3ca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">英伟达<a class="ae kl" href="https://arxiv.org/pdf/1604.07316v1.pdf" rel="noopener ugc nofollow" target="_blank">架构</a></p><p id="1012" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Comma.ai <a class="ae kl" href="https://github.com/commaai/research" rel="noopener ugc nofollow" target="_blank">架构</a></p><p id="9df3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://github.com/udacity/CarND-Behavioral-Cloning-P3" rel="noopener ugc nofollow" target="_blank">行为克隆项目</a></p></div></div>    
</body>
</html>