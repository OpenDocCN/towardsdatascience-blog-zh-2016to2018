<html>
<head>
<title>Deep Learning meets Physics: Restricted Boltzmann Machines Part II</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习遇上物理学:受限玻尔兹曼机器第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-meets-physics-restricted-boltzmann-machines-part-ii-4b159dce1ffb?source=collection_archive---------5-----------------------#2018-05-10">https://towardsdatascience.com/deep-learning-meets-physics-restricted-boltzmann-machines-part-ii-4b159dce1ffb?source=collection_archive---------5-----------------------#2018-05-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="09ed" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">建造你自己的受限玻尔兹曼机器</h2></div><p id="fa65" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">本文是</strong><strong class="kk iu"/><a class="ae le" rel="noopener" target="_blank" href="/deep-learning-meets-physics-restricted-boltzmann-machines-part-i-6df5c4918c15"><strong class="kk iu">的续篇，第一部分</strong> </a> <strong class="kk iu">在这里我介绍了受限玻尔兹曼机背后的理论。该第二部分包括通过受限玻尔兹曼机器的实际实现的逐步指导，该受限玻尔兹曼机器用作推荐系统，并且可以基于用户的喜好来预测用户是否喜欢电影。</strong></p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/5cda38e723b01463dcaf9dfd6d0fabbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9HZMP0Nkc0OkiW7ryfS3gw.png"/></div></div></figure><blockquote class="lr ls lt"><p id="e2c8" class="ki kj lu kk b kl km ju kn ko kp jx kq lv ks kt ku lw kw kx ky lx la lb lc ld im bi translated">(1)在本文中，我不会涉及我所做的步骤背后的理论，我将只解释实际的部分。请务必通过复习本系列第一部分来更新您的理论知识。</p><p id="825f" class="ki kj lu kk b kl km ju kn ko kp jx kq lv ks kt ku lw kw kx ky lx la lb lc ld im bi translated">(2)我在本文中展示的代码来自我在 GitHub 上的<a class="ae le" href="https://github.com/artem-oppermann/Restricted-Boltzmann-Machine" rel="noopener ugc nofollow" target="_blank">项目资源库。因为我只关注模型的实现，所以我跳过了一些预处理步骤，比如将数据分成训练/测试集以及构建输入管道。可以在存储库中检查这些步骤。</a></p></blockquote><h2 id="2d6c" class="ly lz it bd ma mb mc dn md me mf dp mg kr mh mi mj kv mk ml mm kz mn mo mp mq bi translated">先决条件</h2><ul class=""><li id="260f" class="mr ms it kk b kl mt ko mu kr mv kv mw kz mx ld my mz na nb bi translated"><em class="lu"> Python </em> 3.6</li><li id="4514" class="mr ms it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated"><em class="lu">张量流</em> 1.5 或更高</li><li id="396b" class="mr ms it kk b kl nc ko nd kr ne kv nf kz ng ld my mz na nb bi translated">1.11 或更高版本</li></ul><h2 id="d068" class="ly lz it bd ma mb mc dn md me mf dp mg kr mh mi mj kv mk ml mm kz mn mo mp mq bi translated">资料组</h2><p id="177f" class="pw-post-body-paragraph ki kj it kk b kl mt ju kn ko mu jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">我们使用的是<a class="ae le" href="https://grouplens.org/datasets/movielens/" rel="noopener ugc nofollow" target="_blank"> MovieLens 1M 数据集</a>。该集合包含由大约 6000 个用户制作的大约 4000 部电影的 100 万个评级。该模型将在这个数据集上进行训练，并将学习预测用户是否喜欢随机电影。数据集需要一些重新处理步骤。因为通常的受限玻尔兹曼机器只接受二进制值，所以有必要给等级 1-2 一个 0 值——因此用户不喜欢这部电影。相应地，等级 3-5 的值为 1。尚未分级的电影的值为-1。</p><p id="ad38" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在下一步中，转换后的原始数据被分成两个独立的训练和测试数据集。这是必要的两个完全相同的用户在两个数据集，但不同的电影评级。图 1 示出了将原始数据集划分成训练和测试数据的简单示例。在此示例中，前 5 个评级被放入训练集，而其余的用-1 屏蔽，表示尚未评级。相应地，测试集接收剩余的 5 个等级。</p><p id="59c0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在训练时间期间，受限的 Boltzmann 机器学习每个用户的前 5 部电影评级，而在推断时间期间，该模型试图预测后 5 部电影的评级。然后，将这些预测的评级与放入测试集的实际评级进行比较。</p><p id="bfce" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">两个数据集都以二进制<em class="lu"> TFRecords </em>格式保存，这使得数据输入管道非常高效。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/57571c253a6036b87992dcdefbb00a7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*7HtJjWXu8WJ4OApcC5ROIw.png"/></div><figcaption class="nl nm gj gh gi nn no bd b be z dk">Fig. 1. Partitioning of the data into training and test datasets.</figcaption></figure><h2 id="8fbd" class="ly lz it bd ma mb mc dn md me mf dp mg kr mh mi mj kv mk ml mm kz mn mo mp mq bi translated">模型架构</h2><p id="6583" class="pw-post-body-paragraph ki kj it kk b kl mt ju kn ko mu jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">该模型以面向对象的方式实现。受限玻尔兹曼机器是一个具有所有必要操作的类，如训练、丢失、精确、推理等。在里面。一些助手功能被外包到一个单独的脚本中。</p><p id="9ce3" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">构造函数为权重和偏差设置内核初始化器。在下一步中，网络中的所有权重和偏差都被初始化。权重呈正态分布，平均值为 0.0，方差为 0.02，而偏差在开始时都设置为 0.0。可以注意到，网络仅由一个隐藏层组成。结果，只需要一个权重矩阵。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="892b" class="ly lz it bd ma mb mc dn md me mf dp mg kr mh mi mj kv mk ml mm kz mn mo mp mq bi translated"><strong class="ak">采样隐藏的</strong>状态</h2><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/050b8a5a7083b862b4d4e658c7c4427f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*Z8o2XfA7c6PSPrzShYaGZw.png"/></div><figcaption class="nl nm gj gh gi nn no bd b be z dk">Eq. 1. Probability that a hidden neuron is activated.</figcaption></figure><p id="2d40" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">给定二进制输入<strong class="kk iu"> v </strong>，下面的函数<code class="fe ns nt nu nv b">_sample_h(self) </code>获得隐藏神经元被激活的概率(等式 1)。这是通过将输入<strong class="kk iu"> v </strong>乘以权重矩阵、添加偏置并应用 s 形激活来实现的。获得的概率用于从伯努利分布中采样。采样值 1.0 或 0.0 是隐藏神经元的状态。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="adcb" class="ly lz it bd ma mb mc dn md me mf dp mg kr mh mi mj kv mk ml mm kz mn mo mp mq bi translated"><strong class="ak">可视状态的采样</strong></h2><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/9dde23356968aadb49ab367211367549.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*6BMmNqK8H3a_BFSq5K3j-A.png"/></div><figcaption class="nl nm gj gh gi nn no bd b be z dk">Eq. 2. Probability that a visible neuron is activated.</figcaption></figure><p id="1e79" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">给定隐藏状态<strong class="kk iu"> h </strong>，我们可以使用这些来获得可见神经元活动的概率(等式 2)以及相应的状态值。这是在<code class="fe ns nt nu nv b">_sample_v(self)</code>中实现的。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="418b" class="ly lz it bd ma mb mc dn md me mf dp mg kr mh mi mj kv mk ml mm kz mn mo mp mq bi translated">吉布斯采样</h2><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi nx"><img src="../Images/bf533c88ef7778d35a3070d5d8a0456e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UMbNSJVSmAgqkVnQKA62yg.png"/></div></div><figcaption class="nl nm gj gh gi nn no bd b be z dk">Fig.2. Gibbs Sampling.</figcaption></figure><p id="6ba1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">训练的第一部分是一个叫做<em class="lu">吉布斯采样</em>的操作。简而言之，我们取一个输入向量<strong class="kk iu"> v_0 </strong>并用它来预测隐藏状态<strong class="kk iu"> h_0 </strong>的值。另一方面，隐藏状态用于预测新的输入状态<strong class="kk iu"> v </strong>。这个过程重复<em class="lu"> k </em>次。这个过程如图 2 所示。</p><p id="a90e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lu">吉布斯采样</em>在下面截取的代码中实现。迭代发生在 while 循环体中。体内重要的一步是<code class="fe ns nt nu nv b">Vk=tf.where(tf.less(V,0),V,Vk)</code>。该操作确保在每次迭代中，对于每个<strong class="kk iu"> v_k </strong>，为-1 的<strong class="kk iu"> v </strong>中的评级(意味着还没有看过的电影)保持为-1。在<em class="lu"> k </em>迭代之后，我们得到<strong class="kk iu"> v_k </strong>和相应的概率<strong class="kk iu"> p(h_k|v_k)。</strong>连同<strong class="kk iu"> v_0 </strong>和<strong class="kk iu"> h_0 </strong>这些值可用于在下一个训练步骤中计算梯度矩阵。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="np nq l"/></div></figure></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h2 id="4571" class="ly lz it bd ma mb mc dn md me mf dp mg kr mh mi mj kv mk ml mm kz mn mo mp mq bi translated">计算梯度</h2><p id="e525" class="pw-post-body-paragraph ki kj it kk b kl mt ju kn ko mu jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">在前一步骤中获得的值可以用于计算梯度矩阵和梯度向量。根据等式计算梯度。3 是直截了当的。请注意，这个等式中的符号<strong class="kk iu"> a </strong>和<strong class="kk iu"> b </strong>分别代表隐藏的可见偏差，与我在代码中使用的不同符号形成对比。</p><p id="a682" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">唯一棘手的是<em class="lu"> TensorFlow </em> 1.5 不支持外积。但是这个问题可以通过临时整形和应用通常的点乘来解决。</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi of"><img src="../Images/9e97bc9473b211acd8c549373b1bb40f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*lGBNVKoCsiWRmYfaVZGQTw.png"/></div><figcaption class="nl nm gj gh gi nn no bd b be z dk">Eq. 3. Computation of gradients for the weights and biases.</figcaption></figure><p id="04d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">注意，梯度的计算发生在 while 循环中。这仅仅是因为培训是小批量进行的。这意味着循环为小批量中的每个数据样本计算梯度，并将它们添加到先前定义的梯度占位符中。最后，梯度的总和除以小批量的大小。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="3246" class="ly lz it bd ma mb mc dn md me mf dp mg kr mh mi mj kv mk ml mm kz mn mo mp mq bi translated">更新步骤</h2><p id="6469" class="pw-post-body-paragraph ki kj it kk b kl mt ju kn ko mu jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">在计算梯度之后，所有的权重和偏差可以根据等式通过梯度上升来更新。4.对于这个过程，我们必须在<code class="fe ns nt nu nv b">_update_parameter(self).</code>中创建一个赋值操作</p><figure class="lg lh li lj gt lk gh gi paragraph-image"><div class="gh gi og"><img src="../Images/5e9dd1976f8c3b1cd0a51bc9137355b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*rCibXSBkhjpiX74GwFWzmQ.png"/></div><figcaption class="nl nm gj gh gi nn no bd b be z dk">Eq. 4. Update step of the parameters through gradient ascent.</figcaption></figure><p id="ac0f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">整个训练操作在名称范围“操作”下用<code class="fe ns nt nu nv b">optimize(self)</code>方法计算。在此之下，执行更复杂的训练精度操作。基本上，该操作从<strong class="kk iu"> </strong> <em class="lu">吉布斯采样</em> <strong class="kk iu">期间获得的<strong class="kk iu"> v_k </strong>中减去原始输入值<strong class="kk iu"> v_0 </strong>。</strong>减法只发生在<strong class="kk iu"> v_0 </strong> ≥ 0 时。在此之后，相减之和除以所有等级数≥ 0。准确度给出了训练期间正确预测的二进制电影分级的比率。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="0581" class="ly lz it bd ma mb mc dn md me mf dp mg kr mh mi mj kv mk ml mm kz mn mo mp mq bi translated">推理</h2><p id="3296" class="pw-post-body-paragraph ki kj it kk b kl mt ju kn ko mu jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">在推理时间期间，方法<code class="fe ns nt nu nv b">inference(self)</code>接收输入<strong class="kk iu"> v. </strong>该输入是特定用户的一个<strong class="kk iu">训练</strong>样本，用于激活隐藏的神经元(用户电影品味的潜在特征)。隐藏的神经元再次用于预测新的输入<strong class="kk iu"> v </strong>。在最好的情况下，这种新的输入包括对已经存在的评级以及尚未评级的电影的评级的重新创建。</p><p id="ce3a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在<em class="lu"> TensorFlow </em>会话之外，将做出的预测与相应的测试数据进行比较，以进行验证。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="np nq l"/></div></figure><p id="7947" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">网络图</strong></p><p id="5e84" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了概述前面的步骤，这里是主网络图的定义和执行训练和推理步骤的会话的开始。</p><figure class="lg lh li lj gt lk"><div class="bz fp l di"><div class="np nq l"/></div></figure><h2 id="74d5" class="ly lz it bd ma mb mc dn md me mf dp mg kr mh mi mj kv mk ml mm kz mn mo mp mq bi translated">模型的性能</h2><p id="2cdd" class="pw-post-body-paragraph ki kj it kk b kl mt ju kn ko mu jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated">在训练过程中，我们可以在训练集和测试集上检查准确性的进展。准确度给出了正确预测的二进制电影分级的比率。可以看出，在 6 个时期之后，如果用户喜欢或不喜欢随机电影，该模型正确预测的时间为 78%。</p><pre class="lg lh li lj gt oh nv oi oj aw ok bi"><span id="783a" class="ly lz it nv b gy ol om l on oo">epoch_nr: 0, batch: 50/188, acc_train: 0.721, acc_test: 0.709<br/>epoch_nr: 1, batch: 50/188, acc_train: 0.767, acc_test: 0.764<br/>epoch_nr: 2, batch: 50/188, acc_train: 0.772, acc_test: 0.773<br/>epoch_nr: 3, batch: 50/188, acc_train: 0.767, acc_test: 0.725<br/>epoch_nr: 4, batch: 50/188, acc_train: 0.768, acc_test: 0.717<br/>epoch_nr: 5, batch: 50/188, acc_train: 0.772, acc_test: 0.769<br/>epoch_nr: 6, batch: 50/188, acc_train: 0.774, acc_test: 0.771<br/>epoch_nr: 7, batch: 50/188, acc_train: 0.779, acc_test: 0.780</span></pre></div><div class="ab cl ny nz hx oa" role="separator"><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od oe"/><span class="ob bw bk oc od"/></div><div class="im in io ip iq"><h2 id="7dd2" class="ly lz it bd ma mb mc dn md me mf dp mg kr mh mi mj kv mk ml mm kz mn mo mp mq bi translated">参考</h2><p id="b882" class="pw-post-body-paragraph ki kj it kk b kl mt ju kn ko mu jx kq kr nh kt ku kv ni kx ky kz nj lb lc ld im bi translated"><a class="ae le" href="https://github.com/artem-oppermann/Restricted-Boltzmann-Machine/blob/master/README.md" rel="noopener ugc nofollow" target="_blank">https://github . com/artem-opper Mann/Restricted-Boltzmann-Machine/blob/master/readme . MD</a></p></div></div>    
</body>
</html>