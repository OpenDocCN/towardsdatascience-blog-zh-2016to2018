<html>
<head>
<title>[ Only Numpy ] Having Fun with Eigen Value s/ Vectors with Interactive Code in Numpy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">[仅适用于 Numpy ]在 Numpy 中使用交互式代码体验特征值/向量的乐趣</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/only-numpy-having-fun-with-eigen-value-s-vectors-with-interactive-code-in-numpy-80d3443dfd22?source=collection_archive---------6-----------------------#2018-07-10">https://towardsdatascience.com/only-numpy-having-fun-with-eigen-value-s-vectors-with-interactive-code-in-numpy-80d3443dfd22?source=collection_archive---------6-----------------------#2018-07-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/b85c82718be8862e50067fa4f5957fcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*AO6vL-H-9n5RnwdzY6V8BA.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">GIF from this <a class="ae jy" href="https://giphy.com/gifs/3oEjI4T1VNTKgri4fK" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="3c5a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">主成分分析、奇异值分解和独立成分分析都是降维技术。它们都依赖于特征值和向量。今天，我想超越高级 API，进入细节。</p><blockquote class="kx ky kz"><p id="388c" class="jz ka la kb b kc kd ke kf kg kh ki kj lb kl km kn lc kp kq kr ld kt ku kv kw ij bi translated">请注意，这篇文章纯粹是我自己在解释这些概念，所以这篇文章可能会有点不同。</p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="a4c7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">为什么我们甚至需要特征向量/值？(这部分是垃圾)</strong></p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi ll"><img src="../Images/3f896d662d9b3d97683aea5325ad9f7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gcd7qv6BxDOEuDrqU07Uyg.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image from this <a class="ae jy" href="https://skymind.ai/wiki/eigenvector" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="6315" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们实际上可以把每一个矩阵，甚至病历 csv 看作一个转换矩阵。我思考这个问题的方式有点奇怪，例如，我们可以有如下所示的一些数据。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/bb1a57a6905392163181c0bab8a1ccb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*0uUycpINZStdnBweItjkeg.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Data from <a class="ae jy" href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html" rel="noopener ugc nofollow" target="_blank">Sklearn Wine</a></figcaption></figure><p id="eeb7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">数据集用于分类任务，因此有一个目标值未显示在上面的矩阵中。但是当我们为上述数据绘制 2D 散点图时，我们可以得到如下结果。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/27b670287a7c06f05439ab6655645f65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*LFb4EZpMd3cY3qZkpLwlCw.png"/></div></figure><p id="91d3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，我们可以将每个数据点视为基向量的变换。(即稀释葡萄酒的[1，0]o d280/o d315 或黄酮类化合物的[0，1]。).</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="7f34" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">协方差矩阵/相关矩阵</strong></p><div class="lm ln lo lp gt ab cb"><figure class="lw jr lx ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/5c9e5dafd305b2e80a2a483745adfa91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*CqKUClPiwqs8xldeS4eArA.png"/></div></figure><figure class="lw jr mc ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/f55a0e1b478440224845d0a190cd11dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*iNAOH-U9NJLvIa_XfMt1Qw.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk md di me mf">Image from this <a class="ae jy" href="http://users.stat.umn.edu/~helwig/notes/datamat-Notes.pdf" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure></div><p id="a106" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在继续之前，理解协方差和相关矩阵的概念是必要的。因此，请花几分钟时间查看这些材料。如果你想看这些东西的数字计算方法，请点击这里。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="1749" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">改变基本向量/样本数据的示例</strong></p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/6af3b33320aa55f2fcc5526e58a19074.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*eY8MTSniNM1cqeUGj4rzyw.png"/></div></figure><p id="b015" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">让我们做一些非常简单的事情，红点代表给定的两个蓝色数据点的特征值。让我们将该值设置为新的基本向量，并投影两个蓝色数据点。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/7650901649a64f6035009f15e6531402.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*uHvMC80vzsGyGq5hs7igmg.png"/></div></figure><p id="ef5f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所示，我们可以看到，现在我们的数据已经翻转。如果你希望看到如何实现这一点的代码，请见下文。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mh"><img src="../Images/8e0795fe6e63401e0ae5a6f392cff68b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UnvinqqQc960KwT8TQbZXg.png"/></div></div></figure><p id="5b65" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在，让我们来看看我们将要使用的数据集。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/27b670287a7c06f05439ab6655645f65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*LFb4EZpMd3cY3qZkpLwlCw.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Data from <a class="ae jy" href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html" rel="noopener ugc nofollow" target="_blank">Sklearn Wine</a></figcaption></figure><p id="243b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">您已经看到了上面的图表，因为我们将使用来自 sklearn 的葡萄酒数据集。但是，我们不会使用所有维度，而是只使用两个最相关的属性。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mi"><img src="../Images/ce7849289ef3a3ec17bd1f3e3386a12a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZpjMSJYKJrj_OePQGhLp6w.png"/></div></div></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="7e43" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">使用协方差矩阵改变基数</strong></p><div class="lm ln lo lp gt ab cb"><figure class="lw jr mj ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/f8d5b2e0c0091b95f03e9f01444f2296.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*udobL28ZDmA64JgusdDFqA.png"/></div></figure><figure class="lw jr mj ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/61de2e6e1477dbe22544f6686594168a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*TVtZhF_Jh96FlRDMBkKLuQ.png"/></div></figure></div><p id="8e65" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →使用 Numpy <br/>计算的协方差矩阵<strong class="kb ir">右图</strong> →使用内置函数计算的协方差矩阵</p><p id="6776" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">首先，我们需要计算协方差矩阵，从这里我们可以得到生成的协方差矩阵的特征向量和值。(这是原理变化向量。)</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/c822f5a39d72baed76093d49c9d5753d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*7wB-wGcGUS6iByDeHelICw.png"/></div></figure><p id="1344" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">红点</strong> →协方差矩阵的特征向量</p><p id="b725" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所示，在得到每个向量后，我们可以画一个线性图，线的长度并不重要。但是我们可以看到，最大差异存在的区域是数据点的对角线。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/816d82715821130519b37f8428f5f1e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*IAb-GYsLliSYwstflTfFoQ.png"/></div></figure><p id="c961" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最后，我们可以将所有的数据点投影到这个基向量中。不幸的是，我们丢失了属性信息。然而，我们能够看到更清晰的数据版本。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="d83b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">使用相关矩阵改变基础</strong></p><div class="lm ln lo lp gt ab cb"><figure class="lw jr ml ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/7744523142e6fd807355980a0be559c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*ZOz0bzW_28qd-nTK6IKJSA.png"/></div></figure><figure class="lw jr mm ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/e427d264eff964f0b9f93855f7aac92e.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*TVtZhF_Jh96FlRDMBkKLuQ.png"/></div></figure></div><p id="109d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →使用 Numpy <br/>计算相关矩阵<strong class="kb ir">右图</strong> →使用内置函数计算相关矩阵</p><p id="c0af" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在我知道颜色是关闭的，但值是一样的，如下所示。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/807663413f53a77c782c27cf6da4ff8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*_8xYv_xkP0Q_yXviddmeBQ.png"/></div></figure><p id="0c5f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">和上次一样，让我们找出这个矩阵的特征向量。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/5ebc03533f43f97ca77c6b833c314243.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*3BpgxuM2nFyO3CWyC6lPkg.png"/></div></figure><p id="4e99" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">得到的向量彼此对称，相关矩阵本身也是对称的。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/8b0d31eaeebc2bd79a18d967449c9ea4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*uMvhrvWwJqAlmQkbYZStUA.png"/></div></figure><p id="4a4c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">然而，以上是当我们使用从相关矩阵生成的特征向量时得到的投影。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="578f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">奇异值分解(2D) </strong></p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mp"><img src="../Images/3b44c798ce6893559795ed30c3ca4413.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VRQJOsoFw8IL6LLf_HMjYg.png"/></div></div></figure><p id="2310" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">既然我们已经走了这么远，让我们走得更远。我们可以很容易地执行奇异值分解。如上所述，在首先计算转置(A)点积(A)之后。我们可以找到那个矩阵的特征向量。从那里我们可以得到我们的 u，最后，如上面红框所示，我们可以观察到，原始矩阵和重构矩阵之间没有区别。(如果你不明白这个<a class="ae jy" href="https://blog.statsbot.co/singular-value-decomposition-tutorial-52c695315254" rel="noopener ugc nofollow" target="_blank">方法请点击这里。</a>)</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mq"><img src="../Images/2ba449f0ea51c911dd1719daf6480202.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Eho0UmHXqKBZXT3udPTHhA.png"/></div></div></figure><p id="955c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在让我们去掉最不重要的奇异值，进行降维。正如上面所看到的，我们可以清楚地看到，重建的矩阵与原始矩阵并不相同。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/dd743f7f6ba4e88fc744b0ef1489aae5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*DFe7EbwpIYLA6BQGpBHSjw.png"/></div></figure><p id="1506" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">当我们将数据投影到 2D 平面时，我们可以观察到，在 SVD 之后，对角线上的最大变化被捕获。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="f15a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">奇异值分解(3D) </strong></p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/e3bb53d8d6a83e03504e71cf28cca9a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/1*-du1zkg7vNk7FSjQWgu1Mg.gif"/></div></figure><p id="937a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最后，让我们以一些 3D 图来结束，如上所述，我添加了一个额外的属性，“alcalinity_of_ash”。</p><div class="lm ln lo lp gt ab cb"><figure class="lw jr mj ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/1bc87ba55f6a8c03984fcab8a137899d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*voMtm7JuhXRER4o9h7phjQ.png"/></div></figure><figure class="lw jr mj ly lz ma mb paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><img src="../Images/1820202ff068a28396afe4990dfce6f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*qktgyetJDOTMgoL6QLoPBg.png"/></div></figure></div><p id="b8a2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →使用 Numpy <br/>计算的协方差矩阵<strong class="kb ir">右图</strong> →使用内置函数计算的协方差矩阵</p><p id="609f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">再一次，让我们先看看，仅仅改变基底，我们能做什么。当我们根据协方差绘制生成的特征向量时，我们得到如下结果。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi ms"><img src="../Images/499ee542f5199424a67b759807546965.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Mh_PXVj6c7ff4lM7I8FidA.gif"/></div></div></figure><p id="bfb9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我稍微改变了起点，但故事保持不变。现在让我们执行投影。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mt"><img src="../Images/897e8aee648b7172404a492e1d1ee7b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*9N7-UX3_6wbw2ESn_udRDA.gif"/></div></div></figure><p id="96a9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们可以观察到这样一个事实，现在我们的特征向量已经占据了基向量空间。现在它们都互相垂直。此外，我们还可以对 3D 数据执行 SVD。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mu"><img src="../Images/ca0b5ac82a1d3102f93dbc582f7be596.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l3F_AnvHtGKuCZUc9j3u6w.png"/></div></div></figure><p id="0d4c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">就像前面的例子，我们可以看到，重建的矩阵是相同的原始矩阵。现在来降维。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mt"><img src="../Images/1470f8c20215c6bcc5c4f1f2e96751b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*7BaqX_ZCl6XvbMBo_qJpaQ.gif"/></div></div></figure><p id="a742" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">当我们丢弃最不重要的奇异值时，我们的 3D 数据会折叠成一个平面。然而。我们仍然可以观察到这样一个事实，即数据彼此之间仍然是完全可以分离的。</p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mt"><img src="../Images/41a889344bae1bcf0f0e9310e4e5ba08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*BFUYGen_7v93c8Y-QQeArA.gif"/></div></div></figure><p id="256c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">但是，当我们丢弃两个奇异值时，我们可以清楚地看到，我们的数据不再是可分的，因为它折叠成了一条线。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="5f20" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">交互代码</strong></p><figure class="lm ln lo lp gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mv"><img src="../Images/d2f1fccee0dcf7266739d78d41da18d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hwKOwgdJS8cm6Asbvw1yXA.png"/></div></div></figure><p id="010f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><em class="la">对于谷歌实验室，你需要一个谷歌帐户来查看代码，你也不能在谷歌实验室运行只读脚本，所以在你的操场上做一个副本。最后，我永远不会请求允许访问你在 Google Drive 上的文件，仅供参考。编码快乐！</em></p><p id="064d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">要获取这篇<a class="ae jy" href="https://colab.research.google.com/drive/1XgQCRhhg3mZd__gRRT_WxeSFGEaSkEnr" rel="noopener ugc nofollow" target="_blank">文章的代码，请点击这里。</a></p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="0561" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">最后的话</strong></p><p id="b052" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">玩特征值/向量真的很有趣。</p><p id="e72b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 给我，如果你想看我所有写作的列表，请在这里查看我的网站。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的 twitter <a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，并访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。我还实现了<a class="ae jy" href="https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec" rel="noopener">广残网，请点击这里查看博文 pos </a> t。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="9f46" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="dc5d" class="mw mx iq kb b kc kd kg kh kk my ko mz ks na kw nb nc nd ne bi translated">特征值和特征向量在 3 分钟内|用一个有趣的类比解释。(2018).YouTube。检索于 2018 年 7 月 9 日，来自<a class="ae jy" href="https://www.youtube.com/watch?v=5UjQVJu89_Q" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=5UjQVJu89_Q</a></li><li id="a966" class="mw mx iq kb b kc nf kg ng kk nh ko ni ks nj kw nb nc nd ne bi translated">sk learn . datasets . load _ wine-sci kit-learn 0 . 19 . 1 文档。(2018).Scikit-learn.org。检索于 2018 年 7 月 9 日，来自<a class="ae jy" href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/modules/generated/sk learn . datasets . load _ wine . html # sk learn . datasets . load _ wine</a></li><li id="cf8a" class="mw mx iq kb b kc nf kg ng kk nh ko ni ks nj kw nb nc nd ne bi translated">numpy.linalg.inv — NumPy v1.14 手册。(2018).Docs.scipy.org。2018 年 7 月 9 日检索，来自<a class="ae jy" href="https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.inv.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/numpy-1 . 14 . 0/reference/generated/numpy . Lina LG . inv . html</a></li><li id="952a" class="mw mx iq kb b kc nf kg ng kk nh ko ni ks nj kw nb nc nd ne bi translated">正确，e. (2018)。numpy.linalg.eig 创建的特征向量似乎不正确。堆栈溢出。检索于 2018 年 7 月 9 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/32926861/eigenvectors-created-by-numpy-linalg-eig-dont-seem-correct" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/32926861/特征向量-created-by-numpy-Lina LG-EIG-dont-seem-correct</a></li><li id="0ea7" class="mw mx iq kb b kc nf kg ng kk nh ko ni ks nj kw nb nc nd ne bi translated">矩阵的逆。(2018).Mathsisfun.com。检索于 2018 年 7 月 9 日，来自 https://www.mathsisfun.com/algebra/matrix-inverse.html<a class="ae jy" href="https://www.mathsisfun.com/algebra/matrix-inverse.html" rel="noopener ugc nofollow" target="_blank"/></li><li id="4ed3" class="mw mx iq kb b kc nf kg ng kk nh ko ni ks nj kw nb nc nd ne bi translated">matplotlib？，H. (2018)。如何改变用 matplotlib 绘制的图形的大小？。堆栈溢出。检索于 2018 年 7 月 9 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib</a></li><li id="7780" class="mw mx iq kb b kc nf kg ng kk nh ko ni ks nj kw nb nc nd ne bi translated">在 Numpy 中使用矩阵点积/具有交互代码的基的变化的简单分类。(2018).走向数据科学。2018 年 7 月 9 日检索，来自<a class="ae jy" rel="noopener" target="_blank" href="/naive-classification-using-matrix-dot-product-change-of-basis-with-interactive-code-in-numpy-4808e5aa955e">https://towardsdatascience . com/naive-class ification-using-matrix-dot-product-change-of-basis-with-interactive-code-in-numpy-4808 E5 aa 955 e</a></li><li id="34d7" class="mw mx iq kb b kc nf kg ng kk nh ko ni ks nj kw nb nc nd ne bi translated">seaborn . heat map-seaborn 0 . 8 . 1 文档。(2018).Seaborn.pydata.org。检索于 2018 年 7 月 9 日，来自<a class="ae jy" href="https://seaborn.pydata.org/generated/seaborn.heatmap.html" rel="noopener ugc nofollow" target="_blank">https://seaborn.pydata.org/generated/seaborn.heatmap.html</a></li><li id="7b45" class="mw mx iq kb b kc nf kg ng kk nh ko ni ks nj kw nb nc nd ne bi translated">matplotlib，C. (2018 年)。用 matplotlib 改变 y 范围从 0 开始。堆栈溢出。2018 年 7 月 9 日检索，来自<a class="ae jy" href="https://stackoverflow.com/questions/22642511/change-y-range-to-start-from-0-with-matplotlib" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/22642511/change-y-range-to-start-from-0-with-matplotlib</a></li><li id="cfbe" class="mw mx iq kb b kc nf kg ng kk nh ko ni ks nj kw nb nc nd ne bi translated">价值？，H. (2018)。如何使用十进制范围()步长值？。堆栈溢出。检索于 2018 年 7 月 9 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/477486/how-to-use-a-decimal-range-step-value" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/477486/how-to-use-a-decimal-range-step-value</a></li><li id="2c0f" class="mw mx iq kb b kc nf kg ng kk nh ko ni ks nj kw nb nc nd ne bi translated">(2018).Users.stat.umn.edu。检索于 2018 年 7 月 9 日，来自<a class="ae jy" href="http://users.stat.umn.edu/~helwig/notes/datamat-Notes.pdf" rel="noopener ugc nofollow" target="_blank">http://users.stat.umn.edu/~helwig/notes/datamat-Notes.pdf</a></li><li id="28b5" class="mw mx iq kb b kc nf kg ng kk nh ko ni ks nj kw nb nc nd ne bi translated">颜色示例代码:colormaps _ reference . py—Matplotlib 2 . 0 . 2 文档。(2018).Matplotlib.org。检索于 2018 年 7 月 9 日，来自<a class="ae jy" href="https://matplotlib.org/examples/color/colormaps_reference.html" rel="noopener ugc nofollow" target="_blank">https://matplotlib . org/examples/color/colormaps _ reference . html</a></li><li id="e2b7" class="mw mx iq kb b kc nf kg ng kk nh ko ni ks nj kw nb nc nd ne bi translated">使用样式表自定义绘图— Matplotlib 1.5.3 文档。(2018).Matplotlib.org。检索于 2018 年 7 月 9 日，来自 https://matplotlib.org/users/style_sheets.html<a class="ae jy" href="https://matplotlib.org/users/style_sheets.html" rel="noopener ugc nofollow" target="_blank"/></li><li id="fa57" class="mw mx iq kb b kc nf kg ng kk nh ko ni ks nj kw nb nc nd ne bi translated">奇异值分解教程:应用，例子，练习。(2017).统计和机器人。检索于 2018 年 7 月 10 日，来自<a class="ae jy" href="https://blog.statsbot.co/singular-value-decomposition-tutorial-52c695315254" rel="noopener ugc nofollow" target="_blank">https://blog . statsbot . co/singular-value-decomposition-tutorial-52c 695315254</a></li></ol></div></div>    
</body>
</html>