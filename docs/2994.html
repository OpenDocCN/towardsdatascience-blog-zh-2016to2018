<html>
<head>
<title>Deep Quantile Regression in Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">张量流中的深度分位数回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-quantile-regression-in-tensorflow-1dbc792fe597?source=collection_archive---------6-----------------------#2018-03-28">https://towardsdatascience.com/deep-quantile-regression-in-tensorflow-1dbc792fe597?source=collection_archive---------6-----------------------#2018-03-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="2fda" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">深度学习中的一个关键挑战是如何获得对预测器界限的估计。分位数回归最早由 Koenker 和 Bassett [1]在 70 年代引入，它允许我们估计潜在条件数据分布的百分位数，即使在它们不对称的情况下，也能让我们了解预测因子和反应之间的变异性关系。</p><p id="82a0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如 Koeneker 和 Hallock [2]所述，OLS 回归的标准方法是通过绘制一条线来估计数据的条件平均值<em class="kl">,该线使该线和图上所有点之间的距离最小化。相反，分位数回归的目标是估计有条件的<em class="kl">中位数、</em>或任何其他分位数。为此，我们根据所选的分位数对图表上的点和我们的回归线之间的距离进行加权。例如，如果我们选择第 90 个分位数进行估计，我们将拟合一条回归线，使 90%的数据点低于该线，10%高于该线。</em></p><h2 id="6569" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">张量流代码</h2><p id="b763" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">Sachin Abeywardana 最近在 medium 上发表的一篇伟大的<a class="ae lk" rel="noopener" target="_blank" href="/deep-quantile-regression-c85481548b5a">文章展示了如何使用 Keras 进行深度分位数回归。然而，这种实现的限制是，它需要每个分位数单独拟合模型。然而，使用 Tensorflow，我们可以同时拟合任意数量的分位数。</a></p><p id="998d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">用于此实现的<a class="ae lk" href="https://github.com/strongio/quantile-regression-tensorflow/blob/master/Quantile%20Loss.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>可以在<a class="ae lk" href="http://strong.io" rel="noopener ugc nofollow" target="_blank"> Strong Analytics </a> github 上找到。</p><p id="ecb0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们首先实例化一个简单的回归模型，并为我们想要估计的每个分位数添加输出</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="baa8" class="km kn iq lq b gy lu lv l lw lx"># Define the quantiles we’d like to estimate<br/>quantiles = [.1, .5, .9]</span><span id="1702" class="km kn iq lq b gy ly lv l lw lx"># Add placeholders for inputs to the model<br/>x = tf.placeholder(tf.float32, shape=(None, in_shape))<br/>y = tf.placeholder(tf.float32, shape=(None, out_shape))</span><span id="0152" class="km kn iq lq b gy ly lv l lw lx"># Create model using tf.layers API<br/>layer0 = tf.layers.dense(x, units=32, activation=tf.nn.relu)<br/>layer1 = tf.layers.dense(layer0, units=32, activation=tf.nn.relu)</span><span id="c34c" class="km kn iq lq b gy ly lv l lw lx"># Now, create an output for each quantile<br/>outputs = []<br/>for i, quantile in enumerate(quantiles):<br/>    output = tf.layers.dense(layer1, 1, name=”{}_q{}”.format(i, int(quantile*100)))<br/>    outputs.append(output)</span></pre><p id="4c92" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们为每个分位数创建损失</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="5383" class="km kn iq lq b gy lu lv l lw lx">losses = []<br/>for i, quantile in enumerate(quantiles):<br/>   error = tf.subtract(y, output[i])<br/>   loss = tf.reduce_mean(tf.maximum(quantile*error, (quantile-1)*error), axis=-1)<br/>   losses.append(loss)</span></pre><p id="0ccd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们合并损失并实例化我们的优化器</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="7991" class="km kn iq lq b gy lu lv l lw lx">combined_loss = tf.reduce_mean(tf.add_n(losses))<br/>train_step = tf.train.AdamOptimizer().minimize(combined_loss)</span></pre><p id="5197" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基本上就是这样了！现在，我们可以拟合我们的模型，同时估计所有指定的分位数:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="28b1" class="km kn iq lq b gy lu lv l lw lx">for epoch in range(epochs):<br/>   # Split data to batches<br/>   for idx in range(0, data.shape[0], batch_size):<br/>     batch_data = data[idx : min(idx + batch_size, data.shape[0]),:]<br/>     batch_labels = labels[idx : min(idx + batch_size, labels.shape[0]),:]</span><span id="5a5c" class="km kn iq lq b gy ly lv l lw lx">    feed_dict = {x: batch_data,<br/>                 y: batch_labels}</span><span id="69f5" class="km kn iq lq b gy ly lv l lw lx">    _, c_loss = sess.run([train_step, combined_loss], feed_dict)</span></pre><p id="c05d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将这些数据拟合到摩托车碰撞的数据集上(<a class="ae lk" href="https://github.com/sachinruk/KerasQuantileModel" rel="noopener ugc nofollow" target="_blank">从此处开始</a>)得到以下输出:</p><figure class="ll lm ln lo gt ma gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/c46e57f85c80b7a60e10c229292447ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*_lysFbib221Cyf1s4cG6Ng.png"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Estimated quantiles</figcaption></figure><h2 id="6e6b" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">参考文献</h2><p id="64e5" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">1.回归分位数。罗杰·科恩克；吉尔伯特·巴塞特,《计量经济学》,第 46 卷，第 1 号。(1978 年 1 月)，第 33-50 页。</p><p id="9289" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2.分位数回归。罗杰·科恩克；凯文·f·哈洛克。《经济展望杂志》第 15 卷第 4 期，2001 年秋季。(第 143-156 页)。</p></div><div class="ab cl mh mi hu mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ij ik il im in"><p id="38fe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kl">想和芝加哥的顶级数据科学家团队一起从事各种行业中具有挑战性的机器学习和人工智能工作吗？我们正在招聘有才华的数据科学家和工程师！</em>T15】</strong></p><p id="4fdb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<a class="ae lk" href="http://strong.io" rel="noopener ugc nofollow" target="_blank"> strong.io </a>了解更多信息，并在<a class="ae lk" href="https://careers.strong.io/" rel="noopener ugc nofollow" target="_blank"> careers.strong.io </a>申请</p></div></div>    
</body>
</html>