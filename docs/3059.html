<html>
<head>
<title>Save Lives With 10 Lines of Code: Detecting Parkinson’s with XGBoost</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用10行代码拯救生命:用XGBoost检测帕金森</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/detect-parkinsons-with-10-lines-of-code-intro-to-xgboost-51a4bf76b2e6?source=collection_archive---------7-----------------------#2018-04-04">https://towardsdatascience.com/detect-parkinsons-with-10-lines-of-code-intro-to-xgboost-51a4bf76b2e6?source=collection_archive---------7-----------------------#2018-04-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="940b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，您已经涉足了数据科学，听说过“XGBoost”这个术语，但不知道它是什么。我非常喜欢通过<em class="kl">做</em>来学习，所以让我们尝试使用XGBoost来解决现实生活中的问题:诊断帕金森氏症。</p><p id="8685" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">XGBoost是一种流行的技术，是传统回归/神经网络的一种简洁的替代方法。它代表E<strong class="jp ir">X</strong>treme<strong class="jp ir">G</strong>radient<strong class="jp ir">Boost</strong>ing，基本上是构建一个决策树来计算梯度。这里有一个来自<a class="ae km" href="http://xgboost.readthedocs.io/en/latest/model.html" rel="noopener ugc nofollow" target="_blank"> XGBoost网站</a>的流行图片作为例子:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi kn"><img src="../Images/74ffe2d56d9534d11a1e897ab93a27f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fRF3aDCRtElR38sV.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Not so menacing now, huh?</figcaption></figure><p id="22f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这在实践中听起来很简单，但却非常强大。以帕金森氏症检测为例:我们有几个指标可以分析，最终我们需要诊断帕金森氏症(分类！).这对于XGBoost来说是一个完美的问题(<em class="kl">特别是因为只有一个输出，所以我们不需要使用多输出包装器——稍后会详细介绍)</em>。</p><h2 id="6983" class="ld le iq bd lf lg lh dn li lj lk dp ll jy lm ln lo kc lp lq lr kg ls lt lu lv bi translated">让我们写10行代码</h2><p id="e3e5" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">让我们从收集一些数据开始。在我的好朋友<a class="ae km" href="https://medium.com/@shlok_85483" rel="noopener"> Shlok </a>的指引下，我发现了一个格式极佳的数据集:跳到UCI的ML数据库，下载帕金森氏症数据集<code class="fe mb mc md me b">parkinsons.data</code> ( <a class="ae km" href="https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/" rel="noopener ugc nofollow" target="_blank">这里有一个链接</a>)(如果它消失了，就在<a class="ae km" href="https://github.com/pshah123/parkinsons-AI" rel="noopener ugc nofollow" target="_blank">这个回购</a>)。它们是CSV，所以我们可以用熊猫快速解析它们:</p><pre class="ko kp kq kr gt mf me mg mh aw mi bi"><span id="335f" class="ld le iq me b gy mj mk l ml mm">df = pd.read_csv('parkinsons.data')</span></pre><p id="dfe5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们需要获取特性和标签。除了第一列(名称)之外，所有列都是数字，带有标签的列是“状态”(已经是0或1)。我们暂且忽略它们的意义，盲目分析<em class="kl">(实践中不要这么做)</em>。这使得我们很方便地快速获得训练数据:</p><pre class="ko kp kq kr gt mf me mg mh aw mi bi"><span id="3003" class="ld le iq me b gy mj mk l ml mm">features = df.loc[:, df.columns != 'status'].values[:, 1:]<br/>labels = df.loc[:, 'status'].values</span></pre><p id="e953" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们需要缩放我们的要素，使其介于-1和1之间，以便进行规范化。我们可以用<code class="fe mb mc md me b">sklearn</code>的聪明的<code class="fe mb mc md me b">MinMaxScaler</code>来做到这一点:</p><pre class="ko kp kq kr gt mf me mg mh aw mi bi"><span id="6885" class="ld le iq me b gy mj mk l ml mm">scaler = MinMaxScaler((-1, 1))<br/>X = scaler.fit_transform(features)</span></pre><p id="d261" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">目前为止我们有5条线。接下来，让我们把它分成训练和测试数据，这样我们可以防止过度拟合。没有太多的数据点，所以让我们将14%分成测试数据，这次使用<code class="fe mb mc md me b">sklearn</code>的<code class="fe mb mc md me b">train_test_split</code>便利函数:</p><pre class="ko kp kq kr gt mf me mg mh aw mi bi"><span id="fbac" class="ld le iq me b gy mj mk l ml mm">X_r, X_s, Y_r, Y_s = train_test_split(X, labels, test_size=0.14)</span></pre><p id="0a95" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后我们使用<code class="fe mb mc md me b">xgboost</code>的XGBClassifier，它已经为分类而构建，并通过<code class="fe mb mc md me b">xgboost</code>模块(<code class="fe mb mc md me b">pip install xgboost</code>)提供:</p><pre class="ko kp kq kr gt mf me mg mh aw mi bi"><span id="4d9a" class="ld le iq me b gy mj mk l ml mm">model = XGBClassifier()<br/>model.fit(X_r, Y_r)</span></pre><p id="ce50" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这应该需要一瞬间，然后完成树的构建。我们无需花费数小时的训练就能实现融合，这不是很棒吗？</p><p id="cd54" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们现在有8行了—缩短它！让我们用来自<code class="fe mb mc md me b">sklearn</code>的<code class="fe mb mc md me b">accuracy_score</code>函数，根据之前的测试集来评估我们的模型，从而结束这个交易:</p><pre class="ko kp kq kr gt mf me mg mh aw mi bi"><span id="1fc8" class="ld le iq me b gy mj mk l ml mm">Y_hat = [round(yhat) <strong class="me ir">for</strong> yhat <strong class="me ir">in</strong> model.predict(X_test)]<br/>print(accuracy_score(Y_test, Y_hat))</span></pre><p id="d532" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您应该可以看到高达90%的准确度(在测试集上大约为96.42%！).这已经很惊人了，因为2007年的原始论文引用了91.8±2.0%的分类准确率，2016年的其他论文引用了<a class="ae km" href="https://www.sciencedirect.com/science/article/pii/S1386505616300326" rel="noopener ugc nofollow" target="_blank"> 96.4% (SVM) </a>和<a class="ae km" href="https://arxiv.org/pdf/1610.08250.pdf" rel="noopener ugc nofollow" target="_blank"> 97%的带有调优(Boosted LogReg) </a>的准确率；通过一些调整，我们的模型可以远远超过最先进的方法！</p><p id="5508" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">就是这样！10行代码，你就训练了一个完整的帕金森病XGBoosting分类器。您可以在<code class="fe mb mc md me b">Train.ipynb</code> Jupyter笔记本<a class="ae km" href="https://github.com/pshah123/parkinsons-AI" rel="noopener ugc nofollow" target="_blank">此处</a>找到此模型的完整源代码以及另一个UDPRS数据模型。</p><h2 id="8254" class="ld le iq bd lf lg lh dn li lj lk dp ll jy lm ln lo kc lp lq lr kg ls lt lu lv bi translated">事后思考</h2><p id="c9e1" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">XGBoosting极其强大，绝对可以成为你下一个项目的有用工具！不过这要深入得多——对于多输出，您需要一个多输出模型(SciKit Learn有一个很好的包装器),为了更加精确，您需要微调XGBoost模型。在之前的Jupyter笔记本中(以及下面链接的repo中)，我探索了使用Keras处理连续数据，但是来自<code class="fe mb mc md me b">sklearn</code>的MultiOutput包装器几乎可以作为Keras模型的替代。如果你想要更高级的关于微调XGBoost的教程，请查看2016年的<a class="ae km" href="https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/" rel="noopener ugc nofollow" target="_blank">这篇好文章！</a></p></div><div class="ab cl mn mo hu mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ij ik il im in"><div class="ko kp kq kr gt mu"><a href="https://github.com/pshah123/parkinsons-AI" rel="noopener  ugc nofollow" target="_blank"><div class="mv ab fo"><div class="mw ab mx cl cj my"><h2 class="bd ir gy z fp mz fr fs na fu fw ip bi translated">pshah 123/帕金森病-人工智能</h2><div class="nb l"><h3 class="bd b gy z fp mz fr fs na fu fw dk translated">帕金森-人工智能-使用XGBoost和神经网络检测帕金森</h3></div><div class="nc l"><p class="bd b dl z fp mz fr fs na fu fw dk translated">github.com</p></div></div><div class="nd l"><div class="ne l nf ng nh nd ni kx mu"/></div></div></a></div></div><div class="ab cl mn mo hu mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ij ik il im in"><p id="7d0a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">像这样，还有更多？在<a class="ae km" href="https://helloaiko.com" rel="noopener ugc nofollow" target="_blank"> Aiko AI </a>，我们热爱开源项目以及探索和可视化数据！</p></div></div>    
</body>
</html>