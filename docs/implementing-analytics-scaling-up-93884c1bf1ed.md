# 实施分析:向上扩展！

> 原文：<https://towardsdatascience.com/implementing-analytics-scaling-up-93884c1bf1ed?source=collection_archive---------4----------------------->

你终于到了那个时刻:你知道你想用你的分析实现做什么，你的利益相关者都在船上，你准备好将其扩展到整个组织。现在怎么办？

在向更广泛的受众推广您的分析平台之前，您需要考虑几件事情:数据集的结构和存储，扩展您的分析的正确工具；您确保数据质量的方法；和适当的文档来指导您的团队正确使用数据。

## 结构和存储

您将在哪里以及如何存储您的数据？您的数据是结构化的还是非结构化的？真的需要“数据湖”吗？需要进行多少数据操作？什么是正确的安全和访问控制级别？一些用户(如您组织中的数据科学家)是否需要访问更多非结构化数据集来进行分析，而其他人则在寻找 BI 仪表盘、数据可视化和更结构化的报告？

SQL Server、Teradata 等关系数据库或 MySQL、PostgreSQL 等开源数据库支持大规模高效的数据存储。这些数据库使用结构化查询语言或 SQL，它允许用户编写用于基本数据过滤、组合和聚合的查询。您是希望使用关系数据库，还是选择提供更大灵活性的 Hadoop 框架，这将取决于您正在处理的数据类型以及您的用户可能想要回答的问题。

## 合适的工具

随着您需求的发展，您对满足这些需求的“正确工具”的定义也将随之变化。您可以从开源工具开始，随着您在企业范围内的扩展而转向许可产品。

虽然传统数据库可以使用查询和存储过程进行一些数据操作，但它们的主要目的是数据存储和检索。为了获得更强大的复杂数据分析、建模和报告功能，您可以尝试 Python 之类的脚本语言或 R 或 SAS 之类的统计软件包。它们可用于从数据库中提取数据，执行数据准备，然后将结果存储回数据库。他们还可以连接、提取和集成来自任何其他数据源(原始文件、网页、API)的数据，并执行数据验证和错误处理。

对于企业级数据集市，有许多商业和开源的、专门的提取、转换、加载(ETL)软件可用。许多已经与上游的数据库或商业智能和分析产品集成。大多数 ETL 产品不需要任何编码，数据管道可以以图形方式创建、可视化和执行。

## 确保数据质量

越早解决数据质量问题越好；终端用户花在数据争论上的时间越少，他们就可以更多地关注高价值分析。随着您组织的数据基础设施的成熟，从电子表格迁移到数据库和数据仓库，数据质量检查应该正式定义、记录和自动化。应该在数据输入期间使用预定义的业务规则逻辑自动处理异常，或者要求用户立即干预以纠正任何错误。

向终端用户提供干净、集中且可供分析的数据不应是单向的过程。允许最终用户专注于高价值分析，如数据挖掘、网络图、聚类等。，他们可以发现数据中的某些异常值和异常。有效的数据管理应该包括一个反馈循环来交流这些发现，并且如果必要的话，合并 ETL 过程中的任何变化，使得集中的数据管理更加动态和灵活。

## 证明文件

如果你是一个把数据集放在一起的人，你可能知道关于它的一切。数据来自哪里，您用来填充缺失值的插值方法，或者支出日期是指从资金承诺日期到组织收到资金的实际日期之间的任何时间。随着越来越多的人开始关注你的数据集，你不能再把这些知识视为理所当然。这就是适当的数据治理和质量文档的来源。

除了描述数据元素的内容、格式和结构的数据字典之外，源到目标映射允许用户追溯每个数据元素的原始来源。随着计算、转换和数据丰富数量的增长，这对于保持透明度和准确性变得越来越重要。实施和维护这些类型的文档可以降低滥用数据的风险。

这也是为强大的数据治理框架奠定基础的时刻！