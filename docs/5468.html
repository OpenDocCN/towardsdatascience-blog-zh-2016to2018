<html>
<head>
<title>Review: R-FCN — Positive-Sensitive Score Maps (Object Detection)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">综述:R-FCN-阳性敏感得分图(物体检测)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-r-fcn-positive-sensitive-score-maps-object-detection-91cd2389345c?source=collection_archive---------4-----------------------#2018-10-20">https://towardsdatascience.com/review-r-fcn-positive-sensitive-score-maps-object-detection-91cd2389345c?source=collection_archive---------4-----------------------#2018-10-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="e35f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这个故事中，简要回顾了微软和清华大学的 R-FCN(基于区域的完全卷积网络)。<strong class="jp ir">通过正敏感得分图，推理时间比更快的 R-CNN 快得多，同时仍然保持竞争的准确性。</strong></p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/c8d208478390a8a58bb71a871ce9549f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*DE5BLluRs_qR76Mp"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><strong class="bd kx">From R-CNN to R-FCN</strong></figcaption></figure><p id="e68a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一篇在我写这篇论文的时候，在<strong class="jp ir"> 2016 NIPS </strong>上有超过<strong class="jp ir"> 700 次引用</strong>的论文。由于了解对象检测方法的发展可以更多地了解创新背后的原因，我希望我可以在未来的未来包括更多的对象检测方法。(<a class="ky kz ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----91cd2389345c--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="la lb l"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><strong class="ak">R-FCN Demonstration</strong></figcaption></figure></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h1 id="55c0" class="lj lk iq bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">涵盖哪些内容</h1><ol class=""><li id="4677" class="mh mi iq jp b jq mj ju mk jy ml kc mm kg mn kk mo mp mq mr bi translated"><strong class="jp ir">R-FCN 相对于 R-CNN 的优势</strong></li><li id="2abf" class="mh mi iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated"><strong class="jp ir">阳性敏感得分图&amp; ROI 汇集</strong></li><li id="5e59" class="mh mi iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated"><strong class="jp ir">其他详情</strong></li><li id="9f60" class="mh mi iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated"><strong class="jp ir">结果</strong></li></ol></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h1 id="c380" class="lj lk iq bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">1.<strong class="ak">R-FCN 相对 R-CNN 的优势</strong></h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="ab gu cl mx"><img src="../Images/3e4598d2c5600647cc4839eacacb94de.png" data-original-src="https://miro.medium.com/v2/format:webp/1*67iVyCzqapfB5Nyci_zynw.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><strong class="bd kx">R-CNN series</strong></figcaption></figure><p id="3538" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于传统的区域提议网络(RPN)方法，例如 R-CNN、快速 R-CNN 和更快 R-CNN，区域提议首先由 RPN 生成。然后完成 ROI 合并，并通过全连接(FC)层进行分类和边界框回归。</p><p id="2a37" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">ROI 合并后的流程(FC 层)不会在 ROI 之间共享，并且需要时间，这使得 RPN 方法很慢。FC 层增加了连接(参数)的数量，这也增加了复杂性。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi my"><img src="../Images/537cf0d1aeacd886a5acba3485f32411.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z8RC8gqJpwDuTujBEB47Nw.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><strong class="bd kx">R-FCN</strong></figcaption></figure><p id="0349" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在 R-FCN，我们仍有 RPN 来获取区域提案，但与 R-CNN 系列不同的是，ROI 汇集后的<strong class="jp ir"> FC 层被移除</strong>。相反，<strong class="jp ir">所有主要的复杂性都在 ROI 汇集之前移动，以生成评分图</strong>。所有区域提案，在 ROI 汇集后，将使用同一组得分图来执行<strong class="jp ir">平均投票</strong>，这是一个<strong class="jp ir">简单计算。</strong> <strong class="jp ir">因此，在 ROI 层之后没有可学习的层，这几乎是免费的。</strong>结果，R-FCN 甚至比具有竞争地图的更快的 R-CNN 还要快。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h1 id="3c20" class="lj lk iq bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">2.<strong class="ak">阳性敏感得分图&amp; ROI 合并</strong></h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nd"><img src="../Images/6386e744f69faffce4389373dd5de489.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cE6O2N7xxjnSqZzL_WFqDQ.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><strong class="bd kx">Positive-Sensitive Score Maps &amp; Positive-Sensitive ROI Pooling (k=3 in this figure) (Colors are important in this diagram)</strong></figcaption></figure><h2 id="3e5f" class="ne lk iq bd ll nf ng dn lp nh ni dp lt jy nj nk lx kc nl nm mb kg nn no mf np bi translated">2.1 阳性敏感得分图</h2><p id="4c51" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy nq ka kb kc nr ke kf kg ns ki kj kk ij bi translated">为了简单起见，让我们去掉 RPN。</p><p id="a5ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们有 C 类需要检测。(C+1)表示 C 个对象类加上背景类。</p><p id="17d5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在正敏感分数图之前的开始处的许多卷积之后，我们执行<strong class="jp ir"> k (C+1)-d 卷积</strong>。对于每个类，将有 k 个特征图。这些<strong class="jp ir"> k 特征图代表了{左上(TL)，中上(TC)、..，右下(BR)} </strong>我们要检测的对象。</p><h2 id="114a" class="ne lk iq bd ll nf ng dn lp nh ni dp lt jy nj nk lx kc nl nm mb kg nn no mf np bi translated">2.2 积极敏感的投资回报池</h2><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nt"><img src="../Images/b419752ddf8e7274f8a9070895fd98ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5P8_QXxg72JB1e-Ut5_rzw.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><strong class="bd kx">An Example of Positive-Sensitive ROI Pooling</strong></figcaption></figure><p id="a592" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当 ROI 合并时，产生大小为 k 的(C+1)个特征图，即 k (C+1)。在图中，它们以相同的面积和相同的颜色汇集在一起。执行平均投票以生成(C+1)个一维向量。最后对矢量进行 softmax。</p><p id="047f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当区域提案与以下目标不重叠时，我们将投反对票:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nu"><img src="../Images/0bbe57222c9bb3fb2fcdf343d7031501.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xoLqxkgh-Iy6JslijEyHBw.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><strong class="bd kx">When the region proposal does not overlap the object so much.</strong></figcaption></figure><h2 id="2799" class="ne lk iq bd ll nf ng dn lp nh ni dp lt jy nj nk lx kc nl nm mb kg nn no mf np bi translated">2.3 边界框回归</h2><p id="8b3d" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy nq ka kb kc nr ke kf kg ns ki kj kk ij bi translated">执行与类别无关的包围盒回归，这意味着回归在类别之间共享。</p><p id="ccb8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在 k (C+1)-d 卷积层，附加一个兄弟 4k -d 卷积层。在这个 4k 地图库上执行位置敏感 RoI 汇集，为每个 RoI 产生 4k -d 向量。然后通过平均投票聚合成一个 4-d 向量，表示包围盒的<strong class="jp ir"> {tx，ty，tw，th} </strong>(位置和大小)，和 Fast R-CNN 中的一样。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h1 id="f9db" class="lj lk iq bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated"><strong class="ak"> 3。其他细节</strong></h1><h2 id="1639" class="ne lk iq bd ll nf ng dn lp nh ni dp lt jy nj nk lx kc nl nm mb kg nn no mf np bi translated">3.1 主干架构</h2><p id="9214" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy nq ka kb kc nr ke kf kg ns ki kj kk ij bi translated">从 ImageNet 预训练的 ResNet-101 的前 100 个 conv 被用于在阳性敏感分数图之前计算特征图。</p><h2 id="9885" class="ne lk iq bd ll nf ng dn lp nh ni dp lt jy nj nk lx kc nl nm mb kg nn no mf np bi translated">3.2 培训</h2><p id="74f8" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy nq ka kb kc nr ke kf kg ns ki kj kk ij bi translated"><strong class="jp ir">损失紧随快速 R-CNN </strong>:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/c5b1a8f9d822d2927464e1f50874ab04.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*g-5hvGGoaCkT3h_LmYg_3w.png"/></div></figure><p id="43ea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Lcls 是分类损失，Lreg 是边界框回归损失。</p><p id="a446" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">在线硬例挖掘(OHEM) </strong>用于训练。在 N 个建议中，只有具有最高损失的顶部 B 个 ROI 被用于反向传播。</p><p id="ca19" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 4 步交替训练</strong>在更快的 R-CNN 中同样完成，以训练 RPN 和 R-FCN。</p><h2 id="c776" class="ne lk iq bd ll nf ng dn lp nh ni dp lt jy nj nk lx kc nl nm mb kg nn no mf np bi translated">3.3 推理</h2><p id="19a7" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy nq ka kb kc nr ke kf kg ns ki kj kk ij bi translated"><strong class="jp ir">非最大抑制(NMS) </strong>在 0.3 IoU 时执行后处理</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h1 id="7e56" class="lj lk iq bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">4.结果</h1><h2 id="be5a" class="ne lk iq bd ll nf ng dn lp nh ni dp lt jy nj nk lx kc nl nm mb kg nn no mf np bi translated">4.1 VOC 2007 <strong class="ak">数据集</strong></h2><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nw"><img src="../Images/6eb4cf0eaaedb98dfa786c28332c9342.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hDz7gG5yoe6QCteordr8_w.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><strong class="bd kx">Study of k values</strong></figcaption></figure><p id="72fd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">7×7 ROI 大小的 R-FCN 获得了 76.6%的 mAP，优于更快的 R-CNN。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nx"><img src="../Images/bee270560b66f069517f1c21c2384510.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4mQs4pb5xTn551ZnbN8tag.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><strong class="bd kx">The use of OHEM</strong></figcaption></figure><p id="e4f1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用 OHEM，获得了 79.5%的 mAP。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi ny"><img src="../Images/e1f458a33185a7d59c5de05a9e97b9a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rNQbnQzVJCvmpSt-XJN3IQ.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><strong class="bd kx">Multi-Scale Training</strong></figcaption></figure><p id="91d6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用不同比例的图像进行训练，R-FCN 具有 83.6%的 mAP，这比更快的 R-CNN++的 85.6%的 mAP 稍差。但是 R-FCN 的测试时间是每张图片 0.17 秒，比更快的 R-CNN++的测试时间(3.36 秒/张图片)快多了。这是因为 ROI 合并后没有 FC 层。</p><p id="0140" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">而且我们可以看到<strong class="jp ir">训练的细节也是至关重要的，这使得 mAP 增加了这么多，从 76.6%到 83.6%的 mAP。</strong></p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nz"><img src="../Images/c2564ad88dc6628cb3554a8f96f62335.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mxmntL4ho4RgAGfe0_vwbA.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><strong class="bd kx">Different Backbones on VOC 2007</strong></figcaption></figure><p id="5e45" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用 ResNet-152 与使用 ResNet-101 具有相似的映射。这是由于 ResNet 网络问题。<strong class="jp ir">如果在 ResNet 中使用身份映射，可以超过 1000 层</strong>，不会在 152 层饱和。(如果感兴趣，也请阅读我在<a class="ae oa" rel="noopener" target="_blank" href="/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e"> ResNet 上关于身份映射</a>的评论。)</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi ob"><img src="../Images/5f7dfd4c4f7f67371df69e5b90d56c97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SthhLuiCOtNAN7p8mwdhtQ.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><strong class="bd kx">Some Amazing Results on VOC 2007 Dataset</strong></figcaption></figure><h2 id="7dfc" class="ne lk iq bd ll nf ng dn lp nh ni dp lt jy nj nk lx kc nl nm mb kg nn no mf np bi translated">4.2 VOC 2012 和 MS COCO <strong class="ak">数据集</strong></h2><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi oc"><img src="../Images/9635cc34e1f834afc5b552d40dad14b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EwSh0rSUHu8OFCzpc86vOg.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><strong class="bd kx">VOC 2012 Dataset</strong></figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi od"><img src="../Images/9c922cff013ef0d1208c07a7309f18d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G778im-eUTKYBU1AA4QZuw.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><strong class="bd kx">MS COCO Dataset</strong></figcaption></figure><p id="a376" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">类似于 VOC 2007 数据集的结果，<strong class="jp ir"> R-FCN 比更快的 R-CNN++具有竞争力但 mAP 更低。</strong>但是<strong class="jp ir">R-FCN 的测试时间要快得多。</strong></p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="7f57" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对象检测方法可以分为两阶段(R-CNN 系列与 RPN)和一阶段(YOLO，SSD)方法。R-FCN 可以看作是两阶段方法中的一种快速方法。</p><p id="90d6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于了解对象检测方法的发展可以更多地了解创新背后的原因，我希望我可以在未来的未来包括更多的对象检测方法。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h1 id="35bc" class="lj lk iq bd ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg bi translated">参考</h1><p id="638e" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy nq ka kb kc nr ke kf kg ns ki kj kk ij bi translated">【2016 NIPS】【R-FCN】<br/><a class="ae oa" href="https://papers.nips.cc/paper/6465-r-fcn-object-detection-via-region-based-fully-convolutional-networks" rel="noopener ugc nofollow" target="_blank">R-FCN:经由基于区域的完全卷积网络的物体检测</a></p><h1 id="73b4" class="lj lk iq bd ll lm oe lo lp lq of ls lt lu og lw lx ly oh ma mb mc oi me mf mg bi translated">我的评论</h1><p id="8370" class="pw-post-body-paragraph jn jo iq jp b jq mj js jt ju mk jw jx jy nq ka kb kc nr ke kf kg ns ki kj kk ij bi translated">[<a class="ae oa" href="https://medium.com/coinmonks/review-r-cnn-object-detection-b476aba290d1" rel="noopener">R-CNN</a>][<a class="ae oa" href="https://medium.com/coinmonks/review-fast-r-cnn-object-detection-a82e172e87ba" rel="noopener">Fast R-CNN</a>][<a class="ae oa" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202">Fast R-CNN</a>][<a class="ae oa" href="https://medium.com/coinmonks/review-sppnet-1st-runner-up-object-detection-2nd-runner-up-image-classification-in-ilsvrc-906da3753679" rel="noopener">SPPNet</a>][<a class="ae oa" rel="noopener" target="_blank" href="/yolov1-you-only-look-once-object-detection-e1f3ffec8a89">yolov 1</a>][<a class="ae oa" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener">VGGNet</a>][<a class="ae oa" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8">ResNet</a>][<a class="ae oa" rel="noopener" target="_blank" href="/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e">ResNet with Identity Mapping</a>]</p></div></div>    
</body>
</html>