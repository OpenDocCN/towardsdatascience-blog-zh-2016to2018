# 分布如何，肯尼斯？

> 原文：<https://towardsdatascience.com/whats-the-distribution-kenneth-1cab2eefe7b8?source=collection_archive---------7----------------------->

今天早些时候，我发现自己被一个看似简单的问题彻底难倒了:如何解决罕见事件的分类问题？

从某种意义上说，这既是一个“容易”的问题，也是一个“困难”的问题。简单，因为分类算法很多。“困难”是指预测罕见事件通常并不容易:任何分类算法都会受到大量分类错误的困扰。

但是，我觉得有趣的是，这真的揭示了我的思维方式与普通的军情六处人员有多么不同。我的第一反应是按顺序列出逻辑回归、CART 和 RandomForest。为什么？因为我知道每种算法的运动部分是如何工作的，按照我列出的顺序，因此我知道我可以从每种算法中得到什么样的误差分布，以及当我从结果中看到意外的误差分布时会如何反应。我想我“应该”已经回答了梯度增强模型、AdaBoost 或类似的东西，因为我理论上“知道”它们会产生“更好”的预测(如果是这样，它不会很快出现，但是。)，但是，如果没有对何时、何地、如何以及为什么他们错了的良好感觉，也就是说，如果他们错了，如果他们没有错，如果没有错误，或者至少，如果我不知道错误的分布，我不确定我知道如何处理它们。换句话说，这表明我的想法有点反常，至少从通常统计人员的角度来看是这样——我不太关心信号，我最感兴趣的是噪声的分布。

当然，这在某种程度上是对增强模型的不公平描述:它们将模型本身的“错误”内在化了——只是它们的集合性质没有产生单一的明显的噪声分布。[这组课堂讲稿中的幻灯片 61–65 有助于可视化这个过程](http://www.chengli.io/tutorials/gradient_boosting.pdf):从“以噪声为中心”的角度来看，一个重要的事实是，根据观察到的特征，该算法很有可能将 G 误认为 Q、R 或 S，即使经过了相当多的回合。在某种意义上，这相当于我正在思考的那种噪声分布函数:我不在乎“正确”的答案是否是 g。例如，我想知道下一个“正确”的答案是什么(我猜这是 100 轮后的 Q)，它相对于第一个正确答案的概率(显然，约为 50%，100 轮后，0.2 比 0.4)，以及这个概率相对于其他概率的变化率。我也希望有一些东西，一些基线模型，可以这么说，这样我就可以估计“自然地”将 G 误认为 Q 的可能性有多大，这样就可以测量 ML 算法的预测能力，但我不认为有人会这样做，至少在这种情况下。(但有一些问题集中在变量之间的“依赖性”上，例如系词，它引发了一些相同的问题。不一定(太)不同:所谓的“资金外逃”会导致资产价格出现高度相关的短期波动。G 和 Q 在特征上的相似性很可能会将其中一个误认为另一个，即当真正的字母未知时，与配对的 G 和 A 相比，增加了它们在“识别”中的配对相关性——无论是谁或什么在做，将未知字母认为是 G 或 A 的可能性都不是很高。当然，最大似然算法给了我们该算法的概率，但是与它比较的基线选择是什么呢？).

我认为这就是统计学，至少我是这样理解的，与 ML 的观点不同的地方:如果在训练模型的过程中，数据有标签 G，那么它有 100%的概率是 G。在我看来，我不知道我看到了什么:它是有 40%概率的 G 和有 20%概率的 Q，在这之前我已经重复了 100 次关于 G 的观点。这在某种意义上是越(准贝叶斯？)“统计”思维——至少是我接受培训时的思维。我们不知道事实——如果我们知道，我们就不会做统计。(我认为最大似然法更类似于“经典统计学”，在这种意义上:假设 X 是 A，X 不是 A——因此假设潜在的正确答案，并计算给定样本的相对概率。在 ML 上下文中，概率是通过一个更长的过程来计算的。)现实永远只是一个概率分布，对任何事都不会在 p=1。为了搞清楚这一点，我们需要知道我们不知道多少——或者相对于第一种可能性的第二种、第三种或第四种可能性的概率，取决于观察到的样本。因此，统计分析的重点不在于最正确结果的概率，而在于它相对于其他选择有多好。另一方面，从 ML 的角度来看,“正确答案”必然存在，并且被封装在训练集中。问题是，该模型是否能像在训练过程中那样，在应用程序集(测试集和验证集，如果适用，作为中间步骤)中找到正确的答案。其他选项不存在，因为答案是 G，而不是 Q。(我对此的回答是，虽然您在训练/测试集中知道这一点，但您如何知道您是否在应用程序集中看到了 Q 或 G？当我在 2016 年选举前处理民调数据时，我遇到了这个问题:试图将样本分成训练集和测试集是毫无意义的，因为无论如何，直到选举日之前，我们都不知道真正的答案是什么。我们所能做的最好的事情是显示模型识别的各种特征相对于现有数据的稳健程度，但是全国范围内的投票率预测不太可能受到愚蠢的小波动的影响。)在我看来，如果你想变得敏捷，你需要知道第二、第三和第四种可能性是什么，以及它们发生的可能性有多大。所以，如果你认为你看到了一个 G，那么它真的是 Q，A，或者 F 的可能性有多大？如果使用得当，GBM 可以给出这些答案，但我还没有见过有人这样使用它——尽管我并不像我希望的那样关注当前的情况。

总之，我们不应该只是想知道正确的答案。我们所能做的就是根据算法中的任何内容，给出我们认为“最正确”的答案。理想情况下，我们应该想知道相对于“最正确的答案”，不太正确的答案的等级排序以及算法分配给它们的概率如果能够将概率与备选基线进行比较，那就更好了。(一个简单的例子是来自 DWNominate 算法的预测投票与人们只是投票给政党的天真假设。就绝对值而言，DWNominate 预测今天比以前更好，但人们也比以前更经常地投票给政党。与 20 世纪 70 年代相比，DWNominate 作为简单的以政党为中心的投票模型的选票预测指标的相对表现更差，政党和选票的相关性与今天一样。除此之外，在国会不同类别的投票中，DWNominate 得分的预测能力也有很大差异。)现实不仅仅是(据称)正确的答案。预测分析不仅应该帮助我们找到“最正确的”(特别是因为这些答案在无条件的意义上不一定是“正确的”)答案，更重要的是，与一些“合理的”基线(例如“平均值”)相比，这些答案有多错误对我来说，有趣的问题不是平均 X 看起来像什么，而是平均 X 离平均 X 有多远——这是双关语。当然，这是方差的函数定义，或多或少也是 k 级推理的工作方式)。