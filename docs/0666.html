<html>
<head>
<title>Learning about Data Science — Building an Image Classifier (part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解数据科学—构建图像分类器(第2部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learning-about-data-science-building-an-image-classifier-part-2-a7bcc6d5e825?source=collection_archive---------1-----------------------#2017-06-05">https://towardsdatascience.com/learning-about-data-science-building-an-image-classifier-part-2-a7bcc6d5e825?source=collection_archive---------1-----------------------#2017-06-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="70d4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意:这篇文章也可以叫做“我在哪里做得很快。ai的<a class="ae kl" href="http://course.fast.ai/lessons/lesson3.html" rel="noopener ugc nofollow" target="_blank">第三课</a>并意识到有很多东西我可以添加到我的模型中”。</p><p id="fdf6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第一部分，我建立了一个VGG模型:</p><div class="km kn gp gr ko kp"><a href="https://medium.com/@gabrieltseng/learning-about-data-science-building-an-image-classifier-3f8252952329" rel="noopener follow" target="_blank"><div class="kq ab fo"><div class="kr ab ks cl cj kt"><h2 class="bd ir gy z fp ku fr fs kv fu fw ip bi translated">了解数据科学—构建图像分类器</h2><div class="kw l"><h3 class="bd b gy z fp ku fr fs kv fu fw dk translated">嗨！我叫Gabi，正在学习数据科学。我计划写下我正在学习的东西，以帮助我组织…</h3></div><div class="kx l"><p class="bd b dl z fp ku fr fs kv fu fw dk translated">medium.com</p></div></div><div class="ky l"><div class="kz l la lb lc ky ld le kp"/></div></div></a></div></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><p id="7a88" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">我在这篇文章中创建的模型概要:</strong></p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lm"><img src="../Images/788c47feb9047f57136689dbe06648ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MYYz_cDryIwqcg9EAHbkhA.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">I trained the ResNet and Inception V3 models, and used their outputs (and the output of the VGG model trained in part 1) as inputs for a classifier, which I then used to combine the three models and output my final predictions.</figcaption></figure><p id="8555" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">内容:</strong></p><ol class=""><li id="b569" class="mb mc iq jp b jq jr ju jv jy md kc me kg mf kk mg mh mi mj bi translated">我对自己创建的第一个VGG网络实施了丢弃和批量归一化，但这最终对网络的改进作用不大</li><li id="6a5d" class="mb mc iq jp b jq mk ju ml jy mm kc mn kg mo kk mg mh mi mj bi translated"><strong class="jp ir">训练ResNet50和Inception V3 <br/> </strong>我使用Keras的应用程序来创建和加载预训练的ResNet 50和Inception V3网络，并对它们进行微调。</li><li id="53de" class="mb mc iq jp b jq mk ju ml jy mm kc mn kg mo kk mg mh mi mj bi translated"><strong class="jp ir">优化sklearn算法<br/> </strong>把3个模型结合起来，我用的是sklearn。</li></ol></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><p id="12e1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我注意到我的验证准确性高于我的训练准确性:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/92778dcfc44600d5c077d649aa875320.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*pMu5NmnUG_fkMrqdO5kO0w.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">A comparison of the training and validation accuracies for the first 5 epochs when training my model. This is the final model I trained, including the data augmentation and training all the way to the first convolutional layer.</figcaption></figure><p id="b8e1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这表明拟合不足，即模型过于受限，无法正确拟合训练数据。这可能是因为在完全连接的块中添加了一个层:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/0499b247ec70af97680311a086baed0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*YXArOs-E2_3A5Be-9TwJ4A.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">From part 1: A fully connected block, adding a fully connected layer followed by a dropout layer</figcaption></figure><p id="ceca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">丢弃层通过将一半的权重随机设置为0来防止过度拟合(在训练时，这不会发生在验证集上)。一种矫正方法是去除脱落层。</p><ol class=""><li id="072e" class="mb mc iq jp b jq jr ju jv jy md kc me kg mf kk mg mh mi mj bi translated"><strong class="jp ir">去除漏层和批量标准化</strong></li></ol><p id="3336" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">定义和动机:</p><p id="6153" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> Dropout </strong>随机将某个权重比率设置为0。这样做的后果是，它会导致欠拟合，因为我的模型正在训练的一半重量被忽略了。</p><p id="618c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">批处理规范化</strong>类似于我在第1部分中添加的均值预处理层，除了批处理规范化不只是在开始时规范化数据集，而是在层之间进行。这很有用，因为在模型中，值可能会变得非常大，从而扭曲权重。批量标准化可以避免这种情况，从而防止过度拟合。</p><p id="2b74" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我编写了以下方法来实现丢弃和批处理规范化:</p><figure class="ln lo lp lq gt lr"><div class="bz fp l di"><div class="mr ms l"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">vgg_bn returns a VGG model with a defined dropout, and (optionally) with batch normalization. Lines 24–26 adjust the weights, multiplying them by 0.5/(1-dropout). Adding batch normalization doesn’t increase the number of layers in the model, so the weights can be directly copied over by enumerating over both models’ layers using zip()</figcaption></figure><p id="b22c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我使用它能得到的最好结果是批量标准化和0.5的丢弃率(事实证明，删除丢弃率会导致显著的过度拟合，并显著降低验证的准确性)。</p><p id="2232" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就是说，改进是微不足道的(99%对98.5%的验证准确率只代表多了一张正确分类的图像)，并且没有反映在Kaggle中，表明该模型没有显著改进。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mt"><img src="../Images/7b6636b82eb424e9e8098587e41b2332.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6XOsQDkWIo8xaYMzZuOTTw.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">The best result so far!</figcaption></figure><p id="3cc6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">幸运的是，我还有一招！</p><p id="f85d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 2。与ResNet组装</strong></p><p id="8cbe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果我训练不同的模型，它们可能会拾取稍微不同的东西，因此在它们之间，可能所有的图像都被正确分类。因此，我可以训练多个模型，然后组合它们的输出；这被称为集合。</p><p id="0387" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">具体来说，我要训练ResNet50，它在2015年赢得了ImageNet比赛(VGG在2014年获胜)。</p><p id="053a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 2.a.i .实施ResNet </strong></p><p id="575e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> ResNet-50 </a>在映像网2015年的比赛中胜出(VGG在2014年的比赛中胜出)。我的希望是，这两个模型中的差异将允许它们相互补偿，并最终产生更强的结果。</p><p id="fd2c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">ResNet50是一个<strong class="jp ir"> res </strong> idual <strong class="jp ir"> net </strong>的作品，它远比卷积网络(107层到VGG的38层)更深入。形象化ResNet的一个好方法是卷积块的集合(回想一下，集合是不同模型的输出组合)。</p><p id="c9e8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Keras实际上已经预装了一些模型(包括重量)，作为其<a class="ae kl" href="https://keras.io/applications/" rel="noopener ugc nofollow" target="_blank">应用</a>的一部分；我想构建自己的ResNet模型，这样我就可以包含一个预处理层(使用<a class="ae kl" href="http://files.fast.ai/models/" rel="noopener ugc nofollow" target="_blank"> fast.ai weights </a>)，但我也将从这里开始绘制。</p><figure class="ln lo lp lq gt lr"><div class="bz fp l di"><div class="mr ms l"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">The definition for the Lambda layer is a little different than for the VGG model, see why <a class="ae kl" href="https://github.com/fchollet/keras/issues/6442" rel="noopener ugc nofollow" target="_blank">here</a>.</figcaption></figure><p id="792d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 2.a.ii培训结果网</strong></p><p id="f5c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了训练ResNet，我使用了与VGG相同的图像数据生成器。我分两个阶段训练ResNet，首先训练(随机初始化的)最后一层，然后也训练最后一个卷积块。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mu"><img src="../Images/919cdf9f7946ea8c8f2894803dcf24ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WN_GwsKHws2k1dOaDGA-ZA.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">The vertical red line marks where I allow more layers to be trained.</figcaption></figure><p id="17ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在学习率下降的情况下，对更多的时期(另外40个时期)训练ResNet，将验证准确率提高到97%。</p><p id="6d59" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 2.b .盗梦空间V3 </strong></p><p id="4317" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在尝试让ResNet模型工作了很长时间之后，我意识到lambda层对它的性能没有什么帮助。因此，我添加了Inception V3模型，它也是由Keras预加载的，并根据ImageNet数据进行了训练:</p><figure class="ln lo lp lq gt lr"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="bf42" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我将这个V3模型与数据进行拟合:</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mv"><img src="../Images/2d6353469bb81e0dd28478bf1d311bd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K2spgYGA6CrTYtdPzWeJgQ.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">A plot of accuracy against epochs when training the Inception V3 model. The red line marks where I allowed more layers to be trained.</figcaption></figure><p id="89de" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 2.b .组合模型</strong></p><p id="e39e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我打算使用Keras合并层来合并这两个模型。然而，有一个问题:VGG模型是顺序模型，而ResNet和V3模型是功能模型。我在ResNet和VGG中引入的lambda层可以自动预处理图像，这意味着Keras不想将模型从顺序模型更改为功能模型(否则，它<a class="ae kl" href="https://keras.io/models/about-keras-models/" rel="noopener ugc nofollow" target="_blank">应该能够</a>)，所以我要做的是使用<a class="ae kl" href="http://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> Scikit-learn </a>来组合模型。</p><p id="ff47" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为此，我将使用VGG和雷斯内特的输出作为我的线性回归的输入:</p><figure class="ln lo lp lq gt lr"><div class="bz fp l di"><div class="mr ms l"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">This method takes the outputs of the models in the input array ‘model’, and turns them into X data- features- with which a scikit learn linear regression can be trained. The classes of the batches — the true Y values — is also returned. The shape of X is printed to make sure everything is going okay; the number of rows should increase by 1 for every model trained, and the number of columns should stay constant.</figcaption></figure><p id="1e78" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我使用make_xy制作了以下几对特征:</p><p id="2607" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">X_train和Y_train，基于训练数据。</p><p id="fe0e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基于验证数据的X_valid和Y_valid。</p><p id="e764" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我用k近邻、支持向量机和逻辑回归算法进行了实验。</p><p id="a62d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">具有10个邻居的k个最近邻居产生最高的AUC-ROC得分(0.9866)。</p><figure class="ln lo lp lq gt lr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mw"><img src="../Images/b13b9544cb9cf047d35eb200d5139b77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zz7UfX1VOhcq_VKAZgd07g.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk">The AUC-ROC of the knn algorithm when ensembled from the X and Y data.</figcaption></figure><p id="d009" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">结论，我学到了什么</strong></p><p id="b080" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我从集合中最大的收获是，许多差的模型不能弥补一个强的模型；当ResNet和V3达到大约90%的准确率时，我开始尝试组合这些模型，这降低了我的最终分数，而不是提高了它。</p><p id="0b25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我的第二个观点是模特需要很长的训练时间！我在训练我的VGG模型时使用了<a class="ae kl" href="https://keras.io/callbacks/" rel="noopener ugc nofollow" target="_blank">提前停止回调</a>，但没有在Inception V3的ResNet中使用它，因为这些模型并不总是具有不断增加的准确性，提前停止通常会缩短它们的训练。不使用早期停止意味着我没有为大约20个时期训练我的模型，而是最终为接近50或60个时期训练它们。</p><p id="8006" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我也有过快降低学习速度的倾向，并假设模型已经收敛；实验(和耐心)让我大大提高了模型的能力。</p><p id="3a2c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我认识到这个过程可能会令人沮丧！我花了很多时间在最终没有改善我的最终结果的路径上，但是最终得到一个更强的模型是非常棒的。</p></div></div>    
</body>
</html>