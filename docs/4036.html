<html>
<head>
<title>Eigen Vector Projection Auto Encoders in TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow 中的特征向量投影自动编码器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/eigen-vector-projection-auto-encoders-in-tensorflow-46a376dafb34?source=collection_archive---------8-----------------------#2018-07-11">https://towardsdatascience.com/eigen-vector-projection-auto-encoders-in-tensorflow-46a376dafb34?source=collection_archive---------8-----------------------#2018-07-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/78c2b813b32b85262984fcbd366d1672.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*BVSn3b8HuF4ylXBYexrhrA.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">GIF from this <a class="ae jy" href="https://giphy.com/gifs/afvpets-afv-americas-funniest-home-videos-l41Yea1LYiWd8HBGU" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="c2f9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最近我一直在玩<a class="ae jy" rel="noopener" target="_blank" href="/only-numpy-having-fun-with-eigen-value-s-vectors-with-interactive-code-in-numpy-80d3443dfd22">特征值和向量以及投影</a>。(通过点积)现在我想看看它们是如何被整合到神经网络中的。(自动编码器)。此外，请注意，我在这里使用的技术与执行<a class="ae jy" href="https://sebastianraschka.com/Articles/2014_pca_step_by_step.html#4-computing-eigenvectors-and-corresponding-eigenvalues" rel="noopener ugc nofollow" target="_blank">主成分分析(PCA </a>)时非常相似，但并不完全相同。(具体来说，我没有删除维度，也没有对特征值进行排序)。所以我不会叫它 PCA。在这篇文章中，我将比较不同的自动编码器，如…..</p><p id="de41" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="kx">情况 a)改变潜在向量基的自动编码器<br/>情况 b)改变潜在向量基并增加网络参数的自动编码器<br/>情况 c)普通自动编码器<br/>情况 d)改变潜在向量基的自动编码器(不同的激活函数)<br/>情况 e)改变隐藏层基的自动编码器<br/>情况 f)改变隐藏层基的自动编码器(2) </em> </strong></p><blockquote class="ky kz la"><p id="0a83" class="jz ka kx kb b kc kd ke kf kg kh ki kj lb kl km kn lc kp kq kr ld kt ku kv kw ij bi translated"><strong class="kb ir">请注意，这个帖子只是为了自己表达创意。</strong></p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="ea5b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">网络架构/数据集</strong></p><div class="ll lm ln lo gt ab cb"><figure class="lp jr lq lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/2b025d560a821d806850e5295f77d939.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*9YeV40h--XeII5pyiKGgiw.png"/></div></figure><figure class="lp jr lz lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/91eedfc1af340faa8043e3fa51df1d0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*sQGrVsDZ4EhHIsj2bgNdvw.png"/></div></figure></div><p id="9e15" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">蓝色矩形</strong> →卷积/全连接层<br/> <strong class="kb ir">红色矩形</strong> →转置卷积/全连接层</p><p id="04e6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，我们的网络仅由 3 个卷积运算、2 个全连接层和 2 个用于上采样的转置卷积运算组成。对于下采样操作，我选择使用下采样操作。现在我将要使用的数据集是著名的<a class="ae jy" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST 数据集。</a></p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="dcb8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="kx">情况 a)自动编码器改变潜在向量的基础</em> </strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ma"><img src="../Images/6ca3c400f9980f3979659cb038886526.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i2Z600ZmxitzPwXBn2BTyQ.png"/></div></div></figure><p id="e745" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">红色部分</strong> →自动编码器潜在向量的基础变化</p><p id="c458" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">由于我们要将维度从 28*28 降低到 3，因此我们实际上可以计算隐藏表示的协方差矩阵，并使用协方差矩阵的特征向量来投影原始数据。</p><div class="ll lm ln lo gt ab cb"><figure class="lp jr mb lr ls lt lu paragraph-image"><img src="../Images/93ea5d8ff789d31818ae5c3c52d5890f.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/1*f83hDJaNP2qN5q30Khd-jw.gif"/></figure><figure class="lp jr mc lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/ee34e0dbed09270392ae20a5142e7281.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*m7aCcux1XhiQ19-NtGslaA.png"/></div></figure></div><p id="bd77" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左侧 GIF </strong> →生成的训练图像<br/> <strong class="kb ir">右侧图像</strong> →训练阶段的时间成本</p><p id="c9d3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">网络在生成原始图像方面表现不佳，大多数图像都很模糊，甚至与原始图像不接近。现在让我们来看看编码向量的潜在空间。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi md"><img src="../Images/10ffe39d7e71d2b33a7e853f9a24cca4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*dKNI4COxmVz6O-ImYiKj4g.gif"/></div></div></figure><p id="cbea" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，在改变基底之前，我们可以看到编码器实际上在将相似图像彼此聚类方面做得很好。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi md"><img src="../Images/26006377991791da611c4c2f41bd6665.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Ei7Muq42VX92YAKZXfvSbg.gif"/></div></div></figure><p id="a149" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">然而，在投影到本征向量后，我们可以看到，现在数据已经混合在一起，显然彼此不能完全分开。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="88b4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="kx">情况 b)增加了网络参数</em> </strong>改变了潜在向量的基的自动编码器</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi me"><img src="../Images/4ba62e06c0a1d06a931945409798da31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zFuiuDZ4fPNjBeKRHr-zGw.png"/></div></div></figure><p id="1836" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在，我添加了一个名为 network_effect 的参数，这是一个来自均匀分布的 3*3 矩阵。(范围 0–1)。这是因为我想让网络对投影空间有更多的控制。</p><div class="ll lm ln lo gt ab cb"><figure class="lp jr mb lr ls lt lu paragraph-image"><img src="../Images/e94491ad5da95425ca99ad91dd985485.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/1*czzA5BB3s6gnSYD1Uhz3FQ.gif"/></figure><figure class="lp jr mc lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/d381a4a92b3cc51e38b5784698168f66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*IZDFy7GQ6OhjXn0HIoCeow.png"/></div></figure></div><p id="02cc" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图 GIF </strong> →生成的训练图像<br/> <strong class="kb ir">右图</strong> →训练阶段的时间成本</p><p id="e039" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">与情况 a)相比，该网络做得还不错，然而，同样，大多数生成的图像是模糊的，不可识别的。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi md"><img src="../Images/dff603edef80bbc5feec75778fa5f8eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*YrI9TuLnNG4-lE4m33XzfA.gif"/></div></div></figure><p id="7648" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同样，当我们可视化编码的潜在空间时，我们观察到编码器在聚类相似图像方面做得很好。(投影前)</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi md"><img src="../Images/91eba7fdb5c5e547c90a20d34956363a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*v4pOn7D5zUMbWYmv7FvmSQ.gif"/></div></div></figure><p id="3f64" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">但是，在向量投影之后，每一类之间的编码空间实际上恶化了。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="5a70" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="kx">案例 c)普通自动编码器</em> </strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mf"><img src="../Images/c588e31114d8bc7b6e41d9de1e9aac34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*idhAwlIiP-LF2ZQSOeXybQ.png"/></div></div></figure><p id="438c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">被上面两个网络的性能所质疑，我想知道网络架构本身是否是问题所在。所以我训练了一个普通的自动编码器。</p><div class="ll lm ln lo gt ab cb"><figure class="lp jr mb lr ls lt lu paragraph-image"><img src="../Images/76c792766f20d613b54d1cb5c9b40255.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/1*EGCgAUT4BcQY7ikFfRKYNg.gif"/></figure><figure class="lp jr mc lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/1279f3974f8edabb58c502781e69c5d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*l2YezdA5tghVEu3dk0v7YA.png"/></div></figure></div><p id="7f73" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左侧 GIF </strong> →生成的训练图像<br/> <strong class="kb ir">右侧图像</strong> →训练阶段的时间成本</p><p id="087b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">与其他网络相比，vanilla 在生成和分离潜在空间中的数据方面做得最好。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi md"><img src="../Images/0a2599d38c9eee2bab88fc58d313d8e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*BvmnavBd3qk4l-CBT5hC5g.gif"/></div></div></figure><p id="9afe" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，每种颜色的数据点都很好地聚集在一起。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="2b56" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="kx">情况 d)自动编码器改变潜在向量的基础(不同的激活函数)</em> </strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mg"><img src="../Images/6899b3c96231872e169d3c0415a77f55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*99YQQ3JuZ4_IK1KS83chzw.png"/></div></div></figure><p id="7df0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">红色部分</strong> → Tanh 激活功能</p><p id="0b8f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">从以前的 GIF 中，我们可以观察到生成的潜在空间的范围是巨大的。(当我们要生成数据的时候，这不是一件好事。所以我想看看当我使用一个双曲正切函数而不是一个恒等函数时，事情会有什么变化。</p><div class="ll lm ln lo gt ab cb"><figure class="lp jr mb lr ls lt lu paragraph-image"><img src="../Images/576ffc90e7e92f1b58a550b6d45d7ff9.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/1*gCsA2HzKD59RGfhxYn0nTw.gif"/></figure><figure class="lp jr mc lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/aa3ad83367acdd7ae2b5768bfba787e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*xf6ImscbKMiFBYQt2q7Pbw.png"/></div></figure></div><p id="1e13" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左侧 GIF </strong> →生成的训练图像<br/> <strong class="kb ir">右侧图像</strong> →训练阶段的时间成本</p><p id="9032" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">不幸的是，生成的图像非常模糊，不是最好的。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi md"><img src="../Images/99478d885a687425107984007d310b32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*btU2GWr0CLDQDdiRcHN-xA.gif"/></div></div></figure><p id="6a5a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，现在潜在空间在更近的范围内，但是数据点彼此之间的聚类很差。非常非常差。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi md"><img src="../Images/3cc1eb2e6bdc41f4e76101cb89dc8fa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*IxH66WTzg5zUzFOlir283w.gif"/></div></div></figure><p id="7f64" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">然而，在投射之后，它产生了我所见过的最有趣的图案。我希望回到这件事上来，因为它太有趣了。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="366b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="kx">情况 e)隐藏层</em> </strong>基础改变的自动编码器</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mh"><img src="../Images/b7e2929fb3eb316899030f86b1322090.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*knIhNxDJj4tjGaomEmnmWg.png"/></div></div></figure><p id="9385" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在，我想看看当我在创建潜在空间的完全连接的层后面的层上执行投影时的效果。(如果我可怕的描述没有意义，请理解为我在不同的层上做了相同的操作。)</p><div class="ll lm ln lo gt ab cb"><figure class="lp jr mb lr ls lt lu paragraph-image"><img src="../Images/bb8907b209fb97a3c9e1e868023c073a.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/1*LTJ0pufJa0C-GrQyiClIjg.gif"/></figure><figure class="lp jr mc lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/5812a28aabb9f690e690710a3cfab150.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*CcvqZwWLJQ-m1MqGSrQf6A.png"/></div></figure></div><p id="1c94" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">网络实际上在生成新图像方面做得很好，当我们观察潜在空间时，我们可以观察到类似的潜在空间，当我们与普通的自动编码器进行比较时。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi md"><img src="../Images/546cebf698fc9c231e2340e7faa6c770.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*XwXp7SuLSo7mp4BULh0GRw.gif"/></div></div></figure><p id="a154" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">实际上，我认为它比普通的自动编码器做得更好。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="b085" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="kx">情况 f)自动编码器与隐藏层的基础变化(2) </em> </strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mi"><img src="../Images/a39f6d0c23d0924ad418d7c8ff2aeeb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aK87QC2xvFH_pGqMrHplhg.png"/></div></div></figure><p id="b26a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">前一个实验者的自然延伸是在不同的层上执行相同的操作。(在这里，我将在前面两层上执行它。)</p><div class="ll lm ln lo gt ab cb"><figure class="lp jr mb lr ls lt lu paragraph-image"><img src="../Images/279533de8e99c4e8538b47bb53464ae3.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/1*Ga9Ju-9AcV7cYMAiVvmJgg.gif"/></figure><figure class="lp jr mc lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/dc488a8c509daf2e0e3d54f28b6bd7c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*M1ixIFPRhw7zJo3qr1Ab_g.png"/></div></figure></div><p id="0581" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">尽管这个网络产生了最有趣的图像模式，但实验还是彻底失败了。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi md"><img src="../Images/48fdad2a32b54be13cee4cf79416b58e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*V0RbMu118SHXwrVLiicPIw.gif"/></div></div></figure><p id="184e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">当我们看到潜在空间时，我们可以看到这些数据点是无法区分的。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="654a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">互动码</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mj"><img src="../Images/b3683d7fc2da7b2264057b913fcc2dd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nu1EiARGgWryQgUCzNCiPg.png"/></div></div></figure><p id="69c6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于 Google Colab，您需要一个 Google 帐户来查看代码，而且您不能在 Google Colab 中运行只读脚本，所以请在您的操场上创建一个副本。最后，我永远不会请求允许访问你在 Google Drive 上的文件，仅供参考。编码快乐！同样为了透明，我在 github 上上传了所有的训练日志。</p><p id="88a1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">要访问<a class="ae jy" href="https://colab.research.google.com/drive/1OZPXC31aa_vfNlZcU9YQN2f_N1Zvat9P" rel="noopener ugc nofollow" target="_blank">案例 a 的代码，请单击她的</a> e，要查看<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/eigen_auto/casea/viz/casea.txt" rel="noopener ugc nofollow" target="_blank">日志，请单击此处。</a> <br/>点击 h 查看<a class="ae jy" href="https://colab.research.google.com/drive/1JJTkQssUfBrx7FKFADktkfjHYvQHN08q" rel="noopener ugc nofollow" target="_blank">案例 b 的代码，点击 l </a><a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/eigen_auto/caseb/viz/caseb.txt" rel="noopener ugc nofollow" target="_blank"> ogs 点击此处</a>。<br/>要访问<a class="ae jy" href="https://colab.research.google.com/drive/1mI3O58MCQNHZH16L8CXEH3d7P0toqpWC" rel="noopener ugc nofollow" target="_blank">案例 c 的代码，单击</a> re，要查看<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/eigen_auto/casec/viz/casec.txt" rel="noopener ugc nofollow" target="_blank">日志，单击此处</a>。<br/>点击此处访问<a class="ae jy" href="https://colab.research.google.com/drive/11tKfr129M8GoF0gyt7Qd2J1TWC7BXh_A" rel="noopener ugc nofollow" target="_blank"> r 案例 d 的代码，点击此处查看</a><a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/eigen_auto/cased/viz/cased.txt" rel="noopener ugc nofollow" target="_blank">日志。</a> <br/>访问<a class="ae jy" href="https://colab.research.google.com/drive/1aw4PmlS7VrdBXypV0GY89hDQ9V2-yAcx" rel="noopener ugc nofollow" target="_blank">案例 e 的代码点击此处，</a><a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/eigen_auto/casee/viz/casee.txt" rel="noopener ugc nofollow" target="_blank">日志的</a>点击此处。 <br/>点击此处查看<a class="ae jy" href="https://colab.research.google.com/drive/151eI5QtO6xUU7qAVuIUhS-QMdfIXLpp6" rel="noopener ugc nofollow" target="_blank">案例 f 的代码</a>，点击此处查看<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/NeuralNetwork/eigen_auto/casef/viz/casef.txt" rel="noopener ugc nofollow" target="_blank">日志。</a></p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="aa11" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">最后的话</strong></p><p id="f64f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这是一个非常有趣的实验，通常我认为自动编码器本身就是一种降维的方法。但是现在，我越来越想知道是否可以在网络中加入额外的技术。</p><p id="dd31" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 给我，如果你想看我所有写作的列表，请在这里查看我的网站。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的 twitter 上关注我<a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>，访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或者我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。我还实现了<a class="ae jy" href="https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec" rel="noopener">广残网，请点击这里查看博文</a> t。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="18bc" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="1919" class="mk ml iq kb b kc kd kg kh kk mm ko mn ks mo kw mp mq mr ms bi translated">导入 tflearn 错误:属性错误:模块“熊猫”没有属性“计算”问题#766 tflearn/tflearn。(2018).GitHub。检索于 2018 年 7 月 11 日，来自<a class="ae jy" href="https://github.com/tflearn/tflearn/issues/766" rel="noopener ugc nofollow" target="_blank">https://github.com/tflearn/tflearn/issues/766</a></li><li id="f91a" class="mk ml iq kb b kc mt kg mu kk mv ko mw ks mx kw mp mq mr ms bi translated">适合 ML 初学者的 MNIST。(2018).张量流。检索于 2018 年 7 月 11 日，来自<a class="ae jy" href="https://www.tensorflow.org/versions/r1.0/get_started/mnist/beginners" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/versions/r 1.0/get _ started/mnist/初学者</a></li><li id="f4de" class="mk ml iq kb b kc mt kg mu kk mv ko mw ks mx kw mp mq mr ms bi translated">警告，T. (2018)。Tensorflow 导入 mnist 警告。堆栈溢出。检索于 2018 年 7 月 11 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/49901806/tensorflow-importing-mnist-warnings" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/49901806/tensor flow-importing-mnist-warnings</a></li><li id="b0f3" class="mk ml iq kb b kc mt kg mu kk mv ko mw ks mx kw mp mq mr ms bi translated">TensorFlow，E. (2018)。张量流中的特征值问题。堆栈溢出。检索于 2018 年 7 月 11 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/43697539/eigenvalue-problems-in-tensorflow" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/43697539/tensor flow 中的特征值问题</a></li><li id="9157" class="mk ml iq kb b kc mt kg mu kk mv ko mw ks mx kw mp mq mr ms bi translated">基本功能的领域和范围。(2018).Analyzemath.com。检索于 2018 年 7 月 11 日，来自<a class="ae jy" href="http://www.analyzemath.com/DomainRange/domain_range_functions.html" rel="noopener ugc nofollow" target="_blank">http://www . analyze math . com/domain range/domain _ range _ functions . html</a></li><li id="a6b6" class="mk ml iq kb b kc mt kg mu kk mv ko mw ks mx kw mp mq mr ms bi translated">tf.self _ 共轭 _eig | TensorFlow。(2018).张量流。检索于 2018 年 7 月 11 日，来自<a class="ae jy" href="https://www.tensorflow.org/api_docs/python/tf/self_adjoint_eig" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/self _ 共轭 _eig </a></li><li id="e601" class="mk ml iq kb b kc mt kg mu kk mv ko mw ks mx kw mp mq mr ms bi translated">(2018).Users.stat.umn.edu。检索于 2018 年 7 月 11 日，来自<a class="ae jy" href="http://users.stat.umn.edu/~helwig/notes/datamat-Notes.pdf" rel="noopener ugc nofollow" target="_blank">http://users.stat.umn.edu/~helwig/notes/datamat-Notes.pdf</a></li><li id="5c99" class="mk ml iq kb b kc mt kg mu kk mv ko mw ks mx kw mp mq mr ms bi translated">tf.random_uniform | TensorFlow。(2018).张量流。检索于 2018 年 7 月 11 日，来自<a class="ae jy" href="https://www.tensorflow.org/api_docs/python/tf/random_uniform" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/random _ uniform</a></li><li id="ef12" class="mk ml iq kb b kc mt kg mu kk mv ko mw ks mx kw mp mq mr ms bi translated">tf.self _ 共轭 _eig | TensorFlow。(2018).张量流。检索于 2018 年 7 月 11 日，来自<a class="ae jy" href="https://www.tensorflow.org/api_docs/python/tf/self_adjoint_eig" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/self _ agreement _ EIG</a></li><li id="15f4" class="mk ml iq kb b kc mt kg mu kk mv ko mw ks mx kw mp mq mr ms bi translated">实施主成分分析(PCA)。(2014).塞巴斯蒂安·拉什卡博士。检索于 2018 年 7 月 11 日，来自<a class="ae jy" href="https://sebastianraschka.com/Articles/2014_pca_step_by_step.html#4-computing-eigenvectors-and-corresponding-eigenvalues" rel="noopener ugc nofollow" target="_blank">https://sebastianraschka . com/Articles/2014 _ PCA _ step _ by _ step . html # 4-计算-特征向量-及对应-特征值</a></li><li id="5d88" class="mk ml iq kb b kc mt kg mu kk mv ko mw ks mx kw mp mq mr ms bi translated">MNIST 手写数字数据库，Yann LeCun，Corinna Cortes 和 Chris Burges。(2018).Yann.lecun.com。检索于 2018 年 7 月 11 日，来自<a class="ae jy" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank">http://yann.lecun.com/exdb/mnist/</a></li></ol></div></div>    
</body>
</html>