<html>
<head>
<title>Linear Regression Using Least Squares</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用最小二乘法的线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-regression-using-least-squares-a4c3456e8570?source=collection_archive---------0-----------------------#2018-09-08">https://towardsdatascience.com/linear-regression-using-least-squares-a4c3456e8570?source=collection_archive---------0-----------------------#2018-09-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jn jo jp jq"><div class="bz fp l di"><div class="jr js l"/></div></figure><p id="70c9" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">线性回归是最简单的机器学习形式。在这篇文章中，我们将看到线性回归是如何工作的，并从头开始用 Python 实现它。这是上面视频的文字版。如果你喜欢的话，就看着吧。</p><figure class="ks kt ku kv gt jq gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi kr"><img src="../Images/0c7066d7289059e51834796a73bd86eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*QG8dIxNTaBH7Qrxq"/></div></div></figure><h1 id="8ae0" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">线性回归</h1><p id="e0d0" class="pw-post-body-paragraph jt ju iq jv b jw ma jy jz ka mb kc kd ke mc kg kh ki md kk kl km me ko kp kq ij bi translated">在统计学中，线性回归是一种对因变量和一个或多个自变量之间的关系进行建模的线性方法。在一个独立变量的情况下，它被称为简单线性回归。对于一个以上的独立变量，这个过程称为多元线性回归。我们将在本教程中处理简单的线性回归。<br/>设<strong class="jv ir"> X </strong>为自变量<strong class="jv ir"> Y </strong>为因变量。我们将定义这两个变量之间的线性关系如下:</p><figure class="ks kt ku kv gt jq gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/75af73122d6d56bfdb10241f4d2e2ee5.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*p3LTR6GB6g2MpRZzE5JIxw.png"/></div></figure><figure class="ks kt ku kv gt jq gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/d1132de814e7b6ca17db01c669e95d87.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/0*VOqAHDEG8sspPRXC.gif"/></div></figure><p id="e856" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">这是你在高中学过的一条线的方程。<strong class="jv ir"> m </strong>是直线的斜率，<strong class="jv ir"> c </strong>是 y 轴截距。今天，我们将使用这个等式用给定的数据集来训练我们的模型，并针对任何给定的<strong class="jv ir"> X </strong>值来预测<strong class="jv ir"> Y </strong>的值。</p><p id="031e" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">我们今天的挑战是确定<strong class="jv ir"> m </strong>和<strong class="jv ir"> c </strong>的值，它给出了给定数据集的最小误差。我们将通过使用<strong class="jv ir">最小二乘法</strong>来实现这一点。</p><h1 id="7053" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">查找错误</h1><p id="fc27" class="pw-post-body-paragraph jt ju iq jv b jw ma jy jz ka mb kc kd ke mc kg kh ki md kk kl km me ko kp kq ij bi translated">因此，为了最小化误差，我们首先需要一种计算误差的方法。机器学习中的<strong class="jv ir">损失函数</strong>仅仅是预测值与实际值有多大差异的度量。<br/>今天我们将使用<strong class="jv ir">二次损失函数</strong>来计算我们模型中的损失或误差。它可以定义为:</p><figure class="ks kt ku kv gt jq gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/65dc2093d9e29709c7a7d1401dc8f9e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*fobzyXo5yQtPMNTUWfCPJg.png"/></div></figure><figure class="ks kt ku kv gt jq gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi kr"><img src="../Images/f104d52b83086e515dffcb12b935bb84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OVG0UBquPwSiwiUi"/></div></div></figure><p id="d40d" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">我们对它求平方是因为，对于回归线<strong class="jv ir">以下的点，y-p</strong>将为负，我们不希望总误差为负值。</p><h1 id="1a8b" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">最小二乘法</h1><p id="6279" class="pw-post-body-paragraph jt ju iq jv b jw ma jy jz ka mb kc kd ke mc kg kh ki md kk kl km me ko kp kq ij bi translated">现在我们已经确定了损失函数，剩下唯一要做的就是最小化它。这是通过找到<strong class="jv ir"> L </strong>的偏导数，使其等于 0，然后找到<strong class="jv ir"> m </strong>和<strong class="jv ir"> c </strong>的表达式来实现的。在我们完成数学计算后，我们只剩下这些等式:</p><figure class="ks kt ku kv gt jq gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/a302ea98f62b7879381b94bed919a9b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*f_VhshEGxwhT4tZLDzwtgA.png"/></div></figure><p id="6709" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">这里，x̅是输入<strong class="jv ir"> X </strong>中所有值的平均值，而ȳ是期望输出<strong class="jv ir"> Y </strong>中所有值的平均值。这是最小二乘法。现在我们将在 python 中实现这个并进行预测。</p><h1 id="3a91" class="lc ld iq bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">实施模型</h1><figure class="ks kt ku kv gt jq"><div class="bz fp l di"><div class="mi js l"/></div></figure><figure class="ks kt ku kv gt jq gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi mj"><img src="../Images/fa87c33e9dd58d8e52fc829d03bb3036.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*se-AiMX0UbUtBTL9xsnaXQ.png"/></div></div></figure><figure class="ks kt ku kv gt jq"><div class="bz fp l di"><div class="mi js l"/></div></figure><pre class="ks kt ku kv gt mk ml mm mn aw mo bi"><span id="4bfd" class="mp ld iq ml b gy mq mr l ms mt">1.287357370010931 9.908606190326509</span></pre><figure class="ks kt ku kv gt jq"><div class="bz fp l di"><div class="mi js l"/></div></figure><figure class="ks kt ku kv gt jq gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi mj"><img src="../Images/9d1eaa4d5df38838f640dce54547becf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*U49P8IvSW_8U7xzA"/></div></div></figure><p id="2f82" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">不会有太多的准确性，因为我们只是简单地取一条直线，并迫使它以最好的方式适应给定的数据。但是你可以用它来做简单的预测或者了解真实值的大小/范围。对于机器学习的初学者来说，这也是很好的第一步。</p><p id="3fd5" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated"><em class="mu">在这里找到数据集和代码:</em><a class="ae mv" href="https://github.com/chasinginfinity/ml-from-scratch/tree/master/01%20Linear%20Regression%20using%20Least%20Squares" rel="noopener ugc nofollow" target="_blank">T3】https://github . com/chasing infinity/ml-from-scratch/tree/master/01% 20 linear % 20 regression % 20 using % 20 lost % 20 squaresT5】</a></p><blockquote class="mw mx my"><p id="e66c" class="jt ju mu jv b jw jx jy jz ka kb kc kd mz kf kg kh na kj kk kl nb kn ko kp kq ij bi translated">有问题吗？需要帮助吗？联系我！</p></blockquote><p id="55ed" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated"><em class="mu">电子邮件:adarsh1021@gmail.com</em></p><p id="e5dd" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated"><em class="mu">领英:</em><a class="ae mv" href="https://www.linkedin.com/in/adarsh-menon-739573146/" rel="noopener ugc nofollow" target="_blank"><em class="mu">https://www.linkedin.com/in/adarsh-menon-739573146/</em></a></p><p id="6569" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated"><em class="mu">推特:</em><a class="ae mv" href="https://twitter.com/adarsh_menon_" rel="noopener ugc nofollow" target="_blank"><em class="mu">https://twitter.com/adarsh_menon_</em></a></p><p id="e313" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated"><em class="mu">insta gram:</em><a class="ae mv" href="https://www.instagram.com/adarsh_menon_/" rel="noopener ugc nofollow" target="_blank"><em class="mu">https://www.instagram.com/adarsh_menon_/</em></a></p></div></div>    
</body>
</html>