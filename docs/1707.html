<html>
<head>
<title>A Visual Introduction to Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络的可视化介绍</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-visual-introduction-to-neural-networks-68586b0b733b?source=collection_archive---------1-----------------------#2017-10-06">https://towardsdatascience.com/a-visual-introduction-to-neural-networks-68586b0b733b?source=collection_archive---------1-----------------------#2017-10-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="c9f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">更新:我已经添加了一个视频解释来直观地介绍神经网络，这里:<a class="ae kl" href="https://www.youtube.com/watch?v=wgGezGnLTbY" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=wgGezGnLTbY</a></p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="kr ks l"/></div></figure><p id="db06" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">神经网络有多种风格和类型，是目前分类问题的最新技术。卷积神经网络、递归神经网络和最近的生成对抗神经网络也被证明是非常有用的。像逻辑回归、SVM、决策树等方法也用于分类。然而，从这些过渡到神经网络的世界通常充满了抽象。<br/>写这篇博客的目的是简化这些抽象概念。通过使用实验和图表，神经网络的工作是通过这个职位描述。人们可以期待它回答的一些问题是:</p><blockquote class="kt ku kv"><p id="145d" class="jn jo kw jp b jq jr js jt ju jv jw jx kx jz ka kb ky kd ke kf kz kh ki kj kk ij bi translated">1.logistic回归能做什么？<br/> 2。什么是逻辑回归不能做的？<br/> 3。我们如何从逻辑回归过渡到神经网络？<br/> 4。用神经网络改变决策界限<br/> 5。激活和其他超参数的变化如何影响神经网络的收敛</p></blockquote><p id="1f48" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请务必阅读标题，以便更好地理解。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi la"><img src="../Images/410b9060e7c22bd1719a74702a84846b.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*P6Us6TgqllrLpAAzWKxEsQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Sample classification problem to solve. We need a decision plane to separate red and blue points</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lh"><img src="../Images/5b1d4a5ca8e3c54caf268a132090d651.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*LMe9rtF2rMgOoBugwxd1cA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Logistic Regression can solve this problem and give the decision plane as shown. The code for the solution is available <a class="ae kl" href="https://github.com/mediumssharma23/avisualintroductiontonn/" rel="noopener ugc nofollow" target="_blank">here</a>. Process of obtaining in the line is explained in the code</figcaption></figure><p id="5f50" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从上图中我们看到，逻辑回归可以根据颜色(红色和蓝色)对这些点进行分类。<br/>我们来换个问题。下图中的问题是一个非线性问题，意味着我们不能在这种情况下使用一条线(一般为超平面)来简单地对点进行分类。我们还可以从下图中看到，逻辑回归无法解决这个问题，因为它试图用一条线将这些分开。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi li"><img src="../Images/6cb8d50a8527c44ca9a30a0992f80ddb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*0kyck9hCaJ-ZCKE53YQHsg.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">A non linear classification problem</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lj"><img src="../Images/d4f4a206e49219fea6fc62ab1f1fb493.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*-JXVuw3V1m4NYUjm6amS4A.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Logistic Regression unable to solve the problem</figcaption></figure><p id="3145" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">逻辑回归可以被视为单层神经网络(具有1个神经元)并且“sigmoid”作为激活函数。让我们看看一个以‘乙状结肠’为激活和一个神经元的神经网络能否解决这个问题。这是使用Python的Scikit-learn库的MLPClassifier完成的，实现可以在<a class="ae kl" href="https://github.com/mediumssharma23/avisualintroductiontonn/" rel="noopener ugc nofollow" target="_blank">这里</a>找到。<br/>下面三幅图描绘了一个基于单个神经元的神经元试图解决的问题。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/77de12b0ac08b6334ba915db8c51d74e.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*N26WPsK0jAoXC5mce3QUfA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">mlp = MLPClassifier(hidden_layer_sizes=(1),max_iter=500000,activation=’logistic’,learning_rate_init=0.01)</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/c61b0999a2534f2bd4cf892dace06c9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*qBAaxBvSueiEUj8o9UpLZw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">mlp = MLPClassifier(hidden_layer_sizes=(1),max_iter=500000,activation=’identity’,learning_rate_init=0.01)</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lm"><img src="../Images/29b379e6079919513e3122e5e725ce44.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*gphTfQa_xhoQz_WqO724zQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">mlp = MLPClassifier(hidden_layer_sizes=(1),max_iter=500000,activation=’relu’,learning_rate_init=0.01)</figcaption></figure><p id="4b93" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们观察到，基于单个神经元的神经网络如预期的那样给出了线性决策边界，而不管配置(激活函数、学习速率等)如何，该边界都不能解决非线性问题。让我们看看当我们使用两个神经元时会发生什么。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/05bc8bdedcc18aef207be16fc5729502.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*0OqV_Rl9P78of65JjAGmaw.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Non Linear problem with 1 layer and 2 neurons</figcaption></figure><p id="03dd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们观察到，现在我们得到了两个边界，并且分类的误差减少了(如通过正确类别中的点数来判断的)。可以解释为黄色区域的点为蓝色，其他区域为红色。该解仍然有一些误差，但是该解比单个神经元的情况具有更低的误差。我们还可以看到，每个神经元的两个决策边界在这里结合起来，以做出决策。让我们看看当我们将神经元的数量分别增加到2、3、4、6、7和30时会发生什么。(绘制决策边界的代码可以在<a class="ae kl" href="https://github.com/mediumssharma23/avisualintroductiontonn/" rel="noopener ugc nofollow" target="_blank">这里</a>找到)</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/c631dba29b217f4651f9fd35255f239d.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*wI_5688JUU3lvhLWZlDYAQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Decision plane with 3 neurons : lower error than previous case.</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/de2a29a51b977a2d5f65b0b59e9711c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*8VZIuUbRbEJkwgncV28ZwQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Decision plane with 6 neurons. Perfect classification with 100 % accuracy. Model now has learnt to combine 6 decisions to form a final decision. Points in yellow region are classified as blue and rest are classified as red</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/0bee23d016573aabc9252eed44a5a672.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*3VWDiK7F1K0kWbfBKHiEQA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Decision plane with 8 neurons</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/9c33182a48b14554830c2cea581f2ad8.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*fsNSSzuoH30ruslg5Bu0AA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Decision plane with 30 neurons</figcaption></figure><p id="34be" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们观察到，随着神经元数量的增加，模型能够更准确地对这些点进行分类。决策边界是复杂的，因为它是各个决策边界的非线性组合(通过激活函数)。在抽象层次上，它可以被视为多个分类器以非线性方式组合来获取非线性决策平面。可以得出结论，当数据是非线性时，一层具有非线性激活函数的多个神经元可以对其进行分类。这个样本问题相当小。在更高维度和更复杂的问题的情况下，更复杂的架构可以发挥作用。<br/>在上图中，使用了非线性激活函数，如“relu”。这是通过以非线性方式组合各种平面来引入“非线性”。让我们看看当我们使用线性激活函数时会发生什么</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/a7057bd554909ef51030bef26a643d6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*7eBeemvHiZhsHfjrqge4yA.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">30 neurons with linear activation function</figcaption></figure><p id="fdb3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当使用另一个线性函数“Wx+b”组合时，线性激活函数最终再次给出线性决策平面。因此，神经网络必须具有非线性激活，否则增加层和神经元是没有意义的。<br/>让我们看看一个模型如何收敛于一个3类分类问题和一层6个神经元。这里的3个类是深蓝色、浅蓝色和红色，找到的决策空间分别是黄色、蓝色和紫色。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/050324a2203c99f9131d6dcd0c533863.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*JSUprN_dyo20O2bv2xemwg.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Decision boundary of a non linear 3-class classification problem</figcaption></figure><p id="3bde" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在让我们通过另一个问题来了解更多关于神经网络的功能。</p><p id="1136" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">问题和结果是从Tensorflow playground模拟的，tensor flow playground是一个非常好的可视化神经网络工作方式的工具。</p><div class="lu lv gp gr lw lx"><a href="http://playground.tensorflow.org" rel="noopener  ugc nofollow" target="_blank"><div class="ly ab fo"><div class="lz ab ma cl cj mb"><h2 class="bd ir gy z fp mc fr fs md fu fw ip bi translated">张量流-神经网络游乐场</h2><div class="me l"><h3 class="bd b gy z fp mc fr fs md fu fw dk translated">这是一种构建从数据中学习的计算机程序的技术。它非常松散地基于我们如何思考…</h3></div><div class="mf l"><p class="bd b dl z fp mc fr fs md fu fw dk translated">playground.tensorflow.org</p></div></div><div class="mg l"><div class="mh l mi mj mk mg ml lb lx"/></div></div></a></div><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/fb248c7ad5167e195038a4e552b2155c.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*aS0KhfyQvzH5R9_qMVp5wQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">A more complex non linear problem. We need to classify blue and orange points</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/290a953a62453d4f1e9eb1da91620502.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*OEwKg8_XJLeOlKPznC-84Q.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">1 neuron. As expected, only a linear boundary is available and classification is poor</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/6443ad706a17ecd8b5635d95ced75b54.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*JmiWikOkhq4jX7sKR1OrfQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Using 3 neurons. Now the boundary is curved. Classification is somewhat better but far from perfect. Average loss of 0.473 noted. Classification is judged by establishing that blue points must have a blue backgroundand orange must have a orange background</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/acb5d1391670fcf366c917f9f743d287.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*vv3NCLXlH7EFHO_X1NM3-Q.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">5 neurons used and test and train losses are 0.396 and 0.259. So we get a better classification . Model was allowed to run epochs till 1 minute</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/acb5d1391670fcf366c917f9f743d287.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*vv3NCLXlH7EFHO_X1NM3-Q.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Using 5 neurons, classification improves further</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/ab638c698fbdb62282a1907e37e4f007.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*ErY74lCmgZpqQ9qsa5VcBg.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">8 neurons. A better and faster classification. The losses obtained after 1 minute are depicted</figcaption></figure><p id="9efb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在让我们将上面的情况与我们有多个层的情况进行比较。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/78938c2d5260f6c4c7db5fa40c268385.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*tBeciZByyH6qeaQhR4ckTg.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">We observe by using a 3 layer net with 4, 4, 2 neurons in each layer, we get a better and faster classification</figcaption></figure><p id="fbd7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面显示，这个问题可以通过简单地增加一层中的神经元来解决，但是当使用多层时，它解决得更快。多层还使模型能够形成更高级别的特征(输入第一级特征并在其上进行处理)。这种行为的一个很好的例子可以在CNN的图像分类中找到，其中起始层找到基本的形状，如直线、曲线等，但后面的层找到这些形状之上的属性，如脸、手等。让我们通过另一个实验了解更多。上图使用“sigmoid”作为激活函数。众所周知，sigmoid有一个梯度消失的问题。这意味着随着更多的图层出现，计算更新权重所需的梯度逐渐趋于零。“Relu”通常被推荐作为处理这个问题的激活函数。让我们重复上面的数字，但是这次用一个“relu”来验证这个事实</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/a83a08e18910da5a81d0676c97af4b98.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*60TObnE8gsDYQ6m9AljCLQ.png"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Non linear problem decision boundary using 3 layers (4,4,2 neurons respectively) and ‘relu’ as activation</figcaption></figure><p id="7545" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">很明显，使用relu几乎完美地解决了这个问题，并且只需要一半的时间。损失接近于零。此外，使用具有8个relu的1个图层不会获得相同的结果，因为多个图层正在利用它提取的更高级别要素属性。</p><p id="3b88" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种实验的代码可以在<a class="ae kl" href="https://github.com/mediumssharma23/avisualintroductiontonn/" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="5913" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">添加gif动画来展示决策边界如何收敛</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/d93c40844fd5ae9f0735c81df1e1ea79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/1*iT3SEgwnbhLloLY_zk1PfA.gif"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">Animation depicting boundary formation with 3 layers and ‘relu’ activation</figcaption></figure><p id="933e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个博客涵盖了神经网络的可视化方法。这是我第一次尝试写博客。请继续关注即将发布的与机器学习相关的其他主题和应用的帖子。如有任何问题/反馈，请随时联系我，shikharcic23@gmail.com或</p><div class="lu lv gp gr lw lx"><a href="https://www.linkedin.com/in/shikhar-sharma-b98078119/?ppe=1" rel="noopener  ugc nofollow" target="_blank"><div class="ly ab fo"><div class="lz ab ma cl cj mb"><h2 class="bd ir gy z fp mc fr fs md fu fw ip bi translated">Shikhar Sharma |职业简介| LinkedIn</h2><div class="me l"><h3 class="bd b gy z fp mc fr fs md fu fw dk translated">查看Shikhar Sharma在全球最大的职业社区LinkedIn上的个人资料。Shikhar有9份工作列在…</h3></div><div class="mf l"><p class="bd b dl z fp mc fr fs md fu fw dk translated">www.linkedin.com</p></div></div><div class="mg l"><div class="mt l mi mj mk mg ml lb lx"/></div></div></a></div></div></div>    
</body>
</html>