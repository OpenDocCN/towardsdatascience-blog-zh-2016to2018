<html>
<head>
<title>A performance benchmark of Google AutoML Vision using Fashion-MNIST</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用时尚 MNIST 的谷歌汽车视觉的性能基准</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-performance-benchmark-of-google-automl-vision-using-fashion-mnist-a9bf8fc1c74f?source=collection_archive---------11-----------------------#2018-08-20">https://towardsdatascience.com/a-performance-benchmark-of-google-automl-vision-using-fashion-mnist-a9bf8fc1c74f?source=collection_archive---------11-----------------------#2018-08-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/3d5036eb18b9a0617fbb710470c47677.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hmAdZrYZBdNTimc0b_Ehsg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Actual footage of Google AutoML Vision at work.</figcaption></figure><div class=""/><p id="beff" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><a class="ae la" href="https://cloud.google.com/vision/automl/docs/" rel="noopener ugc nofollow" target="_blank"> Google AutoML Vision </a>是谷歌最先进的云服务，能够完全自动地从零开始构建图像识别的深度学习模型。在这篇文章中，Google AutoML Vision 用于在<a class="ae la" href="https://github.com/zalandoresearch/fashion-mnist" rel="noopener ugc nofollow" target="_blank"> Zalando Fashion-MNIST 数据集</a>上建立图像分类模型，这是经典 MNIST 数据集的最新变体，与数字 MNIST 相比，它被认为更难学习 ML 模型。</p><p id="cd0d" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在基准测试期间，AutoML Vision 训练模式包括“免费”(0 美元，计算时间限制为 1 小时)和“付费”(大约。480 美元，24 小时计算时间)并进行评估:</p><p id="18bc" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">因此，free AutoML 模型在计算时间约为 100 秒的测试集上获得了 96.4%的宏 AUC 和 88.9%的准确度分数。30 分钟(提前停止)。付费 AutoML 模型在测试集上实现了 98.5%的宏观 AUC，准确率为 93.9%。</p><h1 id="cf34" class="lb lc jf bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">介绍</h1><p id="7722" class="pw-post-body-paragraph kc kd jf ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">最近，人们对自动机器学习解决方案的兴趣越来越大。像<a class="ae la" href="https://www.h2o.ai/products/h2o-driverless-ai/" rel="noopener ugc nofollow" target="_blank"> H2O 无人驾驶 AI </a>或<a class="ae la" href="https://www.datarobot.com/" rel="noopener ugc nofollow" target="_blank">数据机器人</a>这样的产品，仅举几个例子，其目标是企业客户，并继续进入专业数据科学团队和环境。对于许多用例来说，AutoML 解决方案可以显著地加快时间-2 模型周期，因此允许更快的模型迭代和部署(并且实际上开始在生产中节省/赚钱)。</p><p id="dbd6" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">自动化机器学习解决方案将在未来 3-5 年内彻底改变数据科学和 ML 领域。因此，如今许多需要相应的人工输入或专业知识的人工智能模型或应用将可能由人工智能/人工智能模型本身部分或完全自动化。很可能，这也将导致对“经典”数据科学概况的总体需求下降，而更有利于将模型投入生产的与工程和运营相关的数据科学角色。</p><p id="6dae" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">自动机器学习快速进步的一个最近的例子是深度学习图像识别模型的开发。不久前，建立一个图像分类器是一个非常具有挑战性的任务，只有少数人能够做到。由于计算、方法和软件的进步，障碍已经大大降低，以至于你可以用 10 行 Python 代码用 Keras 建立你的第一个深度学习模型，并获得“okayish”结果。</p><p id="497e" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">毫无疑问，在不久的将来，仍然会有许多 ML 应用和案例不能(完全)自动化。这些情况可能会更复杂，因为基本的 ML 任务，如将分类器拟合到简单的数据集，可以并将很容易地由机器自动化。</p><p id="0e3e" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在这一点上，第一次尝试进入机器学习自动化的方向。谷歌和其他公司正在投资汽车研究和产品开发。市场上最早的专业自动化 ML 产品之一是 Google AutoML Vision。</p><h1 id="ae90" class="lb lc jf bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">谷歌自动视觉</h1><p id="8dce" class="pw-post-body-paragraph kc kd jf ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">Google AutoML Vision(目前处于测试阶段)是 Google 的云服务，用于图像分类任务的自动化机器学习。使用 AutoML Vision，您可以在没有任何编码、神经网络或任何知识的情况下训练和评估深度学习模型。</p><p id="7776" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">AutoML Vision 在 Google Cloud 中运行，可以基于图形用户界面使用，也可以通过 REST、命令行或 Python 使用。AutoML Vision 实现了来自神经架构搜索(NAS)的策略，这是当前深度学习研究中备受关注的科学领域。NAS 基于另一个模型，通常是神经网络或强化学习模型，正在设计旨在解决机器学习任务的神经网络的架构的思想。NAS 研究的基石是 Zoph 等人的论文。(2017) 以及<a class="ae la" href="https://arxiv.org/abs/1802.03268" rel="noopener ugc nofollow" target="_blank"> Pham 等人(2018) </a>。后者也已经在 Python 包<a class="ae la" href="https://autokeras.com/" rel="noopener ugc nofollow" target="_blank"> autokeras </a>(目前处于预发布阶段)中实现，并使神经架构搜索在具有单个 GPU 的桌面计算机上变得可行，而不是在 Zoph 等人使用的 500 个 GPU 上。</p><p id="e6b4" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">算法能够发现神经网络架构的想法似乎非常有前途，但是由于计算约束，这仍然是一种限制(我希望你不介意我将 500–1000 GPU 集群视为计算约束)。但是，神经架构搜索在上市前的产品中究竟有多好呢？</p><h1 id="1ae4" class="lb lc jf bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">基准</h1><p id="8231" class="pw-post-body-paragraph kc kd jf ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">在下面的部分中，Google AutoML vision 用于基于时尚 MNIST 数据集构建图像识别模型。</p><h1 id="cee7" class="lb lc jf bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">资料组</h1><p id="dc0b" class="pw-post-body-paragraph kc kd jf ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">时尚-MNIST 数据集被认为是传统 MNIST 数据集的“替代物”，已经被欧洲在线时尚巨头<a class="ae la" href="https://zalando.com/" rel="noopener ugc nofollow" target="_blank"> Zalando </a>的研究部门开源(查看<a class="ae la" href="https://github.com/zalandoresearch/fashion-mnist" rel="noopener ugc nofollow" target="_blank">时尚-MNIST GitHub repo </a>和<a class="ae la" href="https://research.zalando.com/" rel="noopener ugc nofollow" target="_blank">Zalando research 网站</a>)。它包含 10 个不同服装类别(上衣、裤子、鞋子等)的 60，000 个训练图像和 10，000 个测试图像。).就像在 MNIST 一样，每个图像都是 28×28 的灰度图像。它与训练图像和测试图像具有相同的图像大小和结构。以下是数据集中的一些示例:</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi me"><img src="../Images/2f3c3dc0628ad8a2ff61c5ac3b53fb67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OGq3VyJEnwqWk-KS.png"/></div></div></figure><p id="df9d" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">时尚 MNIST 的制作者认为，如今传统的 MNIST 数据集是一个太简单的任务，无法解决——即使简单的卷积神经网络在测试集上也能达到 99%以上的准确率，而经典的 ML 算法很容易达到 97%以上。出于这样或那样的原因，时尚 MNIST 诞生了。</p><p id="ae4a" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">Fashion-MNIST repo 包含加载数据的帮助函数以及一些用于基准测试和测试模型的脚本。此外，回购协议上的数据有一个清晰的可视化效果。克隆完成后，您可以使用一个简单的 Python 函数(查看下一节中的代码)导入时尚 MNIST 数据，并开始构建您的模型。</p><h1 id="c154" class="lb lc jf bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">使用谷歌自动视觉</h1><h2 id="190f" class="mj lc jf bd ld mk ml dn lh mm mn dp ll kn mo mp lp kr mq mr lt kv ms mt lx mu bi translated">准备数据</h2><p id="fb4c" class="pw-post-body-paragraph kc kd jf ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">AutoML 提供了两种数据摄取方式:(1)上传包含不同文件夹中的训练图像的 zip 文件，对应于各自的标签，或者(2)上传包含 Goolge 云存储(GS)文件路径、标签和可选的用于训练、验证和测试集的数据分区的 CSV 文件。我决定使用 CSV 文件，因为您可以定义数据分区(标记名为 TRAIN、VALIDATION 和 TEST ),以便保持对实验的控制。下面是需要上传到 AutoML Vision 的 CSV 文件的所需结构(没有标题！).</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="36fc" class="mj lc jf mw b gy na nb l nc nd">+------------+------------------------------------+---------------+<br/>| partition  | filepath                           | label         |<br/>+------------+------------------------------------+---------------+<br/>| TRAIN      | gs://bucket/folder/image_0.jpg     | 0             |<br/>| TRAIN      | gs://bucket/folder/image_1.jpg     | 2             |<br/>| ...        | ...                                | ...           |<br/>| VALIDATION | gs://bucket/folder/image_50001.jpg | 3             |<br/>| VALIDATION | gs://bucket/folder/image_50002.jpg | 4             |<br/>| ...        | ...                                | ...           |<br/>| TEST       | gs://bucket/folder/image_60001.jpg | 7             |<br/>| TEST       | gs://bucket/folder/image_60002.jpg | 1             |<br/>| ...        | ...                                | ...           |<br/>+------------+------------------------------------+---------------+</span></pre><p id="a29a" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">就像 MNIST 一样，时尚 MNIST 数据包含各个图像的像素值。为了实际上传图像文件，我开发了一个简短的 python 脚本，负责图像的创建、导出和上传到 GCP。该脚本遍历时尚 MNIST 数据集的每一行，导出图像并上传到 Google 云存储桶中。</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="5b65" class="mj lc jf mw b gy na nb l nc nd">import os<br/>import gzip<br/>import numpy as np<br/>import pandas as pd<br/>from google.cloud import storage<br/>from keras.preprocessing.image import array_to_img</span><span id="7940" class="mj lc jf mw b gy ne nb l nc nd">def load_mnist(path, kind='train'):<br/>    """Load MNIST data from `path`"""<br/>    labels_path = os.path.join(path,<br/>                               '%s-labels-idx1-ubyte.gz'<br/>                               % kind)<br/>    images_path = os.path.join(path,<br/>                               '%s-images-idx3-ubyte.gz'<br/>                               % kind)</span><span id="9140" class="mj lc jf mw b gy ne nb l nc nd">with gzip.open(labels_path, 'rb') as lbpath:<br/>        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,<br/>                               offset=8)</span><span id="f5d1" class="mj lc jf mw b gy ne nb l nc nd">with gzip.open(images_path, 'rb') as imgpath:<br/>        images = np.frombuffer(imgpath.read(), dtype=np.uint8,<br/>                               offset=16).reshape(len(labels), 784)</span><span id="ff86" class="mj lc jf mw b gy ne nb l nc nd">return images, labels</span><span id="3725" class="mj lc jf mw b gy ne nb l nc nd"># Import training data<br/>X_train, y_train = load_mnist(path='data', kind='train')<br/>X_test, y_test = load_mnist(path='data', kind='t10k')</span><span id="7d20" class="mj lc jf mw b gy ne nb l nc nd"># Split validation data<br/>from sklearn.model_selection import train_test_split<br/>X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=10000)</span><span id="1003" class="mj lc jf mw b gy ne nb l nc nd"># Dataset placeholder<br/>files = pd.DataFrame({'part': np.concatenate([<br/>                                   np.repeat('TRAIN', 50000),<br/>                                   np.repeat('VALIDATION', 10000),<br/>                                   np.repeat('TEST', 10000)<br/>                              ]),<br/>                      'file': np.repeat('file', 70000),<br/>                      'label': np.repeat('label', 70000)})</span><span id="9ba6" class="mj lc jf mw b gy ne nb l nc nd"># Stack training and test data into single arrays<br/>X_data = np.vstack([X_train, X_valid, X_test])<br/>y_data = np.concatenate([y_train, y_valid, y_test])</span><span id="ab09" class="mj lc jf mw b gy ne nb l nc nd"># GS path<br/>gs_path = 'gs://secret/fashionmnist'</span><span id="b311" class="mj lc jf mw b gy ne nb l nc nd"># Storgae client<br/>storage_client = storage.Client.from_service_account_json(json_credentials_path='secret.json')<br/>bucket = storage_client.get_bucket('secret-bucket')</span><span id="a2c2" class="mj lc jf mw b gy ne nb l nc nd"># Fill matrix<br/>for i, x in enumerate(X_data):<br/>    # Console print<br/>    if i % 1000 == 0:<br/>        print('Uploading image {image}'.format(image=i))<br/>    # Reshape and export image<br/>    img = array_to_img(x=x.reshape(28, 28, 1))<br/>    img.save(fp='fashionmnist' + '/' + 'image_' + str(i) + '.jpg')<br/>    # Add info to data frame<br/>    files.iloc[i, 1] = gs_path + '/' + 'image_' + str(i) + '.jpg'<br/>    files.iloc[i, 2] = y_data[i]<br/>    # Upload to GCP<br/>    blob = bucket.blob('fashionmnist/' + 'image_' + str(i) + '.jpg')<br/>    blob.upload_from_filename('fashionmnist/' + 'image_' + str(i) + '.jpg')<br/>    # Delete image file<br/>    os.remove('fashionmnist/' + 'image_' + str(i) + '.jpg')</span><span id="f2cc" class="mj lc jf mw b gy ne nb l nc nd"># Export CSV file<br/>files.to_csv(path_or_buf='fashionmnist.csv', header=False, index=False)</span></pre><p id="00be" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">函数<code class="fe nf ng nh mw b">load_mnist</code>来自时尚 MNIST 知识库，将训练和测试数组导入 Python。导入训练集后，使用来自<code class="fe nf ng nh mw b">sklean.model_selection</code>的<code class="fe nf ng nh mw b">train_test_split</code>对 10，000 个样本进行采样和存储，作为验证数据。然后，训练、验证和测试数组被堆叠到<code class="fe nf ng nh mw b">X_data</code>中，以便有一个对象进行迭代。占位符<code class="fe nf ng nh mw b">DataFrame</code>被初始化以存储 AutoML Vision 所需的信息(分区、文件路径和标签)。<code class="fe nf ng nh mw b">storage</code> from <code class="fe nf ng nh mw b">google.cloud</code>使用一个服务帐户 json 文件连接到 GCP(当然，我不会在这里分享)。最后，主流程开始，遍历<code class="fe nf ng nh mw b">X_data</code>，为每一行生成一个图像，保存到磁盘，上传到 GCP，删除不再需要的图像。最后，我将导出的 CSV 文件上传到项目的 Google 云存储桶中。</p><h2 id="0a78" class="mj lc jf bd ld mk ml dn lh mm mn dp ll kn mo mp lp kr mq mr lt kv ms mt lx mu bi translated">进入 AutoML</h2><p id="49ae" class="pw-post-body-paragraph kc kd jf ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">AutoML Vision 目前处于测试阶段，这意味着您必须在试用之前申请。由于我和我的同事目前正在为我们的一个客户探索自动机器学习在计算机视觉项目中的使用，我已经可以通过 GCP 控制台访问 AutoML Vision。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/7875069013be32c876295159ccb1a893.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZmnqrYZbKr1k-v0m.png"/></div></div></figure><p id="c20d" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">此时，开始屏幕看起来相当不起眼。你可以通过点击“开始使用 AutoML”或阅读<a class="ae la" href="https://cloud.google.com/vision/automl/docs/" rel="noopener ugc nofollow" target="_blank">文档</a>开始，这是目前为止非常基本但信息丰富的，特别是当你不熟悉基本的机器学习概念时，如训练-测试-分割、过拟合、精确/召回等。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/79c6c9f96e64283c68c6343bfb648285.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*My_r_qGWL-TraVSQ.png"/></div></div></figure><p id="978a" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">开始后，Google AutoML 会将您带到数据集对话框，这是通向最终 AutoML 模型的第一步。到目前为止，这里没有报告。稍后，您将在这里找到所有导入的数据集。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/4ae1c4420e223dd234efe2769afdd475.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RY072OOEACBS-3jn.png"/></div></div></figure><h2 id="4fd9" class="mj lc jf bd ld mk ml dn lh mm mn dp ll kn mo mp lp kr mq mr lt kv ms mt lx mu bi translated">生成数据集</h2><p id="89f7" class="pw-post-body-paragraph kc kd jf ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">点击“+新建数据集”后，AutoML 会将您带到“创建数据集”对话框。如前所述，可以使用两种不同的方法添加新数据集，如下图所示。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/edef7847adcd620cf4f6e33f626c3f7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*J8yhWhu61-EvNM1C.png"/></div></div></figure><p id="e163" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我已经从我的计算机上传了图像，以及包含 GS 文件路径、分区信息以及相应标签的 CSV 文件到 GS bucket 中。为了将数据集添加到 AutoML Vision，您必须指定包含图像 GS-filepaths 等的 CSV 文件的文件路径。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/977f6bbe9cefb1d60620ef0cc7bd4ddb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*x39gOcDGY8r8mi4Z.png"/></div></div></figure><p id="c6a4" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在“创建数据集”对话框中，如果每个图像有多个标签，您还可以启用多标签分类，这也是一个非常有用的功能。点击“创建数据集”后，AutoML 遍历提供的文件名，并为建模构建数据集。到底是做什么的，既不可见也没有记录。这个导入过程可能需要一段时间，所以它向你展示了时髦的“霹雳游侠”进度条。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/f07c95afd3031df499829b8f1f97b826.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NCQWrPeS7vSJZurr.png"/></div></div></figure><p id="4f74" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">导入完成后，您将收到一封来自 GCP 的电子邮件，通知您数据集的导入已完成。我发现这很有帮助，因为你不必一直开着浏览器窗口盯着进度条。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/3ef4a2d45c3cfca1a836eccc0242a8e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*n4z5TNyvI_xsMenD.png"/></div></div></figure><p id="b6c3" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这封邮件看起来有点奇怪，但嘿，它仍然是测试版…</p><h2 id="a66f" class="mj lc jf bd ld mk ml dn lh mm mn dp ll kn mo mp lp kr mq mr lt kv ms mt lx mu bi translated">训练模型</h2><p id="aca2" class="pw-post-body-paragraph kc kd jf ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">回到 AutoML。构建数据集后，首先看到的是导入的图像。在这个例子中，图像有点像素化，因为它们的分辨率只有 28×28。您可以使用左侧的导航栏浏览不同的标签，也可以手动添加标签到目前为止尚未标记的图像。此外，如果你的图片没有附带任何标签，你可以申请<a class="ae la" href="https://cloud.google.com/vision/automl/docs/human-labeling" rel="noopener ugc nofollow" target="_blank">人工标签服务</a>。此外，如果您需要添加类别等，您可以创建新的标签。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/ec52be60308ad849c2382e2772175de7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gHuchFWFCEa4kvwE.png"/></div></div></figure><p id="bf44" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在让我们严肃起来。进入“训练”对话框后，AutoML 会通知您标签的频率分布。它建议每个类的最小数量为$n=100$标签(我觉得这个数量很低)。此外，它似乎向您显示了整个数据集的频率(一起训练、验证和测试)。我认为，在这一点上，按数据划分的分组频率图会提供更多信息。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/44b24def4ae68ee1433c74c269b91719.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FTgKr8fvRIYK3mYF.png"/></div></div></figure><p id="305b" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">单击“开始培训”会将您带到一个弹出窗口，您可以在其中定义模型名称并分配您愿意投资的培训预算(计算时间/金钱)。您可以选择“1 计算小时”，whis 每月免费提供 10 个型号，或者“24 计算小时(更高质量)”，价格大约为。480 美元(1 小时的自动计算需要 20 美元。然而，如果架构搜索收敛于更早的点，你将只支付到目前为止所消耗的计算时间，我认为这是合理和公平的。最后，还可以选择自定义培训时间，例如 5 小时。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/f70001f90901d85dec721fcb88051b74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5AL67e93VIk3i83q.png"/></div></div></figure><p id="90be" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在这个实验中，我尝试了两个版本，AutoML 的“免费”版本，但我也“全押”并选择了 24 小时选项，以实现可能的最佳模式(“付费模式”)。让我们看看，您可以从 480 美元的尖端 AutoML 解决方案中获得什么。点击“开始训练”后，熟悉的骑士屏幕出现，告诉你，你可以关闭浏览器窗口，让 AutoML 做剩下的事情。奈斯。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/909abd057faee11fa38dff33e0761ad5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EA9bwcWu5Da2zSj-.png"/></div></div></figure><h2 id="d6f2" class="mj lc jf bd ld mk ml dn lh mm mn dp ll kn mo mp lp kr mq mr lt kv ms mt lx mu bi translated">结果和评价</h2><p id="7b14" class="pw-post-body-paragraph kc kd jf ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">首先，我们从免费模式开始。大约花了。30 分钟的训练，似乎很快就找到了解决方案。我不确定 AutoML 在评估收敛标准时到底做了什么，但免费和付费模型之间似乎有所不同，因为免费模型已经收敛了大约 30 分钟的计算，而付费模型没有。</p><p id="49de" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">免费模型的整体模型指标看起来相当不错。在宏类 1 精度为 90.9%和召回率为 87.7%的测试集上，平均精度为 96.4%。时尚-MNIST 数据集上的当前精度基准为 96.7%(wrn 40–4 8.9M 参数)，其次为 96.3%(WRN-28–10+随机擦除)，而低预算模型的精度仅为 89.0%。因此，免费的 AutoML 模式与当前的时尚 MNIST 基准相去甚远。下面，你会发现免费模型的指标截图。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/e86f59c1c4759dc22fb3b20094b2c1a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kVX3leyltNuKRStG.png"/></div></div></figure><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/c80eca09a5315ff1e520da242d6e2311.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aWi_K8rEbZ41AYZR.png"/></div></div></figure><p id="9742" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">付费模型的模型度量看起来要好得多。该方法在测试集上的平均准确率为 98.5%，一级精度为 95.0%，召回率为 92.8%，准确率为 93.9%。这些结果接近当前的基准，但是，没有我希望的那么接近。下面，你会发现付费模型的指标截图。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/3d3c261e0be68bd8a2b55c68c8a5bece.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GJY1kkex4a0si6sE.png"/></div></div></figure><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/9b322cb90fdb7f19c4876601309d627e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*i9YWnV13LEMKTTKw.png"/></div></div></figure><p id="984a" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">“评估”选项卡还显示了更详细的指标，如精度/召回曲线以及分别影响模型指标的分类临界值滑块。在这一页的底部，你会发现混淆矩阵，以及正确和错误分类的例子的相对频率。此外，您可以检查每个类的假阳性和假阴性的图像(如果您想了解您的模型为什么以及何时出错，这非常有帮助)。总体而言，模型评估功能有限，但用户友好。作为一个更深入的用户，当然，我希望看到更多的先进功能，但考虑到目标群体和发展状况，我认为这是相当不错的。</p><h2 id="8a95" class="mj lc jf bd ld mk ml dn lh mm mn dp ll kn mo mp lp kr mq mr lt kv ms mt lx mu bi translated">预言；预测；预告</h2><p id="1525" class="pw-post-body-paragraph kc kd jf ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">拟合和评估模型后，您可以使用几种方法来预测新图像。首先，您可以使用 AutoML 用户界面从本地机器上传新图像。对于没有经验的用户来说，这是一个将他们的模型应用到新图像并获得预测的好方法。对于高级用户和开发人员，AutoML vision 通过 GCP 上的 API 公开模型，同时负责后台的所有技术基础设施。一个简单的 Python 脚本展示了 API 的基本用法:</p><pre class="mf mg mh mi gt mv mw mx my aw mz bi"><span id="5d01" class="mj lc jf mw b gy na nb l nc nd">import sys<br/>from google.cloud import automl_v1beta1</span><span id="c341" class="mj lc jf mw b gy ne nb l nc nd"># Define client from service account json<br/>client = automl_v1beta1.PredictionServiceClient.from_service_account_json(filename='secret.json')</span><span id="71f1" class="mj lc jf mw b gy ne nb l nc nd"># Endpoint<br/>name = 'projects/automl-XXX/locations/us-central1/models/ICNXXXXXXX'</span><span id="bf20" class="mj lc jf mw b gy ne nb l nc nd"># Import a single image<br/>with open('image_10.jpg', 'rb') as ff:<br/>    img = ff.read()</span><span id="2848" class="mj lc jf mw b gy ne nb l nc nd"># Define payload<br/>payload = {'image': {'image_bytes': img}}</span><span id="b98c" class="mj lc jf mw b gy ne nb l nc nd"># Prediction<br/>request = client.predict(name=name, payload=payload, params={})<br/>print(request)</span><span id="7d83" class="mj lc jf mw b gy ne nb l nc nd"># Console output<br/>payload {<br/>  classification {<br/>    score: 0.9356002807617188<br/>  }<br/>  display_name: "a_0"<br/>}</span></pre><p id="ed3d" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">作为第三种方法，如果您想使用完整的 nerdcore，也可以将 API 放在命令行中。我认为，自动化的 API 公开是一个很好的特性，因为它让你可以将你的模型集成到各种脚本和应用程序中。此外，当您想要在生产环境中同时将模型扩展到数百或数千个 API 请求时，Google 会处理所有的细节问题。</p><h1 id="965f" class="lb lc jf bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结论和展望</h1><p id="50c1" class="pw-post-body-paragraph kc kd jf ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">简而言之，即使免费模型在测试集上也取得了相当好的结果，因为投入到模型中的实际时间只是手动构建模型所需时间的一小部分。付费模式取得了明显更好的结果，但是成本为 480 美元。显然，付费服务的目标是数据科学专业人士和公司。</p><p id="b03f" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">AutoML Vision 只是来到谷歌云的一系列新 AutoML 应用的一部分(<a class="ae la" href="https://cloud.google.com/blog/topics/inside-google-cloud/what-week-105-announcements-google-cloud-next-18" rel="noopener ugc nofollow" target="_blank">查看这些来自谷歌 Next 18 </a>的公告)，进一步塑造了该平台在机器学习和人工智能方向的定位。</p><p id="4a18" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">就我个人而言，我相信自动化机器学习解决方案将继续进入专业数据科学项目和应用。借助自动化机器学习，您可以(1)为您的定制解决方案建立基准模型，(2)更快地迭代使用案例和数据产品，以及(3)更快地到达您实际开始在生产中利用数据赚钱的时间点。</p><h1 id="43c9" class="lb lc jf bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">结束语</h1><p id="8a22" class="pw-post-body-paragraph kc kd jf ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">如果你对我的故事有任何意见或问题，欢迎在下面评论！我将尝试回答这些问题。此外，请随意使用我的代码或在您选择的社交平台上与您的同行分享这个故事。如果你想保持联系，请在<a class="ae la" href="https://www.linkedin.com/in/sebastian-heinz-90885272/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae la" href="https://twitter.com/statworx" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注我。</p><p id="7985" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">请确保您也查看了棒极了的 STATWORX 博客，了解更多有趣的数据科学、ML 和 AI 内容，这些内容直接来自我们在德国法兰克福的办公室！</p><p id="840a" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果你对更多像这样的优质内容感兴趣，请加入我的邮件列表，不断为你带来新的数据科学、机器学习和人工智能阅读，并把我和我的团队发送到你的收件箱！</p><figure class="mf mg mh mi gt is"><div class="bz fp l di"><div class="ni nj l"/></div></figure><p id="22e4" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我希望你喜欢我的故事，我真的很喜欢写它。感谢您的宝贵时间！</p></div><div class="ab cl nk nl hu nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="ij ik il im in"><p id="bfd6" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><em class="nr">原载于 2018 年 8 月 20 日</em><a class="ae la" href="https://www.statworx.com/de/blog/a-performance-benchmark-of-google-automl-vision-using-fashion-mnist/" rel="noopener ugc nofollow" target="_blank"><em class="nr">www.statworx.com</em></a><em class="nr">。</em></p></div></div>    
</body>
</html>