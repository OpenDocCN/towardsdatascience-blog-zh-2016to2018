<html>
<head>
<title>An ADMM-Newton method for inequality constrained optimization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不等式约束优化的 ADMM-牛顿法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-admm-newton-method-for-inequality-constrained-optimization-37a470c58a5c?source=collection_archive---------9-----------------------#2018-07-02">https://towardsdatascience.com/an-admm-newton-method-for-inequality-constrained-optimization-37a470c58a5c?source=collection_archive---------9-----------------------#2018-07-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/85bf8e40ab9957ddcc38e89aa70f1737.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SYe8luYy7FVuQktBCf7a1A@2x.jpeg"/></div></div></figure><div class=""/><p id="2729" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">代码</strong> : <a class="ae kw" href="https://github.com/zl376/admm_newton_con" rel="noopener ugc nofollow" target="_blank"> Github </a></p><p id="d986" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">数值优化在包括机器学习在内的许多领域都是必不可少的。在某些情况下，约束被转换为未知变量，这使得应用普通的无约束优化技术变得不那么简单，需要更复杂的方法(例如 L-BFGS-B)。</p><p id="ad0f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">看起来，如果成本函数的梯度和 hessian 是已知的(对于像逻辑回归这样的许多问题来说都是如此)，那么对于不等式约束来说，问题就相对容易了。这把钥匙叫做<strong class="ka jc"> ADMM </strong>。</p><h1 id="86ba" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">问题</h1><p id="895e" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">这种 ADMM(交替方向乘子法)方法解决了下面的约束优化问题:</p><figure class="mb mc md me gt is gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/9c0f90d786d2b3d6276098db0127b078.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/1*jNRPj3V8cpvXDlMH92JrZQ.png"/></div></figure><h1 id="4e1a" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">算法</h1><p id="2634" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">使用<strong class="ka jc">罚函数</strong>和<strong class="ka jc">变量替换</strong>将不等式约束替换为等式约束；</p><figure class="mb mc md me gt is gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/d5a98d7d1dd37e682f0706dc4cc3d0a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*p6VfopPWayZ0T0ou3EvScA.png"/></div></figure><p id="eed9" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在哪里，</p><figure class="mb mc md me gt is gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/b99ac41093193f363a3dd9b46e2bd9b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*HbwReKEtqEmtpsLRrDtx9g.png"/></div></figure><p id="72c9" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然后，等式约束问题可以转化为它的增广拉格朗日(原始-对偶)问题:</p><figure class="mb mc md me gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mh"><img src="../Images/643d6dd61c5425c8fcf0dd75584cb092.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wn7k0N57_43iHWHWUu820Q.png"/></div></div></figure><p id="a61d" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">并用 ADMM [1]求解:</p><figure class="mb mc md me gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mi"><img src="../Images/1f9fc8168b9f146fa960329d71d78f70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4F176of4t4qezJsIf9mEtg.png"/></div></div><figcaption class="mj mk gj gh gi ml mm bd b be z dk">Pseudocode for ADMM</figcaption></figure><h2 id="66aa" class="mn ky jb bd kz mo mp dn ld mq mr dp lh kj ms mt ll kn mu mv lp kr mw mx lt my bi translated">原始子问题中的牛顿更新</h2><p id="affb" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">对于原始下降 1，可以使用<strong class="ka jc">牛顿</strong>更新获得解决方案，这依赖于原始损失函数的梯度和 hessian 的可用性:</p><figure class="mb mc md me gt is gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/33563dcd380d5897f0da46a33d2c3f52.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*greZewrnUEW24TDycihRXg.png"/></div></figure><p id="f5d9" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">和下面的反演:</p><figure class="mb mc md me gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi na"><img src="../Images/36adc5e4fe3b5ce6c80b3eb48b3e595a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8bleyotX6dYexy4SqQm3VA.png"/></div></div></figure><p id="9991" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这种反演可以通过<strong class="ka jc">直接反演</strong>或<strong class="ka jc">迭代法</strong>(如 CG<strong class="ka jc"/>【2】)进行。</p><p id="f615" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">ADMM-牛顿法现在完成了。</p></div><div class="ab cl nb nc hu nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ij ik il im in"><h1 id="0f2a" class="kx ky jb bd kz la ni lc ld le nj lg lh li nk lk ll lm nl lo lp lq nm ls lt lu bi translated">示例:逻辑回归</h1><p id="6ec1" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">考虑具有标签(l)、特征(f)和对权重(x)的正性约束的逻辑回归，则我们有:</p><figure class="mb mc md me gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nn"><img src="../Images/01ee0ef05af4c1344863330d679dd585.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s71ZlbJ_JuW_qNcidjQsZw.png"/></div></div></figure><p id="96df" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用 sigmoid 函数:</p><figure class="mb mc md me gt is gh gi paragraph-image"><div class="gh gi no"><img src="../Images/b11ab03e2b93d982f377e9cf66bb2e19.png" data-original-src="https://miro.medium.com/v2/resize:fit:456/format:webp/1*CRtcRnOc-G-2E4kSfaNC6w.png"/></div></figure><h2 id="ec1d" class="mn ky jb bd kz mo mp dn ld mq mr dp lh kj ms mt ll kn mu mv lp kr mw mx lt my bi translated">模拟数据的结果</h2><p id="a9d6" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">生成 200 个样本，每个样本具有 10 维特征向量:</p><pre class="mb mc md me gt np nq nr ns aw nt bi"><span id="dccf" class="mn ky jb nq b gy nu nv l nw nx">feature, label = make_classification(n_samples=200, n_features=10, n_redundant=0, n_informative=5, random_state=0)</span></pre><p id="7f80" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">和 ADMM 参数被设置为:</p><ul class=""><li id="851f" class="ny nz jb ka b kb kc kf kg kj oa kn ob kr oc kv od oe of og bi translated">\rho = 1</li><li id="4b54" class="ny nz jb ka b kb oh kf oi kj oj kn ok kr ol kv od oe of og bi translated">max_iter = 1000</li><li id="0b12" class="ny nz jb ka b kb oh kf oi kj oj kn ok kr ol kv od oe of og bi translated">tol = 1E-6</li></ul><p id="5dcf" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有/无约束条件下回归权重的比较:</p><figure class="mb mc md me gt is gh gi paragraph-image"><div class="gh gi om"><img src="../Images/a27dff92c188d1509569c74b4ca67594.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*Yp4zERuI2dM93pxPK44iJg.png"/></div></figure><p id="48da" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">约束是有效的，因为输出权重都是正的。请注意，这不再是全局最小值(由于约束)，而是次优性能(AUC)。</p><h1 id="56d3" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">关于方法的注释</h1><p id="a481" class="pw-post-body-paragraph jy jz jb ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">这种方法要求损失函数 E(x)的梯度和 hessian 要么显式(作为矩阵)可用，要么隐式(使用函数)可用。</p><h1 id="0fd6" class="kx ky jb bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">参考</h1><ol class=""><li id="7595" class="ny nz jb ka b kb lv kf lw kj on kn oo kr op kv oq oe of og bi translated">史蒂芬·博伊德、尼尔·帕里克、朱立伦、博尔哈·佩莱托和乔纳森·埃克斯坦(2011)，“通过交替方向乘数法进行分布式优化和统计学习”，《机器学习的基础和趋势:第 3 卷第 1 号，第 1–122 页。</li><li id="2d95" class="ny nz jb ka b kb oh kf oi kj oj kn ok kr ol kv oq oe of og bi translated">Jorge Nocedal，S. Wright，“数值优化”，施普林格科学，1999 年。</li></ol></div></div>    
</body>
</html>