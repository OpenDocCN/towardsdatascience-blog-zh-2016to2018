<html>
<head>
<title>All about Logistic regression in one article</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于逻辑回归的所有内容都在一篇文章中</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/logistic-regression-b0af09cdb8ad?source=collection_archive---------4-----------------------#2018-10-10">https://towardsdatascience.com/logistic-regression-b0af09cdb8ad?source=collection_archive---------4-----------------------#2018-10-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/34532b67e9ef92c898598b08acd0a52b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*PkEl-8DBQa-xEft_tacXLQ.gif"/></div></div></figure></div><div class="ab cl jy jz hu ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="ij ik il im in"><blockquote class="kf"><p id="adeb" class="kg kh iq bd ki kj kk kl km kn ko kp dk translated">每个伟大的领袖背后都有一个更伟大的后勤专家。</p></blockquote></div><div class="ab cl jy jz hu ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="ij ik il im in"><p id="d886" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">与其他算法不同，逻辑回归很容易被年轻的开发人员误导。可能是因为人们还认为它是一个回归机器学习算法。</p><p id="268e" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">逻辑回归是一种统计机器学习算法，它通过考虑极端情况下的结果变量来对数据进行分类，并尝试制作一条对数线来区分它们。</p></div><div class="ab cl jy jz hu ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="ij ik il im in"><h1 id="32f9" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">像我五岁一样解释</h1><p id="468b" class="pw-post-body-paragraph kq kr iq ks b kt ml kv kw kx mm kz la lb mn ld le lf mo lh li lj mp ll lm kp ij bi translated">逻辑回归是线性回归的兄弟，但与其名称不同，逻辑回归是一种分类算法。</p><p id="a695" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">让我们复习一下第一个线性回归:</p><p id="14c8" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated"><strong class="ks ir">公式:</strong></p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/8119089bb905e7a9083bf41dffb78049.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*OfTEldHx13HejUSJyMuSVA.png"/></div></figure><p id="1f03" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">在哪里，</p><ul class=""><li id="8a68" class="mv mw iq ks b kt ku kx ky lb mx lf my lj mz kp na nb nc nd bi translated">y =必须预测的值</li><li id="a949" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated">m =直线的斜率</li><li id="2454" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated">x =输入数据</li><li id="3ea0" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated">c = y 截距</li></ul><p id="abb1" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">有了这些值，我们可以预测 y 值，例如。</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/1a1eaeba0e4b7125cccad77c7b1d58c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*2KAInY20QPhkLCJ8jWVLJw.gif"/></div></figure><ul class=""><li id="9a0a" class="mv mw iq ks b kt ku kx ky lb mx lf my lj mz kp na nb nc nd bi translated">这里的蓝点是 x 值(输入数据)。</li><li id="7f34" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated">现在使用输入数据，我们可以计算斜率和 y 坐标，这样我们的预测线(红线)应该覆盖大部分的点。</li><li id="234e" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated">现在使用这条线，我们可以预测给定 x 值的 y 的任何值。</li></ul><p id="33e8" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">现在，线性回归需要注意的一点是，它适用于连续数据，但如果我们的分类算法需要线性回归，我们需要进一步调整我们的算法。</p><p id="ab8d" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">首先，我们需要定义一个阈值，如果我们的预测值低于阈值，那么它属于第 1 类，否则属于第 2 类。</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nk"><img src="../Images/ef5e665ed9f0adb9ded60d73db4dd6dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YxVImAMf317pbRqthEPYEw.jpeg"/></div></div></figure><p id="3e92" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">现在，如果你在想“哦，这很简单，我们必须用阈值和 vola 来定义线性回归，它变成了分类算法，这里面有一个技巧。我们必须自己定义阈值，对于大型数据集，我们将无法计算阈值。此外，一旦定义了阈值，即使我们的预测值发生变化，阈值也是相同的。</p><p id="30dc" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">更多参考请点击<a class="ae nl" href="https://stats.stackexchange.com/questions/22381/why-not-approach-classification-through-regression" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="2b32" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">另一方面，逻辑回归产生逻辑曲线，该曲线的值限于 0 和 1 之间。</p><p id="ef4d" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">逻辑回归类似于线性回归，但曲线是使用目标变量“几率”的自然对数而不是概率构建的。此外，预测值不必呈正态分布或在每组中具有相等的方差。</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/d5267c9aa1726f37c3c0b43f28076810.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/1*DXKO2GGT0XT_6JFjROajvg.gif"/></div></figure><p id="196c" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">如果你还是不明白，那么我推荐你看下面的视频，它用简单的方式解释了逻辑回归。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="nn no l"/></div></figure></div><div class="ab cl jy jz hu ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="ij ik il im in"><h1 id="70e5" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">公式</h1><p id="13f1" class="pw-post-body-paragraph kq kr iq ks b kt ml kv kw kx mm kz la lb mn ld le lf mo lh li lj mp ll lm kp ij bi translated">为了解释逻辑回归，我需要一些物理媒介来表达我在这个数字媒介中的知识。</p><p id="43e3" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">所以我在笔记本上写了逻辑回归公式，然后拍了照片贴在这里。</p><p id="c1ac" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">如果你想要 pdf 版本，<a class="ae nl" href="https://drive.google.com/file/d/11Lsg-zF3yTZOp3KHBi0bYAeY4F1ayt1r/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">点击这里</a>。</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi np"><img src="../Images/802e746519049b2ea61ce3f819404fc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ngZwG7Uxri2Ja2STjE_GMQ.jpeg"/></div></div><figcaption class="nq nr gj gh gi ns nt bd b be z dk">page 1 of 7</figcaption></figure><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nu"><img src="../Images/6cc77597cf8ec5ddbdeff5d8610eea1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e34_3CblGM3xNwmy5WtzUQ.jpeg"/></div></div><figcaption class="nq nr gj gh gi ns nt bd b be z dk">page 2 of 7</figcaption></figure><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nv"><img src="../Images/8fc61701c8a919f721ff2b40c0e92442.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wrLctIXTxE2Og9yjVMl0bw.jpeg"/></div></div><figcaption class="nq nr gj gh gi ns nt bd b be z dk">page 3 of 7</figcaption></figure><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nw"><img src="../Images/145fcc2b53b0b92f38929c37a04672a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TRnQnln7Y2H6LvpVbZ5Xtw.jpeg"/></div></div><figcaption class="nq nr gj gh gi ns nt bd b be z dk">page 4 of 7</figcaption></figure><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nx"><img src="../Images/4be1e8e1cd4b629c4bb58d8eeea95834.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YunNJfjlTony8PM5zjzbSQ.jpeg"/></div></div><figcaption class="nq nr gj gh gi ns nt bd b be z dk">page 5 of 7</figcaption></figure><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ny"><img src="../Images/ebc6b70b0dfcf94f5f4fa7f62d966115.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C2LSEG3McdR5M63CqH6mLA.jpeg"/></div></div><figcaption class="nq nr gj gh gi ns nt bd b be z dk">page 6 of 7</figcaption></figure><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nz"><img src="../Images/9487ada709151c4940308cf4641a5ff9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KncOFBZPUKEk8-hMgtsFQQ.jpeg"/></div></div><figcaption class="nq nr gj gh gi ns nt bd b be z dk">page 7 of 7</figcaption></figure></div><div class="ab cl jy jz hu ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="ij ik il im in"><h1 id="f17f" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">用 python 实现</h1><ul class=""><li id="abed" class="mv mw iq ks b kt ml kx mm lb oa lf ob lj oc kp na nb nc nd bi translated">用 python 从头开始实现逻辑回归算法<strong class="ks ir"/>，并在每个步骤中进行解释，上传到我的 Github 库。</li><li id="5004" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated">在 Scikit learn 的<strong class="ks ir">帮助下实现逻辑回归也被添加到我的 Github 存储库中。</strong></li></ul><div class="od oe gp gr of og"><a href="https://github.com/2796gaurav/Logistic-regression-explained" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd ir gy z fp ol fr fs om fu fw ip bi translated">2796 gaur av/逻辑回归-已解释</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">简单而详细的解释逻辑回归用于机器学习问题。…</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">github.com</p></div></div><div class="op l"><div class="oq l or os ot op ou jw og"/></div></div></a></div></div><div class="ab cl jy jz hu ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="ij ik il im in"><h1 id="38fa" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">优势</h1><ul class=""><li id="8b86" class="mv mw iq ks b kt ml kx mm lb oa lf ob lj oc kp na nb nc nd bi translated">最简单的机器学习算法之一，但效率极高。</li><li id="59aa" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated">方差很低。</li><li id="0794" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated">它也可以用于特征提取</li><li id="8889" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated">使用随机梯度下降，逻辑模型可以很容易地用新数据更新。</li></ul></div><div class="ab cl jy jz hu ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="ij ik il im in"><h1 id="8db5" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">不足之处</h1><ul class=""><li id="e22a" class="mv mw iq ks b kt ml kx mm lb oa lf ob lj oc kp na nb nc nd bi translated">不能很好地处理大量的分类变量。</li><li id="008b" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated">它需要非线性特征的变换。</li><li id="ed31" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated">它们不够灵活，无法自然地捕捉更复杂的关系。</li></ul></div><div class="ab cl jy jz hu ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="ij ik il im in"><h1 id="147c" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">应用程序</h1><ul class=""><li id="0208" class="mv mw iq ks b kt ml kx mm lb oa lf ob lj oc kp na nb nc nd bi translated">图像分割和分类</li><li id="85e0" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated">地理图像处理</li><li id="7c07" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated">手写识别</li><li id="e9ba" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated">垃圾邮件检测</li></ul></div><div class="ab cl jy jz hu ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="ij ik il im in"><h1 id="59b4" class="ln lo iq bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">何时使用</h1><ul class=""><li id="003d" class="mv mw iq ks b kt ml kx mm lb oa lf ob lj oc kp na nb nc nd bi translated">当我们需要调整比值比时，我们知道一个以上的风险因素。</li><li id="5fff" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated">当卡方检验不显著时。</li></ul></div><div class="ab cl jy jz hu ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="ij ik il im in"><p id="02a1" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">此外，我将添加其他机器学习算法。这篇文章的主旨是深入了解逻辑回归，不使用任何硬词，从头开始解释。此外，如果您想实现逻辑回归，从这些数据集开始，您可以在注释部分用代码注释您的预测得分。</p><ul class=""><li id="27e6" class="mv mw iq ks b kt ku kx ky lb mx lf my lj mz kp na nb nc nd bi translated"><a class="ae nl" href="https://archive.ics.uci.edu/ml/datasets/iris" rel="noopener ugc nofollow" target="_blank">虹膜数据集</a></li><li id="4ddd" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated"><a class="ae nl" href="https://archive.ics.uci.edu/ml/datasets/Wine" rel="noopener ugc nofollow" target="_blank">葡萄酒数据集</a></li><li id="b3ba" class="mv mw iq ks b kt ne kx nf lb ng lf nh lj ni kp na nb nc nd bi translated"><a class="ae nl" href="https://archive.ics.uci.edu/ml/datasets/Adult" rel="noopener ugc nofollow" target="_blank">成人数据集</a></li></ul></div><div class="ab cl jy jz hu ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="ij ik il im in"><p id="beb8" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">如果你想学习更多的机器学习算法，请跟随我，因为我将添加我所知道的所有机器学习算法。T13】</p><p id="fd5e" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">先前我已经以一种非常基本的信息方式添加了朴素贝叶斯解释。 </p><div class="od oe gp gr of og"><a rel="noopener follow" target="_blank" href="/all-about-naive-bayes-8e13cef044cf"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd ir gy z fp ol fr fs om fu fw ip bi translated">关于朴素贝叶斯的一切</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">一个简单而深入的学习经验，在例子的帮助下从零开始学习一个机器学习算法。</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">towardsdatascience.com</p></div></div><div class="op l"><div class="ow l or os ot op ou jw og"/></div></div></a></div><p id="fef5" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm kp ij bi translated">在那之前，</p><h2 id="95d9" class="ox lo iq bd lp oy oz dn lt pa pb dp lx lb pc pd mb lf pe pf mf lj pg ph mj pi bi translated">快乐编码:)</h2><p id="14ef" class="pw-post-body-paragraph kq kr iq ks b kt ml kv kw kx mm kz la lb mn ld le lf mo lh li lj mp ll lm kp ij bi translated">别忘了拍手拍手拍手…</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi pj"><img src="../Images/a1381cbbe903af758657a56ac641e29c.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/1*wUojuA72jfwX83t_QkJxBw.gif"/></div></figure></div></div>    
</body>
</html>