<html>
<head>
<title>Building a k-Nearest-Neighbors (k-NN) Model with Scikit-learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Scikit-learn 构建 k-近邻模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-k-nearest-neighbors-k-nn-model-with-scikit-learn-51209555453a?source=collection_archive---------1-----------------------#2018-09-26">https://towardsdatascience.com/building-a-k-nearest-neighbors-k-nn-model-with-scikit-learn-51209555453a?source=collection_archive---------1-----------------------#2018-09-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/49062aa6cb5fdad050f2921d8dd31690.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T8Pnw0kiVbrPGnqnB2I_Zw.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">k-NN (<a class="ae kc" href="https://www.datacamp.com/" rel="noopener ugc nofollow" target="_blank">Image credit</a>)</figcaption></figure><p id="74f7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">k-近邻(k-NN)是一种有监督的机器学习模型。监督学习是指模型从已经标记的数据中学习。监督学习模型接受一组输入对象和输出值。然后，该模型根据这些数据进行训练，以学习如何将输入映射到所需的输出，这样它就可以学习根据看不见的数据进行预测。</p><p id="d382" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">k-NN 模型通过获取一个数据点并查看“k”个最接近的标记数据点来工作。然后，给数据点分配“k”个最接近点中大多数的标签。</p><p id="2701" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，如果 k = 5，3 个点为“绿色”，2 个点为“红色”，那么所讨论的数据点将被标记为“绿色”，因为“绿色”占大多数(如上图所示)。</p><p id="c6b1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Scikit-learn 是一个用于 Python 的机器学习库。在本教程中，我们将使用 Scikit-learn 构建一个 k-NN 模型来预测患者是否患有糖尿病。</p><h2 id="d45c" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">读入训练数据</h2><p id="eda0" class="pw-post-body-paragraph kd ke iq kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">对于我们的 k-NN 模型，第一步是读入我们将用作输入的数据。对于这个例子，我们使用糖尿病数据集。首先，我们将使用 Pandas 读入数据。我不会详细介绍熊猫，但如果你想进一步深入数据科学和机器学习，这是一个你应该熟悉的库。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="2e97" class="lb lc iq me b gy mi mj l mk ml">import pandas as pd</span><span id="55cd" class="lb lc iq me b gy mm mj l mk ml">#read in the data using pandas<br/>df = pd.read_csv(‘data/diabetes_data.csv’)</span><span id="54cf" class="lb lc iq me b gy mm mj l mk ml">#check data has been read in properly<br/>df.head()</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mn"><img src="../Images/d333d6dcfb3117945451ac453762196b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AAJ_JWUFNKFifZAbkS10IA.jpeg"/></div></div></figure><p id="8b9a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们来看看我们有多少数据。我们将在数据帧上调用“shape”函数，查看数据中有多少行和多少列。行表示患者的数量，列表示特征(年龄、体重等)的数量。)在数据集中。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="dd8d" class="lb lc iq me b gy mi mj l mk ml">#check number of rows and columns in dataset<br/>df.shape</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/991066d3646933d4adc408a8207a3041.png" data-original-src="https://miro.medium.com/v2/resize:fit:368/format:webp/1*rfaxt3oXQ3Xfc8qZSCwpYQ.jpeg"/></div></figure><p id="9b94" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到，我们有 768 行数据(潜在的糖尿病患者)和 9 列数据(8 个输入特征和 1 个目标输出)。</p><h2 id="39e5" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">将数据集分成输入和目标</h2><p id="a545" class="pw-post-body-paragraph kd ke iq kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">现在让我们把数据集分成输入(X)和目标(y)。我们的输入将是除“糖尿病”之外的每一列，因为“糖尿病”是我们将试图预测的。因此，“糖尿病”将是我们的目标。</p><p id="c5dc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用 pandas 'drop '函数从数据帧中删除列' diabetes ',并将其存储在变量' X '中。这将是我们的投入。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="e4de" class="lb lc iq me b gy mi mj l mk ml"><em class="mp">#create a dataframe with all training data except the target column</em><br/>X = df.drop(columns=[‘diabetes’])</span><span id="41c0" class="lb lc iq me b gy mm mj l mk ml"><em class="mp">#check that the target variable has been removed</em><br/>X.head()</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mq"><img src="../Images/eaa47561713c617b1ec62231057902cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jbokr_pt4QtYCum0D_vKuw.jpeg"/></div></div></figure><p id="88d7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将把数据集的“糖尿病”列插入到目标变量(y)中。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="bd1a" class="lb lc iq me b gy mi mj l mk ml">#separate target values<br/>y = df[‘diabetes’].values</span><span id="46f6" class="lb lc iq me b gy mm mj l mk ml">#view target values<br/>y[0:5]</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/de9d03a3999ef60ffef20a1bbae47e5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*lZzY0cSuokbakhPjOVW2cA.jpeg"/></div></figure><h2 id="fb85" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">将数据集拆分为训练和测试数据</h2><p id="6aab" class="pw-post-body-paragraph kd ke iq kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">现在，我们将数据集分为训练数据和测试数据。训练数据是模型将从中学习的数据。测试数据是我们将用来查看模型在看不见的数据上表现如何的数据。</p><p id="80d8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Scikit-learn 有一个我们可以使用的名为“train_test_split”的函数，它使我们可以很容易地将数据集分成训练和测试数据。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="9210" class="lb lc iq me b gy mi mj l mk ml">from sklearn.model_selection import train_test_split</span><span id="b24f" class="lb lc iq me b gy mm mj l mk ml">#split dataset into train and test data<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)</span></pre><p id="9a23" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">“train_test_split”接受 5 个参数。前两个参数是我们之前分开的输入和目标数据。接下来，我们将“测试大小”设置为 0.2。这意味着 20%的数据将用于测试，剩下 80%的数据作为模型学习的训练数据。将“random_state”设置为 1 可以确保我们每次都能获得相同的分割，这样我们就可以重现我们的结果。</p><p id="09c3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将“分层”设置为 y 会使我们的训练分割表示 y 变量中每个值的比例。例如，在我们的数据集中，如果 25%的患者患有糖尿病，75%的患者没有糖尿病，将“分层”设置为 y 将确保随机拆分有 25%的糖尿病患者和 75%的非糖尿病患者。</p><h2 id="990e" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">构建和训练模型</h2><p id="572a" class="pw-post-body-paragraph kd ke iq kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">接下来，我们必须建立模型。代码如下:</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="927e" class="lb lc iq me b gy mi mj l mk ml">from sklearn.neighbors import KNeighborsClassifier</span><span id="351e" class="lb lc iq me b gy mm mj l mk ml"># Create KNN classifier<br/>knn = KNeighborsClassifier(n_neighbors = 3)</span><span id="847d" class="lb lc iq me b gy mm mj l mk ml"># Fit the classifier to the data<br/>knn.fit(X_train,y_train)</span></pre><p id="459e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们将创建一个新的 k-NN 分类器，并将“n_neighbors”设置为 3。概括地说，这意味着如果与新数据点最近的 3 个点中至少有 2 个是没有糖尿病的患者，那么新数据点将被标记为“没有糖尿病”，反之亦然。换句话说，一个新的数据点由 3 个最近点的多数标记。</p><p id="8d9c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将“n_neighbors”设置为 3 作为起点。我们将在下面更详细地讨论如何更好地为“n_neighbors”选择一个值，以便模型可以提高其性能。</p><p id="c939" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们需要训练模型。为了训练我们的新模型，我们将使用“fit”函数并传递我们的训练数据作为参数，以使我们的模型符合训练数据。</p><h2 id="8b50" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">测试模型</h2><p id="4385" class="pw-post-body-paragraph kd ke iq kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">一旦模型训练完毕，我们就可以使用模型上的“预测”功能对测试数据进行预测。如前面检查“y”时所见，0 表示患者没有糖尿病，1 表示患者有糖尿病。为了节省空间，我们将只显示测试集的前 5 个预测。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="b505" class="lb lc iq me b gy mi mj l mk ml">#show first 5 model predictions on the test data<br/>knn.predict(X_test)[0:5]</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/4aa31d60d5c5a41c03a31df3f7db53f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*QJCJc4Us0ry50-GchQ4iNQ.jpeg"/></div></figure><p id="0b0f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到，该模型预测测试集中的前 4 名患者“没有糖尿病”,而第 5 名患者“患有糖尿病”。</p><p id="cfc2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在让我们看看我们的模型在整个测试集上有多精确。为此，我们将使用“score”函数，并传入我们的测试输入和目标数据，以查看我们的模型预测与实际结果的匹配程度。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="5e6b" class="lb lc iq me b gy mi mj l mk ml">#check accuracy of our model on the test data<br/>knn.score(X_test, y_test)</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ms"><img src="../Images/4d0960fd8729ff9fb8aac0a533c90133.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*_l_rQ5HmHBROqyDOsV2mGQ.jpeg"/></div></div></figure><p id="1e9b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的模型具有大约 66.88%的准确度。这是一个好的开始，但我们将在下面看到如何提高模型性能。</p><p id="60af" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">恭喜你。你现在已经建立了一个惊人的 k-NN 模型！</p><h2 id="ea97" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">k 倍交叉验证</h2><p id="92fe" class="pw-post-body-paragraph kd ke iq kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">交叉验证是指数据集被随机分成“k”个组。其中一组用作测试集，其余的用作训练集。该模型在训练集上被训练，并在测试集上被评分。然后重复该过程，直到每个唯一的组都被用作测试集。</p><p id="3539" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，对于 5 重交叉验证，数据集将被分成 5 组，模型将被训练和测试 5 次，因此每组都有机会成为测试集。这可以从下图中看出。</p><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mt"><img src="../Images/6795434753bb9a9080f019b892f1d7fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NyvaFiG_jXcGgOaouumYJQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">5-fold cross validation (<a class="ae kc" href="https://www.datacamp.com/" rel="noopener ugc nofollow" target="_blank">image credit</a>)</figcaption></figure><p id="d7b5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们之前使用的训练-测试-拆分方法称为“保持”。交叉验证比使用维持方法更好，因为维持方法的得分取决于如何将数据拆分为定型集和测试集。交叉验证为模型提供了在多个拆分上进行测试的机会，因此我们可以更好地了解模型在看不见的数据上的表现。</p><p id="baa8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了使用交叉验证来训练和测试我们的模型，我们将使用交叉验证值为 5 的“cross_val_score”函数。“cross_val_score”将我们的 k-NN 模型和我们的数据作为参数。然后，它将我们的数据分成 5 组，并对我们的数据进行 5 次拟合和评分，每次都将准确度分数记录在一个数组中。我们将准确性分数保存在“cv_scores”变量中。</p><p id="723a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了计算 5 个分数的平均值，我们将使用 numpy 的 mean 函数，传入“cv_score”。Numpy 是 Python 中一个有用的数学库。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="5d96" class="lb lc iq me b gy mi mj l mk ml">from sklearn.model_selection import cross_val_score<br/>import numpy as np</span><span id="ae8e" class="lb lc iq me b gy mm mj l mk ml">#create a new KNN model<br/>knn_cv = KNeighborsClassifier(n_neighbors=3)</span><span id="a840" class="lb lc iq me b gy mm mj l mk ml">#train model with cv of 5 <br/>cv_scores = cross_val_score(knn_cv, X, y, cv=5)</span><span id="a581" class="lb lc iq me b gy mm mj l mk ml">#print each cv score (accuracy) and average them<br/>print(cv_scores)<br/>print(‘cv_scores mean:{}’.format(np.mean(cv_scores)))</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mu"><img src="../Images/a27b9a310024287b2e24ceb77e2301ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2JhGurxPzgNe6a9FrRGMsA.jpeg"/></div></div></figure><p id="d68b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用交叉验证，我们的平均分数约为 71.36%。与我们之前使用维持方法进行的测试相比，这更准确地展示了我们的模型在未知数据上的表现。</p><h2 id="dd54" class="lb lc iq bd ld le lf dn lg lh li dp lj ko lk ll lm ks ln lo lp kw lq lr ls lt bi translated">使用 GridSearchCV 超调模型参数</h2><p id="f570" class="pw-post-body-paragraph kd ke iq kf b kg lu ki kj kk lv km kn ko lw kq kr ks lx ku kv kw ly ky kz la ij bi translated">当建立我们的初始 k-NN 模型时，我们将参数“n_neighbors”设置为 3 作为起点，该选择背后没有真正的逻辑。</p><p id="7296" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">超调参数是指通过一个过程来为您的模型找到最佳参数，以提高精度。在我们的例子中，我们将使用 GridSearchCV 来寻找‘n _ neighbors’的最优值。</p><p id="691e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">GridSearchCV 通过在我们指定的参数范围内多次训练我们的模型来工作。这样，我们可以用每个参数测试我们的模型，并找出最佳值以获得最佳精度结果。</p><p id="54dd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于我们的模型，我们将为“n_neighbors”指定一个值范围，以查看哪个值最适合我们的模型。为此，我们将创建一个字典，将' n_neighbors '设置为键，并使用 numpy 创建一个值从 1 到 24 的数组。</p><p id="09b6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们使用网格搜索的新模型将采用新的 k-NN 分类器、我们的 param_grid 和交叉验证值 5，以便找到‘n _ neighbors’的最佳值。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="f863" class="lb lc iq me b gy mi mj l mk ml">from sklearn.model_selection import GridSearchCV</span><span id="b9b6" class="lb lc iq me b gy mm mj l mk ml">#create new a knn model<br/>knn2 = KNeighborsClassifier()</span><span id="bd71" class="lb lc iq me b gy mm mj l mk ml">#create a dictionary of all values we want to test for n_neighbors<br/>param_grid = {‘n_neighbors’: np.arange(1, 25)}</span><span id="bebb" class="lb lc iq me b gy mm mj l mk ml">#use gridsearch to test all values for n_neighbors<br/>knn_gscv = GridSearchCV(knn2, param_grid, cv=5)</span><span id="8066" class="lb lc iq me b gy mm mj l mk ml">#fit model to data<br/>knn_gscv.fit(X, y)</span></pre><p id="d1f4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">训练之后，我们可以检查我们测试的‘n _ neighbors’的哪个值表现最好。为此，我们将在模型上调用‘best _ params _’。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="7a84" class="lb lc iq me b gy mi mj l mk ml">#check top performing n_neighbors value<br/>knn_gscv.best_params_</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/e43d582c78c228bbe0540e873d86249b.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*5TxGsgTaoKkFYVCMEoLYnw.jpeg"/></div></figure><p id="265c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到，14 是“n_neighbors”的最佳值。当“n_neighbors”为 14 时，我们可以使用“best_score_”函数来检查我们的模型的准确性。best_score_ '输出通过交叉验证获得的分数的平均准确度。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="66b9" class="lb lc iq me b gy mi mj l mk ml">#check mean score for the top performing value of n_neighbors<br/>knn_gscv.best_score_</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/898ba26a34a75fb3257440a4cf0e7490.png" data-original-src="https://miro.medium.com/v2/resize:fit:376/format:webp/1*E8_7u3OH5ft8rUE8T1dflw.jpeg"/></div></figure><p id="795f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过使用网格搜索为我们的模型找到最佳参数，我们已经将我们的模型精度提高了 4%以上！</p><p id="3ea4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">感谢阅读！本教程的 GitHub 库(jupyter 笔记本和数据集)可以在<a class="ae kc" href="https://github.com/eijaz1/k-NN-Tutorial-Scikit-learn" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="e0bf" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你想了解我的机器学习内容，请关注我:)</p></div></div>    
</body>
</html>