<html>
<head>
<title>Demystifying Hyper-Parameter tuning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">揭开超参数调谐的神秘面纱</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/demystifying-hyper-parameter-tuning-acb83af0258f?source=collection_archive---------11-----------------------#2018-10-01">https://towardsdatascience.com/demystifying-hyper-parameter-tuning-acb83af0258f?source=collection_archive---------11-----------------------#2018-10-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="badf" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">它是什么，为什么是自然的</h2></div><p id="9976" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi lb translated">超参数结构每天都有许多过程，但很少有人意识到它们的存在。当你想买一双鞋的时候，你正在解决一个超参数优化问题。一旦你决定了要买哪种<strong class="kh ir"> <em class="lk">类型</em> </strong>的鞋子(<strong class="kh ir"><em class="lk">hyper-parameter</em></strong>)你就需要根据鞋子的<strong class="kh ir"> <em class="lk">参数</em> </strong>来满足你的要求(<strong class="kh ir"> <em class="lk">尺码、颜色、… </em> </strong>)。你的可用预算也是一个超级参数，会影响你的选择。</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi ll"><img src="../Images/e4810ce00e5997fbf1012e9ada3dae3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*qehKZrNZ8a590X7hu9-qPQ.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">An everyday hyper-parameter optimization problem</figcaption></figure><h2 id="05d1" class="lx ly iq bd lz ma mb dn mc md me dp mf ko mg mh mi ks mj mk ml kw mm mn mo mp bi translated">超参数调谐</h2><p id="4353" class="pw-post-body-paragraph kf kg iq kh b ki mq jr kk kl mr ju kn ko ms kq kr ks mt ku kv kw mu ky kz la ij bi translated">如果你选择了一双适合你的鞋子，而且颜色也合适，你就能穿上它们。然而，如果你选择了一双红色高跟鞋，你可能会发现跑马拉松很有挑战性。超参数调整对于大多数用例来说可能并不重要，但会显著影响您的流程效率和您试图获得的结果的质量(例如，您可以穿着靴子跑步，但可能没有穿着运动鞋跑得快)。</p><h2 id="aeb2" class="lx ly iq bd lz ma mb dn mc md me dp mf ko mg mh mi ks mj mk ml kw mm mn mo mp bi translated">数据科学中的超参数调整</h2><p id="2c2e" class="pw-post-body-paragraph kf kg iq kh b ki mq jr kk kl mr ju kn ko ms kq kr ks mt ku kv kw mu ky kz la ij bi translated">大多数机器学习模型都有超参数。</p><p id="060c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，一个简单的随机森林算法会有相当多的:</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mv"><img src="../Images/8ee0d0dbe2d5dba34b22a5462f0639e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*69yRXyqyxA7w2cVa285CLw.png"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Scikit-Learn implementation of a Random Forest Classifier</figcaption></figure><p id="6ca5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦用户指定了其超参数的值，该算法将在基础数据集上进行训练。超参数的选择将影响训练的持续时间和预测的准确性。不幸的是，选择超参数并不是直截了当的，因为可能的配置数量随着它们的数量而爆炸，并且配置的评估时间是模型复杂性和底层训练数据大小的函数。此外，这是一种有点黑暗的艺术，正如威廉·科尔森在他的媒体文章<a class="ae nc" rel="noopener" target="_blank" href="/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74">中所说:</a></p><blockquote class="nd"><p id="33a8" class="ne nf iq bd ng nh ni nj nk nl nm la dk translated">超参数调整更多地依赖于实验结果而不是理论，因此确定最佳设置的最佳方法是尝试许多不同的组合来评估每个模型的性能。</p></blockquote><p id="5f7d" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">面对如此多的不确定性，大多数数据科学家放弃超参数调整，坚持使用模型提供的默认值是可以理解的。这在大多数情况下是可行的，但是根据我的初步类比，你可能很难穿着高跟鞋跑马拉松。</p><blockquote class="nd"><p id="74b7" class="ne nf iq bd ng nh ni nj nk nl nm la dk translated">在现实生活中你不会这样做(除非是为了一个好的理由)，那么在数据科学领域你为什么会这样做呢？</p></blockquote><p id="e890" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">第二种最流行的方法是通过<strong class="kh ir"> <em class="lk">网格搜索</em> </strong>(评估每一个配置)找到最佳配置，这将最终导致一个答案。</p><blockquote class="nd"><p id="85ad" class="ne nf iq bd ng nh ni nj nk nl nm la dk translated"><strong class="ak">但是你不会穿着你所有的每一双鞋跑完一场马拉松，从而得出结论说你穿着运动鞋跑得最好，那么你为什么要在数据科学领域做同样的事情呢？</strong></p></blockquote><p id="7ece" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">第三种最流行的方法是通过<strong class="kh ir"> <em class="lk">随机搜索</em> </strong>找到最佳配置，但这仅比网格搜索略好。我就不跟你打这个比方了，因为我希望现在你明白我的意思了。</p><blockquote class="nd"><p id="2cb8" class="ne nf iq bd ng nh ni nj nk nl nm la dk translated">那么如何更有效地进行超参数调优呢？</p></blockquote><p id="24b8" class="pw-post-body-paragraph kf kg iq kh b ki nn jr kk kl no ju kn ko np kq kr ks nq ku kv kw nr ky kz la ij bi translated">头脑铸造公司的推特粉丝似乎知道答案</p><figure class="lm ln lo lp gt lq"><div class="bz fp l di"><div class="ns nt l"/></div></figure><h2 id="41e0" class="lx ly iq bd lz ma mb dn mc md me dp mf ko mg mh mi ks mj mk ml kw mm mn mo mp bi translated">贝叶斯优化</h2><p id="ac59" class="pw-post-body-paragraph kf kg iq kh b ki mq jr kk kl mr ju kn ko ms kq kr ks mt ku kv kw mu ky kz la ij bi translated">贝叶斯优化通过结合对解空间看起来像什么的“信念”,并通过从它评估的配置中“学习”,解决了网格和随机搜索的陷阱。这种信念可以由领域专家指定，但也可以在开始时是平的。如果当你尝试穿着细高跟鞋跑马拉松，你不会再穿你所有的其他高跟鞋了，因为你会知道这很痛苦。此外，如果你有先验知识，你可能从一开始就选择平底鞋！</p><p id="876b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我已经写了一篇更详细的文章(用更少的类比)来解释贝叶斯优化背后的直觉:</p><div class="nu nv gp gr nw nx"><a rel="noopener follow" target="_blank" href="/the-intuitions-behind-bayesian-optimization-with-gaussian-processes-7e00fcc898a0"><div class="ny ab fo"><div class="nz ab oa cl cj ob"><h2 class="bd ir gy z fp oc fr fs od fu fw ip bi translated">高斯过程贝叶斯优化背后的直觉</h2><div class="oe l"><h3 class="bd b gy z fp oc fr fs od fu fw dk translated">在某些应用中，目标函数是昂贵的或难以评估的。在这些情况下，一般…</h3></div><div class="of l"><p class="bd b dl z fp oc fr fs od fu fw dk translated">towardsdatascience.com</p></div></div><div class="og l"><div class="oh l oi oj ok og ol lr nx"/></div></div></a></div><p id="9e6a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以在<a class="ae nc" href="https://www.mindfoundry.ai/learning-hub/the-intuitions-behing-bayesian-optimization" rel="noopener ugc nofollow" target="_blank">这里</a>找到可下载的白皮书版本。</p><p id="3106" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以在这里自动接收我们的贝叶斯优化器 OPTaaS 的 API 密钥！</p><p id="5565" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">【<strong class="kh ir">更新</strong>:我开了一家科技<a class="ae nc" href="http://www.legislate.tech/" rel="noopener ugc nofollow" target="_blank">公司</a>。你可以在这里找到更多的<a class="ae nc" href="https://medium.com/legislate/eliminate-the-work-in-paperwork-c053bfb0188c" rel="noopener"/></p><h2 id="e8ca" class="lx ly iq bd lz ma mb dn mc md me dp mf ko mg mh mi ks mj mk ml kw mm mn mo mp bi translated">贝叶斯优化的扩展</h2><p id="ecdc" class="pw-post-body-paragraph kf kg iq kh b ki mq jr kk kl mr ju kn ko ms kq kr ks mt ku kv kw mu ky kz la ij bi translated">如果你有可以尝试其他鞋子的朋友，你们会集体找到跑马拉松用得更快的最好的一双。同样可以在 BO <a class="ae nc" href="https://mindfoundry.ai/wp-content/uploads/optaas-2-pager.pdf" rel="noopener ugc nofollow" target="_blank">中通过智能配料</a>实现。</p><p id="bd9d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你穿着高跟鞋跑马拉松，你应该(在理论上)很早就意识到这相当痛苦，你应该停下来换双鞋？</p><p id="b9c7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">嗯，这在贝叶斯优化的某些实现中是可能的，在我的下一篇文章中，我将解释如何实现。</p></div></div>    
</body>
</html>