<html>
<head>
<title>GANs N’ Roses</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">甘斯·恩罗斯</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gans-n-roses-c6652d513260?source=collection_archive---------1-----------------------#2017-06-29">https://towardsdatascience.com/gans-n-roses-c6652d513260?source=collection_archive---------1-----------------------#2017-06-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/145d74daf1708e3f74707ed0663f65c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Hq__gQuZMTsxmK20x6nPg.png"/></div></div></figure><p id="cc40" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">“本文假设读者熟悉神经网络和Tensorflow的使用。如果没有，我们会要求您阅读迈克尔·尼尔森关于深度学习的</em> <a class="ae kx" href="http://neuralnetworksanddeeplearning.com/" rel="noopener ugc nofollow" target="_blank"> <em class="kw">这篇</em> </a> <em class="kw">文章，并熟悉如何使用</em><a class="ae kx" href="https://www.tensorflow.org/get_started/" rel="noopener ugc nofollow" target="_blank"><em class="kw">tensor flow</em></a><em class="kw">。”</em></p><p id="75d9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">想象有一天，我们有了一个神经网络，它可以看电影并生成自己的电影，或者听歌并创作新的电影。这个网络会从所见所闻中学习，而不需要你明确地告诉它。这种让神经网络学习的方式被称为无监督学习。</p><p id="6498" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在过去的三年里，事实上以无人监督的方式训练的GANs(生成对抗网络)获得了很多关注，现在被认为是人工智能领域最热门的话题之一。这是《脸书AI》的导演Yann LeCun对他们的看法:</p><blockquote class="ky kz la"><p id="721b" class="jy jz kw ka b kb kc kd ke kf kg kh ki lb kk kl km lc ko kp kq ld ks kt ku kv ij bi translated">生成对抗网络是近十年来机器学习中最有趣的思想。</p></blockquote><p id="4311" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">gan是做梦的神经网络，在观看其中一些图像后生成图像。嗯，这个可以用来做什么？为什么这很重要？</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi le"><img src="../Images/e6321c98f5150f215ba0812c9fba8f60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RRnHZcj9uP2EY5UM.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Generated bedroom images. Source: <a class="ae kx" href="https://arxiv.org/abs/1511.06434v2" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1511.06434v2</a></figcaption></figure><p id="fee4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">直到最近，神经网络(特别是卷积神经网络)只擅长分类任务，例如在猫和狗或者飞机和汽车之间进行分类。但是现在它们可以用来生成猫或狗的图片(尽管它们看起来很奇怪)，这告诉我们它们已经学会了特征。这向我们表明，他们能够理解一个物体本身的特征。</p><p id="1582" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">GANs的这种非凡能力可用于许多令人惊叹的应用，例如:</p><ul class=""><li id="ecbd" class="ln lo iq ka b kb kc kf kg kj lp kn lq kr lr kv ls lt lu lv bi translated">给定文本描述生成图像。查看<a class="ae kx" href="https://arxiv.org/pdf/1612.03242v1.pdf" rel="noopener ugc nofollow" target="_blank">此</a>链接:</li></ul><figure class="lf lg lh li gt jr gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/0768a0323de95dc0e61233d9cd30b19e.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/0*o-DLlcgo-0eQoi1m.png"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Text to Image. Source: <a class="ae kx" href="https://arxiv.org/pdf/1605.05396v2.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1605.05396v2.pdf</a></figcaption></figure><div class="lx ly gp gr lz ma"><a href="https://tryolabs.com/blog/2016/12/06/major-advancements-deep-learning-2016/" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd ir gy z fp mf fr fs mg fu fw ip bi translated">2016年深度学习的主要进展- Tryolabs博客</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">过去几年，深度学习一直是机器学习社区的核心话题，2016年并不是…</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">tryolabs.com</p></div></div><div class="mj l"><div class="mk l ml mm mn mj mo jw ma"/></div></div></a></div><ul class=""><li id="ae0c" class="ln lo iq ka b kb kc kf kg kj lp kn lq kr lr kv ls lt lu lv bi translated">图像到图像的翻译:</li></ul><p id="ef46" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这可能是迄今为止GAN最酷的应用。图像到图像转换可用于从草图生成逼真的图像，将白天拍摄的照片转换为夜间图像，甚至将灰度图像转换为彩色图像。</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mp"><img src="../Images/bc0c9d631328f19617688b1dc1f8b02a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*LZ70kAUr_HE1lzM8.jpg"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Image to Image Translation. Source: <a class="ae kx" href="https://phillipi.github.io/pix2pix/" rel="noopener ugc nofollow" target="_blank">https://phillipi.github.io/pix2pix/</a></figcaption></figure><p id="4d7e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">请点击此链接了解更多详情:</p><div class="lx ly gp gr lz ma"><a href="https://phillipi.github.io/pix2pix/" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd ir gy z fp mf fr fs mg fu fw ip bi translated">基于条件对抗网络的图像到图像翻译</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">基于条件对抗网络的图像到图像翻译</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">phillipi.github.io</p></div></div><div class="mj l"><div class="mq l ml mm mn mj mo jw ma"/></div></div></a></div></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><p id="a500" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">了解了GAN的能力之后，让我们一起登上宣传列车，实现一个简单的GAN来生成玫瑰的图像。好吧，等等，但是为什么是玫瑰？</p><blockquote class="my"><p id="86e8" class="mz na iq bd nb nc nd ne nf ng nh kv dk translated">"<em class="ni">我们不想用一个故事来烦你，但只能说这篇文章是在听了枪炮玫瑰乐队的一首歌后得到的灵感(现在知道标题了吧？？)</em>”</p></blockquote></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="1810" class="nj nk iq bd nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og bi translated"><strong class="ak">让我们看看甘到底是什么:</strong></h1><p id="8db2" class="pw-post-body-paragraph jy jz iq ka b kb oh kd ke kf oi kh ki kj oj kl km kn ok kp kq kr ol kt ku kv ij bi translated">在我们开始构建GAN之前，让我们了解它是如何工作的。生成式对抗网络包含两个神经网络:鉴别器和生成器。鉴别器是卷积神经网络(不知道CNN是什么？看看<a class="ae kx" href="http://neuralnetworksanddeeplearning.com/chap6.html" rel="noopener ugc nofollow" target="_blank">这篇</a>精彩的文章)学习区分真实和虚假的图片。真实的图像来自数据库，假的来自生成器。</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi om"><img src="../Images/1db1b34eac5fcf9d1df5915bd989d618.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*it0RKKXp5yjRqcyczEw_Kw.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Discriminator</figcaption></figure><p id="d014" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该生成器的工作方式类似于反向运行的CNN，它将一个随机数向量作为输入，并在输出端生成一个图像。</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi on"><img src="../Images/109f1a583113575a2e4c4f6a274de90b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D6j2k23kKUGHJEBgJftH2A.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Generator</figcaption></figure><p id="9726" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们稍后将讨论生成器和鉴别器的工作和实现，但现在让我们看一个著名的例子来解释GANs(解释大量借用了<a class="ae kx" href="https://medium.com/@ageitgey/abusing-generative-adversarial-networks-to-make-8-bit-pixel-art-e45d9b96cee7" rel="noopener">滥用生成性对抗网络来制作8位像素艺术</a>)。</p><p id="012c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们把生产者想象成一个伪造者，把鉴别者想象成一个必须辨别真假货币的警察。首先，让我们保证伪造者和警察的工作都一样糟糕。因此，伪造者首先产生一些随机的看起来有噪声的图像，因为它对货币的样子一无所知。</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oo"><img src="../Images/f3fd07a4fd38fcff3818d027a77ddb4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*frhbqwT2_BIYiEPh9LXO1w.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Noisy Image by the Counterfeiter</figcaption></figure><p id="dc40" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，警察被训练来区分伪造者制造的这些假图像和真货币。</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi op"><img src="../Images/87b2618149d4cd0126fc5997d6eadcce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y4nVpcxaTRjsUrKGYXBxvQ.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Train the Police Officer</figcaption></figure><p id="b4fc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">伪造者现在知道其图像被归类为假的，并且警察正在寻找货币中的一些明显特征(例如颜色和图案)。伪造者现在知道了这些特征，并产生了具有这些特征的货币(在这种情况下是图像)。</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oq"><img src="../Images/ef007c6c88a03bb1d30ae92e1cf2d888.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lgd0os-QENS_PNADQkcR2g.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Training the Counterfeiter</figcaption></figure><p id="1bd6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，再次向警官展示来自数据集的真实货币和来自伪造者的新的改进(希望如此)图像，并要求对它们进行分类。因此，官员将会学到真实图像的更多特征(如货币上的脸)。</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi or"><img src="../Images/39a550afd4a2eb8f38e6e6156d67b01f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DSNqKG-dOy3S1mbWpcOkhg.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Train the Police with the new fake images</figcaption></figure><p id="4a4e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">伪造者再次学习这些特征并产生更好看的假图像。</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oq"><img src="../Images/1e8ef31175fe59c26039f37fbe020ff2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FkRv76NHFNfU1NHcNAQDmQ.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Train the counterfeiter again</figcaption></figure><p id="85be" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">伪造者和警察之间的这种持续的斗争一直持续到伪造者制造出看起来和真的一模一样的图像，而警察无法对它们进行分类。</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi os"><img src="../Images/157a149f3b7656fd7ef55111501852e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n9nNPgyNoI0DRbJ0zw3BhQ.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Real or Fake?</figcaption></figure></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><p id="c212" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">GANs N ' Roses在Tensorflow上的实现:</strong></p><p id="5ff2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们使用tensorflow，不使用任何其他东西(除了pillow)，构建一个简单的DCGAN(深度卷积生成对抗网络)。</p><p id="ce1a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但是什么是DCGAN呢？</p><p id="66e3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae kx" href="https://arxiv.org/abs/1511.06434" rel="noopener ugc nofollow" target="_blank"> DCGAN </a>是vanilla GAN的修改版本，以解决vanilla GAN的一些困难，例如:使假图像看起来视觉上令人愉悦，在训练过程中提高稳定性，以便生成器不会通过重复输出符合鉴别器正在寻找的数据分布的图像来发现鉴别器中的缺陷，但与真实图像相差甚远。</p><p id="3777" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是我们试图构建的鉴别器架构:</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ot"><img src="../Images/13334943e7e92a7b0a5a80ec1675f5ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iObxS1LmR9IOTP50K_LtRw.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Discriminator Architecture</figcaption></figure><p id="6b1c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">可以看出，它接受一个图像作为输入，并输出一个logit (1表示真类，0表示假类)。</p><p id="e35b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，我们有生成器架构，它由<a class="ae kx" href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose" rel="noopener ugc nofollow" target="_blank"> conv转置</a>层组成，接受一组随机数作为输入，并在输出端生成图像。</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ou"><img src="../Images/40fdbbf9f9817444e00cb6cce2d6db44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GEfMfFIk666OzPOQzGo2pg.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Generator Architecture</figcaption></figure><p id="b62e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">DCGANs提出的修改直接取自<a class="ae kx" href="https://arxiv.org/pdf/1511.06434.pdf" rel="noopener ugc nofollow" target="_blank">这份</a>文件:</p><ul class=""><li id="52f9" class="ln lo iq ka b kb kc kf kg kj lp kn lq kr lr kv ls lt lu lv bi translated">用步长卷积(鉴别器)和分数步长卷积(生成器)替换任何池层。</li><li id="4be5" class="ln lo iq ka b kb ov kf ow kj ox kn oy kr oz kv ls lt lu lv bi translated">在发生器和鉴别器中使用<a class="ae kx" href="https://standardfrancis.files.wordpress.com/2015/04/screenshot-from-2015-04-16-133436.png?w=1008" rel="noopener ugc nofollow" target="_blank"> batchnorm </a>。</li><li id="aab5" class="ln lo iq ka b kb ov kf ow kj ox kn oy kr oz kv ls lt lu lv bi translated">为更深层次的架构移除完全连接的隐藏层。</li><li id="d0de" class="ln lo iq ka b kb ov kf ow kj ox kn oy kr oz kv ls lt lu lv bi translated">在生成器中对所有层使用ReLU激活，但输出层除外，它使用Tanh。</li><li id="6154" class="ln lo iq ka b kb ov kf ow kj ox kn oy kr oz kv ls lt lu lv bi translated">在所有层的鉴别器中使用LeakyReLU激活。</li></ul><p id="aa0d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们从收集玫瑰的图像开始。一个简单的方法是在谷歌上搜索玫瑰图片，并通过使用ImageSpark等chrome插件下载搜索结果中的所有图片。</p><p id="a765" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们已经收集了67张图片(越多越好),可在<a class="ae kx" href="https://drive.google.com/open?id=0B068a_0Gq8kYSGZ3UmdveFczM0U" rel="noopener ugc nofollow" target="_blank">这里</a>找到。将这些图像提取到以下目录中:</p><p id="4bcb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><project folder="">/数据集/玫瑰花。</project></p><p id="7c78" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">可以通过在Github上克隆这个repo来获得代码和数据集。</p><div class="lx ly gp gr lz ma"><a href="https://github.com/Naresh1318/GANs_N_Roses" rel="noopener  ugc nofollow" target="_blank"><div class="mb ab fo"><div class="mc ab md cl cj me"><h2 class="bd ir gy z fp mf fr fs mg fu fw ip bi translated">纳雷斯1318/甘斯玫瑰</h2><div class="mh l"><h3 class="bd b gy z fp mf fr fs mg fu fw dk translated">GANs_N_Roses -使用深度卷积生成敌对网络，通过tensorflow生成玫瑰图像。</h3></div><div class="mi l"><p class="bd b dl z fp mf fr fs mg fu fw dk translated">github.com</p></div></div><div class="mj l"><div class="pa l ml mm mn mj mo jw ma"/></div></div></a></div><p id="eeb8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们有了图像，下一步是预处理这些图像，将它们重新整形为64 * 64，并将它们缩放到-1到1之间的值。</p><figure class="lf lg lh li gt jr"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="8d62" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将首先写出稍后可用于构建卷积、卷积转置、密集全连接层和LeakyReLU激活的函数(因为它在Tensorflow上尚不可用)。</p><figure class="lf lg lh li gt jr"><div class="bz fp l di"><div class="pb pc l"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Function to implement convolutional layer</figcaption></figure><p id="aefa" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们使用<code class="fe pd pe pf pg b">get_variable()</code>而不是通常的<code class="fe pd pe pf pg b">Variable()</code>在tensorflow上创建一个变量，以便稍后在不同的函数调用之间共享权重和偏差。查看<a class="ae kx" href="https://www.tensorflow.org/versions/r0.12/how_tos/variable_scope/" rel="noopener ugc nofollow" target="_blank">这篇</a>的帖子，了解更多关于共享变量的信息。</p><figure class="lf lg lh li gt jr"><div class="bz fp l di"><div class="pb pc l"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Function to implement convolution transpose</figcaption></figure><figure class="lf lg lh li gt jr"><div class="bz fp l di"><div class="pb pc l"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Function to implement dense fully connected layer</figcaption></figure><figure class="lf lg lh li gt jr"><div class="bz fp l di"><div class="pb pc l"/></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Leaky ReLU</figcaption></figure><p id="3b19" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下一步是构建生成器和鉴别器。先从我们的主角，发电机说起。我们需要构建的生成器架构如下所示:</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ou"><img src="../Images/40fdbbf9f9817444e00cb6cce2d6db44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GEfMfFIk666OzPOQzGo2pg.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Again, the Generator Architecture we’re trying to implement</figcaption></figure><figure class="lf lg lh li gt jr"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="27e7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><code class="fe pd pe pf pg b">generator()</code>函数构建了一个发电机(dah！)使用上图中的架构。已满足DCGAN要求，例如移除所有完全连接的层、仅在生成器中使用ReLU以及使用批量标准化。</p><p id="dc9a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">类似地，鉴别器可以容易地构造如下:</p><p id="ec23" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">所需的架构:</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ot"><img src="../Images/13334943e7e92a7b0a5a80ec1675f5ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iObxS1LmR9IOTP50K_LtRw.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">The Discriminator architecture</figcaption></figure><figure class="lf lg lh li gt jr"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="57d7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们再次避免了密集的全连接层，在鉴别器处使用了泄漏ReLU和批量标准化。</p><p id="d48f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">现在是有趣的部分，训练这些网络:</strong></p><p id="63fc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">鉴别器和发生器的损失函数如下所示:</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ph"><img src="../Images/191f08fab94803f9b3892564d4cd0f58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Nz0afeUXxWUmtqHI."/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Discriminator loss (This must have a negative sign)</figcaption></figure><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pi"><img src="../Images/58ae8684a31af4a736865fc55a3a9931.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LOARbph12P04kCUx."/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Generator loss</figcaption></figure><p id="64e0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">其中x代表实像，z是输入发生器的噪声矢量。</p><figure class="lf lg lh li gt jr"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="0d77" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将把随机输入传递给生成器，zin的形状将是[BATCH_SIZE，Z_DIM]，生成器现在应该在其输出中给出BATCH_SIZE数量的假图像。生成器输出的大小现在将是[BATCH_SIZE，IMAGE_SIZE，IMAGE_SIZE，3]。这是损失函数中的G(z)项。</p><p id="66ea" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">D(x)是接受真实图像或虚假图像的鉴别器，并被训练来区分它们。为了在真实图像上训练鉴别器，我们将把真实图像批次传递给D(x ),并将目标设置为1。类似地，为了在假图像(来自生成器)上训练它，我们将使用D(G(z))将生成器输出连接到鉴别器输入。</p><p id="b2ad" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">鉴频器的损耗通过tensorflow的内置函数实现:</p><figure class="lf lg lh li gt jr"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="5139" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，我们需要训练生成器，使D(G(z))将输出一个1，也就是说，我们将固定鉴别器上的权重，并仅支持生成器权重，以便鉴别器总是输出一个1。</p><p id="3beb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，发电机的损失函数为:</p><figure class="lf lg lh li gt jr"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="faf7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，我们将收集鉴别器和生成器的所有权重(稍后需要仅训练生成器或鉴别器):</p><figure class="lf lg lh li gt jr"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="cd16" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们使用tensorflow的AdamOptimizer来学习权重。下一步是将需要修改的权重分别传递给鉴别器和生成器优化器。</p><figure class="lf lg lh li gt jr"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="3ae4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后一步是运行会话，并将所需的图像批次传递给优化器。我们将训练模型30000次迭代，并定期显示鉴别器和发电机损耗。</p><figure class="lf lg lh li gt jr"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="87fb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了使超参数的调整更容易，并保存每次运行的结果，我们实现了form_results函数并创建了一个名为<code class="fe pd pe pf pg b">mission_control.py</code>的文件。</p><p id="24fb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用<code class="fe pd pe pf pg b">mission_control.py</code>文件可以修改网络的所有超级参数，稍后运行<code class="fe pd pe pf pg b">main.py</code>文件将自动为每次运行创建文件夹，并保存tensorboard文件和生成的图像。</p><figure class="lf lg lh li gt jr"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="5d04" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们可以通过打开tensorboard并将其指向在每个运行文件夹下创建的Tensorboard目录来查看训练期间每次迭代的鉴别器和发电机损耗(查看<a class="ae kx" href="https://github.com/Naresh1318/GANs_N_Roses" rel="noopener ugc nofollow" target="_blank"> GitHub </a>链接以了解更多详细信息)。</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pj"><img src="../Images/f69c6fe7027c89ad4d50215daf774955.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4VBSnFnOOW2HkD8qIjqfyg.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Variation of Generator loss during training</figcaption></figure><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pk"><img src="../Images/7787e2165ec01a7fe4ca5bbaa531f79c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rg3_f1qTAXzjm1JeWfzNZA.png"/></div></div><figcaption class="lj lk gj gh gi ll lm bd b be z dk">Variation of Discriminator loss during training</figcaption></figure><p id="60d3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从这些图中可以看出，鉴别器和发生器损耗在训练阶段不断增加和减少，表明发生器和鉴别器都试图超越彼此。</p><p id="23cd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该代码还保存每次运行生成的图像，其中一些图像如下所示:</p><p id="1464" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在第0次迭代时:</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/05a9f60386ae80191c802307f5721f04.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*RRiwEIpJJOem1v63q7XIQA.jpeg"/></div></figure><p id="880e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">第100次迭代:</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/cdf547c8b8f51bd788d35ef57e9bb6b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*eOkHlUCrpFMHpWl-EkT4Xg.jpeg"/></div></figure><p id="8165" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">第1000次迭代:</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/90e849bab022c75b26e4b06169e271f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*sVcxMLJ6UKnKJ__XBjzd3Q.jpeg"/></div></figure><p id="36d3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">图像在第30000次迭代时被过度拟合:</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/5bbc54802e13e0253533597c1ab74262.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*7-qPfjkt7uDQBRHJNSVx_A.jpeg"/></div></figure><p id="d0e0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">训练阶段生成的图像如下所示:</p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/026f7ec7d40ba1f8c45c354f7c5db0ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/1*14DDJiyUIYLrqdJZFcyN7g.gif"/></div></figure><p id="5217" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这些图像是有希望的，但是在大约1000次迭代之后，可以看到生成器只是从训练数据集中再现图像。我们可以使用更大的数据集，并针对更少的迭代次数对其进行训练，以减少过度拟合。</p><p id="1092" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">gan易于实施，但如果没有正确的超参数和网络架构，则难以训练。我们写这篇文章的主要目的是帮助人们开始使用生成网络。</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="7216" class="nj nk iq bd nl nm nn no np nq nr ns nt nu nv nw nx ny nz oa ob oc od oe of og bi translated"><strong class="ak">别人在干嘛:</strong></h1><ul class=""><li id="b839" class="ln lo iq ka b kb oh kf oi kj pn kn po kr pp kv ls lt lu lv bi translated"><a class="ae kx" href="https://phillipi.github.io/pix2pix/" rel="noopener ugc nofollow" target="_blank">用条件对抗网进行图像到图像的翻译</a>。</li><li id="8eb7" class="ln lo iq ka b kb ov kf ow kj ox kn oy kr oz kv ls lt lu lv bi translated"><a class="ae kx" href="https://arxiv.org/abs/1701.07875" rel="noopener ugc nofollow" target="_blank">瓦瑟斯坦甘</a>。</li><li id="4b91" class="ln lo iq ka b kb ov kf ow kj ox kn oy kr oz kv ls lt lu lv bi translated"><a class="ae kx" href="https://github.com/devnag/pytorch-generative-adversarial-networks" rel="noopener ugc nofollow" target="_blank"> Pytorch实施GANs </a>。</li></ul><p id="acd7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">感谢您阅读这篇相当长的中型文章。如果你觉得它有帮助，请考虑分享它。如对本文有任何疑问，请随时联系我们。</p></div></div>    
</body>
</html>