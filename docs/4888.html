<html>
<head>
<title>FAQ: Build a Handwritten Text Recognition System using TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">FAQ:使用 TensorFlow 构建手写文本识别系统</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/faq-build-a-handwritten-text-recognition-system-using-tensorflow-27648fb18519?source=collection_archive---------2-----------------------#2018-09-13">https://towardsdatascience.com/faq-build-a-handwritten-text-recognition-system-using-tensorflow-27648fb18519?source=collection_archive---------2-----------------------#2018-09-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/d5d80ba9d38313d37c2f58d23c6cf6f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wqOD1RNwjmShxKA1_sggjQ.jpeg"/></div></div></figure><p id="6c46" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">本文是关于如何使用 TensorFlow 实现一个<a class="ae kz" rel="noopener" target="_blank" href="/2326a3487cd5">文本识别模型的文章的后续。它基于 SimpleHTR 库的一个</a><a class="ae kz" href="https://github.com/githubharald/SimpleHTR/tree/97c2512f593760b14669b37a159ead2f1e54961b" rel="noopener ugc nofollow" target="_blank">旧代码版本</a>。</p><p id="8ec5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">有些问题我想在这里讨论一下。我们来看看以下三个一:</p><ol class=""><li id="a74e" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky lf lg lh li bi translated">如何识别图像/数据集中的文本？</li><li id="fec9" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">如何识别包含在行或整页中的文本？</li><li id="c8cf" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">如何计算识别文本的置信度得分？</li></ol><h1 id="660a" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">1 如何识别图像/数据集中的文本？</h1><p id="b2eb" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">在 IAM 数据集上训练预训练模型。来自 IAM 的一个样本如图 1 所示。该模型不仅学习如何阅读文本，还学习数据集样本的外观。如果您浏览 IAM 单词图像，您会注意到这些模式:</p><ul class=""><li id="e145" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky mr lg lh li bi translated">图像具有高对比度</li><li id="260e" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky mr lg lh li bi translated">单词被紧凑地裁剪</li><li id="4628" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky mr lg lh li bi translated">大胆的写作风格</li></ul><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/ef905ae88ba57d53d665aa324da67c17.png" data-original-src="https://miro.medium.com/v2/resize:fit:346/format:webp/1*okWPvEDUCTR67MnmWX60XQ.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Fig. 1: A sample from the IAM dataset.</figcaption></figure><p id="c93b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果你给一个图像输入一个非常不同的风格，你可能会得到一个不好的结果。让我们看一下图 2 所示的图像。</p><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/aa6085f5f59c422912328bd241156c9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*fU7l9-NJq2xopdQfZc3BUA.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Fig. 2: A sample for which the model recognizes the text “.”.</figcaption></figure><p id="315f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该模型识别文本“”在这张图片中。原因是模型从未见过这样的图像:</p><ul class=""><li id="867b" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky mr lg lh li bi translated">低对比度</li><li id="99da" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky mr lg lh li bi translated">单词周围有很多空间</li><li id="f4fd" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky mr lg lh li bi translated">线条非常细</li></ul><p id="d70f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们来看两种改善识别结果的方法。</p><h1 id="16dc" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">1.1 预处理图像</h1><p id="595f" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">让我们从一个简单的方法开始，让图像看起来更像来自 IAM 数据集的样本。我们将使用上面的图像来尝试这一点(见图 3)。首先，让我们来修剪它。该模型仍然识别“.”。然后，我们增加对比度。现在，模型给出了一个好得多的结果:“tello”。这几乎是正确的。如果我们通过应用形态学操作来加粗线条，模型最终能够识别正确的文本:“Hello”。</p><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/6e3caaf66b8e396c62e1c80d251cb599.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*JrY2Q-RhOm9mqvRNjKTiJg.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Fig. 3: Preprocessing steps and the recognized text for each of them.</figcaption></figure><p id="cd0f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这种裁剪可以用一种<a class="ae kz" href="https://github.com/githubharald/WordDetector" rel="noopener ugc nofollow" target="_blank">分词算法</a>来完成。增加对比度和应用形态学操作是通过以下 Python 代码实现的。</p><figure class="mt mu mv mw gt ju"><div class="bz fp l di"><div class="nd ne l"/></div></figure><h1 id="c5e0" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">1.2 创建 IAM 兼容的数据集和训练模型</h1><p id="d16c" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">获得良好读取结果的最佳方法当然是根据您的数据重新训练模型。虽然创建数据集可能相当费力，但绝对值得。您需要将图像-文本对转换成 IAM 兼容的格式。下面的代码显示了如何进行这种转换。DataProvider 类的 getNext()方法在每次调用时返回一个样本(文本和图像)。createIAMCompatibleDataset()函数创建文件 words.txt 和目录 sub，所有图像都放在这个目录中。如果您想要转换数据集，您必须修改 getNext()方法(目前它只是为所提供的单词创建机器打印的文本，以显示示例用法)。</p><figure class="mt mu mv mw gt ju"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="bede" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">转换后，将文件 words.txt 和目录 sub 复制到 SimpleHTR 项目的数据目录中。然后可以通过执行 python main.py - train 来训练模型。</p><h1 id="1000" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">2 如何识别成行或整页的文字？</h1><p id="d573" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">该型号可输入 128×32 的图像，最多可输出 32 个字符。所以，用那个模型识别一个或者两个单词是可能的。但是，更长的句子甚至整页都无法直接阅读:</p><ul class=""><li id="dddb" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky mr lg lh li bi translated">行:要么将行分割成单词，要么将文本识别模型放大，以便它可以处理整行</li><li id="3165" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky mr lg lh li bi translated">整页:将页面分割成单个的单词，然后分别阅读每一页</li></ul><p id="81b7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们先来看看预处理，它既可以用于行级文本处理，也可以用于页面级文本处理。</p><h1 id="5d23" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">2.1 预处理图像</h1><p id="e057" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">如果该行的单词容易分割(单词之间的间隙大，单词的字符之间的间隙小)，那么可以使用类似于 R. Manmatha 和 N. Srimal 提出的简单的单词分割方法(参见图 4 的例子)。然后，将分割后的单词分别输入文本识别模型。对于更复杂的文档，可以使用基于深度学习的<a class="ae kz" href="https://github.com/githubharald/WordDetectorNN" rel="noopener ugc nofollow" target="_blank">分词方法。</a></p><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nf"><img src="../Images/eb1757b98ad81b8bef6833dd0407e07d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*97zlEdb3GUmhqer63V5ATg.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Fig. 4: Word-segmentation on page-level.</figcaption></figure><h1 id="7767" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">2.2 扩展模型以适合完整的文本行</h1><p id="28d1" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">如果在行级别上工作，您可以轻松地扩展模型，以便输入更大的图像和输出更长的字符串。</p><p id="768e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">表 1 显示了我用于文本行识别的架构。它允许更大的输入图像(800×64 ),并且能够输出更大的字符串(长度可达 100)。此外，它包含更多的 CNN 层(7)，并在两层中使用批量标准化。</p><figure class="mt mu mv mw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ng"><img src="../Images/b1f18cee36461bc709d1c65bae86e1f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5RVNW2ryttJKDzRm3tu-rw.png"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Table 1: Architecture for reading on line-level. Use option 1 (LSTM) for the recurrent network. Abbreviations: bidirectional (bidir), batch normalization (BN), convolutional layer (Conv).</figcaption></figure><h1 id="97c6" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">3 如何计算识别文本的置信度得分？</h1><p id="0c2d" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">获得被识别文本的概率的最简单的方法是使用 CTC 损失函数。损失函数将字符概率矩阵和文本作为输入，并输出损失值 L。损失值 L 是看到给定文本的负对数可能性，即 L=-log(P)。如果我们将字符概率矩阵和识别的文本提供给损失函数，然后取消对数和减号，我们得到识别文本的概率 P:P = exp(-L)。</p><p id="974a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">以下代码显示了如何为一个玩具示例计算识别文本的概率。</p><figure class="mt mu mv mw gt ju"><div class="bz fp l di"><div class="nd ne l"/></div></figure><h1 id="cdd2" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">结论</h1><p id="e1d1" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">这篇文章展示了如何处理不同的数据集以及行级甚至页面级的读取。此外，还讨论了计算置信度得分的简单方法。</p><h1 id="1053" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">参考</h1><ul class=""><li id="bc62" class="la lb it kd b ke mm ki mn km nh kq ni ku nj ky mr lg lh li bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/2326a3487cd5">原文</a></li><li id="db37" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky mr lg lh li bi translated"><a class="ae kz" href="https://github.com/githubharald/SimpleHTR/tree/97c2512f593760b14669b37a159ead2f1e54961b" rel="noopener ugc nofollow" target="_blank">本文所基于的文本识别模型代码</a></li><li id="9e9a" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky mr lg lh li bi translated"><a class="ae kz" href="https://github.com/githubharald/SimpleHTR" rel="noopener ugc nofollow" target="_blank">最新版本的文本识别模型</a></li><li id="4903" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky mr lg lh li bi translated"><a class="ae kz" href="https://github.com/githubharald/WordDetector" rel="noopener ugc nofollow" target="_blank">经典分词算法代码</a></li><li id="9364" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky mr lg lh li bi translated"><a class="ae kz" href="https://github.com/githubharald/WordDetectorNN" rel="noopener ugc nofollow" target="_blank">基于深度学习的分词模型代码</a></li><li id="49db" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky mr lg lh li bi translated"><a class="ae kz" href="https://githubharald.github.io/word_detector.html" rel="noopener ugc nofollow" target="_blank">基于深度学习的分词模型描述</a></li></ul><p id="3910" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最后，概述一下我的<a class="ae kz" href="https://harald-scheidl.medium.com/c4683d776120" rel="noopener">其他媒体文章</a>。</p></div></div>    
</body>
</html>