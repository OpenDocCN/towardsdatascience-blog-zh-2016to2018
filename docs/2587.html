<html>
<head>
<title>Only Numpy: Implementing Simple ResNet ( Deep Networks with Stochastic Depth) for MNIST Classification with Interactive Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Only Numpy:使用交互式代码为 MNIST 分类实现简单的 ResNet(具有随机深度的深度网络)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/only-numpy-implementing-simple-resnet-for-mnist-classification-with-interactive-code-d58c77064304?source=collection_archive---------8-----------------------#2018-02-09">https://towardsdatascience.com/only-numpy-implementing-simple-resnet-for-mnist-classification-with-interactive-code-d58c77064304?source=collection_archive---------8-----------------------#2018-02-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/e458cc03ea1a634e3ce90daa7455e341.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QdRO_kjsUxRnV7JxTOCxEw.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Image <a class="ae kc" href="https://pixabay.com/en/road-highway-asphalt-desert-travel-3114475/" rel="noopener ugc nofollow" target="_blank">from Pixel Bay</a></figcaption></figure><p id="ff4f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以我在读这篇文章“<a class="ae kc" href="http://deliprao.com/archives/134" rel="noopener ugc nofollow" target="_blank">随机深度网络将成为新的范式</a> l”，在那里我看到了论文“<a class="ae kc" href="https://arxiv.org/pdf/1603.09382.pdf" rel="noopener ugc nofollow" target="_blank">具有随机深度的深度网络</a>”。在阅读这篇论文时，我看到了下面的图表。</p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lb"><img src="../Images/3c50ff50dec7de1d2d3c3ea9f87b87ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0iZ050bBnVkF7eEJIYeuOA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">ResNet Image from <a class="ae kc" href="https://arxiv.org/abs/1603.09382" rel="noopener ugc nofollow" target="_blank">Original Paper</a></figcaption></figure><p id="e85c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我立刻受到启发，建立了自己的 Res Net。然而，由于批处理规范化对于反向传播来说实现起来有点复杂，所以在今天的实现中我就不把它们算进去了。但是我保证，我会很快实施的！</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="2af3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">网络架构(数学形式)</strong></p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ln"><img src="../Images/817e8ffd1d4e9fd55f18949249a24ac9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nSo_R6Fgtg7dEbIITv8F7A.png"/></div></div></figure><p id="b899" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如上所述，网络架构非常容易理解，我们有某种函数 f()来转换输入数据。我们还有一个额外的函数 id()，即 Identity 函数，它允许从上一层直接连接到当前层。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="df57" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">前馈操作/部分反向传播<br/>(数学方程)</strong></p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lo"><img src="../Images/f0bf0432ec75fba734dbca80fd8a8f57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xTKPzzOJPtqaQ3aYmIGbqA.jpeg"/></div></div></figure><p id="094f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">绿框→3 个剩余块的前馈操作<br/>红框→隐藏权重的部分反向传播。</p><p id="10af" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">蓝色下划线→相对于 W3H 的反向传播<br/>粉色下划线→相对于 W2H 的反向传播<br/>紫色下划线→相对于 W1H 的反向传播</p><p id="9aeb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我不会对每个权重执行反向传播，但是对 W3b、W3a、W2b、W2a、W1b 和 W1a 的反向传播也很容易。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="686d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">前馈操作(代码)</strong></p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lp"><img src="../Images/dc960e7e4c30ec9ed22c2dc3a7511b78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9DYAbY_yShhFvDKqMKpx_Q.png"/></div></div></figure><p id="2b1e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">红色方框→ Res 模块 1 <br/>绿色方框→ Res 模块 2 <br/>蓝色方框→ Res 模块 3</p><p id="7436" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对静止块前馈操作非常简单而有效。然而反向传播过程有点复杂。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="f89a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">反向传播(代码)</strong></p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/790ff241e38aa573b21984090c70115b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yvlhn2Pu_qCwtZTsHPMeog.png"/></div></div></figure><p id="d959" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Res Net 中反向传播有点复杂的主要原因是因为在残差块的末尾发生了加法。在执行反向传播时，我们需要确保我们将所有梯度相对于该权重相加。代码中带红色下划线的部分执行加法。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="236f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">培训和结果(相同的学习率)</strong></p><div class="lc ld le lf gt ab cb"><figure class="lr jr ls lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/1fe916404572cb6001283411c2dc6973.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*kO40bV211ZYSSNlLOWdRHQ.png"/></div></figure><figure class="lr jr lx lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/b13a0eaa163bcb66be362e79e6a72cad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*Y_utDOA39CzKxTYw3xEy_w.png"/></div></figure></div><p id="d270" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，首先我为隐藏权重和其他权重设置了完全相同的学习速率。无论我如何努力，我都无法在这种环境下得到好的结果。所以我决定简单地为不同“类型”的重量设定不同的学习率。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="89e5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">培训和结果(不同的学习率)</strong></p><div class="lc ld le lf gt ab cb"><figure class="lr jr ly lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/6e6e604f553d12058144d75240c8c047.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*LhDRl-VzqRRkb1E1fRUELw.png"/></div></figure><figure class="lr jr lz lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/28396ab9dda3d0d9a3fd5ed1e14ba2a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*VgkC5bWGanp6DVslts6Xpw.png"/></div></figure></div><p id="ec56" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于一个 10 类图像的简单分类任务来说，72 %的准确率并不令人印象深刻。我会回来，希望增加这个模型的准确性。但是看起来，为不同“类型”的权重设置不同的学习率会有更好的结果。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="327f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">交互代码</strong></p><figure class="lc ld le lf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ma"><img src="../Images/61f5afc4edc2d80d291019ebf84cd211.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pIMQruuGwEI4FzYpAx9zTg.png"/></div></div></figure><p id="0944" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="mb">我搬到了谷歌 Colab 寻找交互代码！所以你需要一个谷歌帐户来查看代码，你也不能在谷歌实验室运行只读脚本，所以在你的操场上做一个副本。最后，我永远不会请求允许访问你在 Google Drive 上的文件，仅供参考。编码快乐！</em></p><p id="3333" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要访问<a class="ae kc" href="https://colab.research.google.com/drive/190cpdEXrcWIDe-0qmh2tkDnQ8RfyEV72" rel="noopener ugc nofollow" target="_blank">的互动代码，请点击此链接。</a></p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="6048" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">最后的话</strong></p><p id="d271" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在论文“具有随机深度的深度网络”中提出的主要网络不是简单的 Res 网，而是它们引入了具有随机深度的网络。我将很快尝试实现批量标准化网络。</p><p id="234b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 找我。</p><p id="ccc9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">同时，在我的 twitter <a class="ae kc" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，并访问<a class="ae kc" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或我的<a class="ae kc" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。如果你感兴趣的话，我还做了解耦神经网络的比较。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="c761" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">参考</strong></p><ol class=""><li id="1c79" class="mc md iq kf b kg kh kk kl ko me ks mf kw mg la mh mi mj mk bi translated">黄，孙，杨，刘，陈，丁，温伯格(2016 年 10 月)。具有随机深度的深度网络。在<em class="mb">欧洲计算机视觉会议</em>(第 646–661 页)。斯普林格，查姆。</li><li id="2624" class="mc md iq kf b kg ml kk mm ko mn ks mo kw mp la mh mi mj mk bi translated">D.(2016 年 06 月 05 日)。随机深度网络将成为新常态。检索于 2018 年 2 月 8 日，来自<a class="ae kc" href="http://deliprao.com/archives/134" rel="noopener ugc nofollow" target="_blank">http://deliprao.com/archives/134</a></li></ol></div></div>    
</body>
</html>