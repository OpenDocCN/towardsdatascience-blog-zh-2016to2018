<html>
<head>
<title>Machine Learning for Text Classification Using SpaCy in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中基于空间的文本分类机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-for-text-classification-using-spacy-in-python-b276b4051a49?source=collection_archive---------1-----------------------#2018-04-14">https://towardsdatascience.com/machine-learning-for-text-classification-using-spacy-in-python-b276b4051a49?source=collection_archive---------1-----------------------#2018-04-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/13e9530f2e91d77be912a473eab49a0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_0QqjxddraoElxx-oxEH-A.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo Credit: Pixabay</figcaption></figure><p id="b89e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><a class="ae la" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ir"> spaCy </strong> </a>是Python中流行且易于使用的自然语言处理库。它提供当前最先进的精度和速度水平，并有一个活跃的开源社区。然而，由于SpaCy是一个相对较新的NLP库，它不像<a class="ae la" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> NLTK </a>那样被广泛采用。还没有足够的教程可用。</p><p id="34af" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在这篇文章中，我们将演示如何在没有任何深度学习经验的情况下使用<strong class="ke ir"> spaCy </strong>实现文本分类。</p><h1 id="c4c6" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">数据</h1><p id="fadf" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">对于一个年轻的研究人员来说，寻找和选择一个合适的学术会议来提交他(或她)的学术论文常常是一件既费时又令人沮丧的事情。我们定义“合适的会议”,意思是会议与研究人员的工作一致，并有良好的学术排名。</p><p id="8fe0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">使用会议进程数据集，我们将按照会议对研究论文进行分类。让我们开始吧。数据集可以在<a class="ae la" href="https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/research_paper.csv" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h1 id="c278" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">探索</h1><p id="59f8" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">快速浏览一下:</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="35c8" class="mn lc iq mj b gy mo mp l mq mr">import pandas as pd<br/>import numpy as np<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>import base64<br/>import string<br/>import re<br/>from collections import Counter<br/>from nltk.corpus import stopwords<br/>stopwords = stopwords.words('english')</span><span id="6671" class="mn lc iq mj b gy ms mp l mq mr">df = pd.read_csv('research_paper.csv')<br/>df.head()</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/d1adcbd2d01562c01540f1f4546ae122.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*fBPhDO1-oHsmJvlh6UAyFA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 1</figcaption></figure><p id="6d04" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">没有缺失值。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="646d" class="mn lc iq mj b gy mo mp l mq mr">df.isnull().sum()</span></pre><p id="a44e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">T11】标题0 <br/>会议0<br/>dtype:int 64T15】</strong></p><p id="135d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">将数据拆分为定型集和测试集:</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="64ba" class="mn lc iq mj b gy mo mp l mq mr">from sklearn.model_selection import train_test_split<br/>train, test = train_test_split(df, test_size=0.33, random_state=42)</span><span id="d1e8" class="mn lc iq mj b gy ms mp l mq mr">print('Research title sample:', train['Title'].iloc[0])<br/>print('Conference of this paper:', train['Conference'].iloc[0])<br/>print('Training Data Shape:', train.shape)<br/>print('Testing Data Shape:', test.shape)</span></pre><p id="4092" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> <em class="mu">研究题目样本:配合Smartness:在Ad-Hoc网络中使用异构智能天线。<br/>本文发布会:INFOCOM <br/>训练数据形态:(1679，2) <br/>测试数据形态:(828，2) </em> </strong></p><p id="dcdd" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">该数据集由2507篇简短的研究论文标题组成，已被分为5类(按会议)。下图总结了不同会议的研究论文分布情况。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="1c6e" class="mn lc iq mj b gy mo mp l mq mr">fig = plt.figure(figsize=(8,4))<br/>sns.barplot(x = train['Conference'].unique(), y=train['Conference'].value_counts())<br/>plt.show()</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/5cc37d2a1d456e01da3f702a375adeca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*Kv9STRxeOWckLB1msu0B0g.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 2</figcaption></figure><p id="acbd" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">以下是在SpaCy中进行文本预处理的一种方法。之后，我们试图找出提交给第一类和第二类(会议)的论文中使用的热门词汇——INFOCOM &amp; ISCAS</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="c77b" class="mn lc iq mj b gy mo mp l mq mr">import spacy</span><span id="b74a" class="mn lc iq mj b gy ms mp l mq mr">nlp = spacy.load('en_core_web_sm')<br/>punctuations = string.punctuation</span><span id="4200" class="mn lc iq mj b gy ms mp l mq mr">def cleanup_text(docs, logging=False):<br/>    texts = []<br/>    counter = 1<br/>    for doc in docs:<br/>        if counter % 1000 == 0 and logging:<br/>            print("Processed %d out of %d documents." % (counter, len(docs)))<br/>        counter += 1<br/>        doc = nlp(doc, disable=['parser', 'ner'])<br/>        tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']<br/>        tokens = [tok for tok in tokens if tok not in stopwords and tok not in punctuations]<br/>        tokens = ' '.join(tokens)<br/>        texts.append(tokens)<br/>    return pd.Series(texts)</span><span id="1508" class="mn lc iq mj b gy ms mp l mq mr">INFO_text = [text for text in train[train['Conference'] == 'INFOCOM']['Title']]</span><span id="4d53" class="mn lc iq mj b gy ms mp l mq mr">IS_text = [text for text in train[train['Conference'] == 'ISCAS']['Title']]</span><span id="3615" class="mn lc iq mj b gy ms mp l mq mr">INFO_clean = cleanup_text(INFO_text)<br/>INFO_clean = ' '.join(INFO_clean).split()</span><span id="5b85" class="mn lc iq mj b gy ms mp l mq mr">IS_clean = cleanup_text(IS_text)<br/>IS_clean = ' '.join(IS_clean).split()</span><span id="3eef" class="mn lc iq mj b gy ms mp l mq mr">INFO_counts = Counter(INFO_clean)<br/>IS_counts = Counter(IS_clean)</span><span id="d840" class="mn lc iq mj b gy ms mp l mq mr">INFO_common_words = [word[0] for word in INFO_counts.most_common(20)]<br/>INFO_common_counts = [word[1] for word in INFO_counts.most_common(20)]</span><span id="2405" class="mn lc iq mj b gy ms mp l mq mr">fig = plt.figure(figsize=(18,6))<br/>sns.barplot(x=INFO_common_words, y=INFO_common_counts)<br/>plt.title('Most Common Words used in the research papers for conference INFOCOM')<br/>plt.show()</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mw"><img src="../Images/38c97abfbbda026390bbe97098f2d331.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zY72KrB-HT1Y_RPJA4boTw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 3</figcaption></figure><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="881a" class="mn lc iq mj b gy mo mp l mq mr">IS_common_words = [word[0] for word in IS_counts.most_common(20)]<br/>IS_common_counts = [word[1] for word in IS_counts.most_common(20)]</span><span id="d6d8" class="mn lc iq mj b gy ms mp l mq mr">fig = plt.figure(figsize=(18,6))<br/>sns.barplot(x=IS_common_words, y=IS_common_counts)<br/>plt.title('Most Common Words used in the research papers for conference ISCAS')<br/>plt.show()</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/972a11fee17c5ad61872b86d7f7e24b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7XKrT5hyTxPVFRIlIuslpg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 4</figcaption></figure><p id="bb29" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">INFOCOM的热门词汇是“网络”和“网络”。显而易见，INFOCOM是网络领域和密切相关领域的会议。</p><p id="0af4" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">ISCAS排名靠前的词是“基础”和“设计”。它表明ISCAS是一个关于数据库、系统设计和相关主题的会议。</p><h1 id="1519" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">带空间的机器学习</h1><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="615b" class="mn lc iq mj b gy mo mp l mq mr">from sklearn.feature_extraction.text import CountVectorizer<br/>from sklearn.base import TransformerMixin<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.svm import LinearSVC<br/>from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS<br/>from sklearn.metrics import accuracy_score<br/>from nltk.corpus import stopwords<br/>import string<br/>import re<br/>import spacy<br/>spacy.load('en')<br/>from spacy.lang.en import English<br/>parser = English()</span></pre><p id="2ea8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">下面是使用空间清理文本的另一种方法:</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="a46b" class="mn lc iq mj b gy mo mp l mq mr">STOPLIST = set(stopwords.words('english') + list(ENGLISH_STOP_WORDS))<br/>SYMBOLS = " ".join(string.punctuation).split(" ") + ["-", "...", "”", "”"]</span><span id="56cb" class="mn lc iq mj b gy ms mp l mq mr">class CleanTextTransformer(TransformerMixin):</span><span id="9ef5" class="mn lc iq mj b gy ms mp l mq mr">   def transform(self, X, **transform_params):<br/>        return [cleanText(text) for text in X]</span><span id="9931" class="mn lc iq mj b gy ms mp l mq mr">   def fit(self, X, y=None, **fit_params):<br/>        return self</span><span id="73bc" class="mn lc iq mj b gy ms mp l mq mr">def get_params(self, deep=True):<br/>        return {}<br/>    <br/>def cleanText(text):<br/>    text = text.strip().replace("\n", " ").replace("\r", " ")<br/>    text = text.lower()<br/>    return text</span><span id="f4bd" class="mn lc iq mj b gy ms mp l mq mr">def tokenizeText(sample):<br/>    tokens = parser(sample)<br/>    lemmas = []<br/>    for tok in tokens:<br/>        lemmas.append(tok.lemma_.lower().strip() if tok.lemma_ != "-PRON-" else tok.lower_)<br/>    tokens = lemmas<br/>    tokens = [tok for tok in tokens if tok not in STOPLIST]<br/>    tokens = [tok for tok in tokens if tok not in SYMBOLS]<br/>    return tokens</span></pre><p id="46da" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">定义一个函数来打印出最重要的特征，即具有最高系数的特征:</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="c026" class="mn lc iq mj b gy mo mp l mq mr">def printNMostInformative(vectorizer, clf, N):<br/>    feature_names = vectorizer.get_feature_names()<br/>    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))<br/>    topClass1 = coefs_with_fns[:N]<br/>    topClass2 = coefs_with_fns[:-(N + 1):-1]<br/>    print("Class 1 best: ")<br/>    for feat in topClass1:<br/>        print(feat)<br/>    print("Class 2 best: ")<br/>    for feat in topClass2:<br/>        print(feat)</span><span id="e81a" class="mn lc iq mj b gy ms mp l mq mr">vectorizer = CountVectorizer(tokenizer=tokenizeText, ngram_range=(1,1))<br/>clf = LinearSVC()<br/><br/>pipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer), ('clf', clf)])</span><span id="07bc" class="mn lc iq mj b gy ms mp l mq mr"># data<br/>train1 = train['Title'].tolist()<br/>labelsTrain1 = train['Conference'].tolist()</span><span id="7bed" class="mn lc iq mj b gy ms mp l mq mr">test1 = test['Title'].tolist()<br/>labelsTest1 = test['Conference'].tolist()<br/># train<br/>pipe.fit(train1, labelsTrain1)</span><span id="c21e" class="mn lc iq mj b gy ms mp l mq mr"># test<br/>preds = pipe.predict(test1)<br/>print("accuracy:", accuracy_score(labelsTest1, preds))<br/>print("Top 10 features used to predict: ")<br/><br/>printNMostInformative(vectorizer, clf, 10)<br/>pipe = Pipeline([('cleanText', CleanTextTransformer()), ('vectorizer', vectorizer)])<br/>transform = pipe.fit_transform(train1, labelsTrain1)</span><span id="79df" class="mn lc iq mj b gy ms mp l mq mr">vocab = vectorizer.get_feature_names()<br/>for i in range(len(train1)):<br/>    s = ""<br/>    indexIntoVocab = transform.indices[transform.indptr[i]:transform.indptr[i+1]]<br/>    numOccurences = transform.data[transform.indptr[i]:transform.indptr[i+1]]<br/>    for idx, num in zip(indexIntoVocab, numOccurences):<br/>        s += str((vocab[idx], num))</span></pre><p id="3536" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> <em class="mu">精度:0.7463768115942029 <br/>用于预测的前10个特征:<br/>第1类最佳:<br/> (-0.9286024231429632，'数据库')<br/> (-0.8479561292796286，'芯片')<br/> (-0.7675978546440636，' wimax') <br/>(。</em></strong></p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="c19e" class="mn lc iq mj b gy mo mp l mq mr">from sklearn import metrics<br/>print(metrics.classification_report(labelsTest1, preds, <br/>                                    target_names=df['Conference'].unique()))</span><span id="69cc" class="mn lc iq mj b gy ms mp l mq mr">precision    recall  f1-score   support<br/><br/>       VLDB       0.75      0.77      0.76       159<br/>      ISCAS       0.90      0.84      0.87       299<br/>   SIGGRAPH       0.67      0.66      0.66       106<br/>    INFOCOM       0.62      0.69      0.65       139<br/>        WWW       0.62      0.62      0.62       125<br/><br/>avg / total       0.75      0.75      0.75       828</span></pre><p id="8ec7" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">给你。我们现在已经在SpaCy的帮助下完成了文本分类的机器学习。</p><p id="2b66" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">源代码可以在<a class="ae la" href="https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/machine%20learning%20spaCy.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。过一个学习周末！</p><p id="283b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">参考:<a class="ae la" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank">卡格尔</a></p></div></div>    
</body>
</html>