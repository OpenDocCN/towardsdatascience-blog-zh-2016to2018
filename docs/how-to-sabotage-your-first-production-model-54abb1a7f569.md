# 如何破坏你的第一个生产模型？

> 原文：<https://towardsdatascience.com/how-to-sabotage-your-first-production-model-54abb1a7f569?source=collection_archive---------1----------------------->

我听过很多关于生产中数据科学的恐怖故事。细节很重要，有两个潜在的危险直到为时已晚才显现出来。

![](img/b055f505cccb25da4697017d3d174eb6.png)

Source: [unsplash.com](https://unsplash.com/photos/Q2I85b-7vLY)

Jason Bell 提供了数据科学模型如何在“[数据科学最忽略的东西](https://medium.com/towards-data-science/what-data-science-mostly-ignores-58eb0e75d03d)”中失败的很好的例子。

在这些例子中有两个主要的失败。一是问错了问题。另一个是使用了错误的评估程序。可惜这些技巧很难掌握，有很多微妙的层次。

# 问错误的问题

Jason Bell 指出，我们需要思考我们认为什么是胜利。"谷歌的广告活动会带来销售线索吗？"vs .“谷歌广告活动是否带来了销售线索，从而增加了销售额？”

> 谷歌“亚马逊<some book="" title="">”，第一个广告通常是亚马逊。算法做的好吗？我不这么认为。在这种情况下，人们不会受到广告的影响，但他们仍然会点击它。这是最糟糕的！</some>

有许多创造性的方法来问错误的问题，但是我将直接跳到一个解决方案。

当我们建立一个模型时，我们应该考虑如何使用我们的结果。一个成功的模型将提供信息或做出决定。这一决定可以说是一种干预或政策选择。从这个角度来说，借用[节目评测的一些思路是有意义的。](https://en.wikipedia.org/wiki/Program_evaluation)

项目评估着眼于项目和政策的效率和效果。该规程要求我们提出以下问题:

*   我们的模型所提供的干预是否有必要？
*   我们是否对干预将如何影响下游结果以及上游情景如何影响干预有了可行的理解？
*   干预的实施是否会反映我们心中的设计？
*   我们如何衡量干预是否成功？我们看到的是正确的结果吗？
*   干预的好处是否证明实施所需的成本是合理的？

一般来说，一个完整的项目评估是一个漫长的考验。然而，简单地询问这些问题并与最终用户交流将会避免许多概念性错误。

# 使用错误的评估程序

模型评估背后的直觉非常简单。我们希望根据其在生产条件下的表现来选择最佳型号。如果我们不能在生产中测试，我们最多只能模拟生产条件。我们将我们的数据分成**训练数据**和**测试数据**，以基于过去的数据来模拟未来的条件(参见[交叉验证](https://en.wikipedia.org/wiki/Cross-validation_(statistics)))。

做好这一点非常困难。选择合适的[评估指标](http://scikit-learn.org/stable/modules/model_evaluation.html)和无偏见的数据样本需要仔细关注。

## 错误的评估指标

选择错误的[评估指标](http://scikit-learn.org/stable/modules/model_evaluation.html)是一个常见的问题，与问错误的问题有关。这不是一个困难的选择，我们只需要仔细考虑结果变量和用例。当我们解决了错误的问题时，花哨的模型和 rockstar 编程并不重要。

我不禁想起了史蒂夫·斯基纳的《算法设计》手册中的“如何设计算法”一章。

> 我真的理解这个问题吗？
> 
> (a)投入具体包括什么？
> 
> (b)确切的预期结果或产出是什么？
> 
> (c)我能否构建一个足够小的输入示例，以便手动解决？当我试图解决它时会发生什么？
> 
> (d)我总能找到最佳答案对我的应用程序有多重要？我能满足于接近最优的答案吗？
> 
> (e)我的典型问题有多大？
> 
> (f)速度对我的应用程序有多重要？
> 
> (g)我可以在实施上投入多少时间和精力？

## 取样偏差

机器学习模型只有在它们被训练的环境与它们被使用的环境相同时才起作用。上下文只是意味着我们的训练数据代表了我们的生产数据。如果我们的训练数据不符合我们的用例，我们就有一个采样偏差问题。换句话说，我们收集了错误的训练数据。

采样偏差是无声的。它在数据收集、数据清理、特征工程和决策制定过程中悄悄潜入。

***数据采集***

在数据收集过程中，我们必须处理有限的数据，可能会选择与生产条件不匹配的样品。例如，我们可能会无意中使用现有的客户数据来预测新客户的行为。

不幸的是，存在一种选择偏差效应，某些类型的人成为现有客户，并意味着新客户的行为会有所不同。我们从现有客户那里学到的经验，对新客户来说只有很小的机会。

***数据清理***

在数据清理期间删除有问题的行来提高模型的性能是很诱人的。想象一下，将客户评论分为正面和负面情绪，有些评论太短，无法做任何有用的事情。

如果我们从测试数据和训练数据中删除所有非常短的评论，那么由于模糊性的减少，我们的模型很有可能会做得更好。然而，在生产系统中，我们将不得不处理简短的评论，我们的模型针对错误的上下文进行了优化。

让简短评论成为特例本身并没有什么错，但是我们的评估程序应该反映这种变化。开箱即用的评估程序会夸大我们模型的准确性。

***特色工程***

在特征工程和 ETL 过程中，我们经常想要生成数据的集合，比如均值、中位数等。需要为训练和测试数据分别生成这些聚合。

如果我们或其他人对整个数据集进行平均，那么我们会在测试过程中暴露训练数据中有关“未来”的信息。其结果是，我们会夸大我们的模型的有效性。即使训练和测试数据中的平均值几乎相同，这也是一个问题。

***决策***

决策给模型构建增加了一个奇怪的转折。当基于我们的模型做出决策时，它可能会影响我们建模的结果或我们使用的功能。在生产中评估我们的模型变得困难，并且在我们使用的数据中引入了抽样偏差。

当我们重用一个模型时，这就成了一个问题。我们在特征变量和结果变量之间引入反馈效应。

想象一下，一所大学决定为可能不及格的学生实施预警系统。根据学生过去的课程，我们会在注册时发出警告，以阻止学生注册，如果他们可能会失败。让我们假设识别学生的模型做得非常好。

第一学期，这种模式发挥了作用，提高了课程的通过率。更令人鼓舞的是，那些对自己有把握的学生忽略了警告，并经常成功地上了课。那些对自己没有信心的学生没有选修这门课，从而避免了不及格。

当我们再次尝试应用我们的模型时会发生什么？

如果我们使用旧模式，我们的信息可能会过时。它也从未见过无视警告系统的学生。他们是否与之前的学生群体有足够的差异，从而导致不准确？

如果我们训练一个新的模型呢？因为新的通过率更高，所以肯定会有不同的结果。背景也发生了变化，因为关注预警系统的学生不再反映在数据中。

# 不要放松警惕

如果您有幸拥有一个将用于生产的模型，请花一点时间考虑这些问题。它们不是复杂的想法，但却经常被忽视。大多数问题会在您处理数据时出现，但只有在有人尝试使用您的模型后才会出现。

*如果您觉得这很有帮助，请推荐并分享，点击💚这样其他人就能看到了。*