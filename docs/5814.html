<html>
<head>
<title>Kaggle Competition — Image Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Kaggle 竞赛—图像分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/kaggle-competition-image-classification-676dee6c0f23?source=collection_archive---------15-----------------------#2018-11-10">https://towardsdatascience.com/kaggle-competition-image-classification-676dee6c0f23?source=collection_archive---------15-----------------------#2018-11-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4456" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何使用迁移学习建立一个可以预测输入图像分类的 CNN 模型</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/576e611c2f8b2dd3d074684fadf03210.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KaY2a_tFPOl15OkM"/></div></div></figure><p id="6e23" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">第一个误区</strong> — <a class="ae ln" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>是一个举办机器学习竞赛的网站。我相信这种误解让很多数据科学初学者——包括我——认为 Kaggle 只适合数据专业人士或有多年经验的专家。事实上，Kaggle 提供的不仅仅是竞赛！</p><p id="a4d6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Kaggle 上有如此多的<a class="ae ln" href="https://www.kaggle.com/datasets" rel="noopener ugc nofollow" target="_blank">开放数据集，我们可以简单地从玩我们选择的数据集开始，并在过程中学习。如果你是一个对数据科学毫无经验的初学者，并且可能想在加入之前参加更多的在线课程，请三思！Kaggle 甚至为你提供一些基础而实用的</a><a class="ae ln" href="https://www.kaggle.com/learn/overview" rel="noopener ugc nofollow" target="_blank">编程和数据科学课程</a>。此外，您可以随时在<a class="ae ln" href="https://www.kaggle.com/discussion" rel="noopener ugc nofollow" target="_blank"> Kaggle 讨论</a>中提出您的问题，以便向活跃的数据科学社区寻求建议或澄清任何数据科学问题。</p><p id="8351" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">脸书创始人兼首席执行官马克·扎克伯格在哈佛毕业典礼上的演讲中分享了一段真正启发了我的话</p><blockquote class="lo"><p id="3291" class="lp lq iq bd lr ls lt lu lv lw lx lm dk translated">你只需要开始。</p><p id="1dbf" class="lp lq iq bd lr ls lt lu lv lw lx lm dk translated">—马克·扎克伯格</p></blockquote><p id="cec3" class="pw-post-body-paragraph kr ks iq kt b ku ly jr kw kx lz ju kz la ma lc ld le mb lg lh li mc lk ll lm ij bi translated">开始并迈出第一步一直是做任何事情之前最难的部分，更不用说取得进展或提高了。</p><p id="b685" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">有很多在线资源可以帮助我们开始使用 Kaggle，我将在这里列出一些我认为非常有用的资源:</p><ol class=""><li id="3a3e" class="md me iq kt b ku kv kx ky la mf le mg li mh lm mi mj mk ml bi translated"><a class="ae ln" rel="noopener" target="_blank" href="/use-kaggle-to-start-and-guide-your-ml-data-science-journey-f09154baba35">使用 Kaggle 开始(并指导)您的 ML/数据科学之旅——为什么以及如何进行</a></li></ol><p id="c0c8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">2.<a class="ae ln" rel="noopener" target="_blank" href="/machine-learning-zero-to-hero-everything-you-need-in-order-to-compete-on-kaggle-for-the-first-time-18644e701cf1">机器学习从零到英雄</a></p><p id="503a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">3.<a class="ae ln" rel="noopener" target="_blank" href="/data-science-from-zero-to-kaggle-kernels-master-f9115eadbb3">数据科学 A-Z 从零到 Kaggle 内核大师</a></p><p id="9b9b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在接下来的部分，我希望与你分享一个初学者在他的第一次 Kaggle 比赛中的旅程(和他的团队成员一起)以及一些错误和教训。你可以<a class="ae ln" href="https://www.kaggle.com/chloekexin/da-machine" rel="noopener ugc nofollow" target="_blank">在这里</a>查看代码。这些部分分布如下:</p><ol class=""><li id="0914" class="md me iq kt b ku kv kx ky la mf le mg li mh lm mi mj mk ml bi translated">竞争的背景和数据</li><li id="bdb1" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated">方法</li><li id="5551" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated">结果</li><li id="449b" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated">最后的想法</li></ol><p id="5ebd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们开始吧，我希望你会喜欢它！</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="f1d8" class="my mz iq bd na nb nc nd ne nf ng nh ni jw nj jx nk jz nl ka nm kc nn kd no np bi translated">竞争背景和数据</h1><p id="223d" class="pw-post-body-paragraph kr ks iq kt b ku nq jr kw kx nr ju kz la ns lc ld le nt lg lh li nu lk ll lm ij bi translated">在我的第一篇关于 Medium 的帖子——<a class="ae ln" rel="noopener" target="_blank" href="/my-journey-from-physics-into-data-science-5d578d0f9aa6">我从物理到数据科学的旅程</a>中，我提到了我和我的团队成员——<a class="ae ln" href="https://www.linkedin.com/in/lowweihong/" rel="noopener ugc nofollow" target="_blank"><strong class="kt ir">罗伟鸿</strong> </a> <strong class="kt ir">、</strong> <a class="ae ln" href="https://www.linkedin.com/in/kexinchong/" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir">崇科信</strong> </a> <strong class="kt ir">、</strong>和<a class="ae ln" href="https://www.linkedin.com/in/ling-wei-onn-452957147/" rel="noopener ugc nofollow" target="_blank"><strong class="kt ir">Onn<strong class="kt ir">一起参加了由<a class="ae ln" href="https://shopee.sg/" rel="noopener ugc nofollow" target="_blank"> Shopee </a>和(IET)工程技术学院举办的<a class="ae ln" href="https://www.kaggle.com/c/shopee-iet-machine-learning-competition" rel="noopener ugc nofollow" target="_blank">首届 Kaggle 机器学习竞赛</a>我们在旅途中玩得很开心，我确实从他们身上学到了很多！！</strong></strong></a></p><p id="0076" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Shopee 给了我们 18 个类别的商品图像，我们的目标是建立一个模型，可以预测输入图像到不同类别的分类。</p><p id="df42" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">太好了。现在我们已经了解了上下文。让我们继续我们的图像分类预测方法——这是<strong class="kt ir"> <em class="nv">有趣(我是说最难)</em> </strong>的部分！</p><h2 id="cf41" class="nw mz iq bd na nx ny dn ne nz oa dp ni la ob oc nk le od oe nm li of og no oh bi translated">用于分类的一些图像</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/a40f19c0a3e6c7e129e605a75c188774.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*jJ-ORcGs15p8OewqsUgnyA.png"/></div><figcaption class="oj ok gj gh gi ol om bd b be z dk">Different Images for Classification</figcaption></figure><p id="339a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">正如您从图像中看到的，一些图像中存在一些噪声(不同的背景、描述或裁剪的文字)，这使得图像预处理和模型建立更加困难。</p><p id="741e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在下一节中，我将讨论我们解决这个问题的方法，直到构建我们定制的 CNN 模型。</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="33f3" class="my mz iq bd na nb nc nd ne nf ng nh ni jw nj jx nk jz nl ka nm kc nn kd no np bi translated">方法</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/5465937777c0bf491cb5bd12bfcf28da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dqINTtz48wp8wIL_"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk"><a class="ae ln" href="https://unsplash.com/photos/oVpn10bqxkc" rel="noopener ugc nofollow" target="_blank">(Source)</a></figcaption></figure><p id="0a36" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">每当人们谈论图像分类时，<strong class="kt ir">卷积神经网络(CNN) </strong>就会自然而然地出现在他们的脑海中——毫不奇怪——我们也不例外。</p><p id="e173" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我第一次接触 CNN 时，知识和经验都很少，<strong class="kt ir"> Google </strong>是我最好的老师，我不得不强烈推荐这本由<a class="ae ln" href="https://www.linkedin.com/in/aditdeshpande/" rel="noopener ugc nofollow" target="_blank">阿迪特·德什潘德</a>撰写的简明而全面的 CNN 简介。高水平的解释打破了 CNN 一度令人生畏的结构，变成了我能理解的简单术语。</p><h2 id="2e38" class="nw mz iq bd na nx ny dn ne nz oa dp ni la ob oc nk le od oe nm li of og no oh bi translated">图像预处理</h2><p id="95b2" class="pw-post-body-paragraph kr ks iq kt b ku nq jr kw kx nr ju kz la ns lc ld le nt lg lh li nu lk ll lm ij bi translated">图像预处理也可以称为<a class="ae ln" href="https://keras.io/preprocessing/image/" rel="noopener ugc nofollow" target="_blank">数据增强</a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/1328f3a938d30348e2fc26f41448e4ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yyTp1D3nwvn6scZ5msZJXA.png"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk">Generate batches of tensor image data with real-time data augmentation that will be looped over in batches</figcaption></figure><p id="7989" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在将图像输入模型之前，数据扩充步骤是必要的，特别是对于给定的<a class="ae ln" href="https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced" rel="noopener"> <em class="nv"> </em>不平衡且有限的数据集</a>。通过对图像进行不同的变换、缩放和剪切范围来人为扩展我们的数据集，我们增加了训练数据的数量。</p><h2 id="a717" class="nw mz iq bd na nx ny dn ne nz oa dp ni la ob oc nk le od oe nm li of og no oh bi translated">—第一个错误—</h2><p id="f96e" class="pw-post-body-paragraph kr ks iq kt b ku nq jr kw kx nr ju kz la ns lc ld le nt lg lh li nu lk ll lm ij bi translated">我相信每一种方法都来自于背后的多次尝试和错误。因此，在展示我们的最终方法之前，让我们先谈谈我们的第一个错误。</p><p id="9971" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">我们开始尝试从零开始构建我们的 CNN 模型</strong>(没错，就是这样！)来查看 CNN 模型基于训练和测试图像的表现。我们不知道大多数人很少从零开始训练 CNN 模型，原因如下:</p><ol class=""><li id="2667" class="md me iq kt b ku kv kx ky la mf le mg li mh lm mi mj mk ml bi translated">数据集不足(训练图像)</li><li id="9a4c" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated">CNN 模型很复杂，通常需要几周甚至几个月来训练，尽管我们有集群机器和高性能 GPU。</li><li id="baa0" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated">成本和时间不能保证和证明模型的性能</li></ol><p id="5ee0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">幸好<a class="ae ln" href="https://machinelearningmastery.com/transfer-learning-for-deep-learning/" rel="noopener ugc nofollow" target="_blank">转学</a>来救我们了。</p><h2 id="3bd5" class="nw mz iq bd na nx ny dn ne nz oa dp ni la ob oc nk le od oe nm li of og no oh bi translated">迁移学习</h2><p id="85f4" class="pw-post-body-paragraph kr ks iq kt b ku nq jr kw kx nr ju kz la ns lc ld le nt lg lh li nu lk ll lm ij bi translated">那么……迁移学习到底是什么？</p><p id="d984" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><a class="ae ln" href="https://machinelearningmastery.com/transfer-learning-for-deep-learning/" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir">迁移学习</strong> </a> <strong class="kt ir"> </strong>是一种机器学习方法，其中为一个任务开发的模型被重新用作第二个任务的模型的起点。在我们的例子中，这是一种<a class="ae ln" href="https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/" rel="noopener ugc nofollow" target="_blank">方法</a>,采用预先训练好的模型(之前已经在大型数据集上训练过的网络的权重和参数),并用我们自己的数据集对模型进行“微调”。</p><p id="3a85" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">太好了。由于 Keras 中有如此多的预训练模型可用，我们决定分别尝试不同的预训练模型<em class="nv"/><strong class="kt ir">(vgg 16、VGG19、ResNet50、InceptionV3、DenseNet 等。)</strong>并选出最佳型号。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl oo"><img src="../Images/ddc43391d923f0e3307da2d18dfbcd80.png" data-original-src="https://miro.medium.com/v2/format:webp/1*L8NWufrce1Bt9aDIN7Tu4A.png"/></div><figcaption class="oj ok gj gh gi ol om bd b be z dk"><a class="ae ln" href="https://medium.com/@14prakash/transfer-learning-using-keras-d804b2e04ef8" rel="noopener">Inception V3 Google Research</a></figcaption></figure><p id="fa96" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最终我们选择了<a class="ae ln" href="https://keras.io/applications/#inceptionv3" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir"> InceptionV3 模型</strong> </a>，权重在<a class="ae ln" href="http://image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>上预训练，准确率最高。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/e2f57ca01e16db28ce965d6926432c99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*2gxPp43qtRPZiuDibQBYug.png"/></div></figure><p id="aa85" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为无休止的评论道歉，因为我们想确保每一行都是正确的。</p><p id="f298" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">乍一看，这些代码可能有点令人困惑。让我们通过下面解释的逻辑来进行分解，使事情变得更清楚:</p><ol class=""><li id="1eb1" class="md me iq kt b ku kv kx ky la mf le mg li mh lm mi mj mk ml bi translated">我们首先使用之前导入的预训练的 InceptionV3 模型创建了一个基础模型。为了以后的定制目的，在神经网络的顶部移除了完全连接的最后一层。</li><li id="57aa" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated">然后我们添加了一个<a class="ae ln" href="https://alexisbcook.github.io/2017/global-average-pooling-layers-for-object-localization/" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir">全局空间平均池层</strong> </a>，原因可以在这里找到<a class="ae ln" href="https://www.quora.com/What-is-global-average-pooling" rel="noopener ugc nofollow" target="_blank">。</a></li><li id="f615" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated">之后，我们创建了一个新的<strong class="kt ir">全连接输出层</strong>，接着是一个<strong class="kt ir">脱落层</strong>用于正则化目的。</li><li id="e12a" class="md me iq kt b ku mm kx mn la mo le mp li mq lm mi mj mk ml bi translated">最后，我们为 18 个类别(18 类图像)添加了一个<strong class="kt ir"> softmax 层</strong>，并且<strong class="kt ir">将基础模型与创建的新输出层</strong>相结合。</li></ol><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oq"><img src="../Images/a63fc6c042c2bd9f1b5c8aec11cbf9cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ebqbi6EHVDl1CpxxOYsYCA.png"/></div></div></figure><p id="31da" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在这个阶段，我们冻结了基础模型的所有层，只训练新的输出层。</p><p id="57f9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这就是迁移学习的美妙之处，因为我们不需要重新训练整个组合模型，因为基础模型已经被训练过了。</p><h2 id="6626" class="nw mz iq bd na nx ny dn ne nz oa dp ni la ob oc nk le od oe nm li of og no oh bi translated">微调组合模型</h2><p id="6042" class="pw-post-body-paragraph kr ks iq kt b ku nq jr kw kx nr ju kz la ns lc ld le nt lg lh li nu lk ll lm ij bi translated">一旦顶层训练好了，我们就微调内层的一部分。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi or"><img src="../Images/edbf3b118e563db7781d900e973a59c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*oFZkXES2G7QnHabt2GBXLg.png"/></div></figure><p id="3303" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">可选地，通过选择和训练顶部的 2 个先启块(组合模型中 249 层之后的所有剩余层)来实现微调过程。训练过程与以前相同，只是包括的层数不同。</p><p id="81d1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">是的，我们结束了！</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="c950" class="my mz iq bd na nb nc nd ne nf ng nh ni jw nj jx nk jz nl ka nm kc nn kd no np bi translated">结果</h1><p id="d605" class="pw-post-body-paragraph kr ks iq kt b ku nq jr kw kx nr ju kz la ns lc ld le nt lg lh li nu lk ll lm ij bi translated"><strong class="kt ir">最终准确率为 78.96%。</strong></p><p id="7783" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们尝试了不同的方法来微调超参数，但无济于事。</p><p id="c38b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">当所有的结果和方法在比赛结束后揭晓时，我们发现了我们的第二个错误…</p><h2 id="524b" class="nw mz iq bd na nx ny dn ne nz oa dp ni la ob oc nk le od oe nm li of og no oh bi translated">—第二个错误—</h2><p id="e0d6" class="pw-post-body-paragraph kr ks iq kt b ku nq jr kw kx nr ju kz la ns lc ld le nt lg lh li nu lk ll lm ij bi translated"><strong class="kt ir">我们没有使用叠加法的集合模型。</strong></p><p id="f32c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">所有顶级团队的共同点是他们都使用集合模型。</p><p id="2230" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">相反，我们分别训练不同的预训练模型，只选择最佳模型。这种方法间接使得我们的模型在只使用一个模型测试数据时不够健壮，并且容易过度拟合。</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><h1 id="ba87" class="my mz iq bd na nb nc nd ne nf ng nh ni jw nj jx nk jz nl ka nm kc nn kd no np bi translated">最后的想法</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/64392686b9be668b5a95fb0a404ef7cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Bp7qenFfgeXpm40D"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk"><a class="ae ln" href="https://unsplash.com/photos/JSF-PcnsFx8" rel="noopener ugc nofollow" target="_blank">(Source)</a></figcaption></figure><p id="d00a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">尽管比赛时间很短，但我从我的团队成员和其他团队那里学到了很多东西——从理解 CNN 模型，应用迁移学习，制定我们学习其他团队使用的其他方法的方法。</p><p id="e6b0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个过程并不容易。学习曲线很陡。学习之旅充满挑战，但同时也很有收获。我非常期待另一场比赛！😄</p></div><div class="ab cl mr ms hu mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ij ik il im in"><p id="e53b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">感谢您的阅读。</p><p id="46fd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一如既往，如果您有任何问题或意见，请随时在下面留下您的反馈，或者您可以随时通过<a class="ae ln" href="https://www.linkedin.com/in/admond1994/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系我。在那之前，下一篇文章再见！😄</p><h2 id="f6db" class="nw mz iq bd na nx ny dn ne nz oa dp ni la ob oc nk le od oe nm li of og no oh bi translated">关于作者</h2><p id="5193" class="pw-post-body-paragraph kr ks iq kt b ku nq jr kw kx nr ju kz la ns lc ld le nt lg lh li nu lk ll lm ij bi translated"><a class="ae ln" href="https://www.linkedin.com/in/admond1994/" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir">阿德蒙德·李</strong> </a>目前是东南亚排名第一的商业银行 API 平台<a class="ae ln" href="https://www.trystaq.com" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir"> Staq </strong> </a> <strong class="kt ir"> — </strong>的联合创始人/首席技术官。</p><p id="f20d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">想要获得免费的每周数据科学和创业见解吗？</p><p id="f2b1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><a class="ae ln" href="https://bit.ly/3pGF8jv" rel="noopener ugc nofollow" target="_blank"/></p><p id="c060" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">你可以在<a class="ae ln" href="https://www.linkedin.com/in/admond1994/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>、<a class="ae ln" href="https://medium.com/@admond1994" rel="noopener"> Medium </a>、<a class="ae ln" href="https://twitter.com/admond1994" rel="noopener ugc nofollow" target="_blank"> Twitter </a>、<a class="ae ln" href="https://www.facebook.com/admond1994" rel="noopener ugc nofollow" target="_blank">脸书</a>上和他联系。</p><div class="os ot gp gr ou ov"><a href="https://www.admondlee.com/" rel="noopener  ugc nofollow" target="_blank"><div class="ow ab fo"><div class="ox ab oy cl cj oz"><h2 class="bd ir gy z fp pa fr fs pb fu fw ip bi translated">阿德蒙德·李</h2><div class="pc l"><h3 class="bd b gy z fp pa fr fs pb fu fw dk translated">让每个人都能接触到数据科学。Admond 正在通过先进的社交分析和机器学习，利用可操作的见解帮助公司和数字营销机构实现营销投资回报。</h3></div><div class="pd l"><p class="bd b dl z fp pa fr fs pb fu fw dk translated">www.admondlee.com</p></div></div><div class="pe l"><div class="pf l pg ph pi pe pj kp ov"/></div></div></a></div></div></div>    
</body>
</html>