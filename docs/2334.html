<html>
<head>
<title>Understanding and Writing your first Text Mining Script with R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解并使用 R 编写您的第一个文本挖掘脚本</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-and-writing-your-first-text-mining-script-with-r-c74a7efbe30f?source=collection_archive---------3-----------------------#2018-01-11">https://towardsdatascience.com/understanding-and-writing-your-first-text-mining-script-with-r-c74a7efbe30f?source=collection_archive---------3-----------------------#2018-01-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/74de569e003d50faa8371e61fe227850.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/1*shFDN--tGKUQdHMio1KukA.gif"/></div></figure><h2 id="9377" class="ju jv iq bd jw jx jy dn jz ka kb dp kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">介绍</h2><p id="1367" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la kd lb lc ld kh le lf lg kl lh li lj lk ij bi translated">数据科学变得流行的原因之一是因为它能够在瞬间或仅仅一个查询中揭示大量数据集的信息。</p><p id="f20f" class="pw-post-body-paragraph kq kr iq ks b kt ll kv kw kx lm kz la kd ln lc ld kh lo lf lg kl lp li lj lk ij bi translated">仔细想想，每天我们以文本的形式给出了多少信息？所有这些信息包含了我们的情感、我们的观点、我们的计划、建议、我们最喜欢的短语等等。</p><p id="863f" class="pw-post-body-paragraph kq kr iq ks b kt ll kv kw kx lm kz la kd ln lc ld kh lo lf lg kl lp li lj lk ij bi translated">然而，揭示其中的每一个看起来就像是大海捞针，直到我们使用像文本挖掘/分析这样的技术。</p><p id="3d49" class="pw-post-body-paragraph kq kr iq ks b kt ll kv kw kx lm kz la kd ln lc ld kh lo lf lg kl lp li lj lk ij bi translated">文本挖掘考虑了信息检索、词频分析和研究以及模式识别，以帮助可视化和预测分析。</p><p id="a4c4" class="pw-post-body-paragraph kq kr iq ks b kt ll kv kw kx lm kz la kd ln lc ld kh lo lf lg kl lp li lj lk ij bi translated">在本文中，我们将经历数据集为进一步分析做准备的主要步骤。我们将使用 R 编写脚本，代码将在 R studio 中编写。</p><p id="729f" class="pw-post-body-paragraph kq kr iq ks b kt ll kv kw kx lm kz la kd ln lc ld kh lo lf lg kl lp li lj lk ij bi translated">为了实现我们的目标，我们将使用一个名为“tm”的 R 包。这个软件包支持所有的文本挖掘功能，如加载数据，清理数据和建立一个术语矩阵。它在 CRAN 上有售。</p><h2 id="0658" class="ju jv iq bd jw jx jy dn jz ka kb dp kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">让我们首先在我们的工作空间中安装并加载这个包。</h2><pre class="lq lr ls lt gt lu lv lw lx aw ly bi"><span id="512f" class="ju jv iq lv b gy lz ma l mb mc">#downloading and installing the package from CRAN<br/>install.packages("tm")</span><span id="9419" class="ju jv iq lv b gy md ma l mb mc">#loading tm<br/>library(tm)</span></pre><h2 id="02ad" class="ju jv iq bd jw jx jy dn jz ka kb dp kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">加载数据</h2><p id="94a2" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la kd lb lc ld kh le lf lg kl lh li lj lk ij bi translated">要挖掘的文本可以从不同的源格式加载到 R 中。它可以来自文本文件(。txt)、pdf(。pdf)、csv 文件(。csv) e.t.c，但不管源格式如何，要在 tm 包中使用它，就要把它变成一个“语料库”。</p><p id="476e" class="pw-post-body-paragraph kq kr iq ks b kt ll kv kw kx lm kz la kd ln lc ld kh lo lf lg kl lp li lj lk ij bi translated">语料库被定义为“书面文本的集合，尤其是特定作者的全部作品或关于特定主题的写作主体”。</p><p id="7d78" class="pw-post-body-paragraph kq kr iq ks b kt ll kv kw kx lm kz la kd ln lc ld kh lo lf lg kl lp li lj lk ij bi translated">tm 包使用 Corpus()函数创建一个语料库。</p><pre class="lq lr ls lt gt lu lv lw lx aw ly bi"><span id="fdcb" class="ju jv iq lv b gy lz ma l mb mc">#loading a text file from local computer<br/>newdata&lt;- readlines(filepath)</span><span id="b2ab" class="ju jv iq lv b gy md ma l mb mc">#Load data as corpus<br/>#VectorSource() creates character vectors</span><span id="5012" class="ju jv iq lv b gy md ma l mb mc">mydata &lt;- Corpus(VectorSource(newdata))</span></pre><p id="972f" class="pw-post-body-paragraph kq kr iq ks b kt ll kv kw kx lm kz la kd ln lc ld kh lo lf lg kl lp li lj lk ij bi translated">参考本<a class="ae me" href="http://www.r-tutor.com/r-introduction/data-frame/data-import" rel="noopener ugc nofollow" target="_blank">指南</a>了解更多关于导入文件到 r。</p><h2 id="30cd" class="ju jv iq bd jw jx jy dn jz ka kb dp kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">正在清理数据。</h2><p id="514b" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la kd lb lc ld kh le lf lg kl lh li lj lk ij bi translated">一旦我们成功地将数据加载到工作空间中，就该清理这些数据了。我们在这一步的目标是从数据文件中创建独立的术语(单词),然后才能开始计算它们出现的频率。</p><p id="0eb9" class="pw-post-body-paragraph kq kr iq ks b kt ll kv kw kx lm kz la kd ln lc ld kh lo lf lg kl lp li lj lk ij bi translated">因为 R 是区分大小写的，我们应该首先将整个文本转换成小写，以避免认为相同的单词“write”和“Write”不同。</p><p id="a2b0" class="pw-post-body-paragraph kq kr iq ks b kt ll kv kw kx lm kz la kd ln lc ld kh lo lf lg kl lp li lj lk ij bi translated">我们将删除:网址，表情符号，非英语单词，标点符号，数字，空白和停用词。</p><p id="facf" class="pw-post-body-paragraph kq kr iq ks b kt ll kv kw kx lm kz la kd ln lc ld kh lo lf lg kl lp li lj lk ij bi translated">停用词:tm 包中常用的英文单词如“a”、“is”、“The”都称为停用词。为了使结果更准确，必须去掉这些词。也可以创建自己的自定义停用词。</p><pre class="lq lr ls lt gt lu lv lw lx aw ly bi"><span id="8694" class="ju jv iq lv b gy lz ma l mb mc"># convert to lower case<br/>mydata &lt;- tm_map(mydata, content_transformer(tolower))</span><span id="da9e" class="ju jv iq lv b gy md ma l mb mc">#remove ������ what would be emojis<br/>mydata&lt;-tm_map(mydata, content_transformer(gsub), pattern="\\W",replace=" ")</span><span id="fd8d" class="ju jv iq lv b gy md ma l mb mc"># remove URLs<br/>removeURL &lt;- function(x) gsub("http[^[:space:]]*", "", x)<br/>mydata &lt;- tm_map(mydata, content_transformer(removeURL)<br/>)<br/># remove anything other than English letters or space<br/>removeNumPunct &lt;- function(x) gsub("[^[:alpha:][:space:]]*", "", x)<br/>mydata &lt;- tm_map(mydata, content_transformer(removeNumPunct))</span><span id="06eb" class="ju jv iq lv b gy md ma l mb mc"># remove stopwords<br/>mydata &lt;- tm_map(mydata, removeWords, stopwords("english"))</span><span id="23f2" class="ju jv iq lv b gy md ma l mb mc">#u can create custom stop words using the code below.<br/>#myStopwords &lt;- c(setdiff(stopwords('english'), c("r", "big")),"use", "see", "used", "via", "amp")<br/>#mydata &lt;- tm_map(mydata, removeWords, myStopwords)</span><span id="fcc9" class="ju jv iq lv b gy md ma l mb mc"># remove extra whitespace<br/>mydata &lt;- tm_map(mydata, stripWhitespace)</span><span id="b9ba" class="ju jv iq lv b gy md ma l mb mc"># Remove numbers<br/>mydata &lt;- tm_map(mydata, removeNumbers)</span><span id="3e96" class="ju jv iq lv b gy md ma l mb mc"># Remove punctuations<br/>mydata &lt;- tm_map(mydata, removePunctuation)</span></pre><h2 id="6004" class="ju jv iq bd jw jx jy dn jz ka kb dp kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak">词干</strong></h2><p id="d25c" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la kd lb lc ld kh le lf lg kl lh li lj lk ij bi translated">词干提取是将相似来源的单词聚集成一个单词的过程，例如“通信”、“交流”、“沟通”。词干分析通过删除后缀和将单词简化为基本形式来帮助我们提高挖掘文本的准确性。我们将使用雪球图书馆。</p><pre class="lq lr ls lt gt lu lv lw lx aw ly bi"><span id="b429" class="ju jv iq lv b gy lz ma l mb mc">library(SnowballC)</span><span id="1693" class="ju jv iq lv b gy md ma l mb mc">mydata &lt;- tm_map(mydata, stemDocument)</span></pre><h2 id="b5e4" class="ju jv iq bd jw jx jy dn jz ka kb dp kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">构建术语矩阵并揭示词频</h2><p id="4410" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la kd lb lc ld kh le lf lg kl lh li lj lk ij bi translated">在清理过程之后，我们剩下的是存在于整个文档中的独立术语。这些都存储在一个矩阵中，显示它们的每一次出现。这个矩阵记录了术语在我们的干净数据集中出现的次数，因此被称为<strong class="ks ir">术语矩阵</strong>。</p><pre class="lq lr ls lt gt lu lv lw lx aw ly bi"><span id="a11b" class="ju jv iq lv b gy lz ma l mb mc">#create a term matrix and store it as dtm<br/>dtm &lt;- TermDocumentMatrix(mydata)</span></pre><p id="bd95" class="pw-post-body-paragraph kq kr iq ks b kt ll kv kw kx lm kz la kd ln lc ld kh lo lf lg kl lp li lj lk ij bi translated"><strong class="ks ir">词频</strong>:词在数据集中出现的次数。使用术语矩阵中出现的汇编，词频将向我们指示从数据集中最频繁使用的词到最少使用的词。</p><h2 id="7d49" class="ju jv iq bd jw jx jy dn jz ka kb dp kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">结论</h2><p id="bcfa" class="pw-post-body-paragraph kq kr iq ks b kt ku kv kw kx ky kz la kd lb lc ld kh le lf lg kl lh li lj lk ij bi translated">我们刚刚写了一个基本的文本挖掘脚本，然而这只是文本挖掘的开始。获取原始格式的文本并将其清理到这一点的能力将为我们提供方向，如<strong class="ks ir">构建单词云、情感分析</strong>和<strong class="ks ir">构建模型。</strong></p><p id="d25a" class="pw-post-body-paragraph kq kr iq ks b kt ll kv kw kx lm kz la kd ln lc ld kh lo lf lg kl lp li lj lk ij bi translated">保留这个脚本，因为当我们开始进行情感分析时，它会派上用场。</p><p id="6b92" class="pw-post-body-paragraph kq kr iq ks b kt ll kv kw kx lm kz la kd ln lc ld kh lo lf lg kl lp li lj lk ij bi translated">有任何问题都可以联系我&gt;<a class="ae me" href="https://twitter.com/lornamariak" rel="noopener ugc nofollow" target="_blank"> @lornamariak </a>。</p></div></div>    
</body>
</html>