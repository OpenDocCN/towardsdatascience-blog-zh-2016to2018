<html>
<head>
<title>Judging a book by its cover..!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">根据封面判断一本书..！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/judging-a-book-by-its-cover-1365d001ef50?source=collection_archive---------6-----------------------#2018-04-23">https://towardsdatascience.com/judging-a-book-by-its-cover-1365d001ef50?source=collection_archive---------6-----------------------#2018-04-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3d23" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">项目的GitHub <a class="ae kf" href="https://github.com/nkartik94/Judging-a-book-by-its-cover.git" rel="noopener ugc nofollow" target="_blank">链接</a>。LinkedIn <a class="ae kf" href="https://www.linkedin.com/in/kartiknooney" rel="noopener ugc nofollow" target="_blank">简介</a>。</h2></div></div><div class="ab cl kg kh hu ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="ij ik il im in"><blockquote class="kn ko kp"><p id="b059" class="kq kr ks kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">与流行的谚语“<em class="iq">不要根据封面来判断一本书”相反，一本书的封面实际上可以用来获得关于这本书的各种信息。一本书的封面通常是第一次互动，它会给读者留下印象。它开始与潜在的读者对话，并开始画一个故事，揭示里面的内容。但是，书的封面上写了什么？</em></p><p id="6c9b" class="kq kr ks kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果光是书的封面就能告诉我们选择这本书作为下一次阅读的所有信息，无论是平均评分、有用的评论、书的页数、作者的详细信息，还是对这本书的更好的总结，会怎么样？如果所有这些信息都是从无数的网站上收集来的，使得信息更加真实，那会怎么样呢？</p><p id="9cc7" class="kq kr ks kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">延伸我对书籍的痴迷，这个项目在<em class="iq">计算机视觉</em>和<em class="iq">机器学习的帮助下解决了上述问题。</em></p></blockquote></div><div class="ab cl kg kh hu ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="ij ik il im in"><h1 id="7bfd" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated"><strong class="ak">项目鸟瞰图:</strong></h1><p id="2ccf" class="pw-post-body-paragraph kq kr iq kt b ku mf jr kw kx mg ju kz mh mi lc ld mj mk lg lh ml mm lk ll lm ij bi translated">这个项目是一个临时版本的<em class="ks"> CBIR ( </em>基于内容的图像检索)系统。一旦用户实时点击书籍封面的图片，我们使用一个三级匹配系统来检索书籍封面的最接近匹配，并根据检索到的书籍封面显示从Goodreads和Amazon等网站获得的关于书籍各个方面的总结信息。</p><h2 id="af47" class="mn lo iq bd lp mo mp dn lt mq mr dp lx mh ms mt lz mj mu mv mb ml mw mx md my bi translated"><strong class="ak">三级匹配系统:</strong></h2><ul class=""><li id="c575" class="mz na iq kt b ku mf kx mg mh nb mj nc ml nd lm ne nf ng nh bi translated"><strong class="kt ir">一级:</strong> RGB颜色直方图。</li><li id="cd8c" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><strong class="kt ir">第二级:</strong>结构相似性指数度量(SSIM)。</li><li id="d164" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><strong class="kt ir"> Level-3: </strong>使用SIFT特征的FLANN匹配。</li><li id="607a" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">这个三级匹配系统的基本思想是通过在每一级消除不相关的匹配来缩小精确匹配的范围。随着级别的增加，匹配器产生的结果的准确性增加，并且它用于匹配的时间也增加。</li><li id="530b" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">如果我们在初始级别消除更多的匹配，那么匹配器在下一级别所花费的时间将会减少，但同时潜在的匹配可能已经在前一级别被消除，因此降低了整个系统的准确性。</li><li id="23f1" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">如果我们在初始级别消除非常少的匹配，从而将更多的匹配传递给下一级匹配器，则系统的时间会急剧增加，但系统的准确性不会受到损害。</li><li id="34b6" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">因此，我们减少了每个级别的潜在匹配的数量，但不是通过消除太多的匹配，因此我们在速度和准确性之间进行了微调。</li></ul><h2 id="c3fa" class="mn lo iq bd lp mo mp dn lt mq mr dp lx mh ms mt lz mj mu mv mb ml mw mx md my bi translated"><strong class="ak">十步流程:</strong></h2><ul class=""><li id="5eb2" class="mz na iq kt b ku mf kx mg mh nb mj nc ml nd lm ne nf ng nh bi translated">第一步:建立一个包含所有可用书籍封面及其各自的<em class="ks"> ISBN号</em>的存储库。</li><li id="bba9" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><strong class="kt ir">第二步:</strong>为库中所有的书籍封面图像计算<em class="ks"> RGB颜色直方图</em>。</li><li id="66fc" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><strong class="kt ir">步骤3: </strong>读入查询书籍封面并计算其颜色直方图。</li><li id="7d07" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><strong class="kt ir">步骤4: </strong>基于直方图之间的<em class="ks">相关性</em>在图像库中搜索查询书封面的最接近匹配。<em class="ks">(一级匹配器)。</em></li><li id="d0ea" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><strong class="kt ir">第五步:</strong>使用<em class="ks"> SSIM </em>从<em class="ks">第四步</em>得到的匹配中搜索与查询书封面最接近的匹配。<em class="ks">(二级匹配器)。</em></li><li id="e791" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><strong class="kt ir">第六步:</strong>使用<em class="ks"> FLANN </em>从<em class="ks">第五步</em>得到的匹配中搜索与查询书封面最接近的匹配。<em class="ks">(三级匹配器)。</em></li><li id="be1d" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><strong class="kt ir">步骤7: </strong>显示3级匹配后得到的前4个匹配。还显示前4个检索图像中匹配的<em class="ks"> SIFT </em>特征的数量。</li><li id="2b68" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><strong class="kt ir">步骤8: </strong>绘制查询书封面图像与顶部匹配的匹配。</li><li id="00e4" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><strong class="kt ir">第9步:</strong>创建一个网络爬虫从<em class="ks"> Goodreads和Amazon收集信息。</em></li><li id="5e00" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><strong class="kt ir">步骤-10: </strong>使用顶级匹配的<em class="ks"> ISBN </em>和在<em class="ks">步骤-9中设计的爬虫程序，</em>检索额外的图书信息，如评级数、平均评级、有用评论、图书页数、作者详细信息等。并最终显示所获得信息的汇总版本。</li></ul></div><div class="ab cl kg kh hu ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="ij ik il im in"><h1 id="c463" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">此项目中使用的库:</h1><ul class=""><li id="f7ab" class="mz na iq kt b ku mf kx mg mh nb mj nc ml nd lm ne nf ng nh bi translated"><strong class="kt ir"> OpenCV: </strong>开源计算机视觉是一个主要针对实时计算机视觉的编程函数库。该库拥有超过2500种优化算法，包括一套全面的经典和最先进的计算机视觉和机器学习算法。</li><li id="2a9e" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">Numpy的主要目标是大型、高效、多维数组表示。这个项目处理大量的图像，每个图像被表示为一个numpy数组。将图像表示为NumPy数组不仅计算和资源效率高，而且许多其他图像处理和机器学习库也使用NumPy数组表示。</li><li id="b431" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><strong class="kt ir">Scikit-image:</strong>It<strong class="kt ir"/>是图像处理的算法集合。它包括分割、几何变换、色彩空间处理、分析、过滤、特征检测等算法。它旨在与Python数字和科学库NumPy和SciPy进行互操作。</li><li id="2a1a" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><strong class="kt ir"> Matplotlib: </strong> Matplotlib是一个绘图库。当分析图像时，我们将利用matplotlib，无论是绘制搜索系统的整体准确性还是简单地查看图像本身，matplotlib都是您工具箱中的一个伟大工具。</li><li id="ef0f" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><strong class="kt ir"> Imutils: </strong>这个包包含了一系列OpenCV和便利函数，执行基本任务，比如平移、旋转、调整大小和骨骼化。这是一个由<a class="ae kf" href="https://www.pyimagesearch.com/author/adrian/" rel="noopener ugc nofollow" target="_blank"><strong class="kt ir">Adrian rose Brock</strong></a><strong class="kt ir">开源的精彩而高效的包。</strong></li><li id="d4d2" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><strong class="kt ir">美汤:</strong>是一个从HTML和XML文件中抽取数据的Python库。它与您喜欢的解析器一起工作，提供导航、搜索和修改解析树的惯用方式。BeautifulSoup的优点是，它可以像解析简单的XML一样解析HTML，并毫不费力地将所需的值(文本)返回给我们。</li></ul></div><div class="ab cl kg kh hu ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="ij ik il im in"><h1 id="6c51" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">实施:</h1><blockquote class="kn ko kp"><p id="e316" class="kq kr ks kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">注:</strong>本代码中有某些超参数，可根据个人需求进行微调。我对它们进行了调整，在速度和准确性之间找到了一个最佳平衡点。</p></blockquote><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="7784" class="mn lo iq ns b gy nw nx l ny nz"># Hyper-Parameter for comparing histograms<br/>correl_threshold = 0.9</span><span id="a518" class="mn lo iq ns b gy oa nx l ny nz"># Hyper-Parameters for SSIM comparision<br/>similarity_index_threshold = 0.0<br/>ssim_matches_limit = 100</span><span id="1a4b" class="mn lo iq ns b gy oa nx l ny nz"># Hyper-Parameters for SIFT comparison<br/>sift_features_limit = 1000<br/>lowe_ratio = 0.75<br/>predictions_count = 4</span><span id="dc27" class="mn lo iq ns b gy oa nx l ny nz"># Hyper-Parameters to display results<br/>query_image_number = 2<br/>amazon_reviews_count = 3</span></pre><h2 id="cf2e" class="mn lo iq bd lp mo mp dn lt mq mr dp lx mh ms mt lz mj mu mv mb ml mw mx md my bi translated">第一步:</h2><ul class=""><li id="e11d" class="mz na iq kt b ku mf kx mg mh nb mj nc ml nd lm ne nf ng nh bi translated">封面数据集可以从<a class="ae kf" href="https://github.com/uchidalab/book-dataset" rel="noopener ugc nofollow" target="_blank"> <em class="ks">这个</em> </a>链接下载。该数据集包含来自亚马逊的207，572本书。但都是2017年之前发行的书。</li><li id="e3d3" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">它包含一个shell脚本，将csv文件作为输入传递给python代码。csv文件包含图书的ISBN号，python代码将根据这些ISBN号逐一下载图书封面，并以ISBN号作为图像名称保存。</li><li id="f61b" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">亚马逊不允许使用这种脚本高速下载其数据。下载速度会很少，35kbps左右。按照这种速度，下载所有的书的封面需要将近2天的时间。下载失败可能有几个原因，主要原因是亚马逊阻止了这样的脚本。</li></ul><figure class="nn no np nq gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi ob"><img src="../Images/37fa728e807717b20431b269eb9efb79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vaQEb81rsSLMHJiTxQ8BgQ.jpeg"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk">Figure 1: Download Complete</figcaption></figure><figure class="nn no np nq gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi on"><img src="../Images/03a70d2057bdde5292615aaf4e60d1af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0TefMLI7vyW-pdPiPDDjNw.jpeg"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk">Figure 2: Download Failed</figcaption></figure><ul class=""><li id="f704" class="mz na iq kt b ku kv kx ky mh oo mj op ml oq lm ne nf ng nh bi translated">这个问题的快速解决方法是将包含ISBN号的csv文件<em class="ks">(</em><a class="ae kf" href="https://github.com/uchidalab/book-dataset/blob/master/Task2/book32-listing.csv" rel="noopener ugc nofollow" target="_blank"><em class="ks">book32-listing . csv</em></a><em class="ks">)</em>拆分成几个部分，然后在所有这些零碎的CSV文件上并行运行shell脚本。这样我们可以在几个小时内下载完整的图书封面图片。即使在这种方法中，很少下载会失败，但是我们可以简单地只重新运行该特定片段的shell脚本来重试下载。</li></ul><figure class="nn no np nq gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi or"><img src="../Images/029b0119e34c25c289c5dfcd0a0fc820.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JeOxAJN3IKmMwhUi3KO2_g.jpeg"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk">Figure 3: Parallel download of book covers</figcaption></figure></div><div class="ab cl kg kh hu ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="ij ik il im in"><h2 id="e397" class="mn lo iq bd lp mo mp dn lt mq mr dp lx mh ms mt lz mj mu mv mb ml mw mx md my bi translated">第二步:</h2><ul class=""><li id="afb7" class="mz na iq kt b ku mf kx mg mh nb mj nc ml nd lm ne nf ng nh bi translated">基于内容的图像检索(CBIR)是一种利用视觉属性(如颜色、纹理、形状)来搜索图像的技术。在大型图像数据库中，颜色属性被认为是图像搜索中最常用的低级特征。</li><li id="b12a" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">颜色直方图是一个简单的直方图，显示每个单独的RGB颜色通道的颜色级别。由于我们处理的是RGB色彩空间，这里的像素值将在0–255的范围内。如果您在不同的色彩空间中工作，像素范围可能会有所不同。</li><li id="483d" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">绘制直方图时，X轴充当我们的“箱”。如果我们构建一个有256个面元的直方图，那么我们可以有效地计算每个像素值出现的次数。然后，在Y轴上绘制被装箱到X轴值的像素数。在我们的程序中，我们使用的是RGB 8-bin颜色直方图。</li><li id="4bac" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">首先让我们导入必要的库。</li></ul><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="b6a4" class="mn lo iq ns b gy nw nx l ny nz">import os<br/>import cv2<br/>import imutils <br/>import pickle<br/>import numpy as np</span></pre><blockquote class="kn ko kp"><p id="fee0" class="kq kr ks kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">注意:</strong> Pickle是一个库，它可以用来序列化或反序列化一个python对象，比如一个列表到文本中，并保存到磁盘或从磁盘中检索。通常它们被保存为pickle文件。pkl”作为扩展名。</p></blockquote><ul class=""><li id="f9b7" class="mz na iq kt b ku kv kx ky mh oo mj op ml oq lm ne nf ng nh bi translated">接下来，我们将所有下载的书籍封面的路径列表放入一个名为“<em class="ks"> train_paths”的python列表中。</em></li></ul><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="4bbc" class="mn lo iq ns b gy nw nx l ny nz">train_paths = []</span><span id="a5d0" class="mn lo iq ns b gy oa nx l ny nz">train_path = "/Users/kartik/Desktop/Projects/Book_Covers_Data/amazon_book_cover_images"</span><span id="a6b4" class="mn lo iq ns b gy oa nx l ny nz">for root, dirs, files in os.walk(train_path):<br/>     for file in files:<br/>        train_paths.append((os.path.join(root, file)))</span></pre><ul class=""><li id="6e11" class="mz na iq kt b ku kv kx ky mh oo mj op ml oq lm ne nf ng nh bi translated">现在，我们遍历书籍封面图像的所有路径，并使用<em class="ks"> openCV逐一读入图像。</em>openCV的问题在于，它无法读取太阳下的每一种图像格式，例如，它无法读取gif图像。即使它不能读取图像，<em class="ks"> openCV </em>也不会抛出错误，而是返回一个<em class="ks"> NoneType </em>对象。所以我们需要在计算颜色直方图之前移除所有这样的<em class="ks">非类型</em>对象。</li><li id="a0de" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><em class="ks"> openCV </em>有很好的内置函数来计算颜色直方图，<em class="ks"/><a class="ae kf" href="https://docs.opencv.org/2.4/modules/imgproc/doc/histograms.html" rel="noopener ugc nofollow" target="_blank"><em class="ks">卡尔奇斯特</em></a><em class="ks"/>。默认情况下，<em class="ks"> openCV </em>读取的是"<em class="ks"> BGR" </em>格式的图像，因此在将图像传递给<em class="ks"> calcHist </em>函数之前，我们将图像的颜色方案从BGR转换为RGB。</li><li id="6ed1" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">我们定义了另一个列表"<em class="ks"> hist_train" </em>，它将存储特定书籍封面图像的路径及其相应的颜色直方图。</li></ul><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="7924" class="mn lo iq ns b gy nw nx l ny nz">hist_train = []</span><span id="24d9" class="mn lo iq ns b gy oa nx l ny nz">for path in train_paths:<br/>    image = cv2.imread(path)<br/>   <br/>    if image is None:<br/>        continue</span><span id="e3c9" class="mn lo iq ns b gy oa nx l ny nz">image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)<br/>    # extract a RGB color histogram from the image,<br/>    # using 8 bins per channel, normalize, and update<br/>    # the index<br/>    hist = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8],[0, 256, 0, 256, 0, 256])<br/>    hist = cv2.normalize(hist, None)<br/>    hist_train.append((path,hist))</span></pre><ul class=""><li id="7268" class="mz na iq kt b ku kv kx ky mh oo mj op ml oq lm ne nf ng nh bi translated">在计算完所有图像的颜色直方图后，我们可以将这些数据作为pickle文件保存到磁盘上。</li></ul><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="67f2" class="mn lo iq ns b gy nw nx l ny nz"># Saving the train data histograms to a pickle file</span><span id="176b" class="mn lo iq ns b gy oa nx l ny nz">with open('train_hist_data.pkl', 'wb') as f:<br/>    pickle.dump(hist_train, f)</span></pre><ul class=""><li id="2c53" class="mz na iq kt b ku kv kx ky mh oo mj op ml oq lm ne nf ng nh bi translated">我们可以在以后的任何时候简单地从磁盘加载颜色直方图数据，而不用再次计算所有的直方图。</li></ul><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="3b3f" class="mn lo iq ns b gy nw nx l ny nz"># Loading the train data histograms from pickle file</span><span id="8ab9" class="mn lo iq ns b gy oa nx l ny nz">with open('train_hist_data.pkl', 'rb') as f:<br/>    hist_train = pickle.load(f)</span></pre><blockquote class="kn ko kp"><p id="d480" class="kq kr ks kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">注:</strong>如果处理器性能相当好，计算所有<strong class="kt ir"> 207K </strong>图像的直方图将需要相当长的时间。我在一个16GB内存的i7处理器上花了大约1小时20分钟。</p></blockquote><ul class=""><li id="e9fa" class="mz na iq kt b ku kv kx ky mh oo mj op ml oq lm ne nf ng nh bi translated">图像的RGB颜色直方图可以使用matplot库可视化。对于下面的样本书籍封面，其颜色直方图可以如下获得:</li></ul><figure class="nn no np nq gt oc gh gi paragraph-image"><div class="gh gi os"><img src="../Images/6284cb52fc980bdcbad601acd5ba1a44.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*DLJsEh7d5oAjQ0DBcm12ww.png"/></div></figure><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="53cc" class="mn lo iq ns b gy nw nx l ny nz">import matplotlib.pyplot as plt</span><span id="9a92" class="mn lo iq ns b gy oa nx l ny nz">img_path = "/Users/kartik/Desktop/Projects/S_Images/9781501171383.jpg"<br/>img = cv2.imread(img_path)<br/>color = ('b','g','r')<br/>plt.figure(figsize=(15,10))</span><span id="a509" class="mn lo iq ns b gy oa nx l ny nz">for i,col in enumerate(color):<br/>    histr = cv2.calcHist([img],[i],None,[256],[0,256])<br/>    plt.plot(histr,color = col)<br/>    plt.xlim([0,256])<br/>plt.show()</span></pre><figure class="nn no np nq gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi ot"><img src="../Images/31937ae8b417cf786220b8e3bb3d2814.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oDK06WxYoytnufAbuEj89A.png"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk">Figure 5: RGB Colour Histogram</figcaption></figure></div><div class="ab cl kg kh hu ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="ij ik il im in"><h2 id="5b22" class="mn lo iq bd lp mo mp dn lt mq mr dp lx mh ms mt lz mj mu mv mb ml mw mx md my bi translated">第三步:</h2><ul class=""><li id="4738" class="mz na iq kt b ku mf kx mg mh nb mj nc ml nd lm ne nf ng nh bi translated">我从这些<em class="ks"> 207k </em>图像中创建了一组查询/测试图像，通过随机选取一组图像并对这些图像应用<em class="ks">仿射变换</em>并添加一些剪切。完成这些变换是为了紧密模仿从移动设备拍摄的实时图像。</li></ul><figure class="nn no np nq gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi ou"><img src="../Images/12b2a96fcb9dc8a49995f09b8609e39c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Av2bMjJTIxm3ylX8rjVCQ.png"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk">Figure 6: Images before and after applying Affine Transformation with Shear = 0.1</figcaption></figure><ul class=""><li id="dcdb" class="mz na iq kt b ku kv kx ky mh oo mj op ml oq lm ne nf ng nh bi translated">类似于<em class="ks">步骤2 </em>中的程序，我们读入所有查询书籍封面，并计算它们的RGB颜色直方图。</li></ul><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="78aa" class="mn lo iq ns b gy nw nx l ny nz">query_path = "/Users/kartik/Desktop/Projects/Book_Covers_Data/Test_Images"<br/>query_paths = imlist(query_path)</span><span id="5a5b" class="mn lo iq ns b gy oa nx l ny nz">hist_query = []<br/>for path in query_paths:<br/>    image = cv2.imread(path)<br/>    <br/>    if image is None:<br/>        continue<br/>    <br/>    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)<br/>    # extract a RGB color histogram from the image,<br/>    # using 8 bins per channel, normalize, and update the index<br/>    hist = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8],[0, 256, 0, 256, 0, 256])<br/>    hist = cv2.normalize(hist, None)<br/>    hist_query.append((path,hist))</span></pre></div><div class="ab cl kg kh hu ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="ij ik il im in"><h2 id="970f" class="mn lo iq bd lp mo mp dn lt mq mr dp lx mh ms mt lz mj mu mv mb ml mw mx md my bi translated">第4步(一级匹配器):</h2><ul class=""><li id="2bb5" class="mz na iq kt b ku mf kx mg mh nb mj nc ml nd lm ne nf ng nh bi translated">在<em class="ks">步骤2 </em>中，我们已经索引了整本书封面的所有颜色直方图。并且在<em class="ks">步骤3 </em>中，我们已经计算了查询书籍封面的颜色直方图。现在，我们必须将这些查询书封面直方图与我们的训练数据库中的直方图进行比较，我们必须找出最接近的直方图。</li><li id="858a" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><em class="ks"> openCV </em>中内置了<a class="ae kf" href="https://docs.opencv.org/2.4/modules/imgproc/doc/histograms.html?highlight=comparehist" rel="noopener ugc nofollow" target="_blank"> <em class="ks">函数</em> </a>来比较直方图，但是有几个比较度量可以选择。<em class="ks">相关、卡方、交集、巴特查亚距离、海灵格距离。</em></li></ul><blockquote class="kn ko kp"><p id="ef30" class="kq kr ks kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">注:</strong>比较指标也是一个超参数，可以根据正在处理的数据及其应用进行微调。</p></blockquote><ul class=""><li id="8612" class="mz na iq kt b ku kv kx ky mh oo mj op ml oq lm ne nf ng nh bi translated">对于本项目，使用来自<em class="ks"> openCV </em>的<em class="ks">相关性</em>作为比较指标。使用相关性作为比较度量的cv2直方图比较函数的输出值将给出0到1范围内的值。越接近1的值是越相似的直方图。</li><li id="f965" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">在比较直方图之后，我已经按照返回的相关值的非递减顺序对结果进行了排序，并且仅将相关值高于"<em class="ks">相关阈值"</em>的匹配视为潜在匹配，并且丢弃了其他匹配。</li><li id="313b" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">"<em class="ks">相关性阈值"</em>是一个超参数，可以根据个人需求进行微调。基于对该书封面数据的几次试验，较高的相关阈值消除了大多数非潜在匹配。但是，过高的值也会消除潜在的匹配，从而降低匹配器的准确性。</li><li id="fbd8" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">由于我正在处理一个207K图像的数据集，所以我将“<em class="ks">相关性阈值”的值设置为0.9。如果数据集中的图像数量很少，比如大约3k，那么作为<em class="ks">相关阈值</em>的值0.5 </em>将产生更好的结果。</li></ul><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="eec5" class="mn lo iq ns b gy nw nx l ny nz">hist_matches = []</span><span id="cac8" class="mn lo iq ns b gy oa nx l ny nz">for i in range(len(hist_query)):<br/>    matches = []<br/>    for j in range(len(hist_train)):<br/>        cmp = cv2.compareHist(hist_query[i][1], hist_train[j][1], cv2.HISTCMP_CORREL)<br/>        if cmp &gt; correl_threshold:<br/>            matches.append((cmp,hist_train[j][0]))<br/>    matches.sort(key=lambda x : x[0] , reverse = True)<br/>    hist_matches.append((hist_query[i][0],matches))</span></pre><ul class=""><li id="4560" class="mz na iq kt b ku kv kx ky mh oo mj op ml oq lm ne nf ng nh bi translated">基本上，这里我们将查询书籍封面的直方图与数据库中207k书籍封面的所有207k直方图进行比较。在这一步的最后，我们过滤掉大约800到1000个潜在的匹配。在该步骤结束时获得的潜在匹配的数量主要取决于<em class="ks">相关阈值</em>。这些过滤后的1k结果被传递到下一级。</li></ul></div><div class="ab cl kg kh hu ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="ij ik il im in"><h2 id="b837" class="mn lo iq bd lp mo mp dn lt mq mr dp lx mh ms mt lz mj mu mv mb ml mw mx md my bi translated">步骤5(二级匹配器):</h2><ul class=""><li id="4a71" class="mz na iq kt b ku mf kx mg mh nb mj nc ml nd lm ne nf ng nh bi translated">比较图像的另一个重要的图像描述符是图像的纹理。在比较图像时，均方差(MSE)虽然易于实现，但并不能很好地表明感知的相似性。结构相似性旨在通过考虑纹理来解决这一缺点。SSIM试图模拟图像结构信息的感知变化。</li><li id="e6ee" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">比较两幅图像时，结构相似性指数(SSIM)返回的值介于-1到1之间。指数越接近值1，表示两幅图像非常相似。</li><li id="f4a3" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">现在，我们将查询book-cover与上一步获得的1k左右的潜在匹配进行比较，并根据获得的<em class="ks">相似性指数</em>的非降序对结果进行排序。</li><li id="a421" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated"><em class="ks">相似性指数</em>也是一个超参数，我已经将其设置为0。我认为任何具有正值<em class="ks">相似性指数</em>的匹配都是潜在的匹配，我会将该匹配传递到下一级进行进一步匹配。</li></ul><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="70cc" class="mn lo iq ns b gy nw nx l ny nz">from skimage.measure import compare_ssim as ssim</span><span id="d81e" class="mn lo iq ns b gy oa nx l ny nz">def similarity_index(q_path,m_path):<br/>    q_i = cv2.imread(q_path,0)<br/>    q_i = cv2.resize(q_i,(8,8))<br/>    m_i = cv2.imread(m_path,0)<br/>    m_i = cv2.resize(m_i,(8,8))<br/>    return ssim(q_i,m_i)</span><span id="9355" class="mn lo iq ns b gy oa nx l ny nz">ssim_matches = []</span><span id="4e6b" class="mn lo iq ns b gy oa nx l ny nz">for i in range(len(hist_matches)):<br/>    query_image_path = hist_matches[i][0]<br/>    matches = []<br/>    for j in range(len(hist_matches[i][1])):<br/>        match_image_path = hist_matches[i][1][j][1]<br/>        si = similarity_index(query_image_path,match_image_path)<br/>        if si &gt; similarity_index_threshold:<br/>            matches.append((si,match_image_path))<br/>    matches.sort(key=lambda x : x[0] , reverse = True)<br/>    ssim_matches.append((query_image_path,matches[:ssim_matches_limit]))</span></pre><ul class=""><li id="c890" class="mz na iq kt b ku kv kx ky mh oo mj op ml oq lm ne nf ng nh bi translated">我还使用超级参数<em class="ks"> ssim-matches-limit </em>来限制获得的匹配数。我将值设置为100作为限制，因此只将这一步中获得的前100个匹配传递到下一级匹配。</li></ul></div><div class="ab cl kg kh hu ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="ij ik il im in"><h2 id="8237" class="mn lo iq bd lp mo mp dn lt mq mr dp lx mh ms mt lz mj mu mv mb ml mw mx md my bi translated">第六步(三级匹配器):</h2><ul class=""><li id="1531" class="mz na iq kt b ku mf kx mg mh nb mj nc ml nd lm ne nf ng nh bi translated">匹配不同图像的特征是计算机视觉中的一个常见问题。当所有图像在性质上相似(相同的比例、方向等)时，简单的角点检测器可以工作。但是当你有不同尺度和旋转的图像时，你需要使用<em class="ks">尺度不变特征变换(SIFT)。</em></li><li id="ed02" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">我们想要与图像的“部分”相对应的特征，在比原始像素更整体的水平上。我们想要的功能是不敏感的图像分辨率，比例，旋转，照明变化(如灯的位置)的变化。SIFT算法会做到这一点。</li><li id="538b" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">在将图像传递给<em class="ks"> openCV </em>的<em class="ks"> SIFT </em>函数时，它会返回关键点:我们所有感兴趣点的x、y和八度音程位置，以及方向。<em class="ks">关键点</em>具有比例不变性和旋转不变性。它还为每个关键点生成<em class="ks">描述符</em>，不使用原始亮度值，而是通过计算每个像素的梯度。</li><li id="de94" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">生成的<em class="ks"> SIFT关键点的数量</em>也是一个<em class="ks">超参数</em>。它可以根据计算能力和可用的内存资源进行微调。我已经为生成的<em class="ks"> SIFT特征</em>设置了1000个<em class="ks">关键点</em>的限制。</li></ul><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="48fb" class="mn lo iq ns b gy nw nx l ny nz">def gen_sift_features(image):<br/>    sift = cv2.xfeatures2d.SIFT_create(sift_features_limit)<br/>    # kp is the keypoints<br/>    #<br/>    # desc is the SIFT descriptors, they're 128-dimensional vectors<br/>    # that we can use for our final features<br/>    kp, desc = sift.detectAndCompute(image, None)<br/>    return kp, desc</span></pre><ul class=""><li id="cf72" class="mz na iq kt b ku kv kx ky mh oo mj op ml oq lm ne nf ng nh bi translated">我们为在<em class="ks">步骤-5(二级匹配器)</em>之后获得的每个潜在匹配生成<em class="ks"> SIFT关键点&amp;描述符</em>，并将它们与查询图书封面的<em class="ks"> SIFT关键点&amp;描述符</em>进行比较。使用<em class="ks">FLANN-Matcher</em>完成<em class="ks">关键点</em>的比较。FLANN是一个用于在高维空间中执行快速近似最近邻搜索的库。</li></ul><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="924b" class="mn lo iq ns b gy nw nx l ny nz"># FLANN matcher<br/>FLANN_INDEX_KDTREE = 0<br/>index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)<br/>search_params = dict(checks=50)   # or pass empty dictionary<br/>flann = cv2.FlannBasedMatcher(index_params,search_params)</span></pre><ul class=""><li id="6d07" class="mz na iq kt b ku kv kx ky mh oo mj op ml oq lm ne nf ng nh bi translated">"<em class="ks"> FLANN-Matcher" </em>将返回两幅图像的关键点之间的匹配数量。这里的“<em class="ks">劳氏比”</em>是另一个<em class="ks">超参数</em>，过滤掉<em class="ks"> FLANN-Matcher </em>结果中的弱关键点匹配。理想比值在0.75左右。现在，我们按照关键点匹配计数的非递减顺序对潜在匹配进行排序。</li></ul><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="5f4b" class="mn lo iq ns b gy nw nx l ny nz">predictions = []<br/>for i in range(len(ssim_matches)):<br/>    matches_flann = []<br/>    # Reading query image<br/>    q_path = ssim_matches[i][0]<br/>    q_img = cv2.imread(q_path)<br/>    if q_img is None:<br/>        continue<br/>    q_img = cv2.cvtColor(q_img, cv2.COLOR_BGR2RGB)<br/>    # Generating SIFT features for query image<br/>    q_kp,q_des = gen_sift_features(q_img)<br/>    if q_des is None:<br/>        continue<br/>    <br/>    for j in range(len(ssim_matches[i][1])):<br/>        matches_count = 0<br/>        m_path = ssim_matches[i][1][j][1]<br/>        m_img = cv2.imread(m_path)        <br/>        if m_img is None:<br/>            continue<br/>        m_img = cv2.cvtColor(m_img, cv2.COLOR_BGR2RGB)<br/>        # Generating SIFT features for predicted ssim images<br/>        m_kp,m_des = gen_sift_features(m_img)<br/>        if m_des is None:<br/>            continue<br/>        # Calculating number of feature matches using FLANN<br/>        matches = flann.knnMatch(q_des,m_des,k=2)<br/>        #ratio query as per Lowe's paper<br/>        matches_count = 0<br/>        for x,(m,n) in enumerate(matches):<br/>            if m.distance &lt; lowe_ratio*n.distance:<br/>                matches_count += 1<br/>        matches_flann.append((matches_count,m_path))<br/>    matches_flann.sort(key=lambda x : x[0] , reverse = True)<br/>    predictions.append((q_path,matches_flann[:predictions_count]))</span></pre></div><div class="ab cl kg kh hu ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="ij ik il im in"><h2 id="67e1" class="mn lo iq bd lp mo mp dn lt mq mr dp lx mh ms mt lz mj mu mv mb ml mw mx md my bi translated">第七步:</h2><ul class=""><li id="1e70" class="mz na iq kt b ku mf kx mg mh nb mj nc ml nd lm ne nf ng nh bi translated">现在，我们从在<em class="ks">步骤6(3级匹配器)</em>中获得的预测中，为给定的查询图书封面挑选出前4个预测图书封面，并将它们与关键点匹配的计数一起绘制出来。</li></ul><figure class="nn no np nq gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi ov"><img src="../Images/bdf7caa2e2feb57e111b8b8be86a37af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_0321UluNSI9S5KjFUQ5qQ.png"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk">Figure 7: Top-4 Predictions</figcaption></figure></div><div class="ab cl kg kh hu ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="ij ik il im in"><h2 id="9837" class="mn lo iq bd lp mo mp dn lt mq mr dp lx mh ms mt lz mj mu mv mb ml mw mx md my bi translated">第八步:</h2><ul class=""><li id="8dbf" class="mz na iq kt b ku mf kx mg mh nb mj nc ml nd lm ne nf ng nh bi translated">我们选择最有可能与我们的查询书封面相同的顶部预测图像，并且我们可以绘制精确的<em class="ks"> SIFT关键点</em>匹配。</li></ul><figure class="nn no np nq gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi ow"><img src="../Images/27660fc9432cae17ff72251cff9b76e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8D36BX0hG-vIF_o2zQ8yaA.png"/></div></div><figcaption class="oj ok gj gh gi ol om bd b be z dk">Figure 8: SIFT keypoint matches</figcaption></figure></div><div class="ab cl kg kh hu ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="ij ik il im in"><h2 id="242e" class="mn lo iq bd lp mo mp dn lt mq mr dp lx mh ms mt lz mj mu mv mb ml mw mx md my bi translated">第九步:</h2><blockquote class="kn ko kp"><p id="ba50" class="kq kr ks kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">注:</strong>以下刮刀仅用于教育目的。</p></blockquote><ul class=""><li id="2ae1" class="mz na iq kt b ku kv kx ky mh oo mj op ml oq lm ne nf ng nh bi translated">现在我们使用python抓取框架创建一个网络爬虫，比如<em class="ks"> BeautifulSoup。我们创建了两个独立的scrappers，一个用于Goodreads，另一个用于Amazon。这些刮削器将图书的ISBN号作为输入，并根据它刮削页面。</em></li></ul><blockquote class="kn ko kp"><p id="d589" class="kq kr ks kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Goodreads Scrapper</p></blockquote><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="837b" class="mn lo iq ns b gy nw nx l ny nz">def book_details_goodreads(isbn):<br/>    <br/>    # Goodreads Scraping<br/>    goodreads_base_url = "<a class="ae kf" href="https://www.goodreads.com/book/isbn/" rel="noopener ugc nofollow" target="_blank">https://www.goodreads.com/book/isbn/</a>"<br/>    goodreads_url = goodreads_base_url + isbn<br/>    req = Request(goodreads_url, headers={'User-Agent': 'Mozilla/5.0'})<br/>    page = urlopen(req).read().decode("utf-8")<br/>    soup = BeautifulSoup(page, 'html.parser')<br/>    <br/>    # Book Title<br/>    book_name = soup.find(itemprop="name")<br/>    book_name = str(book_name)<br/>    book_name = remove_tags(book_name)<br/>    book_name = book_name.strip()<br/>    book_name_list = book_name.split(" ")<br/>    <br/>    # Author Names<br/>    author_names = soup.find_all("span",itemprop="name")<br/>    author_names = str(author_names)<br/>    author_names = author_names.split(",")<br/>    author_name = author_names[0]<br/>    author_name = author_name.split("&gt;")[1].split("&lt;")[0]<br/>    for i in range(len(author_names)):<br/>        author_names[i] = author_names[i].split("&gt;")[1].split("&lt;")[0]<br/>    <br/>    author_names_text = ""<br/>    for i in range(len(author_names)):<br/>        author_names_text += str(author_names[i])<br/>        author_names_text += ", "<br/>        <br/>    # Number of Ratings<br/>    rating_count = soup.find(itemprop="ratingCount")<br/>    rating_count = str(rating_count)<br/>    rating_count = rating_count.split('"')[1]</span><span id="d502" class="mn lo iq ns b gy oa nx l ny nz"># Average Rating<br/>    rating_val = soup.find(itemprop="ratingValue")<br/>    rating_val = str(rating_val)<br/>    rating_val = remove_tags(rating_val)<br/>    <br/>    # Number of pages in book<br/>    pg_count = soup.find("meta",  property="books:page_count")<br/>    pg_count = str(pg_count)<br/>    pg_count = pg_count.split('"')[1]<br/>    <br/>    # Book Description<br/>    desc = soup.find("div", id="description")<br/>    if desc is not None:<br/>        desc = desc.find_all("span",style="display:none")<br/>        if desc is not None:<br/>            desc = str(desc)<br/>            desc = remove_tags(desc)<br/>            description = desc.strip("[]")<br/>            description = description.strip()<br/>        else:<br/>            description = "No description found"<br/>    else:<br/>        description = "No description found"</span><span id="cf90" class="mn lo iq ns b gy oa nx l ny nz"># Printing book details from Goodreads<br/>    printmd('**Book Details from Goodreads\n**')<br/>    #print("Book Details from Goodreads\n")<br/>    print("Book Title: ",book_name.splitlines()[0])<br/>    #print("\n")<br/>    print("Authors: ",author_names_text)<br/>    #print("\n")<br/>    print("Average Rating: ",rating_val)<br/>    #print("\n")<br/>    print("Number of ratings: ",rating_count)<br/>    #print("\n")<br/>    print("Number of pages in book: ",pg_count)<br/>    print("\n")<br/>    print("Book Description:")<br/>    print("\n")<br/>    print(description)</span></pre><blockquote class="kn ko kp"><p id="1c83" class="kq kr ks kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">亚马逊废品店</p></blockquote><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="c775" class="mn lo iq ns b gy nw nx l ny nz">def book_details_amazon(isbn):<br/>    <br/>    # Amazon Scraping<br/>    amazon_base_url = "<a class="ae kf" href="https://www.amazon.com/dp/" rel="noopener ugc nofollow" target="_blank">https://www.amazon.com/dp/</a>"<br/>    amazon_url = amazon_base_url + isbn<br/>    req = Request(amazon_url, headers={'User-Agent': 'Mozilla/5.0'})<br/>    page = urlopen(req).read().decode("utf-8")<br/>    soup = BeautifulSoup(page, 'html.parser')<br/>    <br/>    # Book title<br/>    a_title = soup.find_all("span",id="productTitle")<br/>    a_title = str(a_title)<br/>    a_title = remove_tags(a_title)<br/>    a_title = a_title.strip("[]")<br/>    a_title = a_title.strip()<br/>    <br/>    # Book details<br/>    book_info = []<br/>    for li in soup.select('table#productDetailsTable div.content ul li'):<br/>        try:<br/>            title = li.b<br/>            key = title.text.strip().rstrip(':')<br/>            value = title.next_sibling.strip()<br/>            value = value.strip("()")<br/>            book_info.append((key,value))<br/>        except AttributeError:<br/>            break<br/>            <br/>    # Amazon reviews scraping<br/>    amazon_review_base_url = "<a class="ae kf" href="https://www.amazon.com/product-reviews/" rel="noopener ugc nofollow" target="_blank">https://www.amazon.com/product-reviews/</a>"<br/>    amazon_review_url = amazon_review_base_url + isbn + "/ref=cm_cr_getr_d_paging_btm_2?pageNumber="<br/>    req = Request(amazon_review_url, headers={'User-Agent': 'Mozilla/5.0'})<br/>    page = urlopen(req).read().decode("utf-8")<br/>    soup = BeautifulSoup(page, 'html.parser')<br/>    <br/>    # List of book reviews in Amazon<br/>    reviews_list = []<br/>    reviews_list_final = []<br/>    for pg in range(1,5):<br/>        amazon_review_url = amazon_review_base_url + isbn + "/ref=cm_cr_getr_d_paging_btm_2?pageNumber=" + str(pg)<br/>        req = Request(amazon_review_url, headers={'User-Agent': 'Mozilla/5.0'})<br/>        page = urlopen(req).read().decode("utf-8")<br/>        soup = BeautifulSoup(page, 'html.parser')</span><span id="72fb" class="mn lo iq ns b gy oa nx l ny nz">txt = soup.find("div", id="cm_cr-review_list")<br/>        try:<br/>            for rawreview in txt.find_all('span', {'class' : 'a-size-base review-text'}):<br/>                text = rawreview.parent.parent.parent.text<br/>                startindex = text.index('5 stars') + 7<br/>                endindex = text.index('Was this review helpful to you?')<br/>                text = text[startindex:endindex]<br/>                text = text.split("Verified Purchase")[1]<br/>                rText = text.split(".")[:-1]<br/>                review_text = ""<br/>                for i in range(len(rText)):<br/>                    review_text += rText[i]<br/>                    review_text += "."<br/>                if review_text is not "":<br/>                    if "|" not in review_text:<br/>                        reviews_list.append(review_text)<br/>                    else:<br/>                        rText = text.split(".")[:-2]<br/>                        review_text = ""<br/>                        for x in range(len(rText)):<br/>                            review_text += rText[x]<br/>                            review_text += "."<br/>                        reviews_list.append(review_text)<br/>        except AttributeError:<br/>            review_text = "No reviews found."<br/>    <br/>    if amazon_reviews_count &lt; len(reviews_list):<br/>        reviews_list_final = reviews_list[:amazon_reviews_count]<br/>    else:<br/>        reviews_list_final = reviews_list<br/>        <br/>    # Printing book details from Amazon<br/>    printmd('**Book Details from Amazon\n**')<br/>    #print("Book Details from Amazon\n")<br/>    print("Book Title: ",a_title)<br/>    #print("\n")<br/>    for i in range(len(book_info)):<br/>        print(f"{book_info[i][0]} : {book_info[i][1]}")<br/>        #print("\n")<br/>    print("\n")<br/>    if len(reviews_list_final) == 0:<br/>        print(review_text)<br/>        print("\n")<br/>    else:<br/>        print(f"Displaying top {amazon_reviews_count} book reviews:\n")<br/>        for i in range(len(reviews_list_final)):<br/>            review_txt_list = reviews_list_final[i].split(".")[:3]<br/>            review_txt = ""<br/>            for j in range(len(review_txt_list)):<br/>                review_txt += review_txt_list[j]<br/>                review_txt += "."<br/>            review_txt += ".."<br/>            print(review_txt)<br/>            print("\n")</span></pre></div><div class="ab cl kg kh hu ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="ij ik il im in"><h2 id="5a26" class="mn lo iq bd lp mo mp dn lt mq mr dp lx mh ms mt lz mj mu mv mb ml mw mx md my bi translated">第十步:</h2><ul class=""><li id="4ff2" class="mz na iq kt b ku mf kx mg mh nb mj nc ml nd lm ne nf ng nh bi translated">我们将在<em class="ks">第7步</em>结束时获得的最佳匹配的ISBN号作为输入传递给上面的Goodreads和Amazon scrappers，并显示获得的信息。</li></ul><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="0bf1" class="mn lo iq ns b gy nw nx l ny nz">isbn = predictions[query_image_number][1][0][1].split("/")[-1].split(".")[0]</span><span id="38a5" class="mn lo iq ns b gy oa nx l ny nz">book_details_goodreads(isbn)</span></pre><figure class="nn no np nq gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi ox"><img src="../Images/cdb2d419f74490d17bb6bf02d58d72d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LN6qETZyvY7vN3NUGoJIIw.png"/></div></div></figure><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="9805" class="mn lo iq ns b gy nw nx l ny nz">book_details_amazon(isbn)</span></pre><figure class="nn no np nq gt oc gh gi paragraph-image"><div role="button" tabindex="0" class="od oe di of bf og"><div class="gh gi oy"><img src="../Images/434661a16f9dac6c3b573cd1498c6b74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dlTKp7XD3DX1qBPFIK5iwg.png"/></div></div></figure></div><div class="ab cl kg kh hu ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="ij ik il im in"><h1 id="5a27" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结论:</h1><h2 id="eade" class="mn lo iq bd lp mo mp dn lt mq mr dp lx mh ms mt lz mj mu mv mb ml mw mx md my bi translated">结果:</h2><ul class=""><li id="fbcb" class="mz na iq kt b ku mf kx mg mh nb mj nc ml nd lm ne nf ng nh bi translated">基于对超参数的微调，该系统给出了大约90%的准确率，并且检索单个查询书籍封面的结果所花费的平均时间大约为20秒。这里总是在速度和准确性之间进行权衡。当我们试图减少<em class="ks">周转时间时，</em>精度也会降低。</li></ul><h2 id="7077" class="mn lo iq bd lp mo mp dn lt mq mr dp lx mh ms mt lz mj mu mv mb ml mw mx md my bi translated">进一步改进:</h2><ul class=""><li id="fd99" class="mz na iq kt b ku mf kx mg mh nb mj nc ml nd lm ne nf ng nh bi translated">在建立所有书籍封面的颜色直方图储存库时，可以添加诸如K-Means的聚类算法。</li><li id="bf11" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">我们可以用CNN代替SIFT从图像中提取特征。</li><li id="0d4a" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">图像库可以在爬虫的帮助下更新，从亚马逊和Goodreads抓取最新的书籍封面。</li><li id="fcf6" class="mz na iq kt b ku ni kx nj mh nk mj nl ml nm lm ne nf ng nh bi translated">相同的项目可以扩展到移动应用程序，但是复杂的计算在服务器端完成。</li></ul></div><div class="ab cl kg kh hu ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="ij ik il im in"><blockquote class="oz"><p id="afef" class="pa pb iq bd pc pd pe pf pg ph pi lm dk translated">希望你喜欢这个教程。感谢阅读..！</p></blockquote></div></div>    
</body>
</html>