<html>
<head>
<title>Collaborative Filtering and Embeddings — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">协作过滤和嵌入—第2部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/collaborative-filtering-and-embeddings-part-2-919da17ecefb?source=collection_archive---------3-----------------------#2017-12-28">https://towardsdatascience.com/collaborative-filtering-and-embeddings-part-2-919da17ecefb?source=collection_archive---------3-----------------------#2017-12-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/74d16d3a880ffba1f735b8cd032b2b96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*whXK5j18xk_6qRmxqxbEag.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Movie embeddings</figcaption></figure><p id="768e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在第一部分的<a class="ae ld" rel="noopener" target="_blank" href="/collaborative-filtering-and-embeddings-part-1-63b00b9739ce">中，我已经介绍了<strong class="kh iu">协同过滤</strong>背后的基本思想以及<strong class="kh iu">嵌入</strong>和<strong class="kh iu">偏差</strong>的概念。建议您在继续之前阅读该帖子。</a></p><p id="f7e1" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><a class="ae ld" rel="noopener" target="_blank" href="/collaborative-filtering-and-embeddings-part-1-63b00b9739ce"> <strong class="kh iu">协同过滤和嵌入—第一部分</strong> </a></p><p id="78a8" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">在这一部分，我将讨论我们如何使用由<a class="le lf ep" href="https://medium.com/u/34ab754f8c5e?source=post_page-----919da17ecefb--------------------------------" rel="noopener" target="_blank">杰瑞米·霍华德</a> <strong class="kh iu"> </strong>等人开发的一个名为<a class="ae ld" href="https://github.com/fastai/fastai/tree/master/fastai" rel="noopener ugc nofollow" target="_blank"> <strong class="kh iu"> fastai </strong> </a>的库来实现协同过滤。这个库建立在<a class="ae ld" href="http://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh iu"> pytorch </strong> </a>的基础上，专注于更容易实现的<strong class="kh iu">机器学习和深度学习模型</strong>。</p><p id="104f" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">此外，我们将了解如何使用<a class="ae ld" href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" rel="noopener ugc nofollow" target="_blank"><strong class="kh iu">【t-SNE】</strong></a><strong class="kh iu"/><a class="ae ld" href="https://plot.ly/" rel="noopener ugc nofollow" target="_blank"><strong class="kh iu"/></a><strong class="kh iu">和</strong><a class="ae ld" href="https://bokeh.pydata.org/en/latest/" rel="noopener ugc nofollow" target="_blank"><strong class="kh iu">Bokeh</strong></a><strong class="kh iu"/>(<em class="lg">Python交互式可视化库，面向现代web浏览器进行演示</em>)。</p><p id="187f" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这篇文章中提出的大多数想法都来自于<a class="ae ld" href="http://course.fast.ai/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh iu">深度学习MOOC </strong> </a> - <strong class="kh iu"> v2 </strong>由<strong class="kh iu">杰瑞米·霍华德</strong>作为<a class="ae ld" href="https://www.usfca.edu/data-institute" rel="noopener ugc nofollow" target="_blank"> <strong class="kh iu">数据研究所</strong> </a> <strong class="kh iu">的一部分进行的。这篇文章只是我尝试分享我在这个课程中学到的一些惊人的东西。</strong></p><h1 id="7438" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">资料组</h1><p id="88d5" class="pw-post-body-paragraph kf kg it kh b ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky mj la lb lc im bi translated">我用过<a class="ae ld" href="https://grouplens.org/datasets/movielens/" rel="noopener ugc nofollow" target="_blank"><strong class="kh iu">movie lens</strong></a><strong class="kh iu">【1】</strong>数据集(<a class="ae ld" href="http://files.grouplens.org/datasets/movielens/ml-latest-small.zip" rel="noopener ugc nofollow" target="_blank"> ml-latest-small </a>)。该数据集描述了来自电影推荐服务<a class="ae ld" href="http://movielens.org/" rel="noopener ugc nofollow" target="_blank"> MovieLens </a>的<strong class="kh iu">五星</strong>评级和自由文本标记活动。它包含<strong class="kh iu"> 100004评级</strong>和<strong class="kh iu"> 1296标签应用</strong>横跨<strong class="kh iu"> 9125部电影</strong>。这些数据是由<strong class="kh iu"> 671位用户</strong>在1995年1月09日至2016年10月16日之间创建的。</p><p id="9336" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们将使用两个文件:<code class="fe mk ml mm mn b">ratings.csv</code>和<code class="fe mk ml mm mn b">movies.csv</code></p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="8d7d" class="lh li it bd lj lk mv lm ln lo mw lq lr ls mx lu lv lw my ly lz ma mz mc md me bi translated">使用fastai的协同过滤</h1><p id="0d49" class="pw-post-body-paragraph kf kg it kh b ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky mj la lb lc im bi translated">开始之前，我们需要两件东西:</p><ul class=""><li id="c12f" class="na nb it kh b ki kj km kn kq nc ku nd ky ne lc nf ng nh ni bi translated">支持GPU的机器(本地或AWS)</li><li id="873c" class="na nb it kh b ki nj km nk kq nl ku nm ky nn lc nf ng nh ni bi translated">在你的机器上安装fastai库:<code class="fe mk ml mm mn b">pip install fastai</code></li></ul><p id="d668" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">注意:在这篇文章的最后，我已经详细解释了如何为fastai设置你的系统</p><p id="e468" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">下面是使用fastai实现的一步一步的代码演练。底层算法和我们在<a class="ae ld" href="https://medium.com/p/63b00b9739ce/edit" rel="noopener"> <strong class="kh iu">第一部分</strong> </a>讨论过的一样。</p><h2 id="4ffc" class="no li it bd lj np nq dn ln nr ns dp lr kq nt nu lv ku nv nw lz ky nx ny md nz bi translated">步骤1:数据加载</h2><figure class="oa ob oc od gt ju"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="50aa" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们正在看2个文件:<strong class="kh iu">收视率和电影</strong></p><figure class="oa ob oc od gt ju gh gi paragraph-image"><div class="gh gi og"><img src="../Images/7fab7bdab374ce5024f44a4ddc643c44.png" data-original-src="https://miro.medium.com/v2/resize:fit:494/format:webp/0*FNk6VplhL7NMEqhW.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Figure 1: Ratings</figcaption></figure><p id="28ce" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh iu">评分</strong>包含不同用户对不同电影的评分。</p><figure class="oa ob oc od gt ju gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/d5899cf0e493e6d6ee3924fdde03a8bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/0*pep-bMuYv7G5vhp2.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Figure 2: Movies</figcaption></figure><p id="1e74" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh iu">电影</strong>包含关于电影的元数据。<code class="fe mk ml mm mn b">movieid</code>是连接2个数据集的关键。</p><h2 id="8a1f" class="no li it bd lj np nq dn ln nr ns dp lr kq nt nu lv ku nv nw lz ky nx ny md nz bi translated">第二步:模特训练</h2><pre class="oa ob oc od gt oi mn oj ok aw ol bi"><span id="2b8b" class="no li it mn b gy om on l oo op">#fastai function<br/><strong class="mn iu">val_idxs = get_cv_idxs(len(ratings))</strong> #get validation indices </span></pre><p id="9cba" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们将把数据分为训练集和验证集。我们的验证是原始数据集的20%。</p><pre class="oa ob oc od gt oi mn oj ok aw ol bi"><span id="66d0" class="no li it mn b gy om on l oo op"><strong class="mn iu">wd=2e-4</strong> #weight decay<br/><strong class="mn iu">n_factors</strong> = 50 #dimension of embedding vector</span></pre><p id="3ff4" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们将使用<a class="ae ld" href="https://metacademy.org/graphs/concepts/weight_decay_neural_networks#focus=weight_decay_neural_networks&amp;mode=learn" rel="noopener ugc nofollow" target="_blank"> <strong class="kh iu">重量衰减</strong> </a>来减少<strong class="kh iu">过度拟合</strong>。我们还必须定义我们的<strong class="kh iu">嵌入向量</strong>的维度。</p><pre class="oa ob oc od gt oi mn oj ok aw ol bi"><span id="445c" class="no li it mn b gy om on l oo op">#fastai function<br/><strong class="mn iu">cf = CollabFilterDataset.from_csv(path, 'ratings.csv', 'userId', 'movieId', 'rating')</strong> #creating a custom data loader</span></pre><p id="6ec9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">现在我们必须为协同过滤创建一个数据对象。你可以把它看作是将原始数据转换成模型所要求的形式的东西。<code class="fe mk ml mm mn b">from_csv</code>意味着输入应该是一个<strong class="kh iu"> csv文件</strong>。</p><p id="445b" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">函数的参数:</p><ul class=""><li id="585c" class="na nb it kh b ki kj km kn kq nc ku nd ky ne lc nf ng nh ni bi translated"><code class="fe mk ml mm mn b">path</code>:CSV文件的位置路径</li><li id="d767" class="na nb it kh b ki nj km nk kq nl ku nm ky nn lc nf ng nh ni bi translated"><code class="fe mk ml mm mn b">ratings.csv</code>:CSV文件的名称。它应该是图1所示的<strong class="kh iu">长格式</strong></li><li id="a9ee" class="na nb it kh b ki nj km nk kq nl ku nm ky nn lc nf ng nh ni bi translated"><code class="fe mk ml mm mn b">userID/movieID</code>:2个实体的列名</li><li id="3f2b" class="na nb it kh b ki nj km nk kq nl ku nm ky nn lc nf ng nh ni bi translated"><code class="fe mk ml mm mn b">rating</code>:要预测的因变量的列名</li></ul><pre class="oa ob oc od gt oi mn oj ok aw ol bi"><span id="7dc4" class="no li it mn b gy om on l oo op">#create a learner (model) and specify the batch size and optimizer <br/><strong class="mn iu">learn = cf.get_learner(n_factors, val_idxs, 64, opt_fn=optim.Adam) </strong><br/>#fastai function</span></pre><p id="7922" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">下一步是创建一个模型对象，它是我们已经创建的数据对象的函数。<code class="fe mk ml mm mn b">learner</code>在fastai库中与model同义。该函数采用以下参数:</p><ul class=""><li id="4042" class="na nb it kh b ki kj km kn kq nc ku nd ky ne lc nf ng nh ni bi translated"><code class="fe mk ml mm mn b">n_factors</code>:嵌入向量的维数(在我们的例子中为<strong class="kh iu">50</strong></li><li id="2d42" class="na nb it kh b ki nj km nk kq nl ku nm ky nn lc nf ng nh ni bi translated"><code class="fe mk ml mm mn b">val_idxs</code>:验证时必须考虑的ratings.csv文件中的行索引</li><li id="6d58" class="na nb it kh b ki nj km nk kq nl ku nm ky nn lc nf ng nh ni bi translated"><code class="fe mk ml mm mn b">batch size</code>:梯度下降的每一步传递给优化器的行数。在我们的例子中，每次迭代将传递64行数据</li><li id="4930" class="na nb it kh b ki nj km nk kq nl ku nm ky nn lc nf ng nh ni bi translated"><code class="fe mk ml mm mn b">opt_fn</code>:我们想要使用的优化器。在我们的例子中我们使用的是<a class="ae ld" href="http://ruder.io/optimizing-gradient-descent/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh iu">亚当</strong> </a> <strong class="kh iu">。在这个库中，你可以访问不同的优化器</strong></li></ul><figure class="oa ob oc od gt ju gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/5763efb55887bc483960a9dc8ec9d6ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:272/format:webp/0*lgXXFb4_R0IVzmkU.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Figure 3: Optimisers</figcaption></figure><pre class="oa ob oc od gt oi mn oj ok aw ol bi"><span id="fd24" class="no li it mn b gy om on l oo op">#training with learning rate as 1e-2 <br/><strong class="mn iu">learn.fit(1e-2, 2, wds=wd, cycle_len=1, cycle_mult=2, use_wd_sched=True)</strong> <br/>#fastai function</span></pre><p id="4745" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">训练的最后一步是实际训练模型。在<code class="fe mk ml mm mn b">learner</code>对象上调用<code class="fe mk ml mm mn b">fit</code>训练模型并学习嵌入和偏置矩阵中的<strong class="kh iu">正确值。</strong></p><p id="3881" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">函数的参数:</p><ul class=""><li id="301e" class="na nb it kh b ki kj km kn kq nc ku nd ky ne lc nf ng nh ni bi translated"><code class="fe mk ml mm mn b">learning rate</code> : 1e-2是我们用于优化的学习率</li><li id="c6a9" class="na nb it kh b ki nj km nk kq nl ku nm ky nn lc nf ng nh ni bi translated"><code class="fe mk ml mm mn b">wd</code>:通过重量衰减</li><li id="3ef8" class="na nb it kh b ki nj km nk kq nl ku nm ky nn lc nf ng nh ni bi translated"><code class="fe mk ml mm mn b">cycle_len/cycle_mult</code>:这些是fastai的好东西，整合了最先进的<strong class="kh iu">学习率计划</strong>方法。<em class="lg">帖子末尾包含与此相关的有用文章的链接。</em></li><li id="b4f8" class="na nb it kh b ki nj km nk kq nl ku nm ky nn lc nf ng nh ni bi translated"><code class="fe mk ml mm mn b">use_wd_sched</code>:是否使用体重衰减时间表</li></ul><p id="33a1" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">当您运行上面的代码时，模型将开始训练，如下所示。您可以在每个时期后观察<strong class="kh iu">训练(左)和验证(右)损失</strong>。我们优化的损失函数是<code class="fe mk ml mm mn b">MSE (Mean squared error)</code>。</p><figure class="oa ob oc od gt ju gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/068a59be5875c4ec7fecffb995570ea0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/0*RnWhSpnnVxmTZcd7.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Figure 4: Model training</figcaption></figure><h2 id="99dd" class="no li it bd lj np nq dn ln nr ns dp lr kq nt nu lv ku nv nw lz ky nx ny md nz bi translated">步骤3:验证预测</h2><pre class="oa ob oc od gt oi mn oj ok aw ol bi"><span id="0e8e" class="no li it mn b gy om on l oo op"><strong class="mn iu">preds = learn.predict()</strong> #prediction on validation<br/><strong class="mn iu">math.sqrt(metrics.mean_squared_error(y,preds))</strong> #calculating RMSE</span></pre><p id="8c7a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们将使用训练好的模型来预测验证并计算<strong class="kh iu"> RMSE </strong>。我们得到了一个<strong class="kh iu"> ~.90 </strong>的RMSE，与该数据集的当前<a class="ae ld" href="https://www.librec.net/release/v1.3/example.html" rel="noopener ugc nofollow" target="_blank">基准</a>相当。</p><pre class="oa ob oc od gt oi mn oj ok aw ol bi"><span id="e8bb" class="no li it mn b gy om on l oo op"><strong class="mn iu">y=learn.data.val_y</strong> #actual ratings for validation<br/><strong class="mn iu">sns.jointplot(preds, y, kind='hex', stat_func=None);</strong></span></pre><figure class="oa ob oc od gt ju gh gi paragraph-image"><div class="gh gi or"><img src="../Images/daaf061f085c07d9f2057a3c43624d04.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/0*mZvGj8YZGrDg9P0g.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Figure 5: Predictions (y) vs Actual (x) (Ratings)</figcaption></figure><p id="2995" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们还可以看到，我们从模型预测与实际收视率相符。</p><p id="0b3a" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">现在，我们将尝试解释嵌入和偏见，看看它们是否捕捉到一些有意义的信息。</p></div><div class="ab cl mo mp hx mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="im in io ip iq"><h1 id="c5e7" class="lh li it bd lj lk mv lm ln lo mw lq lr ls mx lu lv lw my ly lz ma mz mc md me bi translated">解释嵌入和偏见</h1><p id="acb4" class="pw-post-body-paragraph kf kg it kh b ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky mj la lb lc im bi translated">我们将把重点放在电影的嵌入和偏见上，因为我们有电影的<strong class="kh iu">实际名称</strong>。</p><h2 id="3574" class="no li it bd lj np nq dn ln nr ns dp lr kq nt nu lv ku nv nw lz ky nx ny md nz bi translated">电影嵌入</h2><p id="fa73" class="pw-post-body-paragraph kf kg it kh b ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky mj la lb lc im bi translated">我们知道我们的嵌入向量的维数是<strong class="kh iu"> 50 </strong>。可视化这样的高维向量是困难的，几乎是不可能的。</p><p id="0ce8" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><a class="ae ld" href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" rel="noopener ugc nofollow" target="_blank"><strong class="kh iu">t-分布式随机邻居嵌入(t-SNE) </strong> </a>是一种有效的方法，可以在较低的维度上可视化它们，同时保持这些向量之间的<strong class="kh iu">空间关系</strong>。</p><figure class="oa ob oc od gt ju"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="0d31" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">使用上面的代码，我已经将嵌入向量的维数减少到<strong class="kh iu"> 2 (t-SNE分量)</strong>。下面我们可以看到为3000部电影嵌入的2个t-SNE组件。每个点代表一部电影。</p><figure class="oa ob oc od gt ju gh gi paragraph-image"><div class="gh gi os"><img src="../Images/f399671b38f6f607bdf65be02c28247b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/0*2h2lEMHCLOsZCXq8.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">y-tsne vs x-tsne components of embedding vectors (3000 movies)</figcaption></figure><p id="b0e6" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">你可以在这里玩这个剧情:<a class="ae ld" href="http://tsne.getforge.io/" rel="noopener ugc nofollow" target="_blank"><strong class="kh iu">http://tsne.getforge.io/</strong></a></p><p id="8b64" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">进一步放大我们可以看到来自同一个系列的<strong class="kh iu">电影在<strong class="kh iu">嵌入空间</strong>非常接近(几乎重叠)。这表明嵌入不仅仅是为了减少损失而优化的一些数字。</strong></p><blockquote class="ot ou ov"><p id="e510" class="kf kg lg kh b ki kj kk kl km kn ko kp ow kr ks kt ox kv kw kx oy kz la lb lc im bi translated">我们希望同一个系列的电影在风格、导演、演员等方面或多或少有些相似。嵌入空间的紧密性反映了嵌入正在捕捉这些特征</p></blockquote><figure class="oa ob oc od gt ju gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/995700c899a880f3a92915092e385f6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*IxrvCYRuOXFeuKshzfpOBg.png"/></div></figure><figure class="oa ob oc od gt ju gh gi paragraph-image"><div class="gh gi pa"><img src="../Images/6252910baefa6c63988a665b649192b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*s_HeWq2usWRkVrkAb7LOUg.png"/></div></figure><figure class="oa ob oc od gt ju gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/be9cd69cd730d769cdc88d0f2680aa04.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*i_rqIKEMvPsjfeKtMmu2hQ.png"/></div></figure><h2 id="06aa" class="no li it bd lj np nq dn ln nr ns dp lr kq nt nu lv ku nv nw lz ky nx ny md nz bi translated">电影偏见</h2><p id="cc0b" class="pw-post-body-paragraph kf kg it kh b ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky mj la lb lc im bi translated">电影偏差可以被认为是对电影实际质量的一种度量<strong class="kh iu">，针对不同用户的不同分级模式进行调整</strong>。</p><blockquote class="ot ou ov"><p id="61b9" class="kf kg lg kh b ki kj kk kl km kn ko kp ow kr ks kt ox kv kw kx oy kz la lb lc im bi translated">偏见可以被认为是电影实际上有多好/受欢迎的代表</p></blockquote><p id="70ae" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">让我们看看这是否反映在我们模型的偏差中</p><figure class="oa ob oc od gt ju"><div class="bz fp l di"><div class="oe of l"/></div></figure><figure class="oa ob oc od gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi pc"><img src="../Images/041534248aef4b78f983a3ba30415689.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*l1WQoCmoiAc1-utl.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Bottom 15 movies based on bias</figcaption></figure><figure class="oa ob oc od gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi pc"><img src="../Images/cb01b55bc58dce31daafe80a45ebd996.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pOcNREGkGJ-aIlzE.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Top 15 movies based on bias</figcaption></figure><p id="9117" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">看着这个列表，我想大多数人都会同意这个列表看起来或多或少是合适的，并且更接近我们的大多数期望。</p><blockquote class="ot ou ov"><p id="9163" class="kf kg lg kh b ki kj kk kl km kn ko kp ow kr ks kt ox kv kw kx oy kz la lb lc im bi translated">基于偏见对电影进行排名比仅仅平均所有用户给出的评级更有意义。与名字相反，它实际上使排名不偏不倚</p></blockquote><h2 id="a6ce" class="no li it bd lj np nq dn ln nr ns dp lr kq nt nu lv ku nv nw lz ky nx ny md nz bi translated">嵌入聚类(基于评级)</h2><p id="5d03" class="pw-post-body-paragraph kf kg it kh b ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky mj la lb lc im bi translated">对我来说，这是最有趣的部分。下面我挑选了一个评价电影数量最多的用户(<strong class="kh iu"> userID:547 </strong>)。现在我在尝试看看用户给出的评分和不同电影的嵌入向量之间有没有什么看得见的关系。</p><figure class="oa ob oc od gt ju"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="05f0" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">猜猜看…</p><figure class="oa ob oc od gt ju gh gi paragraph-image"><div class="gh gi pd"><img src="../Images/7aad4ae253145fa7f4f86b43563579e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*UXuShItw0aQrbv7jJzEp0w.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">t-SNE components of movie embeddings clustered by ratings (userID: 547)</figcaption></figure><p id="7761" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">很明显，<strong class="kh iu">高评级(黑与红)</strong>的电影集中在嵌入空间的一部分。类似地，那些<strong class="kh iu">等级低的电影(绿色和蓝色</strong>)集中在空间的另一部分。</p><p id="80f9" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><em class="lg">链接到html文件的情节。下载并在浏览器中打开:</em><a class="ae ld" href="https://github.com/shik3519/collaborative-filtering/blob/master/t-SNE_cluster_rating.html" rel="noopener ugc nofollow" target="_blank">https://github . com/shik 3519/collaborative-filtering/blob/master/t-SNE _ cluster _ rating . html</a></p><h2 id="e70b" class="no li it bd lj np nq dn ln nr ns dp lr kq nt nu lv ku nv nw lz ky nx ny md nz bi translated">嵌入聚类(基于偏差)</h2><p id="af0c" class="pw-post-body-paragraph kf kg it kh b ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky mj la lb lc im bi translated">类似地，我也尝试过根据电影偏好对电影嵌入进行聚类。<strong class="kh iu">期望具有相似偏差(如所讨论的无偏流行度的度量)的电影在嵌入空间中应该是接近的。</strong></p><figure class="oa ob oc od gt ju"><div class="bz fp l di"><div class="oe of l"/></div></figure><p id="b69b" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我们可以在下图中看到。</p><figure class="oa ob oc od gt ju gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/e93019add07ce62072e06d5c85c27949.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*KK9w3ZmzJb9Tlb4sLE1xPw.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">t-SNE components of movie embeddings (clustered by movie bias)</figcaption></figure><blockquote class="ot ou ov"><p id="dc19" class="kf kg lg kh b ki kj kk kl km kn ko kp ow kr ks kt ox kv kw kx oy kz la lb lc im bi translated">好(或坏)的电影都有一些共同的特征，这些特征被嵌入捕捉到了</p></blockquote><p id="287e" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><em class="lg">链接到绘图的html文件。下载并在浏览器中打开:</em><a class="ae ld" href="https://github.com/shik3519/collaborative-filtering/blob/master/t-SNE_emb_cluster_bias.html" rel="noopener ugc nofollow" target="_blank">https://github . com/shik 3519/collaborative-filtering/blob/master/t-SNE _ emb _ cluster _ bias . html</a></p><p id="6737" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">我觉得很新奇，所以我试着想象电影嵌入的三个t-SNE组件。每个点代表一部电影，点的大小和颜色取决于偏差。</p><figure class="oa ob oc od gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi pf"><img src="../Images/b86de1fe5ac4a3fe9ba531409b197fbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*67LN133v__ICWqz41_XrBg.png"/></div></div></figure><p id="7146" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">下面是实际剧情的链接:<strong class="kh iu"/><a class="ae ld" href="https://plot.ly/~shik1470/2/" rel="noopener ugc nofollow" target="_blank">https://plot.ly/~shik1470/2/</a></p><p id="e807" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">链接到用于此图的数据:<a class="ae ld" href="https://github.com/shik3519/collaborative-filtering/blob/master/t-sne1.csv" rel="noopener ugc nofollow" target="_blank">https://github . com/shik 3519/collaborative-filtering/blob/master/t-SNE 1 . CSV</a></p><h1 id="45e7" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">最后的想法</h1><p id="5a75" class="pw-post-body-paragraph kf kg it kh b ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky mj la lb lc im bi translated">到现在为止，我想你会有点相信嵌入的想法是非常强大的。这个概念可以扩展到任何有大量分类变量的结构化数据问题。</p><blockquote class="ot ou ov"><p id="0369" class="kf kg lg kh b ki kj kk kl km kn ko kp ow kr ks kt ox kv kw kx oy kz la lb lc im bi translated">分类变量的每一级可以被表示为高维向量，该向量可以捕获标签或一位热码编码未能捕获的关系。标签或一个热编码假设每个实体都是相互独立的，如果你仔细想想，肯定不是这样。</p></blockquote><p id="ef46" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">这是另一个关于在结构化环境中使用嵌入的很酷的帖子，你一定要看看。</p><div class="pg ph gp gr pi pj"><a rel="noopener follow" target="_blank" href="/structured-deep-learning-b8ca4138b848"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd iu gy z fp po fr fs pp fu fw is bi translated">结构化深度学习</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">快的</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">towardsdatascience.com</p></div></div><div class="ps l"><div class="pt l pu pv pw ps px jz pj"/></div></div></a></div><h1 id="1f35" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">有用的资源</h1><ol class=""><li id="115c" class="na nb it kh b ki mf km mg kq py ku pz ky qa lc qb ng nh ni bi translated"><strong class="kh iu">学习率选择和调度:</strong></li></ol><div class="pg ph gp gr pi pj"><a href="https://techburst.io/improving-the-way-we-work-with-learning-rate-5e99554f163b" rel="noopener  ugc nofollow" target="_blank"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd iu gy z fp po fr fs pp fu fw is bi translated">提高我们的工作方式和学习速度。</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">一.导言</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">techburst.io</p></div></div><div class="ps l"><div class="qc l pu pv pw ps px jz pj"/></div></div></a></div><div class="pg ph gp gr pi pj"><a rel="noopener follow" target="_blank" href="/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd iu gy z fp po fr fs pp fu fw is bi translated">估计深度神经网络的最佳学习速率</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">学习率是用于训练深度神经网络的最重要的超参数之一。</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">towardsdatascience.com</p></div></div><div class="ps l"><div class="qd l pu pv pw ps px jz pj"/></div></div></a></div><div class="pg ph gp gr pi pj"><a href="https://medium.com/38th-street-studios/exploring-stochastic-gradient-descent-with-restarts-sgdr-fa206c38a74e" rel="noopener follow" target="_blank"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd iu gy z fp po fr fs pp fu fw is bi translated">探索重新开始的随机梯度下降(SGDR)</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">这是我第一篇深度学习的博文。我在2017年1月左右开始了我的深度学习之旅，在我听说了…</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">medium.com</p></div></div><div class="ps l"><div class="qe l pu pv pw ps px jz pj"/></div></div></a></div><p id="9ac8" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">2.t-SNE: </p><div class="pg ph gp gr pi pj"><a href="https://distill.pub/2016/misread-tsne/" rel="noopener  ugc nofollow" target="_blank"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd iu gy z fp po fr fs pp fu fw is bi translated">如何有效地使用t-SNE</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">一种流行的探索高维数据的方法叫做t-SNE，是由范德马滕和辛顿提出的…</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">蒸馏. pub</p></div></div><div class="ps l"><div class="qf l pu pv pw ps px jz pj"/></div></div></a></div><div class="pg ph gp gr pi pj"><a href="https://medium.com/@luckylwk/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b" rel="noopener follow" target="_blank"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd iu gy z fp po fr fs pp fu fw is bi translated">在Python中使用PCA和t-SNE可视化高维数据集</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">任何与数据相关的挑战的第一步都是从探索数据本身开始。这可以通过查看…</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">medium.com</p></div></div><div class="ps l"><div class="qg l pu pv pw ps px jz pj"/></div></div></a></div><div class="pg ph gp gr pi pj"><a href="https://www.kaggle.com/ykhorramz/lda-and-t-sne-interactive-visualization" rel="noopener  ugc nofollow" target="_blank"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd iu gy z fp po fr fs pp fu fw is bi translated">LDA和T-SNE交互式可视化</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">使用NIPS 2015论文中的数据</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">www.kaggle.com</p></div></div><div class="ps l"><div class="qh l pu pv pw ps px jz pj"/></div></div></a></div><figure class="oa ob oc od gt ju"><div class="bz fp l di"><div class="qi of l"/></div></figure><p id="0165" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">3.<strong class="kh iu">法斯泰:</strong></p><ul class=""><li id="abdb" class="na nb it kh b ki kj km kn kq nc ku nd ky ne lc nf ng nh ni bi translated">【https://github.com/fastai/fastai】Github回购库:<a class="ae ld" href="https://github.com/fastai/fastai" rel="noopener ugc nofollow" target="_blank">T7】</a></li><li id="9a6d" class="na nb it kh b ki nj km nk kq nl ku nm ky nn lc nf ng nh ni bi translated"><a class="ae ld" href="https://github.com/fastai/fastai/blob/master/courses/dl1/lesson5-movielens.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="kh iu"> fastai笔记本上的协同过滤</strong> </a></li></ul><p id="1fcf" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh iu">设置fastai的说明:</strong></p><figure class="oa ob oc od gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi qj"><img src="../Images/cb9a29f6bf7d908b3c2903250bc8d661.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qa-oZI62PVzOmfP7LR3Djg.png"/></div></div></figure><figure class="oa ob oc od gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi qk"><img src="../Images/c62e61cba0925d7ad894af54a38a2d3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I-cLwAhcS0WKmlVI3joc6Q.png"/></div></div></figure><p id="76de" class="pw-post-body-paragraph kf kg it kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated">4.<a class="ae ld" href="https://github.com/shik3519/collaborative-filtering" rel="noopener ugc nofollow" target="_blank"> <strong class="kh iu">本帖GitHub回购</strong> </a> <strong class="kh iu"> : </strong>本回购包含本帖中显示的笔记本和剧情</p><h1 id="f4ed" class="lh li it bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">参考文献和引文</h1><p id="e1c6" class="pw-post-body-paragraph kf kg it kh b ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky mj la lb lc im bi translated">[1] F .麦克斯韦·哈珀和约瑟夫·康斯坦。2015.电影镜头数据集:历史和背景。ACM交互式智能系统汇刊(TiiS) 5，4，第19篇(2015年12月)，19页。http://dx.doi.org/10.1145/2827872</p></div></div>    
</body>
</html>