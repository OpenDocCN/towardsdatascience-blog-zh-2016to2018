<html>
<head>
<title>ResNet for Traffic Sign Classification With PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch在交通标志分类中的应用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/resnet-for-traffic-sign-classification-with-pytorch-5883a97bbaa3?source=collection_archive---------6-----------------------#2018-02-26">https://towardsdatascience.com/resnet-for-traffic-sign-classification-with-pytorch-5883a97bbaa3?source=collection_archive---------6-----------------------#2018-02-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/bc0b3b631e363bcf1ef977bb3e163830.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IF58XADcG46rwFDeHEp_fg.jpeg"/></div></div></figure><p id="5c55" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae kw" href="http://benchmark.ini.rub.de/?section=gtsrb&amp;subsection=about" rel="noopener ugc nofollow" target="_blank">德国交通标志识别基准数据集</a>可能是与自动驾驶汽车相关的最流行的图像分类。自动驾驶汽车需要检测和分类交通标志，以理解应用于一段道路的交通规则。也许，这个数据集太小，不够完整，不能用于实际应用。然而，它是计算机视觉算法的一个很好的基准。</p><h1 id="bb9b" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">资料组</h1><p id="9604" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">数据集由两部分组成:训练集和测试集。训练集包含39209幅交通标志图像，分为43类，如停车标志、自行车穿越和限速30公里/小时</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/788570acfc88572a8988e8e2baafc04b.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*h5aLplGNALniYVqq4Dk32w.png"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk">Examples of German Traffic Sign Recognition Dataset images</figcaption></figure><p id="160b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">数据集非常不平衡。例如，有1800个“速度限制(50公里/小时)”标志的实例，但只有168个“向左转弯危险”标志的实例。</p><p id="184c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">测试集有12630个标记图像。这些图像被用于2011年IJCNN竞赛的评估。</p><p id="602c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你可以从<a class="ae kw" href="http://benchmark.ini.rub.de/?section=gtsrb&amp;subsection=dataset" rel="noopener ugc nofollow" target="_blank">官网</a>下载数据集。</p><h1 id="a644" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">方法</h1><p id="222c" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">我尝试使用在ImageNet数据集上预先训练的<a class="ae kw" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"> ResNet34 </a>卷积神经网络进行迁移学习。</p><p id="9a4a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我在fast.ai 最新版<a class="ae kw" href="http://course.fast.ai/" rel="noopener ugc nofollow" target="_blank">《程序员深度学习》课程中学到的解决计算机视觉问题的通用方法。我去年在旧金山大学参加了那个课程的离线版本。课程使用了</a><a class="ae kw" href="https://github.com/fastai/fastai" rel="noopener ugc nofollow" target="_blank"> fastai </a>，一个基于PyTorch构建的深度学习库。它为训练深度学习模型提供了易于使用的构建模块。</p><p id="c420" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我花了大部分时间优化超参数和调整图像增强。</p><h1 id="9ed3" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">密码</h1><p id="f796" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">我<a class="ae kw" href="https://github.com/surmenok/GTSRB" rel="noopener ugc nofollow" target="_blank">在GitHub上发布了</a>我的代码。您可以下载一个<a class="ae kw" href="https://github.com/surmenok/GTSRB/blob/master/german-traffic-signs.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a>，它包含了从下载数据集到基于未标记的测试集创建提交文件的所有步骤。训练CNN模型的代码大多基于<a class="ae kw" href="http://course.fast.ai/" rel="noopener ugc nofollow" target="_blank"> fast.ai课程</a>的CNN课程。</p><p id="b751" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们来看看训练和评估模型的步骤。</p><h1 id="b037" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">准备</h1><p id="4d60" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">准备环境。我必须安装<a class="ae kw" href="https://github.com/fastai/fastai" rel="noopener ugc nofollow" target="_blank"> fastai </a>库及其所有依赖项。</p><p id="e254" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下载数据集，解包。将训练集(39209个图像)拆分为训练集和验证集，并将文件移动到正确的文件夹中。我用80%的样本进行训练，20%的样本进行验证。</p><p id="7912" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">小心分裂。该数据集包含每个物理交通标志的30张照片。根据文件名区分不同的系列是很容易的。如果您只是随机拆分数据集，那么将会有信息从验证集泄漏到训练集。</p><p id="1b9c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我一开始就犯了这个错误。我随机分割数据集，得到了超过99.6%的惊人的验证准确率。当测试准确率只有87%时，我很惊讶:测试准确率和验证准确率之间的巨大差异是验证集设计不良或过度适应验证集的标志。</p><p id="dc30" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">正确的方法是找到图像系列，并将每个系列完全放入训练集或验证集中，确保它不会分成两部分。要了解更多关于创建好的验证集的信息，请阅读<a class="ae kw" href="http://www.fast.ai/2017/11/13/validation-sets/" rel="noopener ugc nofollow" target="_blank">的这篇文章</a>，作者<a class="ae kw" href="https://twitter.com/math_rachel?lang=en" rel="noopener ugc nofollow" target="_blank">雷切尔·托马斯</a>。</p><h1 id="2e0d" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">探索性分析</h1><p id="9865" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">浏览数据集。检查班级的分布，看看每个班级的一些图片示例。</p><p id="c2b5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">图像有不同的大小。看看尺寸的直方图。它将让您了解CNN的输入维度应该是多少。</p><h1 id="d9d6" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">培养</h1><p id="3049" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">加载在ImageNet数据集上预先训练的ResNet34模型。删除最后一层，并在顶部添加一个新的softmax层。</p><figure class="mb mc md me gt jr"><div class="bz fp l di"><div class="mj mk l"/></div></figure><p id="f023" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我的一般训练方法是:从一个小的模型输入(我从32x32的图像尺寸开始)和一个短的训练程序(总共7个时期)开始，以优化训练速度。你需要快速迭代。理想情况下，实验不应该超过几分钟。</p><p id="52ee" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，优化批量大小。在GPU内存允许的情况下，尽量增大批量大小。较大的批量有助于减少培训时间。但是，通过实验，我发现太大的批量(例如，1024个样本或更多)会导致较低的验证准确性。我猜模型很早就开始过度拟合了。我最后得到了一个批量256。</p><p id="d35d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">只有在你找到一组像样的超参数后，才切换到更大的图像和更长的细粒度训练。最后我用了96x96的图像，训练了19个纪元。</p><h2 id="8067" class="ml ky iq bd kz mm mn dn ld mo mp dp lh kj mq mr ll kn ms mt lp kr mu mv lt mw bi translated">图像增强</h2><p id="0a7a" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">设置图像增强。这是一种帮助模型更好地概括的技术。你在训练集中添加了很多人为的例子。这些例子是基于已经存在的例子，但是你稍微改变了它们:旋转几度，改变照明，放大，等等。</p><figure class="mb mc md me gt jr"><div class="bz fp l di"><div class="mj mk l"/></div></figure><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/a7381e341a36c19c3f1744afd2151467.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*MHuIZY_q4XLyGcIGLXoHTQ.png"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk">Examples of augmented images</figcaption></figure><p id="82fe" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我使用了以下变换的组合:旋转最大20度，光照变化最大80%，缩放最大20%。</p><p id="eebc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">灯光增强非常重要。在项目的早期阶段，我看到非常暗的图像有最不正确的预测。在照明增强方面的进取性将验证准确性提高了3%以上。通过直接改变R、G和B通道的值来改变照明。详见<a class="ae kw" href="https://github.com/fastai/fastai/blob/master/fastai/transforms.py" rel="noopener ugc nofollow" target="_blank"> RandomLighting </a>类。</p><p id="9641" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我尝试过并拒绝的其他东西:直方图均衡化以提高对比度，随机模糊，填充。</p><h2 id="937f" class="ml ky iq bd kz mm mn dn ld mo mp dp lh kj mq mr ll kn ms mt lp kr mu mv lt mw bi translated">学习率</h2><p id="03a4" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">使用这里描述的简单算法<a class="ae kw" rel="noopener" target="_blank" href="/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0"/>为训练搜索一个好的开始学习率。</p><figure class="mb mc md me gt jr"><div class="bz fp l di"><div class="mj mk l"/></div></figure><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi my"><img src="../Images/3ff46c99d5955aeba6e27ee26751c64c.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*q9BHX7NSewow4JxBWv_CZg.png"/></div></figure><h2 id="3cfa" class="ml ky iq bd kz mm mn dn ld mo mp dp lh kj mq mr ll kn ms mt lp kr mu mv lt mw bi translated">微调最后一层</h2><p id="d7e4" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">冻结除最后一层以外的所有层。以该学习速率训练一个时期的模型。以我为例，学习率是0.01。这里的目标是为最后一层获得合理的权重。如果我们不这样做，稍后训练一个未冻结的模型会导致更低的层混乱，因为梯度会更大。我尝试了这两个选项，训练一个时期的最后一层在验证准确性方面有大约1%的提高。我还使用了重量衰减来做一个小小的改进。</p><figure class="mb mc md me gt jr"><div class="bz fp l di"><div class="mj mk l"/></div></figure><h2 id="9f1d" class="ml ky iq bd kz mm mn dn ld mo mp dp lh kj mq mr ll kn ms mt lp kr mu mv lt mw bi translated">微调整个模型</h2><p id="5a9c" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">解冻所有层。训练三个时代。</p><figure class="mb mc md me gt jr"><div class="bz fp l di"><div class="mj mk l"/></div></figure><p id="2848" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然后使用<a class="ae kw" href="https://arxiv.org/abs/1608.03983" rel="noopener ugc nofollow" target="_blank">带热重启的随机梯度下降(SGDR) </a>训练几个时期。</p><figure class="mb mc md me gt jr"><div class="bz fp l di"><div class="mj mk l"/></div></figure><p id="3d5c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我尝试使用<a class="ae kw" href="https://arxiv.org/abs/1609.04747" rel="noopener ugc nofollow" target="_blank">区别性微调</a>，为模型的不同部分设置不同的学习率。在这种情况下，我们希望模型的第一层比最后一层训练得少。第一层比其他层更通用。当在ImageNet数据集上训练时，这些层学到了对我们的任务非常有用的模式，我们不想失去这些知识。另一方面，最后一层是非常特定于任务的，我们希望在我们的任务中重新训练它们。不幸的是，它对改进度量没有帮助。如果对所有层应用较大的学习率，模型的训练效果会更好。我猜这是因为交通标志与狗、猫和飞机非常不同，因此较低层的信息不像在其他计算机视觉应用中那样有用。</p><p id="d6d9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">验证集上最佳模型的准确率为99.0302%。</p><h2 id="5318" class="ml ky iq bd kz mm mn dn ld mo mp dp lh kj mq mr ll kn ms mt lp kr mu mv lt mw bi translated">误差分析</h2><p id="b9f6" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">除了像混淆矩阵这样的常用工具，您还可以通过检查一些极端情况来分析错误:最不正确的预测、最正确的预测、最不确定的预测。</p><p id="b0b7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">要查找每个类最不正确的预测，必须对验证集进行推理，并选择正确类的预测概率最小的示例。</p><figure class="mb mc md me gt jr"><div class="bz fp l di"><div class="mj mk l"/></div></figure><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/e5d28e54990d79ffed15f9b10040b0dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*aqFBgbcBD546Km-0bAwn3A.png"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk">Most incorrect images</figcaption></figure><p id="bec1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这些图像看起来太模糊太亮。</p><p id="6946" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">类似地，您可以找到将最高概率分配给正确类(“最正确”)的示例，以及正确类的概率接近1/num_classes(“最不确定”)的示例。</p><p id="b726" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此分析的结果有助于您调整图像增强参数，可能还有模型的一些超参数。</p><h2 id="d3ed" class="ml ky iq bd kz mm mn dn ld mo mp dp lh kj mq mr ll kn ms mt lp kr mu mv lt mw bi translated">在完整训练集上重新运行训练</h2><p id="9912" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">在之前的所有步骤中，我们将80%的训练集用于训练，20%用于验证。现在，由于我们发现了好的超参数，我们不再需要验证集，可以将这20%的图像添加到训练集中，以进一步改进模型。</p><p id="6f0c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这里，我只是使用相同的参数重新运行所有的训练步骤，但是使用所有32909个训练图像进行训练。</p><h1 id="557a" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">在测试集上测试</h1><p id="a5ca" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">测试集(12630幅图像)旨在测试最终模型的性能。我们没有在前面的步骤中查看测试集，以避免过度适应测试集。现在，我们可以在测试集上评估模型。我在测试集上获得了99.2953%的准确率。相当不错！我们能进一步改进它吗？</p><h1 id="ee38" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">测试时间增加</h1><p id="d92f" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">测试时间增强(TTA)通常有助于进一步提高精确度。诀窍是创建输入图像的几个增强版本，对每个版本进行预测，然后平均结果。这背后的直觉是，模型在分类一些图像时可能是错误的，但是稍微改变图像可以帮助模型更好地分类它。这就像如果一个人想对一个物体进行分类，他们从不同的角度看它，稍微改变一下照明，把它移到离眼睛更近的地方，直到他们能找到最有信心识别这个物体的最佳视角。</p><figure class="mb mc md me gt jr"><div class="bz fp l di"><div class="mj mk l"/></div></figure><p id="8917" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">的确，TTA帮我把准确率从99.2953%提高到了99.6120%。它将误差减少了45%(从0.7047%减少到0.388%)。</p><h1 id="f795" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">有多好？</h1><p id="1c24" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">测试集上的准确率为<strong class="ka ir"> 99.6120% </strong>。我们来对比几个基准。</p><p id="0927" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最先进的是由Mrinal Haloi 基于《T2》的CNN。99.81%.错误率比我好两倍。</p><p id="1b48" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">2011年IJCNN竞赛排行榜上的<a class="ae kw" href="http://benchmark.ini.rub.de/?section=gtsrb&amp;subsection=results#156ref" rel="noopener ugc nofollow" target="_blank">前几名:</a></p><ul class=""><li id="31cc" class="na nb iq ka b kb kc kf kg kj nc kn nd kr ne kv nf ng nh ni bi translated"><a class="ae kw" href="https://doi.org/10.1016/j.neunet.2018.01.005" rel="noopener ugc nofollow" target="_blank">Á·阿尔瓦罗阿科斯-加西亚等人制作的带3个空间转换器的CNN</a></li><li id="de2f" class="na nb iq ka b kb nj kf nk kj nl kn nm kr nn kv nf ng nh ni bi translated"><a class="ae kw" href="https://www.sciencedirect.com/science/article/pii/S0893608012000524?via%3Dihub" rel="noopener ugc nofollow" target="_blank">CNN委员会</a>由Dan Cireş an等人提出99.46%</li><li id="0f39" class="na nb iq ka b kb nj kf nk kj nl kn nm kr nn kv nf ng nh ni bi translated">用于物体识别的基于颜色斑点的COSFIRE过滤器作者:巴里斯·格瑟。98.97%</li></ul><p id="ac4d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果我的模特参加比赛，她会获得第二名。总的来说，几天的工作还不错。</p></div><div class="ab cl no np hu nq" role="separator"><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt nu"/><span class="nr bw bk ns nt"/></div><div class="ij ik il im in"><p id="71f4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来阅读:</p><div class="nv nw gp gr nx ny"><a rel="noopener follow" target="_blank" href="/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd ir gy z fp od fr fs oe fu fw ip bi translated">估计深度神经网络的最佳学习速率</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">学习率是用于训练深度神经网络的最重要的超参数之一。</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">towardsdatascience.com</p></div></div><div class="oh l"><div class="oi l oj ok ol oh om jw ny"/></div></div></a></div><div class="nv nw gp gr nx ny"><a href="https://medium.com/@surmenok/getting-started-with-nvidia-jetson-tx2-5952a2d8d7ae" rel="noopener follow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd ir gy z fp od fr fs oe fu fw ip bi translated">NVIDIA Jetson TX2入门</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">Jetson TX2是NVIDIA的一款高能效嵌入式人工智能计算设备。这是一台小型计算机，有一个信用卡那么大…</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">medium.com</p></div></div><div class="oh l"><div class="on l oj ok ol oh om jw ny"/></div></div></a></div><div class="nv nw gp gr nx ny"><a href="https://hackernoon.com/fast-ai-what-i-learned-from-lessons-1-3-b10f9958e3ff" rel="noopener  ugc nofollow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd ir gy z fp od fr fs oe fu fw ip bi translated">Fast.ai:我从第1-3课中学到了什么</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">Fast.ai是一个非常棒的深度学习课程，适合那些喜欢通过做来学习的人。与其他课程不同，在这里您将…</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">hackernoon.com</p></div></div><div class="oh l"><div class="oo l oj ok ol oh om jw ny"/></div></div></a></div></div></div>    
</body>
</html>