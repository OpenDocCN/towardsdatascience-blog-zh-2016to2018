<html>
<head>
<title>Collision Detection System using CoreML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 CoreML 的碰撞检测系统</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/collision-detection-system-using-coreml-f453923670a4?source=collection_archive---------15-----------------------#2017-08-02">https://towardsdatascience.com/collision-detection-system-using-coreml-f453923670a4?source=collection_archive---------15-----------------------#2017-08-02</a></blockquote><div><div class="fc ii ij ik il im"/><div class="in io ip iq ir"><div class=""/><p id="d84c" class="pw-post-body-paragraph jr js iu jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko in bi translated">最近在 WWDC 17，苹果推出了 CoreML 和 ARKit。这开启了无数的可能性，让数以百万计的人可以通过他们的手机来设计令人惊叹的应用程序。利用这些新技术，我们想为什么不设计一个可以在日常通勤中帮助每个人的应用程序。经过一番头脑风暴，我们决定建立一个驾驶辅助 dashcam 应用程序。</p><p id="7f32" class="pw-post-body-paragraph jr js iu jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko in bi translated">我们计划设计的驾驶员辅助应用程序将由一个碰撞检测管道组成，该管道将检测驾驶员是否会撞到车辆前方的障碍物。该应用程序将不断从相机中获取帧，检测每帧中的对象，找到每个对象的深度，传感器融合以计算车辆的速度和碰撞时间。</p><h1 id="83d6" class="kp kq iu bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated"><strong class="ak">物体检测:</strong></h1><p id="d62c" class="pw-post-body-paragraph jr js iu jt b ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk lr km kn ko in bi translated">从上面的讨论中，我们可以理解，解决这个问题的第一个里程碑是使对象检测算法在移动电话上工作。理想的算法应该以最高的精度预测障碍物，几乎实时运行，并且没有假阳性。基于这些要求，解决对象检测问题的最佳方法是使用深度学习算法。</p><p id="74a6" class="pw-post-body-paragraph jr js iu jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko in bi translated">以对象检测问题而闻名的深度学习算法有 R-CNN、快速 R-CNN、更快 R-CNN、YOLO、YOLO 9000、SSD、MobileNet SSD。</p><p id="c622" class="pw-post-body-paragraph jr js iu jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko in bi translated">经过一个月的头脑风暴和编码，我们使用 CoreML 框架实现了 YOLO，达到了目标检测的里程碑。</p><figure class="lt lu lv lw gu lx gi gj paragraph-image"><div class="gi gj ls"><img src="../Images/3405547ba5f89635d3bf86d16cc3a78b.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*LZpSGujJ8VlVgFzOr_9vZw.png"/></div><figcaption class="ma mb gk gi gj mc md bd b be z dk">Object Detection Prototype</figcaption></figure><p id="52df" class="pw-post-body-paragraph jr js iu jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko in bi translated">我们在下面的博客中记录了我们是如何完成这项任务的— <strong class="jt iv"> </strong> <a class="ae me" href="https://sriraghu.com/2017/07/12/computer-vision-in-ios-object-detection/" rel="noopener ugc nofollow" target="_blank"> <strong class="jt iv">链接</strong> </a>。</p><h1 id="27ca" class="kp kq iu bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">深度计算:</h1><p id="5060" class="pw-post-body-paragraph jr js iu jt b ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk lr km kn ko in bi translated">障碍物的深度可以定义为障碍物距离摄像机的距离。</p><figure class="lt lu lv lw gu lx gi gj paragraph-image"><div class="gi gj mf"><img src="../Images/75b650cea248675b24f2b14c3da38780.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*2RHrxoK3y96FOJ4VwSnL4A.png"/></div><figcaption class="ma mb gk gi gj mc md bd b be z dk">Depth (or) Distance of obstacle from car</figcaption></figure><p id="89de" class="pw-post-body-paragraph jr js iu jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko in bi translated">一般来说，深度可以通过一些特殊的硬件立即计算出来，这些硬件通常被称为 RGBD 相机。现在流行的消费级 RGBD 相机是微软的 Kinect (Xbox)。但另一方面，消费者手机没有深度传感器。它们只是 RGB 相机(又称单目视觉)。我们怎么计算深度呢？</p><p id="017a" class="pw-post-body-paragraph jr js iu jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko in bi translated">为了使用单目摄像机计算与汽车的距离，我们可以遵循以下策略之一</p><ol class=""><li id="fcb0" class="mg mh iu jt b ju jv jy jz kc mi kg mj kk mk ko ml mm mn mo bi translated">时间方法——根据图像中运动的时间顺序计算深度(例如:视觉里程计)</li><li id="92f1" class="mg mh iu jt b ju mp jy mq kc mr kg ms kk mt ko ml mm mn mo bi translated">每帧方法-其中在当前帧中计算的深度独立于先前的帧(例如:三角测量技术，或深度学习技术等)。)</li></ol><p id="129c" class="pw-post-body-paragraph jr js iu jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko in bi translated">在我们的例子中，我们现在选择了每帧三角测量法，并提出了一些数学公式，找到了计算汽车深度的方法。用我们的公式计算的深度在米的尺度上是精确的，但在厘米的尺度上就不那么精确了。因此，我们决定保持三级(安全、中等和危险)碰撞检测报警系统，而不是非常精确的深度精度。</p><h1 id="0dca" class="kp kq iu bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">传感器融合:</h1><p id="7b5d" class="pw-post-body-paragraph jr js iu jt b ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk lr km kn ko in bi translated">一旦我们从上述阶段计算出深度，我们将使用传感器融合来组合手机中的各种传感器，以获得我们汽车的速度。然后，我们在简单的运动学公式中使用它来计算特定帧中的 T.T.C(碰撞时间)。在研究人类对警报的平均反应时间的基础上，我们战略性地将 T.T.C .划分为警报系统的三个阶段。</p><p id="4cb0" class="pw-post-body-paragraph jr js iu jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko in bi translated">此外，假设用于检测汽车的算法是鲁棒的并且视野良好，那么我们很有可能在一帧中检测到许多汽车。在这种情况下，我们可能需要找到一辆我们将来可能会撞上的车。通过传感器融合，我们通过图像处理技术稳健地计算我们汽车的轨迹，将问题从'<em class="mu"> n </em>辆汽车归结为<strong class="jt iv"> 1 </strong>辆汽车，然后我们计算那辆特定汽车的 T.T.C。</p><figure class="lt lu lv lw gu lx gi gj paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gi gj mv"><img src="../Images/ecf2faf220b7400574460fbbc8fe4120.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0cr1eKU38JIgRqjYcxYxPg.png"/></div></div><figcaption class="ma mb gk gi gj mc md bd b be z dk">Trajectory of car estimation from sensor fusion and T.T.C</figcaption></figure><p id="24a7" class="pw-post-body-paragraph jr js iu jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko in bi translated">将这些放在一起，我们已经准备好了管道的基本工作演示，可以在下面的视频中看到。</p><figure class="lt lu lv lw gu lx"><div class="bz fq l di"><div class="na nb l"/></div><figcaption class="ma mb gk gi gj mc md bd b be z dk">Demo (Testing Phase)</figcaption></figure><h1 id="fdc4" class="kp kq iu bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">未来工作:</h1><p id="6a17" class="pw-post-body-paragraph jr js iu jt b ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk lr km kn ko in bi translated">在这篇博客中，我们展示了如何利用 CoreML、计算机视觉和传感器融合的力量来创建一个能够真正帮助人们日常通勤的应用程序。我们正在积极工作，使用深度学习技术或鲁棒的视觉惯性里程计技术来改进检测到的车辆的深度估计。此外，我们正在计划是否可以使用 iPhone 7 Plus(窄基线相机系统)中提供的两个相机的功率来估计深度。根据从两个不同视点(或两个相机)捕获的图像来估计场景中对象的深度的区域被称为“来自立体的深度”。这个领域是受人类视觉系统的启发而产生的，下图概括了我试图解释的内容。</p><figure class="lt lu lv lw gu lx gi gj paragraph-image"><div class="gi gj nc"><img src="../Images/5f81eda3dfa0a96b0c610285858a03ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*WXN-0jSmneFWymyVmsJ3SQ.png"/></div><figcaption class="ma mb gk gi gj mc md bd b be z dk">Depth estimation of objects through stereo vision</figcaption></figure><p id="0780" class="pw-post-body-paragraph jr js iu jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko in bi translated">感谢您阅读本博客，并请留下您对我们工作的评论/看法。我还要感谢苹果公司的 CoreML 团队，是他们惊人的 API 让这一切成为可能。</p></div></div>    
</body>
</html>