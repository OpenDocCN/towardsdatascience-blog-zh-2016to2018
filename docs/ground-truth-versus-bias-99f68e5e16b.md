# 基本事实与偏见

> 原文：<https://towardsdatascience.com/ground-truth-versus-bias-99f68e5e16b?source=collection_archive---------9----------------------->

![](img/ea334da56c48a8baca13043ee25f3295.png)

Photo by [David Kovalenko](https://unsplash.com/photos/G85VuTpw6jg?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/truth?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

机器学习的主要目标是在给定一组输入的情况下预测结果。在人工智能社区取得的惊人进展中，这个目标一直保持不变。几十年前的这些进步引导我们研究今天有趣的社会含义。具体来说，在我们的算法技术中嵌入的基本事实和偏见之间有一种独特而敏感的相互作用。

# 相互影响

基础事实是我们的模型用来训练和测试自己的标记结果。通过有监督的机器学习方法，我们的模型试图将输入与这一事实联系起来。也就是说，当我们命令脚本进行拟合和预测时，我们会做出一些假设。我们说，我们相信有一种关系存在，这些变量有一些预测能力，这些结束标签是最终的真相。

最后一点可能会有点模糊。

我们怎么知道末端标签是真实的呢？好吧，如果我们谈论的是试图预测温度，我们可以相当肯定的是，这些数字中有很多是真实的。也就是说，现在的温度传感技术既精确又准确。然而，如果我们预测某个人是否会得到贷款，或者某个人是否是 x 公司的合适人选呢？

这就是有趣的地方。在这些情况下，我们引入了偏见——人为的偏见，隐含的和未知的偏见。这些混杂的变量可以成就或破坏一个实验，这就是为什么人们大声疾呼在我们的算法中包含多样性。

我同意这个观点。然而，我也相信我们的算法是工具，不管数据集如何*多样化*，垃圾进垃圾出的概念仍然盛行。

也就是说，这是良好的第一步。我相信，提高算法可推广性的下一步是始终回到最初的、潜在的假设，并作为数据科学家批判性地评估它们。

我们真正要求算法做的是什么？有没有可以减轻偏差的来源

这些问题至关重要，尤其是当我们使用这些模型来筛选一组从事特定任务的人时。也许我们会在此期间发现一些关于我们自己的有趣的事情。

感谢阅读。