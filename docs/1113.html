<html>
<head>
<title>3 Things You Didn’t Know About Simple Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于简单线性回归你不知道的3件事</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/3-things-you-didnt-know-about-simple-linear-regression-b5a86362dd53?source=collection_archive---------5-----------------------#2017-07-30">https://towardsdatascience.com/3-things-you-didnt-know-about-simple-linear-regression-b5a86362dd53?source=collection_archive---------5-----------------------#2017-07-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="8714" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">线性回归将输入线性映射到输出。假设作为观测数据基础的数据生成过程是<em class="kl"> y </em> = X𝛽 + 𝜖，其中</p><ul class=""><li id="78a4" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated"><em class="kl"> y </em>是长度为<em class="kl"> n </em>(数据点数)的响应向量</li><li id="3ba1" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">x是一个由(<em class="kl"> p </em> +1)个独立变量组成的<em class="kl"> n </em>矩阵</li><li id="0705" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">𝛽是回归系数的(<em class="kl"> p </em> +1)向量</li><li id="5a3b" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">𝜖也是每个元素iid ~ N(0,𝜎的(<em class="kl"> p </em> +1)个扰动向量</li></ul><p id="dc07" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">x中的每一行有<em class="kl"> p </em>个元素加上常数1，常数1方便地包括系数向量𝛽.中的截距项在没有使用截距项的问题中，1被省略(通常是特定于应用的决定)。𝜖是不可知的，所以我们基于x对<em class="kl"> y </em>建模所能做的最好的事情就是用<em class="kl"> b </em>来估计𝛽，即<em class="kl"> ŷ </em> = X <em class="kl"> b </em>，其中<em class="kl"> ŷ </em>是对<em class="kl"> y </em>的估计。</p><p id="368b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了拟合训练数据，我们最小化残差平方和，其中残差被定义为<em class="kl"> y </em> - <em class="kl"> ŷ </em>。由于<em class="kl"> ŷ </em> = X <em class="kl"> b </em>，平方和可以写成(<em class="kl">y</em>-x<em class="kl">b</em>)ᵀ(<em class="kl">y</em>-x<em class="kl">b</em>)。对<em class="kl"> b </em>的每个元素进行微分(<em class="kl">y</em>-x<em class="kl">b</em>)ᵀ(<em class="kl">y</em>-x<em class="kl">b</em>)给出了著名的正规方程:Xᵀ( <em class="kl"> y </em> -X <em class="kl"> b </em> ) = 0。假设XᵀX是可逆的，<em class="kl"> b </em> = (XᵀX)- Xᵀ <em class="kl"> y </em>。</p><p id="1c7b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">线性回归的几何解释也许更直观。X的列向量跨越一个子空间，最小化残差相当于将y正交投影到这个子空间上，如下图所示。通过正交性，可以立即得到正规方程。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi la"><img src="../Images/b27654685d5b6ca294d6bba1d0e61a55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GT_lYlpF9e252-Rf6aQepw.jpeg"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Elements of Statistical Learning, p46</figcaption></figure><p id="ebc2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有了这些事实，我们就可以得出带有截距和斜率系数的简单线性回归的某些性质。我们将引用R中的一个线性回归示例来仔细检查这些属性。</p><pre class="lb lc ld le gt lq lr ls lt aw lu bi"><span id="53dc" class="lv lw iq lr b gy lx ly l lz ma">&gt; set.seed(13)<br/>&gt; n = 20; x = 1:n; y = 2*x + rnorm(n, sd = 1)<br/>&gt; model = lm(y~x)<br/>&gt; summary(model)</span><span id="1f22" class="lv lw iq lr b gy mb ly l lz ma">Call:<br/>lm(formula = y ~ x)</span><span id="ad29" class="lv lw iq lr b gy mb ly l lz ma">Residuals:<br/>     Min       1Q   Median       3Q      Max <br/>-1.89019 -0.47625  0.01282  0.77558  1.48740</span><span id="c7df" class="lv lw iq lr b gy mb ly l lz ma">Coefficients:<br/>            Estimate Std. Error t value Pr(&gt;|t|)    <br/>(Intercept)  0.61809    0.43205   1.431     0.17    <br/>x            1.95829    0.03607  54.296   &lt;2e-16 ***<br/>---<br/>Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span><span id="3d7c" class="lv lw iq lr b gy mb ly l lz ma">Residual standard error: 0.9301 on 18 degrees of freedom<br/>Multiple R-squared:  0.9939, Adjusted R-squared:  0.9936 <br/>F-statistic:  2948 on 1 and 18 DF,  p-value: &lt; 2.2e-16</span></pre><ol class=""><li id="e572" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk mc ks kt ku bi translated">残差之和为零。由正规方程xᵀ(<em class="kl">y</em>-x<em class="kl">b</em>)= xᵀ(<em class="kl">y</em>-<em class="kl">ŷ</em>)= 0。由于x有一列1，1ᵀ( <em class="kl"> y </em> - <em class="kl"> ŷ </em> ) = 0。我们可以用<code class="fe md me mf lr b">sum(model$residuals)</code>在R中进行健全性检查。再者，X中任意一列与残差的点积为0，可以用<code class="fe md me mf lr b">sum(x*model$residuals)</code>来查。</li><li id="d7bf" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk mc ks kt ku bi translated">斜率项的t检验与F检验等效，因为它们都有相同的零假设:斜率为0。这就是为什么它们的p值在上面的总结中是匹配的，2e-16和2.2e-16。来自具有<em class="kl"> k </em>自由度的t分布的随机变量<em class="kl"> T </em>等于<em class="kl">z</em>/sqrt(𝜒_ {<em class="kl">k</em>}/<em class="kl">k</em>，其中𝜒 _{ <em class="kl"> k </em> }是具有<em class="kl"> k </em>自由度的卡方随机变量。平方<em class="kl"> T_ </em> ( <em class="kl"> k </em>)给出<em class="kl"> F </em> (1 <em class="kl">，k </em>)随机变量:<em class="kl">t</em>_ {<em class="kl">k</em>} =<em class="kl">z</em>/(𝜒_ {<em class="kl">k</em>}/<em class="kl">k</em>)=(𝜒_{1}/1)/(𝜒_ {<em class="kl">k</em>}/<em class="kl">k<em class="kl">我们可以确认，对汇总中x项的t值(54.296)求平方，得到报告的F统计量(2948)。</em></em></li><li id="c475" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk mc ks kt ku bi translated">决定系数<em class="kl"> R </em>等于<em class="kl"> x </em>和<em class="kl"> y </em>之间相关性的平方。<em class="kl"> R </em>测量由<em class="kl"> x </em>解释的<em class="kl"> y </em>的变化比例。一个证明y与<em class="kl"> ŷ </em>的相关性的平方等于<em class="kl"> R </em>这里是<a class="ae mg" href="https://economictheoryblog.com/2014/11/05/proof/" rel="noopener ugc nofollow" target="_blank">这里是</a>，对于简单线性回归来说<em class="kl"> y </em>与<em class="kl"> ŷ </em>的相关性与<em class="kl"> y </em>与<em class="kl"> x </em>的相关性相同。请注意<code class="fe md me mf lr b">cor(x,y)^2</code>给出的值与“多R平方”旁边报告的值相同:0.9939。</li></ol></div></div>    
</body>
</html>