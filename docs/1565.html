<html>
<head>
<title>GENERATIVE ADVERSERIAL NETWORKS &amp; SEMI-SUPERVISED LEARNING</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成广告序列网络和半监督学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generative-adverserial-networks-semi-supervised-learning-24f5fb027934?source=collection_archive---------5-----------------------#2017-09-20">https://towardsdatascience.com/generative-adverserial-networks-semi-supervised-learning-24f5fb027934?source=collection_archive---------5-----------------------#2017-09-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="675d" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</h1><p id="f5fe" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我将直接进入我们上次在高层<a class="ae lj" href="http://jakublangr.com/gans-tutorial.html" rel="noopener ugc nofollow" target="_blank">解释过的内容。该代码也可以在</a><a class="ae lj" href="https://github.com/jakubLangr/Gans-Semi-Supervised/blob/master/gans_semi_supervised_learning.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub </a>和<a class="ae lj" href="https://medium.com/@james.langr" rel="noopener"> Medium </a>上获得。这部分与 Jupyter 笔记本相同，只是缺少代码输出。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lk"><img src="../Images/e5a042ea0c2a9866c3e87925dbd752ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gN5evYDXMcazJhWbzJUTYA.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Just a sanity check that my synthesising of faces works as expected.</figcaption></figure><h1 id="d308" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">生成广告序列网络和半监督学习</h1><h1 id="6bca" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">作者:雅各布·朗格</h1><p id="9843" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这段代码是为我写的，用来试验人工智能的一些最新进展。我特别选择了半监督学习和生成式逆向网络(GANs)来推动自己。其中一些代码是作为深度学习课程的<a class="ae lj" href="https://www.kadenze.com/courses/creative-applications-of-deep-learning-with-tensorflow-iv" rel="noopener ugc nofollow" target="_blank">创造性应用的作业完成的，这对我学习现代人工智能有极大的帮助。一些广泛的框架来自于</a><a class="ae lj" href="https://www.linkedin.com/in/pkmital" rel="noopener ugc nofollow" target="_blank"> Parag Mital </a>对课程最后部分的预编码设置和解释，但他的代码的这种用法是完全新颖的，需要大量的工程、缝合和抽象。在这个 Jupyter 笔记本中，我做了以下事情:</p><ol class=""><li id="d5cc" class="ma mb iq kn b ko mc ks md kw me la mf le mg li mh mi mj mk bi translated">导入所有必要的依赖项(以及一些我在开发过程中使用但在最终版本中没有使用的依赖项)</li><li id="bb32" class="ma mb iq kn b ko ml ks mm kw mn la mo le mp li mh mi mj mk bi translated">使用 GAN 方法生成合成图像。+更具体地说，<a class="ae lj" href="http://blog.aylien.com/introduction-generative-adversarial-networks-code-tensorflow/" rel="noopener ugc nofollow" target="_blank">这种最近非常流行的无监督技术</a>可以通过竞争另一个网络来欺骗对方(稍后解释)，来学习<a class="ae lj" href="http://jakublangr.com/mmlab.ie.cuhk.edu.hk/projects/CelebA.html" rel="noopener ugc nofollow" target="_blank">名人数据集</a>上构成人脸的更高表示(以及潜在空间中的许多属性)+或者，人们可以将这种方法视为使用自动编码器风格的基因生成模型，该模型试图基于播种因子生成新的示例。</li><li id="1144" class="ma mb iq kn b ko ml ks mm kw mn la mo le mp li mh mi mj mk bi translated">这种播种因子或“潜在特征空间”总是对生成模型的某些方面进行编码，一旦理解，就可以用于可预测地操纵生成图像的性质——例如秃顶、性别或微笑。</li><li id="a412" class="ma mb iq kn b ko ml ks mm kw mn la mo le mp li mh mi mj mk bi translated">因此，我们可以产生几乎无限的新例子，因为我们知道如何操纵潜在空间，我们可以知道它们的标签。在这个例子中，我们创建了 40，000 张男人和女人的脸，现在可以用于进一步的训练</li><li id="5c86" class="ma mb iq kn b ko ml ks mm kw mn la mo le mp li mh mi mj mk bi translated">然后，我们在合成数据上训练下一层分类器，用于男性或女性面部的二元分类。然而，我们不是从头开始训练一个新的分类器，而是使用一种使用牛津大学的<code class="fe mq mr ms mt b">Visual Geometry Group</code>或<code class="fe mq mr ms mt b">vgg16</code>预训练网络的<code class="fe mq mr ms mt b">transfer learning</code>方法来获得更高的准确性，而不必在大规模集群上训练数天。</li><li id="d6bc" class="ma mb iq kn b ko ml ks mm kw mn la mo le mp li mh mi mj mk bi translated">我们使用不同的<code class="fe mq mr ms mt b">vgg16</code>名人面孔预测(确切地说是<code class="fe mq mr ms mt b">2623</code>)并在带有标签的合成例子上训练一个简单的完全连接的两层神经网络。(这取代了典型的迁移学习方法，即删除最后一层并在其上进行训练。在这里，我们简单地将其分为 2 个步骤)</li><li id="cc12" class="ma mb iq kn b ko ml ks mm kw mn la mo le mp li mh mi mj mk bi translated">使用 100 个手工标记(由我)的例子来评估新分类器的准确性。</li></ol><h1 id="3ece" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">动机</h1><p id="b28f" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这真的很令人兴奋，因为它允许我们在几乎没有标记数据的情况下训练分类器，只要我们有许多未标记的数据，<a class="ae lj" href="http://jakublangr.com/ai-2016-review.html" rel="noopener ugc nofollow" target="_blank">这是一个非常有前途的策略，特别是对于拥有较小数据集的较小公司</a>。</p><h1 id="925e" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">术语的简要定义:</h1><p id="dd90" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">半监督学习:基本上是在训练过程中使用未标记数据和标记数据</p><p id="a0b3" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">生成性广告系列网络:详细解释如下</p><p id="1957" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">代码是在<code class="fe mq mr ms mt b">Tensorflow 1.0.0</code>做的。</p><pre class="ll lm ln lo gt mx mt my mz aw na bi"><span id="c160" class="nb jo iq mt b gy nc nd l ne nf"># First check the Python version<br/>import sys<br/>if sys.version_info &lt; (3,4):<br/>    print('You are running an older version of Python!\n\n',<br/>          'You should consider updating to Python 3.4.0 or',<br/>          'higher as the libraries built for this course',<br/>          'have only been tested in Python 3.4 and higher.\n')<br/>    print('Try installing the Python 3.5 version of anaconda'<br/>          'and then restart `jupyter notebook`:\n',<br/>          'https://www.continuum.io/downloads\n\n')</span><span id="4132" class="nb jo iq mt b gy ng nd l ne nf"># Now get necessary libraries<br/>try:<br/>    import os<br/>    import pandas as pd<br/>    import pickle<br/>    import tflearn<br/>    import pickle<br/>    from joblib import Parallel, delayed<br/>    import random<br/>    import multiprocessing<br/>    import numpy as np<br/>    import matplotlib.pyplot as plt<br/>    from skimage.transform import resize<br/>    from skimage import data<br/>    from scipy.misc import imresize<br/>    from scipy.ndimage.filters import gaussian_filter<br/>    import IPython.display as ipyd<br/>    import tensorflow as tf<br/>    from libs import utils, datasets, dataset_utils, nb_utils<br/>except ImportError as e:<br/>    print(e)<br/>    print("Make sure you have started notebook in the same directory",<br/>          "as the provided zip file which includes the 'libs' folder",<br/>          "and the file 'utils.py' inside of it.  You will NOT be able",<br/>          "to complete this assignment unless you restart jupyter",<br/>          "notebook inside the directory created by extracting",<br/>          "the zip file or cloning the github repo.")<br/>    print(e)</span><span id="cb48" class="nb jo iq mt b gy ng nd l ne nf"># We'll tell matplotlib to inline any drawn figures like so:<br/>%matplotlib inline<br/>plt.style.use('ggplot')</span></pre><h1 id="3c38" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">生成对抗网络(GAN) /深度卷积网络(DCGAN)</h1><h1 id="5a0d" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</h1><p id="9be8" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">回想一下，生成性对抗网络是两个网络，一个生成器和一个鉴别器。“生成器”获取一个特征向量，并将该特征向量解码成图像。鉴别器与自动编码器的编码器完全一样，只是它在最终层中只能有 1 个值。我们用一个 sigmoid 把这个值压扁在 0 和 1 之间，然后把它的意思解读为:1，你给我的图像是真的，或者 0，你给我的图像是生成器生成的，是假的！所以鉴别器就像一个编码器，它拍摄图像，然后进行测谎。你在给我灌输谎言吗？还是形象真实？</p><p id="69ac" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">以自动编码器为例。损失函数部分作用于输入空间。它说，每像素，我的重建和输入图像有什么不同？每像素的 l2 损失。回想一下，当时我们认为这不是最好的主意，因为每像素的差异并不代表我们对图像的感知。考虑这一点的一种方法是，如果我们有相同的图像，并将其平移几个像素。我们无法分辨这种差异，但两幅图像之间的每像素差异可能非常大。</p><p id="dd29" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">GAN 不使用每像素差异。相反，它训练一个距离函数:鉴别器。鉴别器接受两个图像，真实图像和生成的图像，并学习相似图像应该是什么样子！这真的是这个网络令人惊奇的部分，并且为无监督学习开辟了一些非常令人兴奋的潜在未来方向。另一个也学习距离功能的网络被称为暹罗网络。我们在本课程中没有涉及到这个网络，但它常用于面部验证，或断言两张脸是否相同。</p><p id="20a9" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">众所周知，GAN 网络的训练是一个巨大的痛苦！因此，我们实际上不会训练它。相反，我们将讨论这个基本网络的扩展，称为 VAEGAN(变分自动编码器 GAN)。现在，让我们继续创建 GAN。</p><p id="c1f3" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">让我们首先创建两个网络:鉴别器和生成器。我们将首先构建一个通用编码器，用于我们的鉴别器。我们想要的是使用我们的编码器的每个层的维度列表对输入占位符进行编码。在卷积网络的情况下，我们的维度列表应该对应于输出滤波器的数量。我们还需要指定每层卷积网络的内核高度和宽度。</p><p id="1fbb" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">我们首先需要一个占位符。这将是输入鉴别器的“真实”图像，鉴别器将把该图像编码成单个值，0 或 1，表示“是，这是真实的”,或者“否，这不是真实的”。</p><p id="7b75" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">该描述由 Parag 在麻省理工学院许可下善意提供。</p><pre class="ll lm ln lo gt mx mt my mz aw na bi"><span id="1260" class="nb jo iq mt b gy nc nd l ne nf">net = CV.get_celeb_vaegan_model()</span></pre><p id="4fb7" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">我们将加载包含在这个字典中的 graph_def。它遵循与<code class="fe mq mr ms mt b">inception</code>、<code class="fe mq mr ms mt b">vgg16</code>和<code class="fe mq mr ms mt b">i2v</code>预训练网络相同的思想。它是一个定义了关键字<code class="fe mq mr ms mt b">graph_def</code>的字典，具有图的预训练网络。它还包括<code class="fe mq mr ms mt b">labels</code>和一个<code class="fe mq mr ms mt b">preprocess</code>键。我们将不得不做一件额外的事情，那就是关闭来自变化层的随机采样。这并不是真正必要的，但将确保我们每次使用网络时得到相同的结果。我们将使用<code class="fe mq mr ms mt b">input_map</code>参数来做到这一点。不要担心这没有任何意义，因为我们没有覆盖任何深度的变化层。要知道，这是从网络中移除一个随机过程，因此它是完全确定的。如果我们没有这样做，我们每次使用网络时都会得到稍微不同的结果(这可能是您所希望的)。</p><p id="3145" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">现在让我们得到网络的相关部分:<code class="fe mq mr ms mt b">X</code>，网络的输入图像，<code class="fe mq mr ms mt b">Z</code>，输入图像的编码，<code class="fe mq mr ms mt b">G</code>，解码图像。在许多方面，这就像我们在上面学到的自动编码器，除了不是<code class="fe mq mr ms mt b">Y</code>作为输出，我们有来自我们的生成器的<code class="fe mq mr ms mt b">G</code>！我们训练它的方式非常不同:我们在生成器和鉴别器之间使用对抗过程，并使用鉴别器自己的距离度量来帮助训练网络，而不是像素到像素的差异。</p><pre class="ll lm ln lo gt mx mt my mz aw na bi"><span id="6072" class="nb jo iq mt b gy nc nd l ne nf">X = g.get_tensor_by_name('net/x:0')<br/>Z = g.get_tensor_by_name('net/encoder/variational/z:0')<br/>G = g.get_tensor_by_name('net/generator/x_tilde:0')</span></pre><p id="b1a3" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">让我们来看看一些数据:</p><pre class="ll lm ln lo gt mx mt my mz aw na bi"><span id="ade5" class="nb jo iq mt b gy nc nd l ne nf">files = sorted(datasets.CELEB())<br/>img_i = 20<br/>img = plt.imread(files[img_i])<br/>plt.imshow(img)</span></pre><p id="2f88" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">探索名人网络属性</p><p id="df28" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">现在，让我们尝试探索数据集的属性。我们没有用任何受监督的标签来训练网络，但名人网络数据集对其 200，000 张图像中的每张图像都有 40 个属性。这些已经被解析并存储在网络字典中:</p><p id="3dd3" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">找出某个属性的潜在编码名人数据集包括其 200，000+图像的每个属性。这允许我们将一些我们知道具有特定属性的图像(例如“微笑”)输入编码器。我们存储它们的编码，并保留编码值的这种分布。然后，我们可以查看任何其他图像，看看它是如何编码的，并通过添加我们微笑图像的编码来稍微改变编码！结果应该是我们的形象，但更多的微笑。这太疯狂了，我们将看看如何做到这一点。首先让我们检查我们的潜在空间:潜在特征算法现在让我们试着写一个通用函数来执行我们刚刚做的所有事情，这样我们就可以用许多不同的特征来做这件事。然后我们将尝试把它们结合起来，合成出具有我们想要的特征的人…</p><pre class="ll lm ln lo gt mx mt my mz aw na bi"><span id="59ff" class="nb jo iq mt b gy nc nd l ne nf">def get_features_for(label='Bald', has_label=True, n_imgs=50):<br/>    # Helper function to obtain labels and then preprocessing and returning<br/>    # a vector for the seeding function for GAN<br/>    # basically figures out the embedding for a particular attribute<br/>    label_i = net['labels'].index(label)<br/>    label_idxs = np.where(net['attributes'][:, label_i] == has_label)[0]<br/>    label_idxs = np.random.permutation(label_idxs)[:n_imgs]<br/>    imgs = [plt.imread(files[img_i])[..., :3]<br/>            for img_i in label_idxs]<br/>    preprocessed = np.array([CV.preprocess(img_i) for img_i in imgs])<br/>    zs = sess.run(Z, feed_dict={X: preprocessed})<br/>    return np.mean(zs, 0)</span></pre><p id="b2cc" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">现在我们使用代码在“男性”和“非男性”(女性)图像之间创建一个插值。因为我们只使用了两个端点，所以我们得到了两个图像:一个 100%的男人和一个 100%的女人(请注意，我们也可以通过对两个种子向量进行加权平均来得到中间的任何图像)。</p><pre class="ll lm ln lo gt mx mt my mz aw na bi"><span id="d755" class="nb jo iq mt b gy nc nd l ne nf">def gan_generate_data(num_iter=20000,imgs=15):<br/>    # generates 2*(number of iter) images <br/>    # adding random number of pictures for each synthesis (to increase variation)<br/>    # returns list of [Male, Female] * num_iter images<br/>    generated_images = []</span><span id="a2e2" class="nb jo iq mt b gy ng nd l ne nf">    for i in range(num_iter):</span><span id="10f4" class="nb jo iq mt b gy ng nd l ne nf">        n_imgs = random.choice(range(imgs-10, imgs+10))</span><span id="1480" class="nb jo iq mt b gy ng nd l ne nf">        z1 = get_features_for('Male', True, n_imgs=n_imgs)<br/>        z2 = get_features_for('Male', False, n_imgs=n_imgs)</span><span id="c51e" class="nb jo iq mt b gy ng nd l ne nf">        notmale_vector = z2 - z1<br/>        amt = np.linspace(0, 1, 2)<br/>        zs = np.array([z1 + notmale_vector*amt_i for amt_i in amt])<br/>        g = sess.run(G, feed_dict={Z: zs})</span><span id="c6a4" class="nb jo iq mt b gy ng nd l ne nf">        generated_images.append(g[0])<br/>        generated_images.append(g[1])</span><span id="f506" class="nb jo iq mt b gy ng nd l ne nf">        if i%1000==0:<br/>            print('Iteration number : {}'.format(i))</span><span id="d06b" class="nb jo iq mt b gy ng nd l ne nf">    return generated_images</span><span id="c112" class="nb jo iq mt b gy ng nd l ne nf">generated_data = gan_generate_data()</span></pre><p id="8fb1" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">很好，我们有数据可以使用，它保存在一个 pickle 文件中，所以我们不必重新创建它。现在，让我们只添加一个热编码标签(我们已经以可预测的方式完成了此操作，即 male (0)总是第一个)。我们可以对它进行感官检查，得到整个样品的形状。</p><pre class="ll lm ln lo gt mx mt my mz aw na bi"><span id="8222" class="nb jo iq mt b gy nc nd l ne nf">labels = [0,1] * 20000<br/>generated_data = np.array(generated_data)<br/>generated_data.shape</span></pre><h1 id="0f44" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">延长</h1><p id="2edc" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在让我们进入迁移学习部分。首先，我们必须离开网络。</p><pre class="ll lm ln lo gt mx mt my mz aw na bi"><span id="55f4" class="nb jo iq mt b gy nc nd l ne nf">from libs import vgg16, inception, i2v</span><span id="75e0" class="nb jo iq mt b gy ng nd l ne nf">net = vgg16.get_vgg_face_model()</span></pre><h1 id="d107" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">迁移学习</h1><p id="0cda" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这里我们得到了<code class="fe mq mr ms mt b">vgg16</code>网络，我们已经在前面加载了它，并使用它来为它自己的一个预训练类生成预测。然而，由于我们想要预测不同的任务，我们然后使用<code class="fe mq mr ms mt b">transferred_predictions</code>函数来获得 2623 个不同类别的预测，然后使用它作为下一个分类器的输入，来训练它识别性别。</p><p id="723d" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">为了有效地做到这一点，我们必须首先做一些图像处理，这是我们在<code class="fe mq mr ms mt b">transferred_df</code>做的。</p><pre class="ll lm ln lo gt mx mt my mz aw na bi"><span id="c703" class="nb jo iq mt b gy nc nd l ne nf">def transferred_predictions(img):<br/>    # gets an image (`np.array`) as an input outputs net's final layer predictions <br/>    results = []</span><span id="18ff" class="nb jo iq mt b gy ng nd l ne nf">    # Grab the tensor defining the input to the network<br/>    x = g.get_tensor_by_name(names[0] + ":0")</span><span id="3227" class="nb jo iq mt b gy ng nd l ne nf">    # And grab the tensor defining the softmax layer of the network<br/>    softmax = g.get_tensor_by_name(names[-2] + ":0")</span><span id="8b32" class="nb jo iq mt b gy ng nd l ne nf">    with tf.Session(graph=g) as sess, g.device('/cpu:0'):<br/>        # Remember from the lecture that we have to set the dropout<br/>        # "keep probability" to 1.0.<br/>        res = softmax.eval(feed_dict={x: img } ) # , Not using droput here<br/>                    # 'net/dropout_1/random_uniform:0': [[1.0] * 4096],<br/>                    # 'net/dropout/random_uniform:0': [[1.0] * 4096]})<br/>        test_array = res.argsort()[-5:][::-1].flatten()<br/>        results = ([(res.flatten()[int(idx)], <br/>                net['labels'][int(idx)])<br/>               for idx in test_array ])</span><span id="3092" class="nb jo iq mt b gy ng nd l ne nf">        result = pd.DataFrame(results, columns=['score','label']) # .sort(columns='score')</span><span id="07d7" class="nb jo iq mt b gy ng nd l ne nf">        results.append(result.score)</span><span id="dcd5" class="nb jo iq mt b gy ng nd l ne nf">    return results</span><span id="1aa8" class="nb jo iq mt b gy ng nd l ne nf">def transferred_df(generated_data):<br/>    # does the preprocessing of the `list` of generated_data and outputs `list` of predictions<br/>    results = []</span><span id="bf63" class="nb jo iq mt b gy ng nd l ne nf">    for i in range(len(generated_data)):<br/>        img = imresize(generated_data[i], size=(224,224,3))<br/>        img = net['preprocess'](img)[np.newaxis]<br/>        result = transferred_predictions(img)<br/>        results.append(result)</span><span id="c225" class="nb jo iq mt b gy ng nd l ne nf">        if i%1000==0:<br/>            print("Current image id {}".format(i))</span><span id="df41" class="nb jo iq mt b gy ng nd l ne nf">    return results<br/></span><span id="d6a9" class="nb jo iq mt b gy ng nd l ne nf">def parallel_transfer_eval(generated_data):<br/>    # returns parallely executed `transferred_df` using first split (fs), second (ss) and third (ts) as divisors<br/>    pool = multiprocessing.Pool(4)<br/>    fs = int(len(generated_data)/4)<br/>    ss = int(2*len(generated_data)/4)<br/>    ts = int(3*len(generated_data)/4)<br/>    target = generated_data[:fs], generated_data[fs:ss], generated_data[ss:ts],generated_data[ts:]<br/>    results = pool.map(transferred_df, zip(target))<br/>    # results = Parallel(n_jobs=4)(delayed(transferred_df)(img) for img in generated_data)</span><span id="8e21" class="nb jo iq mt b gy ng nd l ne nf">    return results</span></pre><h1 id="eae8" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">利用迁移学习</h1><p id="406d" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在我们在典型的<a class="ae lj" href="http://cs231n.github.io/transfer-learning/" rel="noopener ugc nofollow" target="_blank">迁移学习</a>范例中使用<code class="fe mq mr ms mt b">vgg16</code>做出的预测。在这里，我们只是采用最后一层预测，重塑特征，并将其提供给下一层分类器(有时也通过移除最后(几个)完全连接的层来完成)，并对整个网络进行训练。这里我们只是在最后一层创建一个新的。实践支持这两种方法。</p><pre class="ll lm ln lo gt mx mt my mz aw na bi"><span id="6f7c" class="nb jo iq mt b gy nc nd l ne nf">from sklearn.cross_validation import train_test_split</span><span id="35fb" class="nb jo iq mt b gy ng nd l ne nf"># train-test for proper evaluation<br/>train_X, test_X, train_y, test_y = train_test_split(X, y )</span><span id="bbc1" class="nb jo iq mt b gy ng nd l ne nf">tflearn.init_graph(num_cores=8, gpu_memory_fraction=0.5)</span><span id="256d" class="nb jo iq mt b gy ng nd l ne nf"># set up the network<br/>net = tflearn.input_data(shape=[None, 2623])<br/>net = tflearn.fully_connected(net, 2, activation='softmax')<br/>net = tflearn.regression(net, optimizer='adam', loss='categorical_crossentropy')</span><span id="2dae" class="nb jo iq mt b gy ng nd l ne nf"># train<br/>model = tflearn.DNN(net)<br/>model.fit(generated_data, labels, validation_set=train_X)<br/></span><span id="a19c" class="nb jo iq mt b gy ng nd l ne nf">from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.preprocessing import LabelEncoder</span><span id="a5d2" class="nb jo iq mt b gy ng nd l ne nf"># reshape labels so that they match what the network expects<br/>labels = ['Male', 'Female'] * 10000<br/>encoder = LabelEncoder()<br/>encoder.fit(labels)<br/>labels = encoder.transform(labels)<br/>labels = np_utils.to_categorical(labels)<br/>labels.shape</span><span id="b711" class="nb jo iq mt b gy ng nd l ne nf">test_imgs = np.array([CV.preprocess(plt.imread(file)) for file in files[:100]])<br/>test_imgs.shape</span></pre><p id="25f5" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">我们已经完成了这一点，因为我们已经对生成的和手工标记的图像(测试)进行了评分！然而，这只是我们旅程中的第一步，因为现在我们必须将<code class="fe mq mr ms mt b">vgg16</code>生成的分数转移到新的分类器上(转移学习中的最后一位，通常通过删除最后一层并使用新的最终层重新运行网络来简化，但这里是为了训练目的而明确完成的。)</p><h1 id="4d52" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">训练和评估新的分类器</h1><p id="a871" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了简单起见，我们将只使用<code class="fe mq mr ms mt b">tflearn</code>分类器，这样我们就可以更容易地使用迁移学习来完成前面所有工作的复杂性:1 .我们训练(基于合成数据和因此完全可预测的标签)2。我们对(我的)手举例子进行评价</p><pre class="ll lm ln lo gt mx mt my mz aw na bi"><span id="5f6f" class="nb jo iq mt b gy nc nd l ne nf">from __future__ import absolute_import<br/>from __future__ import division<br/>from __future__ import print_function<br/></span><span id="b4b7" class="nb jo iq mt b gy ng nd l ne nf">labels = [0,1] * 10000</span><span id="2f9c" class="nb jo iq mt b gy ng nd l ne nf">feature_columns = [tf.contrib.layers.real_valued_column("", dimension=2623)]<br/></span><span id="0e65" class="nb jo iq mt b gy ng nd l ne nf">classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,<br/>                                            hidden_units=[2623,512],<br/>                                            gradient_clip_norm=.01,<br/>                                            optimizer=tf.train.AdamOptimizer(learning_rate=0.1),<br/>                                            n_classes=2)<br/>                                            # model_dir='./model')</span><span id="af86" class="nb jo iq mt b gy ng nd l ne nf"># Fit model.<br/>classifier.fit(x=array,<br/>               y=labels,<br/>               batch_size=256,<br/>               steps=10000)<br/></span><span id="3948" class="nb jo iq mt b gy ng nd l ne nf"># Evaluate accuracy.<br/>test_labels = np.array([0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,<br/>       0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,<br/>       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,<br/>       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,<br/>       0, 0, 0, 0, 0, 0, 0, 0])</span><span id="380a" class="nb jo iq mt b gy ng nd l ne nf"># test_array = np.array([ [res[0] for res in result] for result in test_array ])</span><span id="dd42" class="nb jo iq mt b gy ng nd l ne nf">accuracy_score = classifier.evaluate(x=test_array,<br/>                                     y=test_labels)["accuracy"]<br/>print('Accuracy: {0:f}'.format(accuracy_score))</span></pre><h1 id="14a3" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">一般讨论</h1><p id="d7a4" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">结果并不是那么出色，然而，我认为这是一个迷人的研究领域，很可能会成为人工智能未来的最大领域之一:但我们仍然比随机(持续)要好，如果我在这方面花更多时间，可能会变得更好。</p><p id="7173" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">此外，在许多行业应用中，只需稍加修改，这些代码就可以进行微调和重用:</p><p id="48e8" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">a) 3D 对象生成</p><p id="ea08" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">b) <a class="ae lj" href="https://www.youtube.com/watch?v=u7kQ5lNfUfg" rel="noopener ugc nofollow" target="_blank"> Pix2Pix 应用</a>设法根据风格创建新图像，或者只是从卫星图像生成地图。这里的可能性实际上是无限的。</p><p id="39b7" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">c)灌制老电影。仅举几个例子。</p><p id="6b0d" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">感谢您的阅读，如果您对此感兴趣，请浏览<a class="ae lj" href="http://jakublangr.com" rel="noopener ugc nofollow" target="_blank">我的网站</a>了解更多信息！</p><p id="943c" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated">由于我通常会在我的网站上发布文章一周后在 Medium 上发布，所以我会为那些坚持到现在的人增加一点奖励，并提到我的下一篇文章将是关于区块链的，并评估它将如何改变金融世界。</p><p id="501d" class="pw-post-body-paragraph kl km iq kn b ko mc kq kr ks md ku kv kw mu ky kz la mv lc ld le mw lg lh li ij bi translated"><strong class="kn ir">2018 年 10 月 8 日更新:我正在与人合著一本关于 GANs 的书</strong> <a class="ae lj" href="http://bit.ly/gan-book" rel="noopener ugc nofollow" target="_blank"> <strong class="kn ir">，你可以在这里找到。</strong> </a> <strong class="kn ir">如需更多更新，您可以关注我@langrjakub，</strong>因为我通常不会更新旧文章，但如果您感兴趣，请在 Twitter 上与我联系。</p><h1 id="c447" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">发布在<a class="ae lj" href="http://jakublangr.com/category/technical.html" rel="noopener ugc nofollow" target="_blank">技术</a></h1><p id="0f2b" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><a class="ae lj" href="http://jakublangr.com/tag/python.html" rel="noopener ugc nofollow" target="_blank">python</a><a class="ae lj" href="http://jakublangr.com/tag/ai.html" rel="noopener ugc nofollow" target="_blank">AI</a><a class="ae lj" href="http://jakublangr.com/tag/semi-supervised-learning.html" rel="noopener ugc nofollow" target="_blank">半监督学习</a> <a class="ae lj" href="http://jakublangr.com/tag/gans.html" rel="noopener ugc nofollow" target="_blank"> GANs </a> <a class="ae lj" href="http://jakublangr.com/tag/generative.html" rel="noopener ugc nofollow" target="_blank">创成式</a> <a class="ae lj" href="http://jakublangr.com/tag/adverserial.html" rel="noopener ugc nofollow" target="_blank"> Adverserial </a> <a class="ae lj" href="http://jakublangr.com/tag/neural-networks.html" rel="noopener ugc nofollow" target="_blank">神经网络</a> <a class="ae lj" href="http://jakublangr.com/tag/code.html" rel="noopener ugc nofollow" target="_blank">代码</a></p></div></div>    
</body>
</html>