# 不，机器学习不仅仅是美化了的统计学

> 原文：<https://towardsdatascience.com/no-machine-learning-is-not-just-glorified-statistics-26d3952234e3?source=collection_archive---------0----------------------->

![](img/772751477a59adfb14aa7e0b9249db0e.png)

original comic by [sandserif](https://www.instagram.com/sandserifcomics/)

随着对深度学习的大肆宣传开始消退，这个迷因最近在社交媒体上到处都是，在互联网上产生了赞赏的笑声。机器学习真的没什么好兴奋的，或者它只是古老的统计技术的修正，这种观点越来越普遍；问题是这不是真的。

我明白——成为深度学习传道者中过度热情、喝得醉醺醺的一员并不时尚。2013 年鼓吹从屋顶上进行深度学习的人工智能专家现在只是带着一丝懊恼使用这个术语，而是倾向于淡化现代神经网络的力量，以免它们与许多人联系在一起，这些人似乎仍然认为`import keras`是跨越每个障碍的一步，他们知道这一点，就比他们的竞争对手有一些巨大的优势。

虽然深度学习确实已经不再是一个有用的流行语，正如 Yann LeCun 所说的，但这种过度修正的态度已经产生了对人工智能的进步、未来和有用性的不健康的怀疑。这一点从关于即将到来的*人工智能冬天*的讨论中可以清楚地看到，在这个冬天里，人工智能研究预计将像过去几十年一样停滞多年。

然而，这篇文章的目的不是反对人工智能冬天。这也不是说一个学术团体比另一个学术团体更值得深度学习的荣誉；更确切地说，是为了说明信用 ***是*** 的到期；我们看到的发展超越了大型计算机和更好的数据集；随着最近在深度神经网络和相关工作中的成功，机器学习代表了世界上最前沿的技术进步。

## 机器学习！=统计

> “当你筹款时，它是人工智能。当你在招人的时候，就是 ML。当你实施时，这是逻辑回归。”
> 
> ——推特上的每个人

要解决的主要问题，也是这篇文章的标题，是机器学习不仅仅是美化了的统计学——老一套的东西，只是有了更大的计算机和更花哨的名字。这个概念来自机器学习中流行的统计概念和术语，如*回归*、*权重、偏差、模型、*等。此外，许多模型近似于通常认为的统计函数:分类模型的 softmax 输出由逻辑组成，使得训练图像分类器的过程成为*逻辑回归*。

尽管这种思路在技术上是正确的，但将机器学习作为一个整体减少到仅仅是统计学的一个附属部分是相当牵强的。其实比较没有太大意义。统计学是数学的一个领域，处理对数据的理解和解释。机器学习只不过是一类计算算法(因此它从计算机科学中出现)。在许多情况下，这些算法在帮助理解数据方面完全没有用，只在某些类型的不可解释的预测建模方面有帮助。在某些情况下，例如在强化学习中，算法可能根本不使用预先存在的数据集。另外，在图像处理的情况下，将图像称为数据集的*实例*，将像素称为*特征*从一开始就有点牵强。

当然，重点不是计算机科学家应该得到所有的荣誉，或者统计学家不应该；像任何研究领域一样，导致今天的成功的贡献来自各种学术学科，其中首先是统计学和数学。然而，为了正确评估机器学习方法的强大影响和潜力，重要的是首先消除错误的观念，即人工智能的现代发展只不过是使用更大的计算机和更好的数据集的古老统计技术。

## **机器学习不需要统计学的高深知识**

听我说完。当我正在学习机器学习的诀窍时，我很幸运地参加了一个致力于深度学习技术的精彩课程，该课程是我本科计算机科学计划的一部分。我们分配的项目之一是在 TensorFlow 中实施和培训 Wasserstein GAN。

在这一点上，我只上了一门统计学导论课，这是一门必修的普通选修课，然后很快就忘记了大部分内容。不用说，我的统计技能不是很强。然而，我能够阅读并理解一篇关于最先进的生成机器学习模型的论文，从头实现它，并通过在 MS Celebs 数据集上训练它，生成不存在的个人的非常令人信服的假图像。

在整个课堂上，我和我的同学们成功地训练了癌症组织图像分割、神经机器翻译、基于字符的文本生成和图像风格转换的模型，所有这些都采用了过去几年才发明的尖端机器学习技术。

然而，如果你问我，或者那堂课的大多数学生，如何计算总体的方差，或者定义边际概率，你可能会得到茫然的目光。

这似乎与人工智能只是古老的统计技术的重新命名的说法有点不一致。

的确，在深度学习课程中，一个 ML 专家可能比一个 CS 本科生有更强的统计学基础。一般来说，信息论需要对数据和概率有很强的理解，我当然会建议任何有兴趣成为数据科学家或机器学习工程师的人培养对统计概念的深刻直觉。但问题仍然是:*如果机器学习是统计学的一个分支，那么一个几乎没有统计学背景的人怎么可能对最前沿的 ML 概念有深刻的理解？*

还应该承认，许多机器学习算法比大多数神经网络技术需要更强的统计和概率背景，但即使是这些方法也经常被称为 [*统计机器学习*](http://www.stat.cmu.edu/~larry/=sml/) 或[*统计学习*](https://lagunita.stanford.edu/courses/HumanitiesSciences/StatLearning/Winter2016/about) ，好像是为了将自己与常规的、较少统计的那种区分开来。此外，近年来机器学习领域的大多数炒作创新都是在神经网络领域，所以这一点无关紧要。

当然，机器学习并不是独自生活在一个世界里。同样，在现实世界中，任何希望做很酷的机器学习工作的人可能都在处理各种类型的数据问题，因此也需要对统计学有很强的理解。这并不是说 ML 从不使用或建立统计概念，但这并不意味着它们是一回事。

## **机器学习=表示+评估+优化**

公平地说，对我自己和我的同学来说，我们在算法、计算复杂性、最优化方法、微积分、线性代数，甚至一些概率方面都有很强的基础。我认为，所有这些都比先进的统计学知识与我们正在解决的问题更相关。

机器学习是一类计算算法，它迭代地“学习”某个函数的近似值。华盛顿大学计算机科学教授 Pedro Domingos[展示了组成机器学习算法的三个组成部分](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf):表示、评估和优化。

**表示**包括将输入从一个空间转换到另一个更有用的空间，该空间更容易解释。在卷积神经网络的背景下考虑这一点。原始像素对于区分狗和猫是没有用的，所以我们将它们转换成更有用的表示(例如，来自 softmax 输出的 logits ),它可以被解释和评估。

**评价**本质上是损失函数。您的算法如何有效地将您的数据转换到更有用的空间？您的 softmax 输出与您的一次性编码标签(分类)有多相似？您是否正确预测了展开的文本序列中的下一个单词(文本 RNN)？你的潜在分布偏离单位高斯(VAE)有多远？这些问题告诉你你的表征功能工作得有多好；更重要的是，它们定义了*将学会做什么。*

优化是拼图的最后一块。一旦你有了评价组件，你可以 ***优化******表示函数*** 以提高你的 ***评价指标*** 。在神经网络中，这通常意味着使用一些随机梯度下降的变体，根据一些定义的损失函数来更新网络的权重和偏差。瞧啊。你有世界上最好的图像分类器(至少，如果你是 2012 年的 Geoffrey Hinton，你有)。

当训练图像分类器时，除了定义适当的损失函数之外，学习的表示函数具有逻辑输出是完全不相关的。借用像*逻辑回归*这样的统计术语确实给了我们有用的词汇来讨论我们的模型空间，但是它们没有将它们从优化问题重新定义为数据理解问题。

***先不说:人工智能这个词很蠢。*** *人工智能问题只是计算机还不擅长解决的问题。19 世纪，* [*机械计算器被认为是智能的(链接)。*](https://books.google.com/books?id=bSM_AQAAMAAJ&pg=PA308&dq=%22Instead+of+simply+reproducing+the+operations+of+man%27s+intelligence,+the+arithmometer+relieves+that+intelligence+from+the+necessity+of+making+the+operations.+Instead+of+repeating+responses+dictated+to+it,+this+instrument+instantaneously+dictates+the+proper+answer+to+the+man+who+asks+it+a+question.+It+is+not+matter+producing+material+effects,+but+matter+which+thinks,+reflects,+reasons%22&hl=en&sa=X&ved=0ahUKEwjxwdSqzvTbAhVjj1QKHa4vDvcQ6AEILjAB#v=onepage&q=%22Instead%20of%20simply%20reproducing%20the%20operations%20of%20man's%20intelligence%2C%20the%20arithmometer%20relieves%20that%20intelligence%20from%20the%20necessity%20of%20making%20the%20operations.%20Instead%20of%20repeating%20responses%20dictated%20to%20it%2C%20this%20instrument%20instantaneously%20dictates%20the%20proper%20answer%20to%20the%20man%20who%20asks%20it%20a%20question.%20It%20is%20not%20matter%20producing%20material%20effects%2C%20but%20matter%20which%20thinks%2C%20reflects%2C%20reasons%22&f=false) *既然这个术语与深度学习联系如此紧密，我们已经开始说人工通用智能(AGI)来指代任何比高级模式匹配机制更智能的东西。然而，我们甚至还没有对一般智力的一致定义或理解。人工智能这个术语唯一能做的就是激起人们对所谓的“奇点”或类似终结者的杀手机器人的恐惧。我希望我们可以停止使用这样一个空洞的，耸人听闻的术语来指真正的技术。*

## 深度学习的技术

进一步挑战深度学习的据称统计性质的是，嗯，深度神经网络的几乎所有内部工作方式。当然，全连接节点由权重和偏差组成，但卷积层呢？整流器激活？批量正常化？残留层？退学？记忆和注意力机制？

这些创新是高性能深度网络发展的核心，但它们与传统的统计技术相去甚远(可能因为它们根本不是统计技术)。如果你不相信我，试着告诉一个统计学家你的模型过度拟合，并问他们是否认为随机丢弃你的模型的 1 亿个参数中的一半是个好主意。

我们甚至不要谈论模型的可解释性。

## 回归超过 1 亿个变量——没问题？

让我也从规模上指出深网和传统统计模型的区别。深度神经网络是巨大的。例如，VGG-16 通信网络架构[有大约 1.38 亿个参数](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture9.pdf)。你认为你的普通学术顾问会如何回应一个想要对超过 *1 亿个变量*进行多元回归的学生？这个想法很可笑。这是因为训练 VGG-16 不是多元回归——而是机器学习。

## 新领域

在过去的几年里，你可能已经在没完没了的论文、帖子和文章中宣扬机器学习现在可以做的很酷的事情，所以我不会在这上面花太多时间。然而，我要提醒你，深度学习不仅比以前的技术更好，它还使我们能够解决一种全新的问题**。**

在 2012 年之前，涉及非结构化和半结构化数据的问题充其量是一个挑战。可训练的 CNN 和 LSTMs 在这方面是一个巨大的飞跃。这在计算机视觉、自然语言处理、语音转录等领域取得了相当大的进展，并使人脸识别、自动驾驶汽车和对话式人工智能等技术取得了巨大进步。

诚然，大多数机器学习算法最终都涉及到将模型拟合到数据中——从这个角度来看，这是一个统计过程。同样真实的是，航天飞机最终只是一架带翅膀的飞行器，然而我们并没有看到模因嘲笑围绕美国宇航局 20 世纪太空探索的兴奋，将其作为飞机的过度宣传。

与太空探索一样，深度学习的出现并没有解决世界上所有的问题。在许多领域，尤其是在“人工智能”领域，仍有重大差距需要克服。也就是说，它对我们解决复杂的非结构化数据问题的能力做出了重大贡献。机器学习继续代表着世界技术进步和创新的前沿。它不仅仅是墙上的一个裂缝和一个闪亮的新框架。

***编辑:***

许多人将这篇文章解读为对统计学领域的 diss，或者是对我自己对机器学习的肤浅理解的背叛。回想起来，我后悔把这么多注意力放在 ML 和统计学的不同上，而不是放在我的中心观点上:**机器学习不全是炒作**。

让我说清楚:统计学和机器学习无论如何都不是不相关的。机器学习完全利用并建立在统计学的概念之上，统计学家在他们的工作中正确地利用机器学习技术。这两个领域之间的区别并不重要，这也是我不应该如此关注的。最近一直在关注*贝叶斯神经网络的想法。* BNNs 涉及在给定一些先验信念的情况下逼近神经网络参数的概率分布。这些技术给出了不确定性量化的原则方法，并产生更好的正则化预测。

在研究这些问题时，如果我说我不是在“做统计”，那我就是个白痴，我也不会这么做。这两个领域并不相互排斥，但这并不意味着它们是相同的，当然也不意味着它们没有实质内容或价值。一位数学家可以指着一位研究量子场论的理论物理学家，正确地说她在做数学，但如果这位数学家断言她的物理领域实际上只不过是被过度炒作的数学，她可能会提出异议。

计算科学也是如此:你可能会指着手指说“他们在做统计”，而“他们”可能会同意。统计在机器学习研究中非常重要，许多统计学家处于这项工作的前沿。但是 ML 已经开发了 1 亿个参数的神经网络，具有残差连接和批量标准化、现代激活、退出和许多其他技术，这些技术导致了几个领域的进步，特别是在顺序决策和计算感知方面。它发现并利用了令人难以置信的高效优化算法，利用自动微分和并行运行在令人眼花缭乱的快速和廉价的 GPU 技术。多亏了高级的、优雅简单的张量操作软件，所有这些对任何有基本编程能力的人来说都是可及的。“哦，人工智能只是逻辑回归”有点低估了，你不觉得吗？

*如果你像我一样，喜欢与机器学习爱好者们交流，请关注我的* [*Twitter*](https://twitter.com/joeddav) *和/或*[*LinkedIn*](https://www.linkedin.com/in/josephdavison/)*。如果你想找 ML 咨询工作，直接联系*[*josephddavison@gmail.com*](mailto:josephddavison@gmail.com)*。*