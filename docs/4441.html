<html>
<head>
<title>Watching a Learner Learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">观察学习者学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/watching-a-learner-learn-cd49b9d01dd0?source=collection_archive---------15-----------------------#2018-08-15">https://towardsdatascience.com/watching-a-learner-learn-cd49b9d01dd0?source=collection_archive---------15-----------------------#2018-08-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b602" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用 Keras 和 Matplotlib</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e7cc09d6d600016654dd33b4546cc3f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fCev19Bv_pq4EUfpLzI5uw.png"/></div></div></figure><p id="c422" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">除了理解训练算法，更清楚地了解学习者拟合数据时实际发生了什么也是不错的。</p><p id="515d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我写了下面展示的工具，以配合一个外行人关于机器学习如何工作的演示。其目的是帮助商业领域的专家寻找机器学习，并就解决他们自己的问题和机会进行头脑风暴。我想演示学习的迭代过程，但也想避免让非程序员看代码。</p><p id="c8f6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在这样做的过程中，我发现看着一个模特学习是令人着迷的。人们可以看到模型首先关注什么，它很难找到什么，超参数设置如何影响过程，等等。这也有助于调试。</p><p id="1890" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Jupyter 笔记本和一个模块中的所有代码都是 Python。你可以在 Github 上找到<a class="ae ln" href="https://github.com/alipeles/KerasTrainingVisualization" rel="noopener ugc nofollow" target="_blank">代码</a>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lo lp l"/></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Full video of neural network training</figcaption></figure><h1 id="53a5" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">它是如何工作的</h1><p id="b93f" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">机器学习模型是最终的早期交付/中期交付。一旦用随机数据初始化了一个模型，它就是一个工作的发布候选，尽管不是非常精确的。拟合每一批新数据会产生一系列新候选模型中的下一个，平均而言，如果一切顺利，这些模型的质量会逐步提高。</p><p id="3af1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，基本的攻击计划是运行一个比批量大得多的代表性数据样本，通过每个候选模型并绘制当前候选模型认为整个目标函数看起来像什么。重要的是，这些结果仅供展示，对训练没有帮助。</p><p id="dc89" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Keras 提供了一种机制，允许程序在不同的点插入自己的代码，包括批处理结束。稍后我将讨论如何注册回调。</p><p id="1b0a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在我开始之前有两个警告:</p><ol class=""><li id="9b9d" class="mr ms iq kt b ku kv kx ky la mt le mu li mv lm mw mx my mz bi translated">到目前为止，这段代码只适用于具有一个特征和一个标签的 Keras 模型。</li><li id="7325" class="mr ms iq kt b ku na kx nb la nc le nd li ne lm mw mx my mz bi translated">这是狗慢，Keras 会抱怨它。把这个用于学习，而不是生产。更多关于性能以及如何使其易于管理的想法，请参见下文。</li></ol><h1 id="dbb9" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">绘制模型</h1><p id="b6bf" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">我发现最少的有用数据包括 3 件事，这可以在下图左侧的大图中看到</p><ol class=""><li id="2e16" class="mr ms iq kt b ku kv kx ky la mt le mu li mv lm mw mx my mz bi translated">拟合数据的固定散点图。(灰色圆点填充了大部分情节。)</li><li id="3902" class="mr ms iq kt b ku na kx nb la nc le nd li ne lm mw mx my mz bi translated">最新候选模型的输出图。(蓝色实线。)</li><li id="3012" class="mr ms iq kt b ku na kx nb la nc le nd li ne lm mw mx my mz bi translated">对损失的想象。(实线周围的蓝色阴影区域。)</li></ol><p id="3412" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">顺便说一下，这个线性例子只是为了说明。你永远不会真的用神经网络来找到这种关系。但是，您可以获得一些有用的见解，例如，方差似乎与输入变量相关(异方差)，并且您会注意到优化器在斜率之前关注截距。</p><p id="1809" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">线性示例也有助于获得超参数如何影响训练的直观感觉。例如，尝试不同的学习速率、衰减或批量大小。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/5ee7d8b0570d03ae0cc523b0b5ba5d1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ddd6AikLBgpIzljrGqvwiw.png"/></div></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="lo lp l"/></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk">Full video of linear training</figcaption></figure><p id="ad65" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">另外两个有趣的数据系列，特别是对于熟悉机器学习的外行人来说，可以在上图右侧的较小图表中看到:</p><ol class=""><li id="cd45" class="mr ms iq kt b ku kv kx ky la mt le mu li mv lm mw mx my mz bi translated">整个数据集(或代表性样本)在训练过程中的损失图。</li><li id="4a66" class="mr ms iq kt b ku na kx nb la nc le nd li ne lm mw mx my mz bi translated">训练过程中每批的损耗图。</li></ol><p id="48de" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在回调中，计算图表所需的数据非常简单:</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="9ce9" class="nk lv iq ng b gy nl nm l nn no">y_pred = model.predict(X)</span><span id="6fa1" class="nk lv iq ng b gy np nm l nn no">loss = np.square(y - y_pred)</span></pre><p id="e589" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">请注意，损失是一个<em class="nq">向量</em>,表示在代表性样本中的每个数据点，模型有多远。</p><p id="7497" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了关注模型的哪个部分对损失贡献最大，我添加了一个平滑选项，使用卷积来计算移动平均值。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="02bc" class="nk lv iq ng b gy nl nm l nn no">if loss_smoothing &gt; 1:<br/>    loss = np.convolve(loss,<br/>             np.ones((loss_smoothing,))/loss_smoothing, mode='same')</span></pre><p id="e5c8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">绘制图形主要是直接使用 Matplotlib，除了每个组件只创建一次，例如</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="0a2d" class="nk lv iq ng b gy nl nm l nn no">y_pred_line = ax_main.plot(X, y_pred, '-',<br/>                 color='steelblue', lw=4,<br/>                 label='model', zorder=15)[0]</span></pre><p id="7e65" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">然后，在后续调用中，使用第一次调用中返回的对象更新数据。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="aadf" class="nk lv iq ng b gy nl nm l nn no">y_pred_line.set_ydata(y_pred)</span></pre><p id="745d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一些小事情需要注意:</p><ol class=""><li id="9881" class="mr ms iq kt b ku kv kx ky la mt le mu li mv lm mw mx my mz bi translated">使用<em class="nq"> zorder </em>来控制复杂图形中图层的顺序(什么在什么上面)。</li><li id="5691" class="mr ms iq kt b ku na kx nb la nc le nd li ne lm mw mx my mz bi translated">散点图绘制成本很高，而且不会改变。因此，它在设置期间被绘制一次，并且不再被绘制。</li><li id="6182" class="mr ms iq kt b ku na kx nb la nc le nd li ne lm mw mx my mz bi translated">假设损失是均方误差。理想情况下，这将是可选择和可重写的。</li><li id="d621" class="mr ms iq kt b ku na kx nb la nc le nd li ne lm mw mx my mz bi translated">任何正则化惩罚都被忽略。显示正则化损失并可视化它何时成为损失的重要部分将是有趣的。</li></ol><p id="04ec" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一个更复杂的问题是如何创建动画。Matplotlib 包括一个动画库，但它假设它将控制时钟，告诉程序何时重画。我们需要事件驱动的重绘。</p><p id="daf1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">使用<em class="nq"> %matplotlib inline </em>时，回调只需要调用<em class="nq"> plt.show() </em>将更改刷新到屏幕。包含下面的语句，告诉 iPython 每次都清除输出图。否则，每个<em class="nq"> plt.show() </em>调用将在前一个图形的下方创建一个新的图形。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="73bd" class="nk lv iq ng b gy nl nm l nn no">clear_output(wait=True)</span></pre><p id="1e97" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">内联工作有一些限制，特别是图形的大小有限。使用 QT5 或另一个独立的显示器，每次更新数据时都必须刷新绘图事件。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="4b00" class="nk lv iq ng b gy nl nm l nn no">fig.canvas.draw()<br/>fig.canvas.flush_events()</span></pre><h1 id="dc7e" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">注册回拨</h1><p id="506b" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">Keras 为滚动回调提供了一个 lambda 选项。</p><h2 id="f8f9" class="nk lv iq bd lw nr ns dn ma nt nu dp me la nv nw mg le nx ny mi li nz oa mk ob bi translated"><a class="ae ln" href="https://keras.io/callbacks/#lambdacallback" rel="noopener ugc nofollow" target="_blank"> LambdaCallback </a></h2><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="c800" class="nk lv iq ng b gy nl nm l nn no">keras.callbacks.LambdaCallback(on_epoch_begin=<strong class="ng ir">None</strong>, on_epoch_end=<strong class="ng ir">None</strong>, on_batch_begin=<strong class="ng ir">None</strong>, on_batch_end=<strong class="ng ir">None</strong>, on_train_begin=<strong class="ng ir">None</strong>, on_train_end=<strong class="ng ir">None</strong>)</span></pre><p id="8973" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="nq"> LambdaCallback() </em>实际上只是将回调封装在一些代码中，告诉 Keras 何时调用它。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="8bac" class="nk lv iq ng b gy nl nm l nn no">redraw_callback = LambdaCallback(on_batch_end=cb_redraw)</span></pre><p id="8657" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">包装后的回调被传递到拟合步骤。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="3a2d" class="nk lv iq ng b gy nl nm l nn no">model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,<br/>          callbacks=[<strong class="ng ir">redraw_callback</strong>])</span></pre><p id="8008" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Keras 向回调传递非常少的信息，例如，不是模型或数据集。因此，为了确保回调得到它需要的东西，闭包是必需的。</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="eaf9" class="nk lv iq ng b gy nl nm l nn no">def get_redraw(X_in, y_in, model, batch_size, epochs, **kwargs):</span><span id="7bf7" class="nk lv iq ng b gy np nm l nn no">    # [argument processing]</span><span id="29e3" class="nk lv iq ng b gy np nm l nn no">    # [setup steps]</span><span id="f921" class="nk lv iq ng b gy np nm l nn no">    # [initialization of any variables retained between calls]</span><span id="e98e" class="nk lv iq ng b gy np nm l nn no">    def redraw(batch, logs):</span><span id="70c7" class="nk lv iq ng b gy np nm l nn no">        # [code that will be run after each batch]</span><span id="9824" class="nk lv iq ng b gy np nm l nn no">    # return the closure around the actual callback function<br/>    return redraw</span></pre><p id="8668" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">然后，在将调用传递回<em class="nq"> model.fit() </em>的代码中:</p><pre class="kg kh ki kj gt nf ng nh ni aw nj bi"><span id="16e5" class="nk lv iq ng b gy nl nm l nn no">cb_redraw = get_redraw( <em class="nq">[arguments]</em> )</span><span id="3e08" class="nk lv iq ng b gy np nm l nn no">redraw_callback = LambdaCallback(on_batch_end=cb_redraw)</span><span id="4195" class="nk lv iq ng b gy np nm l nn no">model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,<br/>          callbacks=[redraw_callback])</span></pre><h1 id="127d" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">表演</h1><p id="8036" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">不可回避的事实是，重新运行模型并绘制所有这些图形需要大量时间。根据模型的复杂程度，回调的计算时间可能会使实际训练相形见绌。</p><p id="c174" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">没有什么能使它成为一个可用于生产的工具。但是，一些技术有助于将性能提高到对学习有用的水平。</p><p id="af63" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">顺便说一下，绘图可能是最慢的部分。此外，Matplotlib 有时会在大型数据集上出错。</p><p id="70f9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">回调采用三个参数来管理数据大小:</p><ul class=""><li id="6a7a" class="mr ms iq kt b ku kv kx ky la mt le mu li mv lm oc mx my mz bi translated"><em class="nq"> graph_sparsity </em>可以减少重算中使用的数据量。值为<em class="nq"> n </em>表示仅使用数据点的<em class="nq"> 1/n </em>。</li><li id="1a55" class="mr ms iq kt b ku na kx nb la nc le nd li ne lm oc mx my mz bi translated"><em class="nq"> scatter_sparsity </em>对散点图做同样的事情。散点图不会成为性能瓶颈，因为它只绘制一次，但它会导致溢出。</li><li id="56ac" class="mr ms iq kt b ku na kx nb la nc le nd li ne lm oc mx my mz bi translated"><em class="nq"> loss_smoothing </em>控制损失线的视觉外观，但也减少了需要绘制的点数。这可能有很大的影响，因为损失是在模型线上下多次绘制的。</li></ul><p id="d3f7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">另一个重要的性能指标是<em class="nq">频率，</em>控制模型评估和重绘的频率。我提供了 3 个频率选项:</p><ul class=""><li id="dfe3" class="mr ms iq kt b ku kv kx ky la mt le mu li mv lm oc mx my mz bi translated">标量值<em class="nq"> n </em>表示图表应该每<em class="nq"> n </em>批更新一次。因为训练过程往往在开始时很快，后来很慢，所以这只对较小的数据集有效。</li><li id="552e" class="mr ms iq kt b ku na kx nb la nc le nd li ne lm oc mx my mz bi translated">true/false 值的数组，每批一个，指示是否更新。请注意，这是批处理运行的总数。它不会在每个时期结束时重置为零。</li><li id="c105" class="mr ms iq kt b ku na kx nb la nc le nd li ne lm oc mx my mz bi translated">决定每批是否更新的频率回调，例如，基于模型是否已经改变到值得重画。</li></ul><h1 id="c2da" class="lu lv iq bd lw lx ly lz ma mb mc md me jw mf jx mg jz mh ka mi kc mj kd mk ml bi translated">获取结果</h1><p id="2bcb" class="pw-post-body-paragraph kr ks iq kt b ku mm jr kw kx mn ju kz la mo lc ld le mp lg lh li mq lk ll lm ij bi translated">还有最后一个特性，如果你想存储动画，比如向客户展示。您可以将<em class="nq">显示模式</em>设置为“文件”或“屏幕”(默认)。在文件模式下，它会将每个图像作为一个单独的文件保存到指定的路径。</p><p id="1fe2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">走到最后一步，创建一个动画，大概是很少的 Python 代码，但是我还没有做到。同时，你可以用 iMovie 之类的工具把图片串起来。</p></div></div>    
</body>
</html>