<html>
<head>
<title>Review: ResNet — Winner of ILSVRC 2015 (Image Classification, Localization, Detection)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">点评:ResNet——2015 年国际影像分类、定位、检测奖得主</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8?source=collection_archive---------4-----------------------#2018-09-15">https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8?source=collection_archive---------4-----------------------#2018-09-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="343b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本故事中，<strong class="jp ir"> ResNet </strong> [1]回顾。ResNet 可以通过<strong class="jp ir">学习残差表示函数</strong>而不是直接学习信号表示，拥有一个<strong class="jp ir">的<strong class="jp ir">非常深</strong>的网络达到 152 层</strong>。</p><p id="daab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> ResNet 引入了跳过连接</strong>(或<strong class="jp ir">快捷连接</strong>)来将来自上一层的输入适配到下一层，而不对输入进行任何修改。跳过连接使得能够有更深的网络，最终 ResNet 成为 ILSVRC 2015 在图像分类、检测和定位方面的<strong class="jp ir">赢家，以及 MS COCO 2015 检测和分割的赢家。</strong>这是一篇<strong class="jp ir"> 2016 CVPR </strong>论文，引用<strong class="jp ir">超过 19000 次。</strong> ( <a class="kl km ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----e39402bfa5d8--------------------------------" rel="noopener" target="_blank">曾锡豪</a> @中)</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi kn"><img src="../Images/ef2044764bf66b635af77816b737d623.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IGgSqXFauzbeJtZJ6CBPbg.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">ILSVRC 2015 Image Classification Ranking</strong></figcaption></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="4854" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">ImageNet 是一个数据集，包含超过 1500 万张带有标签的高分辨率图像，大约有 22，000 个类别。ILSVRC 在 1000 个类别中的每个类别中使用大约 1000 个图像的 ImageNet 子集。总的来说，大约有 120 万幅训练图像、50，000 幅验证图像和 100，000 幅测试图像。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="05b4" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">涵盖哪些内容</h1><ol class=""><li id="ad5c" class="mj mk iq jp b jq ml ju mm jy mn kc mo kg mp kk mq mr ms mt bi translated"><strong class="jp ir">平面网络问题(消失/爆炸梯度)</strong></li><li id="ef11" class="mj mk iq jp b jq mu ju mv jy mw kc mx kg my kk mq mr ms mt bi translated"><strong class="jp ir">剩余网络中的跳过/快捷连接(ResNet) </strong></li><li id="c2ea" class="mj mk iq jp b jq mu ju mv jy mw kc mx kg my kk mq mr ms mt bi translated"><strong class="jp ir"> ResNet 架构</strong></li><li id="fce5" class="mj mk iq jp b jq mu ju mv jy mw kc mx kg my kk mq mr ms mt bi translated"><strong class="jp ir">瓶颈设计</strong></li><li id="637f" class="mj mk iq jp b jq mu ju mv jy mw kc mx kg my kk mq mr ms mt bi translated"><strong class="jp ir">消融研究</strong></li><li id="fd38" class="mj mk iq jp b jq mu ju mv jy mw kc mx kg my kk mq mr ms mt bi translated"><strong class="jp ir">与最先进方法的比较(图像分类)</strong></li><li id="5b9a" class="mj mk iq jp b jq mu ju mv jy mw kc mx kg my kk mq mr ms mt bi translated"><strong class="jp ir">与最先进方法的比较(物体检测)</strong></li></ol></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="bc57" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated"><strong class="ak"> 1。普通网络的问题</strong></h1><p id="3e44" class="pw-post-body-paragraph jn jo iq jp b jq ml js jt ju mm jw jx jy mz ka kb kc na ke kf kg nb ki kj kk ij bi translated"><strong class="jp ir">对于传统的深度学习网络</strong>，它们通常有 conv 层，然后是用于分类任务的全连接(FC)层，如 AlexNet、ZFNet 和 VGGNet，没有任何跳过/快捷连接，我们在这里将它们称为<strong class="jp ir">平面网络</strong>。<strong class="jp ir">当平面网络较深时(层数增加)，会出现消失/爆炸渐变的问题。</strong></p><h2 id="3339" class="nc lm iq bd ln nd ne dn lr nf ng dp lv jy nh ni lz kc nj nk md kg nl nm mh nn bi translated">消失/爆炸渐变</h2><p id="f384" class="pw-post-body-paragraph jn jo iq jp b jq ml js jt ju mm jw jx jy mz ka kb kc na ke kf kg nb ki kj kk ij bi translated">在反向传播期间，当误差函数相对于训练的每次迭代中的当前权重的偏导数时，这具有将这些小/大数的<em class="no"> n </em>乘以<em class="no"> n </em>层网络中的“前”层的梯度的效果</p><p id="23dc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当网络很深的时候，这些小数字的乘积<em class="no"> n </em>就会变成零(消失)。</p><p id="d64a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当网络很深，并且这些大数相乘<em class="no"> n </em>就会变得过大(爆炸)。</p><p id="391b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们期望更深的网络会有更准确的预测。然而，下面显示了一个例子，<strong class="jp ir"> 20 层平面网络比 56 层平面网络</strong>具有更低的训练误差和测试误差，由于梯度消失，出现了退化问题。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi np"><img src="../Images/52f64fd81d3fa7d5693272bed85381af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8IeAViN2CT7abuYK4XWfCg.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">Plain Networks for CIFAR-10 Dataset</strong></figcaption></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="ee0c" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">2.<strong class="ak">剩余网络中的跳过/快捷连接(ResNet) </strong></h1><p id="e9b9" class="pw-post-body-paragraph jn jo iq jp b jq ml js jt ju mm jw jx jy mz ka kb kc na ke kf kg nb ki kj kk ij bi translated">为了解决消失/爆炸渐变的问题，添加了一个跳过/快捷连接，以在几个权重层后将输入<em class="no"> x </em>添加到输出，如下所示:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/14d41948e535243c27e242891b02f328.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*rbhjv7ZdAgXM2MlBUL5Mmw.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">A Building Block of Residual Network</strong></figcaption></figure><p id="67b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，输出<em class="no"> H(x)= </em> <em class="no"> F(x) + x </em>。<strong class="jp ir">权重层其实就是学习一种残差映射:<em class="no"> F(x)=H(x)-x </em> </strong>。</p><p id="c1b7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">即使权重层存在消失梯度，我们仍然始终有身份<em class="no"> x </em>转移回更早的层。</strong></p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="88b3" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">3.ResNet 架构</h1><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi nr"><img src="../Images/a1bd786fcaef3d853f8f51905c30dccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6hF97Upuqg_LdsqWY6n_wg.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">34-layer ResNet with Skip / Shortcut Connection (Top), 34-layer Plain Network (Middle), 19-layer VGG-19 (Bottom)</strong></figcaption></figure><p id="4096" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上图显示了 ResNet 架构。</p><ol class=""><li id="7680" class="mj mk iq jp b jq jr ju jv jy ns kc nt kg nu kk mq mr ms mt bi translated">VGG-19 [2](下图)是 2014 年 ILSVRC 中最先进的方法。</li><li id="2c81" class="mj mk iq jp b jq mu ju mv jy mw kc mx kg my kk mq mr ms mt bi translated"><strong class="jp ir"> 34 层平面网(中间)作为 VGG-19 </strong>的深层网，即更多的 conv 层。</li><li id="82f1" class="mj mk iq jp b jq mu ju mv jy mw kc mx kg my kk mq mr ms mt bi translated"><strong class="jp ir"> 34 层残差网络(ResNet)(上)是普通网络，增加了 skip / shortcut 连接。</strong></li></ol><p id="24ed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于 ResNet，当输入尺寸小于输出尺寸时，有<strong class="jp ir"> 3 种类型的跳过/快捷连接。</strong></p><p id="770e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(A)快捷方式执行标识映射，并额外填充零以增加维度。因此，没有额外的参数。</p><p id="a0f5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(B)投影快捷方式仅用于增加维度，其他快捷方式是恒等式。需要额外的参数。</p><p id="317e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(C)所有快捷方式都是投影。额外的参数比(B)的多。</p><h1 id="0a51" class="ll lm iq bd ln lo nv lq lr ls nw lu lv lw nx ly lz ma ny mc md me nz mg mh mi bi translated"><strong class="ak"> 4。瓶颈设计</strong></h1><p id="120b" class="pw-post-body-paragraph jn jo iq jp b jq ml js jt ju mm jw jx jy mz ka kb kc na ke kf kg nb ki kj kk ij bi translated">由于现在网络很深，时间复杂度很高。瓶颈设计用于降低复杂性，如下所示:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/69a154a525afc08120e03ef57c8469da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*aGYJlTYjzhO9tC-sGjzmvg.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">The Basic Block (Left) and The Proposed Bottleneck Design (Right)</strong></figcaption></figure><p id="dec2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如图(右)所示，<strong class="jp ir"> 1×1 conv 层被添加到网络</strong>的起点和终点。这是网络中的网络和 GoogLeNet (Inception-v1)中建议的技术。事实证明，<strong class="jp ir"> 1×1 conv 可以减少连接(参数)的数量，同时不会使网络性能下降太多。</strong>(有兴趣请访问我的评论。)</p><p id="12d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">通过瓶颈设计，34 层 ResNet 变成了 50 层 ResNet。</strong>还有<strong class="jp ir">有瓶颈设计的更深网络:</strong> <strong class="jp ir"> ResNet-101 和 ResNet-152。</strong>全网整体架构如下:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi ob"><img src="../Images/fea76566dfa2ad1072c58c29c61ff212.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_3va4Zi5lzs5EKeSWyTgWw.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">The overall architecture for all network</strong></figcaption></figure><p id="9a4c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意到<strong class="jp ir"> VGG-16/19 有 15.3/19.6 亿次 FLOPS。ResNet-152 的复杂度仍然低于 VGG-16/19！！！！</strong></p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="acd2" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">5.消融研究</h1><h2 id="bbce" class="nc lm iq bd ln nd ne dn lr nf ng dp lv jy nh ni lz kc nj nk md kg nl nm mh nn bi translated">5.1 普通网络与 ResNet</h2><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi oc"><img src="../Images/51d42bfcceeefe9ee85d29c9af93dd50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k9o3BFNQCkLsC1Wadpod0w.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">Validation Error: 18-Layer and 34-Layer Plain Network (Left), 18-Layer and 34-Layer ResNet (right)</strong></figcaption></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi od"><img src="../Images/70a2cd5b35e474ed11c32dba652d7ffb.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*qIxWtZYrdi1p3tTGuKKnyA.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">Top-1 Error Using 10-Crop Testing</strong></figcaption></figure><p id="6a1f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当使用平面网络时，由于消失梯度问题，18 层比 34 层好。</p><p id="2b03" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用 ResNet 时，34 层优于 18 层，通过跳过连接解决了消失梯度问题。</p><p id="6890" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果对比 18 层的素网和 18 层的 ResNet，没有太大区别。这是因为对于浅层网络不存在消失梯度问题。</p><h2 id="6507" class="nc lm iq bd ln nd ne dn lr nf ng dp lv jy nh ni lz kc nj nk md kg nl nm mh nn bi translated"><strong class="ak"> 5.2 其他设置</strong></h2><p id="51bf" class="pw-post-body-paragraph jn jo iq jp b jq ml js jt ju mm jw jx jy mz ka kb kc na ke kf kg nb ki kj kk ij bi translated"><strong class="jp ir">批量归一化</strong>(从 Inception-v2) <strong class="jp ir"> </strong>用在每次 conv 之后。<strong class="jp ir">使用 10-作物测试</strong>。采用多尺度平均分数的<strong class="jp ir">全卷积形式</strong> <strong class="jp ir"> {224，256，384，480，640} </strong>。<strong class="jp ir"> 6 个模型用于集成增强。</strong>以上是之前深度学习框架中使用的一些技术。如果感兴趣，也请随时阅读我的评论。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="af73" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated"><strong class="ak"> 6。与最先进方法的比较(图像分类)</strong></h1><h2 id="c5ef" class="nc lm iq bd ln nd ne dn lr nf ng dp lv jy nh ni lz kc nj nk md kg nl nm mh nn bi translated"><strong class="ak"> 6.1 ILSVRC </strong></h2><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/267485638f9a98d928ba9ece5ee9ac24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*J4bprdWbW2F-E0z0dGptJw.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">10-Crop Testing Results</strong></figcaption></figure><p id="0f41" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过比较 ResNet-34 A、B 和 C，<strong class="jp ir"> B 略好于 A，C 略好于 B，因为引入了额外的参数，所有参数的误差率都在 7%左右。</strong></p><p id="cf84" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">通过将网络深度增加到 152 层，获得了 5.71%的 top-5 错误率</strong>，这比 VGG-16、GoogLeNet (Inception-v1)和 PReLU-Net 好得多。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi of"><img src="../Images/b9a4ed889ed717b82dbacaf03e39ff89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*CqUPq-w3h3u7m1LTiXycxg.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">10-Crop Testing + Fully Conv with Multiple Scale Results</strong></figcaption></figure><p id="af3e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> ResNet-152 通过 10 次作物测试+多次完全 Conv，可以获得 4.49%的错误率。</strong></p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi og"><img src="../Images/6e8f5672774f48d6278725eb066fe73b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*n3n_MLPaiUjQrzpjrxex1Q.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">10-Crop Testing + Fully Conv with Multiple Scale + 6-Model Ensemble Results</strong></figcaption></figure><p id="dcfd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">加入 6 模型集成技术，<strong class="jp ir">错误率为 3.57%。</strong></p><h2 id="b37f" class="nc lm iq bd ln nd ne dn lr nf ng dp lv jy nh ni lz kc nj nk md kg nl nm mh nn bi translated">6.2 CIFAR-10</h2><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="gh gi oh"><img src="../Images/581e6a1ea3e423d201e980e79825d5bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bcsDb-VfzXZIsPgjeAV9SA.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">CIFAR-10 Results</strong></figcaption></figure><p id="976b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有了 skip 连接，我们可以更深入。然而，当层数从 110 层增加到 1202 层时，误差率从 6.43%增加到 7.93%，这是一个有待解决的问题。尽管如此，ResNet-1202 不存在优化困难，即它仍然可以收敛。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="caad" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated"><strong class="ak"> 7。与最先进方法的比较(物体检测)</strong></h1><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/eae2a860288b8369b73c4336157a7e30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*FjD9z_dGPiOjoQYyCMYKLA.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">PASCAL VOC 2007/2012 mAP (%)</strong></figcaption></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/3c94c77e711d4909541a764a6f01150d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*FgshWKTjYjD1uNLtaUMueA.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk"><strong class="bd ld">MS COCO mAP (%)</strong></figcaption></figure><p id="401c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">通过在更快的 R-CNN 中采用 ResNet-101，ResNet 获得了比 VGG-16 更好的性能。</strong></p><p id="1a85" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">ResNet 最终获得了 ImageNet 检测、定位、COCO 检测和 COCO 分割的第一名！！！</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><h1 id="ffb7" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">参考</h1><ol class=""><li id="511a" class="mj mk iq jp b jq ml ju mm jy mn kc mo kg mp kk mq mr ms mt bi translated">【2016 CVPR】【ResNet】<br/><a class="ae ok" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank">用于图像识别的深度残差学习</a></li><li id="695a" class="mj mk iq jp b jq mu ju mv jy mw kc mx kg my kk mq mr ms mt bi translated">【2015 ICLR】【VGGNet】<br/><a class="ae ok" href="https://arxiv.org/pdf/1409.1556" rel="noopener ugc nofollow" target="_blank">用于大规模图像识别的极深度卷积网络</a></li><li id="5fd2" class="mj mk iq jp b jq mu ju mv jy mw kc mx kg my kk mq mr ms mt bi translated">[2015 NIPS][更快的 R-CNN] <br/> <a class="ae ok" href="https://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf" rel="noopener ugc nofollow" target="_blank">更快的 R-CNN:通过区域提议网络实现实时目标检测</a></li><li id="af18" class="mj mk iq jp b jq mu ju mv jy mw kc mx kg my kk mq mr ms mt bi translated">【2017 TPAMI】【更快的 R-CNN】<br/><a class="ae ok" href="https://ieeexplore.ieee.org/document/7485869/" rel="noopener ugc nofollow" target="_blank">更快的 R-CNN:利用区域提议网络实现实时对象检测</a></li></ol><h1 id="a2e7" class="ll lm iq bd ln lo nv lq lr ls nw lu lv lw nx ly lz ma ny mc md me nz mg mh mi bi translated">我的评论</h1><ol class=""><li id="8844" class="mj mk iq jp b jq ml ju mm jy mn kc mo kg mp kk mq mr ms mt bi translated"><a class="ae ok" href="https://medium.com/@sh.tsang/review-faster-r-cnn-object-detection-f5685cb30202" rel="noopener">回顾:更快的 R-CNN(物体检测)</a></li><li id="dee3" class="mj mk iq jp b jq mu ju mv jy mw kc mx kg my kk mq mr ms mt bi translated"><a class="ae ok" href="https://medium.com/@sh.tsang/review-batch-normalization-inception-v2-bn-inception-the-2nd-to-surpass-human-level-18e2d0f56651" rel="noopener">回顾:批量归一化(Inception-v2/BN-Inception)——ILSVRC 2015 中第二个超越人类水平的性能(图像分类)</a></li><li id="6320" class="mj mk iq jp b jq mu ju mv jy mw kc mx kg my kk mq mr ms mt bi translated"><a class="ae ok" href="https://medium.com/coinmonks/review-prelu-net-the-first-to-surpass-human-level-performance-in-ilsvrc-2015-image-f619dddd5617" rel="noopener">回顾:在 ILSVRC 2015(图像分类)中第一个超越人类水平性能的 PReLU-Net</a></li><li id="06c4" class="mj mk iq jp b jq mu ju mv jy mw kc mx kg my kk mq mr ms mt bi translated"><a class="ae ok" href="https://medium.com/coinmonks/paper-review-of-googlenet-inception-v1-winner-of-ilsvlc-2014-image-classification-c2b3565a64e7" rel="noopener">回顾:Google net(Inception v1)——ILSVRC 2014(图像分类)获奖者</a></li><li id="4ccc" class="mj mk iq jp b jq mu ju mv jy mw kc mx kg my kk mq mr ms mt bi translated"><a class="ae ok" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener">点评:VGGNet—ils vrc 2014 亚军(图像分类)、冠军(本地化)</a></li></ol></div></div>    
</body>
</html>