<html>
<head>
<title>Feel discouraged by the sparse data in your hand? Give Factorization Machine a shot (1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对手中稀疏的数据感到气馁？给因式分解机一个机会(1)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/feel-discouraged-by-sparse-data-in-your-hand-give-factorization-machine-a-shot-1-7094628aa4ff?source=collection_archive---------11-----------------------#2018-11-15">https://towardsdatascience.com/feel-discouraged-by-sparse-data-in-your-hand-give-factorization-machine-a-shot-1-7094628aa4ff?source=collection_archive---------11-----------------------#2018-11-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="fd7c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你是一名工业界的数据科学家，你是否有过这样的经历:面对你的客户，告诉他们由于数据稀疏，项目可能无法实现他们的期望？</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/cee24a6b2d85b723ccbf39b6df1bfb1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*ebvnLNzKit9UpB300tvkrw.jpeg"/></div></figure><p id="2ce1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">的确，没有人能无草制砖。准确地说，<strong class="js iu"> <em class="kw">中的<strong class="js iu"> <em class="kw">大量</em> </strong>名副其实的</em> </strong>数据是数据科学家期待的‘稻草’。然而，事实并不总是如此。我们应该让数据的弱点阻止我们进行我们的项目吗？不要！</p><p id="2d4b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">今天，我将介绍一个高性能模型，即使没有理想的数据，它也能产生出色的结果。就是<strong class="js iu"> <em class="kw">因式分解机</em> </strong> (FM)。</p><p id="5471" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="kw">因式分解机</em> </strong>是 2012 年 Steffen Rendle 在日本大阪大学工作期间想出的。它已经成为推荐系统和文本分析的主流模型。</p><p id="ace2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">作者强调了 FM 的三大优势:</p><p id="156f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 1。</strong> <strong class="js iu">对稀疏数据友好。</strong></p><p id="b28a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 2。</strong> <strong class="js iu">线性计算复杂度。</strong></p><p id="2310" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 3。</strong> <strong class="js iu">一个通用的预测器。</strong></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi kx"><img src="../Images/bb122ff2dec05d66cd3f94cc29731787.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*MivjJQ4cdme3zEWmUGbvrw.gif"/></div></div></figure><p id="844c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在阐明因式分解机之前，让我们用一个应用场景来描述这个模型。</p><p id="aeac" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">“电子商务网站要求你根据每个顾客的历史评分数据，预测他们对每件商品的评分。”</p><p id="a612" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该比率从 1 到 5 递增，适用于来自<strong class="js iu"> <em class="kw">非常差</em> </strong>、<strong class="js iu"> <em class="kw">差、一般到好以及优秀</em> </strong>的印象。</p><p id="305c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在，让我们来看一下历史数据。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi lc"><img src="../Images/8b9fc8b5bdbbaec83a03ecc25bbe1526.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DUC7lBVCJnvd_z_pGfYmyw.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">historical rated data by users to merchandises</figcaption></figure><p id="1e04" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="kw">列</em> </strong>表示商品名称，包括“靴子”、“咖啡豆”、“杯子”、“耳机”、“花”、“足球”、“帽子”、“笔记本电脑”、“连指手套”和“毛衣”。<strong class="js iu"> <em class="kw">行</em> </strong>指的是用户名包括 April、Brian、Daniel、Eric 和 Frank。</p><p id="110d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">矩阵中的每个值都是用户对该行中该列商品的评分。</strong></p><p id="eb20" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然而，在实际场景中，网站通常需要支持数百万用户和商品的高吞吐量。只有用户购买的商品才能从顾客那里得到分数。很有可能我们会得到一个非常<strong class="js iu"> <em class="kw">大的稀疏矩阵</em> </strong>，其中<strong class="js iu"> <em class="kw"> </em> </strong>的大部分值都是零。</p><p id="067a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在继续之前，让我们将问题简化为"<strong class="js iu">基于用户如何与他/她购买的商品(X) </strong>进行交互来对分数(Y)建模。"</p><p id="7e7a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这里来 2 度因式分解机的模型方程。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi lh"><img src="../Images/8689cbbc056c8b5fb4939ab1d3ca5f7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ehw5_Jmb-nZ02pPP2vdxkA.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">The model equation of factorization machine of 2 degrees</figcaption></figure><p id="2114" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="kw">看着眼熟？</em> </strong>是的，它是在线性回归的基础上增加了自变量之间的相互作用这一项而发展起来的。该等式中的<strong class="js iu"> <em class="kw"> Wij </em> </strong>是在我们的示例中量化用户和机构之间的交互的系数。</p><p id="0d7b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如何估计相互作用系数<strong class="js iu"> <em class="kw"> Wij </em> </strong>也是本文讨论的重点，也是因式分解机的显著特点。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi li"><img src="../Images/30c3c0a74dfd2121d05ab24b795df763.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kuaTmJN_rVQ2k_knShtjQQ.jpeg"/></div></div></figure><p id="6e24" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">回到我们讨论的大型稀疏数据，如果我们直接进行系数估计会发生什么？</strong>不难知道，由于历史数据中没有交互(用户和机构之间),大量系数将被估计为零。</p><p id="60d6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果我们还陷入直接从已知去研究未知的思维习惯，怎么给一个用户从来不评分的项目打分呢？这就是<strong class="js iu"> <em class="kw">因式分解机</em> </strong>的用武之地。</p><p id="4632" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">“因式分解在机器中通过因式分解对交互进行建模，这允许在稀疏性下对高阶交互进行高质量的参数估计。”</strong></p><p id="5e8b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">听起来很抽象？</p><p id="89f8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在就让<strong class="js iu"> <em class="kw">用更多的角色来丰富用户</em> </strong>的描述吧。April 是一名 26 岁的亚洲女性，是一名科学家，住在洛杉矶。四月的形象通过她的<strong class="js iu"> <em class="kw">性别、年龄、职业、种族和居住地</em> </strong> <em class="kw">变得具体。</em></p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi lj"><img src="../Images/faf492ab23599ad5b0a7c2b878a3a73d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TpccjWKEgtHKRnsyj4CwUA.jpeg"/></div></div></figure><p id="a17f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="kw">同样，</em> </strong>她评价的杯子是为圣诞节设计的绿色陶瓷杯，70 美元，星巴克的。杯子的更多细节被考虑进去，如<strong class="js iu"> <em class="kw">颜色、质地、类型、季节、价格和公司</em> </strong>。</p><p id="6261" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">在系数估计中描述两个具有多重特征的自变量的过程就是因式分解的过程。</strong></p><p id="8cf7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，在数学中，独立变量表示如下。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi lk"><img src="../Images/d2e9cfe436879d32fc0357d1b932e184.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SMQhJUnvGy2HdEYsovfYxA.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">The feature vector representing independent variables</figcaption></figure><p id="7013" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="kw"> k </em> </strong>是描述自变量的数量特征。<strong class="js iu"> <em class="kw"> i </em> </strong>是自变量的个数。在圣诞杯四月得分的例子中，用户和商品分别有 6 个特征。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi ll"><img src="../Images/d188e772f4708919e66c3bca02498d38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WVWv395TMIwjgwRfI-iq4w.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">The feature vector of user</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi lm"><img src="../Images/e969080c378c57e28fb4bc966a4717c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SvT55fyZnmctWPfJFDBlRQ.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">The feature vector of merchandise</figcaption></figure><p id="13d8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，用户和商品之间的交互可以用下面的格式表示。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/d535ab79d89579fb128576c1b96dbf8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*LyhQT_EnYpo0GU-lryIICw.jpeg"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">The interactions between i-th and j-th variable</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/ab9a5da1ea0d3507b83dc34e06c2d6da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*4BMCzMkPzX7J-eMpa3OwVQ.jpeg"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">The calculation process of the interaction coefficient</figcaption></figure><p id="0b36" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">模型方程可以重写如下。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/cfab4a2c72be8737712cab4e87488957.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*5Gnk50KK2XmO4f_Gl62-1w.jpeg"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">The model equation of factorization machine of 2 degrees</figcaption></figure><p id="ebe8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">到目前为止，你可能想知道为什么要费心通过特征向量将变量扩展到多堆维度？痛点和策略有什么关系？</p><p id="ba2c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因为它们通过分解相互作用参数打破了它们的独立性。一般来说，这意味着一个相互作用的数据也有助于估计相关相互作用的参数。”</p><p id="0ccd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我用我们掌握的数据来说明这一点。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="gh gi lc"><img src="../Images/77b1842d3fc7939fcdf3b07b4db20592.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pi6EroDIDrbTYBrDRyDzEg.jpeg"/></div></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">historical rated data by users to merchandises</figcaption></figure><p id="eb51" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从上面的观察来看，由<strong class="js iu">埃里克</strong>对<strong class="js iu"> <em class="kw">咖啡豆</em> </strong>和<strong class="js iu"> <em class="kw">杯</em> </strong>的费率差不多，分别是 5(<strong class="js iu"><em class="kw">【W(埃里克，咖啡豆)</em> </strong>)和 4(<strong class="js iu"><em class="kw">【W(埃里克，杯)</em> </strong>)。于是特征向量<strong class="js iu"> <em class="kw"> V(咖啡豆)</em> </strong>和<strong class="js iu"> <em class="kw"> V(杯子)</em> </strong>可以视为大致相同，<strong class="js iu"> <em class="kw"> V(咖啡豆)</em> </strong> = <strong class="js iu"> <em class="kw"> V(杯子)</em> </strong>。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/18c095eb91a99d16245e8e33ba083fc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*3cB3VuXmMiObo_NMwE_ZkQ.jpeg"/></div></figure><p id="7b55" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此<strong class="js iu"> <em class="kw"> W(四月，咖啡豆)</em> </strong>，四月率到咖啡豆，<strong class="js iu"> <em class="kw"> </em> </strong>可以推断为与<em class="kw"> </em> <strong class="js iu"> <em class="kw"> W(四月，杯)</em> </strong>相同，即 1 <em class="kw">。</em></p><p id="8762" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">完美解决痛点。哈？</p><p id="f013" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们把独立变量的所有特征向量放入矩阵。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/36135940826c2f7136158339f4111806.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*jEMaOCZfFKF7hF5VzweL3A.jpeg"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">The matrix containing all feature vectors</figcaption></figure><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ls"><img src="../Images/2507bf0fd982c1a5de41fa4e9e2e3069.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*rdI2wHQjMfNuzQ2zSLrG5w.jpeg"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">The feature vectors in matrix</figcaption></figure><p id="f355" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="kw">左边两个矩阵</em> </strong>是自变量特征向量的展开。</p><p id="da6d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="kw">右矩阵</em> </strong>包含两个特征向量相乘的交互系数。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/c9b0352913ad1cbc562f6744addfaadb.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/1*P-FOPbKUkdYqotXFZMrK8w.jpeg"/></div><figcaption class="ld le gj gh gi lf lg bd b be z dk">The interaction matrix of 2-degree Factorization Machine</figcaption></figure><p id="671d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">标有蓝色的那一半矩阵正是要估计的相互作用项。</p><p id="7260" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">那么如何估计模型的系数呢？为什么说计算复杂度是线性的？让我们把它们放在下一篇文章中。</p><p id="1b88" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> <em class="kw">简报:</em> </strong></p><p id="e054" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本文通过推荐系统中的一个应用场景来介绍因式分解机，通过矩阵分解来解决稀疏数据下的系数估计问题。</p><p id="7df5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">paper . DVI<a class="ae lu" href="https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf" rel="noopener ugc nofollow" target="_blank">https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf</a></p><p id="ae58" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果您有任何问题，请随时留下您的评论。</p></div></div>    
</body>
</html>