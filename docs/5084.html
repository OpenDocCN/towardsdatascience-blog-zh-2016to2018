<html>
<head>
<title>DCGANs (Deep Convolutional Generative Adversarial Networks)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度卷积生成对抗网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dcgans-deep-convolutional-generative-adversarial-networks-c7f392c2c8f8?source=collection_archive---------6-----------------------#2018-09-26">https://towardsdatascience.com/dcgans-deep-convolutional-generative-adversarial-networks-c7f392c2c8f8?source=collection_archive---------6-----------------------#2018-09-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jn jo jp jq"><div class="bz fp l di"><div class="jr js l"/></div></figure><p id="ff41" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">生成对抗网络最有趣的部分之一是生成网络的设计。生成器网络能够获取随机噪声并将其映射到图像中，使得鉴别器无法辨别哪些图像来自数据集，哪些图像来自生成器。</p><p id="073c" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">这是神经网络的一个非常有趣的应用。通常，神经网络将输入映射为二进制输出(1 或 0)，可能是回归输出(某个实数值)，甚至是多个分类输出(如 MNIST 或 CIFAR-10/100)。</p><p id="6d4c" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">在本文中，我们将看到神经网络如何从随机噪声映射到图像矩阵，以及在生成器网络中使用卷积层如何产生更好的结果。</p><p id="977f" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">我们将回顾在 ICLR 展示<a class="ae kr" href="https://arxiv.org/abs/1511.06434" rel="noopener ugc nofollow" target="_blank"> DCGANs 的论文，这是一个生成卧室的生成器网络架构，我们将回顾来自 GANs-in-Action 知识库的一些 Python/Keras 代码。</a></p><figure class="kt ku kv kw gt jq gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ks"><img src="../Images/ad648464bc39e2311eb0d01d65943445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rdXKdyfNjorzP10ZA3yNmQ.png"/></div></div></figure><p id="2404" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">这是 LSUN 场景建模论文中介绍的 DCGAN 生成器。该网络接收一个 100×1 的噪声矢量，表示为 Z，并将其映射到 64×64×3 的 G(Z)输出。</p><p id="797f" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">这种架构特别有趣的是第一层扩展随机噪声的方式。网络从 100x1 到 1024x4x4！这一层被称为“项目和整形”。</p><p id="0447" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">我们看到，在这一层之后，应用了传统的卷积层，该卷积层使用传统卷积层教导的(N+P — F)/S + 1 等式来重塑网络。在上图中，我们可以看到 N 参数(高度/宽度)从 4 到 8 到 16 到 32，似乎没有任何填充，内核过滤器参数 F 是 5x5，步幅是 2。您可能会发现，这个等式对于设计定制输出大小的卷积层非常有用。</p><p id="4d7c" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">我们看到网络从</p><p id="ba98" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">100 x 1→1024 x 4 x 4→512 x 8 x 8→256 x 16 x 16→128 x 32 x 32→64 x 64 x 3</p><figure class="kt ku kv kw gt jq gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ld"><img src="../Images/d72246743a7d81a379944edd7ca83eb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bNjBJm6827sRXvzmcjGTDQ.png"/></div></div></figure><p id="ea25" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">以上是论文中给出的网络输出，引用了 5 代训练后的结果。相当令人印象深刻的东西。</p><p id="7844" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">现在，让我们看一些 python 代码:</p><p id="4df3" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">这段代码摘自 Jakub Langr 和 Vladimir Bok 创建的 gans-in-action 知识库，据我所知，这是在 Keras 中实现 gans 的最佳入门代码。我认为这本书还没有发行，但我想象它会很好。</p><div class="le lf gp gr lg lh"><a href="https://github.com/GANs-in-Action/gans-in-action/blob/master/chapter-3/Chapter_3_GAN.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="li ab fo"><div class="lj ab lk cl cj ll"><h2 class="bd ir gy z fp lm fr fs ln fu fw ip bi translated">战斗中的甘斯/战斗中的甘斯</h2><div class="lo l"><h3 class="bd b gy z fp lm fr fs ln fu fw dk translated">行动中的 GANs 的伙伴知识库:具有生成性对抗网络的深度学习…</h3></div><div class="lp l"><p class="bd b dl z fp lm fr fs ln fu fw dk translated">github.com</p></div></div><div class="lq l"><div class="lr l ls lt lu lq lv lb lh"/></div></div></a></div><p id="590b" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">下面的代码是我如何运行我的第一个 GAN 网络的，(没有实现 DCGANs):</p><pre class="kt ku kv kw gt lw lx ly lz aw ma bi"><span id="e814" class="mb mc iq lx b gy md me l mf mg">def generator(img_shape, z_dim):<br/>  model = Sequential()</span><span id="d07c" class="mb mc iq lx b gy mh me l mf mg">  # Hidden layer<br/>  model.add(Dense(128, input_dim = z_dim))</span><span id="abb4" class="mb mc iq lx b gy mh me l mf mg">  # Leaky ReLU<br/>  model.add(LeakyReLU(alpha=0.01))</span><span id="9c0b" class="mb mc iq lx b gy mh me l mf mg">  # Output layer with tanh activation<br/>  model.add(Dense(28*28*1, activation='tanh'))<br/>  model.add(Reshape(img_shape)</span><span id="aa2a" class="mb mc iq lx b gy mh me l mf mg">  z = Input(shape=(z_dim,))<br/>  img = model(z)</span><span id="fb8c" class="mb mc iq lx b gy mh me l mf mg">  return Model(z, img)</span></pre><p id="662d" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">下面的架构并不复杂，实际上在 MNIST 数据集的例子上产生了相当不错的结果。该模型接受噪声矢量并将其映射到密集连接的层，该层映射到输出层，该输出层是被整形为 28×28 MNIST 数字矩阵的平面 784×1 矢量。</p><p id="6484" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">现在让我们将其与 gans-in-action 存储库中提供的 DCGAN 代码进行对比:</p><pre class="kt ku kv kw gt lw lx ly lz aw ma bi"><span id="f5fd" class="mb mc iq lx b gy md me l mf mg">def generator(img_shape, z_dim):<br/>  model = Sequential()<br/> <br/>  # Reshape input into 7x7x256 tensor via a fully connected layer<br/>  model.add(Dense(256*7*7, input_dim = z_dim))<br/>  model.add(Reshape((7,7,256))</span><span id="2f1a" class="mb mc iq lx b gy mh me l mf mg">  # Transposed convolution layer, from 7x7x256 into 14x14x128 tensor<br/>  model.add(Conv2DTranspose(<br/>               128, kernel_size = 3, strides = 2, padding='same'))</span><span id="684d" class="mb mc iq lx b gy mh me l mf mg">  #Batch normalization<br/>  model.add(BatchNormalization())</span><span id="a543" class="mb mc iq lx b gy mh me l mf mg">  #Leaky ReLU<br/>  model.add(LeakyReLU(alpha=0.01))</span><span id="d94c" class="mb mc iq lx b gy mh me l mf mg">  # Transposed convolution layer, from 14x14x128 to 14x14x64 tensor<br/>  model.add(Conv2DTranspose(<br/>              64, kernel_size=3, strides=1, padding='same'))</span><span id="31a4" class="mb mc iq lx b gy mh me l mf mg">  # Batch normalization<br/>  model.add(BatchNormalization())</span><span id="aa06" class="mb mc iq lx b gy mh me l mf mg">  # Leaky ReLU<br/>  model.add(LeakyReLU(alpha=0.01))</span><span id="391d" class="mb mc iq lx b gy mh me l mf mg">  # Transposed convolution layer, from 14x14x64 to 28x28x1 tensor<br/>  model.add(Conv2DTranspose(<br/>               1, kernel_size = 3, strides = 2, padding='same'))</span><span id="7f13" class="mb mc iq lx b gy mh me l mf mg">  # Tanh activation<br/>  model.add(Activation('tanh'))</span><span id="9363" class="mb mc iq lx b gy mh me l mf mg">  z = Input(shape=(z_dim,))<br/>  img = model(z)</span><span id="cc94" class="mb mc iq lx b gy mh me l mf mg">  return Model(z, img)</span></pre><p id="e770" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">我们看到上面的架构非常类似于 ICLR，LSUN 场景生成器论文中提出的 DCGAN。输入从 100×1 噪声投射到 7x7x256 张量，然后卷积，直到达到 28×28×1 MNIST 数字输出。</p><figure class="kt ku kv kw gt jq gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ks"><img src="../Images/ad648464bc39e2311eb0d01d65943445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rdXKdyfNjorzP10ZA3yNmQ.png"/></div></div></figure><p id="c4f9" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">同样，我们看到同样的项目和整形，接着是卷积层进入起始代码中图表的输出。</p><h1 id="ff08" class="mi mc iq bd mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne bi translated">结论</h1><p id="7d61" class="pw-post-body-paragraph jt ju iq jv b jw nf jy jz ka ng kc kd ke nh kg kh ki ni kk kl km nj ko kp kq ij bi translated">我希望这篇文章能帮助您开始构建自己的 DCGANs。我认为它至少很好地解释了高层架构应该如何工作。剩下的挑战在于为卷积层以及投影和整形层找到正确的参数。</p><p id="c484" class="pw-post-body-paragraph jt ju iq jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ij bi translated">我真的发现这个开源代码库和 ICLR 论文的结合有助于我理解这个概念。我对构建 GANs 并看到他们能做什么感到非常兴奋，请留下您认为真正有帮助的任何其他资源的评论。如果您想了解使用这些 DCGANs 进行数据扩充的进一步研究，请点击此处。</p></div><div class="ab cl nk nl hu nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="ij ik il im in"><h1 id="8c78" class="mi mc iq bd mj mk nr mm mn mo ns mq mr ms nt mu mv mw nu my mz na nv nc nd ne bi translated"><a class="ae kr" href="https://medium.com/@connorshorten300" rel="noopener"> CShorten </a></h1><p id="fc78" class="pw-post-body-paragraph jt ju iq jv b jw nf jy jz ka ng kc kd ke nh kg kh ki ni kk kl km nj ko kp kq ij bi translated">Connor Shorten 是佛罗里达大西洋大学计算机科学专业的学生。对计算机视觉、深度学习和软件工程感兴趣。</p></div></div>    
</body>
</html>