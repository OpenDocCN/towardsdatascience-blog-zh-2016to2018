<html>
<head>
<title>I scraped BuzzFeed’s database of NYPD police disciplinary cases</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我从BuzzFeed上搜集了NYPD警察纪律案件的数据库</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/i-scraped-buzzfeeds-database-of-nypd-police-disciplinary-cases-74a30bb5fde8?source=collection_archive---------9-----------------------#2018-04-16">https://towardsdatascience.com/i-scraped-buzzfeeds-database-of-nypd-police-disciplinary-cases-74a30bb5fde8?source=collection_archive---------9-----------------------#2018-04-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="3ad5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">BuzzFeed的数据很棒，但我们能以一种更有用的格式收集它吗？</h2></div><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi kg"><img src="../Images/85562d9dbe039319208a9d74e540b461.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Y6UjdVVkh88lcPoK."/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Photo by <a class="ae kw" href="https://unsplash.com/@worldcity?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Dane Tewari</a> on <a class="ae kw" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="2e86" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated"><strong class="kz ir">TL；博士:</strong> BuzzFeed今天发布了一组<a class="ae kw" href="https://www.buzzfeed.com/kendalltaggart/nypd-police-misconduct-database-explainer" rel="noopener ugc nofollow" target="_blank">有趣的数据</a>——大约1800名被“指控行为不当”的纽约警察局(NYPD)雇员的纪律案件档案我写了<a class="ae kw" href="https://github.com/joshtemple/nypd-cases" rel="noopener ugc nofollow" target="_blank">一个scraper </a>来下载PDF和纯文本格式的数据进行大规模分析。</p><p id="eb37" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">不幸的是，案例文件的存储方式不便于大规模分析。每个案例文件都以单独的PDF格式存储，但是没有明确的方法下载所有的文件。原始文本存储在JavaScript界面中的选项卡后面。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi lt"><img src="../Images/e0b73d7daf6febc89847935d3cf80960.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AAThXJJsEL1eilj4hp-anA.png"/></div></div></figure><p id="95d4" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我想对这些数据进行一些基于文本的分析，但是为了做到这一点，我需要每个案例文件的原始文本(最好是pdf)。手动下载每一个都很耗时，所以我决定构建一个刮刀来收集数据。</p><h2 id="c8e4" class="lu lv iq bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated">下载PDF数据</h2><p id="3ef8" class="pw-post-body-paragraph kx ky iq kz b la mn jr lc ld mo ju lf lg mp li lj lk mq lm ln lo mr lq lr ls ij bi translated">首先，BuzzFeed提供了一个有用的<a class="ae kw" href="http://data.buzzfeed.com/projects/2018-04-nypd/nypd-discipline.csv" rel="noopener ugc nofollow" target="_blank"> CSV文件</a>，其中包含每个案例文件的URL。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi ms"><img src="../Images/bbb86e5b3f4513d950190a53dcfeb3c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cK40EklF2EWRllF_jqtIqw.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">A few rows from the BuzzFeed CSV.</figcaption></figure><p id="594d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">CSV中的链接会将您带到存储在DocumentCloud上的案例文件。该接口主要是JavaScript，这使得抓取更具挑战性，因为没有太多的HTML。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi mt"><img src="../Images/eda0e39dc68e7155578502358c8d1b3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hXVuMmizhu09mcXAtxqZHQ.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Each case file has been converted to plain text via <a class="ae kw" href="https://en.wikipedia.org/wiki/Optical_character_recognition" rel="noopener ugc nofollow" target="_blank">optical character recognition (OCR)</a>, though the conversion is fairly messy.</figcaption></figure><p id="bf3b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我的第一个目标是下载PDF格式的所有案例文件。PDF文件存储在与BuzzFeed CSV中的URL结构非常相似的URL中。通过一点regex，我能够将DocumentCloud URLs转换为PDF资产的URL，并使用Python的<a class="ae kw" href="http://docs.python-requests.org/en/master/" rel="noopener ugc nofollow" target="_blank"> requests </a>库下载它们。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="mu mv l"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">A few regular expressions format the URL correctly for downloading the PDF.</figcaption></figure><h2 id="a5d9" class="lu lv iq bd lw lx ly dn lz ma mb dp mc lg md me mf lk mg mh mi lo mj mk ml mm bi translated">下载文本数据</h2><p id="4606" class="pw-post-body-paragraph kx ky iq kz b la mn jr lc ld mo ju lf lg mp li lj lk mq lm ln lo mr lq lr ls ij bi translated">下载转换后的纯文本更具挑战性。纯文本位于DocumentCloud JavaScript界面中，在一个名为text的选项卡后面。通过HTML抓取文本是不可行的，因为它不存在于页面的常规源代码中。对于Selenium这样的web驱动程序来说，这是一个自然的用例，它允许您像人类一样与web页面进行交互。</p><p id="581b" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">为了获取数据，我需要Selenium单击Text选项卡，以便下载纯文本。我需要一种可靠的方法来访问Selenium中的文本选项卡，所以我使用了Chrome的开发工具<em class="mw">(在Chrome中，右键单击感兴趣的元素，然后单击Inspect) </em>来获取文本选项卡的XPath。<a class="ae kw" href="https://en.wikipedia.org/wiki/XPath" rel="noopener ugc nofollow" target="_blank"> XPath </a>是一种查询语言，它使得在网页上查找特定元素变得更加容易。有时候自己编写XPath查询更好，因为这样会更灵活。在这种情况下，Chrome的XPath足以让我每次都能看到文本标签。</p><figure class="kh ki kj kk gt kl gh gi paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gh gi mx"><img src="../Images/b4b4c4a2ec515abe564db3adfad407e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_nKuL2sdAwHZ52fMmKQ43A.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Chrome Developer Tools makes XPath easy. Right click on the tag of interest and choose Copy &gt;&gt; Copy XPath.</figcaption></figure><p id="8c5d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">使用XPath查询，我指示Selenium单击Text选项卡。通过检查Chrome开发工具中的文本，不难获得纯文本的HTML类的名称。我可以使用Selenium的text属性将原始文本下载到一个文件中。</p><figure class="kh ki kj kk gt kl"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="d67d" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">最后，我编写了一个循环来为CSV中的每个URL下载PDF和原始文本文件。现在，我有了一个数据语料库，可以对其应用我自己的OCR算法或建立文本挖掘分析。</p><p id="c6f5" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">一般来说，没有一种“正确的”方法可以从网络上抓取数据。在这种情况下，我没有使用基于HTML的抓取(例如，使用像<a class="ae kw" href="http://docs.python-requests.org/en/master/" rel="noopener ugc nofollow" target="_blank">请求</a>这样的库)，但是逆向工程URL和Selenium抓取的结合给了我所需要的。</p><p id="f178" class="pw-post-body-paragraph kx ky iq kz b la lb jr lc ld le ju lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">如果您想下载BuzzFeed数据集用于您自己的分析，请在这里克隆我的刮刀<a class="ae kw" href="https://github.com/joshtemple/nypd-cases" rel="noopener ugc nofollow" target="_blank">并让我知道它是如何为您工作的！</a></p></div></div>    
</body>
</html>