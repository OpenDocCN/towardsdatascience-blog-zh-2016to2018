<html>
<head>
<title>How to Preprocess Character Level Text with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用 Keras 预处理字符级文本</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-preprocess-character-level-text-with-keras-349065121089?source=collection_archive---------8-----------------------#2018-07-06">https://towardsdatascience.com/how-to-preprocess-character-level-text-with-keras-349065121089?source=collection_archive---------8-----------------------#2018-07-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/a1319abdee869d1c187ddccc9c3e1451.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WALRM3RW8XGSbV_Avouqeg.jpeg"/></div></div></figure><blockquote class="kb kc kd"><p id="8ea0" class="ke kf kg kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><em class="it">你可以在这里找到笔记本</em><a class="ae ld" href="https://github.com/BrambleXu/nlp-beginner-guide-keras/blob/master/char-level-cnn/notebooks/char-level-text-preprocess-with-keras-summary.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="it"/></a></p></blockquote><p id="f2bb" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">这篇简介的目的是让您了解如何使用 Keras 在字符级预处理文本。文章的其余部分组织如下。</p><ul class=""><li id="e47b" class="lh li it kh b ki kj km kn le lj lf lk lg ll lc lm ln lo lp bi translated">加载数据</li><li id="5501" class="lh li it kh b ki lq km lr le ls lf lt lg lu lc lm ln lo lp bi translated">标记器</li><li id="c6a1" class="lh li it kh b ki lq km lr le ls lf lt lg lu lc lm ln lo lp bi translated">改变词汇</li><li id="5c19" class="lh li it kh b ki lq km lr le ls lf lt lg lu lc lm ln lo lp bi translated">要索引的字符</li><li id="8bc9" class="lh li it kh b ki lq km lr le ls lf lt lg lu lc lm ln lo lp bi translated">填料</li><li id="ac24" class="lh li it kh b ki lq km lr le ls lf lt lg lu lc lm ln lo lp bi translated">获取标签</li></ul><h1 id="0d7a" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">加载数据</h1><p id="a106" class="pw-post-body-paragraph ke kf it kh b ki mt kk kl km mu ko kp le mv ks kt lf mw kw kx lg mx la lb lc im bi translated">首先，我们使用 pandas 加载训练数据。</p><figure class="mz na nb nc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi my"><img src="../Images/cb073d46cc6b87b2297a163c73dcc7dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YiHWk0_1r1G7ZqNb"/></div></div></figure><p id="b2d0" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">将第 1 列和第 2 列合并为一个文本。</p><figure class="mz na nb nc gt ju gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/a52971c2bf943d6d5fcab2fec16b5dd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/0*kd5MHaGsv29c81PN"/></div></figure><h1 id="2211" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">标记器</h1><p id="64b3" class="pw-post-body-paragraph ke kf it kh b ki mt kk kl km mu ko kp le mv ks kt lf mw kw kx lg mx la lb lc im bi translated">将第 1 列保存到<code class="fe ne nf ng nh b">texts</code>，并将所有句子转换为小写。</p><figure class="mz na nb nc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ni"><img src="../Images/1040872fef841e6d920a39add0aca150.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IvSrkJDpHGEEVi_2"/></div></div></figure><p id="8868" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">初始化记号赋予器时，只有两个参数很重要。</p><ul class=""><li id="2547" class="lh li it kh b ki kj km kn le lj lf lk lg ll lc lm ln lo lp bi translated"><code class="fe ne nf ng nh b">char_level=True</code>:这可以告诉<code class="fe ne nf ng nh b">tk.texts_to_sequences()</code>在字符级处理句子。</li><li id="915d" class="lh li it kh b ki lq km lr le ls lf lt lg lu lc lm ln lo lp bi translated"><code class="fe ne nf ng nh b">oov_token='UNK'</code>:这将在词汇表中添加一个 UNK 令牌。我们可以用<code class="fe ne nf ng nh b">tk.oov_token</code>来称呼它。</li></ul><p id="c47a" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">在调用<code class="fe ne nf ng nh b">tk.fit_on_texts(texts)</code>之后，<code class="fe ne nf ng nh b">tk</code>类将包含关于训练数据的必要信息。我们可以调用<code class="fe ne nf ng nh b">tk.word_index</code>来查看字典。这里<code class="fe ne nf ng nh b">UNK</code>的索引是<code class="fe ne nf ng nh b">word_count+1</code>。</p><figure class="mz na nb nc gt ju gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/c03b30cba31198cf8bcfdc5d482a8882.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/0*2FfXeSKylnXvMA3e"/></div></figure><p id="cb72" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">这是从训练数据中学习到的字符字典。但是如果我们已经有一个角色列表，我们必须改变<code class="fe ne nf ng nh b">tk_word_index</code>。</p><h1 id="98ab" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">改变词汇</h1><p id="97cc" class="pw-post-body-paragraph ke kf it kh b ki mt kk kl km mu ko kp le mv ks kt lf mw kw kx lg mx la lb lc im bi translated">看到我已经有一个角色列表调用<code class="fe ne nf ng nh b">alphabet</code>，我们基于<code class="fe ne nf ng nh b">alphabet</code>构建一个<code class="fe ne nf ng nh b">char_dict</code>。</p><figure class="mz na nb nc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nk"><img src="../Images/bc5764462e39d118e23469e46d67a53a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lW0GldyfLc38mN31"/></div></div></figure><p id="3c4a" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">我们将为<code class="fe ne nf ng nh b">UNK</code>分配一个新的索引。</p><figure class="mz na nb nc gt ju gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/74adfbc4d5122a9d8977a368cb123698.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*UoaqaW2Z3T3D8ZWj"/></div></figure><h1 id="f10f" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">要索引的字符</h1><p id="b81d" class="pw-post-body-paragraph ke kf it kh b ki mt kk kl km mu ko kp le mv ks kt lf mw kw kx lg mx la lb lc im bi translated">在我们得到正确的词汇后，我们可以用字符索引来表示所有的文本。</p><p id="414d" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">这一步非常简单，<code class="fe ne nf ng nh b">tk.texts_to_sequences()</code>会为我们自动完成这个转换。</p><figure class="mz na nb nc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nm"><img src="../Images/d3e120c533856aea8926ecf261aebc56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AjcsDHzsX1BpYcaD"/></div></div></figure><p id="192a" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">我们可以看到字符串表示被索引表示所取代。我们列出了前 5 个句子长度。</p><figure class="mz na nb nc gt ju gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/bfdae9a72743a2add72a076a67f157a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/0*g9f6hoHmUxbKmfHO"/></div></figure><h1 id="c065" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">填料</h1><p id="b52d" class="pw-post-body-paragraph ke kf it kh b ki mt kk kl km mu ko kp le mv ks kt lf mw kw kx lg mx la lb lc im bi translated">因为文本有不同的长度，我们必须使所有的文本长度相同，这样 CNN 就可以处理批量数据。</p><figure class="mz na nb nc gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi no"><img src="../Images/ae8ac536776c377f346f0a6fd86bad17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IRrsvEKhyCHB48Py"/></div></div></figure><p id="569a" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">这里我们将最大句子长度设置为 1014。如果文本的长度小于 1014，则该部分的其余部分将被填充为 0。如果文本长度大于 1014，超过 1014 的部分将被截断。因此所有文本将保持相同的长度。</p><p id="1a4d" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">最后，我们将列表转换成 Numpy 数组。</p><figure class="mz na nb nc gt ju gh gi paragraph-image"><div class="gh gi np"><img src="../Images/19fa33f3530f7a2646c2fd6fdb05829a.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/0*G5tz7VKD6Z5Vbm8K"/></div></figure><h1 id="7441" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">获取标签</h1><p id="de7a" class="pw-post-body-paragraph ke kf it kh b ki mt kk kl km mu ko kp le mv ks kt lf mw kw kx lg mx la lb lc im bi translated">首先，我们将<code class="fe ne nf ng nh b">train_df</code>中的第 0 列分配给一个<code class="fe ne nf ng nh b">class_list</code>，这个一维列表包含每个文本的所有标签。但是我们的任务是一个多类任务，所以我们必须把它转换成一个二维数组。这里我们可以使用 Keras 中的<code class="fe ne nf ng nh b">to_categorical</code>方法</p><figure class="mz na nb nc gt ju gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/24fda4ba9f1dbebdb59e6e03ad3c7e27.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/0*vqxdQV9GadEQvTCu"/></div></figure><p id="dced" class="pw-post-body-paragraph ke kf it kh b ki kj kk kl km kn ko kp le kr ks kt lf kv kw kx lg kz la lb lc im bi translated">至于测试数据集，我们只需要再次执行相同的过程。</p><h1 id="6b28" class="lv lw it bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">摘要</h1><p id="5ca0" class="pw-post-body-paragraph ke kf it kh b ki mt kk kl km mu ko kp le mv ks kt lf mw kw kx lg mx la lb lc im bi translated">为了方便使用，我将所有代码加在一起。</p><pre class="mz na nb nc gt nr nh ns nt aw nu bi"><span id="4903" class="nv lw it nh b gy nw nx l ny nz"># write all code in one cell</span><span id="5c89" class="nv lw it nh b gy oa nx l ny nz">#========================Load data=========================<br/>import numpy as np<br/>import pandas as pd</span><span id="9e81" class="nv lw it nh b gy oa nx l ny nz">train_data_source = '../data/ag_news_csv/train.csv'<br/>test_data_source = '../data/ag_news_csv/test.csv'</span><span id="f29f" class="nv lw it nh b gy oa nx l ny nz">train_df = pd.read_csv(train_data_source, header=None)<br/>test_df = pd.read_csv(test_data_source, header=None)</span><span id="c224" class="nv lw it nh b gy oa nx l ny nz"># concatenate column 1 and column 2 as one text<br/>for df in [train_df, test_df]:<br/>    df[1] = df[1] + df[2]<br/>    df = df.drop([2], axis=1)<br/>    <br/># convert string to lower case <br/>train_texts = train_df[1].values <br/>train_texts = [s.lower() for s in train_texts]</span><span id="9fa4" class="nv lw it nh b gy oa nx l ny nz">test_texts = test_df[1].values <br/>test_texts = [s.lower() for s in test_texts]</span><span id="2c2a" class="nv lw it nh b gy oa nx l ny nz">#=======================Convert string to index================<br/>from keras.preprocessing.text import Tokenizer<br/>from keras.preprocessing.sequence import pad_sequences</span><span id="3578" class="nv lw it nh b gy oa nx l ny nz"># Tokenizer<br/>tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')<br/>tk.fit_on_texts(train_texts)<br/># If we already have a character list, then replace the tk.word_index<br/># If not, just skip below part</span><span id="b5e1" class="nv lw it nh b gy oa nx l ny nz">#-----------------------Skip part start--------------------------<br/># construct a new vocabulary <br/>alphabet="abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\"/\\|_@#$%^&amp;*~`+-=&lt;&gt;()[]{}"<br/>char_dict = {}<br/>for i, char in enumerate(alphabet):<br/>    char_dict[char] = i + 1<br/>    <br/># Use char_dict to replace the tk.word_index<br/>tk.word_index = char_dict <br/># Add 'UNK' to the vocabulary <br/>tk.word_index[tk.oov_token] = max(char_dict.values()) + 1<br/>#-----------------------Skip part end----------------------------</span><span id="aaff" class="nv lw it nh b gy oa nx l ny nz"># Convert string to index <br/>train_sequences = tk.texts_to_sequences(train_texts)<br/>test_texts = tk.texts_to_sequences(test_texts)</span><span id="2eb3" class="nv lw it nh b gy oa nx l ny nz"># Padding<br/>train_data = pad_sequences(train_sequences, maxlen=1014, padding='post')<br/>test_data = pad_sequences(test_texts, maxlen=1014, padding='post')</span><span id="e819" class="nv lw it nh b gy oa nx l ny nz"># Convert to numpy array<br/>train_data = np.array(train_data)<br/>test_data = np.array(test_data)</span><span id="8421" class="nv lw it nh b gy oa nx l ny nz">#=======================Get classes================<br/>train_classes = train_df[0].values<br/>train_class_list = [x-1 for x in train_classes]</span><span id="6c36" class="nv lw it nh b gy oa nx l ny nz">test_classes = test_df[0].values<br/>test_class_list = [x-1 for x in test_classes]</span><span id="bfaf" class="nv lw it nh b gy oa nx l ny nz">from keras.utils import to_categorical<br/>train_classes = to_categorical(train_class_list)<br/>test_classes = to_categorical(test_class_list)</span></pre><blockquote class="kb kc kd"><p id="9d5b" class="ke kf kg kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc im bi translated"><strong class="kh iu"> <em class="it">查看我的其他帖子</em> </strong> <a class="ae ld" href="https://medium.com/@bramblexu" rel="noopener"> <strong class="kh iu"> <em class="it">中等</em> </strong> </a> <strong class="kh iu"> <em class="it">同</em> </strong> <a class="ae ld" href="https://bramblexu.com/posts/eb7bd472/" rel="noopener ugc nofollow" target="_blank"> <strong class="kh iu"> <em class="it">一分类查看</em> </strong> </a> <strong class="kh iu"> <em class="it">！<br/>GitHub:</em></strong><a class="ae ld" href="https://github.com/BrambleXu" rel="noopener ugc nofollow" target="_blank"><strong class="kh iu"><em class="it">bramble Xu</em></strong></a><strong class="kh iu"><em class="it"><br/>LinkedIn:</em></strong><a class="ae ld" href="https://www.linkedin.com/in/xu-liang-99356891/" rel="noopener ugc nofollow" target="_blank"><strong class="kh iu"><em class="it">徐亮</em> </strong> </a> <strong class="kh iu"> <em class="it"> <br/>博客:</em></strong><a class="ae ld" href="https://bramblexu.com" rel="noopener ugc nofollow" target="_blank"><strong class="kh iu"><em class="it">bramble Xu</em></strong></a></p></blockquote></div></div>    
</body>
</html>