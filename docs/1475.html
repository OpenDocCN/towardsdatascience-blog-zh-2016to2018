<html>
<head>
<title>Familiarization of Sequence to Sequence model in Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习中序列对序列模型的熟悉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sequence-to-sequence-using-encoder-decoder-15e579c10a94?source=collection_archive---------9-----------------------#2017-09-08">https://towardsdatascience.com/sequence-to-sequence-using-encoder-decoder-15e579c10a94?source=collection_archive---------9-----------------------#2017-09-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="a3b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">序列到序列模型</strong>是接受序列输入并输出序列的模型。</p><h1 id="9236" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><strong class="ak">建筑</strong></h1><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="ab gu cl lo"><img src="../Images/f8da36b368e705e4e44c844e2918fc8d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*CbrcRZVFynXnSJM0OBZL1w.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Sequence to Sequence</figcaption></figure><p id="944a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">编码器</strong> r是一个RNN，接收输入并将其编码成一个向量。</p><p id="b6b7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">编码器的<strong class="jp ir">最后隐藏状态</strong>给出编码向量。</p><p id="1be9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">编码向量重复n次，其中<strong class="jp ir">n =输出的时间步长数。</strong></p><p id="f8fe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">解码器</strong>，也是RNN，将<strong class="jp ir">编码矢量</strong>和<strong class="jp ir">先前</strong> <strong class="jp ir">状态</strong>作为输入，并给出输出。</p><h2 id="64b5" class="lv km iq bd kn lw lx dn kr ly lz dp kv jy ma mb kz kc mc md ld kg me mf lh mg bi translated">编码器和解码器中的时间步长数不需要相等。</h2><h1 id="e696" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><strong class="ak">为什么是Seq2seq？</strong></h1><p id="a0c6" class="pw-post-body-paragraph jn jo iq jp b jq mh js jt ju mi jw jx jy mj ka kb kc mk ke kf kg ml ki kj kk ij bi translated">当你想在看到整个输入句子后生成输出时，可以使用seq2seq模型。</p><p id="0fd0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，在机器翻译中，翻译句子中的第一个单词可能取决于输入句子中的最后一个单词。</p><h1 id="128c" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><strong class="ak">图像字幕</strong></h1><p id="b080" class="pw-post-body-paragraph jn jo iq jp b jq mh js jt ju mi jw jx jy mj ka kb kc mk ke kf kg ml ki kj kk ij bi translated">在图像字幕中，生成图像的文本描述。</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="gh gi mm"><img src="../Images/30262135cb07938484f7d62ff60700b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aK57SNxiEdxPakgY.png"/></div></div></figure><h2 id="3d94" class="lv km iq bd kn lw lx dn kr ly lz dp kv jy ma mb kz kc mc md ld kg me mf lh mg bi translated"><strong class="ak">训练数据由带有相应标题的图像组成。</strong></h2><p id="e91b" class="pw-post-body-paragraph jn jo iq jp b jq mh js jt ju mi jw jx jy mj ka kb kc mk ke kf kg ml ki kj kk ij bi translated">编码器现在被卷积神经网络所取代。来自最后一个隐藏状态的输出被提供给解码器RNN。</p></div></div>    
</body>
</html>