<html>
<head>
<title>Custom Optimizer in TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow中的自定义优化器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/custom-optimizer-in-tensorflow-d5b41f75644a?source=collection_archive---------5-----------------------#2017-11-13">https://towardsdatascience.com/custom-optimizer-in-tensorflow-d5b41f75644a?source=collection_archive---------5-----------------------#2017-11-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/b022f68eceec4eb7f9f472f0e5cd919f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/0*Q8wwCCdYhZEIqOlM.png"/></div></figure><h1 id="2e8a" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">介绍</h1><p id="af67" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">当对非结构化数据建模时，例如在语言或图像处理中，神经网络起着非常重要的作用。这种网络的想法是使用节点和边来模拟大脑的结构，这些节点和边具有由激活函数处理的数字权重。这种网络的输出主要产生预测，例如分类。这是通过使用一些优化损失函数对给定目标进行优化来实现的。<br/> <br/>在<a class="ae lq" href="https://www.bigdatarepublic.nl/regression-prediction-intervals-with-xgboost/" rel="noopener ugc nofollow" target="_blank">之前的一篇文章</a>中，我们已经讨论了定制这个损失函数的重要性，对于梯度推进树的情况。在本帖中，我们将讨论如何定制优化器来加速和改进寻找损失函数(局部)最小值的过程。</p><h1 id="e205" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">优化者</h1><p id="51cb" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">虽然神经网络的架构在从数据中提取信息时起着重要作用，但所有(大多数)都是通过基于损失函数梯度的更新规则来优化的。</p><p id="df7c" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">更新规则由优化器决定。不同优化器的性能和更新速度可能会有很大差异。梯度告诉我们更新的方向，但是我们可能采取多大的一步还不清楚。小步让我们保持在正确的轨道上，但是可能要花很长时间才能达到(局部)最小值。大步加快了这个过程，但它可能会把我们推离正确的方向。</p><p id="0b10" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated"><a class="ae lq" href="http://ruder.io/optimizing-gradient-descent/index.html#adam" rel="noopener ugc nofollow" target="_blank">亚当</a>【2】和<a class="ae lq" href="http://ruder.io/optimizing-gradient-descent/index.html#rmsprop" rel="noopener ugc nofollow" target="_blank">rms prop</a>【3】是两个非常流行的优化器，仍然在大多数神经网络中使用。两者都使用梯度及其平方的指数衰减平均值来更新变量。</p><p id="ace2" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">通过生成固定的数值更新或代数规则，已经进行了寻找新的优化器的研究。</p><p id="9f21" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">使用控制器递归神经网络，一个团队[1]发现了两种新的有趣的优化器，PowerSign和AddSign，它们都是高性能的，并且比当前流行的优化器(如Adam)需要更少的资源。</p><h1 id="b2be" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">在TensorFlow中实现优化器</h1><p id="ae0c" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">Tensorflow是一个流行的用于实现神经网络的python框架。虽然文档非常丰富，但要找到阅读它的方法通常是一个挑战。</p><p id="37c2" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">在这篇博文中，我将解释如何实现PowerSign和AddSign。</p><p id="6434" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">优化器包括两个重要步骤:</p><ul class=""><li id="fa1e" class="lw lx iq ku b kv lr kz ls ld ly lh lz ll ma lp mb mc md me bi translated"><strong class="ku ir"> compute_gradients() </strong>更新计算图形中的梯度</li><li id="fd20" class="lw lx iq ku b kv mf kz mg ld mh lh mi ll mj lp mb mc md me bi translated"><strong class="ku ir"> apply_gradients() </strong>更新变量</li></ul><p id="245e" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">在运行Tensorflow会话之前，应该启动一个优化器，如下所示:</p><figure class="mk ml mm mn gt jr"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="b2a6" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated"><code class="fe mq mr ms mt b">tf.train.GradientDescentOptimizer</code>是类<code class="fe mq mr ms mt b">GradientDescentOptimizer</code>的对象，顾名思义，它实现了梯度下降算法。</p><p id="8576" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">方法<strong class="ku ir"> minimize() </strong>以“成本”作为参数被调用，由两个方法<strong class="ku ir"> compute_gradients() </strong>和<strong class="ku ir"> apply_gradients() </strong>组成。</p><p id="a76e" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">对于这篇文章，以及AddSign和PowerSign的实现，我们必须仔细看看这最后一步<strong class="ku ir"> apply_gradients() </strong>。</p><p id="b70f" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">该方法依赖于我们将要创建的(new) <code class="fe mq mr ms mt b">Optimizer</code>(类)来实现以下方法:<strong class="ku ir"> _create_slots() </strong>，<strong class="ku ir"> _prepare() </strong>，<strong class="ku ir"> _apply_dense() </strong>，<strong class="ku ir"> _apply_sparse() </strong>。</p><p id="bddd" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated"><strong class="ku ir"> _create_slots() </strong>和<strong class="ku ir"> _prepare() </strong>创建并初始化附加变量，如动量。</p><p id="e166" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated"><strong class="ku ir"> _apply_dense() </strong>和<strong class="ku ir"> _apply_sparse() </strong>实现实际的Ops，更新变量。Ops一般都是用C++写的。您无需自己更改C++头文件，仍然可以通过这些方法返回一些操作的python包装器。</p><p id="0c37" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">这是按如下方式完成的:</p><figure class="mk ml mm mn gt jr"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="1216" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">现在让我们把所有东西放在一起，展示PowerSign和AddSign的实现。</p><p id="05fa" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">首先，您需要以下模块来添加Ops，</p><figure class="mk ml mm mn gt jr"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="82f3" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">现在让我们实现AddSign和PowerSign。这两个优化器实际上非常相似，都利用了动量的符号</p><p id="974a" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated"><code class="fe mq mr ms mt b">m</code>和<code class="fe mq mr ms mt b">g</code>进行渐变更新。</p><figure class="mk ml mm mn gt jr gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/f8bb045b7de3e4b040f20a0e9d015a3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:88/format:webp/0*9wx_uCF-0cTkdzAM.png"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">The momentum and gradient, respectively.</figcaption></figure><h2 id="85fd" class="mz jv iq bd jw na nb dn ka nc nd dp ke ld ne nf ki lh ng nh km ll ni nj kq nk bi translated">PowerSign</h2><p id="efda" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">对于PowerSign，变量的更新工作如下:</p><figure class="mk ml mm mn gt jr gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/4730ce17d9b180949e98efed97b8b9d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/0*REHJxXHS1jNuaPca.png"/></div></figure><p id="bfd3" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">以下代码中的衰减率<code class="fe mq mr ms mt b">f_n</code>被设置为1。我不会在这里讨论这个问题，我可以参考文献[1]了解更多细节。</p><figure class="mk ml mm mn gt jr"><div class="bz fp l di"><div class="mo mp l"/></div></figure><h2 id="7243" class="mz jv iq bd jw na nb dn ka nc nd dp ke ld ne nf ki lh ng nh km ll ni nj kq nk bi translated">添加标志</h2><p id="e3ef" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">AddSign与PowerSign非常相似，如下所示:</p><figure class="mk ml mm mn gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi nm"><img src="../Images/c0588b5eb8b35281ee0b01aa1a5dc4ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*esgSYxuFjV36-VK-.png"/></div></div></figure><figure class="mk ml mm mn gt jr"><div class="bz fp l di"><div class="mo mp l"/></div></figure><h1 id="1b30" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">优化器的性能测试</h1><p id="8b07" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">Rosenbrock函数是一个著名的优化算法性能测试。该函数是非凸的，定义如下:</p><figure class="mk ml mm mn gt jr gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/b68f791864995048f16bfb8ab07c0c63.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/0*A7CzxQVunjj4hjPT.png"/></div></figure><p id="7ea0" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">生成的形状绘制在下图中。正如我们所见，它在x = 1和y = 1时有一个最小值。</p><figure class="mk ml mm mn gt jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/b022f68eceec4eb7f9f472f0e5cd919f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1158/format:webp/0*Q8wwCCdYhZEIqOlM.png"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Rosenbrock function</figcaption></figure><p id="19ba" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">以下脚本通过给定优化器在每个时期生成真实最小值与近似最小值的欧几里德距离。</p><figure class="mk ml mm mn gt jr"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="fdaf" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">下面绘制了运行4000个时期的每个优化器的性能比较。</p><figure class="mk ml mm mn gt jr gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/f6e9e9526f6e89cfeea0f99bf4bd030b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/0*7GDQkh7mVyQsPrAS.png"/></div></figure><p id="9261" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">虽然性能因超参数的选择而有很大差异，但需要注意PowerSign的极快收敛。下面，已经绘制了几个时期的近似值的坐标。</p><figure class="mk ml mm mn gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nn no di np bf nq"><div class="gh gi nt"><img src="../Images/4dc1187d1105eecb985eaac4d98628c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PRg-EFhCUGzLlSwVLd6dbw.png"/></div></div></figure><h2 id="7b95" class="mz jv iq bd jw na nb dn ka nc nd dp ke ld ne nf ki lh ng nh km ll ni nj kq nk bi translated">最终讨论</h2><p id="7b18" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">Tensorflow允许我们创建自己的定制程序。最近的研究进展产生了两个新的有前途的优化器，即PowerSign和AddSign。PowerSign的快速早期收敛使其成为一个有趣的优化器，可以与Adam等其他优化器结合使用。</p><p id="7ebf" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">参考:</p><ol class=""><li id="4bf0" class="lw lx iq ku b kv lr kz ls ld ly lh lz ll ma lp nu mc md me bi translated">有关PowerSign和AddSign的更多信息，请参见arxiv论文“具有强化学习的神经优化器搜索”，Bello等人。艾尔。，<a class="ae lq" href="https://arxiv.org/abs/1709.07417." rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1709.07417.</a></li><li id="77a0" class="lw lx iq ku b kv mf kz mg ld mh lh mi ll mj lp nu mc md me bi translated">金马博士和巴律师事务所(2015年)。亚当:一种随机优化方法。学习表征国际会议，1-13。</li><li id="fbcd" class="lw lx iq ku b kv mf kz mg ld mh lh mi ll mj lp nu mc md me bi translated">未发表过的</li><li id="84b4" class="lw lx iq ku b kv mf kz mg ld mh lh mi ll mj lp nu mc md me bi translated">通过<a class="ae lq" href="https://stackoverflow.com/questions/38431054/how-to-create-an-optimizer-in-tensorflow" rel="noopener ugc nofollow" target="_blank">这篇StackOverflow帖子</a>，我发现了很多有用的信息，并试图将其捆绑到这篇帖子中。</li></ol></div></div>    
</body>
</html>