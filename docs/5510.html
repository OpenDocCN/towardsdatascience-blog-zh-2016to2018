<html>
<head>
<title>AI Aids Eyes : A computer vision system to remind operators to wear safety glasses</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能辅助眼睛:一个计算机视觉系统，提醒操作员戴上安全眼镜</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ai-aids-eyes-a-computer-vision-system-to-remind-operators-to-wear-safety-glasses-ba0a1fe51b0?source=collection_archive---------22-----------------------#2018-10-22">https://towardsdatascience.com/ai-aids-eyes-a-computer-vision-system-to-remind-operators-to-wear-safety-glasses-ba0a1fe51b0?source=collection_archive---------22-----------------------#2018-10-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="1549" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">演示</h1><p id="af3d" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这是该系统的演示。</p><p id="e29e" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">当系统检测到有人拿起电钻时，它会自动发出安全眼镜警告。为了表示安全眼镜警告的存在，在演示视频中，RGB 图像的边框是红色的。</p><p id="c47a" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">当系统检测到没有钻头被拾起时，它不会发出任何安全眼镜警告。为了表示没有安全眼镜警告，在演示视频中，RGB 图像的边框是绿色的。</p><p id="c8bb" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">如演示视频所示，计算机视觉系统成功检测到操作员是否拿起了钻头。</p><figure class="lo lp lq lr gt ls"><div class="bz fp l di"><div class="lt lu l"/></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk">Demo</figcaption></figure><h1 id="d414" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">五金器具</h1><p id="df82" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我用木材(来自家得宝)形成一个支撑结构。然后，我在支撑结构上安装了一个微软 XBOX 360 Kinect 传感器(来自亚马逊)，以监控地面上的活动。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi lz"><img src="../Images/7a2ba4a2efce4f00f113c2ee9d4ff382.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zm4tXjJjmV1txXS0kq3yZQ.jpeg"/></div></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk">Hardware</figcaption></figure><h1 id="d8c9" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">分割</h1><p id="b1ca" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">下面示出了由 RGB 图像、深度图像和提取的对象的图像组成的示例。</p><figure class="lo lp lq lr gt ls gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi mg"><img src="../Images/c72a4656fc85a6996e8c84ba86d88d4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PZ7VlYA_1vdzJJok2vBgmQ.png"/></div></div><figcaption class="lv lw gj gh gi lx ly bd b be z dk">RGB image, depth image and the image of the segmented object for classification</figcaption></figure><p id="7c61" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">对于计算机视觉算法来说，仅从 RGB 图像来确定操作者的手是否拿着钻头是具有挑战性的。但是，有了深度信息，问题就简单了。</p><p id="13a6" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">我的分割算法将 RGB 图像上像素的颜色设置为黑色，如果其对应的深度在预定义的范围之外。这使我能够分割被拾取的对象。</p><h1 id="27f4" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">分类</h1><p id="82eb" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我通过分别拍摄自己手持电钻/挥舞双手来收集数据。</p><p id="b456" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">然后，我使用迁移学习技术来调整一个 VGG 神经网络，该网络是使用 ImageNet 预先训练的。但是结果并不好。也许提取的图像与 ImageNet 中的自然图像不相似。</p><p id="0a82" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">因此，我从头开始使用提取的图像来训练卷积神经网络。结果还算不错。在验证集上，分类器的准确率约为 95%。</p><p id="dfa2" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">该模型的一个片段如下所示。</p><pre class="lo lp lq lr gt mh mi mj mk aw ml bi"><span id="870c" class="mm jo iq mi b gy mn mo l mp mq">from keras.preprocessing.image import ImageDataGenerator<br/>from keras.models import Sequential<br/>from keras.layers import Conv2D, MaxPooling2D<br/>from keras.layers import Activation, Dropout, Flatten, Dense<br/>from keras import backend as K</span><span id="137c" class="mm jo iq mi b gy mr mo l mp mq"># dimensions of our images.<br/>img_width, img_height = 120, 120</span><span id="8f8d" class="mm jo iq mi b gy mr mo l mp mq">train_data_dir = '/home/kakitone/Desktop/kinect/data/train4/'<br/>validation_data_dir = '/home/kakitone/Desktop/kinect/data/test4/'<br/>nb_train_samples = 2000<br/>nb_validation_samples = 1000<br/>epochs = 5<br/>batch_size = 8</span><span id="6109" class="mm jo iq mi b gy mr mo l mp mq">if K.image_data_format() == 'channels_first':<br/>    input_shape = (3, img_width, img_height)<br/>else:<br/>    input_shape = (img_width, img_height, 3)</span><span id="35c3" class="mm jo iq mi b gy mr mo l mp mq">model = Sequential()<br/>model.add(Conv2D(4, (3, 3), input_shape=input_shape))<br/>model.add(Activation('relu'))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))</span><span id="fe84" class="mm jo iq mi b gy mr mo l mp mq">model.add(Conv2D(8, (3, 3)))<br/>model.add(Activation('relu'))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))</span><span id="e69d" class="mm jo iq mi b gy mr mo l mp mq">model.add(Conv2D(16, (3, 3)))<br/>model.add(Activation('relu'))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))</span><span id="9801" class="mm jo iq mi b gy mr mo l mp mq">model.add(Flatten())<br/>model.add(Dense(16))<br/>model.add(Activation('relu'))<br/>model.add(Dense(1))<br/>model.add(Activation('sigmoid'))</span><span id="d854" class="mm jo iq mi b gy mr mo l mp mq">model.compile(loss='binary_crossentropy',<br/>              optimizer='rmsprop',<br/>              metrics=['accuracy'])</span><span id="5c36" class="mm jo iq mi b gy mr mo l mp mq"># this is the augmentation configuration we will use for training<br/>train_datagen = ImageDataGenerator(<br/>    rescale=1. / 255,<br/>    shear_range=0.2,<br/>    zoom_range=0.2,<br/>    horizontal_flip=True)</span><span id="cd46" class="mm jo iq mi b gy mr mo l mp mq"># this is the augmentation configuration we will use for testing:<br/># only rescaling<br/>test_datagen = ImageDataGenerator(rescale=1. / 255)</span><span id="1df4" class="mm jo iq mi b gy mr mo l mp mq">train_generator = train_datagen.flow_from_directory(<br/>    train_data_dir,<br/>    target_size=(img_width, img_height),<br/>    batch_size=batch_size,<br/>    class_mode='binary')</span><span id="783e" class="mm jo iq mi b gy mr mo l mp mq">validation_generator = test_datagen.flow_from_directory(<br/>    validation_data_dir,<br/>    target_size=(img_width, img_height),<br/>    batch_size=batch_size,<br/>    class_mode='binary')</span><span id="7442" class="mm jo iq mi b gy mr mo l mp mq">model.fit_generator(<br/>    train_generator,<br/>    steps_per_epoch=nb_train_samples // batch_size,<br/>    epochs=epochs,<br/>    validation_data=validation_generator,<br/>    validation_steps=nb_validation_samples // batch_size)</span></pre><h1 id="98de" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">最后的话</h1><h1 id="91d8" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi">2000</h1><p id="39e7" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">每天大约有 2000 名美国工人因工作导致眼部受伤，需要接受治疗。</p><h1 id="e1cd" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi">60%</h1><p id="f471" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><a class="ae ms" href="https://www.ehstoday.com/ppe/eye_face_head/watch_importance_protecting" rel="noopener ugc nofollow" target="_blank">近 60% </a>受伤工人在事故发生时没有佩戴护目镜，或者佩戴了不适合工作的护目镜。</p><p id="f4d9" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">安全应该永远放在第一位。每当我听到涉及电动工具的事故，我的心就沉了下去。我希望这篇文章可以提高人们的意识，即人工智能可以为我们提供额外的保护。</p><p id="ad89" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">做东西开心，注意安全！</p></div></div>    
</body>
</html>