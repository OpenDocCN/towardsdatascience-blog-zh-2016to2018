<html>
<head>
<title>How I used text mining to decide which Ted Talk to watch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我如何使用文本挖掘来决定观看哪个Ted演讲</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-i-used-text-mining-to-decide-which-ted-talk-to-watch-dfe32e82bffd?source=collection_archive---------6-----------------------#2018-03-15">https://towardsdatascience.com/how-i-used-text-mining-to-decide-which-ted-talk-to-watch-dfe32e82bffd?source=collection_archive---------6-----------------------#2018-03-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="7309" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我喜欢ted演讲，谁不喜欢呢？当我第一次看这个数据集的时候，我突然想到了一些事情。首先，由于这个数据集包含了许多ted演讲的文字记录，默认情况下，我们有一个非常丰富的语料库，并且在语言学上有很好的结构。第二，由于这个语料库有很好的语言学属性，它可能是一个和路透社20新闻组或任何版本的古滕贝格语料库一样好的数据集。这让我想到:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi km"><img src="../Images/3d161c528356bcb516a03e312bb36f08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/1*bZL39rYSFVMYeWs2sC_TrQ.gif"/></div></figure><p id="f387" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="ku">我有许多ted演讲的所有记录的数据，我能试着想出一种方法来根据它们的相似性推荐ted演讲吗，就像官方Ted页面所做的那样？</em> </strong></p><p id="f4ec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当然，官方ted页面所使用的推荐引擎将会比我在这里演示的更加复杂，并且还会涉及到使用某种历史用户-项目交互数据。</p><p id="3fdd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里的想法是演示如何仅仅使用内容就能产生推荐。当你没有任何用户-项目交互数据时，这变得非常重要，尤其是当你开始一个新的项目，并且仍然想要为你的内容的消费者提供相关的上下文推荐时。</p><h1 id="3448" class="kv kw iq bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated"><strong class="ak">满足数据</strong></h1><p id="f320" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">数据以表格文件的形式输入，每次谈话的文字记录存储在名为<strong class="jp ir"> <em class="ku">文字记录</em> </strong>的一行中。下面是该文件的样子</p><pre class="kn ko kp kq gt ly lz ma mb aw mc bi"><span id="b8f9" class="md kw iq lz b gy me mf l mg mh"><strong class="lz ir">import</strong> <strong class="lz ir">pandas</strong> <strong class="lz ir">as</strong> <strong class="lz ir">pd</strong><br/>transcripts=pd.read_csv("E:<strong class="lz ir">\\</strong>Kaggle<strong class="lz ir">\\</strong>ted-data<strong class="lz ir">\\</strong>transcripts.csv")<br/>transcripts.head()</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mi"><img src="../Images/3502f7ed027a4911adc0ff224b21be03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h0qgH4IvyqMzSJ2NmqytAw.png"/></div></div></figure><p id="b325" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在检查了数据的样子之后，我发现我可以很容易地从url中提取演讲的标题。我的最终目标是使用抄本栏中的文本来创建一个相似性度量。然后为一个演讲推荐4个最相似的标题。使用简单的字符串分割操作将标题从url中分离出来非常简单，如下所示</p><pre class="kn ko kp kq gt ly lz ma mb aw mc bi"><span id="2dcf" class="md kw iq lz b gy me mf l mg mh">transcripts['title']=transcripts['url'].map(<strong class="lz ir">lambda</strong> x:x.split("/")[-1])<br/>transcripts.head()</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mn"><img src="../Images/5593203a5a4860efd7ef833b334038ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tY168MGF5ppJIqYkuAck_g.png"/></div></div></figure><p id="9b59" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这一点上，我准备开始拼凑将帮助我建立一个谈话推荐器的组件。为了实现这一目标，我必须:</p><ol class=""><li id="c708" class="mo mp iq jp b jq jr ju jv jy mq kc mr kg ms kk mt mu mv mw bi translated">创建每个转录本的向量表示</li><li id="8a83" class="mo mp iq jp b jq mx ju my jy mz kc na kg nb kk mt mu mv mw bi translated">为上面创建的向量表示创建相似性矩阵</li><li id="499c" class="mo mp iq jp b jq mx ju my jy mz kc na kg nb kk mt mu mv mw bi translated">对于每个演讲，基于一些相似性度量，选择4个最相似的演讲</li></ol><h1 id="3b80" class="kv kw iq bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated"><strong class="ak">使用Tf-Idf创建单词向量:</strong></h1><p id="e1bf" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">因为我们的最终目标是基于内容的相似性来推荐演讲，所以我们要做的第一件事是，创建一个可以比较的文字记录的表示。一种方法是为每个转录本创建一个tfidf载体。但是这个tfidf到底是什么东西？让我们先讨论一下。</p><h2 id="c26f" class="md kw iq bd kx nc nd dn lb ne nf dp lf jy ng nh lj kc ni nj ln kg nk nl lr nm bi translated">语料库、文档和计数矩阵</h2><p id="2e4d" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">为了表示文本，我们将把每个抄本看作一个“文档”，把所有文档的集合看作一个“语料库”。然后，我们将创建一个向量，表示每个文档中出现的字数，如下所示:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi nn"><img src="../Images/d21d90ef33ddbe66cbd265858dac885a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B_eROYUoByowdWJ5LsuaaA.png"/></div></div></figure><p id="38b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如您所见，对于每个文档，我们都创建了一个向量来计算每个单词出现的次数。所以向量(1，1，1，1，0，0)表示文档1中单词“This”、“is”、“sentence”、“one”、“two”、“three”的计数。这就是所谓的计数矩阵。这种文本表示有一个问题，它没有考虑到文档中单词的重要性。例如，单词“one”在文档1中只出现一次，但在其他文档中却没有出现，因此从其重要性的角度来看，“one”是文档1的一个重要单词，因为它表征了文档1，但是如果我们查看文档1的计数向量，我们可以看到“one”的权重为1，像“This”、“is”等单词也是如此。关于文档中单词重要性的问题可以使用所谓的<strong class="jp ir"> <em class="ku"> Tf-Idf </em> </strong>来处理。</p><h1 id="6593" class="kv kw iq bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated">术语频率-逆文档频率(Tf-Idf):</h1><p id="de30" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">为了理解Tf-Idf如何帮助识别单词的重要性，让我们做一个思维实验，问我们自己几个问题，什么决定一个单词是否重要？</p><ol class=""><li id="2d9d" class="mo mp iq jp b jq jr ju jv jy mq kc mr kg ms kk mt mu mv mw bi translated">如果这个词在文档中出现很多？</li><li id="a7e3" class="mo mp iq jp b jq mx ju my jy mz kc na kg nb kk mt mu mv mw bi translated">如果这个词在语料库中很少出现？</li><li id="44b9" class="mo mp iq jp b jq mx ju my jy mz kc na kg nb kk mt mu mv mw bi translated">1和2都是？</li></ol><p id="f136" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果一个单词在文档中出现很多，但在语料库中的其他文档中很少出现，则该单词在文档中是重要的。<strong class="jp ir">术语频率</strong>衡量该词在给定文档中出现的频率，而<strong class="jp ir">逆文档频率</strong>衡量该词在语料库中出现的频率。这两个量的乘积，衡量这个词的重要性，被称为<strong class="jp ir"> Tf-Idf </strong>。创建tf-idf表示相当简单，如果您正在使用机器学习框架，比如scikit-learn，那么创建文本数据的矩阵表示也相当简单</p><pre class="kn ko kp kq gt ly lz ma mb aw mc bi"><span id="6294" class="md kw iq lz b gy me mf l mg mh"><strong class="lz ir">from</strong> <strong class="lz ir">sklearn.feature_extraction</strong> <strong class="lz ir">import</strong> text<br/>Text=transcripts['transcript'].tolist()<br/>tfidf=text.TfidfVectorizer(input=Text,stop_words="english")<br/>matrix=tfidf.fit_transform(Text)<br/><em class="ku">#print(matrix.shape)</em></span></pre><p id="b446" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，一旦我们通过考虑单词的重要性来解决表示单词向量的问题，我们就可以开始处理下一个问题了，如何找出哪些文档(在我们的例子中是Ted talk抄本)与给定的文档相似？</p><h1 id="c926" class="kv kw iq bd kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls bi translated"><strong class="ak">查找相似文档</strong></h1><p id="faf7" class="pw-post-body-paragraph jn jo iq jp b jq lt js jt ju lu jw jx jy lv ka kb kc lw ke kf kg lx ki kj kk ij bi translated">为了在不同的文档中找出相似的文档，我们需要计算相似性的度量。通常在处理Tf-Idf向量时，我们使用余弦相似度。可以把余弦相似性看作是衡量一个TF-Idf向量与另一个向量的接近程度。如果你还记得之前的讨论，我们能够把每个抄本表示为一个向量，所以余弦相似度将成为我们发现一个Ted演讲的抄本和另一个有多相似的一种方法。</p><p id="2033" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以本质上，我从Tf-Idf向量创建了一个余弦矩阵来表示每个文档与另一个文档的相似程度，大致如下:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi no"><img src="../Images/08900bae07bde839d276837533032bfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ke0h9RPwGQrdbdHNb0J6Kw.png"/></div></div></figure><p id="cff5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">再一次，使用sklearn，这样做是非常直接的</p><pre class="kn ko kp kq gt ly lz ma mb aw mc bi"><span id="2955" class="md kw iq lz b gy me mf l mg mh"><em class="ku">### Get Similarity Scores using cosine similarity</em><br/><strong class="lz ir">from</strong> <strong class="lz ir">sklearn.metrics.pairwise</strong> <strong class="lz ir">import</strong> cosine_similarity<br/>sim_unigram=cosine_similarity(matrix)</span></pre><p id="4bc5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我现在要做的就是，根据余弦相似度，找出每份抄本中最相似的4份。从算法上来说，这相当于为上面构建的余弦矩阵中的每一行找出五列的索引，这五列与对应于相应行号的文档(在我们的情况下是抄本)最相似。这是使用几行代码完成的</p><pre class="kn ko kp kq gt ly lz ma mb aw mc bi"><span id="566a" class="md kw iq lz b gy me mf l mg mh"><strong class="lz ir">def</strong> get_similar_articles(x):<br/>    <strong class="lz ir">return</strong> ",".join(transcripts['title'].loc[x.argsort()[-5:-1]])<br/>transcripts['similar_articles_unigram']=[get_similar_articles(x) <strong class="lz ir">for</strong> x <strong class="lz ir">in</strong> sim_unigram]</span></pre><p id="e8d1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们通过检查建议来检查我们是如何公平的。让我们从列表中选择任何一个Ted演讲题目，比如说我们选择:</p><pre class="kn ko kp kq gt ly lz ma mb aw mc bi"><span id="862d" class="md kw iq lz b gy me mf l mg mh">transcripts['title'].str.replace("_"," ").str.upper().str.strip()[1]</span><span id="0778" class="md kw iq lz b gy np mf l mg mh">'AL GORE ON AVERTING CLIMATE CRISIS'</span></pre><p id="7e2a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，根据我们的分析，四个最相似的标题是</p><pre class="kn ko kp kq gt ly lz ma mb aw mc bi"><span id="84a7" class="md kw iq lz b gy me mf l mg mh">transcripts['similar_articles_unigram'].str.replace("_"," ").str.upper().str.strip().str.split("<strong class="lz ir">\n</strong>")[1]</span><span id="356e" class="md kw iq lz b gy np mf l mg mh">['RORY BREMNER S ONE MAN WORLD SUMMIT',<br/> ',ALICE BOWS LARKIN WE RE TOO LATE TO PREVENT CLIMATE CHANGE HERE S HOW WE ADAPT',<br/> ',TED HALSTEAD A CLIMATE SOLUTION WHERE ALL SIDES CAN WIN',<br/> ',AL GORE S NEW THINKING ON THE CLIMATE CRISIS']</span></pre><p id="51b0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可以清楚地看到，通过使用Tf-Idf向量来比较会谈的记录，我们能够挑选出，主题相似的会谈。</p><p id="5ddb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我还在这里创建了一个kaggle内核，别忘了向上投票:<a class="ae kl" href="https://www.kaggle.com/gunnvant/building-content-recommender-tutorial" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/gunvant/building-content-recommender-tutorial</a></p><p id="a3d8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可以在这里找到完整的代码<a class="ae kl" href="https://github.com/Gunnvant/ted_talks/blob/master/BlogMarch18.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/gun vant/ted _ talks/blob/master/blog March 18 . ipynb</a></p></div></div>    
</body>
</html>