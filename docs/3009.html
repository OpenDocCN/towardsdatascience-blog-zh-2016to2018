<html>
<head>
<title>A Simple and Scalable Analytics Pipeline</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简单且可扩展的分析管道</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-simple-and-scalable-analytics-pipeline-53720b1dbd35?source=collection_archive---------2-----------------------#2018-03-30">https://towardsdatascience.com/a-simple-and-scalable-analytics-pipeline-53720b1dbd35?source=collection_archive---------2-----------------------#2018-03-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/10b97e1eccf0e3c5094ef34c892a2ce0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kAHwjRnAosbm537VLcyhmw.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Source: <a class="ae jd" href="https://www.flickr.com/photos/bilfinger/14074154115" rel="noopener ugc nofollow" target="_blank">https://www.flickr.com/photos/bilfinger/14074154115</a></figcaption></figure><div class=""/><p id="a7a4" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">收集关于应用程序使用和用户行为的数据，例如玩家在游戏中的进度，对于产品团队来说是无价的。通常，整个团队都致力于构建和维护数据管道，以收集和存储应用程序的跟踪数据。然而，随着许多新的无服务器工具的出现，构建用于收集应用程序使用数据的分析管道的障碍已经大大减少。Google的PubSub、DataFlow和BigQuery等托管工具使小型团队能够建立可扩展到大量事件的分析管道，同时只需最低的运营开销。这篇文章描述了如何在谷歌云平台(GCP)上建立一个轻量级的分析管道，这个管道是完全管理的(无服务器的)并且可以自动扩展以满足需求。</p><p id="f856" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我受到了谷歌用于手机游戏分析的参考架构的启发。这篇文章的目标是展示一个小团队可以构建和维护一个<a class="ae jd" href="https://github.com/bgweber/GameAnalytics" rel="noopener ugc nofollow" target="_blank">数据管道</a>，它可以扩展到大型事件量，为数据科学任务提供一个数据湖，为分析团队提供一个查询环境，并具有对其他组件的可扩展性，如应用程序的实验框架。</p><p id="1fae" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我用来实现这条数据管道的核心技术是谷歌的数据流，它现在与<a class="ae jd" href="https://cloud.google.com/blog/big-data/2016/08/cloud-dataflow-apache-beam-and-you" rel="noopener ugc nofollow" target="_blank"> Apache Beam </a>库集成在一起。数据流任务定义了要在事件集合上执行的操作图，这些事件可以是流数据源。这篇文章展示了一个用Java实现的数据流任务，它将跟踪事件从PubSub主题传输到数据湖和BigQuery。关于数据流及其概念的介绍可以在<a class="ae jd" href="https://cloud.google.com/dataflow/docs/concepts" rel="noopener ugc nofollow" target="_blank">谷歌的文档</a>中找到。虽然数据流任务是可移植的，但由于它们现在是基于Apache Beam的，这篇文章主要讨论如何将数据流与GCP上的其他托管服务结合使用，以构建一个简单、无服务器、可伸缩的数据管道。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lb"><img src="../Images/f40645b5e0e739b50a5fc17cd98fbec0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D24UM1tNmIma92QMoURR1A.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">My lightweight implementation of the GCP Reference Architecture for Analytics.</figcaption></figure><p id="6c1a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">执行所有这些功能的数据管道相对简单。管道从PubSub读取消息，然后转换事件以实现持久性:管道的BigQuery部分将消息转换为TableRow对象并直接传输到BigQuery，而管道的AVRO部分将事件批处理到离散的窗口中，然后将事件保存到Google存储中。操作图如下图所示。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div class="gh gi lg"><img src="../Images/499a24636ba95726b43c91267311dfc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:912/format:webp/1*Em8fueB7v6pcG20Jzo67Zw.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">The streaming pipeline deployed to Google Cloud</figcaption></figure><h2 id="caf4" class="lh li jg bd lj lk ll dn lm ln lo dp lp ko lq lr ls ks lt lu lv kw lw lx ly lz bi translated"><strong class="ak">设置环境</strong></h2><p id="047c" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">构建数据管道的第一步是设置编译和部署项目所需的依赖项。我使用了以下maven依赖项来为向管道发送事件的跟踪API和处理事件的数据管道设置环境。</p><pre class="lc ld le lf gt mf mg mh mi aw mj bi"><span id="3306" class="lh li jg mg b gy mk ml l mm mn">&lt;!-- <em class="mo">Dependencies for the Tracking API </em>-&gt;<br/>&lt;dependency&gt;<br/>  &lt;groupId&gt;com.google.cloud&lt;/groupId&gt;<br/>  &lt;artifactId&gt;google-cloud-pubsub&lt;/artifactId&gt;<br/>  &lt;version&gt;0.32.0-beta&lt;/version&gt;<br/>  &lt;/dependency&gt;<br/>&lt;/dependencies&gt;</span><span id="39a0" class="lh li jg mg b gy mp ml l mm mn">&lt;!-- <em class="mo">Dependencies for the data pipeline </em>-&gt;<br/>&lt;dependency&gt;<br/>  &lt;groupId&gt;com.google.cloud.dataflow&lt;/groupId&gt;<br/>  &lt;artifactId&gt;google-cloud-dataflow-java-sdk-all&lt;/artifactId&gt;<br/>  &lt;version&gt;2.2.0&lt;/version&gt;<br/>&lt;/dependency&gt;</span></pre><p id="1fc6" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我使用Eclipse来编写和编译本教程的代码，因为它是开源的。然而，其他ide如<a class="ae jd" href="https://www.jetbrains.com/idea/" rel="noopener ugc nofollow" target="_blank"> IntelliJ </a>为部署和监控数据流任务提供了额外的特性。在将作业部署到Google Cloud之前，您需要为PubSub和DataFlow设置一个服务帐户。设置这些凭证超出了本文的范围，更多细节可以在<a class="ae jd" href="https://cloud.google.com/bigquery/docs/authentication/service-account-file" rel="noopener ugc nofollow" target="_blank"> Google文档</a>中找到。</p><p id="a41d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">运行这个数据管道的另一个先决条件是在GCP上设置一个PubSub主题。我定义了一个<em class="mo"> raw-events </em>主题，用于发布和消费数据管道的消息。关于创建PubSub主题的更多细节可在<a class="ae jd" href="https://cloud.google.com/pubsub/docs/quickstart-console" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p><p id="e7ba" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要部署这个数据管道，您需要用上面列出的maven依赖项设置一个java环境，设置一个Google Cloud项目并启用计费，在存储和BigQuery服务上启用计费，并创建一个用于发送和接收消息的PubSub主题。所有这些托管服务都要花钱，但有一个免费层可用于构建数据管道原型。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/1698b2e6fd7409f3aed93cd57f4bfb48.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*vHNf1jaeT52Vysyi6Bwd3Q.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Sending events from a server to a PubSub topic</figcaption></figure><h2 id="d5af" class="lh li jg bd lj lk ll dn lm ln lo dp lp ko lq lr ls ks lt lu lv kw lw lx ly lz bi translated">发布事件</h2><p id="7691" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">为了构建可用的数据管道，构建封装发送事件数据细节的API是很有用的。<a class="ae jd" href="https://github.com/bgweber/GameAnalytics/blob/master/events/tracking/TrackingAPI.java" rel="noopener ugc nofollow" target="_blank">跟踪API </a>类提供了这一功能，并可用于将生成的事件数据发送到数据管道。下面的代码显示了发送事件的方法签名，并显示了如何生成示例数据。</p><pre class="lc ld le lf gt mf mg mh mi aw mj bi"><span id="64b7" class="lh li jg mg b gy mk ml l mm mn">/** Event Signature for the Tracking API <br/>public void sendEvent(String eventType, String eventVersion, HashMap&lt;String, String&gt; attributes);<br/>*/</span><span id="e646" class="lh li jg mg b gy mp ml l mm mn">// send a batch of events    <br/>for (int i=0; i&lt;10000; i++) {</span><span id="b552" class="lh li jg mg b gy mp ml l mm mn">  // generate event names      <br/>  String eventType = Math.random() &lt; 0.5 ? <br/>      "Session" : (Math.random() &lt; 0.5 ? "Login" : "MatchStart");</span><span id="44df" class="lh li jg mg b gy mp ml l mm mn">  // create attributes to send      <br/>  HashMap&lt;String, String&gt; attributes = new HashMap&lt;String,String&gt;();<br/>  attributes.put("userID", "" + (int)(Math.random()*10000));<br/>  attributes.put("deviceType", Math.random() &lt; 0.5 ? <br/>      "Android" : (Math.random() &lt; 0.5 ? "iOS" : "Web"));</span><span id="393f" class="lh li jg mg b gy mp ml l mm mn">  // send the event      <br/>  tracking.sendEvent(eventType, "V1", attributes);      <br/>}</span></pre><p id="9343" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">跟踪API建立一个到PubSub主题的连接，以JSON格式传递事件，并实现一个回调来通知传递失败。下面提供了用于发送事件的代码，它基于Google的PubSub示例，在这里<a class="ae jd" href="https://cloud.google.com/pubsub/docs/quickstart-client-libraries" rel="noopener ugc nofollow" target="_blank">提供</a>。</p><pre class="lc ld le lf gt mf mg mh mi aw mj bi"><span id="4180" class="lh li jg mg b gy mk ml l mm mn">// Setup a PubSub connection <br/>TopicName topicName = TopicName.of(projectID, topicID);<br/>Publisher publisher = Publisher.newBuilder(topicName).build();</span><span id="ce43" class="lh li jg mg b gy mp ml l mm mn">// Specify an event to send<br/>String event = {\"eventType\":\"session\",\"eventVersion\":\"1\"}";</span><span id="00ce" class="lh li jg mg b gy mp ml l mm mn">// Convert the event to bytes    <br/>ByteString data = ByteString.copyFromUtf8(event.toString());</span><span id="f743" class="lh li jg mg b gy mp ml l mm mn">//schedule a message to be published    <br/>PubsubMessage pubsubMessage = <br/>  PubsubMessage.newBuilder().setData(data).build();</span><span id="6587" class="lh li jg mg b gy mp ml l mm mn">// publish the message, and add this class as a callback listener<br/>ApiFuture&lt;String&gt; future = publisher.publish(pubsubMessage);    ApiFutures.addCallback(future, this);</span></pre><p id="466c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面的代码使应用程序能够将事件发送到PubSub主题。下一步是在完全托管的环境中处理这些事件，该环境可以根据需要进行扩展以满足需求。</p><h2 id="c19b" class="lh li jg bd lj lk ll dn lm ln lo dp lp ko lq lr ls ks lt lu lv kw lw lx ly lz bi translated">存储事件</h2><p id="6782" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">数据管道的一个关键功能是让数据科学和分析团队可以使用测量的事件进行分析。用作端点的数据源应该具有低延迟，并且能够扩展到大量事件。本教程中定义的数据管道展示了如何将事件输出到BigQuery和数据湖，后者可用于支持大量分析业务用户。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/8509e7cd3053118606c126590b95ce5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*6PyIneSrx05Oco5EJLt8Ig.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Streaming event data from PubSub to DataFlow</figcaption></figure><p id="5a3c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个数据管道的第一步是从PubSub主题中读取事件，并将获取的消息传递给数据流流程。DataFlow提供了一个PubSub连接器，它支持将PubSub消息流式传输到其他DataFlow组件。下面的代码显示了如何实例化数据管道、指定流模式以及使用来自特定PubSub主题的消息。这个过程的输出是一组PubSub消息，可以存储起来供以后分析。</p><pre class="lc ld le lf gt mf mg mh mi aw mj bi"><span id="3d15" class="lh li jg mg b gy mk ml l mm mn">// set up pipeline options    <br/>Options options = PipelineOptionsFactory.fromArgs(args)<br/>  .withValidation().as(Options.class);    <br/>options.setStreaming(true);    <br/>Pipeline pipeline = Pipeline.create(options);</span><span id="e2a8" class="lh li jg mg b gy mp ml l mm mn">// read game events from PubSub    <br/>PCollection&lt;PubsubMessage&gt; events = pipeline<br/>  .apply(PubsubIO.readMessages().fromTopic(topic));</span></pre><p id="a079" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们希望存储事件的第一种方式是采用列格式，这种格式可用于构建数据湖。虽然这篇文章没有展示如何在下游ETL中利用这些文件，但是拥有一个数据湖是在需要修改数据库时维护数据集副本的好方法。数据湖提供了一种在由于模式变化或数据接收问题而需要时重新加载数据的方法。分配给该进程的数据管道部分如下所示。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/b759053c7faa30401c62bfcc20b03f32.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*zh8nwJv15teB8Z2WNz2Nfw.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Batching events to AVRO format and saving to Google Storage</figcaption></figure><p id="48b6" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于AVRO，我们不能使用直接分流的方法。在保存到平面文件之前，我们需要将事件分组到批处理中。在数据流中实现这一点的方法是应用窗口函数，将事件分组为固定的批次。下面的代码应用转换，将PubSub消息转换为String对象，以5分钟为间隔将消息分组，并将结果批量输出到Google Storage上的AVRO文件。</p><pre class="lc ld le lf gt mf mg mh mi aw mj bi"><span id="f443" class="lh li jg mg b gy mk ml l mm mn">// AVRO output portion of the pipeline    <br/>events<br/>.apply("To String", ParDo.of(new DoFn&lt;PubsubMessage, String&gt;() {<br/>  @ProcessElement        <br/>  public void processElement(ProcessContext c) throws Exception {<br/>    String message = new String(c.element().getPayload());<br/>    c.output(message);        <br/>  }      <br/>}))</span><span id="2ffc" class="lh li jg mg b gy mp ml l mm mn">// Batch events into 5 minute windows      <br/>.apply("Batch Events", Window.&lt;String&gt;into(    <br/>    FixedWindows.of(Duration.standardMinutes(5)))       <br/>  .triggering(AfterWatermark.pastEndOfWindow())     <br/>  .discardingFiredPanes()              <br/>  .withAllowedLateness(Duration.standardMinutes(5)))       </span><span id="e859" class="lh li jg mg b gy mp ml l mm mn">// Save the events in ARVO format      <br/>.apply("To AVRO", AvroIO.write(String.class)<br/>  .to("gs://your_gs_bucket/avro/raw-events.avro")<br/>  .withWindowedWrites() <br/>  .withNumShards(8)<br/>  .withSuffix(".avro"));</span></pre><p id="d51c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">总而言之，上面的代码将事件分批放入5分钟的窗口中，然后将事件导出到Google Storage上的AVRO文件中。</p><p id="a9a8" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这部分数据管道的结果是谷歌存储上的AVRO文件的集合，可以用来建立一个数据湖。每隔5分钟就会生成一个新的AVRO输出，下游ETL可以将原始事件解析为经过处理的特定于事件的表模式。下图显示了AVRO文件的输出示例。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/322260298a83b5782b2a6f7dd77b2ba3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*vLvvRRlslmUMMYjrEqrgzw.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">AVRO files saved to Google Storage</figcaption></figure><p id="04ae" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">除了创建数据湖之外，我们还希望在查询环境中可以立即访问事件。DataFlow提供了一个BigQuery连接器来实现这一功能，传输到这个端点的数据在短时间内就可以用于分析。下图显示了数据管道的这一部分。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/e7ddeb000a3bf3ea8d30c5c637484e50.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*P9oh6O7LM9PtXxTPYslrEQ.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Streaming events from DataFlow to BigQuery</figcaption></figure><p id="fb0e" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据管道将PubSub消息转换为TableRow对象，这些对象可以直接插入到BigQuery中。下面的代码由两个应用方法组成:数据转换和IO写入程序。转换步骤从PubSub读取消息有效负载，将消息解析为JSON对象，提取<em class="mo"> eventType </em>和<em class="mo"> eventVersion </em>属性，并使用这些属性以及时间戳和消息有效负载创建TableRow对象。第二个apply方法告诉管道将记录写入BigQuery，并将事件追加到现有表中。</p><pre class="lc ld le lf gt mf mg mh mi aw mj bi"><span id="c23f" class="lh li jg mg b gy mk ml l mm mn">// parse the PubSub events and create rows to insert into BigQuery    events.apply("To Table Rows", new <br/>  PTransform&lt;PCollection&lt;PubsubMessage&gt;, PCollection&lt;TableRow&gt;&gt;() { <br/>    public PCollection&lt;TableRow&gt; expand(<br/>        PCollection&lt;PubsubMessage&gt; input) {       <br/> <br/>      return input.apply("To Predictions", ParDo.of(new  <br/>          DoFn&lt;PubsubMessage, TableRow&gt;() {    <br/>     <br/>    @ProcessElement          <br/>    public void processElement(ProcessContext c) throws Exception {<br/>      String message = new String(c.element().getPayload()); <br/> <br/>      // parse the json message for attributes<br/>      JsonObject jsonObject = <br/>          new JsonParser().parse(message).getAsJsonObject();<br/>      String eventType = jsonObject.get("eventType").getAsString();<br/>      String eventVersion = jsonObject.<br/>              get("eventVersion").getAsString();          <br/>      String serverTime = dateFormat.format(new Date()); <br/> <br/>     // create and output the table row            <br/>     TableRow record = new TableRow();            <br/>     record.set("eventType", eventType);               <br/>     record.set("eventVersion", eventVersion);          <br/>     record.set("serverTime", serverTime);<br/>     record.set("message", message);            <br/>     c.output(record);          <br/>  }}));      <br/>}})<br/> <br/>//stream the events to Big Query    <br/>.apply("To BigQuery",BigQueryIO.writeTableRows()   <br/>  .to(table)           <br/>  .withSchema(schema)<br/>  .withCreateDisposition(CreateDisposition.CREATE_IF_NEEDED)<br/>  .withWriteDisposition(WriteDisposition.WRITE_APPEND));</span></pre><p id="2db6" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">总结一下上面的代码，从PubSub消费的每个消息都转换为带有时间戳的TableRow对象，然后流式传输到BigQuery进行存储。</p><p id="22a6" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据管道的这一部分的结果是，事件将被流式传输到BigQuery，并可在由DataFlow任务指定的输出表中进行分析。为了有效地将这些事件用于查询，您需要构建额外的ETL来创建具有模式化记录的已处理事件表，但现在已经有了用于存储跟踪事件的数据收集机制。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/02827aeade824202d7f582321b793212.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3U2d_4hGDhq1JkGxFh7LaA.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Game event records queried from the raw-events table in BigQuery</figcaption></figure><h2 id="2bad" class="lh li jg bd lj lk ll dn lm ln lo dp lp ko lq lr ls ks lt lu lv kw lw lx ly lz bi translated"><strong class="ak">部署和自动扩展</strong></h2><p id="b4f5" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">使用DataFlow，您可以在本地测试数据管道，或者部署到云中。如果在未指定其他属性的情况下运行代码示例，则数据管道将在本地计算机上执行。为了部署到云并利用此数据管道的自动缩放功能，您需要指定一个新的runner类作为运行时参数的一部分。为了运行数据管道，我使用了以下运行时参数:</p><pre class="lc ld le lf gt mf mg mh mi aw mj bi"><span id="7fc0" class="lh li jg mg b gy mk ml l mm mn">--runner=org.apache.beam.runners.dataflow.DataflowRunner <br/>--jobName=game-analytics<br/>--project=your_project_id <br/>--tempLocation=gs://temp-bucket</span></pre><p id="5c83" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">部署作业后，您应该会看到一条消息，说明作业已提交。然后您可以点击<a class="ae jd" href="https://console.cloud.google.com/dataflow" rel="noopener ugc nofollow" target="_blank"> DataFlow控制台</a>查看任务:</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/99f52b335489d20952f89e4be6587b06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*gXJ4SO9IRe2aRm0vOYPipw.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">The steaming data pipeline running on Google Cloud</figcaption></figure><p id="8d7c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面指定的运行时配置将不会默认为自动缩放配置。为了部署根据需求扩大规模的作业，您需要指定其他属性，例如:</p><pre class="lc ld le lf gt mf mg mh mi aw mj bi"><span id="b0c3" class="lh li jg mg b gy mk ml l mm mn">--autoscalingAlgorithm=THROUGHPUT_BASED<br/>--maxNumWorkers=30</span></pre><p id="89ce" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有关设置数据流任务以适应繁重工作负载条件的更多详细信息，请参见Spotify的这篇Google文章中的<a class="ae jd" href="https://cloud.google.com/blog/big-data/2016/03/comparing-cloud-dataflow-autoscaling-to-spark-and-hadoop" rel="noopener ugc nofollow" target="_blank">和这篇文章</a><a class="ae jd" href="https://labs.spotify.com/2016/03/10/spotifys-event-delivery-the-road-to-the-cloud-part-iii/" rel="noopener ugc nofollow" target="_blank">。下图显示了DataFlow如何根据需要进行扩展以满足需求。</a></p><figure class="lc ld le lf gt is gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/6858ca79c1b386e833d13f375dc4de55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*WFAhIl1qQV0g4qIEpwgq7A.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">An example of Dataflow auto scaling. The pipeline will scale up and down as necessary to match demand.</figcaption></figure><h2 id="3cfc" class="lh li jg bd lj lk ll dn lm ln lo dp lp ko lq lr ls ks lt lu lv kw lw lx ly lz bi translated">结论</h2><p id="d82c" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">现在有各种各样的工具可以用最少的努力为游戏或网络应用建立一个分析管道。使用托管资源使小型团队能够利用无服务器和自动扩展的基础架构，以最少的基础架构管理扩展到大量事件。您可以记录应用程序的所有相关数据，而不是使用数据供应商现成的数据收集解决方案。</p><p id="901f" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇文章的目标是展示如何使用GCP堆栈建立数据湖和查询环境。虽然这里介绍的方法不能直接移植到其他云，但是用于实现该数据管道核心功能的Apache Beam库是可移植的，并且可以利用类似的工具在其他云提供商上构建可伸缩的数据管道。</p><p id="2a37" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该架构是对分析和数据科学团队有用的事件收集系统的最小实现。为了满足大多数分析团队的需求，需要将原始事件转换为经过处理的熟事件，以满足业务需求。这个讨论超出了本文的范围，但是分析基础现在应该已经到位，可以构建一个高效的数据平台。</p><p id="7882" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Github上提供了该示例管道的完整源代码:</p><div class="ip iq gp gr ir my"><a href="https://github.com/bgweber/GameAnalytics" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab fo"><div class="na ab nb cl cj nc"><h2 class="bd jh gy z fp nd fr fs ne fu fw jf bi translated">BG Weber/游戏分析</h2><div class="nf l"><h3 class="bd b gy z fp nd fr fs ne fu fw dk translated">游戏分析——游戏分析的全面管理管道</h3></div><div class="ng l"><p class="bd b dl z fp nd fr fs ne fu fw dk translated">github.com</p></div></div><div class="nh l"><div class="ni l nj nk nl nh nm ix my"/></div></div></a></div><p id="f963" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae jd" href="https://www.linkedin.com/in/ben-weber-3b87482/" rel="noopener ugc nofollow" target="_blank">本·韦伯</a>是<a class="ae jd" href="https://angel.co/windfall-data" rel="noopener ugc nofollow" target="_blank">意外收获数据</a>的首席数据科学家，我们的任务是建立最准确和全面的净值模型。意外收获团队正在壮大，并正在招聘<a class="ae jd" href="https://angel.co/windfall-data/jobs/191572-senior-data-engineer" rel="noopener ugc nofollow" target="_blank">工程师</a>和<a class="ae jd" href="https://angel.co/windfall-data/jobs/335043-data-scientist" rel="noopener ugc nofollow" target="_blank">数据科学家</a>。</p></div></div>    
</body>
</html>