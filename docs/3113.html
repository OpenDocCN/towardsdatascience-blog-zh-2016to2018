<html>
<head>
<title>How to build a collaborative filtering model for personalized recommendations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何构建个性化推荐的协同过滤模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-a-collaborative-filtering-model-for-personalized-recommendations-using-tensorflow-and-b9a77dc1320?source=collection_archive---------3-----------------------#2018-04-10">https://towardsdatascience.com/how-to-build-a-collaborative-filtering-model-for-personalized-recommendations-using-tensorflow-and-b9a77dc1320?source=collection_archive---------3-----------------------#2018-04-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="0cef" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">基于张量流和张量流变换的推荐模型</h2></div><p id="ad18" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">2020年4月更新:请注意，现在有一种更简单的方法可以做到这一点。阅读本文关于构建 <a class="ae lb" rel="noopener" target="_blank" href="/training-a-recommendation-model-for-google-analytics-data-using-bigquery-ml-2327f9a2e8e9"> <strong class="kh ir">模型的建议使用BigQuery ML </strong> </a> <strong class="kh ir">。</strong></p><p id="13e5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本文中，我将带您逐步了解如何使用TensorFlow的Estimator API来构建用于产品推荐的WALS协同过滤模型。最近，我的同事Lukman Ramsey发布了一系列解决方案，详细介绍了如何构建推荐模型— <a class="ae lb" href="https://cloud.google.com/solutions/machine-learning/recommendation-system-tensorflow-overview" rel="noopener ugc nofollow" target="_blank">阅读这些解决方案</a>，了解什么是推荐以及如何建立端到端系统。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/6a4910ebad677d2d6c5c11a1fa15d45a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ycJv4thAOM34uqtee6Obrg.jpeg"/></div></div><figcaption class="lo lp gj gh gi lq lr bd b be z dk">Recommending chocolates to users is a collaborative filtering problem</figcaption></figure><p id="90e3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本文中，我将用Apache Beam替换原始解决方案中对Pandas的使用——这将允许解决方案更容易地扩展到更大的数据集。因为上下文存在于解决方案中，所以我将在这里简单地深入技术细节。完整的源代码在GitHub 上。</p><h2 id="6c80" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">步骤1:提取原始数据</h2><p id="1736" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">对于协同过滤，我们不需要知道任何关于用户或内容的属性。本质上，我们需要知道的只是userId、itemId和特定用户对特定项目的评价。在这种情况下，我们可以用花在页面上的时间作为评级的代理。Google Analytics 360将web流量信息导出到BigQuery，我就是从BigQuery中提取数据的:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="dd44" class="ls lt iq mr b gy mv mw l mx my">#standardSQL<br/>WITH visitor_page_content AS (<br/><br/>   SELECT  <br/>     fullVisitorID,<br/>     (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) AS latestContentId,  <br/>     (LEAD(hits.time, 1) OVER (PARTITION BY fullVisitorId ORDER BY hits.time ASC) - hits.time) AS session_duration <br/>   FROM `cloud-training-demos.GA360_test.ga_sessions_sample`,   <br/>     UNNEST(hits) AS hits<br/>   WHERE <br/>     # only include hits on pages<br/>      hits.type = "PAGE"<br/><br/>   GROUP BY   <br/>     fullVisitorId, latestContentId, hits.time<br/>     )<br/><br/># aggregate web stats<br/>SELECT   <br/>  fullVisitorID as visitorId,<br/>  latestContentId as contentId,<br/>  SUM(session_duration) AS session_duration <br/> <br/>FROM visitor_page_content<br/>  WHERE latestContentId IS NOT NULL <br/>  GROUP BY fullVisitorID, latestContentId<br/>  HAVING session_duration &gt; 0<br/>  ORDER BY latestContentId</span></pre><p id="4b28" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">查询本身特定于报纸设置Google Analytics的方式，特别是他们设置自定义维度的方式，您可能需要使用不同的查询来提取数据，如下表所示:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mz"><img src="../Images/4ef9132ad314d3058a307826abdc14cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a0FoY7IyvR57z8TrcTbRdw.png"/></div></div></figure><p id="a16c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是进行协同过滤所需的原始数据集。显然，你将使用什么样的visitorId、contentId和ratings取决于你的问题。除此之外，其他一切都很标准，您应该能够照原样使用它。</p><h2 id="b9d7" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">步骤2:创建枚举的用户和项目id</h2><p id="fe81" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">WALS算法要求枚举用户id和项目id，也就是说，它们应该只是交互矩阵中的行号和列号。因此，我们需要获取上面的visitorId，它是一个字符串，并将它们映射到0，1，2，…我们需要对项目id做同样的事情。此外，评级必须是小数字，通常为0-1。因此，我们必须调整session_duration。</p><p id="ea26" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了进行这种映射，我们将使用<a class="ae lb" href="https://github.com/tensorflow/transform" rel="noopener ugc nofollow" target="_blank">TensorFlow Transform</a>(TFT)——这是一个允许您使用Apache Beam创建预处理数据集进行训练的库，然后在推理期间将该预处理作为tensor flow图的一部分来应用！</p><p id="8408" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是我使用TFT的预处理功能的关键:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="2168" class="ls lt iq mr b gy mv mw l mx my"><strong class="mr ir">def</strong> preprocess_tft(rowdict):<br/>    median = 57937<br/>    result = {<br/>      'userId' : tft.string_to_int(rowdict['visitorId'], vocab_filename='vocab_users'),<br/>      'itemId' : tft.string_to_int(rowdict['contentId'], vocab_filename='vocab_items'),<br/>      'rating' : 0.3 * (1 + (rowdict['session_duration'] - median)/median)<br/>    }<br/>    <em class="na"># cap the rating at 1.0</em><br/>    result['rating'] = tf.where(tf.less(result['rating'], tf.ones(tf.shape(result['rating']))),<br/>                               result['rating'], tf.ones(tf.shape(result['rating'])))<br/>    <strong class="mr ir">return</strong> result</span></pre><p id="face" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">预处理BigQuery中由visitorId、contentId和session_duration组成的行的结果是一个名为result的Python字典，它包含三列:userId、itemId和rating。</p><p id="6518" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">tft.string_to_int查看整个训练数据集，并创建一个映射来枚举访问者，并将该映射(“词汇表”)写入文件vocab_users。我对contentId做了同样的事情，创建了itemId。通过将session_duration调整到0–1之间来获得评级。我的缩放基本上去掉了极长会话持续时间的长尾，这可能代表了在阅读报纸文章时关闭笔记本电脑的人。需要注意的关键点是，我使用纯张量流函数(如tf.less和tf.ones)来进行这种裁剪。这很重要，因为这种预处理函数必须在推理(预测)过程中作为张量流服务图的一部分来应用。</p><p id="95be" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用Apache Beam将预处理功能应用于训练数据集:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="5f18" class="ls lt iq mr b gy mv mw l mx my">transformed_dataset, transform_fn = (<br/>          raw_dataset | beam_impl.AnalyzeAndTransformDataset(preprocess_tft))</span></pre><h2 id="2b07" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">步骤3:写出WALS训练数据集</h2><p id="961f" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">WALS的训练集由两个文件组成，一个文件提供特定用户评定的所有项目(按行排列的交互矩阵)，另一个文件提供评定了特定项目的所有用户(按列排列的交互矩阵)。显然，这两个文件包含相同的数据，但是有必要分割数据集，以便可以并行处理它们。我们也可以在进行枚举的同一个Apache Beam管道中这样做:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="9696" class="ls lt iq mr b gy mv mw l mx my">users_for_item = (transformed_data<br/>    | 'map_items' &gt;&gt; beam.Map(<strong class="mr ir">lambda</strong> x : (x['itemId'], x))<br/>    | 'group_items' &gt;&gt; beam.GroupByKey()<br/>    | 'totfr_items' &gt;&gt; beam.Map(<strong class="mr ir">lambda</strong> item_userlist : to_tfrecord(item_userlist, 'userId')))</span></pre><p id="6e45" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们可以在云数据流上执行Apache Beam管道。这是一个完全托管的服务，所以我们不必到处设置基础设施和安装软件(完整代码见GitHub 中的<a class="ae lb" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/10_recommend/wals_tft.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本)。</a></p><p id="9398" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此时，我们将拥有以下文件:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="ed0f" class="ls lt iq mr b gy mv mw l mx my">items_for_user-00000-of-00003<br/>...<br/>users_for_item-00000-of-00004<br/>...</span><span id="39ad" class="ls lt iq mr b gy nb mw l mx my">transform_fn/transform_fn/saved_model.pb<br/>transform_fn/transform_fn/assets/<br/>transform_fn/transform_fn/assets/vocab_items<br/>transform_fn/transform_fn/assets/vocab_users</span></pre><ol class=""><li id="f7eb" class="nc nd iq kh b ki kj kl km ko ne ks nf kw ng la nh ni nj nk bi translated">` ''项目的用户''以TFExample格式包含每个项目的所有用户/评级。这里的项目和用户是整数(不是字符串)，即itemId不是contentId，userId不是visitorId。等级被缩放。</li><li id="7f93" class="nc nd iq kh b ki nl kl nm ko nn ks no kw np la nh ni nj nk bi translated">` ` items_for_user ` `以TFExample格式包含每个用户的所有项目/评级。这里的项目和用户是整数(不是字符串)，即itemId不是contentId，userId不是visitorId。等级被缩放。</li><li id="109a" class="nc nd iq kh b ki nl kl nm ko nn ks no kw np la nh ni nj nk bi translated">` ` vocab_items ` `包含从contentId到枚举itemId的映射</li><li id="3f18" class="nc nd iq kh b ki nl kl nm ko nn ks no kw np la nh ni nj nk bi translated">` ` vocab_users ` `包含从visitorId到枚举userId的映射</li><li id="04e4" class="nc nd iq kh b ki nl kl nm ko nn ks no kw np la nh ni nj nk bi translated">saved_model.pb包含我们在预处理过程中进行的所有张量流变换，因此它们也可以在预测过程中应用。</li></ol><h2 id="51f3" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">步骤4:编写张量流代码</h2><p id="ff42" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">TensorFlow中有一个基于估算器API的WALS实现。我们使用它的方式与使用任何其他估计器一样——参见GitHub repo中的函数read_dataset()和train_and_evaluate()。</p><p id="1137" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更有趣的是我们如何使用训练好的估计量进行批量预测。对于特定用户，我们希望找到前K项。这可以在TensorFlow中通过以下方式实现:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="5aaa" class="ls lt iq mr b gy mv mw l mx my"><strong class="mr ir">def</strong> find_top_k(user, item_factors, k):<br/>  all_items = tf.matmul(tf.expand_dims(user, 0), tf.transpose(item_factors))<br/>  topk = tf.nn.top_k(all_items, k=k)<br/>  <strong class="mr ir">return</strong> tf.cast(topk.indices, dtype=tf.int64)</span></pre><p id="3fcd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">批量预测包括为每个用户调用上述函数，但是要确保当我们写出输出时，我们写出的是字符串visitorId，而不是数字userId(contentId/userId也是如此):</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="2030" class="ls lt iq mr b gy mv mw l mx my"><strong class="mr ir">def</strong> batch_predict(args):<br/>  <strong class="mr ir">import</strong> <strong class="mr ir">numpy</strong> <strong class="mr ir">as</strong> <strong class="mr ir">np</strong><br/>  <br/>  <em class="na"># read vocabulary into Python list for quick index-ed lookup</em><br/>  <strong class="mr ir">def</strong> create_lookup(filename):<br/>      <strong class="mr ir">from</strong> <strong class="mr ir">tensorflow.python.lib.io</strong> <strong class="mr ir">import</strong> file_io<br/>      dirname = os.path.join(args['input_path'], 'transform_fn/transform_fn/assets/')<br/>      <strong class="mr ir">with</strong> file_io.FileIO(os.path.join(dirname, filename), mode='r') <strong class="mr ir">as</strong> ifp:<br/>        <strong class="mr ir">return</strong> [x.rstrip() <strong class="mr ir">for</strong> x <strong class="mr ir">in</strong> ifp]<br/>  originalItemIds = create_lookup('vocab_items')<br/>  originalUserIds = create_lookup('vocab_users')<br/>  <br/>  <strong class="mr ir">with</strong> tf.Session() <strong class="mr ir">as</strong> sess:<br/>    estimator = tf.contrib.factorization.WALSMatrixFactorization(<br/>                         num_rows=args['nusers'], num_cols=args['nitems'],<br/>                         embedding_dimension=args['n_embeds'],<br/>                         model_dir=args['output_dir'])<br/>           <br/>    <em class="na"># but for in-vocab data, the row factors are already in the checkpoint</em><br/>    user_factors = tf.convert_to_tensor(estimator.get_row_factors()[0]) <em class="na"># (nusers, nembeds)</em><br/>    <em class="na"># in either case, we have to assume catalog doesn't change, so col_factors are read in</em><br/>    item_factors = tf.convert_to_tensor(estimator.get_col_factors()[0])<em class="na"># (nitems, nembeds)</em><br/>    <br/>    <em class="na"># for each user, find the top K items</em><br/>    topk = tf.squeeze(tf.map_fn(<strong class="mr ir">lambda</strong> user: find_top_k(user, item_factors, args['topk']), <br/>                                user_factors, dtype=tf.int64))<br/>    <strong class="mr ir">with</strong> file_io.FileIO(os.path.join(args['output_dir'], 'batch_pred.txt'), mode='w') <strong class="mr ir">as</strong> f:<br/>      <strong class="mr ir">for</strong> userId, best_items_for_user <strong class="mr ir">in</strong> enumerate(topk.eval()):<br/>        f.write(originalUserIds[userId] + '<strong class="mr ir">\t</strong>') <em class="na"># write userId \t item1,item2,item3...</em><br/>        f.write(','.join(originalItemIds[itemId] <strong class="mr ir">for</strong> itemId <strong class="mr ir">in</strong> best_items_for_user) + '<strong class="mr ir">\n</strong>')</span></pre><p id="f8f1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了进行训练和批量预测，我们可以在Cloud ML Engine上运行TensorFlow模型，同样不需要任何基础设施:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="d465" class="ls lt iq mr b gy mv mw l mx my">gcloud ml-engine jobs submit training $JOBNAME \<br/>   --region=$REGION \<br/>   --module-name=trainer.task \<br/>   --package-path=${PWD}/wals_tft/trainer \<br/>   --job-dir=$OUTDIR \<br/>   --staging-bucket=gs://$BUCKET \<br/>   --scale-tier=BASIC_GPU \<br/>   --runtime-version=1.5 \<br/>   -- \<br/>   --output_dir=$OUTDIR \<br/>   --input_path=gs://${BUCKET}/wals/preproc_tft \<br/>   --num_epochs=10 --nitems=5668 --nusers=82802</span></pre><p id="4235" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">像这样硬编码nitems和nusers有点难看。因此，我们可以回到我们的Beam管道，让它将nitems和nusers也写入文件，然后简单地执行“gsutil cat”来获得适当的值GitHub上的完整代码可以做到这一点。</p><p id="b195" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是输出结果的一个示例:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="b249" class="ls lt iq mr b gy mv mw l mx my">6167894456739729438	298997422,262707977,263058146<br/>3795498541234027150	296993188,97034003,298989783</span></pre><p id="0c20" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">实际上，每个visitorId有3个项目。</p><h2 id="2b01" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">第5步:行和列因子</h2><p id="158e" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">虽然进行产品推荐是WALS的主要用例，但另一个用例是寻找表示产品和用户的低维方法，例如，通过对项目因子和列因子进行聚类来进行产品或客户细分。因此，我们实现了一个服务函数来将这些返回给调用者(同样，完整代码请参见GitHub):</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="5922" class="ls lt iq mr b gy mv mw l mx my"><strong class="mr ir">def</strong> for_user_embeddings(originalUserId):<br/>      <em class="na"># convert the userId that the end-user provided to integer</em><br/>      originalUserIds = tf.contrib.lookup.index_table_from_file(<br/>          os.path.join(args['input_path'], 'transform_fn/transform_fn/assets/vocab_users'))<br/>      userId = originalUserIds.lookup(originalUserId)<br/>      <br/>      <em class="na"># all items for this user (for user_embeddings)</em><br/>      items = tf.range(args['nitems'], dtype=tf.int64)<br/>      users = userId * tf.ones([args['nitems']], dtype=tf.int64)<br/>      ratings = 0.1 * tf.ones_like(users, dtype=tf.float32)<br/>      <strong class="mr ir">return</strong> items, users, ratings, tf.constant(True)</span></pre><h2 id="e8ac" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">管弦乐编曲</h2><p id="25c9" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">注意，本文只是关于替换原解决方案中的机器学习训练和批量预测部分。原始解决方案还解释了如何进行编排和过滤。它们在哪里？</p><p id="2b13" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此时，我们现在有了一个BigQuery查询、一个Beam/Dataflow管道和一个潜在的AppEngine应用程序(见下文)。你如何一个接一个地定期运行它们？按照解决方案中的建议，使用Apache Airflow来执行此流程编排。</p><h2 id="ab9b" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">过滤</h2><p id="2e23" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">如果你向顾客推荐巧克力，那么推荐一种他们已经尝试过的巧克力是可以的，但是如果你向用户推荐报纸文章，那么避免推荐他们已经读过的文章是很重要的。</p><p id="e891" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与原始解决方案不同，我的批量预测代码不会过滤掉用户已经阅读过的文章。如果重要的是推荐不包括已经阅读/购买的项目，那么有两种方法可以做到这一点。</p><p id="2b4a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更简单的方法是在找到top_k之前，将对应于已经读取的项目(这里是评级&lt; 0.01的项目)的条目清零:</p><pre class="ld le lf lg gt mq mr ms mt aw mu bi"><span id="a09c" class="ls lt iq mr b gy mv mw l mx my"><strong class="mr ir">def</strong> find_top_k(user, item_factors, read_items, k):<br/>  all_items = tf.matmul(tf.expand_dims(user, 0), <br/>                        tf.transpose(item_factors))<br/>  all_items = tf.where(tf.less(read_items, <br/>                               0.01*tf.ones(tf.shape(read_items))),<br/>                       all_items,<br/>                       tf.zeros(tf.shape(all_items)))<br/>  topk = tf.nn.top_k(all_items, k=k)<br/>  <strong class="mr ir">return</strong> tf.cast(topk.indices, dtype=tf.int64)</span></pre><p id="b234" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这样做的问题是滞后-您可能不会推荐用户昨天阅读的项目(因为它在您的训练数据集中)，但批量预测代码确实可以实时访问阅读的文章流，因此您将推荐他们几分钟前阅读的文章。</p><p id="9f57" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果这种滞后是您想要避免的问题，那么您应该使批量预测中的k更高(例如，即使您打算只推荐其中的5篇，您也会从推荐者那里获得20篇文章)，然后在AppEngine中进行第二级过滤，如原始解决方案中所建议的那样。</p><h2 id="ef3f" class="ls lt iq bd lu lv lw dn lx ly lz dp ma ko mb mc md ks me mf mg kw mh mi mj mk bi translated">摘要</h2><p id="f96c" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">您现在可以进行批量预测、在线预测和训练，而无需设置任何集群！另外，TensorFlow Transform允许我们简化元数据的计算和项目/用户的映射，以适应WALS范式。</p><p id="4cf7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">感谢我的同事Lukman Ramsey和Yiliang Zhao对本文提出的有益意见和建议。</p></div></div>    
</body>
</html>