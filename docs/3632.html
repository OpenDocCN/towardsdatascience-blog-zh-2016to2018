<html>
<head>
<title>Deep Learning for Named Entity Recognition #2: Implementing the state-of-the-art Bidirectional LSTM + CNN model for CoNLL 2003</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">命名实体识别的深度学习#2:为 CoNLL 2003 实现最先进的双向 LSTM + CNN 模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-for-named-entity-recognition-2-implementing-the-state-of-the-art-bidirectional-lstm-4603491087f1?source=collection_archive---------6-----------------------#2018-06-02">https://towardsdatascience.com/deep-learning-for-named-entity-recognition-2-implementing-the-state-of-the-art-bidirectional-lstm-4603491087f1?source=collection_archive---------6-----------------------#2018-06-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/a61edaad959ea2afbce0d24ff5cfb36a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aNi8qrFdo-5fxI-739ldbw.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="0f12" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">基于 Chiu 和 Nichols (2016)，该实现在 2003 年 CoNLL 新闻数据上取得了 90%以上的 F1 分数。</h2></div><p id="f32b" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">CoNLL 2003 是对 NER 有用的许多公开可用的数据集之一。在这篇文章中，我们将使用 Keras 和 Tensorflow 在 Python 中实现 Chiu 和 Nichols (2016) ( <a class="ae lm" href="https://arxiv.org/abs/1511.08308" rel="noopener ugc nofollow" target="_blank">此处</a>)的当前 SOTA 算法。该实现的核心是双向 LSTM (BLSTM ),同时还使用卷积神经网络(CNN)来识别字符级模式。</p><p id="938d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">假设读者熟悉 CNN(如果不熟悉，请阅读 Denny Britz 的摘要<a class="ae lm" href="http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/" rel="noopener ugc nofollow" target="_blank">这里</a>，但不太熟悉 BLSTMs，让我们快速描述一下为什么 BLSTMs 特别适合 NER。</p><h1 id="d4eb" class="ln lo jb bd lp lq lr ls lt lu lv lw lx kh ly ki lz kk ma kl mb kn mc ko md me bi translated">双向 LSTMs</h1><p id="85c3" class="pw-post-body-paragraph kq kr jb ks b kt mf kc kv kw mg kf ky kz mh lb lc ld mi lf lg lh mj lj lk ll ij bi translated">长短期记忆(LSTM)细胞是递归神经网络(RNNs)的构建模块。虽然前馈神经网络中的普通 LSTM 细胞像人类一样处理文本(从左到右)，但 BLSTMs 也考虑相反的方向。随着输入信息量的增加，这使得模型能够发现更多的模式。换句话说，该模型不仅考虑感兴趣的记号之后的记号序列，还考虑感兴趣的记号之前的<em class="mk">。</em></p><p id="a374" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">下图更正式地表达了这一观点。请注意，<strong class="ks jc"> <em class="mk"> x </em> </strong>代表输入序列，<strong class="ks jc"> <em class="mk"> h </em> </strong> <em class="mk"> </em>代表向前或向后运行的输出序列(分别由指向右边或左边的箭头定义)，<strong class="ks jc"> <em class="mk"> y </em> </strong>代表串接的输出序列，其中<em class="mk">∑</em>串接向前和向后输出元素。</p><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ml"><img src="../Images/85248f55924720ff57e4017e42b3a6f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QBrVVvYps5zo6QtBRRq4fA.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">Unfolded BLSTM architecture with 3 consecutive steps. From Cui et al. (2017) (<a class="ae lm" href="https://arxiv.org/pdf/1801.02143.pdf" rel="noopener ugc nofollow" target="_blank">here</a>).</figcaption></figure><p id="6120" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">维基百科的文章(<a class="ae lm" href="https://en.wikipedia.org/wiki/Bidirectional_recurrent_neural_networks" rel="noopener ugc nofollow" target="_blank">此处</a>)包含了更多的细节，包括到舒斯特和帕利瓦尔(1997)的原始论文的链接(<a class="ae lm" href="https://pdfs.semanticscholar.org/4b80/89bc9b49f84de43acc2eb8900035f7d492b2.pdf" rel="noopener ugc nofollow" target="_blank">此处</a>)。</p><h1 id="1e42" class="ln lo jb bd lp lq lr ls lt lu lv lw lx kh ly ki lz kk ma kl mb kn mc ko md me bi translated">Keras 实施</h1><p id="7660" class="pw-post-body-paragraph kq kr jb ks b kt mf kc kv kw mg kf ky kz mh lb lc ld mi lf lg lh mj lj lk ll ij bi translated">我使用 Keras 和 Tensorflow 后端。这通常是最有效的设置，尤其是在 GPU 上运行时。</p><div class="ip iq gp gr ir mu"><a href="https://github.com/mxhofer/Named-Entity-Recognition-BidirectionalLSTM-CNN-CoNLL" rel="noopener  ugc nofollow" target="_blank"><div class="mv ab fo"><div class="mw ab mx cl cj my"><h2 class="bd jc gy z fp mz fr fs na fu fw ja bi translated">MX hofer/命名实体识别双向 TM-CNN-CoNLL</h2><div class="nb l"><h3 class="bd b gy z fp mz fr fs na fu fw dk translated">命名实体识别双向 TM-CNN-CoNLL - Keras 实现 Chiu 和 Nichols (2016)</h3></div><div class="nc l"><p class="bd b dl z fp mz fr fs na fu fw dk translated">github.com</p></div></div><div class="nd l"><div class="ne l nf ng nh nd ni ix mu"/></div></div></a></div><p id="b90a" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">以下是主要步骤。</p><h2 id="d281" class="nj lo jb bd lp nk nl dn lt nm nn dp lx kz no np lz ld nq nr mb lh ns nt md nu bi translated">嵌入</h2><p id="ca5c" class="pw-post-body-paragraph kq kr jb ks b kt mf kc kv kw mg kf ky kz mh lb lc ld mi lf lg lh mj lj lk ll ij bi translated">加载训练、开发和测试数据文件后，<em class="mk"> embed </em>函数创建单词和字符级嵌入。这意味着单词和字符被映射到神经网络可以处理的实数。更具体地说，标签(例如 B-ORG、I-ORG、B-LOC 等。)、记号大小写(例如，小写、大写或数字记号)和字符使用字典数据结构被映射到实数。此外，所有唯一的单词被映射到手套嵌入向量。</p><h2 id="2728" class="nj lo jb bd lp nk nl dn lt nm nn dp lx kz no np lz ld nq nr mb lh ns nt md nu bi translated">模型架构</h2><p id="79ae" class="pw-post-body-paragraph kq kr jb ks b kt mf kc kv kw mg kf ky kz mh lb lc ld mi lf lg lh mj lj lk ll ij bi translated">BLSTM 层构成网络的核心，具有以下三个输入:</p><ol class=""><li id="ed7d" class="nv nw jb ks b kt ku kw kx kz nx ld ny lh nz ll oa ob oc od bi translated">字符级模式由卷积神经网络识别</li><li id="2ad5" class="nv nw jb ks b kt oe kw of kz og ld oh lh oi ll oa ob oc od bi translated">来自手套嵌入的单词级输入</li><li id="9924" class="nv nw jb ks b kt oe kw of kz og ld oh lh oi ll oa ob oc od bi translated">大小写输入(无论单词是小写、大写等。)</li></ol><p id="dc8a" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">下图显示了所有层的模型架构。一个<em class="mk"> softmax </em>激活层生成最终输出。</p><figure class="mm mn mo mp gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oj"><img src="../Images/37796aa17e147dc1b195762f2e7c6640.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IZSxs-rwglEWALLBDRfTzw.png"/></div></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">Model architecture, Chiu and Nichols (2016).</figcaption></figure><h2 id="1763" class="nj lo jb bd lp nk nl dn lt nm nn dp lx kz no np lz ld nq nr mb lh ns nt md nu bi translated">因素</h2><p id="e857" class="pw-post-body-paragraph kq kr jb ks b kt mf kc kv kw mg kf ky kz mh lb lc ld mi lf lg lh mj lj lk ll ij bi translated">推荐参数与论文略有不同。这可能是因为我们不知道 Chiu 和 Nichols (2016)在不使用额外的基于规则的方法的情况下会取得什么样的 F1 分数。仅考虑他们的机器学习模型组件，这些参数达到 90%+的 F1 分数:</p><ul class=""><li id="d2b5" class="nv nw jb ks b kt ku kw kx kz nx ld ny lh nz ll ok ob oc od bi translated">80 个时代</li><li id="961f" class="nv nw jb ks b kt oe kw of kz og ld oh lh oi ll ok ob oc od bi translated">0.68 辍学</li><li id="3908" class="nv nw jb ks b kt oe kw of kz og ld oh lh oi ll ok ob oc od bi translated">200 个 LSTM 州大小</li><li id="4964" class="nv nw jb ks b kt oe kw of kz og ld oh lh oi ll ok ob oc od bi translated">3 卷积宽度</li><li id="4032" class="nv nw jb ks b kt oe kw of kz og ld oh lh oi ll ok ob oc od bi translated">那达慕乐观主义者</li></ul><p id="5613" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在您的本地机器上运行代码时，您只需 30 个历元和大约 1 个小时的训练，就可以获得大约 86%的 F1 分数，其中包括上述的下降、LSTM 状态大小、卷积宽度和优化器参数(见下图)。</p><figure class="mm mn mo mp gt is gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/572bf2967fd0c03b7607a30a7fb36364.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*0gtY0bII9Iiy6Ulyk4EwyQ.png"/></div><figcaption class="mq mr gj gh gi ms mt bd b be z dk">Learning curve with 30 epochs.</figcaption></figure><p id="9ab9" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">总之，双向 LSTMs 是用于命名实体识别的非常强大和灵活的神经网络类型。提示:尝试在 CoNLL 格式的不同数据上重用模型。表现如何？</p></div><div class="ab cl om on hu oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="ij ik il im in"><p id="81fa" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我希望这为 CoNLL 2003 数据的当前 SOTA 模型提供了一个有用的概述和实现。让我知道你用不同的参数和其他调整得到的结果！👋</p></div></div>    
</body>
</html>