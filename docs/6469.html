<html>
<head>
<title>A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络综合指南 ELI5 方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53?source=collection_archive---------0-----------------------#2018-12-15">https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53?source=collection_archive---------0-----------------------#2018-12-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/0239cc890f84217c4eb8e3f9fab657e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vkQ0hXDaQv57sALXAJquxA.jpeg"/></div></div></figure><p id="0bac" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">人工智能见证了在弥合人类和机器能力之间的差距方面的巨大发展。研究人员和爱好者一样，致力于该领域的许多方面，使惊人的事情发生。许多这样的领域之一是计算机视觉领域。</p><p id="7431" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该领域的目标是使机器能够像人类一样看待世界，以类似的方式感知世界，甚至将这些知识用于多种任务，如图像和视频识别、图像分析和分类、媒体娱乐、推荐系统、自然语言处理等。具有深度学习的计算机视觉的进步已经随着时间的推移而构建和完善，主要是在一种特定的算法上——一种<strong class="ka ir">卷积神经网络</strong>。</p><blockquote class="kw kx ky"><p id="a521" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated">准备好尝试自己的卷积神经网络了吗？查看<a class="ae ld" href="https://saturncloud.io/?utm_source=Medium+&amp;utm_medium=Medium&amp;utm_campaign=SumitSaha&amp;utm_term=ConvolutionalNeuralNets" rel="noopener ugc nofollow" target="_blank">土星云</a>免费计算(包括免费 GPU)。</p></blockquote><h2 id="a61f" class="le lf iq bd lg lh li dn lj lk ll dp lm kj ln lo lp kn lq lr ls kr lt lu lv lw bi translated">介绍</h2><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lx"><img src="../Images/98c3ccfac508d3115c391c6f0a3d5eb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uAeANQIOQPqWZnnuH-VEyw.jpeg"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk">A CNN sequence to classify handwritten digits</figcaption></figure><p id="fb70" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">卷积神经网络(ConvNet/CNN) </strong>是一种深度学习算法，可以接受输入图像，为图像中的各个方面/对象分配重要性(可学习的权重和偏差)，并能够区分彼此。与其他分类算法相比，ConvNet 中所需的预处理要低得多。在原始方法中，滤波器是手工设计的，经过足够的训练，ConvNets 有能力学习这些滤波器/特性。</p><p id="ffef" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">ConvNet 的架构类似于人脑中神经元的连接模式，其灵感来自视觉皮层的组织。单个神经元只在视野中被称为感受野的有限区域内对刺激做出反应。这些区域的集合重叠覆盖了整个可视区域。</p><h2 id="9dc9" class="le lf iq bd lg lh li dn lj lk ll dp lm kj ln lo lp kn lq lr ls kr lt lu lv lw bi translated">为什么 ConvNets 优于前馈神经网络？</h2><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/30f3c8fefb9ad195392445cf62477b28.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*GLQjM9k0gZ14nYF0XmkRWQ.png"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Flattening of a 3x3 image matrix into a 9x1 vector</figcaption></figure><p id="6383" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">图像不过是像素值的矩阵，对吗？那么，为什么不干脆将图像扁平化(例如，将 3×3 的图像矩阵转化为 9×1 的向量)并将其输入到多级感知器中进行分类呢？哦..不完全是。</p><p id="df65" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在极其基本的二进制图像的情况下，该方法在执行类别预测时可能显示平均精度分数，但是当涉及到整体上具有像素依赖性的复杂图像时，该方法将几乎没有精度。</p><p id="4f1c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">通过应用相关过滤器，ConvNet 能够<strong class="ka ir">成功捕捉图像中的空间和时间相关性</strong>。由于所涉及的参数数量的减少和权重的可重用性，该架构对图像数据集执行更好的拟合。换句话说，可以训练网络更好地理解图像的复杂程度。</p><h2 id="c380" class="le lf iq bd lg lh li dn lj lk ll dp lm kj ln lo lp kn lq lr ls kr lt lu lv lw bi translated">输入图像</h2><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/29c9f2fb3efb2ed7cc73c3d45e2493d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*15yDvGKV47a0nkf5qLKOOQ.png"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk">4x4x3 RGB Image</figcaption></figure><p id="f21b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在图中，我们有一个 RGB 图像，它由三个颜色平面(红色、绿色和蓝色)分开。图像存在于许多这样的色彩空间中——灰度、RGB、HSV、CMYK 等。</p><p id="3bb1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你可以想象一旦图像达到 8K (7680×4320)的尺寸，计算量会有多大。ConvNet 的作用是将图像简化为一种更容易处理的形式，而不会丢失对获得良好预测至关重要的特征。当我们要设计一个不仅擅长学习特征，而且可扩展到大规模数据集的架构时，这一点很重要。</p><h2 id="cad1" class="le lf iq bd lg lh li dn lj lk ll dp lm kj ln lo lp kn lq lr ls kr lt lu lv lw bi translated">卷积层—内核</h2><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/289f2deaca9bc4dac099606d40f6432a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/1*GcI7G-JLAQiEoCON7xFbhg.gif"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Convoluting a 5x5x1 image with a 3x3x1 kernel to get a 3x3x1 convolved feature</figcaption></figure><p id="0f71" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">图像尺寸= 5(高)x 5(宽)x 1(通道数，如 RGB)</p><p id="9be0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在上面的演示中，绿色部分类似于我们的<strong class="ka ir"> 5x5x1 输入图像，I </strong>。卷积层第一部分的卷积运算中涉及的元素称为<strong class="ka ir">内核/滤波器，K </strong>，用黄色表示。我们选择了<strong class="ka ir"> K 作为一个 3x3x1 的矩阵。</strong></p><pre class="ly lz ma mb gt mj mk ml mm aw mn bi"><span id="e9b7" class="le lf iq mk b gy mo mp l mq mr">Kernel/Filter, K = </span><span id="63d3" class="le lf iq mk b gy ms mp l mq mr">1  0  1<br/>0  1  0<br/>1  0  1</span></pre><p id="b923" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于<strong class="ka ir">步长= 1(非步长)</strong>，内核移位 9 次，每次在 K 和内核所悬停的图像部分 P 之间执行<strong class="ka ir">逐元素</strong> <strong class="ka ir">乘法运算(</strong> <a class="ae ld" href="https://en.wikipedia.org/wiki/Hadamard_product_(matrices)#:~:text=In%20mathematics%2C%20the%20Hadamard%20product,elements%20i%2C%20j%20of%20the" rel="noopener ugc nofollow" target="_blank"> <strong class="ka ir">哈达玛乘积</strong> </a> <strong class="ka ir">)。</strong></p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/6f86a0a0d497d003f0fc8afb8b62cd43.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*NsiYxt8tPDQyjyH3C08PVA@2x.png"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Movement of the Kernel</figcaption></figure><p id="e26f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">过滤器以一定的步幅值向右移动，直到解析完整的宽度。继续前进，它向下跳到具有相同步幅值的图像的开头(左侧),并重复该过程，直到遍历整个图像。</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mu"><img src="../Images/3cf7049e2e21f0a284b9dd40b42d57ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*ciDgQEjViWLnCbmX-EeSrA.gif"/></div></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Convolution operation on a MxNx3 image matrix with a 3x3x3 Kernel</figcaption></figure><p id="54cb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在具有多个通道(例如 RGB)的图像的情况下，内核具有与输入图像相同的深度。在 Kn 和 In 栈之间进行矩阵乘法([K1，I1]；[K2，I2]；[K3，I3])，所有结果与偏差相加，得到一个压缩的单深度通道卷积特征输出。</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/8d0c8d79ca7ffa7b613f2c4923420c69.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/1*1VJDP6qDY9-ExTuQVEOlVg.gif"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Convolution Operation with Stride Length = 2</figcaption></figure><p id="a57a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">卷积操作的目的是<strong class="ka ir">从输入图像中提取高级特征</strong>，如边缘。ConvNets 不必仅限于一个卷积层。按照惯例，第一个 ConvLayer 负责捕获边缘、颜色、渐变方向等低级特征。随着图层的增加，该架构也适应了高级功能，为我们提供了一个对数据集中的图像有全面了解的网络，就像我们会做的那样。</p><p id="7f9d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该操作有两种类型的结果-一种是与输入相比，卷积特征的维数减少，另一种是维数增加或保持不变。这是通过在前一种情况下应用<strong class="ka ir">有效填充</strong>，或者在后一种情况下应用<strong class="ka ir">相同填充</strong>来完成的。</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/478a1347de022bbcc210913c1aaf68e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/1*nYf_cUIHFEWU1JXGwnz-Ig.gif"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk"><strong class="bd mw">SAME padding:</strong> 5x5x1 image is padded with 0s to create a 6x6x1 image</figcaption></figure><p id="8652" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当我们将 5x5x1 图像放大为 6x6x1 图像，然后对其应用 3x3x1 内核时，我们发现卷积矩阵的维数为 5x5x1。因此得名——<strong class="ka ir">同垫</strong>。</p><p id="7bb2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">另一方面，如果我们在没有填充的情况下执行相同的操作，我们会看到一个矩阵，它具有内核(3x3x1)本身的维度— <strong class="ka ir">有效填充</strong>。</p><p id="8d12" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下面的存储库包含了许多这样的 gif，它们将帮助你更好地理解垫高和步幅长度是如何协同工作以达到我们需要的结果的。</p><div class="mx my gp gr mz na"><a href="https://github.com/vdumoulin/conv_arithmetic" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd ir gy z fp nf fr fs ng fu fw ip bi translated">vdumoulin/conv 算术</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">深度学习背景下的卷积算法技术报告——VDU moulin/conv 算法</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">github.com</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no jw na"/></div></div></a></div><h2 id="333b" class="le lf iq bd lg lh li dn lj lk ll dp lm kj ln lo lp kn lq lr ls kr lt lu lv lw bi translated">汇集层</h2><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/c18e95e3e13b54f15346cce812f4b45f.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/1*uoWYsCV5vBU8SHFPAPao-w.gif"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk">3x3 pooling over 5x5 convolved feature</figcaption></figure><p id="6015" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">与卷积层类似，汇集层负责减小卷积要素的空间大小。这是为了<strong class="ka ir">通过降维来降低处理数据</strong>所需的计算能力。此外，它对于<strong class="ka ir">提取旋转和位置不变的主导特征</strong>是有用的，从而保持有效训练模型的过程。</p><p id="6ee5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有两种类型的池:最大池和平均池。<strong class="ka ir">最大池</strong>从内核覆盖的图像部分返回<strong class="ka ir">最大值</strong>。另一方面，<strong class="ka ir">平均池</strong>返回内核覆盖的图像部分的所有值的<strong class="ka ir">平均值。</strong></p><p id="b9da" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最大池也表现为<strong class="ka ir">噪音抑制</strong>。它完全丢弃有噪声的激活，并且在降维的同时执行去噪。另一方面，平均池只是作为一种噪声抑制机制来执行降维。因此，我们可以说<strong class="ka ir">最大池比平均池</strong>性能好得多。</p><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/635926b797dea477708d6e7fb6020556.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*KQIEqhxzICU7thjaQBfPBQ.png"/></div><figcaption class="mc md gj gh gi me mf bd b be z dk">Types of Pooling</figcaption></figure><p id="6915" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">卷积层和汇集层一起形成卷积神经网络的第 I 层。根据图像的复杂性，这种层的数量可以增加，以捕捉更低层次的细节，但代价是更多的计算能力。</p><p id="3751" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在经历了上述过程之后，我们已经成功地使模型理解了特征。接下来，我们将使最终输出变平，并将其输入常规神经网络进行分类。</p><h2 id="82e5" class="le lf iq bd lg lh li dn lj lk ll dp lm kj ln lo lp kn lq lr ls kr lt lu lv lw bi translated">分类—全连接层(FC 层)</h2><figure class="ly lz ma mb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nr"><img src="../Images/741f7d83ea6fa768c89b2d92cbc98e95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kToStLowjokojIQ7pY2ynQ.jpeg"/></div></div></figure><p id="7432" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">添加全连接层是学习由卷积层的输出表示的高级特征的非线性组合的(通常)廉价方式。全连接层正在学习该空间中可能的非线性函数。</p><p id="2f60" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">既然我们已经将输入图像转换成适合多层感知器的形式，我们应该将图像展平成一个列向量。平坦化的输出被馈送到前馈神经网络，并且反向传播被应用于训练的每次迭代。在一系列时期内，该模型能够区分图像中的主要特征和某些低级特征，并使用<strong class="ka ir"> Softmax 分类</strong>技术对其进行分类。</p><p id="53a6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有各种可用的 CNN 架构，它们是构建算法的关键，在可预见的未来，这些算法将作为一个整体为 AI 提供动力。其中一些列举如下:</p><ol class=""><li id="b784" class="ns nt iq ka b kb kc kf kg kj nu kn nv kr nw kv nx ny nz oa bi translated">LeNet</li><li id="2ba9" class="ns nt iq ka b kb ob kf oc kj od kn oe kr of kv nx ny nz oa bi translated">AlexNet</li><li id="3f07" class="ns nt iq ka b kb ob kf oc kj od kn oe kr of kv nx ny nz oa bi translated">VGGNet</li><li id="e514" class="ns nt iq ka b kb ob kf oc kj od kn oe kr of kv nx ny nz oa bi translated">谷歌网</li><li id="735c" class="ns nt iq ka b kb ob kf oc kj od kn oe kr of kv nx ny nz oa bi translated">雷斯内特</li><li id="b68a" class="ns nt iq ka b kb ob kf oc kj od kn oe kr of kv nx ny nz oa bi translated">ZFNet</li></ol></div><div class="ab cl og oh hu oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="ij ik il im in"><p id="9c7d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> GitHub 笔记本——使用 TensorFlow 的 MNIST 数据集识别手写数字</strong></p><div class="mx my gp gr mz na"><a href="https://github.com/ss-is-master-chief/MNIST-Digit.Recognizer-CNNs" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab fo"><div class="nc ab nd cl cj ne"><h2 class="bd ir gy z fp nf fr fs ng fu fw ip bi translated">ss-is-master-chief/MNIST 数字。识别器-CNN</h2><div class="nh l"><h3 class="bd b gy z fp nf fr fs ng fu fw dk translated">CNN 识别运行 10 个时期的手写数字(MNIST)的实现。准确率:98.99% …</h3></div><div class="ni l"><p class="bd b dl z fp nf fr fs ng fu fw dk translated">github.com</p></div></div><div class="nj l"><div class="on l nl nm nn nj no jw na"/></div></div></a></div><blockquote class="kw kx ky"><p id="f7b3" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated">准备好尝试自己的卷积神经网络了吗？查看<a class="ae ld" href="https://saturncloud.io/?utm_source=Medium+&amp;utm_medium=Medium&amp;utm_campaign=SumitSaha&amp;utm_term=ConvolutionalNeuralNets" rel="noopener ugc nofollow" target="_blank">土星云</a>免费计算(包括免费 GPU)。</p></blockquote></div></div>    
</body>
</html>