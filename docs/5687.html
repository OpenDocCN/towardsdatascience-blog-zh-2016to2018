<html>
<head>
<title>Review: SSD — Single Shot Detector (Object Detection)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回顾:固态硬盘—单次检测器(物体检测)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-ssd-single-shot-detector-object-detection-851a94607d11?source=collection_archive---------2-----------------------#2018-11-03">https://towardsdatascience.com/review-ssd-single-shot-detector-object-detection-851a94607d11?source=collection_archive---------2-----------------------#2018-11-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="5995" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi kl translated"><span class="l km kn ko bm kp kq kr ks kt di"> T </span> his time，<strong class="jp ir"> SSD(单发探测器)</strong>回顾。通过使用 SSD，我们只需要<strong class="jp ir">拍摄一张照片来检测图像内的多个对象</strong>，而基于区域提议网络(RPN)的方法，如<a class="ae ku" href="https://medium.com/coinmonks/review-r-cnn-object-detection-b476aba290d1" rel="noopener"> R-CNN </a>系列，需要拍摄两张照片，一张用于生成区域提议，一张用于检测每个提议的对象。因此，与基于双镜头 RPN 的方法相比，SSD 要快得多。</p><p id="70b2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> SSD300 在 59 FPS 时实现了 74.3%的 mAP</strong>，而<strong class="jp ir"> SSD500 在 22 FPS 时实现了 76.9%的 mAP</strong>，其性能优于<a class="ae ku" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202">更快的 R-CNN(7 FPS 时 73.2%的 mAP)</a>和<a class="ae ku" rel="noopener" target="_blank" href="/yolov1-you-only-look-once-object-detection-e1f3ffec8a89">yolov 1(45 FPS 时 63.4%的 mAP)</a>。下面是一个使用 MobileNet 进行特征提取的 SSD 示例:</p><figure class="kv kw kx ky gt kz"><div class="bz fp l di"><div class="la lb l"/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="ak">SSD</strong></figcaption></figure><p id="d817" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从上面我们可以看到惊人的<strong class="jp ir">实时性能</strong>。而 SSD 是我写这个故事的时候<strong class="jp ir"> 2016 ECCV </strong>一篇超过<strong class="jp ir"> 2000 引用</strong>的论文。(<a class="lg lh ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----851a94607d11--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><h1 id="1b19" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">涵盖哪些内容</h1><ol class=""><li id="de24" class="mn mo iq jp b jq mp ju mq jy mr kc ms kg mt kk mu mv mw mx bi translated"><strong class="jp ir">多箱探测器</strong></li><li id="5c79" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk mu mv mw mx bi translated"><strong class="jp ir"> SSD 网络架构</strong></li><li id="4830" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk mu mv mw mx bi translated"><strong class="jp ir">损失函数</strong></li><li id="84d6" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk mu mv mw mx bi translated"><strong class="jp ir">默认框的比例和长宽比</strong></li><li id="a54f" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk mu mv mw mx bi translated"><strong class="jp ir">培训的一些细节</strong></li><li id="7ffc" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk mu mv mw mx bi translated"><strong class="jp ir">结果</strong></li></ol></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><h1 id="51cc" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">1.<strong class="ak">多箱探测器</strong></h1><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi nd"><img src="../Images/d75905c468e2b779a9bedc2819e9f855.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*St98vVQEqLndeV_-SeUc9Q.png"/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="bd nk">SSD: Multiple Bounding Boxes for Localization (loc) and Confidence (conf)</strong></figcaption></figure><ul class=""><li id="cf93" class="mn mo iq jp b jq jr ju jv jy nl kc nm kg nn kk no mv mw mx bi translated">经过一定的卷积进行特征提取后，我们得到<strong class="jp ir">一个尺寸为<em class="np"> m </em> × <em class="np"> n </em>(位置数)的特征层，具有<em class="np"> p </em>通道</strong>，如上面的 8×8 或 4×4。并且在这个<em class="np">m</em>×<em class="np">n</em>×<em class="np">p</em>特征层上应用 3×3 conv。</li><li id="28c6" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk no mv mw mx bi translated">对于每个位置，我们得到了 k 个包围盒。这些 k 个边界框具有不同的大小和纵横比。这个概念是，也许一个垂直的长方形更适合人类，一个水平的长方形更适合汽车。</li><li id="1e46" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk no mv mw mx bi translated"><strong class="jp ir">对于每个边界框，我们将计算<em class="np"> c </em>类分数和相对于原始默认边界框形状的 4 个偏移量。</strong></li><li id="432f" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk no mv mw mx bi translated">因此，我们得到了<strong class="jp ir">(<em class="np">c</em>+4)<em class="np">kmn</em>输出。</strong></li></ul><p id="fb40" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这也是论文被称为“SSD:单拍<strong class="jp ir">多盒</strong>探测器”的原因。但以上只是 SSD 的一部分。</p></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><h1 id="26e4" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">2.<strong class="ak"> SSD 网络架构</strong></h1><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi nq"><img src="../Images/0f4b37e107ac4e36338cb36b0f804f98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t2oxAKMUMpdKEqI9b1JSLw.png"/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="bd nk">SSD (Top) vs YOLO (Bottom)</strong></figcaption></figure><p id="7588" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了有更精确的检测，不同层的特征图也通过一个小的 3×3 卷积来进行对象检测，如上所示。</p><ul class=""><li id="7a8d" class="mn mo iq jp b jq jr ju jv jy nl kc nm kg nn kk no mv mw mx bi translated">比如说<strong class="jp ir">在 Conv4_3，尺寸是 38×38×512 </strong>。<strong class="jp ir">采用 3×3 conv。</strong>并且有<strong class="jp ir"> 4 个边界框</strong>和<strong class="jp ir">每个边界框将有(类+ 4)个输出</strong>。因此，在 Conv4_3，输出为 38×38×4×( <em class="np"> c </em> +4)。假设有 20 个对象类加上一个背景类，输出为 38×38×4×(21+4)= 144400。<strong class="jp ir">就包围盒的数量而言，有 38×38×4 = 5776 个包围盒。</strong></li><li id="91ff" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk no mv mw mx bi translated">类似地，对于其他 conv 层:</li><li id="f013" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk no mv mw mx bi translated">Conv7: 19×19×6 = 2166 盒(每个位置 6 盒)</li><li id="ec3b" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk no mv mw mx bi translated">Conv8_2: 10×10×6 = 600 盒(每个位置 6 盒)</li><li id="460e" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk no mv mw mx bi translated">Conv9_2: 5×5×6 = 150 盒(每个位置 6 盒)</li><li id="4d9b" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk no mv mw mx bi translated">Conv10_2: 3×3×4 = 36 盒(每个位置 4 盒)</li><li id="053c" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk no mv mw mx bi translated">Conv11_2: 1×1×4 = 4 盒(每个位置 4 盒)</li></ul><p id="ff59" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果把它们加起来，我们总共得到了 5776+2166+600+150+36+4 =<strong class="jp ir">8732 箱</strong>。如果我们记得 YOLO，最后有 7×7 个位置，每个位置有 2 个边界框。YOLO 只有 7×7×2 = 98 盒。因此<strong class="jp ir"> SSD 有 8732 个包围盒，比 YOLO </strong>多。</p></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><h1 id="262a" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">3.损失函数</h1><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/77a543575e0829be7edc28b82e6cba94.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*vfpARz-ozzpb0jHM8yJ0zA.png"/></div></figure><p id="3636" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">损失函数包括两项:Lconf 和 Lloc，其中 N 是匹配的默认框。匹配的默认框</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/af19e39320bd0713b764866a628b8e15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*yOU4TCmYwLgS06kvcfSWxA.png"/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="bd nk">Localization Loss</strong></figcaption></figure><p id="4a5e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Lloc 是定位损失，它是预测框(l)和地面实况框(g)参数之间的平滑 L1 损失。这些参数包括边界框的中心点(cx，cy)、宽度(w)和高度(h)的偏移量。这种损失与更快的 R-CNN 中的损失类似。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi nt"><img src="../Images/a450fa2ec6ddf9a4d772c56673c20019.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*flNOlxfJj0Pyt1lNZmQaLA.png"/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="bd nk">Confidence Loss</strong></figcaption></figure><p id="da09" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Lconf 是置信度损失，它是多个类别置信度(c)的软最大损失。(通过交叉验证将α设置为 1。)<em class="np"> xij^p </em> = {1，0}，是将类别<em class="np"> p </em>的第<em class="np"> i </em>个默认框匹配到第<em class="np"> j </em>个真实框的指示器。</p></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><h1 id="d85f" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated"><strong class="ak"> 4。</strong>默认框的比例和长宽比</h1><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/7a9e5413b8580dc85a1c00c7943d4df8.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*bX2dGa3mgbO5Fdwv8biQUg.png"/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="bd nk">Scale of Default Boxes</strong></figcaption></figure><p id="22f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">假设我们有<em class="np"> m </em>个特征图用于预测，我们可以计算第<em class="np"> k </em>个特征图的<em class="np"> Sk </em>。Smin 是 0.2，Smax 是 0.9。这意味着最低层的比例为 0.2，最高层的比例为 0.9。中间的所有层都是规则间隔的。</p><p id="bf71" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于每个比例 sk，我们有 5 个非方形纵横比:</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/6d76ca23c097b57702f8fdddfd42d126.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*vI4qQt5MRNTtOA1ODyKbEA.png"/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="bd nk">5 Non-Square Bounding Boxes</strong></figcaption></figure><p id="176e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于 1:1 的纵横比，我们得到 sk ':</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/44067a8b259720a8cdbc2d7c7a9c88a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:288/format:webp/1*C6MiW3aHuZwMjht2svfAnQ.png"/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="bd nk">1 Square Bounding Box</strong></figcaption></figure><p id="8fb5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，我们总共最多可以有 6 个不同纵横比的边界框。对于只有 4 个边界框的层，ar = 1/3，省略 3。</p><h1 id="96db" class="lp lq iq bd lr ls nx lu lv lw ny ly lz ma nz mc md me oa mg mh mi ob mk ml mm bi translated">5.训练的一些细节</h1><h2 id="4293" class="oc lq iq bd lr od oe dn lv of og dp lz jy oh oi md kc oj ok mh kg ol om ml on bi translated">5.1 硬负开采</h2><p id="9c7a" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy oo ka kb kc op ke kf kg oq ki kj kk ij bi translated">我们没有使用所有的负面例子，而是使用每个默认框的最高置信损失对它们进行排序，并挑选出顶部的例子，这样负面和正面之间的比率最多为 3:1。</p><p id="718b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这可以导致<strong class="jp ir">更快的优化</strong>和<strong class="jp ir">更稳定的训练</strong>。</p><h2 id="4c63" class="oc lq iq bd lr od oe dn lv of og dp lz jy oh oi md kc oj ok mh kg ol om ml on bi translated">5.2 数据扩充</h2><p id="689b" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy oo ka kb kc op ke kf kg oq ki kj kk ij bi translated">每个训练图像通过以下方式随机采样:</p><ul class=""><li id="8cef" class="mn mo iq jp b jq jr ju jv jy nl kc nm kg nn kk no mv mw mx bi translated">整个原始输入图像</li><li id="957a" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk no mv mw mx bi translated">对面片进行采样，使其与对象的重叠为 0.1、0.3、0.5、0.7 或 0.9。</li><li id="28d2" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk no mv mw mx bi translated">随机抽取补丁样本</li></ul><p id="caeb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">每个采样面片的<strong class="jp ir">大小为【0.1，1】</strong>或原始图像大小，<strong class="jp ir">纵横比从 1/2 到 2 </strong>。在上述步骤之后，每个采样的小块将被<strong class="jp ir">调整到固定的大小</strong>，并且除了一些<strong class="jp ir">光度量失真</strong>【14】之外，还可能以 0.5 的概率<strong class="jp ir">水平翻转。</strong></p><h2 id="53e8" class="oc lq iq bd lr od oe dn lv of og dp lz jy oh oi md kc oj ok mh kg ol om ml on bi translated">5.3 阿特鲁卷积(空洞算法/扩张卷积)</h2><p id="711e" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy oo ka kb kc op ke kf kg oq ki kj kk ij bi translated">基本网络是<a class="ae ku" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener"> VGG16 </a>，并使用 ILSVRC 分类数据集进行预训练。<strong class="jp ir"> FC6 和 FC7 变为卷积层，分别为 Conv6 和 Conv7 </strong>，如上图所示。</p><p id="15bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，<strong class="jp ir"> FC6 和 FC7 使用阿特鲁卷积</strong>(又名空洞算法或扩张卷积)代替常规卷积。<strong class="jp ir"> pool5 由 2×2-s2 改为 3×3-s1 </strong>。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi or"><img src="../Images/de6a416acab5fbdbb9983b493e400ac7.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/0*7LCdr8W3gSQdnlSC.gif"/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="bd nk">Atrous convolution / Hole algorithm / Dilated convolution</strong></figcaption></figure><p id="a0f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如我们所见，特征图在 Conv6 和 Conv7 处较大，使用如上所示的阿特鲁卷积可以<strong class="jp ir">增加感受野，同时保持参数数量相对较少</strong>。(我希望在未来的日子里，我可以回顾一下 DeepLab，以更详细地介绍这一点。)</p><h1 id="9d61" class="lp lq iq bd lr ls nx lu lv lw ny ly lz ma nz mc md me oa mg mh mi ob mk ml mm bi translated">6.结果</h1><p id="05f4" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy oo ka kb kc op ke kf kg oq ki kj kk ij bi translated">有两种型号:SSD300 和 SSD512。<br/> SSD300: 300×300 输入图像，分辨率更低，速度更快。<br/> SSD512: 512×512 输入图像，分辨率更高，更精确。让我们看看结果。</p><h2 id="af5f" class="oc lq iq bd lr od oe dn lv of og dp lz jy oh oi md kc oj ok mh kg ol om ml on bi translated">6.1 模型分析</h2><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi os"><img src="../Images/4e9689381a191a34aa5a179a661f3272.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dglk5_SXSft7cvsBP8CW7Q.png"/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="bd nk">Model Analysis</strong></figcaption></figure><ul class=""><li id="afdb" class="mn mo iq jp b jq jr ju jv jy nl kc nm kg nn kk no mv mw mx bi translated">数据扩充至关重要，它将 mAP 从 65.5%提高到 74.3%。</li><li id="71d8" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk no mv mw mx bi translated">随着更多的默认框形状，它从 71.6%提高到 74.3%的地图。</li><li id="9333" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk no mv mw mx bi translated">阿特鲁的情况也差不多。但是没有 atrous 的要慢 20%左右。</li></ul><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi ot"><img src="../Images/921c1f7f9e7945b0e63451530d4b40fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gH7QFNMRBrdIH4sH4MRNhA.png"/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="bd nk">Multiple Output Layers at Different Resolutions</strong></figcaption></figure><p id="925d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">随着 conv 图层的输出越来越多，包含的边界框也越来越多。正常情况下，准确率从 62.4%提高到 74.6%。然而，<strong class="jp ir">conv 11 _ 2 的加入使结果变得更糟。作者认为盒子不够大，无法覆盖大型物体。</strong></p><h2 id="5628" class="oc lq iq bd lr od oe dn lv of og dp lz jy oh oi md kc oj ok mh kg ol om ml on bi translated">6.2 帕斯卡 VOC 2007</h2><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi ou"><img src="../Images/657f6a41f29dcafe8c20d3bc2906af5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*phgh8Vu3C4r5DBhkcjA1WQ.png"/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="bd nk">Pascal VOC 2007 Dataset</strong></figcaption></figure><p id="09d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如上图，SSD512 有 81.6%的 mAP。SSD300 具有 79.6%的 mAP，这已经优于 78.8%的更快的 R-CNN。</p><h2 id="7b5a" class="oc lq iq bd lr od oe dn lv of og dp lz jy oh oi md kc oj ok mh kg ol om ml on bi translated">6.3 帕斯卡 VOC 2012</h2><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi ov"><img src="../Images/7c9d7c4367763987ac3895049d6795db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2BZyw-1rXwjqcZHypbr74g.png"/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="bd nk">Pascal VOC 2012 Dataset</strong></figcaption></figure><p id="db99" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">SSD512 (80.0%)比更快的 R-CNN (75.9%)准确率高 4.1%。</p><h2 id="48cc" class="oc lq iq bd lr od oe dn lv of og dp lz jy oh oi md kc oj ok mh kg ol om ml on bi translated">6.4 可可女士</h2><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi ow"><img src="../Images/9fcf74547bcb7480f271288057b4a9bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_VA-yIJHXjcGL4-IxpYBlQ.png"/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="bd nk">MS COCO Dataset</strong></figcaption></figure><p id="7c24" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">SSD512 在 mAP@0.5 中只比更快的 R-CNN 好 1.2%。这是因为对于较大的对象，它具有好得多的 AP (4.8%)和 AR (4.6%)，但是对于小对象，它在 AP (1.3%)和 AR (2.0%)方面的改善相对较小。</p><p id="5117" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">更快的 R-CNN 在使用 SSD 的较小对象上更具竞争力。作者认为，这是由于基于 RPN 的方法，其中包括两个镜头。</p><h2 id="0a69" class="oc lq iq bd lr od oe dn lv of og dp lz jy oh oi md kc oj ok mh kg ol om ml on bi translated">6.5 ILSVRC DET</h2><p id="6e33" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy oo ka kb kc op ke kf kg oq ki kj kk ij bi translated">在 SSD300 上获得初步结果:在 val2 集合上获得 43.4%的 mAP。</p><h2 id="1562" class="oc lq iq bd lr od oe dn lv of og dp lz jy oh oi md kc oj ok mh kg ol om ml on bi translated">6.6 小物体精度的数据扩充</h2><p id="df02" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy oo ka kb kc op ke kf kg oq ki kj kk ij bi translated">为了克服第 6.4 节中提到的对小目标漏检的弱点，进行了<strong class="jp ir">“缩小”操作以创建更多的小训练样本。</strong>跨多个数据集实现了 2%-3%的 mAP 增长，如下所示:</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi ox"><img src="../Images/539a1edcce6fe3156bc079551fb64a7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-luLefjEZDHBQgMVda9J_w.png"/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="bd nk">Data Augmentation for Small Object Accuracy</strong></figcaption></figure><h2 id="9ade" class="oc lq iq bd lr od oe dn lv of og dp lz jy oh oi md kc oj ok mh kg ol om ml on bi translated">6.7 推理时间</h2><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi oy"><img src="../Images/18c0dafdf67917417486bd8d583626cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QZtSZIaUecoVQyD6_xug6Q.png"/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="bd nk">Inference Time</strong></figcaption></figure><ul class=""><li id="d87a" class="mn mo iq jp b jq jr ju jv jy nl kc nm kg nn kk no mv mw mx bi translated">批量大小为 1 时，SSD300 和 SSD512 分别可以获得 46 和 19 FPS。</li><li id="ad17" class="mn mo iq jp b jq my ju mz jy na kc nb kg nc kk no mv mw mx bi translated">在批量大小为 8 的情况下，SSD300 和 SSD512 分别可以获得 59 和 22 FPS。</li></ul></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi oz"><img src="../Images/101ef120fde05bb5bfd9f8e1358ef13a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4BLx59c0GBy1v7hPL3nn2g.png"/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk"><strong class="bd nk">Some “Crazy” Detection Results on MS COCO Dataset</strong></figcaption></figure></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><p id="3b44" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">SSD300 和 SSD512 都有较高的 mAP 和较高的 FPS。因此，SSD 是需要研究的目标检测方法之一。顺便说一下，我希望将来能报道 DSSD。</p></div><div class="ab cl li lj hu lk" role="separator"><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln lo"/><span class="ll bw bk lm ln"/></div><div class="ij ik il im in"><h1 id="1405" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">参考</h1><p id="6a24" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy oo ka kb kc op ke kf kg oq ki kj kk ij bi translated">【2016 ECCV】【SSD】<br/><a class="ae ku" href="https://arxiv.org/abs/1512.02325" rel="noopener ugc nofollow" target="_blank">SSD:单发多盒探测器</a></p><h1 id="6887" class="lp lq iq bd lr ls nx lu lv lw ny ly lz ma nz mc md me oa mg mh mi ob mk ml mm bi translated">我的相关评论</h1><p id="b768" class="pw-post-body-paragraph jn jo iq jp b jq mp js jt ju mq jw jx jy oo ka kb kc op ke kf kg oq ki kj kk ij bi translated">[ <a class="ae ku" href="https://medium.com/coinmonks/review-r-cnn-object-detection-b476aba290d1" rel="noopener"> R-CNN </a> ] [ <a class="ae ku" href="https://medium.com/coinmonks/review-fast-r-cnn-object-detection-a82e172e87ba" rel="noopener">快速 R-CNN </a> ] [ <a class="ae ku" rel="noopener" target="_blank" href="/review-faster-r-cnn-object-detection-f5685cb30202">更快 R-CNN</a>][<a class="ae ku" rel="noopener" target="_blank" href="/yolov1-you-only-look-once-object-detection-e1f3ffec8a89">yolov 1</a>][<a class="ae ku" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener">VGGNet</a>]</p></div></div>    
</body>
</html>