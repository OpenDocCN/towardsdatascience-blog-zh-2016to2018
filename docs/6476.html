<html>
<head>
<title>Dealing With Class Imbalanced Datasets For Classification.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于分类的类不平衡数据集的处理。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dealing-with-class-imbalanced-datasets-for-classification-2cc6fad99fd9?source=collection_archive---------7-----------------------#2018-12-15">https://towardsdatascience.com/dealing-with-class-imbalanced-datasets-for-classification-2cc6fad99fd9?source=collection_archive---------7-----------------------#2018-12-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/de8b9f3f7d8d2c659bbd22e040f5104c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x5n_2wtEk16SJEC9_V54FQ.jpeg"/></div></div></figure><p id="a9cf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">倾斜的数据集并不少见。它们很难处理。当遇到这样的问题时，通常的分类模型和技术经常失败。虽然你的模型甚至可以让你在这种情况下达到 99%的准确率，但是，如果你用一个合理的指标来衡量自己，如 ROC Auc 得分，那么你将面临登上排行榜的麻烦。这是因为如果数据集是倾斜的，例如，阳性与阴性的比例为 10:1，那么通过预测每个样本的阳性而无需任何学习，您就可以获得 90%的准确率！那么，我们如何解决这个问题呢？这篇文章将会强调一些你可以用来做好这些工作的有效技巧。这些技术包括对数据进行不同的采样，巧妙地设置一些超参数，以及使用包含不同版本的常用算法的库，这些算法可以在内部处理不平衡。</p><ol class=""><li id="f3af" class="kw kx iq ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated"><strong class="ka ir">采样</strong></li></ol><p id="6123" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你可以用两种不同的方法做到这一点。</p><p id="46cc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">a.<em class="lf">欠采样。</em></p><p id="3ac0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">比方说，您的数据集中有 40，000 个阳性样本和 2，000 个阴性样本。从今以后，我们将把它作为我们的运行范例。你可以做的只是从 40，000 个样本中随机选取 2，000 个阳性样本，所有 2，000 个阴性样本，然后只在这 4，000 个样本上训练和验证你的模型。这将允许你以通常的方式使用所有的分类算法。这种方法很容易实现，运行速度也很快。然而，一个不利之处是，您可能会丢弃您拥有的 38，000 个阳性样本，并且这些数据将付诸东流。</p><p id="dda1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了克服这个问题，您可以创建一个模型集合，其中每个模型使用一组不同的 2，000 个阳性样本和所有 2，000 个阴性样本，并分别进行训练和验证。然后在你的测试集上，你对所有这些模型进行多数投票。这使您可以考虑到所有的数据，而不会导致不平衡。此外，你甚至可以对不同的集合使用不同的算法，这样你的集合会更加健壮。然而，这在计算上有点昂贵。</p><p id="0961" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">b.<em class="lf">过采样</em></p><p id="1cdb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这个方法中，您生成了少数类的更多样本。为此，您可以先创建创成式模型，然后创建新样本，也可以只选取现有样本进行替换。存在多种过采样技术，如<em class="lf"> SMOTE、ADASYN </em>等。您将不得不看看哪一个最适合您的用例。此外，过采样本身是一个计算量很大的过程。主要的优点是，这允许你的一个模型立刻考虑你的所有数据，并且还帮助你生成新的数据。</p><p id="cc5d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 2。使用秤重位置重量参数。</strong></p><p id="2429" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你使用的是 XGBoost 这样的算法，有一个简单的方法。您可以设置算法的<em class="lf"> scale_pos_weight </em>超参数，以指示您的数据集具有一定比例的正负类，XGBoost 将处理其余部分。因此，在我们运行的 40，000 个阳性样本和 2，000 个阴性样本的例子中，如果我们想在这个数据集上训练我们的 XGBoost 分类器，我们应该将 scale_pos_weight 的值设置为 40，000/2，000 = 20。<br/>这在实践中非常奏效。然而，一个缺点是这限制了您使用 XGBoost 和其他类似的算法，因为不是所有的算法都有这个可调的超参数。</p><p id="9242" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 3。使用不平衡学习图书馆。</strong></p><p id="762b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">是的，你猜对了。已经有一个成熟的 python 库专门用于处理这类问题。这个库是 sklearn-contrib 的一部分。但是很容易迷失在图书馆的细节里。对我来说效果最好的是<em class="lf">BalancedRandomForestClassifier</em>。通常的随机森林算法在不平衡数据集上表现极差。然而，这个平衡随机森林分类器是 imblearn 包的一部分，工作得非常好。它在内部处理采样问题。您可以获得随机森林所有功能以及熟悉的 sklearn API。该库的其他特性包括内置过采样器、欠采样器以及两者的组合。)和其他专门用于处理倾斜数据集的算法。这里有很多值得探索的地方。</p><p id="5a75" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一个月前，当我开始处理一个 20:1 不平衡的数据集时，我找不到关于如何解决这个问题的很好的资源。因此，我决定展示我在试图找到有效处理倾斜数据集的方法时学到的东西。我希望这对你有好处。你可以在我的<a class="ae lg" href="https://github.com/arrayslayer/ML-Project" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>找到代码库中使用的所有这些技术。请随时在评论中提出建议，你可能知道的任何其他方法可以帮助人们在这场不平等的战斗中找到伟大的平等！谢谢你。</p></div></div>    
</body>
</html>