<html>
<head>
<title>Using Bagging and Boosting to Improve Classification Tree Accuracy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Bagging和Boosting提高分类树的准确性</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-bagging-and-boosting-to-improve-classification-tree-accuracy-6d3bb6c95e5b?source=collection_archive---------1-----------------------#2017-07-09">https://towardsdatascience.com/using-bagging-and-boosting-to-improve-classification-tree-accuracy-6d3bb6c95e5b?source=collection_archive---------1-----------------------#2017-07-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="4488" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Bagging和boosting是两种可以用来提高分类回归树(CART)准确性的技术。在这篇文章中，我将从我在早期文章中开发的单个90+点葡萄酒分类树开始，并将其分类精度与两个新的袋装和提升算法进行比较。</p><p id="dbd9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为打包和提升都依赖于分类器的集合，所以它们被称为“集成”方法。这两种分类器本身都不是一种分类器，而是通过聚合其他几个子分类器的预测来产生分类预测。</p><p id="7b54" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我将再次使用从《葡萄酒爱好者》杂志上搜集的葡萄酒评论数据，该杂志可在https://www.kaggle.com/zynicide/wine-reviews的<a class="ae kl" href="https://www.kaggle.com/zynicide/wine-reviews" rel="noopener ugc nofollow" target="_blank">免费获得。它包含了150，000种葡萄酒的分数，以及每瓶葡萄酒的价格、酒厂、产区、品种&amp;等信息。对于这个项目，我将只使用美国种植的葡萄酒。</a></p><p id="bbf7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我将使用sci-kit learn的DecisionTreeClassifier对我的70%的数据(训练样本)训练一个单一的分类树，无需超参数调整。这将作为未来合奏表演的基准:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="kr ks l"/></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kt"><img src="../Images/907c5a2ce315cd9adcab17bf7e95ee60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*QYteoYa6J3fBk2pyCGvhbg.png"/></div></figure><h1 id="81b7" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">制袋材料</h1><p id="5aab" class="pw-post-body-paragraph jn jo iq jp b jq lu js jt ju lv jw jx jy lw ka kb kc lx ke kf kg ly ki kj kk ij bi translated">Bagging使用了一种简单的方法，这种方法在统计分析中反复出现——通过合并多个估计值来改进一个估计值。Bagging使用训练数据的引导抽样构建n个分类树，然后组合它们的预测以产生最终的元预测。</p><p id="59a2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Sci-kit learn实现的bagging ensemble是BaggingClassifier，它接受一个基础分类器的名称作为输入，bagging ensemble将复制该分类器n次。BaggingClassifier的主要调整超参数是在元预测中创建和聚合的基本分类器的数量。</p><p id="7f8a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是bagging系综在改变(1)基本估计量的数量和(2)基本估计量的大小(叶子的数量)时的表现:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="kr ks l"/></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/d06005c7087503813585d0812400c13c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*4DggM7mvm8IhuTbwvWzMrQ.png"/></div></figure><p id="4875" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如上所示，bagging预测精度对基础估计量的限制很敏感。在实践中，限制基估计量的大小在bagging系综中是多余的，因为bootstrap抽样获得了与限制基树相似的结果。</p><p id="18ff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">另一个关键的观察是，bagging集成的性能不会超过单一CART基准，直到估计器的数量超过阈值水平。单树装袋集成的准确性比单个CART差很多——如果你问这是怎么回事，可以用bootstrap采样来解释:由于bootstrap，单树装袋集成中的基本估计器不会使用100%的训练数据。Bootstrap采样是一种可调参数的bagging分类器。</p><h1 id="0c5b" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">助推</h1><p id="7701" class="pw-post-body-paragraph jn jo iq jp b jq lu js jt ju lv jw jx jy lw ka kb kc lx ke kf kg ly ki kj kk ij bi translated">为了展示boosting方法的功效，我将使用AdaBoost，它在sci-kit learn中实现为AdaBoostClassifier。这种类型的集成创建了n个基本估计量，就像bagging一样，但它是以迭代的方式实现的，如下所示:</p><ol class=""><li id="d05e" class="ma mb iq jp b jq jr ju jv jy mc kc md kg me kk mf mg mh mi bi translated">使用正常方法训练基于估计值#1</li><li id="b237" class="ma mb iq jp b jq mj ju mk jy ml kc mm kg mn kk mf mg mh mi bi translated">观察基础估计器#1错误预测的训练数据样本，并为这些样本创建权重D&gt;1.0</li><li id="c3cc" class="ma mb iq jp b jq mj ju mk jy ml kc mm kg mn kk mf mg mh mi bi translated">训练基础估计量#2，在计算同质性基尼/熵度量时将权重D应用于样本</li><li id="1146" class="ma mb iq jp b jq mj ju mk jy ml kc mm kg mn kk mf mg mh mi bi translated">重复n次。</li></ol><p id="1383" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过这种方式，增强创建了连续的基本分类器，这些基本分类器被告知对来自训练数据的误分类样本给予更大的重视。像bagging一样，来自<em class="mo">所有</em>提升基本分类器的结果被聚集以产生元预测。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="kr ks l"/></div></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/d9bce2afdb82e332e87d9a96dd0a1ab4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*11cHCPS7dJxfGzYJeYenEw.png"/></div></figure><p id="36cd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与bagging相比，boosting集成的精度随着基估计量的增加而迅速提高。此外，在我的示例中，无论基础估计器是终止的树桩还是完整的树，提升集成的精度都收敛到超过估计器数量= 15+时的原始CART精度。</p><p id="4cc4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Boosting和bagging是两种能够从分类算法中挤出额外预测准确性的集成方法。使用任一方法时，应仔细调整超参数，以找到模型灵活性、效率和预测改进的最佳平衡。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/9e392ff373b4113015e0dafaa6fc304d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*w6draAbAYEkVOGhcgDvMww.png"/></div></figure><div class="mq mr gp gr ms mt"><a href="https://github.com/dasotelo/Python_Projects/blob/master/Wine_Bag_Boost.py" rel="noopener  ugc nofollow" target="_blank"><div class="mu ab fo"><div class="mv ab mw cl cj mx"><h2 class="bd ir gy z fp my fr fs mz fu fw ip bi translated">dasotelo/Wine_Bag_Boost.py</h2><div class="na l"><p class="bd b dl z fp my fr fs mz fu fw dk translated">github.com</p></div></div><div class="nb l"><div class="nc l nd ne nf nb ng ku mt"/></div></div></a></div></div></div>    
</body>
</html>