<html>
<head>
<title>Integrating TensorFlow Distributed Image Serving with the TensorFlow Object Detection API</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将 TensorFlow 分布式图像服务与 TensorFlow 对象检测 API 集成</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/integrating-tensorflow-distributed-image-serving-with-the-tensorflow-object-detection-api-5f62d80bce4c?source=collection_archive---------11-----------------------#2018-07-25">https://towardsdatascience.com/integrating-tensorflow-distributed-image-serving-with-the-tensorflow-object-detection-api-5f62d80bce4c?source=collection_archive---------11-----------------------#2018-07-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f4b5" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">通过网络为您的 TensorFlow 对象检测模型服务</h2></div><p id="f507" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这款笔记本是<a class="ae lb" href="https://medium.com/@tmlabonte/serving-image-based-deep-learning-models-with-tensorflow-servings-restful-api-d365c16a7dc4" rel="noopener">使用 TensorFlow-Serving 的 RESTful API </a>服务基于图像的深度学习模型的续集。请务必阅读该文章，以了解 TensorFlow 服务和 TensorFlow 分布式图像服务(Tendies)库的基础知识。强烈推荐克隆<a class="ae lb" href="https://github.com/tmlabonte/tendies" rel="noopener ugc nofollow" target="_blank">Tendies 库</a>来跟随本教程，因为我将关注重要的代码摘录而不是整个文件。如果你想在笔记本上查看这篇文章，点击<a class="ae lb" href="https://github.com/tmlabonte/tendies/blob/master/full_functionality/tendies-extension-tutorial.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="a943" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我们将扩展基本 Tendies 类的功能，以集成一个<a class="ae lb" href="https://arxiv.org/abs/1506.01497" rel="noopener ugc nofollow" target="_blank">更快的 R-CNN </a>深度神经网络，它使用<a class="ae lb" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank"> TensorFlow 对象检测 API </a>。这将允许我们为符合 REST 的远程推理提供更快的 R-CNN，就像上一篇文章中的 CycleGAN 一样。</p><p id="ac74" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">CycleGAN 相当简单，因为它接受图像并输出图像；然而，更快的 R-CNN 接受一个图像并输出张量的字典。此外，对象检测 API 迫使我们从 pipeline.config <em class="lc">构建我们的模型，并且</em>重新定义推理函数，使得服务更快的 R-CNN 成为更困难的任务。整合新模型和趋势的步骤如下:</p><ol class=""><li id="b1ad" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated">在 LayerInjector 中定义预处理和后处理功能。</li><li id="e468" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">在 ServerBuilder 中创建或导入模型推理函数。</li><li id="a02e" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">创建或导入客户端。</li></ol><p id="3955" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然我将使用更快的 R-CNN 进行演示，但是这些步骤对于任何任意模型都是相同的，所以请按照您的特定用例随意操作。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi lr"><img src="../Images/c208015570b362ddb7f9d123d12753be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uVrA7cShVWntCS4Xss0XVw.png"/></div></div></figure></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="e095" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">分层注射</h1><p id="1f7b" class="pw-post-body-paragraph kf kg iq kh b ki nc jr kk kl nd ju kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">每个预处理函数必须将图像位串、图像大小和*args(其中*args 可用于表示任意数量的自定义位置参数)作为参数，然后将模型输入作为张量返回。相反，每个后处理函数必须将模型输出和*args 作为参数，然后返回输出节点名称列表以及输出是否应该作为图像传输。这些输出将在导出模型时在 ServerBuilder 中使用。</p><p id="e946" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们将定义我们的预处理函数，它将把图像位串转换成适合推理的 uint8 张量。</p><pre class="ls lt lu lv gt nh ni nj nk aw nl bi"><span id="4d09" class="nm ml iq ni b gy nn no l np nq">import tensorflow as tf<br/>def bitstring_to_uint8_tensor(self, input_bytes, image_size, *args):<br/>    input_bytes = tf.reshape(input_bytes, [])</span><span id="6ce3" class="nm ml iq ni b gy nr no l np nq"># Transforms bitstring to uint8 tensor<br/>    input_tensor = tf.image.decode_png(input_bytes, channels=3)</span><span id="4693" class="nm ml iq ni b gy nr no l np nq"># Ensures tensor has correct shape<br/>    input_tensor = tf.reshape(input_tensor, [image_size, image_size, 3])</span><span id="641e" class="nm ml iq ni b gy nr no l np nq"># Expands the single tensor into a batch of 1<br/>    input_tensor = tf.expand_dims(input_tensor, 0)<br/>    return input_tensor</span></pre><p id="0515" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">符合对象检测 API 的模型返回有用张量的字典，比如 num_detections、detection _ boxes 等等。在我们的后处理函数中，我们将遍历这些张量并给它们分配名称，这样我们就可以在 ServerBuilder 中提取它们。我们还必须考虑检测类张量的 1-索引。最后，我们返回一个输出节点名称列表，并将 output_as_image 设置为 False，因为我们将通过 JSON 将输出张量(不是可视化的图像)发送回客户机。</p><pre class="ls lt lu lv gt nh ni nj nk aw nl bi"><span id="9f7b" class="nm ml iq ni b gy nn no l np nq">def object_detection_dict_to_tensor_dict(self, object_detection_tensor_dict, *args):<br/>    # Sets output to a non-image<br/>    OUTPUT_AS_IMAGE = False<br/>    # Class labels are 1-indexed<br/>    LABEL_ID_OFFSET = 1</span><span id="bdd0" class="nm ml iq ni b gy nr no l np nq">    # Assigns names to tensors and adds them to output list<br/>    output_node_names = []<br/>    for name, tensor in object_detection_tensor_dict.items():<br/>        if name == "detection_classes":<br/>            tensor += LABEL_ID_OFFSET<br/>        tensor = tf.identity(tensor, name)<br/>        output_node_names.append(name)</span><span id="d33b" class="nm ml iq ni b gy nr no l np nq">    # Returns output list and image boolean<br/>    return output_node_names, OUTPUT_AS_IMAGE</span></pre><p id="c71e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您遵循您自己的模型，可以随意使用*args 来接受您需要的任意多个参数进行处理。Tendies 对张量的形状和类型相当挑剔，所以要确保你的预处理器的输出和后处理器的输入分别等价于你的模型的输入和输出。</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="2bce" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">推理功能</h1><p id="32b9" class="pw-post-body-paragraph kf kg iq kh b ki nc jr kk kl nd ju kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">接下来，我们必须从 pipeline.config 构建更快的 R-CNN，并定义我们的推理函数。其代码在 example_usage()下的 ServerBuilder.py 中，这是我们的模型导出的地方。通过将配置文件读入对象检测 API model_builder，我们可以实例化一个更快的 R-CNN，而无需实际查看模型代码。接下来的几个单元格被认为在 example_usage()的范围内。</p><pre class="ls lt lu lv gt nh ni nj nk aw nl bi"><span id="b674" class="nm ml iq ni b gy nn no l np nq">from object_detection.protos import pipeline_pb2<br/>from object_detection.builders import model_builder<br/>from google.protobuf import text_format</span><span id="a76e" class="nm ml iq ni b gy nr no l np nq"># Builds object detection model from config file<br/>pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()<br/>with tf.gfile.GFile(config_file_path, 'r') as config:<br/>    text_format.Merge(config.read(), pipeline_config)</span><span id="4791" class="nm ml iq ni b gy nr no l np nq">detection_model = model_builder.build(pipeline_config.model, is_training=False)</span></pre><p id="ab26" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于 export_graph 期望单个推理函数，但是对象检测 API 有自己的前后处理要做，所以我们必须自己将它们组合起来。这是使用闭包的好地方，因为当我们传递推理函数时，我们希望保留实例化更快的 R-CNN 的范围。<a class="ae lb" href="https://i.imgflip.com/2en7d1.jpg" rel="noopener ugc nofollow" target="_blank">闭包是最好的</a>。</p><pre class="ls lt lu lv gt nh ni nj nk aw nl bi"><span id="c29c" class="nm ml iq ni b gy nn no l np nq"># Creates inference function, encapsulating object detection requirements<br/>def object_detection_inference(input_tensors):<br/>    # Converts uint8 inputs to float tensors<br/>    inputs = tf.to_float(input_tensors)</span><span id="d48b" class="nm ml iq ni b gy nr no l np nq">    # Object detection preprocessing<br/>    preprocessed_inputs, true_image_shapes = detection_model.preprocess(inputs)<br/>    # Object detection inference<br/>    output_tensors = detection_model.predict(preprocessed_inputs, true_image_shapes)<br/>    # Object detection postprocessing<br/>    postprocessed_tensors = detection_model.postprocess(output_tensors, true_image_shapes)<br/>    return postprocessed_tensors</span></pre><p id="9a52" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我们将实例化一个 ServerBuilder 和 LayerInjector，然后导出模型。注意，我们将推理函数、预处理器和后处理器传递给 export_graph()。</p><pre class="ls lt lu lv gt nh ni nj nk aw nl bi"><span id="3a9b" class="nm ml iq ni b gy nn no l np nq"># Instantiates a ServerBuilder<br/>server_builder = ServerBuilder()</span><span id="9a3e" class="nm ml iq ni b gy nr no l np nq"># Instantiates a LayerInjector<br/>layer_injector = LayerInjector()</span><span id="bc29" class="nm ml iq ni b gy nr no l np nq"># Exports model<br/>print("Exporting model to ProtoBuf...")<br/>output_node_names, output_as_image = server_builder.export_graph(<br/>                            object_detection_inference,<br/>                            layer_injector.bitstring_to_uint8_tensor,<br/>                            layer_injector.object_detection_dict_to_tensor_dict,<br/>                            FLAGS.model_name,<br/>                            FLAGS.model_version,<br/>                            FLAGS.checkpoint_dir,<br/>                            FLAGS.protobuf_dir,<br/>                            FLAGS.image_size)<br/>print("Wrapping ProtoBuf in SavedModel...")<br/>server_builder.build_saved_model(output_node_names,<br/>                                 output_as_image,<br/>                                 FLAGS.model_name,<br/>                                 FLAGS.model_version,<br/>                                 FLAGS.protobuf_dir,<br/>                                 FLAGS.serve_dir)<br/>print("Exported successfully!")</span></pre></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="f42d" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">客户</h1><p id="ebf8" class="pw-post-body-paragraph kf kg iq kh b ki nc jr kk kl nd ju kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">创建定制趋势客户端的最佳方式是从客户端继承，这为远程推理提供了一个框架。在这样的子类中，只需创建 visualize()和相关的 helper 函数，然后调用 client.inference()开始评估过程。</p><p id="24ca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将需要几个这样的帮助函数；第一个函数与我们的预处理函数几乎完全相同，只是没有添加批处理。</p><pre class="ls lt lu lv gt nh ni nj nk aw nl bi"><span id="10b0" class="nm ml iq ni b gy nn no l np nq">def bitstring_to_uint8_tensor(self, input_bytes):<br/>    input_bytes = tf.reshape(input_bytes, [])</span><span id="3102" class="nm ml iq ni b gy nr no l np nq">    # Transforms bitstring to uint8 tensor<br/>    input_tensor = tf.image.decode_jpeg(input_bytes, channels=3)</span><span id="f4c5" class="nm ml iq ni b gy nr no l np nq">    # Ensures tensor has correct shape<br/>    input_tensor = tf.reshape(input_tensor, [self.image_size, self.image_size, 3])<br/>    return input_tensor</span></pre><p id="d497" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的第二个助手函数将用于从提供的标签映射中的对象检测 API 创建我们的类别索引字典；这个更快的 R-CNN 的具体实现只有一个类，所以很简单:</p><pre class="ls lt lu lv gt nh ni nj nk aw nl bi"><span id="5952" class="nm ml iq ni b gy nn no l np nq">from object_detection.utils import label_map_util<br/>def get_category_index(self):<br/>    # Loads label map<br/>    label_map = label_map_util.load_labelmap(self.label_path)<br/>    <br/>    # Builds category index from label map<br/>    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=1, use_display_name=True)<br/>    category_index = label_map_util.create_category_index(categories)<br/>    return category_index</span></pre><p id="da51" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">借助我们的助手，我们的可视化功能还不算太差。我们将解码 JSON 数据并将其转换为边界框，然后在对象检测 API visualization_utils 的帮助下将它们覆盖在输入图像上。请注意，我们将输入图像转换为张量，因此我们必须。在可视化之前对其进行 eval()。</p><pre class="ls lt lu lv gt nh ni nj nk aw nl bi"><span id="7859" class="nm ml iq ni b gy nn no l np nq">from object_detection.utils import visualization_utils<br/>def visualize(self, input_image, response, i):<br/>    # Processes response for visualization<br/>    detection_boxes = response["detection_boxes"]<br/>    detection_classes = response["detection_classes"]<br/>    detection_scores = response["detection_scores"]<br/>    image = self.bitstring_to_uint8_tensor(input_image)<br/>    with tf.Session() as sess:<br/>        image = image.eval()</span><span id="a66f" class="nm ml iq ni b gy nr no l np nq">    # Overlays bounding boxes and labels on image<br/>    visualization_utils.visualize_boxes_and_labels_on_image_array(<br/>        image,<br/>        np.asarray(detection_boxes, dtype=np.float32),<br/>        np.asarray(detection_classes, dtype=np.uint8),<br/>        scores=np.asarray(detection_scores, dtype=np.float32),<br/>        category_index=self.get_category_index(),<br/>        instance_masks=None,<br/>        use_normalized_coordinates=True,<br/>        line_thickness=2)</span><span id="7f2d" class="nm ml iq ni b gy nr no l np nq">    # Saves image<br/>    output_file = self.output_dir + "/images/" + self.output_filename + str(i) + self.output_extension<br/>    visualization_utils.save_image_array_as_png(image, output_file)</span></pre></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="8c6d" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">使用服务器</h1><p id="c29b" class="pw-post-body-paragraph kf kg iq kh b ki nc jr kk kl nd ju kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">既然我们已经完成了集成更快的 R-CNN 和 Tendies，让我们运行服务器。首先，我们必须导出我们的模型:</p><p id="3d51" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe ns nt nu ni b">python serverbuilder.py --checkpoint_dir $(path) --image_size 512</code></p><p id="bef9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">截至 2018 年 7 月，Python 3 不支持 TensorFlow 服务，但<a class="ae lb" href="https://github.com/tensorflow/serving/issues/700" rel="noopener ugc nofollow" target="_blank">有人提出了解决方案</a>。安装 Python 3 TensorFlow 服务 API，包括:</p><p id="c734" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe ns nt nu ni b">pip install tensorflow-serving-api-python3</code></p><p id="7713" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们可以用下面的命令从 bash 运行这个 TensorFlow 模型服务器:</p><p id="332c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe ns nt nu ni b">tensorflow_model_server --rest_api_port=8501 --model_name=saved_model --model_base_path=$(path)</code></p><p id="7a79" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中$(path)是服务器目录的路径。在我的例子中，它是/mnt/c/Users/Tyler/Desktop/tendies/full _ functional/serve。</p><p id="2415" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我们可以通过在输入图像的文件夹上调用我们的客户端来运行远程推理:</p><p id="8ff7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><code class="fe ns nt nu ni b">python objectdetectionclient.py</code></p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="6a98" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">结论</h1><p id="c2dc" class="pw-post-body-paragraph kf kg iq kh b ki nc jr kk kl nd ju kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">感谢跟随本教程；希望对你有帮助！这个笔记本是用我的 TensorFlow 分布式图像服务库构建的，你可以在这里下载<a class="ae lb" href="https://github.com/tmlabonte/tendies" rel="noopener ugc nofollow" target="_blank"/>。更多关于我的博文和信息，请访问<a class="ae lb" href="https://tmlabonte.github.io/" rel="noopener ugc nofollow" target="_blank">我的网站</a>。</p></div></div>    
</body>
</html>