<html>
<head>
<title>A short introduction to NLP in Python with spaCy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的自然语言处理简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-short-introduction-to-nlp-in-python-with-spacy-d0aa819af3ad?source=collection_archive---------2-----------------------#2017-03-17">https://towardsdatascience.com/a-short-introduction-to-nlp-in-python-with-spacy-d0aa819af3ad?source=collection_archive---------2-----------------------#2017-03-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/03ea1c95a000bece93ce552667c38269.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r9eFin6RONqGk_JPegpi0A.jpeg"/></div></div></figure><div class=""/><p id="46df" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">自然语言处理(NLP)是数据科学最有趣的子领域之一，人们越来越期望数据科学家能够迅速找到涉及利用非结构化文本数据的解决方案。尽管如此，许多应用数据科学家(STEM和社会科学背景)缺乏NLP经验。</p><p id="a876" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这篇文章中，我将探索一些基本的NLP概念，并展示如何使用Python中越来越流行的<a class="ae kz" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank"> spaCy </a>包来实现它们。这篇文章是为绝对的NLP初学者写的，但是需要具备Python知识。</p><p id="8603" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">你说是spaCy？</p><p id="ba09" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">spaCy是Matt Honnibal在<a class="ae kz" href="https://explosion.ai/" rel="noopener ugc nofollow" target="_blank"> Explosion AI开发的“Python中的工业强度NLP”的一个相对较新的包。</a>它的设计考虑到了应用数据科学家，这意味着它不会让用户在决定使用什么深奥的算法来执行常见任务时感到沉重，而且它的速度很快。非常快(在Cython中实现)。如果你熟悉Python数据科学栈，spaCy就是你的NLP的<code class="fe la lb lc ld b">numpy</code>——它相当低级，但是非常直观和高性能。</p><p id="7c1d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">那么，它能做什么呢？</strong></p><p id="3e6b" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">spacy为任何NLP项目中常用的任务提供一站式服务，包括:</p><ul class=""><li id="37db" class="le lf je kd b ke kf ki kj km lg kq lh ku li ky lj lk ll lm bi translated">符号化</li><li id="3701" class="le lf je kd b ke ln ki lo km lp kq lq ku lr ky lj lk ll lm bi translated">引理满足</li><li id="131e" class="le lf je kd b ke ln ki lo km lp kq lq ku lr ky lj lk ll lm bi translated">词性标注</li><li id="5ccd" class="le lf je kd b ke ln ki lo km lp kq lq ku lr ky lj lk ll lm bi translated">实体识别</li><li id="5704" class="le lf je kd b ke ln ki lo km lp kq lq ku lr ky lj lk ll lm bi translated">依存句法分析</li><li id="55ab" class="le lf je kd b ke ln ki lo km lp kq lq ku lr ky lj lk ll lm bi translated">句子识别</li><li id="745e" class="le lf je kd b ke ln ki lo km lp kq lq ku lr ky lj lk ll lm bi translated">单词到向量的转换</li><li id="a510" class="le lf je kd b ke ln ki lo km lp kq lq ku lr ky lj lk ll lm bi translated">许多方便的方法来清理和规范文本</li></ul><p id="80e4" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我将提供其中一些特性的高级概述，并展示如何使用spaCy访问它们。</p><p id="177e" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">我们开始吧！</strong></p><p id="c28e" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">首先，我们加载spaCy的管道，按照惯例，它存储在一个名为<code class="fe la lb lc ld b">nlp</code>的变量中。声明这个变量需要几秒钟的时间，因为spaCy会预先加载它的模型和数据，以便以后节省时间。实际上，这很早就完成了一些繁重的工作，这样就不会在每次对数据应用<code class="fe la lb lc ld b">nlp</code>解析器时产生成本。请注意，这里我使用的是英语语言模型，但也有一个全功能的德语模型，跨几种语言实现了标记化(下面讨论)。</p><p id="e20f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们对样本文本调用nlp来创建一个<code class="fe la lb lc ld b">Doc</code>对象。<code class="fe la lb lc ld b">Doc</code>对象现在是文本本身、文本片段(<code class="fe la lb lc ld b">Span</code>对象)和文本元素(<code class="fe la lb lc ld b">Token</code>对象)的NLP任务的容器。值得注意的是，<code class="fe la lb lc ld b">Token</code>和<code class="fe la lb lc ld b">Span</code>对象实际上没有数据。相反，它们包含指向包含在<code class="fe la lb lc ld b">Doc</code>对象中的数据的指针，并且被延迟评估(即，根据请求)。spaCy的许多核心功能都是通过对<code class="fe la lb lc ld b">Doc</code> (n=33)、<code class="fe la lb lc ld b">Span</code> (n=29)和<code class="fe la lb lc ld b">Token</code> (n=78)对象的方法来访问的。</p><pre class="ls lt lu lv gt lw ld lx ly aw lz bi"><span id="9a84" class="ma mb je ld b gy mc md l me mf">In[1]: import spacy <br/>...: nlp = spacy.load("en") <br/>...: doc = nlp("The big grey dog ate all of the chocolate, but fortunately he wasn't sick!")</span></pre><p id="d6b1" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">标记化</strong></p><p id="c48f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">标记化是许多NLP任务中的基础步骤。将文本标记化是将一段文本拆分成单词、符号、标点、空格和其他元素，从而创建“标记”的过程。一种简单的方法是在空格处拆分字符串:</p><pre class="ls lt lu lv gt lw ld lx ly aw lz bi"><span id="3d03" class="ma mb je ld b gy mc md l me mf">In[2]: doc.text.split() <br/>...: Out[2]: ['The', 'big', 'grey', 'dog', 'ate', 'all', 'of', 'the', 'chocolate,', 'but', 'fortunately', 'he', "wasn't", 'sick!']</span></pre><p id="604a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">表面上，这看起来很好。但是，注意<code class="fe la lb lc ld b">a)</code>它忽略了标点符号，<code class="fe la lb lc ld b">b)</code>它没有拆分动词和副词(“was”、“n t”)。换句话说，它是幼稚的，它无法识别文本中帮助我们(和机器)理解其结构和意义的元素。让我们看看SpaCy是如何处理的:</p><pre class="ls lt lu lv gt lw ld lx ly aw lz bi"><span id="2191" class="ma mb je ld b gy mc md l me mf">In[3]: [token.orth_ for token in doc] <br/>...: Out[3]: ['The', 'big', 'grey', 'dog', 'ate', 'all', 'of', 'the', 'chocolate', ',', 'but', 'fortunately', 'he', 'was', "n't", ' ', 'sick', '!']</span></pre><p id="5f17" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这里我们访问each token的<code class="fe la lb lc ld b">.orth_</code>方法，该方法返回token的字符串表示而不是SpaCy token对象，这可能并不总是可取的，但值得注意。SpaCy识别标点符号，并能够将这些标点符号从单词符号中分离出来。SpaCy许多标记方法提供了处理文本的字符串和整数表示——带下划线后缀的方法返回字符串，不带下划线后缀的方法返回整数。例如:</p><pre class="ls lt lu lv gt lw ld lx ly aw lz bi"><span id="96c7" class="ma mb je ld b gy mc md l me mf">In[4]: [(token, token.orth_, token.orth) for token in doc] <br/>...: Out[4]: [<br/>(The, 'The', 517), <br/>(big, 'big', 742), <br/>(grey, 'grey', 4623), <br/>(dog, 'dog', 1175), <br/>(ate, 'ate', 3469), <br/>(all, 'all', 516), <br/>(of, 'of', 471), <br/>(the, 'the', 466), <br/>(chocolate, 'chocolate', 3593), <br/>(,, ',', 416), <br/>(but, 'but', 494), <br/>(fortunately, 'fortunately', 15520),<br/> (he, 'he', 514),<br/> (was, 'was', 491),<br/> (n't, "n't", 479),<br/> ( , ' ', 483), <br/>(sick, 'sick', 1698), <br/>(!, '!', 495)]</span></pre><p id="ff39" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这里，我们在一个元组列表中返回SpaCy令牌、令牌的字符串表示和令牌的整数表示。</p><p id="190f" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果您希望避免返回标点符号或空白符号，SpaCy为此提供了便利方法(以及许多其他常见的文本清理任务)—例如，要删除停用词，您可以调用<code class="fe la lb lc ld b">.is_stop</code>方法。</p><pre class="ls lt lu lv gt lw ld lx ly aw lz bi"><span id="832d" class="ma mb je ld b gy mc md l me mf">In[5]: [token.orth_ for token in doc if not token.is_punct | token.is_space] <br/>...: Out[5]: ['The', 'big', 'grey', 'dog', 'ate', 'all', 'of', 'the', 'chocolate', 'but', 'fortunately', 'he', 'was', "n't", 'sick']</span></pre><p id="306a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">很酷，对吧？</p><p id="50ed" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">词汇化</strong></p><p id="e2af" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">与记号化相关的一个任务是引理满足。引理满足是将一个词简化为其基本形式的过程，如果你愿意，可以称之为其母词。一个词的不同用法往往有相同的词根意义。例如，<code class="fe la lb lc ld b">practice, practised and practising</code>本质上都是指同一个东西。人们常常希望将词义与其基本形式相似的词标准化。通过SpaCy，我们可以用一个令牌的<code class="fe la lb lc ld b">.lemma_</code>方法访问每个单词的基本形式:</p><pre class="ls lt lu lv gt lw ld lx ly aw lz bi"><span id="d747" class="ma mb je ld b gy mc md l me mf">In[6]: practice = "practice practiced practicing" <br/>...: nlp_practice = nlp(practice) <br/>...: [word.lemma_ for word in nlp_practice] <br/>...: Out[6]: ['practice', 'practice', 'practice']</span></pre><p id="8591" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这为什么有用？一个直接的用例是机器学习，特别是文本分类。例如，在创建“单词包”之前对文本进行词条匹配可以避免单词重复，因此，允许模型建立跨多个文档的单词使用模式的更清晰的图像。</p><p id="da40" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">位置标记</strong></p><p id="73f0" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">词性标注是分配语法属性(如名词、动词、副词、形容词等)的过程。)到话。共享相同POS标签的单词倾向于遵循相似的句法结构，并且在基于规则的过程中是有用的。</p><p id="01e9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">例如，在一个事件的给定描述中，我们可能希望确定谁拥有什么。通过利用所有格，我们可以做到这一点(前提是文本语法正确！).SpaCy使用了流行的Penn Treebank POS标签，参见<a class="ae kz" href="https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html" rel="noopener ugc nofollow" target="_blank">https://www . ling . upenn . edu/courses/Fall _ 2003/ling 001/Penn _ tree bank _ POS . html</a>。使用SpaCy，您可以分别使用<code class="fe la lb lc ld b">.pos_</code>和<code class="fe la lb lc ld b">.tag_</code>方法访问粗粒度和细粒度的POS标签。在这里，我访问细粒度的POS标记:</p><pre class="ls lt lu lv gt lw ld lx ly aw lz bi"><span id="a227" class="ma mb je ld b gy mc md l me mf">In[7]: doc2 = nlp("Conor's dog's toy was hidden under the man's sofa in the woman's house") <br/>...: <br/>pos_tags = [(i, i.tag_) for i in doc2] ...: <br/>pos_tags <br/>...: Out[7]: [(Conor, 'NNP'), ('s, 'POS'), (dog, 'NN'), ('s, 'POS'), (toy, 'NN'), (was, 'VBD'), (hidden, 'VBN'), (under, 'IN'), (the, 'DT'), (man, 'NN'), ('s, 'POS'), (sofa, 'NN'), (in, 'IN'), (the, 'DT'), (woman, 'NN'), ('s, 'POS'), (house, 'NN')]</span></pre><p id="2eb7" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以看到“<code class="fe la lb lc ld b">’s</code>令牌被标记为<code class="fe la lb lc ld b">POS</code>。我们可以利用这个标签来提取所有者和他们所拥有的东西:</p><pre class="ls lt lu lv gt lw ld lx ly aw lz bi"><span id="3399" class="ma mb je ld b gy mc md l me mf">In[8]: owners_possessions = [] <br/>...: for i in pos_tags: <br/>    ...: if i[1] == "POS": ...: owner = i[0].nbor(-1) <br/>...:         possession = i[0].nbor(1) <br/>...:         owners_possessions.append((owner, possession)) ...: ...:         owners_possessions <br/>...: Out[8]: [(Conor, dog), (dog, toy), (man, sofa), (woman, house)]</span></pre><p id="f5bd" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这将返回所有者拥有元组的列表。如果你想在这方面表现得更好，你可以在一个清单comprehenion中这样做(我认为这样更好！):</p><pre class="ls lt lu lv gt lw ld lx ly aw lz bi"><span id="7107" class="ma mb je ld b gy mc md l me mf">In[9]: [(i[0].nbor(-1), i[0].nbor(+1)) for i in pos_tags if i[1] == "POS"] <br/>...: Out[9]: [(Conor, dog), (dog, toy), (man, sofa), (woman, house)]</span></pre><p id="2cc4" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这里我们使用每个令牌的<code class="fe la lb lc ld b">.nbor</code>方法，它返回一个令牌的相邻令牌。</p><p id="524d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd jf">实体识别</strong></p><p id="75bd" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">实体识别是将在文本中发现的命名实体分类到预定义的类别中的过程，例如人、地点、组织、日期等。spaCy使用一种统计模型来对广泛的实体进行分类，包括人、事件、艺术品和国籍/宗教(完整列表请参见文档<a class="ae kz" href="https://spacy.io/docs/usage/entity-recognition)." rel="noopener ugc nofollow" target="_blank">https://spaCy . io/docs/usage/entity-recognition)。</a></p><p id="ba99" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">例如，让我们从巴拉克·奥巴马的维基百科条目中选取前两句话。我们将解析这个文本，然后使用<code class="fe la lb lc ld b">Doc</code>对象的<code class="fe la lb lc ld b">.ents</code>方法访问标识的实体。通过在<code class="fe la lb lc ld b">Doc</code>上调用这个方法，我们可以访问额外的<code class="fe la lb lc ld b">Token</code>方法，特别是<code class="fe la lb lc ld b">.label_</code>和<code class="fe la lb lc ld b">.label</code>:</p><pre class="ls lt lu lv gt lw ld lx ly aw lz bi"><span id="b218" class="ma mb je ld b gy mc md l me mf">In[10]: wiki_obama = """Barack Obama is an American politician who served as ...: the 44th President of the United States from 2009 to 2017. He is the first ...: African American to have served as president, ...: as well as the first born outside the contiguous United States.""" <br/>...: <br/>...: nlp_obama = nlp(wiki_obama) ...: [(i, i.label_, i.label) for i in nlp_obama.ents] <br/>...: Out[10]: [(Barack Obama, 'PERSON', 346), (American, 'NORP', 347), (the United States, 'GPE', 350), (2009 to 2017, 'DATE', 356), (first, 'ORDINAL', 361), (African, 'NORP', 347), (American, 'NORP', 347), (first, 'ORDINAL', 361), (United States, 'GPE', 350)]</span></pre><p id="b1a9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">您可以看到模型已经识别的实体，以及它们有多准确(在本例中)。人是不言自明的，NORP是国家或宗教团体，GPE识别地点(城市，国家等)。)，DATE表示特定的日期或日期范围，ORDINAL表示代表某种顺序的单词或数字。</p><p id="eab6" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在我们讨论<code class="fe la lb lc ld b">Doc</code>方法的时候，有必要提一下spaCy的句子标识符。在NLP任务中，想要将文档分割成句子并不罕见。通过访问一个<code class="fe la lb lc ld b">Doc's</code> <code class="fe la lb lc ld b">.sents</code>方法，使用SpaCy很容易做到这一点:</p><pre class="ls lt lu lv gt lw ld lx ly aw lz bi"><span id="40b0" class="ma mb je ld b gy mc md l me mf">In[11]: for ix, sent in enumerate(nlp_obama.sents, 1): <br/>...: print("Sentence number {}: {}".format(ix, sent)) <br/>...: <br/>Sentence number 1: Barack Obama is an American politician who served as the 44th President of the United States from 2009 to 2017. Sentence number 2: He is the first African American to have served as president, as well as the first born outside the contiguous United States.</span></pre></div><div class="ab cl mg mh hx mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="im in io ip iq"><p id="11b9" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="mn">原载于2017年3月17日dataflume.wordpress.com</em><a class="ae kz" href="https://dataflume.wordpress.com/2017/03/17/intro-nlp-python-spacy/" rel="noopener ugc nofollow" target="_blank"><em class="mn"/></a><em class="mn">。</em></p></div></div>    
</body>
</html>