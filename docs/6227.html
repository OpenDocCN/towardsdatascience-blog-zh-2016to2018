<html>
<head>
<title>Facebook’s Open-Source Reinforcement Learning Platform — A Deep Dive</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">脸书的开源强化学习平台——深度探索</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/facebooks-open-source-reinforcement-learning-platform-a-deep-dive-313a3d9d528?source=collection_archive---------13-----------------------#2018-12-02">https://towardsdatascience.com/facebooks-open-source-reinforcement-learning-platform-a-deep-dive-313a3d9d528?source=collection_archive---------13-----------------------#2018-12-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/c3aec6f9f48a5dd7c2106875834c8b00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bk5BVUcrwHyp5QTR.png"/></div></div></figure><p id="3f94" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">脸书决定开源他们创建的平台，以解决他们正在研究的规模的端到端强化学习问题。所以我当然要试试这个。)让我们一起来看看他们是如何安装的，以及您自己应该做些什么来让它工作。</p><blockquote class="kw kx ky"><p id="2b88" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><em class="iq">我开始创建一个全新的 Ubuntu 18.10 安装</em></p><p id="7126" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><em class="iq">还测试并验证了在 Linux 的 Windows 子系统上工作</em></p></blockquote><h1 id="1f62" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">安装 Anaconda</h1><p id="7c7d" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">让我们从安装 Anaconda 开始，这很容易通过导航到位于<a class="ae mg" href="https://conda.io/docs/user-guide/install/index.html" rel="noopener ugc nofollow" target="_blank">https://conda.io/docs/user-guide/install/index.html</a>的文档来完成，然后我们可以找到到 Linux 安装程序<a class="ae mg" href="https://www.anaconda.com/download/#linux" rel="noopener ugc nofollow" target="_blank">https://www.anaconda.com/download/#linux</a>的链接，这将为我们提供安装程序脚本:<a class="ae mg" href="https://repo.anaconda.com/archive/Anaconda3-5.3.0-Linux-x86_64.sh." rel="noopener ugc nofollow" target="_blank">https://repo . Anaconda . com/archive/Anaconda 3-5 . 3 . 0-Linux-x86 _ 64 . sh .</a></p><p id="82b2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们可以通过运行以下命令来下载并运行它:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="640c" class="mq le iq mm b gy mr ms l mt mu">curl https://repo.anaconda.com/archive/Anaconda3-5.3.0-Linux-x86_64.sh -o conda.sh<br/>bash conda.sh</span></pre><p id="ee4b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然后按照安装程序的步骤安装 Anaconda</p><p id="cb93" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">完成后，通过以下方式将 conda 安装添加到您的<code class="fe mv mw mx mm b">PATH</code>变量:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="a0c2" class="mq le iq mm b gy mr ms l mt mu">echo 'export PATH="$PATH":/home/&lt;YOUR_USER&gt;/anaconda3/bin' &gt;&gt; ~/.bashrc<br/>. ~/.bashrc</span></pre><blockquote class="kw kx ky"><p id="5d55" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><em class="iq">注意:对于 Python 3 版本</em>，anaconda 的默认安装是/home/ubuntu/anaconda3</p></blockquote><h1 id="55bd" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">为我们的 Horizon 安装配置 Anaconda</h1><p id="de33" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">脸书地平线需要几个特定软件的通道，我们可以很容易地将它们添加到 anaconda 中:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="dd80" class="mq le iq mm b gy mr ms l mt mu">conda config --add channels conda-forge # ONNX/tensorboardX<br/>conda config --add channels pytorch</span></pre><h1 id="6a82" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">安装 Horizon</h1><blockquote class="kw kx ky"><p id="dbeb" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><em class="iq">要深入了解如何安装 Horizon，请查看 Git repo:</em><a class="ae mg" href="https://github.com/facebookresearch/Horizon/blob/master/docs/installation.md" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://github . com/Facebook research/Horizon/blob/master/docs/installation . MD</em></a></p></blockquote><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="3fc3" class="mq le iq mm b gy mr ms l mt mu">git clone https://github.com/facebookresearch/Horizon.git<br/>cd Horizon/<br/>conda install `cat docker/requirements.txt` # wait till it solved the environment, then select y<br/>source activate base # Activate the base conda environment</span><span id="636c" class="mq le iq mm b gy my ms l mt mu">pip install onnx # Install ONNX<br/>export JAVA_HOME="$(dirname $(dirname -- `which conda`))" # Set JAVA_HOME to anaconda installation<br/>cd # Go back to root</span><span id="e60f" class="mq le iq mm b gy my ms l mt mu"># Install Spark 2.3.1<br/>wget http://www-eu.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz<br/>tar -xzf spark-2.3.1-bin-hadoop2.7.tgz<br/>sudo mv spark-2.3.1-bin-hadoop2.7 /usr/local/spark</span><span id="561c" class="mq le iq mm b gy my ms l mt mu">export PATH=$PATH:/usr/local/spark/bin # add to PATH so we can find spark-submit</span><span id="b08b" class="mq le iq mm b gy my ms l mt mu"># Install OpenAI Gym<br/>pip install "gym[classic_control,box2d,atari]"</span><span id="afff" class="mq le iq mm b gy my ms l mt mu"># Build Thrift Classes<br/>cd Horizon/<br/>thrift --gen py --out . ml/rl/thrift/core.thrift</span><span id="938d" class="mq le iq mm b gy my ms l mt mu"># Build Horizon<br/>pip install -e . # we use "-e" for "ephemral package" which will instantly reflect changes in the package</span></pre><h1 id="6266" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">地平线(全球概览)</h1><h1 id="2ece" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">介绍</h1><p id="8d6b" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">Horizon 是一个端到端平台，其中<em class="kz">“包括模拟环境的工作流，以及用于预处理、培训和导出生产模型的分布式平台。”</em>——<a class="ae mg" href="https://code.fb.com/ml-applications/horizon/" rel="noopener ugc nofollow" target="_blank">(消息来源)</a></p><p id="2e6d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从阅读<a class="ae mg" href="https://research.fb.com/wp-content/uploads/2018/10/Horizon-Facebooks-Open-Source-Applied-Reinforcement-Learning-Platform.pdf" rel="noopener ugc nofollow" target="_blank">文件</a>中，我们可以了解到该平台是基于以下考虑而创建的:</p><ul class=""><li id="803a" class="mz na iq ka b kb kc kf kg kj nb kn nc kr nd kv ne nf ng nh bi translated">高效处理大型数据集的能力</li><li id="a95e" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv ne nf ng nh bi translated">能够自动高效地预处理数据</li><li id="e9e5" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv ne nf ng nh bi translated">竞争算法性能</li><li id="c0a2" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv ne nf ng nh bi translated">发布前的算法性能评估</li><li id="bec7" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv ne nf ng nh bi translated">服务于生产的柔性模型</li><li id="5e9f" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv ne nf ng nh bi translated">平台可靠性</li></ul><p id="125a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这听起来对我来说太棒了，所以让我们从如何利用这个平台开始，然后我们可以更深入地了解它的工作原理。</p><blockquote class="kw kx ky"><p id="33bb" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><em class="iq">对于强化学习中用到的一些术语，可以随时查看我之前的</em> <a class="ae mg" href="https://xaviergeerinck.com/rl-overview-terminology" rel="noopener ugc nofollow" target="_blank"> <em class="iq">博文</em> </a> <em class="iq">了解一下。</em></p></blockquote><h1 id="ab0c" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">入门指南</h1><p id="5192" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">开始使用 Horizon 就像检查他们编写的<a class="ae mg" href="https://github.com/facebookresearch/Horizon/blob/master/docs/usage.md" rel="noopener ugc nofollow" target="_blank">用法</a>文档一样简单。这包括以下步骤</p><ol class=""><li id="72ef" class="mz na iq ka b kb kc kf kg kj nb kn nc kr nd kv nn nf ng nh bi translated">创建培训数据</li><li id="3efc" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv nn nf ng nh bi translated">将数据转换为时间线格式</li><li id="3f69" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv nn nf ng nh bi translated">创建标准化参数</li><li id="e480" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv nn nf ng nh bi translated">训练模型</li><li id="c238" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv nn nf ng nh bi translated">评估模型</li></ol><h1 id="2cd9" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">地平线—批量 RL(深潜)</h1><p id="e07d" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">现在，我们知道了 Horizon 平台的总体概念，让我们按照使用文档中所写的那样运行不同的步骤，并深入了解它们，发现幕后发生的事情。让我们从创建训练数据开始。</p><h1 id="1661" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">1.创建培训数据</h1><p id="80bb" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">我们的使用文档列出了我们应该通过以下命令创建训练数据:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="a240" class="mq le iq mm b gy mr ms l mt mu"># Create a directory where we will put the training data<br/>mkdir cartpole_discrete</span><span id="0fba" class="mq le iq mm b gy my ms l mt mu"># Generate training data<br/>python ml/rl/test/gym/run_gym.py -p ml/rl/test/gym/discrete_dqn_cartpole_v0_100_eps.json -f cartpole_discrete/training_data.json</span></pre><p id="f5c1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但是这实际上是做什么的呢？打开位于<code class="fe mv mw mx mm b">ml/rl/test/gym/</code>中的<code class="fe mv mw mx mm b">run_gym.py</code>文件，在<code class="fe mv mw mx mm b">main()</code>方法中向我们展示了以下内容:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="5a6c" class="mq le iq mm b gy mr ms l mt mu">def main(args):<br/>    parser = argparse.ArgumentParser(<br/>        description="Train a RL net to play in an OpenAI Gym environment."<br/>    )<br/>    parser.add_argument("-p", "--parameters", help="Path to JSON parameters file.")</span></pre><p id="1fa4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这向我们展示了当运行命令<code class="fe mv mw mx mm b">python ml/rl/test/gym/run_gym.py</code>时，我们能够在控制台中看到我们的脚本的使用情况，运行该命令会导致:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="15fb" class="mq le iq mm b gy mr ms l mt mu">Traceback (most recent call last):<br/>  File "ml/rl/test/gym/run_gym.py", line 611, in &lt;module&gt;<br/>    + " [-s &lt;score_bar&gt;] [-g &lt;gpu_id&gt;] [-l &lt;log_level&gt;] [-f &lt;filename&gt;]"<br/>Exception: Usage: python run_gym.py -p &lt;parameters_file&gt; [-s &lt;score_bar&gt;] [-g &lt;gpu_id&gt;] [-l &lt;log_level&gt;] [-f &lt;filename&gt;]</span></pre><p id="2fe4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">向我们解释，如果我们给出由我们的<code class="fe mv mw mx mm b">-p</code>参数定义的参数文件，它将加载这个 JSON 文件并将其加载到一个名为<code class="fe mv mw mx mm b">params</code>的变量中，而如果我们添加<code class="fe mv mw mx mm b">-f</code>参数，我们将能够将收集的样本作为一个 RLDataSet 保存到提供的文件中。</p><h2 id="6793" class="mq le iq bd lf no np dn lj nq nr dp ln kj ns nt lr kn nu nv lv kr nw nx lz ny bi translated">main()方法</h2><p id="4485" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">main 方法现在将继续做几件事情:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="3631" class="mq le iq mm b gy mr ms l mt mu"># Load our parameters from the json<br/>with open(args.parameters, "r") as f:<br/>    params = json.load(f)</span><span id="38f3" class="mq le iq mm b gy my ms l mt mu"># Initialize a dataset variable of type `RLDataset` if the `file_path` parameter is set<br/>#    `file_path`: If set, save all collected samples as an RLDataset to this file.<br/>dataset = RLDataset(args.file_path) if args.file_path else None</span><span id="777f" class="mq le iq mm b gy my ms l mt mu"># Call the method `run_gym` with the parameters and arguments provided<br/>reward_history, timestep_history, trainer, predictor = run_gym(<br/>    params, args.score_bar, args.gpu_id, dataset, args.start_saving_from_episode<br/>)</span><span id="e2bb" class="mq le iq mm b gy my ms l mt mu"># Save our dataset if provided through the -f parameter<br/>if dataset:<br/>    dataset.save()</span><span id="be37" class="mq le iq mm b gy my ms l mt mu">#  Save the results to a csv if the `results_file_path` parameter is set<br/>if args.results_file_path:<br/>    write_lists_to_csv(args.results_file_path, reward_history, timestep_history)</span><span id="18bb" class="mq le iq mm b gy my ms l mt mu"># Return our reward history<br/>return reward_history</span></pre><p id="0fe4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">运行使用文档<code class="fe mv mw mx mm b">python ml/rl/test/gym/run_gym.py -p ml/rl/test/gym/discrete_dqn_cartpole_v0_100_eps.json -f cartpole_discrete/training_data.json</code>中显示的命令后，我们可以在由<code class="fe mv mw mx mm b">-f</code>参数定义的<code class="fe mv mw mx mm b">training_data.json</code>文件中看到以下结构。</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="f0df" class="mq le iq mm b gy mr ms l mt mu">{<br/>    "ds": "2019-01-01",<br/>    "mdp_id": "0",<br/>    "sequence_number": 10,<br/>    "state_features": {<br/>        "0": -0.032091656679586175,<br/>        "1": -0.016310561477682117,<br/>        "2": -0.01312794549150956,<br/>        "3": -0.04438365281404494<br/>    },<br/>    "action": "1",<br/>    "reward": 1.0,<br/>    "action_probability": 1.0,<br/>    "possible_actions": [<br/>        "0",<br/>        "1"<br/>    ],<br/>    "metrics": {<br/>        "reward": 1.0<br/>    }<br/>}</span></pre><h2 id="aa0c" class="mq le iq bd lf no np dn lj nq nr dp ln kj ns nt lr kn nu nv lv kr nw nx lz ny bi translated">RLDataset 类</h2><p id="5b27" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">这是由<code class="fe mv mw mx mm b">-f</code>参数生成的，它将以<code class="fe mv mw mx mm b">RLDataset</code>类提供的格式将结果保存到提供的文件中。检查位于<code class="fe mv mw mx mm b">ml/rl/training/rl_dataset.py</code>的这个类向我们显示:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="65e1" class="mq le iq mm b gy mr ms l mt mu">"""<br/>Holds a collection of RL samples in the "pre-timeline" format.</span><span id="7e58" class="mq le iq mm b gy my ms l mt mu">:param file_path: String Load/save the dataset from/to this file.<br/>"""</span><span id="0f11" class="mq le iq mm b gy my ms l mt mu"># === LINES REMOVED ===</span><span id="42c6" class="mq le iq mm b gy my ms l mt mu">self.rows.append(<br/>{<br/>    "ds": "2019-01-01",  # Fix ds for simplicity in open source examples<br/>    "mdp_id": str(mdp_id),<br/>    "sequence_number": int(sequence_number),<br/>    "state_features": state_features,<br/>    "action": action,<br/>    "reward": reward,<br/>    "action_probability": action_probability,<br/>    "possible_actions": possible_actions,<br/>    "metrics": {"reward": reward},<br/>}</span></pre><h2 id="855c" class="mq le iq bd lf no np dn lj nq nr dp ln kj ns nt lr kn nu nv lv kr nw nx lz ny bi translated">run_gym()方法</h2><p id="b01e" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">现在我们可以看到这些行被创建并保存在内存中的<code class="fe mv mw mx mm b">RLDataset</code>类中。但是实际上是什么在使用它并填充它呢？让我们先来看看我们的<code class="fe mv mw mx mm b">run_gym()</code>方法的总体情况:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="3772" class="mq le iq mm b gy mr ms l mt mu">env_type = params["env"]</span><span id="8933" class="mq le iq mm b gy my ms l mt mu"># Initialize the OpenAI Gym Environment<br/>env = OpenAIGymEnvironment(<br/>    env_type,<br/>    rl_parameters.epsilon,<br/>    rl_parameters.softmax_policy,<br/>    rl_parameters.gamma,<br/>)<br/>replay_buffer = OpenAIGymMemoryPool(params["max_replay_memory_size"])<br/>model_type = params["model_type"]</span><span id="17ce" class="mq le iq mm b gy my ms l mt mu">use_gpu = gpu_id != USE_CPU</span><span id="b15c" class="mq le iq mm b gy my ms l mt mu"># Use the "training" {} parameters and "model_type": "&lt;MODEL&gt;" model_type<br/># to create a trainer as the ones listed in /ml/rl/training/*_trainer.py<br/># The model_type is defined in /ml/rl/test/gym/open_ai_gym_environment.py<br/>trainer = create_trainer(params["model_type"], params, rl_parameters, use_gpu, env)</span><span id="4d8f" class="mq le iq mm b gy my ms l mt mu"># Create a GymDQNPredictor based on the ModelType and Trainer above<br/># This is located in /ml/rl/test/gym/gym_predictor.py<br/>predictor = create_predictor(trainer, model_type, use_gpu)</span><span id="5ae2" class="mq le iq mm b gy my ms l mt mu">c2_device = core.DeviceOption(<br/>    caffe2_pb2.CUDA if use_gpu else caffe2_pb2.CPU, int(gpu_id)<br/>)</span><span id="b0c3" class="mq le iq mm b gy my ms l mt mu"># Train using SGD (stochastic gradient descent)<br/># This just passess the parameters given towards a method called train_gym_online_rl which will train our algorithm<br/>return train_sgd(<br/>    c2_device,<br/>    env,<br/>    replay_buffer,<br/>    model_type,<br/>    trainer,<br/>    predictor,<br/>    "{} test run".format(env_type),<br/>    score_bar,<br/>    **params["run_details"],<br/>    save_timesteps_to_dataset=save_timesteps_to_dataset,<br/>    start_saving_from_episode=start_saving_from_episode,<br/>)</span></pre><p id="e46a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><code class="fe mv mw mx mm b">run_gym</code>方法似乎在使用我们从 JSON 文件中加载的参数来初始化 OpenAI Gym 环境。因此，让我们打开一个 JSON 文件，运行一个快速的<code class="fe mv mw mx mm b">cat ml/rl/test/gym/discrete_dqn_cartpole_v0_100_eps.json</code>向我们展示:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="f2b5" class="mq le iq mm b gy mr ms l mt mu">{<br/>  "env": "CartPole-v0",<br/>  "model_type": "pytorch_discrete_dqn",<br/>  "max_replay_memory_size": 10000,<br/>  "use_gpu": false,<br/>  "rl": {<br/>    "gamma": 0.99,<br/>    "target_update_rate": 0.2,<br/>    "reward_burnin": 1,<br/>    "maxq_learning": 1,<br/>    "epsilon": 1,<br/>    "temperature": 0.35,<br/>    "softmax_policy": 0<br/>  },<br/>  "rainbow": {<br/>    "double_q_learning": false,<br/>    "dueling_architecture": false<br/>  },<br/>  "training": {<br/>    "layers": [<br/>      -1,<br/>      128,<br/>      64,<br/>      -1<br/>    ],<br/>    "activations": [<br/>      "relu",<br/>      "relu",<br/>      "linear"<br/>    ],<br/>    "minibatch_size": 64,<br/>    "learning_rate": 0.001,<br/>    "optimizer": "ADAM",<br/>    "lr_decay": 0.999,<br/>    "use_noisy_linear_layers": false<br/>  },<br/>  "run_details": {<br/>    "num_episodes": 100,<br/>    "max_steps": 200,<br/>    "train_every_ts": 1,<br/>    "train_after_ts": 1,<br/>    "test_every_ts": 2000,<br/>    "test_after_ts": 1,<br/>    "num_train_batches": 1,<br/>    "avg_over_num_episodes": 100<br/>  }<br/>}</span></pre><p id="bab1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">其中显示了<code class="fe mv mw mx mm b">Environment</code>、<code class="fe mv mw mx mm b">Epsilon</code>、<code class="fe mv mw mx mm b">Softmax Policy</code>和<code class="fe mv mw mx mm b">Gamma parameters</code>都用于启动<code class="fe mv mw mx mm b">OpenAIGymEnvironment</code>，其余参数传递给训练器。接下来，<code class="fe mv mw mx mm b">run_gym</code>方法还将初始化一个 replay_buffer，创建训练器和预测器。此后它将运行<code class="fe mv mw mx mm b">train_sgd</code>方法。</p><p id="b4c6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">既然我们现在知道了我们的<code class="fe mv mw mx mm b">run_gym()</code>方法，让我们进一步看看我们的<code class="fe mv mw mx mm b">dataset</code>变量是如何进一步传递的:</p><ul class=""><li id="579d" class="mz na iq ka b kb kc kf kg kj nb kn nc kr nd kv ne nf ng nh bi translated"><code class="fe mv mw mx mm b">run_gym()</code>将获取由<code class="fe mv mw mx mm b">main()</code>方法传递的方法作为<code class="fe mv mw mx mm b">save_timesteps_to_dataset</code>参数</li><li id="3253" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv ne nf ng nh bi translated"><code class="fe mv mw mx mm b">run_gym()</code>将把它传递给<code class="fe mv mw mx mm b">train_sgd()</code>方法</li><li id="0ffc" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv ne nf ng nh bi translated"><code class="fe mv mw mx mm b">train_sgd()</code>将它传递给<code class="fe mv mw mx mm b">train_gym_online_rl()</code>方法。</li></ul><h2 id="be13" class="mq le iq bd lf no np dn lj nq nr dp ln kj ns nt lr kn nu nv lv kr nw nx lz ny bi translated">train_gym_online_rl()方法</h2><p id="7f18" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">现在定义了这个参数后，<code class="fe mv mw mx mm b">train_gym_online_rl()</code>方法将通过<code class="fe mv mw mx mm b">RLDataset</code>类中定义的<code class="fe mv mw mx mm b">insert()</code>方法保存几个变量:</p><blockquote class="kw kx ky"><p id="c186" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><em class="iq">记住</em> <code class="fe mv mw mx mm b"><em class="iq">RLDataset</em></code> <em class="iq">类是在文件中定义的:</em><code class="fe mv mw mx mm b"><em class="iq">ml/rl/training/rl_dataset.py</em></code><em class="iq"/><code class="fe mv mw mx mm b"><em class="iq">insert</em></code><em class="iq">方法定义为:</em> <code class="fe mv mw mx mm b"><em class="iq">RLDataset::insert(mdp_id, sequence_number, state, action, reward, terminal, possible_actions, time_diff, action_probability)</em></code></p></blockquote><p id="b212" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">来源:<a class="ae mg" href="https://github.com/facebookresearch/Horizon/blob/bbea36948bd409f03ec449be4539bd6bd9006418/ml/rl/test/gym/run_gym.py#L208" rel="noopener ugc nofollow" target="_blank"> run_gym.py#L208 </a></p><p id="b957" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">来源变量来自<code class="fe mv mw mx mm b">run_gym.py</code>输出变量类型描述 i mdp_id <code class="fe mv mw mx mm b">string</code>情节(例如游戏的整个播放过程)的唯一 ID EP _ time steps-1 sequence _ number<code class="fe mv mw mx mm b">integer</code>定义 mdp(例如事件的时间戳)状态中状态的排序。action_to_log 动作<code class="fe mv mw mx mm b">string</code>选择的动作名称奖励奖励<code class="fe mv mw mx mm b">float</code>此状态下的奖励/动作终端终端<code class="fe mv mw mx mm b">bool</code>未使用可能的动作可能的动作<code class="fe mv mw mx mm b">list&lt;string&gt;</code>此状态下所有可能的动作列表。请注意，所采取的行动必须出现在此列表中。1.0 action_probability <code class="fe mv mw mx mm b">float</code>如果策略是随机的，则采取此操作的概率，否则为空。请注意，我们强烈鼓励使用随机策略，而不是在每个时间步选择最佳行动。这种探索将改善评价，并最终导致更好地了解政策。1 time_diff <code class="fe mv mw mx mm b">integer</code>未 Ised？ds <code class="fe mv mw mx mm b">string</code>这个数据集的唯一 ID</p><p id="962a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们的<code class="fe mv mw mx mm b">run_gym.py</code>现在将运行<code class="fe mv mw mx mm b">-p</code>文件(例如<code class="fe mv mw mx mm b">ml/rl/test/gym/discrete_dqn_cartpole_v0_100_eps.json</code>)中指定的一定数量的剧集，其中它将(当它能够)使用<code class="fe mv mw mx mm b">train_gym_online_rl()</code>方法来:</p><ul class=""><li id="f5cc" class="mz na iq ka b kb kc kf kg kj nb kn nc kr nd kv ne nf ng nh bi translated">获取可能的操作</li><li id="2431" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv ne nf ng nh bi translated">采取行动(基于它是否是离散行动类型)</li><li id="9daf" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv ne nf ng nh bi translated">浏览健身房环境并检索<code class="fe mv mw mx mm b">next_state</code>、<code class="fe mv mw mx mm b">reward</code>和<code class="fe mv mw mx mm b">terminal</code>变量</li><li id="56ff" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv ne nf ng nh bi translated">基于<code class="fe mv mw mx mm b">gym_env.policy</code>变量中的<code class="fe mv mw mx mm b">policy</code>定义要采取的 next_action</li><li id="8351" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv ne nf ng nh bi translated">增加获得的奖励</li><li id="af79" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv ne nf ng nh bi translated">将观察到的行为插入重放缓冲区</li><li id="6da5" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv ne nf ng nh bi translated">每个<code class="fe mv mw mx mm b">train_every_ts</code>从<code class="fe mv mw mx mm b">replay_buffer</code>上取下<code class="fe mv mw mx mm b">num_train_batches</code>并用这些训练<code class="fe mv mw mx mm b">trainer</code></li><li id="fc71" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv ne nf ng nh bi translated">注意:这个训练器是在<code class="fe mv mw mx mm b"><a class="ae mg" href="https://github.com/facebookresearch/Horizon/blob/bbea36948bd409f03ec449be4539bd6bd9006418/ml/rl/test/gym/run_gym.py#L208" rel="noopener ugc nofollow" target="_blank">create_trainer()</a></code>方法中创建的，该方法将创建一个 DDPGTrainer、SACTrainer、ParametericDQNTrainer 或 DQNTrainer</li><li id="0ae8" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv ne nf ng nh bi translated">每个<code class="fe mv mw mx mm b">test_every_ts</code>记录我们的模型在<code class="fe mv mw mx mm b">logger</code>、<code class="fe mv mw mx mm b">avg_reward_history</code>和<code class="fe mv mw mx mm b">timestep_history</code>的表现</li><li id="5ab1" class="mz na iq ka b kb ni kf nj kj nk kn nl kr nm kv ne nf ng nh bi translated">记录剧集结束的时间</li></ul><h1 id="2fde" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">2.将我们的训练数据转换为时间线格式</h1><p id="df02" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">在第 2 步中，我们将转换之前以以下格式保存的培训数据:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="3502" class="mq le iq mm b gy mr ms l mt mu">{<br/>    "ds": "2019-01-01",<br/>    "mdp_id": "0",<br/>    "sequence_number": 10,<br/>    "state_features": {<br/>        "0": -0.032091656679586175,<br/>        "1": -0.016310561477682117,<br/>        "2": -0.01312794549150956,<br/>        "3": -0.04438365281404494<br/>    },<br/>    "action": "1",<br/>    "reward": 1.0,<br/>    "action_probability": 1.0,<br/>    "possible_actions": [<br/>        "0",<br/>        "1"<br/>    ],<br/>    "metrics": {<br/>        "reward": 1.0<br/>    }<br/>}</span></pre><p id="aeb8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于他们所谓的<code class="fe mv mw mx mm b">timeline</code>格式，这是一种给定一个表(state，action，mdp_id，sequence_number，reward，possible_next_actions)返回强化学习所需的表(mdp_id，state_features，action，reward，next_state_features，next_action，sequence_number，sequence_number_ordinal，time_diff，possible_next_actions)的格式，在<a class="ae mg" href="https://github.com/facebookresearch/Horizon/blob/master/preprocessing/src/main/scala/com/facebook/spark/rl/Timeline.scala" rel="noopener ugc nofollow" target="_blank"> Timeline.scala </a>中定义，我们可以表示为:</p><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nz"><img src="../Images/feebe3b491e6e8506d5036a18333d980.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zP9piisCRHs_i03u.png"/></div></div></figure><p id="4b38" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这将执行一个 Spark 作业，通过 Hive 运行一个查询，并将结果返回到一个不同的文件中。</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="f962" class="mq le iq mm b gy mr ms l mt mu"># Build timeline package (only need to do this first time)<br/>mvn -f preprocessing/pom.xml clean package</span><span id="0129" class="mq le iq mm b gy my ms l mt mu"># Clear last run's spark data (in case of interruption)<br/>rm -Rf spark-warehouse derby.log metastore_db preprocessing/spark-warehouse preprocessing/metastore_db preprocessing/derby.log</span><span id="9566" class="mq le iq mm b gy my ms l mt mu"># Run timelime on pre-timeline data<br/>/usr/local/spark/bin/spark-submit \<br/>  --class com.facebook.spark.rl.Preprocessor preprocessing/target/rl-preprocessing-1.1.jar \<br/>  "`cat ml/rl/workflow/sample_configs/discrete_action/timeline.json`"</span><span id="9fda" class="mq le iq mm b gy my ms l mt mu"># Merge output data to single file<br/>mkdir training_data<br/>mv cartpole_discrete_timeline/part* training_data/cartpole_training_data.json</span><span id="62dd" class="mq le iq mm b gy my ms l mt mu"># Remove the output data folder<br/>rm -Rf cartpole_discrete_timeline</span></pre><p id="62da" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">执行之后，我们现在可以通过运行<code class="fe mv mw mx mm b">head -n1 training_data/cartpole_training_data.json</code>来查看创建的文件:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="6178" class="mq le iq mm b gy mr ms l mt mu">{<br/>	"mdp_id": "31",<br/>	"sequence_number": 5,<br/>	"propensity": 1.0,<br/>	"state_features": {<br/>		"0": -0.029825548651835395,<br/>		"1": 0.19730168855281788,<br/>		"2": 0.013065490574540607,<br/>		"3": -0.29148843030554333<br/>	},<br/>	"action": 0,<br/>	"reward": 1.0,<br/>	"next_state_features": {<br/>		"0": -0.02587951488077904,<br/>		"1": 0.0019959027899765502,<br/>		"2": 0.00723572196842974,<br/>		"3": 0.005286388581067669<br/>	},<br/>	"time_diff": 1,<br/>	"possible_next_actions": [1, 1],<br/>	"metrics": {<br/>		"reward": 1.0<br/>	}<br/>}</span></pre><blockquote class="kw kx ky"><p id="baea" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><em class="iq">有趣的是，Spark 引擎将允许我们利用完全由 CPU 操作运行的分布式集群。GPU 操作将在稍后阶段进行。允许我们完全利用 HDFS 上的一个集群和纯粹用于 GPU 计算的一个集群。</em></p></blockquote><h1 id="ae77" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">3.正常化</h1><p id="9552" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">为了减少噪音和更快地训练我们的神经网络，我们使用了“标准化”。Horizon 包含一个工具，该工具可自动分析训练数据集，并为每个要素确定最佳变换函数和相应的归一化参数。</p><p id="0cc7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">要运行它，可以使用以下命令:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="8e65" class="mq le iq mm b gy mr ms l mt mu">python ml/rl/workflow/create_normalization_metadata.py -p ml/rl/workflow/sample_configs/discrete_action/dqn_example.json</span></pre><p id="c5e5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">打开<code class="fe mv mw mx mm b">/ml/rl/workflow/sample_configs/discrete_action/dqn_example.json</code>文件，我们可以看到一个类似的配置文件被传递给我们的健身房环境的主函数:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="5320" class="mq le iq mm b gy mr ms l mt mu">{<br/>	"training_data_path": "training_data/cartpole_training_data.json",<br/>	"state_norm_data_path": "training_data/state_features_norm.json",<br/>	"model_output_path": "outputs/",<br/>	"use_gpu": true,<br/>	"use_all_avail_gpus": true,<br/>	"norm_params": {<br/>		"output_dir": "training_data/",<br/>		"cols_to_norm": [<br/>			"state_features"<br/>		],<br/>		"num_samples": 1000<br/>	},<br/>	"actions": [<br/>		"0",<br/>		"1"<br/>	],<br/>	"epochs": 100,<br/>	"rl": {<br/>		"gamma": 0.99,<br/>		"target_update_rate": 0.2,<br/>		"reward_burnin": 1,<br/>		"maxq_learning": 1,<br/>		"epsilon": 0.2,<br/>		"temperature": 0.35,<br/>		"softmax_policy": 0<br/>	},<br/>	"rainbow": {<br/>		"double_q_learning": true,<br/>		"dueling_architecture": false<br/>	},<br/>	"training": {<br/>		"layers": [-1,<br/>			128,<br/>			64, -1<br/>		],<br/>		"activations": [<br/>			"relu",<br/>			"relu",<br/>			"linear"<br/>		],<br/>		"minibatch_size": 256,<br/>		"learning_rate": 0.001,<br/>		"optimizer": "ADAM",<br/>		"lr_decay": 0.999,<br/>		"warm_start_model_path": null,<br/>		"l2_decay": 0,<br/>		"use_noisy_linear_layers": false<br/>	},<br/>	"in_training_cpe": null<br/>}</span></pre><p id="d2d4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，让我们打开<code class="fe mv mw mx mm b">ml/rl/workflow/create_normalization_metadata.py</code>文件，在这里我们可以立即看到它的 main 方法以一个名为<code class="fe mv mw mx mm b">create_norm_table</code>的函数开始。</p><p id="0087" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><code class="fe mv mw mx mm b">create_norm_table()</code>方法将接受参数(上面的 json)并利用<code class="fe mv mw mx mm b">norm_params</code>、<code class="fe mv mw mx mm b">training_data_path</code>、<code class="fe mv mw mx mm b">cols_to_norm</code>和<code class="fe mv mw mx mm b">output_dir</code>配置来创建规范化表。</p><p id="d82e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这个规范化表是通过检查要规范化的列(在上面的 json 中是列<code class="fe mv mw mx mm b">state_features</code>)构建的，它将通过<code class="fe mv mw mx mm b">get_norm_metadata()</code>函数获取元数据。该函数将开始从我们的数据集中读取数据，并开始对要素及其值进行采样。一旦它收集到足够的样本(如<code class="fe mv mw mx mm b">norm_params["num_samples]</code>配置所定义的)，它将继续。</p><h1 id="46e9" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">4.训练模型</h1><p id="1b36" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">由于现在一切都经过预处理，数据也标准化了，我们准备开始训练我们的模型。为此，我们可以运行以下命令:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="7355" class="mq le iq mm b gy mr ms l mt mu">python ml/rl/workflow/dqn_workflow.py -p ml/rl/workflow/sample_configs/discrete_action/dqn_example.json</span></pre><p id="613f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">它将利用<a class="ae mg" href="https://github.com/facebookresearch/Horizon/blob/master/ml/rl/workflow/dqn_workflow.py" rel="noopener ugc nofollow" target="_blank"> dqn_workflow.py </a>文件选择正确的教练来训练它的模型。运行此命令将导致:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="e721" class="mq le iq mm b gy mr ms l mt mu">INFO:__main__:CPE evaluation took 0.23067665100097656 seconds.<br/>INFO:__main__:Training finished. Processed ~3961 examples / s.<br/>INFO:ml.rl.workflow.helpers:Saving PyTorch trainer to outputs/trainer_1543773299.pt<br/>INFO:ml.rl.workflow.helpers:Saving Caffe2 predictor to outputs/predictor_1543773299.c2<br/>INFO:ml.rl.caffe_utils:INPUT BLOB: input.1. OUTPUT BLOB:11<br/>INFO:ml.rl.training.dqn_predictor:Generated ONNX predict net:<br/>INFO:ml.rl.training.dqn_predictor:name: "torch-jit-export_predict"<br/>op {<br/>  input: "input.1"<br/>  input: "1"<br/>  input: "2"<br/>  output: "7"<br/>  name: ""<br/>  type: "FC"<br/>}<br/>op {<br/>  input: "7"<br/>  output: "8"<br/>  name: ""<br/>  type: "Relu"<br/>}<br/>op {<br/>  input: "8"<br/>  input: "3"<br/>  input: "4"<br/>  output: "9"<br/>  name: ""<br/>  type: "FC"<br/>}<br/>op {<br/>  input: "9"<br/>  output: "10"<br/>  name: ""<br/>  type: "Relu"<br/>}<br/>op {<br/>  input: "10"<br/>  input: "5"<br/>  input: "6"<br/>  output: "11"<br/>  name: ""<br/>  type: "FC"<br/>}<br/>device_option {<br/>  device_type: 0<br/>  device_id: 0<br/>}<br/>external_input: "input.1"<br/>external_input: "1"<br/>external_input: "2"<br/>external_input: "3"<br/>external_input: "4"<br/>external_input: "5"<br/>external_input: "6"<br/>external_output: "11"</span><span id="e580" class="mq le iq mm b gy my ms l mt mu">INFO:ml.rl.preprocessing.preprocessor_net:Processed split (0, 4) for feature type CONTINUOUS<br/>INFO:ml.rl.preprocessing.preprocessor_net:input# 0: preprocessor_net.py:287:Where_output0</span></pre><h1 id="6270" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">5.评估模型</h1><p id="a77f" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">模型是训练出来的，但是我们怎么测试呢？这可以通过附带的 cartpole 实验评估脚本来完成:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="f4ba" class="mq le iq mm b gy mr ms l mt mu">python ml/rl/test/workflow/eval_cartpole.py -m outputs/predictor_&lt;number&gt;.c2</span><span id="c1e4" class="mq le iq mm b gy my ms l mt mu">def main(model_path):<br/>    predictor = DQNPredictor.load(model_path, "minidb", int_features=False)</span><span id="dc9f" class="mq le iq mm b gy my ms l mt mu">    env = OpenAIGymEnvironment(gymenv=ENV)</span><span id="5eac" class="mq le iq mm b gy my ms l mt mu">    avg_rewards, avg_discounted_rewards = env.run_ep_n_times(<br/>        AVG_OVER_NUM_EPS, predictor, test=True<br/>    )</span><span id="6b05" class="mq le iq mm b gy my ms l mt mu">    logger.info(<br/>        "Achieved an average reward score of {} over {} evaluations.".format(<br/>            avg_rewards, AVG_OVER_NUM_EPS<br/>        )<br/>    )<br/></span><span id="583e" class="mq le iq mm b gy my ms l mt mu">def parse_args(args):<br/>    if len(args) != 3:<br/>        raise Exception("Usage: python &lt;file.py&gt; -m &lt;parameters_file&gt;")</span><span id="785a" class="mq le iq mm b gy my ms l mt mu">    parser = argparse.ArgumentParser(description="Read command line parameters.")<br/>    parser.add_argument("-m", "--model", help="Path to Caffe2 model.")<br/>    args = parser.parse_args(args[1:])<br/>    return args.model</span></pre><p id="03d9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这将使用给定的模型运行我们的健身房环境，并以对数线的形式返回 x 评估的奖励分数。</p><p id="d146" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这方面的一个例子是:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="8601" class="mq le iq mm b gy mr ms l mt mu">INFO:__main__:Achieved an average reward score of 9.34 over 100 evaluations.</span></pre><h1 id="355f" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">6.通过 Tensorboard 可视化</h1><p id="a2f5" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">现在，最后一步是通过 Tensorboard 可视化一切，我们可以这样开始:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="3b81" class="mq le iq mm b gy mr ms l mt mu">tensorboard --logdir outputs/</span></pre><p id="2edb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这将产生一个绑定到<a class="ae mg" href="https://localhost:6006" rel="noopener ugc nofollow" target="_blank"> https://localhost:6006 </a>的进程。</p><h1 id="aea9" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">渲染我们训练过的模型</h1><p id="1a3c" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">一旦我们训练了我们的模型，我们就能够通过 Tensorboard 可视化它。然而，我们也希望能够在评估模型的同时查看模型的运行情况。为了能够从这开始，首先安装先决条件+依赖项，如下所示:<a class="ae mg" href="https://xaviergeerinck.com/running-openai-gym-on-windows-and-js" rel="noopener ugc nofollow" target="_blank">如何在 Windows 上用 Javascript 运行 open ai Gym</a>。</p><p id="e247" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们现在要做的另一件事是更改<code class="fe mv mw mx mm b">eval_cartpole.py</code>文件，并在<code class="fe mv mw mx mm b">run_ep_n_times()</code>方法中添加<code class="fe mv mw mx mm b">render=True</code>，使其看起来像这样:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="05cc" class="mq le iq mm b gy mr ms l mt mu">avg_rewards, avg_discounted_rewards = env.run_ep_n_times(<br/>    AVG_OVER_NUM_EPS, predictor, test=True, render=True<br/>)</span></pre><p id="b955" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当我们现在通过以下方式重新推出评估工具时:</p><pre class="mh mi mj mk gt ml mm mn mo aw mp bi"><span id="cd2f" class="mq le iq mm b gy mr ms l mt mu">python ml/rl/test/workflow/eval_cartpole.py -m outputs/predictor_&lt;number&gt;.c2</span></pre><p id="f2f0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将能够看到我们的流程产生:</p><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/cf10b73c14559f8ec9ae8d97864731a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/0*Utu7lY1yRDJwQ7gH.png"/></div></figure></div></div>    
</body>
</html>