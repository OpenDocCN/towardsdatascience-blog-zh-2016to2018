<html>
<head>
<title>TensorFlow Serving client. Make it slimmer and faster!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow 服务客户。让它更瘦更快！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tensorflow-serving-client-make-it-slimmer-and-faster-b3e5f71208fb?source=collection_archive---------7-----------------------#2018-03-06">https://towardsdatascience.com/tensorflow-serving-client-make-it-slimmer-and-faster-b3e5f71208fb?source=collection_archive---------7-----------------------#2018-03-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div class="gh gi io"><img src="../Images/be89cea52cb769775adda9ebaa5fa185.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*i1P4DBQeUGDo5LwIjASO-A.jpeg"/></div></figure><div class=""/><p id="4016" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><a class="ae ks" href="https://www.tensorflow.org/serving/" rel="noopener ugc nofollow" target="_blank"> TensorFlow Serving </a>提供了一种在生产中部署和服务模型的简洁方式。我之前已经描述过部署过程<a class="ae ks" rel="noopener" target="_blank" href="/how-to-deploy-machine-learning-models-with-tensorflow-part-3-into-the-cloud-7115ff774bb6">这里</a>。不幸的是，有两个问题我很久以后才注意到，感谢宝贵的评论。首先，单次预测花费太多时间。第二，实际上，没有必要在客户端使用 TensorFlow。</p><p id="55a9" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">瓶颈是对 TensorFlow 的调用，它创建了一个张量 protobuf(完整的代码可以在<a class="ae ks" href="https://github.com/Vetal1977/tf_serving_example/blob/master/svnh_semi_supervised_client.py" rel="noopener ugc nofollow" target="_blank">这里</a>找到):</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="1b57" class="lc ld ix ky b gy le lf l lg lh">tf.contrib.util.make_tensor_proto(data, shape=[1])</span></pre><p id="b425" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">所有其他事情都不依赖于 TensorFlow，仅仅需要从 protobufs 生成 Python 文件。</p><h1 id="e225" class="li ld ix bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">解决方案</h1><p id="edf5" class="pw-post-body-paragraph ju jv ix jw b jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn mj kp kq kr ij bi translated">我介绍了一个专门针对图像预测的解决方案，而不改变原始的 protobufs。我发现了一篇很棒的博文<a class="ae ks" href="https://medium.com/@stianlindpetlund/tensorflow-serving-101-pt-2-682eaf7469e7" rel="noopener"/>,作者走得更远，复制并修改了原始的 protobufs。这允许将代码减少到最少，如果我只需要预测的话，我肯定会这么做。</p><h2 id="21f9" class="lc ld ix bd lj mk ml dn ln mm mn dp lr kf mo mp lv kj mq mr lz kn ms mt md mu bi translated">从 protobufs 生成 Python 代码</h2><p id="3419" class="pw-post-body-paragraph ju jv ix jw b jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn mj kp kq kr ij bi translated">我们必须创建一个在 TensorFlow protobuf 文件中描述的具有特定类型和形状的<em class="mv"> TensorProto </em>对象。我们可以按原样使用我们的图像数据数组。</p><p id="e119" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">更具体地说，这意味着我们必须从 TensorFlow 核心 protobufs 生成 Python 文件，并直接使用它们，而不是任何包装器。我已经生成了它们，并放入我的库<a class="ae ks" href="https://github.com/Vetal1977/tf_serving_example/tree/master/tensorflow/core" rel="noopener ugc nofollow" target="_blank">这里</a>。如果您愿意，您可以自己动手(假设您克隆了示例项目):</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="1477" class="lc ld ix ky b gy le lf l lg lh"># 1<br/>cd &lt;tensorflow serving source folder&gt;</span><span id="563d" class="lc ld ix ky b gy mw lf l lg lh"># 2<br/>python -m grpc.tools.protoc ./tensorflow/tensorflow/core/framework/*.proto --python_out=&lt;path to the project&gt; --grpc_python_out=&lt;path to the project&gt; --proto_path=.</span><span id="ce11" class="lc ld ix ky b gy mw lf l lg lh"># 3<br/>python -m grpc.tools.protoc ./tensorflow/tensorflow/core/example/*.proto --python_out=&lt;path to the project&gt; --grpc_python_out=&lt;path to the project&gt; --proto_path=.</span><span id="c08e" class="lc ld ix ky b gy mw lf l lg lh"># 4<br/>python -m grpc.tools.protoc ./tensorflow/tensorflow/core/protobuf/*.proto --python_out=&lt;path to the project&gt; --grpc_python_out=&lt;path to the project&gt; --proto_path=.</span></pre><p id="ac2a" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">不幸的是，由于依赖关系，您需要所有这些，或者您必须调整 protobufs 以满足您的需要，并消除不需要的依赖关系。</p><h2 id="9107" class="lc ld ix bd lj mk ml dn ln mm mn dp lr kf mo mp lv kj mq mr lz kn ms mt md mu bi translated">替换张量流代码</h2><p id="83b1" class="pw-post-body-paragraph ju jv ix jw b jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn mj kp kq kr ij bi translated">现在我们可以替换一个“标准的”张量原型创造</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="c3a8" class="lc ld ix ky b gy le lf l lg lh">tf.contrib.util.make_tensor_proto(data, shape=[1])</span></pre><p id="14d6" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">包含以下内容:</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="0c10" class="lc ld ix ky b gy le lf l lg lh">dims = [tensor_shape_pb2.TensorShapeProto.Dim(size=1)]<br/>tensor_shape_proto = tensor_shape_pb2.TensorShapeProto(dim=dims)<br/>tensor_proto = tensor_pb2.TensorProto(<br/>    dtype=types_pb2.DT_STRING,<br/>    tensor_shape=tensor_shape_proto,<br/>    string_val=[data])</span></pre><p id="ef53" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这是怎么回事？首先，我们创建一个与我们的数据相匹配的 dimension 对象——我们只有一个图像要预测。接下来，我们使用创建的维度对象初始化适当的张量形状。最后，我们用张量形状和我们的数据创建所需的类型为<em class="mv"> string </em>的张量 protobuf。我们必须将数据放入<em class="mv">字符串值</em>中，因为我们有一个<em class="mv">字符串</em>的张量。你可以在生成的<em class="mv">tensor flow/core/framework/types _ Pb2 . py</em>文件中找到其他可用的类型。</p><p id="91e9" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">现在，我们可以将张量 protobuf 设置为请求输入:</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="cb5f" class="lc ld ix ky b gy le lf l lg lh">request.inputs['images'].CopyFrom(tensor_proto)</span></pre><p id="6032" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">你可以在这里找到完整的代码<a class="ae ks" href="https://github.com/Vetal1977/tf_serving_example/blob/master/svnh_semi_supervised_client_no_tf.py" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="d3a5" class="lc ld ix bd lj mk ml dn ln mm mn dp lr kf mo mp lv kj mq mr lz kn ms mt md mu bi translated">表演</h2><p id="7e7a" class="pw-post-body-paragraph ju jv ix jw b jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn mj kp kq kr ij bi translated">你也可以显著提高表现。如果您喜欢在客户端继续使用 TensorFlow 框架，请进行以下更改:在开始时导入<em class="mv"> make_tensor_proto </em>，稍后调用它。</p><pre class="kt ku kv kw gt kx ky kz la aw lb bi"><span id="b0b1" class="lc ld ix ky b gy le lf l lg lh">...<br/>from tensorflow.contrib.util import make_tensor_proto<br/>...</span><span id="339e" class="lc ld ix ky b gy mw lf l lg lh">request.inputs['images'].CopyFrom(make_tensor_proto(data, shape=[1]))</span></pre><p id="4b36" class="pw-post-body-paragraph ju jv ix jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">如果您不再在客户端使用 TensorFlow，性能会自动提高。在我的系统上，现在单个图像预测需要 3 毫秒，而不是 300 毫秒。</p><h1 id="bb9c" class="li ld ix bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">摘要</h1><p id="44a5" class="pw-post-body-paragraph ju jv ix jw b jx mf jz ka kb mg kd ke kf mh kh ki kj mi kl km kn mj kp kq kr ij bi translated">TensorFlow 服务客户端不需要 TensorFlow 框架来发出请求。您唯一需要做的就是正确初始化发送给服务器的 gRPC 请求。您可以使用原始 TensorFlow Core protobufs 和以下 Python 文件并创建适当的 tensor protobuf 对象来实现这一点。如果您希望客户端中的 TensorFlow 尽可能少，您需要调整原始 protobufs 以满足您的特定需求。</p></div></div>    
</body>
</html>