<html>
<head>
<title>WHY did your model predict THAT? (Part 2 of 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么你的模型预测到了？(第 2 部分，共 2 部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-did-your-model-predict-that-part-2-of-2-48e3d50e1daf?source=collection_archive---------8-----------------------#2018-05-11">https://towardsdatascience.com/why-did-your-model-predict-that-part-2-of-2-48e3d50e1daf?source=collection_archive---------8-----------------------#2018-05-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="5461" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇文章的第一部分，<a class="ae kl" href="https://medium.com/@mateini_12893/why-did-your-model-predict-that-4f7ed3526397" rel="noopener">请点击这里</a>。在那里，我们激发了对分类器预测解释的需求，提到了以前的工作(LIME 包)并详细描述了我们的算法。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi km"><img src="../Images/7c7126caa1fd1b3feab87ace01c899df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*wz7tTrlUaXGAfb2kKXQ_HQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Not understanding the predictions of a machine-learning model.</figcaption></figure><p id="e209" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个帖子会比较短。有四个部分。</p><ul class=""><li id="b0e6" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk ld le lf lg bi translated">在<strong class="jp ir">第 1 节中，</strong>我们给出了代码实现的链接</li><li id="ca64" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">在<strong class="jp ir">第 2 节中，</strong>我们将我们的算法特性与 LIME 的进行了并排比较</li><li id="859e" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">在第 3 节<strong class="jp ir">，</strong>中，我们用一个教学例子来说明我们算法的使用。</li><li id="6371" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">在第 4 节中，我们展示了我们的结论。</li></ul></div><div class="ab cl lm ln hu lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="ij ik il im in"><h2 id="4166" class="lt lu iq bd lv lw lx dn ly lz ma dp mb jy mc md me kc mf mg mh kg mi mj mk ml bi translated">1.代码实现</h2><p id="82c8" class="pw-post-body-paragraph jn jo iq jp b jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk ij bi translated">我们以非常短的 Python 模块<strong class="jp ir">tcxp</strong>(<strong class="jp ir">t</strong>REE-<strong class="jp ir">c</strong>classifier e<strong class="jp ir">XP</strong>lanation)的形式实现了上述方法，该模块依赖于决策树分类器和随机森林的 scikit-learn 实现。代码可以在<a class="ae kl" href="http://www.yuxiglobal.com" rel="noopener ugc nofollow" target="_blank">羽西环球</a>的公开共享数据分析库<a class="ae kl" href="https://github.com/YuxiGlobal/data-analytics/tree/master/tree_classif_explain/py" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="5d9f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">提供的 Python 代码仅用于说明和教学目的，因为它肯定不是可能的最佳实现。它包含一对嵌套循环:一个在实例 x[ <em class="mr"> i </em>上，另一个在给定树中这些实例所遵循的路径的节点上。后一个循环可以通过使用 np.take 和 np.diff 进行矢量化来完成。此外，整个过程可以很容易地移植到 Cython，以产生真正优化的版本。</p><p id="25e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还制作了代码的 Spark 2.2 实现，依赖于 Spark 自己的 ML 库(spark-ml)，可以在这里找到<a class="ae kl" href="https://github.com/YuxiGlobal/data-analytics/tree/master/tree_classif_explain/spark" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="8269" class="lt lu iq bd lv lw lx dn ly lz ma dp mb jy mc md me kc mf mg mh kg mi mj mk ml bi translated">2.与石灰的对比</h2><p id="d0a5" class="pw-post-body-paragraph jn jo iq jp b jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk ij bi translated">下表总结了与 LIME 相比，我们的解释生成算法及其实现的一些关键特性。每一项的详细信息包含在第一部分的<a class="ae kl" href="https://medium.com/@mateini_12893/why-did-your-model-predict-that-4f7ed3526397" rel="noopener">第 3 节中。</a></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi ms"><img src="../Images/1d1b50370dcbe87b635e2fffb04baf54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2RzqaDk25Od2FHAjiKgvzg@2x.png"/></div></div></figure><h2 id="6879" class="lt lu iq bd lv lw lx dn ly lz ma dp mb jy mc md me kc mf mg mh kg mi mj mk ml bi translated">3.一个例子</h2><p id="a20c" class="pw-post-body-paragraph jn jo iq jp b jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk ij bi translated">让我们通过一个例子来说明 Python 模块的用法。</p><p id="ee8f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们考虑 Kaggle 的经典<em class="mr">泰坦尼克号:灾难中的机器学习</em>二进制分类任务。在这项任务中，我们得到了一个由 891 条记录组成的训练集，每条记录都包含泰坦尼克号上一名乘客的信息。这些字段包括性别、年龄、乘客级别、支付的票价、与乘客同行的兄弟姐妹和父母的数量以及他们上船的港口。除此之外，还有一个“幸存”二进制列，告诉我们哪些乘客在沉船事件中幸存。该任务的目标是训练一个监督模型，根据给定的乘客变量尽可能好地预测该类别。</p><p id="c439" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面的代码从 scikit-learn 导入了必要的类来训练一个随机森林分类器，以及从我们开发的 tcxp 模块中导入了<strong class="jp ir"> rf_explain </strong>函数。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="d465" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后一行执行训练数据的少量预处理。结果如下所示。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi mz"><img src="../Images/99ab5feb80038345e07ac89ccfdab9be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pRHsKZv-77dS3sneKnk86g@2x.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">A sample of train_df</figcaption></figure><p id="61b1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在可以用几行代码训练一个随机森林:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="2d8a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后一行计算的准确度是 85%。对几行工作来说还不错。然而，这并不是我们所寻求的最高精度。我们想直观地了解为什么模型会做出预测。</p><p id="a245" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是通过对 rf_explain_function 的一个函数调用来完成的</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="2a0f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个调用返回(1)，一个 891 乘 9(特征的数量)的矩阵，包含解释数组作为行，以及(2)，p[0]概率，它是一个乘客在没有考虑他们的任何特征的情况下在泰坦尼克号事件中幸存的<em class="mr">先验</em>概率。</p><p id="31e5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在让我们来看看几位乘客，看看他们的预测和解释是否</p><p id="75b2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">乘客 1 </strong>(上表第二排)预计有 0.963 的生还概率，事实上她幸存了下来。解释数组如下:tc_exps[1，:]=[0.11 0.01 0.02-0.01 0.11 0.00 0.28 0.03 0.02]，不过最好在一个图中看到:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="mx my l"/></div></figure><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi na"><img src="../Images/8a1e6c7780ded8f313a87eb2232b310d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J-8uBg2acogI2mNlYOv5eg@2x.png"/></div></div></figure><p id="f93f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这名乘客幸存下来并不令人惊讶，因为头等舱的女性乘客生还的可能性非常高。解释数组将这些特征与票价(与 Pclass 高度相关)一起显示为预测的最具决定性的特征。</p><p id="9b64" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">14 号乘客(</strong>上表中倒数第二排)没有成功，我们的模型正确预测了相对较低的生存概率。要解释为什么，我们来看看解释情节:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi na"><img src="../Images/09ec4af14e5101bb02795963e297b468.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZHdOMdCjzU0VwNR8VazNsA@2x.png"/></div></div></figure><p id="4e53" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这种情况下，她乘坐三等舱旅行的事实对她的生存机会产生了负面影响。</p><p id="bbb3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一个更有趣的案例由<strong class="jp ir">乘客 305 </strong>(上表最后一行)<strong class="jp ir">、</strong>提出，他幸存了下来，尽管他是男性:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi nb"><img src="../Images/9d375710b8fa1e21b5ffc761d2553af7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s96mhHBKXrfUBNvID2Rruw@2x.png"/></div></div></figure><p id="0600" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们看到，他乘坐的航班，但主要是他的年龄，以及他与父母和兄弟姐妹一起旅行的事实，导致他的生存概率为 67.7%。</p><h2 id="3dfa" class="lt lu iq bd lv lw lx dn ly lz ma dp mb jy mc md me kc mf mg mh kg mi mj mk ml bi translated">结论</h2><p id="f540" class="pw-post-body-paragraph jn jo iq jp b jq mm js jt ju mn jw jx jy mo ka kb kc mp ke kf kg mq ki kj kk ij bi translated">正如最后一节所示，我们的树分类器解释方法很可能产生合理的解释，并阐明否则黑盒 ML 架构的预测。这种方法和其他更通用的方法(如 LIME)一起，产生了一些希望，希望有一天这些高级算法可以摆脱目前的坏名声。与任何其他解释方法一样，我们的方法为从这种模型的预测中得出的更聪明的指令性行动开辟了道路。</p></div></div>    
</body>
</html>