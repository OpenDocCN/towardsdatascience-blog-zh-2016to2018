<html>
<head>
<title>Finding Similar Quora Questions with Word2Vec and Xgboost</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 Word2Vec 和 Xgboost 寻找相似的 Quora 问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/finding-similar-quora-questions-with-word2vec-and-xgboost-1a19ad272c0d?source=collection_archive---------4-----------------------#2018-10-29">https://towardsdatascience.com/finding-similar-quora-questions-with-word2vec-and-xgboost-1a19ad272c0d?source=collection_archive---------4-----------------------#2018-10-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/e3106227b54e2f5e5678e90de5bdeb99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u2fhBUw-XnwfzSVbeKJKdA.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">photo credit: Pixabay</figcaption></figure><div class=""/><div class=""><h2 id="df66" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">如何使用自然语言处理来识别任何文本数据集中的相似记录</h2></div><p id="b57a" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">上周，我们探索了使用 BOW、TFIDF 和 Xgboost 识别相似文档的不同重复数据删除技术。我们发现传统的方法如 TFIDF 可以取得一些令人印象深刻的结果。这也是<a class="ae lq" href="https://www.link-assistant.com/news/tf-idf-tool.html" rel="noopener ugc nofollow" target="_blank">谷歌长期以来在索引和信息检索中使用 TFIDF 来计算给定关键词对给定页面的重要性的原因之一</a>。</p><p id="6ade" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">为了继续我们的学习之旅并增长我们的技能，今天，我们将探讨如何使用不同的方法解决相同的匹配和重复数据消除问题，同样，我们将把重复数据消除作为分类器的扩展来处理。我们开始吧！</p><h1 id="1468" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated">数据</h1><p id="79ed" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated">Quora 重复问题对的任务是确定一对问题是否具有相同的含义。数据包含一对问题和一个由人类专家标记的基本事实标签，标记这对问题是否重复。请注意，这些标签是主观的，这意味着并非所有人类专家都同意这一对问题是否重复。因此，这些数据应被视为有根据的，而不是 100%准确的。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="1a16" class="mx ls jf mt b gy my mz l na nb">df = pd.read_csv('quora_train.csv')<br/>df = df.dropna(how="any").reset_index(drop=True)<br/>a = 0 <br/>for i in range(a,a+10):<br/>    print(df.question1[i])<br/>    print(df.question2[i])<br/>    print()</span></pre><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nc"><img src="../Images/f7c9d0bd5c3350c9178c4e51ef91c92c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EyfpGLFJT3vxp3bnjBSAxw.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Figure 1</figcaption></figure><h1 id="34c5" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated">计算单词移动者的距离</h1><p id="0ed6" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated"><a class="ae lq" href="http://proceedings.mlr.press/v37/kusnerb15.pdf" rel="noopener ugc nofollow" target="_blank"> WMD </a>是一种允许我们以一种有意义的方式评估两个文档之间“距离”的方法，不管它们有没有共同点。它使用单词的矢量嵌入。它将两个文本文档之间的差异度量为一个文档的嵌入单词需要“行进”以到达另一个文档的嵌入单词的最小距离。让我们看一个例子，下面的问题对被标记为重复:</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="5f8d" class="mx ls jf mt b gy my mz l na nb">question1 = 'What would a Trump presidency mean for current international master’s students on an F1 visa?'<br/>question2 = 'How will a Trump presidency affect the students presently in US or planning to study in US?'</span><span id="bc4b" class="mx ls jf mt b gy nd mz l na nb">question1 = question1.lower().split()<br/>question2 = question2.lower().split()</span><span id="e9b1" class="mx ls jf mt b gy nd mz l na nb">question1 = [w for w in question1 if w not in stop_words]<br/>question2 = [w for w in question2 if w not in stop_words]</span></pre><p id="08dc" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们将使用<a class="ae lq" href="https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit" rel="noopener ugc nofollow" target="_blank"> word2vec 预训练的谷歌新闻语料库</a>。我们将这些加载到一个 Gensim Word2Vec 模型类中。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="b8f0" class="mx ls jf mt b gy my mz l na nb">import gensim</span><span id="bfdf" class="mx ls jf mt b gy nd mz l na nb">from gensim.models import Word2Vec<br/>    <br/>model = gensim.models.KeyedVectors.load_word2vec_format('./word2Vec_models/GoogleNews-vectors-negative300.bin.gz', binary=True)</span></pre><p id="94c3" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">让我们用 wmdistance 方法计算这两个句子的 WMD。记住，这两句话表达的是同一个意思，在原 quora 数据中被标注为重复。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="e50d" class="mx ls jf mt b gy my mz l na nb">distance = model.wmdistance(question1, question2)<br/>print('distance = %.4f' % distance)</span></pre><p id="5df3" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> <em class="ne">距离= 1.8293 </em> </strong></p><p id="269d" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">这两个句子之间的计算距离相当大。这就把我们带到了规范化的大规模杀伤性武器。</p><h1 id="ee05" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated"><strong class="ak">标准化 word2vec 向量</strong></h1><p id="96af" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated">当使用 wmdistance 方法时，首先规范化 word2vec 向量是有益的，这样它们都具有相等的长度。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="431f" class="mx ls jf mt b gy my mz l na nb">model.init_sims(replace=True)<br/>distance = model.wmdistance(question1, question2)<br/>print('normalized distance = %.4f' % distance)</span></pre><p id="8e2c" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> <em class="ne">归一化距离= 0.7589 </em> </strong></p><p id="fb9b" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">正常化后，距离变小了很多。</p><p id="0f64" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">再来一对试试，这次这两道题不重复。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="6d28" class="mx ls jf mt b gy my mz l na nb">question3 = 'Why am I mentally very lonely? How can I solve it?'<br/>question4 = 'Find the remainder when [math]23^{24}[/math] is divided by 24,23?'</span><span id="596e" class="mx ls jf mt b gy nd mz l na nb">question3 = question3.lower().split()<br/>question4 = question4.lower().split()</span><span id="b117" class="mx ls jf mt b gy nd mz l na nb">question3 = [w for w in question3 if w not in stop_words]<br/>question4 = [w for w in question4 if w not in stop_words]</span><span id="bc96" class="mx ls jf mt b gy nd mz l na nb">distance = model.wmdistance(question3, question4)<br/>print('distance = %.4f' % distance)</span></pre><p id="9ed0" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> <em class="ne">距离= 1.2637 </em> </strong></p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="3335" class="mx ls jf mt b gy my mz l na nb">model.init_sims(replace=True)<br/>distance = model.wmdistance(question3, question4)<br/>print('normalized distance = %.4f' % distance)</span></pre><p id="2332" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> <em class="ne">归一化距离= 1.2637 </em> </strong></p><p id="2723" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">归一化后，距离保持不变。WMD 认为第二对没有第一对相似。成功了！</p><h1 id="b138" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated">模糊的</h1><p id="670f" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated">我们已经介绍了 Python 中<a class="ae lq" rel="noopener" target="_blank" href="/natural-language-processing-for-fuzzy-string-matching-with-python-6632b7824c49">模糊字符串匹配的一些基础知识，让我们快速浏览一下</a><a class="ae lq" href="https://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/" rel="noopener ugc nofollow" target="_blank"> FuzzyWuzzy </a>是否可以帮助我们解决问题重复数据删除问题。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="ea2d" class="mx ls jf mt b gy my mz l na nb">from fuzzywuzzy import fuzz</span><span id="512f" class="mx ls jf mt b gy nd mz l na nb">question1 = 'What would a Trump presidency mean for current international master’s students on an F1 visa?'<br/>question2 = 'How will a Trump presidency affect the students presently in US or planning to study in US?'<br/>fuzz.ratio(question1, question2)</span></pre><p id="0d6e" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> <em class="ne"> 53 </em> </strong></p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="fdd0" class="mx ls jf mt b gy my mz l na nb">fuzz.partial_token_set_ratio(question1, question2)</span></pre><p id="5ce0" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> <em class="ne"> 100 </em> </strong></p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="92d1" class="mx ls jf mt b gy my mz l na nb">question3 = 'Why am I mentally very lonely? How can I solve it?'<br/>question4 = 'Find the remainder when [math]23^{24}[/math] is divided by 24,23?'<br/>fuzz.ratio(question3, question4)</span></pre><p id="4b7a" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> <em class="ne"> 28 </em> </strong></p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="22ff" class="mx ls jf mt b gy my mz l na nb">fuzz.partial_token_set_ratio(question3, question4)</span></pre><p id="1601" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> <em class="ne"> 37 </em> </strong></p><p id="3e6c" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">基本上，Fuzzywuzzy 不认为第二对问题是相似的。那很好。因为根据人类评价，第二对是不相似的。</p><h1 id="6f9b" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated">特征工程</h1><p id="8630" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated">首先，我们创建几个函数来计算 WMD 和归一化 WMD 以及单词到向量的表示。</p><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="nf ng l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">wmd_normWmd_sent2vec</figcaption></figure><p id="8c71" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们将创建的新功能包括:</p><ul class=""><li id="831e" class="nh ni jf kw b kx ky la lb ld nj lh nk ll nl lp nm nn no np bi translated">单词的长度。</li><li id="1687" class="nh ni jf kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated">字符的长度。</li><li id="ebe9" class="nh ni jf kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated">问题 1 和问题 2 之间常用词的长度。</li><li id="6b32" class="nh ni jf kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated">问题 1 和问题 2 之间的长度差。</li><li id="ec3e" class="nh ni jf kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated">向量 question1 和 question2 之间的余弦距离。</li><li id="8c70" class="nh ni jf kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated">城市街区(曼哈顿)矢量问题 1 和问题 2 之间的距离。</li><li id="a4d4" class="nh ni jf kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated">向量 question1 和 question2 之间的雅克卡距离。</li><li id="3a12" class="nh ni jf kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated">向量问题 1 和问题 2 之间的堪培拉距离。</li><li id="0585" class="nh ni jf kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated">向量 question1 和 question2 之间的欧几里德距离。</li><li id="cc32" class="nh ni jf kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated">向量 question1 和 question2 之间的闵可夫斯基距离。</li><li id="d30d" class="nh ni jf kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated">向量问题 1 和问题 2 之间的 Bray-Curtis 距离。</li><li id="4f8d" class="nh ni jf kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated">向量问题 1 和问题 2 的偏度和峰度。</li><li id="6e80" class="nh ni jf kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated">大规模杀伤性武器</li><li id="b8c4" class="nh ni jf kw b kx nq la nr ld ns lh nt ll nu lp nm nn no np bi translated">标准化大规模杀伤性武器</li></ul><p id="c8de" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">所有的距离计算都可以通过使用<code class="fe nv nw nx mt b">scipy.spatial.distance</code>函数来完成。</p><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="nf ng l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">new_features1</figcaption></figure><h1 id="5d24" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated">word 2 虚拟建模</h1><p id="186b" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated">我们将使用 word2vec 预训练的谷歌新闻语料库。我下载并保存到“word2Vec_models”文件夹中。然后，我们将这些加载到一个 Gensim Word2Vec 模型类中。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="97c1" class="mx ls jf mt b gy my mz l na nb">model = gensim.models.KeyedVectors.load_word2vec_format('./word2Vec_models/GoogleNews-vectors-negative300.bin.gz', binary=True)<br/>df['wmd'] = df.apply(lambda x: wmd(x['question1'], x['question2']), axis=1)</span></pre><h1 id="b6b9" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated"><strong class="ak">归一化 Word2vec 建模</strong></h1><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="8e4b" class="mx ls jf mt b gy my mz l na nb">norm_model = gensim.models.KeyedVectors.load_word2vec_format('./word2Vec_models/GoogleNews-vectors-negative300.bin.gz', binary=True)<br/>norm_model.init_sims(replace=True)<br/>df['norm_wmd'] = df.apply(lambda x: norm_wmd(x['question1'], x['question2']), axis=1)</span></pre><p id="3986" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">获取问题 1 和问题 2 的向量，然后计算所有距离。</p><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="nf ng l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">new_features2</figcaption></figure><h1 id="60ad" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated">Xgboost</h1><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="nf ng l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Xgboost</figcaption></figure><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ny"><img src="../Images/8aa2c1949c2c007e71c02cabfb36a282.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WNMDV6N-xcfbgHJA_TTsYQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Figure 2</figcaption></figure><p id="3f87" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们创建的所有新功能的 Xgboost 实现了 0.77 的测试准确性，低于字符级 TF-IDF + Xgboost 的 0.80，但是，我们能够将重复问题的召回率从 0.67 提高到 0.73，这是一个显著的改进。</p><p id="1392" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">Jupyter 笔记本可以在<a class="ae lq" href="https://github.com/susanli2016/NLP-with-Python/blob/master/Word2vec_xgboost.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。祝你一周工作顺利！</p><p id="d0bb" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">参考:</p><p id="5483" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><a class="ae lq" href="https://www.linkedin.com/pulse/duplicate-quora-question-abhishek-thakur/" rel="noopener ugc nofollow" target="_blank">https://www . LinkedIn . com/pulse/duplicate-quora-question-abhishek-thakur/</a></p></div></div>    
</body>
</html>