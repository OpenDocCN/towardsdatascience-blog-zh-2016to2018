<html>
<head>
<title>Detecting the Fault Line using k-mean Clustering and RANSAC</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用 k-均值聚类和 RANSAC 检测故障线路</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/detecting-the-fault-line-using-k-mean-clustering-and-ransac-9a74cb61bb96?source=collection_archive---------11-----------------------#2018-09-19">https://towardsdatascience.com/detecting-the-fault-line-using-k-mean-clustering-and-ransac-9a74cb61bb96?source=collection_archive---------11-----------------------#2018-09-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f829" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">k 均值聚类和<strong class="ak">随机样本一致性</strong></h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/a14e8170fa130574d17e6c7de66a261a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1LYzvW16dLf_3V4oM7EYwg.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Fig. 1- fitted plane from the last blog</figcaption></figure><p id="9ead" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我的<a class="ae lr" href="https://medium.com/@ns2586/detecting-the-fault-line-using-principal-component-analysis-pca-7d5d265336a3" rel="noopener">上一篇博文</a>中，我使用主成分分析法(PCA)探测了帕克菲尔德附近圣安地列斯断层沿线的断层线。虽然已知断层线在该区域几乎是垂直的，但拟合的平面却相当水平(图 1)。这大概是因为 PCA 对“异常值”非常敏感，因为它是基于相关/协方差矩阵的方法。也可以假定，由于所有点的权重相同，一些远离主断层线的数据点可能使平面发生了倾斜。为了改善结果，采取了几种不同的方法，我将在这篇博客中详细介绍这些步骤。</p><p id="714e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> K 均值聚类</strong></p><p id="de53" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于断层结构非常复杂，所以在上一篇博客中，从整个数据集中随机选择一部分来拟合一个平面，而不是将一个平面拟合到整个数据集中。然而，这可能会潜在地导致一个问题，因为我们不知道所选择的点是否属于同一断层结构。因此，不是随机选择一个子集，而是应用 k 均值聚类将数据点分成更多“相似”点的聚类。</p><p id="6b82" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">k 均值聚类是一种聚类算法，它将数据点分成 n 个聚类。通过 1)将数据点分配到最近的质心，2)将质心位置更新到所分配的数据点的中心，以及 3)将数据点重新分配到最近的质心，来确定每个聚类的最佳质心。这个过程重复进行，直到它稳定下来，一旦完成，分配给质心的数据点就形成一个簇。</p><p id="6061" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">轮廓系数</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/03302c3fdcdba730052b3140859d67bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BQaDV6aP_iZvHXU4OK9Zbg.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Fig. 2 silhouette coefficient</figcaption></figure><p id="3c97" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">轮廓系数用于确定最佳聚类数(图 2)。轮廓系数，取值在-1 到 1 之间，表示每个点分配给其分类的情况。测量从一个点到它自己的聚类以及到它的相邻聚类的距离(可以使用任何种类的距离度量，在这种情况下使用欧几里德距离),并且比较这些距离。下面是推导轮廓系数 s 的公式:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/92f848d7f88657408ecd174473a5f179.png" data-original-src="https://miro.medium.com/v2/resize:fit:246/format:webp/1*4Dql6dBFjTI6ev_qKf90MQ.png"/></div></figure><p id="49d8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其中<em class="lu"> a </em>是从一个数据点到同一聚类中所有数据点的平均距离，而<em class="lu"> b </em>是从该点到最近聚类中所有数据点的平均距离。</p><p id="74a0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">高值表示它被很好地分配给自己的簇，低/负值表示它分配得不好。如图 2 所示，3 是该研究的最佳集群数。下图左侧显示了 3 组数据点，右侧显示了拟合的平面(像上次一样使用 PCA 来拟合平面)。</p><div class="kg kh ki kj gt ab cb"><figure class="lv kk lw lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/b1b23d9e549202aa7ab04934fc018107.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*g6o4GhES05WQOkTo8vkPvg.png"/></div></figure><figure class="lv kk mb lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/eac1b150d1f5d17fee859a2ed2344378.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*VYn2MSsLIUkLEy6LQBmGGw.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk mc di md me">Fig. 3 * black dots are the centroids of the clusters</figcaption></figure></div><p id="0a8f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用 k-means，拟合的平面看起来更好。但为了进一步改善结果，使用了异常值检测方法来消除一些可能会使平面倾斜的异常值。</p><p id="473f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">随机样本一致性(RANSAC) </strong></p><p id="43b2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">随机样本一致性是一种检测异常值的迭代方法。迭代方法使用初始猜测来生成一系列改进的近似。它广泛应用于图像处理领域，用于去除数据集中的噪声。因为它去除了异常值，所以您需要小心它的应用— RANSAC 只有在异常值对您预测的值没有影响时才是可行的。RANSAC 算法查找异常值的方式如下:</p><ol class=""><li id="6f21" class="mf mg iq kx b ky kz lb lc le mh li mi lm mj lq mk ml mm mn bi translated">随机选择一个数据子集(<em class="lu">假设内联者</em>)</li><li id="1c52" class="mf mg iq kx b ky mo lb mp le mq li mr lm ms lq mk ml mm mn bi translated">使用该子集，计算模型参数</li><li id="150d" class="mf mg iq kx b ky mo lb mp le mq li mr lm ms lq mk ml mm mn bi translated">将整个数据集与步骤 2 中建立的模型进行比较，所有与估计模型(基于损失函数)吻合的点将组成<em class="lu">共识集</em> (=内联集)</li></ol><p id="d71c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">RANSAC 有一个<a class="ae lr" href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RANSACRegressor.html" rel="noopener ugc nofollow" target="_blank"> sklearn 库</a>，它有一个属性 inlier_mask_，告诉您哪些数据点被视为 inlier:</p><pre class="kg kh ki kj gt mt mu mv mw aw mx bi"><span id="0ebb" class="my mz iq mu b gy na nb l nc nd">ransac = linear_model.RANSACRegressor()<br/>ransac.fit(X, y)<br/>inlier_mask = ransac.inlier_mask_<br/>outlier_mask = np.logical_not(inlier_mask)</span></pre><p id="24ed" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于 3 个集群的导出的内层，拟合平面。图 4 中左图上的透明点是异常值，右图显示了拟合的平面。</p><div class="kg kh ki kj gt ab cb"><figure class="lv kk ne lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/80480975bc1008e256d7e875e524768c.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*5PDCsNquXRKOhxrjBguM2g.png"/></div></figure><figure class="lv kk nf lx ly lz ma paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><img src="../Images/c1bc13e903cb06604e8e3fc56aece9dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*QOOPHit2w8Chpx-oHv7G6w.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk ng di nh me">Fig. 4 transparent data points are the ‘outliers’</figcaption></figure></div><p id="b821" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">结论</strong></p><p id="2fae" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用 k-均值聚类、RANSAC 和 PCA，拟合的断层线变得更加接近现实(而不是垂直平面)。由于 PCA 对远离其他观测值的点非常敏感，RANSAC 非常有助于防止这些点扭曲拟合平面。尽管在绘制主要断层线时忽略了这些异常值，但它们可能是某些潜在断层结构的一部分。将进一步研究这些异常值，以了解断层的复杂结构。</p></div></div>    
</body>
</html>