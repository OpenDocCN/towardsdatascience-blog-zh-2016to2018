<html>
<head>
<title>Understanding Data Science Classification Metrics in Scikit-Learn in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解 Scikit 中的数据科学分类指标-了解 Python</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-data-science-classification-metrics-in-scikit-learn-in-python-3bc336865019?source=collection_archive---------0-----------------------#2018-08-05">https://towardsdatascience.com/understanding-data-science-classification-metrics-in-scikit-learn-in-python-3bc336865019?source=collection_archive---------0-----------------------#2018-08-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/6bd8d48381571d5d692f2cabfb35ff3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*Hqh7JvLI8pvzB9cUzUOf3g.png"/></div></figure><p id="1f11" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在本教程中，我们将浏览 Python 的 scikit 中的一些分类指标——从头开始学习并编写我们自己的函数，以理解其中一些函数背后的数学原理。</p><p id="6341" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">数据科学中预测建模的一个主要领域是分类。分类包括试图预测总体中某个特定样本来自哪个类别。例如，如果我们试图预测某个特定的患者是否会再次住院，两个可能的类别是住院(阳性)和未住院(阴性)。然后，分类模型会尝试预测每个患者是否会住院。换句话说，分类只是试图预测来自总体的特定样本应该放在哪个桶中(预测正对预测负),如下所示。</p><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi ks"><img src="../Images/4f2aa600631243f45ee7034222eb0d10.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*hkne2nyU_HPdye2Rzankdg.png"/></div></figure><p id="0eb5" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">当您训练您的分类预测模型时，您会想要评估它有多好。有趣的是，有许多不同的方法来评估性能。大多数使用 Python 进行预测建模的数据科学家都使用名为 scikit-learn 的 Python 包。Scikit-learn 包含许多用于分析模型性能的内置函数。在本教程中，我们将遍历其中一些指标，并从头开始编写我们自己的函数，以理解其中一些指标背后的数学原理。如果你更喜欢阅读性能指标，请点击这里查看我在<a class="ae kx" rel="noopener" target="_blank" href="/data-science-performance-metrics-for-everyone-4d68f4859eef">的上一篇文章。</a></p><p id="943f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">本教程将涵盖来自<code class="fe ky kz la lb b">sklearn.metrics</code>的以下指标:</p><ul class=""><li id="f8f7" class="lc ld iq jw b jx jy kb kc kf le kj lf kn lg kr lh li lj lk bi translated">困惑 _ 矩阵</li><li id="7512" class="lc ld iq jw b jx ll kb lm kf ln kj lo kn lp kr lh li lj lk bi translated">准确性 _ 得分</li><li id="c371" class="lc ld iq jw b jx ll kb lm kf ln kj lo kn lp kr lh li lj lk bi translated">回忆 _ 分数</li><li id="7552" class="lc ld iq jw b jx ll kb lm kf ln kj lo kn lp kr lh li lj lk bi translated">精度分数</li><li id="d6d2" class="lc ld iq jw b jx ll kb lm kf ln kj lo kn lp kr lh li lj lk bi translated">f1 _ 分数</li><li id="acf5" class="lc ld iq jw b jx ll kb lm kf ln kj lo kn lp kr lh li lj lk bi translated">roc _ 曲线</li><li id="ac44" class="lc ld iq jw b jx ll kb lm kf ln kj lo kn lp kr lh li lj lk bi translated">roc_auc_score</li></ul><h2 id="3518" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated"><span class="l mj mk ml bm mm mn mo mp mq di"> G </span>开始了</h2><p id="deb3" class="pw-post-body-paragraph ju jv iq jw b jx mr jz ka kb ms kd ke kf mt kh ki kj mu kl km kn mv kp kq kr ij bi translated">关于样本数据集和 jupyter 笔记本，请访问我的 github <a class="ae kx" href="https://github.com/andrewwlong/classification_metrics_sklearn" rel="noopener ugc nofollow" target="_blank">这里</a>。假设有两个类，我们将从头开始编写自己的函数。请注意，您需要填写标记为<code class="fe ky kz la lb b"># your code here</code>的部分</p><p id="4d1f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">让我们加载一个样本数据集，它具有实际标签(actual_label)和两个模型的预测概率(model_RF 和 model_LR)。这里的概率是第一类的概率。</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="0ddb" class="lq lr iq lb b gy na nb l nc nd">import pandas as pd<br/>df = pd.read_csv('data.csv')<br/>df.head()</span></pre><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ne"><img src="../Images/059368fed6405cdd6b02587307515f8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*EhiR_7tXZqzk2V0dA60O7g.png"/></div></div></figure><p id="16dd" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在大多数数据科学项目中，您将定义一个阈值来定义哪些预测概率被标记为预测正与预测负。现在让我们假设阈值是 0.5。让我们添加两个额外的列，将概率转换为预测标签。</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="2a5d" class="lq lr iq lb b gy na nb l nc nd">thresh = 0.5<br/>df['predicted_RF'] = (df.model_RF &gt;= 0.5).astype('int')<br/>df['predicted_LR'] = (df.model_LR &gt;= 0.5).astype('int')<br/>df.head()</span></pre><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/482f35d90402221f6e6ba6115d7b2e07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*Q44l7tx1AREOeYmgh4mkKA.png"/></div></figure><h2 id="96df" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated">困惑 _ 矩阵</h2><p id="aea9" class="pw-post-body-paragraph ju jv iq jw b jx mr jz ka kb ms kd ke kf mt kh ki kj mu kl km kn mv kp kq kr ij bi translated">给定一个实际标签和一个预测标签，我们可以做的第一件事是将样本分成 4 个桶:</p><ul class=""><li id="12d4" class="lc ld iq jw b jx jy kb kc kf le kj lf kn lg kr lh li lj lk bi translated">真正值-实际值= 1，预测值= 1</li><li id="9127" class="lc ld iq jw b jx ll kb lm kf ln kj lo kn lp kr lh li lj lk bi translated">假阳性-实际= 0，预测= 1</li><li id="a257" class="lc ld iq jw b jx ll kb lm kf ln kj lo kn lp kr lh li lj lk bi translated">假阴性-实际= 1，预测= 0</li><li id="efca" class="lc ld iq jw b jx ll kb lm kf ln kj lo kn lp kr lh li lj lk bi translated">真负值-实际值= 0，预测值= 0</li></ul><p id="2e9f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这些桶可以用下面的图像表示(原始源<a class="ae kx" href="https://en.wikipedia.org/wiki/Precision_and_recall#/media/File:Precisionrecall.svg" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Precision _ and _ recall #/media/File:Precision recall . SVG</a>)，我们将在下面的许多计算中引用这个图像。</p><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/7a705a0baf3eebae7e67296c9a414f8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*2WBrkJP8qKO3DDG7Lvg0hg.png"/></div></figure><p id="1ca4" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">这些存储桶也可以使用如下所示的混淆矩阵来显示:</p><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/0c521cc7da01d4cedf5c7610bfe578fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*6Vy8J9kL_iXZeAh5KrZgCw.png"/></div></figure><p id="ea0e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们可以从 scikit-learn 获得混淆矩阵(作为 2x2 数组),它将实际标签和预测标签作为输入</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="a8a1" class="lq lr iq lb b gy na nb l nc nd">from sklearn.metrics import confusion_matrix</span><span id="e4b8" class="lq lr iq lb b gy nm nb l nc nd">confusion_matrix(df.actual_label.values, df.predicted_RF.values)</span></pre><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/ff2bd7392927098f9e848f2fa8fe74c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*8lQVtLS8gDPC8ayDi3U6Ww.png"/></div></figure><p id="205e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">其中有 5047 个真阳性，2360 个假阳性，2832 个假阴性和 5519 个真阴性。让我们定义自己的函数来验证<code class="fe ky kz la lb b">confusion_matrix</code>。注意，第一个我填了，另外 3 个你需要填。</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="931e" class="lq lr iq lb b gy na nb l nc nd">def find_TP(y_true, y_pred):<br/>    # counts the number of true positives (y_true = 1, y_pred = 1)<br/>    return sum((y_true == 1) &amp; (y_pred == 1))<br/>def find_FN(y_true, y_pred):<br/>    # counts the number of false negatives (y_true = 1, y_pred = 0)<br/>    return # your code here<br/>def find_FP(y_true, y_pred):<br/>    # counts the number of false positives (y_true = 0, y_pred = 1)<br/>    return # your code here<br/>def find_TN(y_true, y_pred):<br/>    # counts the number of true negatives (y_true = 0, y_pred = 0)<br/>    return # your code here</span></pre><p id="3b9f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">您可以检查您的结果是否与</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="a2cb" class="lq lr iq lb b gy na nb l nc nd">print('TP:',find_TP(df.actual_label.values, df.predicted_RF.values))<br/>print('FN:',find_FN(df.actual_label.values, df.predicted_RF.values))<br/>print('FP:',find_FP(df.actual_label.values, df.predicted_RF.values))<br/>print('TN:',find_TN(df.actual_label.values, df.predicted_RF.values))</span></pre><p id="c76a" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">让我们写一个函数来计算这四个参数，然后再写一个函数来复制<code class="fe ky kz la lb b">confusion_matrix</code></p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="3f72" class="lq lr iq lb b gy na nb l nc nd">import numpy as np<br/>def find_conf_matrix_values(y_true,y_pred):<br/>    # calculate TP, FN, FP, TN<br/>    TP = find_TP(y_true,y_pred)<br/>    FN = find_FN(y_true,y_pred)<br/>    FP = find_FP(y_true,y_pred)<br/>    TN = find_TN(y_true,y_pred)<br/>    return TP,FN,FP,TN<br/>def my_confusion_matrix(y_true, y_pred):<br/>    TP,FN,FP,TN = find_conf_matrix_values(y_true,y_pred)<br/>    return np.array([[TN,FP],[FN,TP]])</span></pre><p id="a586" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">检查您的结果是否与匹配</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="a92d" class="lq lr iq lb b gy na nb l nc nd">my_confusion_matrix(df.actual_label.values, df.predicted_RF.values)</span></pre><p id="9cf4" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">不要手动比较，让我们使用 Python 的内置<code class="fe ky kz la lb b">assert </code>和 numpy 的<code class="fe ky kz la lb b">array_equal </code>函数来验证我们的函数工作正常</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="0d34" class="lq lr iq lb b gy na nb l nc nd">assert  np.array_equal(my_confusion_matrix(df.actual_label.values, df.predicted_RF.values), confusion_matrix(df.actual_label.values, df.predicted_RF.values) ), 'my_confusion_matrix() is not correct for RF'</span><span id="82bd" class="lq lr iq lb b gy nm nb l nc nd">assert  np.array_equal(my_confusion_matrix(df.actual_label.values, df.predicted_LR.values),confusion_matrix(df.actual_label.values, df.predicted_LR.values) ), 'my_confusion_matrix() is not correct for LR'</span></pre><p id="3421" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">给定这四个桶(TP，FP，FN，TN)，我们可以计算许多其他性能指标。</p><h2 id="32ac" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated">准确性 _ 得分</h2><p id="0fd0" class="pw-post-body-paragraph ju jv iq jw b jx mr jz ka kb ms kd ke kf mt kh ki kj mu kl km kn mv kp kq kr ij bi translated">最常见的分类指标是准确度，即预测正确的样本比例，如下所示:</p><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi no"><img src="../Images/ee34116e35d5a84a4977702d63c970f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*N4Lo9Miw397g3XpX7o0CDw.png"/></div></div></figure><p id="9660" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们可以从 scikit-learn 获得准确度分数，它将实际标签和预测标签作为输入</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="6a84" class="lq lr iq lb b gy na nb l nc nd">from sklearn.metrics import accuracy_score</span><span id="79b3" class="lq lr iq lb b gy nm nb l nc nd">accuracy_score(df.actual_label.values, df.predicted_RF.values)</span></pre><p id="8b71" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">你的答案应该是 0。38660 . 68868686861</p><p id="97f9" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">使用上面的公式，定义你自己的复制<code class="fe ky kz la lb b">accuracy_score</code>的函数。</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="e8bb" class="lq lr iq lb b gy na nb l nc nd">def my_accuracy_score(y_true, y_pred):<br/>    # calculates the fraction of samples predicted correctly<br/>    TP,FN,FP,TN = find_conf_matrix_values(y_true,y_pred)  <br/>    return # your code here</span><span id="1a9f" class="lq lr iq lb b gy nm nb l nc nd">assert my_accuracy_score(df.actual_label.values, df.predicted_RF.values) == accuracy_score(df.actual_label.values, df.predicted_RF.values), 'my_accuracy_score failed on RF'<br/>assert my_accuracy_score(df.actual_label.values, df.predicted_LR.values) == accuracy_score(df.actual_label.values, df.predicted_LR.values), 'my_accuracy_score failed on LR'<br/>print('Accuracy RF: %.3f'%(my_accuracy_score(df.actual_label.values, df.predicted_RF.values)))<br/>print('Accuracy LR: %.3f'%(my_accuracy_score(df.actual_label.values, df.predicted_LR.values)))</span></pre><p id="6abe" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">使用精确度作为性能度量，RF 模型比 LR 模型(0.62)更精确(0.67)。那么我们是否应该就此打住，说 RF 模型是最好的模型呢？不要！准确性并不总是评估分类模型的最佳指标。例如，假设我们试图预测一件 100 次中只有 1 次发生的事情。我们可以建立一个模型，通过说事件从未发生，获得 99%的准确性。然而，我们抓住了 0%我们关心的事件。这里的 0%度量是另一个称为召回的性能度量。</p><h2 id="61dd" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated">回忆 _ 分数</h2><p id="41b8" class="pw-post-body-paragraph ju jv iq jw b jx mr jz ka kb ms kd ke kf mt kh ki kj mu kl km kn mv kp kq kr ij bi translated">回忆(也称为敏感度)是您正确预测的阳性事件的比例，如下所示:</p><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/26a18503574aec3cb3750b523478389a.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*nCMqH8BnHgsaxY6mcP6cAQ.png"/></div></figure><p id="517e" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们可以从 scikit-learn 获得准确度分数，它将实际标签和预测标签作为输入</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="2786" class="lq lr iq lb b gy na nb l nc nd">from sklearn.metrics import recall_score</span><span id="fb94" class="lq lr iq lb b gy nm nb l nc nd">recall_score(df.actual_label.values, df.predicted_RF.values)</span></pre><p id="2ef2" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">使用上面的公式定义您自己的复制<code class="fe ky kz la lb b">recall_score</code>的函数。</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="f651" class="lq lr iq lb b gy na nb l nc nd">def my_recall_score(y_true, y_pred):<br/>    # calculates the fraction of positive samples predicted correctly<br/>    TP,FN,FP,TN = find_conf_matrix_values(y_true,y_pred)  <br/>    return # your code here</span><span id="d869" class="lq lr iq lb b gy nm nb l nc nd">assert my_recall_score(df.actual_label.values, df.predicted_RF.values) == recall_score(df.actual_label.values, df.predicted_RF.values), 'my_accuracy_score failed on RF'<br/>assert my_recall_score(df.actual_label.values, df.predicted_LR.values) == recall_score(df.actual_label.values, df.predicted_LR.values), 'my_accuracy_score failed on LR'<br/>print('Recall RF: %.3f'%(my_recall_score(df.actual_label.values, df.predicted_RF.values)))<br/>print('Recall LR: %.3f'%(my_recall_score(df.actual_label.values, df.predicted_LR.values)))</span></pre><p id="0faf" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">提高召回率的一种方法是通过降低预测阳性的阈值来增加您定义为预测阳性的样本数量。不幸的是，这也会增加误报的数量。另一个称为精度的性能指标考虑到了这一点。</p><h2 id="b6d4" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated">精度分数</h2><p id="ab9b" class="pw-post-body-paragraph ju jv iq jw b jx mr jz ka kb ms kd ke kf mt kh ki kj mu kl km kn mv kp kq kr ij bi translated">精度是预测的阳性事件中实际为阳性的部分，如下所示:</p><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/554c4ae154c909a5e33be1e296d1ec63.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*M7LtRth4_A4Hwa_lgRDeIg.png"/></div></figure><p id="7f56" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们可以从 scikit-learn 获得准确度分数，它将实际标签和预测标签作为输入</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="8df0" class="lq lr iq lb b gy na nb l nc nd">from sklearn.metrics import precision_score</span><span id="2a89" class="lq lr iq lb b gy nm nb l nc nd">precision_score(df.actual_label.values, df.predicted_RF.values)</span></pre><p id="1c59" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">使用上面的公式，定义您自己的复制<code class="fe ky kz la lb b">precision_score</code>的函数。</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="b8c4" class="lq lr iq lb b gy na nb l nc nd">def my_precision_score(y_true, y_pred):<br/>    # calculates the fraction of predicted positives samples that are actually positive<br/>    TP,FN,FP,TN = find_conf_matrix_values(y_true,y_pred)  <br/>    return # your code here</span><span id="027e" class="lq lr iq lb b gy nm nb l nc nd">assert my_precision_score(df.actual_label.values, df.predicted_RF.values) == precision_score(df.actual_label.values, df.predicted_RF.values), 'my_accuracy_score failed on RF'<br/>assert my_precision_score(df.actual_label.values, df.predicted_LR.values) == precision_score(df.actual_label.values, df.predicted_LR.values), 'my_accuracy_score failed on LR'<br/>print('Precision RF: %.3f'%(my_precision_score(df.actual_label.values, df.predicted_RF.values)))<br/>print('Precision LR: %.3f'%(my_precision_score(df.actual_label.values, df.predicted_LR.values)))</span></pre><p id="7439" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">在这种情况下，看起来 RF 模型在召回率和精确度上都更好。但是，如果一个模型更擅长回忆，而另一个模型更擅长精确，你会怎么做。一些数据科学家使用的一种方法叫做 F1 分数。</p><h2 id="f1cc" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated">f1 _ 分数</h2><p id="50fa" class="pw-post-body-paragraph ju jv iq jw b jx mr jz ka kb ms kd ke kf mt kh ki kj mu kl km kn mv kp kq kr ij bi translated">f1 分数是召回率和精确度的调和平均值，分数越高，模型越好。f1 分数使用以下公式计算:</p><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/abe643ed8cde88882f9222628f311aca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*WaXly05rd5MIWLE5QI3cvg.png"/></div></figure><p id="dc02" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们可以从 scikit-learn 获得 f1 分数，它将实际标签和预测标签作为输入</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="569a" class="lq lr iq lb b gy na nb l nc nd">from sklearn.metrics import f1_score</span><span id="9435" class="lq lr iq lb b gy nm nb l nc nd">f1_score(df.actual_label.values, df.predicted_RF.values)</span></pre><p id="32f8" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">使用上面的公式，定义您自己的复制<code class="fe ky kz la lb b">f1_score</code>的函数。</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="a640" class="lq lr iq lb b gy na nb l nc nd">def my_f1_score(y_true, y_pred):<br/>    # calculates the F1 score<br/>    recall = my_recall_score(y_true,y_pred)  <br/>    precision = my_precision_score(y_true,y_pred)  <br/>    return # your code here</span><span id="55f7" class="lq lr iq lb b gy nm nb l nc nd">assert my_f1_score(df.actual_label.values, df.predicted_RF.values) == f1_score(df.actual_label.values, df.predicted_RF.values), 'my_accuracy_score failed on RF'<br/>assert my_f1_score(df.actual_label.values, df.predicted_LR.values) == f1_score(df.actual_label.values, df.predicted_LR.values), 'my_accuracy_score failed on LR'<br/>print('F1 RF: %.3f'%(my_f1_score(df.actual_label.values, df.predicted_RF.values)))<br/>print('F1 LR: %.3f'%(my_f1_score(df.actual_label.values, df.predicted_LR.values)))</span></pre><p id="2cff" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">到目前为止，我们假设我们定义了 0.5 的阈值来选择哪些样本被预测为阳性。如果我们改变这个阈值，性能指标将会改变。如下图所示:</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="5326" class="lq lr iq lb b gy na nb l nc nd">print('scores with threshold = 0.5')<br/>print('Accuracy RF: %.3f'%(my_accuracy_score(df.actual_label.values, df.predicted_RF.values)))<br/>print('Recall RF: %.3f'%(my_recall_score(df.actual_label.values, df.predicted_RF.values)))<br/>print('Precision RF: %.3f'%(my_precision_score(df.actual_label.values, df.predicted_RF.values)))<br/>print('F1 RF: %.3f'%(my_f1_score(df.actual_label.values, df.predicted_RF.values)))<br/>print(' ')<br/>print('scores with threshold = 0.25')<br/>print('Accuracy RF: %.3f'%(my_accuracy_score(df.actual_label.values, (df.model_RF &gt;= 0.25).astype('int').values)))<br/>print('Recall RF: %.3f'%(my_recall_score(df.actual_label.values, (df.model_RF &gt;= 0.25).astype('int').values)))<br/>print('Precision RF: %.3f'%(my_precision_score(df.actual_label.values, (df.model_RF &gt;= 0.25).astype('int').values)))<br/>print('F1 RF: %.3f'%(my_f1_score(df.actual_label.values, (df.model_RF &gt;= 0.25).astype('int').values)))</span></pre><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/0a5711f92031ef4ce8ee591ef2fa32ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*9gYq8pjzXmFC_waFHIfxSA.png"/></div></figure><p id="1228" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">如果我们没有选择阈值，我们如何评估一个模型？一种非常常用的方法是使用受试者工作特性(ROC)曲线。</p><h2 id="29a5" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated">roc 曲线和 roc AUC 分数</h2><p id="e921" class="pw-post-body-paragraph ju jv iq jw b jx mr jz ka kb ms kd ke kf mt kh ki kj mu kl km kn mv kp kq kr ij bi translated">ROC 曲线非常有助于理解真阳性率和假阳性率之间的平衡。Sci-kit learn 内置了 ROC 曲线和分析这些曲线的功能。这些函数(<code class="fe ky kz la lb b">roc_curve</code>和<code class="fe ky kz la lb b">roc_auc_score</code>)的输入是实际标签和预测概率(不是预测标签)。<code class="fe ky kz la lb b">roc_curve</code>和<code class="fe ky kz la lb b">roc_auc_score</code>都是复杂的函数，所以我们不会让你从头开始写这些函数。相反，我们将向您展示如何使用 sci-kit learn 的功能，并解释其中的关键点。让我们从使用<code class="fe ky kz la lb b">roc_curve</code>制作 ROC 图开始。</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="99a3" class="lq lr iq lb b gy na nb l nc nd">from sklearn.metrics import roc_curve</span><span id="2897" class="lq lr iq lb b gy nm nb l nc nd">fpr_RF, tpr_RF, thresholds_RF = roc_curve(df.actual_label.values, df.model_RF.values)<br/>fpr_LR, tpr_LR, thresholds_LR = roc_curve(df.actual_label.values, df.model_LR.values)</span></pre><p id="eb0d" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated"><code class="fe ky kz la lb b">roc_curve</code>函数返回三个列表:</p><ul class=""><li id="486a" class="lc ld iq jw b jx jy kb kc kf le kj lf kn lg kr lh li lj lk bi translated">阈值=按降序排列的所有唯一预测概率</li><li id="8184" class="lc ld iq jw b jx ll kb lm kf ln kj lo kn lp kr lh li lj lk bi translated">fpr =每个阈值的假阳性率(FP / (FP + TN))</li><li id="5567" class="lc ld iq jw b jx ll kb lm kf ln kj lo kn lp kr lh li lj lk bi translated">tpr =每个阈值的真实阳性率(TP / (TP + FN))</li></ul><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nf ng di nh bf ni"><div class="gh gi ns"><img src="../Images/d34157e8cd2824ac234ee9a51addd8d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xol1v1mdRKBtXUAW-IJDgw.png"/></div></div></figure><p id="f84f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们可以为每个模型绘制 ROC 曲线，如下所示。</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="480d" class="lq lr iq lb b gy na nb l nc nd">import matplotlib.pyplot as plt</span><span id="8c44" class="lq lr iq lb b gy nm nb l nc nd">plt.plot(fpr_RF, tpr_RF,'r-',label = 'RF')<br/>plt.plot(fpr_LR,tpr_LR,'b-', label= 'LR')<br/>plt.plot([0,1],[0,1],'k-',label='random')<br/>plt.plot([0,0,1,1],[0,1,1,1],'g-',label='perfect')<br/>plt.legend()<br/>plt.xlabel('False Positive Rate')<br/>plt.ylabel('True Positive Rate')<br/>plt.show()</span></pre><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/2000ad1f1488f77873ad301f458d4879.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*ZSdwz-JEahHZLfNJyypbAA.png"/></div></figure><p id="e24f" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">从这个图中我们可以观察到一些东西:</p><ul class=""><li id="5994" class="lc ld iq jw b jx jy kb kc kf le kj lf kn lg kr lh li lj lk bi translated">随机猜测标签的模型将导致黑线，并且您希望有一个在这条黑线上方有曲线的模型</li><li id="2531" class="lc ld iq jw b jx ll kb lm kf ln kj lo kn lp kr lh li lj lk bi translated">离黑线越远的 ROC 越好，所以 RF(红色)比 LR(蓝色)好看</li><li id="7392" class="lc ld iq jw b jx ll kb lm kf ln kj lo kn lp kr lh li lj lk bi translated">虽然不能直接看到，但高阈值会在左下角产生一个点，低阈值会在右上角产生一个点。这意味着，随着门槛的降低，你会以更高的 FPR 为代价获得更高的 TPR</li></ul><p id="3e57" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">为了分析性能，我们将使用曲线下面积指标。</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="f782" class="lq lr iq lb b gy na nb l nc nd">from sklearn.metrics import roc_auc_score</span><span id="2324" class="lq lr iq lb b gy nm nb l nc nd">auc_RF = roc_auc_score(df.actual_label.values, df.model_RF.values)<br/>auc_LR = roc_auc_score(df.actual_label.values, df.model_LR.values)</span><span id="aa28" class="lq lr iq lb b gy nm nb l nc nd">print('AUC RF:%.3f'% auc_RF)<br/>print('AUC LR:%.3f'% auc_LR)</span></pre><p id="c8af" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">如您所见，RF 模型的曲线下面积(AUC = 0.738)优于 LR (AUC = 0.666)。当我绘制 ROC 曲线时，我喜欢将 AUC 添加到图例中，如下所示。</p><pre class="kt ku kv kw gt mw lb mx my aw mz bi"><span id="eb0f" class="lq lr iq lb b gy na nb l nc nd">import matplotlib.pyplot as plt<br/>plt.plot(fpr_RF, tpr_RF,'r-',label = 'RF AUC: %.3f'%auc_RF)<br/>plt.plot(fpr_LR,tpr_LR,'b-', label= 'LR AUC: %.3f'%auc_LR)<br/>plt.plot([0,1],[0,1],'k-',label='random')<br/>plt.plot([0,0,1,1],[0,1,1,1],'g-',label='perfect')<br/>plt.legend()<br/>plt.xlabel('False Positive Rate')<br/>plt.ylabel('True Positive Rate')<br/>plt.show()</span></pre><figure class="kt ku kv kw gt jr gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/f5aa0aec8eca828c07579fae43e6a7e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*jVuzeTAddlTOWdLwlVkfkw.png"/></div></figure><p id="b1f0" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">总体而言，在这个玩具示例中，RF 型号在所有性能指标上都胜出。</p><h2 id="edc8" class="lq lr iq bd ls lt lu dn lv lw lx dp ly kf lz ma mb kj mc md me kn mf mg mh mi bi translated">结论</h2><p id="d038" class="pw-post-body-paragraph ju jv iq jw b jx mr jz ka kb ms kd ke kf mt kh ki kj mu kl km kn mv kp kq kr ij bi translated">在预测分析中，在两个模型之间做出决定时，选择一个性能指标非常重要。正如您在这里看到的，有许多选项可供选择(准确度、召回率、精确度、f1 分数、AUC 等)。最终，您应该使用最适合当前业务问题的性能指标。许多数据科学家更喜欢使用 AUC 来分析每个模型的性能，因为它不需要选择阈值，有助于平衡真阳性率和假阳性率。</p><p id="fdf5" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">如果您对如何改进本教程有任何建议，请留下您的评论。</p></div></div>    
</body>
</html>