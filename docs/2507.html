<html>
<head>
<title>Learning Artistic Styles from Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从图像中学习艺术风格</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learning-artistic-styles-from-images-fa14c60890c1?source=collection_archive---------7-----------------------#2018-02-02">https://towardsdatascience.com/learning-artistic-styles-from-images-fa14c60890c1?source=collection_archive---------7-----------------------#2018-02-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/92531d5279ba45fd920b5799186f2039.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*Abg7_gskNuM5fF1o2cYgGQ.jpeg"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Neural Style Transfer with my face and various other styles.</figcaption></figure><p id="5442" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">目前，科技领域正在进行一场军备竞赛，深度学习和人工智能已经成为下一个行业级术语。每个人都希望通过人工智能的成功和创新应用，取得下一个巨大的商业成功。</p><p id="6eb0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一个这样的突破是使用深度学习神经网络从数学上分离图像的内容和风格。很自然地，我们会想到将一幅图像的内容和另一幅图像的风格融合到一幅图像中。这个想法在2015年被Gatys成功实施。等人在他们的论文“<a class="ae kw" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank">一种艺术风格的神经算法”</a>。</p><p id="8241" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从那以后，对基本思想有了许多见解和改进。该算法的现代迭代现在被称为神经风格转移，自2015年问世以来取得了很大进展。你可以在本文<a class="ae kw" href="https://nurture.ai/p/fc15202b-e538-4cd0-9afb-73775151b740" rel="noopener ugc nofollow" target="_blank">这里</a>阅读更多关于改进的内容。</p><h1 id="368e" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">神经风格转移？</h1><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi lv"><img src="../Images/6418be4c5030f1b938c2b4acbf9cfca4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QR7WvbdfsO4KP5BTbaOznQ.jpeg"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image A provides the content. Image B is the final result, taking the semantic contents from Image A and the style from the smaller image.</figcaption></figure><blockquote class="me mf mg"><p id="f88f" class="jy jz mh ka b kb kc kd ke kf kg kh ki mi kk kl km mj ko kp kq mk ks kt ku kv ij bi translated">转换风格背后的核心思想是拍摄两幅图像，比如一张人的照片和一幅画，并合成一幅同时匹配照片的<strong class="ka ir">语义内容</strong> <strong class="ka ir">表示</strong>和相应艺术作品的<strong class="ka ir">风格表示</strong>的图像</p></blockquote><p id="4d4a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如上所述——我们将对图像的风格和内容表示进行数学量化。使用一个空白的或者随机生成的图像(也称为模仿品)，我们逐步地将它与期望的样式和内容表示相匹配。</p><h1 id="eaf0" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">深度学习脱颖而出！</h1><p id="4d61" class="pw-post-body-paragraph jy jz iq ka b kb ml kd ke kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv ij bi translated">那么深度学习到底是如何在这里发挥作用的呢？能够将风格和内容从图像中分离出来是怎么回事——这是人们有时很难辨别的。</p><p id="c0e3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">显然，用于深度学习的神经网络真的很擅长提出图像特征的高级和低级表示。为了形象化，让我们看看CNN的图片。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/280118f6fb8f6b855a4dda5ef3449c0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*XrQ4e9J4RU3jEBpghN7yzw.jpeg"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Style and content representations taken at each layer of a Neural Network.</figcaption></figure><p id="bc18" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">研究网络每一层的要素表示，您会发现每一层都会逐渐产生一个抽象概念，即<strong class="ka ir">样式</strong>(顶部一行图像)和<strong class="ka ir">语义内容</strong>(底部一行图像)。</p><p id="e29f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在卷积神经网络(CNN)中，每一层都用来进一步抽象我们提供给它的图像的像素表示。最初，我们将向CNN提供一幅图像。但是CNN并不像我们人类那样将这张图像视为图像，而是将图像视为值的矩阵(更准确地说是张量)。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/b0c480f68a93081b515aa8fa5d902977.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*QJtTdtPhikY3KywV44L0Pw.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">A matrix representation of the image of the letter a. Pixel values closer to 1 correspond to colors closer to black white values closer to 0 correspond to a lighter hue. Image taken from <a class="ae kw" href="http://pippin.gimp.org/image_processing/chap_dir.html" rel="noopener ugc nofollow" target="_blank">http://pippin.gimp.org/image_processing/chap_dir.html</a></figcaption></figure><p id="c4ff" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在每一层，将内核应用于图像的一个小块，在整个图像上移动，最终生成图像的中间矢量表示。虽然这些生成的向量可能实际上没有任何意义，但它们允许我们捕捉图像的特征。你可以看看这篇文章，深入了解CNN是如何做到这一点的。</p><p id="a525" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">自然，这些图像绝不是风格和内容的确切定义，但这是神经网络如何感知它的。</p><h1 id="96f7" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">定义内容和风格</h1><p id="a68d" class="pw-post-body-paragraph jy jz iq ka b kb ml kd ke kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv ij bi translated">现在我们已经大致了解了图像的抽象特征在哪里(图层之间的矢量表示)。但是我们如何让他们离开CNN呢？</p><p id="5f56" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这就是我们前面提到的论文的关键贡献发挥作用的地方。</p><p id="c17f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该论文的工作基于一个流行且强大的架构(当时)，被称为<a class="ae kw" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank"> VGG </a>，它赢得了2014年ImageNet分类挑战赛。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/898447f3d807390785c05c335042a9b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*-bmWcAo1KoNWTpkaC7PaRA.jpeg"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Layers of the VGG19 neural network, taken from <a class="ae kw" href="https://ethereon.github.io/netscope/#/gist/3785162f95cd2d5fee77" rel="noopener ugc nofollow" target="_blank">https://ethereon.github.io/netscope/#/gist/3785162f95cd2d5fee77</a></figcaption></figure><p id="949a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这种架构中，特别是在“conv4_2”层的中间向量最好地代表了图像的语义内容。而style最好由以下层的特征组合来表示:“conv1_1”、“conv2_1”、“conv3_1”、“conv4_1”和“conv5_1”。你会问，我们是如何选择特定的层的？真的只是试错。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/a846e9420cd2d96d93c0c1ceaf505fb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*Sf7XZpRqxdPlbHIaaEecdQ.jpeg"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image taken from <a class="ae kw" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank">A Neural Algorithm for Artistic Style</a>. The image structures captured by the style representations increase in size and complexity when including style features from higher layers of the network. This can be explained by the increasing receptive field sizes and feature complexity along the network’s processing hierarchy.</figcaption></figure><p id="8dfc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这个想法是，你在神经网络中的位置越低(越接近对物体进行分类)，特征向量就越能代表图像的语义内容。而网络中的高层能够更好地捕捉图像的风格。</p><h1 id="c474" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">秘密成分</h1><p id="6427" class="pw-post-body-paragraph jy jz iq ka b kb ml kd ke kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv ij bi translated">既然我们已经弄清楚了样式和内容表示，我们需要一种方法来迭代地匹配随机生成的白噪声图像(我们的仿作)和表示。</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi mu"><img src="../Images/0c2ad6b9f65e092e57526fc4ff484a8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XnpHmR7gG_RkSirWvpItZw.jpeg"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">A randomly generated white noise image, which we will iteratively match to the style and content representations.</figcaption></figure><blockquote class="me mf mg"><p id="5998" class="jy jz mh ka b kb kc kd ke kf kg kh ki mi kk kl km mj ko kp kq mk ks kt ku kv ij bi translated">为了可视化在层级的不同层编码的图像信息，我们在白噪声图像上执行梯度下降，以找到与原始图像的特征响应相匹配的另一个图像。</p></blockquote><p id="ddc9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，我们定义了内容表示和我们的仿作之间的平方误差损失:</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/fe34d3a9b042fd329759b14c0d9bc69d.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*FMBybOhol4bVVrURgzh5Tg.jpeg"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">The content loss</figcaption></figure><p id="5eee" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">其中向量P是原始图像，向量x是生成的图像，并且<em class="mh"> P_l </em>和<em class="mh"> F_l </em>在层<em class="mh"> l </em>中它们各自的特征表示。</p><p id="f3f7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由此可以使用标准误差反向传播来计算生成图像的梯度w.r.t.。因此，我们可以逐步更新随机白噪声图像，直到它在“conv4_2”层中给出与我们想要从中获取语义内容的图像相同的响应。</p><h1 id="7350" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">输入克矩阵</h1><p id="4dff" class="pw-post-body-paragraph jy jz iq ka b kb ml kd ke kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv ij bi translated">然而，风格并不直截了当。我们首先构建一个样式表示<br/>,它计算不同滤波器响应之间的相关性。这是通过<a class="ae kw" href="https://en.wikipedia.org/wiki/Gramian_matrix" rel="noopener ugc nofollow" target="_blank">克矩阵</a>完成的:</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/c03167ac0bc8c38aa6a43aede577015e.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*PBpc80QUKmGHuueZwBcNTw.jpeg"/></div></figure><p id="2021" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">其中<em class="mh"> G^l_ij </em>是层<em class="mh"> l </em>中矢量化特征<em class="mh"> i </em>和<em class="mh"> j </em>的内积。关于为什么Gram矩阵可以捕捉样式信息的更多信息可以在<a class="ae kw" href="https://arxiv.org/abs/1701.01036" rel="noopener ugc nofollow" target="_blank">本文</a>中找到。</p><p id="f61a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">通过最小化来自原始图像的Gram矩阵和要生成的图像的Gram矩阵的条目之间的均方距离，我们可以使用来自白噪声图像的梯度下降来找到与原始图像的风格表示相匹配的另一个图像。</p><p id="6e4f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">风格的损失定义为:</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/26774ee83e2b70f261afa896f3a92aba.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*1qqWAYfJ1pcp4qXvZYN9Pw.jpeg"/></div></figure><p id="6057" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">其中<em class="mh"> E_l </em>为:</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi my"><img src="../Images/44b7dcafa83ea90e2e046b9dd3a267cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*_dG01vAQLgP_CnymJFBgRg.jpeg"/></div></figure><p id="c1b5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="mh"> G </em>和<em class="mh"> A </em>分别是<em class="mh"> l </em>层中原始图像和生成图像的风格的Gram矩阵表示。然后，可以使用类似于上述内容表示的标准误差反向传播来计算梯度。</p><h2 id="dcc9" class="mz ky iq bd kz na nb dn ld nc nd dp lh kj ne nf ll kn ng nh lp kr ni nj lt nk bi translated">把它们放在一起</h2><p id="5d09" class="pw-post-body-paragraph jy jz iq ka b kb ml kd ke kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv ij bi translated">现在，我们已经拥有了生成图像所需的所有要素，给定了一个我们想要从中学习风格的图像和一个我们想要从中学习内容的图像。</p><blockquote class="me mf mg"><p id="eb3c" class="jy jz mh ka b kb kc kd ke kf kg kh ki mi kk kl km mj ko kp kq mk ks kt ku kv ij bi translated">为了生成将照片的内容与绘画风格混合的图像，我们共同最小化白噪声图像与网络的一层中的照片的内容表示和CNN的多层中的绘画风格表示的距离。</p></blockquote><p id="dd97" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们最小化以下损失函数:</p><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/af5a01b38b95d918c9503294ad6cd2eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*bUcSnH4-1yqASSneohxDRA.jpeg"/></div></figure><p id="5e89" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">其中<em class="mh">α</em>和<em class="mh">β</em>是用于在新图像的构建期间确定总体贡献的权重。</p><h1 id="2c6e" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">如果呢？</h1><p id="d33a" class="pw-post-body-paragraph jy jz iq ka b kb ml kd ke kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv ij bi translated">尽管这篇文章是在2018年写的，但所描述的技术并不新，而且已经存在多年了。</p><p id="312f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">事实上，已经对现有模型进行了大量的改进和修改，极大地提升了它的许多方面的性能，例如<a class="ae kw" href="https://arxiv.org/abs/1612.04337" rel="noopener ugc nofollow" target="_blank">提高风格转换的速度</a>、<a class="ae kw" href="https://arxiv.org/abs/1701.01036" rel="noopener ugc nofollow" target="_blank">减少损失以生成更好的图像</a>、<a class="ae kw" href="https://deepart.io/" rel="noopener ugc nofollow" target="_blank">制作艺术</a>(这是由论文的原作者制作的)等等。</p><p id="657d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最让我感兴趣的是，我曾经认为抽象和不可量化的东西——即图像的抽象风格和内容——现在可以用数学来表示。自然，这使人想知道同样的事情是否可以用于其他抽象的品质。不仅仅是图像，而是所有形式的媒介，无论是视频还是文本。</p><p id="d313" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果情感、动机和情节等抽象概念也可以量化，那会怎样？那我们该拿这些做什么？我们生活在令人兴奋的时代，我迫不及待地想看看更多的技术和人工智能能给我们的文化带来什么。</p></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><p id="09f6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="mh">觉得这个有用？请随意击碎拍手，并检查我的其他作品。</em>😄</p><p id="cce2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="mh">李中清是</em> <a class="ae kw" href="https://nurture.ai/" rel="noopener ugc nofollow" target="_blank"> <em class="mh">培育的人工智能研究员。AI </em> </a> <em class="mh">。他最近从莫纳什大学计算机科学专业毕业，撰写了关于人工智能和深度学习的文章。在Twitter上关注他@</em><a class="ae kw" href="https://twitter.com/JamsaWamsa" rel="noopener ugc nofollow" target="_blank"><em class="mh">jamsawamsa</em></a><em class="mh">。</em></p></div></div>    
</body>
</html>