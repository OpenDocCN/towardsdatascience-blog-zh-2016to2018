<html>
<head>
<title>Mouse Cursor Control Using Facial Movements — An HCI Application</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用面部动作控制鼠标光标——一个人机交互应用程序</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/mouse-control-facial-movements-hci-app-c16b0494a971?source=collection_archive---------3-----------------------#2018-10-07">https://towardsdatascience.com/mouse-control-facial-movements-hci-app-c16b0494a971?source=collection_archive---------3-----------------------#2018-10-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="e436" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个用 Python(3.6)编写的 HCI(人机交互)应用程序可以让你通过面部动作控制鼠标光标，只需普通的网络摄像头就能工作。它是免提的，不需要可穿戴的硬件或传感器。</p><p id="fb95" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">特别感谢<strong class="jp ir">阿德里安·罗斯布鲁克</strong>令人惊叹的博客帖子【2】【3】、代码片段和他的<a class="ae kl" href="https://github.com/jrosebr1/imutils" rel="noopener ugc nofollow" target="_blank"> imutils </a>库【7】，它们在实现我的想法中发挥了重要作用。</p><h1 id="d2f6" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">工作示例</h1><figure class="lk ll lm ln gt lo"><div class="bz fp l di"><div class="lp lq l"/></div></figure><h1 id="7484" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">使用</h1><p id="c770" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">现在，我完全理解这些面部动作做起来可能有点奇怪，尤其是当你在人群中的时候。作为一名<a class="ae kl" href="https://www.healthline.com/health/benign-positional-vertigo" rel="noopener ugc nofollow" target="_blank">良性位置性眩晕</a>的患者，我讨厌自己做这些动作。但我希望随着时间的推移，它们会变得更容易，不那么怪异。请随意建议一些我可以纳入该项目的公共友好行动。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi lw"><img src="../Images/70f664983004d5c8a0f180a07a9df173.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OqOtL0Sffvqk86jG5sGAFw.jpeg"/></div></div></figure><h1 id="3bb3" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">密码</h1><p id="0881" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">您可以在以下位置找到代码文件:</p><div class="md me gp gr mf mg"><a href="https://github.com/acl21/Mouse_Cursor_Control_Handsfree" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab fo"><div class="mi ab mj cl cj mk"><h2 class="bd ir gy z fp ml fr fs mm fu fw ip bi translated">ACL 21/Mouse _ Cursor _ Control _ 免提</h2><div class="mn l"><h3 class="bd b gy z fp ml fr fs mm fu fw dk translated">Python(3.6)中的这个 HCI(人机交互)应用程序将允许你用你的…</h3></div><div class="mo l"><p class="bd b dl z fp ml fr fs mm fu fw dk translated">github.com</p></div></div><div class="mp l"><div class="mq l mr ms mt mp mu mb mg"/></div></div></a></div><h2 id="ed5c" class="mv kn iq bd ko mw mx dn ks my mz dp kw jy na nb la kc nc nd le kg ne nf li ng bi translated">使用的库</h2><ul class=""><li id="d0dc" class="nh ni iq jp b jq lr ju ls jy nj kc nk kg nl kk nm nn no np bi translated">Numpy — 1.13.3</li><li id="7b15" class="nh ni iq jp b jq nq ju nr jy ns kc nt kg nu kk nm nn no np bi translated">OpenCV — 3.2.0</li><li id="024f" class="nh ni iq jp b jq nq ju nr jy ns kc nt kg nu kk nm nn no np bi translated">PyAutoGUI — 0.9.36</li><li id="b944" class="nh ni iq jp b jq nq ju nr jy ns kc nt kg nu kk nm nn no np bi translated">Dlib — 19.4.0</li><li id="0a97" class="nh ni iq jp b jq nq ju nr jy ns kc nt kg nu kk nm nn no np bi translated">Imutils — 0.4.6</li></ul><p id="3010" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">repo 的 README.md 中提到了执行步骤。如果有任何错误，请随时提出问题。</p><h1 id="88e9" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">它是如何工作的</h1><p id="0cf9" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">这个项目的核心是预测给定人脸的面部标志。我们可以利用这些地标完成很多事情。从检测视频中的眨眼到预测受试者的情绪。面部标志的应用、结果和可能性是巨大而有趣的。</p><p id="7761" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="http://dlib.net/" rel="noopener ugc nofollow" target="_blank"> Dlib </a>的预建模型，本质上是【4】的实现，不仅可以进行快速人脸检测，还可以让我们准确预测 68 个 2D 面部标志。非常方便。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi nv"><img src="../Images/c887d83dbd8ee2b406e298a713651146.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EZ9o_UGKR6Z-F_Ea2jmyGg.jpeg"/></div></div></figure><p id="25c6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用这些预测的面部标志，我们可以建立适当的特征，这将进一步允许我们检测某些行为，如使用眼睛纵横比(下面将详细介绍)来检测眨眼或眨眼，使用嘴巴纵横比来检测打哈欠等，甚至可能是噘嘴。在这个项目中，这些动作被编程为控制鼠标光标的触发器。<a class="ae kl" href="http://pyautogui.readthedocs.io" rel="noopener ugc nofollow" target="_blank"> PyAutoGUI </a>库用于移动光标。</p><h2 id="3f80" class="mv kn iq bd ko mw mx dn ks my mz dp kw jy na nb la kc nc nd le kg ne nf li ng bi translated">眼睛长宽比(耳朵)</h2><p id="6270" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">你会发现眼睛长宽比[1]是最简单也是最优雅的特征，它很好地利用了面部标志。耳朵帮助我们发现眨眼和眨眼等动作。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi nw"><img src="../Images/5cb551abea976f2797ba867844917292.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Ix1R90EmXixWYd5MGSJdQ.png"/></div></div></figure><p id="50df" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可以看到，每当眼睛闭上时，耳朵值就会下降。我们可以训练一个简单的分类器来检测下落。然而，正常的<em class="nx"> if </em>条件工作正常。大概是这样的:</p><pre class="lk ll lm ln gt ny nz oa ob aw oc bi"><span id="b19c" class="mv kn iq nz b gy od oe l of og">if EAR &lt;= SOME_THRESHOLD:<br/>      EYE_STATUS = 'CLOSE'</span></pre><h2 id="8b80" class="mv kn iq bd ko mw mx dn ks my mz dp kw jy na nb la kc nc nd le kg ne nf li ng bi translated">嘴部长宽比</h2><p id="1852" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">受到耳朵功能的高度启发，我稍微调整了一下公式，以获得一个可以检测张开/闭合嘴的度量。没有创意，但很管用。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi oh"><img src="../Images/8ce81addc866a5c125106efc80448b47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LC6YYNhB3aIzMTMVMY5Pdg.jpeg"/></div></div></figure><p id="93fd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与耳朵类似，当嘴张开时，MAR 值上升。类似的直觉也适用于这一指标。</p><h1 id="54aa" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">预建模型详细信息</h1><p id="50c4" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">该模型提供了两个重要的功能。检测面部的检测器和预测界标的预测器。所使用的面部检测器是使用结合了线性分类器、图像金字塔和滑动窗口检测方案的经典梯度方向直方图(HOG)特征制成的。</p><p id="ba77" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">面部标志估计器是通过使用 Dlib 的论文实现来创建的:<a class="ae kl" href="https://www.semanticscholar.org/paper/One-millisecond-face-alignment-with-an-ensemble-of-Kazemi-Sullivan/1824b1ccace464ba275ccc86619feaa89018c0ad" rel="noopener ugc nofollow" target="_blank"> <em class="nx">一毫秒面部对齐与瓦希德·卡泽米和约瑟芬·沙利文</em> </a>的回归树集合，CVPR 2014。并在 iBUG 300-W 人脸地标数据集上进行训练:C. Sagonas，E. Antonakos，G，Tzimiropoulos，S. Zafeiriou，M. Pantic。300 人面临野外挑战:数据库和结果。<a class="ae kl" href="https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/" rel="noopener ugc nofollow" target="_blank"> <em class="nx">图像与视觉计算(IMAVIS)，面部地标定位“野外”特刊。2016 </em> </a>。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi oi"><img src="../Images/16806a5585bec2fa592726a03005f816.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rmy_Dtu2Dd5h5QbvbKbpag.png"/></div></div></figure><p id="7512" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可以从<a class="ae kl" href="http://dlib.net/files," rel="noopener ugc nofollow" target="_blank">http://dlib.net/files,</a>点击<strong class="jp ir">shape _ predictor _ 68 _ face _ landmarks . dat . bz2</strong>获得训练好的模型文件。模型，。dat 文件必须在项目文件夹中。</p><p id="372c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">注意:</strong>iBUG 300-W 数据集的许可不包括商业用途。因此，您应该联系伦敦帝国理工学院，了解您是否可以在商业产品中使用该模型文件。</p><h1 id="496c" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">参考</h1><p id="ea0c" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated"><strong class="jp ir">【1】</strong>。Tereza Soukupova 和 Jan Cˇ ech。<a class="ae kl" href="https://vision.fe.uni-lj.si/cvww2016/proceedings/papers/05.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="nx">利用面部标志点进行实时眨眼检测</em> </a>。2016 年 2 月，第 21 届计算机视觉冬季研讨会。<br/><strong class="jp ir">【2】</strong>。艾德里安·罗斯布鲁克。<a class="ae kl" href="https://www.pyimagesearch.com/2017/04/10/detect-eyes-nose-lips-jaw-dlib-opencv-python/" rel="noopener ugc nofollow" target="_blank"> <em class="nx">用 dlib、OpenCV、Python </em> </a>检测眼睛、鼻子、嘴唇、下巴。<br/><strong class="jp ir">【3】</strong>。艾德里安·罗斯布鲁克。<a class="ae kl" href="https://www.pyimagesearch.com/2017/04/24/eye-blink-detection-opencv-python-dlib/" rel="noopener ugc nofollow" target="_blank"> <em class="nx">用 OpenCV、Python 和 dlib </em> </a>进行眨眼检测。<br/><strong class="jp ir">【4】</strong>。瓦希德·卡泽米约瑟芬·苏利文。<a class="ae kl" href="https://ieeexplore.ieee.org/document/6909637" rel="noopener ugc nofollow" target="_blank"> <em class="nx">一毫秒人脸对齐与回归树</em> </a>系综。2014 年在 CVPR。<br/><strong class="jp ir">【5】</strong>。S. Zafeiriou、G. Tzimiropoulos 和 M. Pantic。<a class="ae kl" href="http://ibug.doc.ic.ac.uk/resources/300-VW/.3" rel="noopener ugc nofollow" target="_blank"> <em class="nx">野外 300 视频(300-VW)面部标志追踪野外挑战</em> </a>。在 2015 年 ICCV 研讨会上。<br/><strong class="jp ir"><br/></strong>。c .萨戈纳斯、G. Tzimiropoulos、S. Zafeiriou、M. Pantic。<a class="ae kl" href="https://ibug.doc.ic.ac.uk/media/uploads/documents/sagonas_iccv_2013_300_w.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="nx">野外 300 张人脸挑战赛:首届人脸地标定位挑战赛</em> </a>。IEEE 国际会议论文集。在计算机视觉(ICCV-W)，300 面临野外挑战(300-W)。澳大利亚悉尼，2013 年 12 月<br/><strong class="jp ir">【7】</strong>。艾德里安·罗斯布鲁克。<em class="nx"> Imutils </em>。<a class="ae kl" href="https://github.com/jrosebr1/imutils" rel="noopener ugc nofollow" target="_blank">https://github.com/jrosebr1/imutils</a>。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi oj"><img src="../Images/de4debd297463049509dce9f1a974051.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GENBf59JzMt8oSNmH75mEA.jpeg"/></div></div><figcaption class="ok ol gj gh gi om on bd b be z dk">Photo by <a class="ae kl" href="https://unsplash.com/photos/28XgB4jULqg?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Orysya Dibrova</a> on <a class="ae kl" href="https://unsplash.com/search/photos/computer-mouse-handsfree?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div></div>    
</body>
</html>