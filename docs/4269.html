<html>
<head>
<title>What’s WRONG with Metrics?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">度量标准有什么问题？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/choosing-the-right-metric-is-a-huge-issue-99ccbe73de61?source=collection_archive---------3-----------------------#2018-08-03">https://towardsdatascience.com/choosing-the-right-metric-is-a-huge-issue-99ccbe73de61?source=collection_archive---------3-----------------------#2018-08-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/8a5b1376b0422be8fa8229c433e15ea2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V4KSdNgvBpBPHjpI9vV5SA.jpeg"/></div></div></figure><p id="fb18" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi kw translated">或者任何类型的机器学习问题，你<strong class="ka ir">必须</strong>知道你将如何评估你的结果，或者评估标准是什么。</p><p id="00f0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在本帖中，我们将查看<strong class="ka ir">最常见的指标</strong>，并根据目标和我们试图解决的问题讨论每个指标的有用性。</p><h1 id="ac62" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">分类指标</h1><h2 id="e2ef" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated">准确(性)</h2><p id="f9ac" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">可能是分类器性能的最直接和直观的度量。它只是简单地计算我们在预测总数中预测正确类别的次数。</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/5fa71111e55a0789d12eb51981e81a36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*vybvyaIUIQ5JjERWlb2_uQ.png"/></div></figure><p id="5ab0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">当面对阶级不平衡的问题时，准确性显然是一个错误的衡量标准</strong>。假设你有两个类:A 类是你的数据集的 99%，B 类是剩下的 1%。通过预测每个时间案例的 A 类，您可以达到 99%的准确率。这看起来是个好成绩，但事实并非如此。</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/d345e09f31b6a5a39a5581e4bbf23f36.png" data-original-src="https://miro.medium.com/v2/resize:fit:370/format:webp/1*ENXQ_IF7Z1rnEu2h8stCJg.png"/></div></figure><h2 id="45cf" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated">精确度和召回率</h2><p id="0671" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">一般来说，在<strong class="ka ir">召回</strong>(被如此分类的真正肯定的实例的百分比)和<strong class="ka ir">精度</strong>(真正肯定的肯定分类的百分比)之间存在权衡。</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi na"><img src="../Images/4ee02a03e40652de1ad9156923e2067b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*aC4mQKv-qR8xykNx9251ZQ.png"/></div></div></figure><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/03e04d07db39ab711147c71dab1a9197.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*y-dMFo9EfaCKHXJevwKOEQ.png"/></div></figure><p id="b540" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在您想要检测少数类的实例的情况下，您通常更关心召回率而不是精确度。正如在欺诈检测的情况下，错过正面实例通常比错误地标记负面实例代价更高。</p><h2 id="72d5" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated">f-测度</h2><p id="c60b" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">我们都希望的理想场景是拥有高精度<strong class="ka ir">和</strong>高召回率！</p><p id="6828" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但要选择你的最佳模式，你需要一个单一的数字性能总结。F1 得分是精确度和召回率的调和平均值:</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nc"><img src="../Images/6b62f734018d2c41593afe8c7b839434.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*zecyXGxeN04Ccb18NaATqQ.png"/></div></div></figure><p id="3a30" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">F1 分数<strong class="ka ir">没有一个很好的直观解释</strong>，它是一个被称为 F-Beta 分数的指标的特例，F-Beta 分数衡量的是用户对回忆的重视程度是对精确度的重视程度的β倍。</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/076b31db892a73cd27033aa2b36c0682.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*2YIU9iAzaE_g91vv2XU7Ew.png"/></div></figure><h2 id="e18f" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated">卡帕</h2><p id="b024" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated"><strong class="ka ir"> Kappa </strong>或 Cohen 的 Kappa 类似于分类准确性，只是它是在数据集的随机机会基线上进行标准化的:</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/ca475c122ba6614aca10782f496b82a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:416/format:webp/1*uuJ_PlgMMwZVcyn6dQoYjQ.png"/></div></figure><p id="ecfa" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">其中 po 是观察到的一致，pe 是预期的一致。</p><p id="9569" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">它基本上告诉你你的分类器(po)的性能比一个简单地根据每个类(pe)的频率随机猜测的分类器的性能好多少。</p><p id="16b3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">没有标准化的方法来解释它的值。<a class="ae nf" href="https://www.ncbi.nlm.nih.gov/pubmed/843571" rel="noopener ugc nofollow" target="_blank">兰迪斯和科赫(1977) </a>提供了一种表征价值观的方法。根据他们的方案，a 值 0 表示不同意，0-0.20 表示轻微，0.21-0.40 表示一般，0.41-0.60 表示一般，0.61-0.80 表示基本同意，0.81-1 表示几乎完全同意。</p><h2 id="8f27" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated">罗马纪元</h2><p id="9874" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">这是业内使用的流行指标之一。</p><p id="8345" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">AUC 代表曲线下面积。该曲线可以代表 ROC 曲线或 PR 曲线。</p><blockquote class="ng nh ni"><p id="d44d" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated">PR 曲线说明了在不同阈值设置下<strong class="ka ir">精度</strong>和<strong class="ka ir">召回</strong>之间的权衡。</p><p id="7fe0" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated">ROC 曲线是通过在不同的阈值设置下绘制<strong class="ka ir"> TPR </strong>(真阳性率)，也称为灵敏度，相对于<strong class="ka ir"> FPR </strong>(假阳性率)，也称为特异性而创建的。</p></blockquote><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nn"><img src="../Images/200ad476b228bd0d27aa4aeb395e3152.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b7KR6yPf2NlUhlxLcVKRZA.png"/></div></div></figure><p id="9a3f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">以下是 ROC 曲线绘制的可视化效果:</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi no"><img src="../Images/a1c01c3d6dacbb5fa22300d0863493df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*foMOQk2yPp745FTxhL8SCg.gif"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Each point on the ROC curve (left)<strong class="bd nt"> </strong>represents a different cutoff value — The curves on the right represent the Class-Conditional Probabilities</figcaption></figure><p id="a5b8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们看看当重叠部分的百分比增加/减少时会发生什么:</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nu"><img src="../Images/f498e87782716201b2fe28544bc70987.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*8F-fY3zanGzYeCX0NlN2MQ.gif"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">ROC curve (left) and Class-Conditional Probabilities (right) — varying the the percentage of overlapping for a fixed threshold</figcaption></figure><p id="89dc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">重叠越少，误差越小，ROC 曲线向上和向左移动得越远。所以，分班越好，AUC 就越高。</p><p id="cce5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">换句话说，AUC 不在乎绝对值，<strong class="ka ir">只在乎排名</strong>。你只需要很好地分开你的类，以获得高 AUC。</p><p id="0496" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">ROC 和 PR 有什么区别？</strong></p><p id="52e0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">召回率=真阳性率(TPR)。所以区别在于精度和假阳性率。</p><p id="77dd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这两种度量的主要区别在于，精度分母包含假阳性，而假阳性率分母包含真阴性。</p><blockquote class="ng nh ni"><p id="54a6" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated">精度衡量的是被分类为阳性的样本实际上是阳性的概率，而假阳性率衡量的是阴性样本中假阳性的比率。</p></blockquote><p id="d388" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">应该用哪个？</strong></p><p id="6216" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于任何度量标准来说，这完全取决于您打算如何处理数据。如果你的模型需要在正类和负类上表现的一样好。例如，为了对猫和狗之间的图像进行分类，您希望模型在猫和狗身上都表现良好。为此，您可以使用 ROC-AUC。另一方面，如果您对模型在负类上的表现并不真正感兴趣，而只是希望确保每个正预测都是正确的(精度)，并且您得到尽可能多的正预测(回忆)，那么您应该选择 PR-AUC。</p><p id="40b2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">简而言之:</p><blockquote class="ng nh ni"><p id="a064" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated"><strong class="ka ir">使用 PR-AUC 关注小阳性类别</strong></p><p id="20c1" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated"><strong class="ka ir">当两类检测同等重要时，使用 ROC-AUC</strong></p><p id="9a3b" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated"><strong class="ka ir">当阳性结果占多数时，使用 ROC-AUC，或者切换标签，使用 precision 和 recall </strong></p></blockquote><p id="225f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">注意</strong>:许多人倾向于坚持使用 ROC，因为在大多数情况下这是一个更容易解释的指标。除此之外，计算精确的 PR 曲线就不那么直接了。(查看此<a class="ae nf" href="https://classeval.wordpress.com/introduction/introduction-to-the-precision-recall-plot/" rel="noopener ugc nofollow" target="_blank">链接</a>了解更多详情)。</p><p id="f692" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">也就是说，AUC 也有其缺点:它可能会给出潜在的误导性结果…见下图！！</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/31cedc913011173772f0d33b1784805a.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*TZZpIkWDzn53rZYQKkk9YQ.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Both models A and B have an equal area under the ROC cure. However, in the high FPR range, model B is better than A, whereas in the low FPR range model A is better than B.</figcaption></figure><p id="f78d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有些人不建议使用 AUC，原因如下:</p><blockquote class="ng nh ni"><p id="63de" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated">(1)它忽略了预测的概率值和模型的拟合优度</p><p id="201f" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated">(2)它总结了在人们很少操作的曲线空间区域上的测试性能</p><p id="745d" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated">(3)它同等重视遗漏和犯错误</p><p id="197a" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated">(4)它没有给出关于模型误差的空间分布的信息</p><p id="1c6d" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated">(5)模型执行的总程度高度影响良好预测的缺席率和 AUC 分数</p><p id="8603" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated">豪尔赫·洛沃、阿尔韦托·希门尼斯·瓦尔夫德和雷蒙多·雷亚尔</p></blockquote><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nw"><img src="../Images/0ff093297533460fc2944fc70844f0a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FEKOE-h-Aim__6JyV-g0ag.png"/></div></div></figure><h2 id="27fe" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated">部分 AUC (pAUC)</h2><p id="bb55" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">部分 AUC 已被提议作为标准 AUC 的替代措施。当使用部分 AUC 时，只考虑 ROC 空间的特定区域。</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/f0d9b7666d465c89e4ff0a154dceefc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*3VrMcUe9aaR_PcbVUgzb9w.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">pAUC denotes the area of shaded region</figcaption></figure><h2 id="e1a1" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated">双向 pAUC</h2><p id="bcb2" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">双向 pAUC 不是只限制假阳性率(FPR)，而是关注曲线下的部分区域，同时具有水平和垂直限制。已经表明，pAUC 对真阳性率(TPR)的间接控制在概念上和实践上都是误导的。</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ny"><img src="../Images/8c16f44f02b8b8f23df16bf580b1b1e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lTPcntMVRE8jv4_A9fi6Sw.png"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Two-way pAUC denotes the area of shaded region A. This shaded region is directly determined by explicit FPR upper bound p0 (= 0.5) and TPR lower bound q0 (= 0.65). In contrast, pAUC denotes the area of both region A and B. Its<strong class="bd nt"> indirect</strong> FPR lower bound (green dotted line) is determined by the TPR lower bound q0</figcaption></figure><h2 id="1494" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated">对数损失</h2><p id="e0e4" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">对数损失是基于概率的最重要的分类度量<strong class="ka ir">之一。</strong></p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nz"><img src="../Images/83e294272e597f03c00a7b41785ffaee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xOLpWWRuTwUS6vEwVg3K3g.png"/></div></div></figure><p id="ce6f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">其中 yi 是真实标签，pi 是 yi = 1 的概率。</p><p id="31ae" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">这完全是关于信心</strong>:如果对于一个特定的观察，分类器分配一个非常小的概率给正确的类，那么相应的对日志损失的贡献将会非常大。对数损失度量可以被视为精确度的“软”度量。</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/514a35548185716eadaf44336bf052c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*_iUXBdhGeJ_glKCIjRA1DQ.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">2 different models — same AUC but different LogLoss</figcaption></figure><p id="2b3b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这两个模型输出有<strong class="ka ir">相同的排名，</strong>因此<strong class="ka ir">相同的 ROC-AUC，PR-AUC </strong>！</p><p id="1d28" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但是，根据 LogLoss 值，右边的模型比左边的要好。</p><p id="41fc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是显而易见的，因为 Logloss <strong class="ka ir">包含了概率置信度的概念。</strong></p><p id="8d8c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这个指标的一个缺点是多数阶级可以支配损失！！</p></div><div class="ab cl ob oc hu od" role="separator"><span class="oe bw bk of og oh"/><span class="oe bw bk of og oh"/><span class="oe bw bk of og"/></div><div class="ij ik il im in"><h1 id="7896" class="lf lg iq bd lh li oi lk ll lm oj lo lp lq ok ls lt lu ol lw lx ly om ma mb mc bi translated">学习对指标进行排序</h1><p id="3434" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">现在让我们来看看如何评估一个搜索引擎、一个推荐系统或者任何输出商品列表的系统。</p><p id="6d08" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在研究文献中，排序“项目”被称为学习排序。</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi on"><img src="../Images/4ba86532686954fa1d7f6635a80e80a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*uXTaF72GgosbWCnLjwRJBQ.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Example of ranked urls for a given query</figcaption></figure><p id="a9ba" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">两个最流行的排名指标是地图@k 和 NDCG@k。让我们看看他们是如何工作的…</p><p id="e570" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">符号:</p><blockquote class="ng nh ni"><p id="718c" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated"><strong class="ka ir"> rel(i) </strong>是指示函数，如果等级 I 处的项目是相关的，则等于 1，否则等于 0。</p><p id="4a6e" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated"><strong class="ka ir"> P(i) </strong>是 top-i 集合中相关的返回项目的比例。</p><p id="b6a0" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated"><strong class="ka ir"> n </strong>是系统做出的预测次数。</p><p id="0580" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated"><strong class="ka ir"> m </strong>是项目全空间中相关项目的个数。</p><p id="0c54" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated"><strong class="ka ir"> Q </strong>是查询总数。</p></blockquote><p id="0ed8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了解释 MAP@k 做什么，我们需要从 AP@k 开始……</p><h2 id="4de8" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated">美联社@k</h2><p id="4b12" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">这个度量关心第 k 项的平均精度</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/a05697c8122b22fc089c0288786d461d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*Dkc25zz7dRbC9fZlCqtLTw.png"/></div></figure><p id="1176" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当推荐的数量不可能捕获所有正确的推荐时，所使用的标准化因子防止 AP@k 分数被不公平地抑制。</p><p id="a08d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">……不要担心，这里有一个简单的例子可以更好地理解公式:</p><p id="8a71" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">考虑一下，对于一个给定的查询，您必须预测一个包含多达 10 个项目的有序列表。并且只有<strong class="ka ir"> 4 </strong>个可能的正确预测(地面真相)。</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi op"><img src="../Images/7c584c3d64e249ed7ec946bf79ef9f18.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*ddkebSr26TLgnE0rxxBb9g.png"/></div></figure><p id="cc8d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于每一个预测，你都需要检查它是否正确。如果不是，你的预测就没有分数。如果它是正确的，你得到的点数等于正确预测的点数，包括这一个。</p><p id="4ab4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你除以的数就是可能的点数。换句话说，这是 10 个(你最多能预测的)和 4 个实际正确答案中的较小者。</p><p id="8372" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此:AP@10 = (1/2 + 2/3 + 3/5 + 4/9 ) / 4 = 0.55</p><h2 id="d2ab" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated">地图@k</h2><p id="5f3d" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">MAP@k 计算所有查询的平均精度(AP@k) <strong class="ka ir">的平均值。对，一个平均一个平均！！</strong></p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oq"><img src="../Images/513a75dc2371593dfe2e218c0010d418.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U_8xPCEYMFoiLseS60INDw.png"/></div></div></figure><p id="1fe5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">AP@k 是一个度量，它接受前 k 个项目的排序列表，并将其与给定查询的真实“相关”项目集的列表进行比较。AP@k 奖励你在你的列表中有很多相关的条目，并且把最可能正确的条目放在最上面。因此，<strong class="ka ir">顺序</strong> <strong class="ka ir">对于</strong>计算 AP@k 分数很重要。MAP@k 只是计算 AP@k 在所有查询中的平均值。</p><p id="838e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，让我们解释另一个流行的排名质量指标…</p><h2 id="82a4" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated">NDCG@k</h2><p id="cfbf" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">该指标声明了以下内容:</p><ol class=""><li id="ce43" class="or os iq ka b kb kc kf kg kj ot kn ou kr ov kv ow ox oy oz bi translated">非常相关的结果&gt;稍微相关的结果&gt;不相关的结果(<strong class="ka ir">C</strong>u 累计<strong class="ka ir"> G </strong> ain)。</li><li id="92bd" class="or os iq ka b kb pa kf pb kj pc kn pd kr pe kv ow ox oy oz bi translated">当相关结果出现在结果集的前面时，它们会更有用(<strong class="ka ir"> D </strong> iscounting)。</li><li id="e613" class="or os iq ka b kb pa kf pb kj pc kn pd kr pe kv ow ox oy oz bi translated">排序的结果应该与所执行的查询无关(<strong class="ka ir"> N </strong>规范化)。</li></ol><p id="1b76" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"><em class="nj">【CG】</em></strong>是检索到的候选项的相关性得分的总和。它被计算为前 k 个相关性分数的总和:</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/25e9b845937b1748a9ed3dde2552dff4.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*NYnQURU_4JxtgMslKeX0zg.png"/></div></figure><p id="4a00" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="nj">贴现 CG (DCG) </em> </strong>，基本上根据项目的位置来惩罚相关性分数。使用对数衰减:</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/5581daa6597114e2b707ab31f66dc082.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*klG8Wssng0mkCX9SYLHsSQ.png"/></div></figure><p id="dec7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">提出了一个替代方案<a class="ae nf" href="https://dl.acm.org/citation.cfm?doid=1102351.1102363" rel="noopener ugc nofollow" target="_blank"/>以更加强调检索相关项目:</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/3c56eccf4c8a77826038660416c485a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*f1vKUIYdeux9tT-LHgPDEw.png"/></div></figure><p id="56ba" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">名词（noun 的缩写）b:当相关值为二进制时，<strong class="ka ir"> DCG@k </strong>的这两个公式是相同的。</p><p id="8029" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然而，这个分数没有固定的上限，因为它取决于查询返回的结果的数量，因此为了比较不同查询的 DCG，我们必须<strong class="ka ir"> <em class="nj">将它们</em> </strong>归一化。为了实现这一点，我们将 DCG 值除以最佳可能(<strong class="ka ir"> <em class="nj">【理想】</em> </strong>)排名，得到<strong class="ka ir"><em class="nj"/></strong>，一个介于 0 和 1 之间的值。</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/ff41348386c04c44906a921aa7927c9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*ssRWaeNVuPlpjAbCF9-9lQ.png"/></div></figure><p id="8f5d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">地图@k vs NDCG@k:主要区别？</strong></p><p id="45df" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">顺序对 MAP@k 和 NDCG@k 都很重要。但主要区别是 MAP@k 假设二元相关性(一个项目是感兴趣的还是不感兴趣的)，而 NDCG@k 允许实数形式的相关性分数。</p><figure class="mv mw mx my gt jr"><div class="bz fp l di"><div class="pj pk l"/></div></figure><p id="b384" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">连续变量的度量呢？</p><h1 id="bedd" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">回归度量</h1><p id="e8e3" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">当谈到回归性能指标时，MAE 和 RMSE 是两个最流行的指标。</p><h2 id="7d66" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated">绝对平均误差</h2><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/6721ac3bf4927807a42a145c26df0392.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*kVz6tauEJSvqoUhJKwKdCw.png"/></div></figure><h2 id="63d5" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated">均方根误差</h2><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/053af76beac53b947aa4571d499e939b.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*2FuOTKbl8Zv_lqSZBuuthQ.png"/></div></figure><p id="3058" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">梅与 RMSE:应该使用哪一个？</p><p id="c3ea" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">以下几点可能有助于你做出决定:</p><blockquote class="ng nh ni"><p id="b6be" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated">当误差分布预期为高斯分布时，RMSE 比 MAE 更适合表示模型性能。</p><p id="d20d" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated">MAE 适用于描述均匀分布的误差。</p><p id="6681" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated">MAE 对异常值更稳健:最小化平方误差导致找到它的平均值，最小化绝对误差导致找到它的中值。我们都知道中位数比简单平均数对异常值更稳健。</p><p id="d888" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated">RMSE 避免使用绝对值，这在许多数学计算中是非常不可取的。例如，可能很难计算 MAEs 相对于某些模型参数的梯度。</p></blockquote><p id="c68a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">….那<strong class="ka ir"> R 呢？</strong></p><h1 id="7f09" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">r 平方</h1><p id="ec90" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">R 平方的定义相当直接:它是用线性模型解释的响应变量变化的百分比。</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi pn"><img src="../Images/d8ab3cd6240018f206a46d1b3b486872.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*Qa-yBGhyT-_ovCfcP3kaiw.png"/></div></figure><p id="5ee6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">误解:</strong> R 不在 0 和 1 之间。R 的最大值是 1，但也可能是负值。</p><p id="d51c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">R 有什么问题吗？</p><p id="7784" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">是啊！！！当增加新的预测值时，r 总是增加，不管它们是否有用:</p><blockquote class="ng nh ni"><p id="76bd" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated"><em class="iq">每当您向模型中添加一个变量时，其估计系数的值可以为零，在这种情况下，解释方差的比例保持不变，也可以采用非零值</em> <strong class="ka ir"> <em class="iq">，因为它提高了拟合的质量</em> </strong> <em class="iq">。通过构造，你的</em> R <em class="iq">不能在增加一个变量后变小- </em> <a class="ae nf" href="https://www.quora.com/Why-when-the-number-of-variables-increases-does-the-R-square-also-increase-in-linear-regression" rel="noopener ugc nofollow" target="_blank"> <em class="iq"> Maxime Phillot 在 Quora </em> </a>上的响应</p></blockquote><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/ee0c918d7c3a09834aa1c784d7fa22a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*COUXre4yBp--B-Azd2iIrQ.jpeg"/></div></figure><p id="a00b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们如何克服这个问题？</p><h2 id="78d3" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated"><strong class="ak">调整后的 R </strong></h2><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi po"><img src="../Images/522727f2782f2925ebec28c375f07f94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*YH-Hx6WHgGRJef9lODltlQ.png"/></div></figure><p id="dbfe" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">其中 n 是观察值的总数，k 是预测值的数量。</p><p id="e1fc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果添加有用的术语，该指标将会增加，如果添加不太有用的预测值，该指标将会减少。</p><h1 id="4a5c" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">更多指标！！！！</h1><h2 id="8269" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated"><strong class="ak"> NLP/NLG 指标:BLEU 和 ROUGE </strong></h2><p id="5fe4" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">这两个指标是互补的，主要用于评估文本的自动摘要和机器翻译。</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pp"><img src="../Images/c43809857e1179e87362a17ca34fa3b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0mDi2W00z7a4PAiae7mLhQ.jpeg"/></div></div></figure><h2 id="a389" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated">双语评估替补演员</h2><figure class="mv mw mx my gt jr"><div class="bz fp l di"><div class="pj pk l"/></div></figure><h2 id="0272" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated"><strong class="ak">胭脂(面向回忆的吉斯丁评价替角)</strong></h2><p id="7be2" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">胭脂只基于回忆。</p><p id="51ca" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">基于用于计算召回的特征，胭脂可以有许多类型:</p><ul class=""><li id="57e7" class="or os iq ka b kb kc kf kg kj ot kn ou kr ov kv pq ox oy oz bi translated"><strong class="ka ir"> ROUGE-N </strong>基于一元、二元、三元或更高阶的<strong class="ka ir"> N </strong> -gram 重叠。</li><li id="e1bf" class="or os iq ka b kb pa kf pb kj pc kn pd kr pe kv pq ox oy oz bi translated"><strong class="ka ir"> ROUGE-L/W/S </strong>分别基于<strong class="ka ir"> L </strong> ongest 公共子序列(LCS)、<strong class="ka ir"> W </strong> eighted LCS 和<strong class="ka ir"> S </strong> kip-bigram 共现统计。</li></ul><p id="4f17" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有关这些指标的更多信息，您可以参考林的论文。</p><h2 id="4cd1" class="md lg iq bd lh me mf dn ll mg mh dp lp kj mi mj lt kn mk ml lx kr mm mn mb mo bi translated"><strong class="ak">语音识别指标:WER(单词错误率)</strong></h2><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/96c8ac6170b0c416e1febec0eccbb324.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*sJWe43a5JwObFJ3xYcRnDQ.png"/></div></figure><p id="17f1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">WER 是用于评估 ASR(自动语音识别)系统的常用指标。这里有一个简单的方法来理解 WER 是如何计算的:</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/38f661c7c560ee44758c35bc16ab8305.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*nPzfbxGYlVAxdqjHo1WHug.png"/></div></figure><blockquote class="ng nh ni"><p id="9e04" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated">删除:</p><p id="fa09" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated"><strong class="ka ir">语音输入:</strong>我昨天连接了<br/> <strong class="ka ir"> ASR 结果:</strong>我昨天连接了</p><p id="dc03" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated">插入:</p><p id="2334" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated"><strong class="ka ir">语音输入:</strong>昨天连接了<br/> <strong class="ka ir"> ASR 结果:</strong>昨天连接了</p><p id="3fdd" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated">替代:</p><p id="235f" class="jy jz nj ka b kb kc kd ke kf kg kh ki nk kk kl km nl ko kp kq nm ks kt ku kv ij bi translated"><strong class="ka ir">语音输入:</strong>昨天连接了<br/> <strong class="ka ir"> ASR 结果:</strong>连接了是</p></blockquote><h1 id="7197" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated"><strong class="ak">奖金！</strong></h1><p id="2170" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">走到最后是你应得的。</p><p id="d403" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">以下是您可以在网上找到的挑战列表，这些挑战使用我们提供的一个指标来评估参与者模型的性能。</p><figure class="mv mw mx my gt jr"><div class="bz fp l di"><div class="pt pk l"/></div></figure><h1 id="52c1" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated"><strong class="ak">结论</strong></h1><p id="f9f2" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">没有硬性规定可以找到一个理想的指标来说明在所有情况下应该最小化/最大化什么！这完全取决于业务需求和您试图解决的问题的背景。主要的信息很简单，当定义一个问题时，度量应该被接受并扮演一个关键的角色。</p><p id="4fd8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">请继续关注，如果你喜欢这篇文章，请留下👏！</p><h1 id="aa22" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated"><strong class="ak">参考文献</strong></h1><p id="7c12" class="pw-post-body-paragraph jy jz iq ka b kb mp kd ke kf mq kh ki kj mr kl km kn ms kp kq kr mt kt ku kv ij bi translated">[1] <a class="ae nf" href="https://www2.unil.ch/biomapper/Download/Lobo-GloEcoBioGeo-2007.pdf" rel="noopener ugc nofollow" target="_blank"> Jorge M. Lobo，A. Jiménez 和 R.Raimundo，AUC:对预测分布模型性能的误导性衡量，2007 年</a></p><p id="6314" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">[1] <a class="ae nf" href="https://arxiv.org/abs/1508.00298" rel="noopener ugc nofollow" target="_blank">卢琨，双向部分 AUC 及其性质，2017 </a></p><p id="fff8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">[2] <a class="ae nf" href="https://web.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf" rel="noopener ugc nofollow" target="_blank">斯坦福大学信息检索导论课程</a></p><p id="eb0e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">[2] <a class="ae nf" href="http://www.aclweb.org/anthology/W04-1013" rel="noopener ugc nofollow" target="_blank">林金耀，胭脂:摘要自动评价软件包，2004 </a></p></div></div>    
</body>
</html>