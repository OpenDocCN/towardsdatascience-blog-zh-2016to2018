<html>
<head>
<title>Why it’s Not Difficult to Train A Neural Network with a Dynamic Structure Anymore!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么训练一个具有动态结构的神经网络不再困难！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-its-not-difficult-to-train-neural-network-with-dynamic-structure-anymore-bc5e2f67fef0?source=collection_archive---------0-----------------------#2017-02-21">https://towardsdatascience.com/why-its-not-difficult-to-train-neural-network-with-dynamic-structure-anymore-bc5e2f67fef0?source=collection_archive---------0-----------------------#2017-02-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="4d14" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">TLDR；最后，开源社区解决了神经网络中动态结构的需求。在过去的3个月中，我们看到了3个支持动态结构的主要库版本。</p><ol class=""><li id="7d52" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk kq kr ks kt bi translated"><a class="ae ku" href="https://github.com/tensorflow/fold" rel="noopener ugc nofollow" target="_blank">张量流折叠</a>(谷歌)</li><li id="70b1" class="kl km iq jp b jq kv ju kw jy kx kc ky kg kz kk kq kr ks kt bi translated"><a class="ae ku" href="https://github.com/clab/dynet" rel="noopener ugc nofollow" target="_blank">达内</a> (CMU)</li><li id="d57b" class="kl km iq jp b jq kv ju kw jy kx kc ky kg kz kk kq kr ks kt bi translated"><a class="ae ku" href="https://github.com/pytorch/pytorch" rel="noopener ugc nofollow" target="_blank"> Pytorch </a> (Twitter、NVIDIA、SalesForce、ParisTech、CMU、数字推理、INRIA、ENS)</li></ol><p id="29be" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<a class="ae ku" href="https://www.innoplexus.com/" rel="noopener ugc nofollow" target="_blank"> Innoplexus </a>，我们从结构化、非结构化和半结构化来源收集信息，以帮助我们的客户做出实时决策。为了达到这个速度，我们将自然语言中的文本从非结构化的源转换成适当结构化的表示。由于速度是一个主要的瓶颈，我们的NLP系统是基于语言的递归结构，这是由于工具的可用性和计算在多台机器上的分布。</p><p id="2209" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">随着时间的推移，我们意识到递归方法的局限性，如LSTM和GRU试图将递归自然语言纳入一个序列框架。这导致在信息处理任务中语法信息的丢失。但不幸的是，从头开始实现递归神经网络可能会变成一场噩梦，因为它涉及到以非常高的精度编写复杂的反向传播代码。</p><p id="04d8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">大多数ML库，如Tensorflow、Torch或Theano，允许创建静态网络，该网络限制了作为输入函数的网络结构的变化。这被证明是自然语言处理/理解中的重大限制，其中句法信息被编码在作为输入文本的函数而变化的解析树中。像<a class="ae ku" href="https://github.com/clab/lstm-parser" rel="noopener ugc nofollow" target="_blank">句法分析</a>、<a class="ae ku" href="https://github.com/neubig/lamtram" rel="noopener ugc nofollow" target="_blank">机器翻译</a>和<a class="ae ku" href="http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf" rel="noopener ugc nofollow" target="_blank">情感分析</a>这样的许多应用需要句法信息和语义信息。由于没有任何框架可用，开发人员不得不在Numpy中实现培训过程。这被证明是非常容易出错的，并且是必须以高精度执行的单调乏味的任务。</p><p id="ede6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们在<a class="ae ku" href="https://www.innoplexus.com/" rel="noopener ugc nofollow" target="_blank"> Innoplexus </a>实现实体提取器时遇到了类似的问题。它使用语义统一的递归神经网络，具有树状结构。由于没有任何支持动态结构的框架，我们最终在Tensorflow中实现了它。这给我们的计算图带来了沉重的负担，使得我们的训练过程缓慢，内存效率低下。此外，决定批量大小来刷新图表成为训练过程中的一个关键问题。正当我们准备在Numpy中重写整个训练过程以加快速度时，我们遇到了Dynet。</p><blockquote class="la lb lc"><p id="6868" class="jn jo ld jp b jq jr js jt ju jv jw jx le jz ka kb lf kd ke kf lg kh ki kj kk ij bi translated">DyNet(原名<a class="ae ku" href="http://github.com/clab/cnn-v1" rel="noopener ugc nofollow" target="_blank"> cnn </a>)是由卡耐基梅隆大学和其他许多人开发的神经网络库。它是用C++编写的(使用Python中的绑定)，设计为在CPU或GPU上运行时都很有效，并且适用于具有针对每个训练实例而变化的动态结构的网络。</p></blockquote><p id="2c6a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们在Dynet中重构了代码，对Tensorflow代码做了微小的修改。就可用功能而言，Dynet不如tensorflow成熟，因此我们最终为Tensorflow编写了实现。另一方面，PyTorch更加成熟，并得到了更广泛的社区的支持。您可以创建这样的动态图形:</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="gh gi lh"><img src="../Images/ed78ae2b5f1682a48c894947d6461dfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*I3_AlBEy3L7hL5_u."/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">PyTorch: Dynamic Graph Construction</figcaption></figure><p id="6e3e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Google最近推出了Fold，它包含了比tensorflow更广泛的Python对象。它提供了对结构化数据的支持，比如嵌套列表、字典和<a class="ae ku" href="https://developers.google.com/protocol-buffers/" rel="noopener ugc nofollow" target="_blank">协议缓冲区</a>。这克服了Tensorflow的静态图形限制。它的方法与PyTorch/Dynet完全不同。它使用<a class="ae ku" href="https://arxiv.org/abs/1702.02181" rel="noopener ugc nofollow" target="_blank">动态批处理</a>来并行化多个实例图中的操作。仔细看看，这很酷。简而言之，它是这样工作的:</p><figure class="li lj lk ll gt lm gh gi paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="gh gi lh"><img src="../Images/b2b718317034efbe08d235b502e762ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*DBx-ALOG4gSUb9dYNUhGRA.gif"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Tensorflow Fold: How it works.</figcaption></figure><p id="da92" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在自然语言处理领域，语言可以有不同的表达长度，因此动态计算图是必不可少的。人们可以想象语法是如何被解析来实现对堆栈和动态内存以及动态计算的需求的。Carlos E. Perez在他的<a class="ae ku" href="https://medium.com/intuitionmachine/pytorch-dynamic-computational-graphs-and-modular-deep-learning-7e7f89f18d1#.b0o0sfqzo" rel="noopener">文章</a>中恰当地总结了这一重大进展。</p><blockquote class="la lb lc"><p id="d261" class="jn jo ld jp b jq jr js jt ju jv jw jx le jz ka kb lf kd ke kf lg kh ki kj kk ij bi translated">随着这一发展，预计深度学习架构将走过与传统计算相同的进化道路将是合理的。也就是从单一的独立程序到更加模块化的程序。引入动态计算图就像引入过程的概念，而以前只有“goto”语句。正是过程的概念使我们能够以可组合的方式编写程序。当然，有人会说DL架构不需要堆栈，但人们只需要看看最近对超网络和拉伸网络的研究。在研究中的网络中，像堆栈这样的上下文切换似乎是有效的。</p></blockquote><p id="7a3c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们正在使用这些库来重构我们的代码，以便通过较小的修改从递归系统转移到递归系统。这极大地改进了我们现有的模型，并使我们能够解决以前无法解决的问题。我希望这能帮助你实现和我们一样的转变！</p><p id="4588" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">快乐黑客:D</p></div></div>    
</body>
</html>