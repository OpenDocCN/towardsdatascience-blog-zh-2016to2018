<html>
<head>
<title>Why AdamW matters</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么 AdamW 如此重要</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-adamw-matters-736223f31b5d?source=collection_archive---------1-----------------------#2018-06-03">https://towardsdatascience.com/why-adamw-matters-736223f31b5d?source=collection_archive---------1-----------------------#2018-06-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/317fb997be23919f7acc45682ad5d655.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zIZO5ilMcSNR5g-yKcg3UA.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">When you find yourself in a rocky terrain, take small steps ;) [Mount Sinai, Egypt]</figcaption></figure><div class=""/><div class=""><h2 id="76e2" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">像 Adam 这样的自适应优化器已经成为训练神经网络的默认选择。然而，当以最先进的结果为目标时，研究人员通常更喜欢带动量的随机梯度下降(SGD ),因为已经观察到用 Adam 训练的模型也不会泛化。</h2></div></div><div class="ab cl ku kv hu kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ij ik il im in"><p id="8909" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">来自德国弗赖堡大学的 Ilya Loshchilov 和 Frank Hutter 最近发表了他们的<a class="ae lx" href="https://arxiv.org/abs/1711.05101" rel="noopener ugc nofollow" target="_blank">文章</a>“在 Adam 中固定权重衰减正则化”，其中他们证明了 L2 正则化对于自适应算法的效果明显不如 SGD。他们提出了 Adam 的一个改进版本，称为 AdamW，它产生的模型概括得更好，因此能够与 SGD 竞争，同时训练得更快。</p><p id="f331" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld jg">读完这篇文章的摘要，你会理解 1) Adam 是如何工作的，2)什么是 L2 正则化，为什么使用它，以及 3)为什么改进版 AdamW 比标准 Adam 产生更好的概化模型。</strong></p><h1 id="1a38" class="ly lz jf bd ma mb mc md me mf mg mh mi kl mj km mk ko ml kp mm kr mn ks mo mp bi translated">①亚当</h1><p id="48e7" class="pw-post-body-paragraph lb lc jf ld b le mq kg lg lh mr kj lj lk ms lm ln lo mt lq lr ls mu lu lv lw ij bi translated">试着想象最小化一个神经网络的成本函数<em class="mv"> f </em>就像在山上走下山坡:你随机初始化你的网络的权重，这意味着从山上的一个随机点开始。你的目标是尽可能快地达到成本函数的最小值(谷值)。在每一步之前，你计算梯度<em class="mv"> ∇ f </em>(确定山坡最向哪个方向倾斜)并向相反方向走一步:新的权重<em class="mv"> x(t) </em>(按照文章的注释)<em class="mv"> </em>等于旧的权重<em class="mv"> x(t-1) </em>减去梯度乘以学习速率α:</p><blockquote class="mw"><p id="19c3" class="mx my jf bd mz na nb nc nd ne nf lw dk translated">x(t)= x(t-1) — α ∇ f</p></blockquote><p id="7d64" class="pw-post-body-paragraph lb lc jf ld b le ng kg lg lh nh kj lj lk ni lm ln lo nj lq lr ls nk lu lv lw ij bi translated">按照这个步骤，你最终会到达山谷(或至少是当地的最小值)，然而，当你走在坡度变化不大的草地上时，你可能想迈出更大、更大胆的步伐，或者当你爬下坡度不断变化的岩石时，迈出更小的步伐。Adams 为您做到了这一点:当梯度变化不大时大步前进，当梯度变化很快时小步前进(单独调整每种重量的步长)。</p><p id="53ad" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">让我们了解亚当是如何工作的(暂时忽略彩色部分):</p><figure class="nm nn no np gt is gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/a7ef3bedecf398572a9d16f608d27519.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*BOPnuP6VP0JVnJsoCdTo-g.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Taken from “Fixing Weight Decay Regularization in Adam” by Ilya Loshchilov, Frank Hutter.</figcaption></figure><p id="4552" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">Adam 跟踪梯度的(指数移动)平均值(称为一阶矩，从现在开始表示为<em class="mv"> m </em>)和梯度的平方(称为原始二阶矩，从现在开始表示为<em class="mv"> v </em> ) <em class="mv">。</em></p><p id="67a1" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">在每个时间步中，计算梯度<em class="mv">g=∇f</em>【x(t-1)】,然后计算移动平均值:</p><blockquote class="mw"><p id="cf5e" class="mx my jf bd mz na nb nc nd ne nf lw dk translated">m(t) = β1 m(t-1) + (1-β1) g(t)</p><p id="c0a8" class="mx my jf bd mz na nb nc nd ne nf lw dk translated">v(t) = β2 v(t-1) + (1-β2) g(t)</p></blockquote><p id="a553" class="pw-post-body-paragraph lb lc jf ld b le ng kg lg lh nh kj lj lk ni lm ln lo nj lq lr ls nk lu lv lw ij bi translated">参数β1(即 0.9)和β2(即 0.999)控制平均值衰减的速度，即“过去多长时间内对梯度(平方)进行平均”。按以下方式阅读方程式:“新平均值等于旧平均值的 0.9 倍(或梯度平方的 0.999 倍)加上当前梯度的 0.1 倍”。对于每一个时间步长，旧的梯度再乘以 0.9，这意味着它们对移动平均值的贡献越来越小。</p><p id="9c85" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">请注意，在第 9 行和第 10 行中，平均值由<em class="mv"> (1-β^t) </em>重新调整，其中<em class="mv"> t </em>是时间步长。为了理解为什么这是必要的，考虑第一个时间步长并记住<em class="mv"> m(0) </em>和<em class="mv"> v(0) </em>被初始化为 0。这意味着第一个时间步长后的平均值为<em class="mv">m(1)</em>= 0.9 0+0.1<em class="mv">g(1)</em>= 0.1<em class="mv">g(1)</em>。但是，第一个时间步长之后的平均值应该正好是 g(1)，这是将<em class="mv"> m(1) </em>除以(1–0.9)= 0.1 得到的结果。</p><p id="90cb" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">为简单起见，我们设置<em class="mv"> η=1 </em>(学习率计划乘数)，并将所有内容放在第 12 行:</p><p id="5d28" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">当向下“下山”一步时，步长通过将学习速率α乘以<em class="mv"> m(t) </em>并除以<em class="mv"> v(t) </em>的根来调整(此时我们忽略帽子^)。</p><blockquote class="mw"><p id="cf1a" class="mx my jf bd mz na nb nc nd ne nf lw dk translated">x(t)= x(t-1)-αm(t)/[sqrt(v(t))+ϵ]</p></blockquote><p id="1773" class="pw-post-body-paragraph lb lc jf ld b le ng kg lg lh nh kj lj lk ni lm ln lo nj lq lr ls nk lu lv lw ij bi translated">记住一个随机变量<em class="mv"> x </em>的方差定义为<em class="mv">Var(x)=&lt;x&gt;-&lt;x&gt;</em>其中<em class="mv"> &lt; &gt; </em>为期望值。梯度平方的指数移动平均值被称为无中心方差，因为我们没有减去梯度平均值的平方。</p><p id="a839" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">方差量化了梯度围绕其平均值变化的程度。如果梯度保持近似恒定，因为我们“走在草地上”，梯度的方差近似为 0，无中心方差<em class="mv"> v(t) </em>近似等于<em class="mv"> m(t) </em>。这就意味着<em class="mv"> m(t) / sqrt(v(t)) </em>在 1 左右，步长“下山”的顺序是<em class="mv"> α </em>。</p><p id="3b74" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">另一方面，如果梯度快速变化，<em class="mv"> sqrt(v(t)) </em>比<em class="mv"> m(t) </em>大得多，因此“下山”的步长比<em class="mv"> α </em>小得多。</p><p id="8498" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">总之，这意味着 Adam 能够通过估计梯度的一阶和二阶矩来为每个个体权重调整步长。当梯度变化不大且“我们在下山时不必小心”时，步长为<em class="mv"> α、</em>的数量级，如果它们发生变化且“我们需要小心不要走错方向”，则步长要小得多。</p><p id="ce23" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">在下一节中，我将解释什么是 L2 正则化，在最后一节中，我将总结作者的研究结果，即为什么使用 L2 正则化的 Adam 产生的模型比使用 SGD 训练的模型更差，以及他们如何解决这个问题。</p><h1 id="b44d" class="ly lz jf bd ma mb mc md me mf mg mh mi kl mj km mk ko ml kp mm kr mn ks mo mp bi translated">2) L2 正则化和权重衰减</h1><p id="4ce1" class="pw-post-body-paragraph lb lc jf ld b le mq kg lg lh mr kj lj lk ms lm ln lo mt lq lr ls mu lu lv lw ij bi translated">L2 正则化或权重衰减背后的思想是，观察到具有较小权重的网络(所有其他条件相同)过拟合较少且泛化能力较好。如果你不熟悉这个概念，我建议你读一读迈克尔·尼尔森的伟大的电子书。</p><p id="668c" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">当然，大重量仍然是可能的，但前提是它们能显著减少损失。每步的权重衰减率<em class="mv"> w </em>定义了最小化原始损失函数(如果选择小的<em class="mv"> w </em>则更重要)和找到小权重(如果选择大的<em class="mv"> w </em>则更重要)的相对重要性。如果如前所述比较权重的更新(新权重等于旧权重减去学习率乘以梯度)</p><blockquote class="mw"><p id="6480" class="mx my jf bd mz na nb nc nd ne nf lw dk translated">x(t) = x(t-1) — α ∇ f[x(t-1)]</p></blockquote><p id="a10b" class="pw-post-body-paragraph lb lc jf ld b le ng kg lg lh nh kj lj lk ni lm ln lo nj lq lr ls nk lu lv lw ij bi translated">重量衰减的版本</p><blockquote class="mw"><p id="72fd" class="mx my jf bd mz na nb nc nd ne nf lw dk translated">x(t) = (1-w) x(t-1) — α ∇ f[x(t-1)]</p></blockquote><p id="1be8" class="pw-post-body-paragraph lb lc jf ld b le ng kg lg lh nh kj lj lk ni lm ln lo nj lq lr ls nk lu lv lw ij bi translated">您会注意到附加项<em class="mv"> -w x(t-1) </em>，它指数衰减权重<em class="mv"> x </em>，从而迫使网络学习更小的权重。</p><p id="06ab" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">通常，不是执行<em class="mv">权重衰减，而是定义</em>正则化损失函数(<em class="mv"> L2 正则化</em>):</p><blockquote class="mw"><p id="7342" class="mx my jf bd mz na nb nc nd ne nf lw dk translated">f _ reg[x(t-1)]= f[x(t-1)]+w '/2x(t-1)</p></blockquote><p id="ed03" class="pw-post-body-paragraph lb lc jf ld b le ng kg lg lh nh kj lj lk ni lm ln lo nj lq lr ls nk lu lv lw ij bi translated">如果你计算这个正则化损失函数的梯度</p><blockquote class="mw"><p id="d3ec" class="mx my jf bd mz na nb nc nd ne nf lw dk translated">∇f _ reg[x(t-1)]=∇f[x(t-1)]+w ' x(t-1)</p></blockquote><p id="7e40" class="pw-post-body-paragraph lb lc jf ld b le ng kg lg lh nh kj lj lk ni lm ln lo nj lq lr ls nk lu lv lw ij bi translated">并更新权重</p><blockquote class="mw"><p id="549e" class="mx my jf bd mz na nb nc nd ne nf lw dk translated">x(t) = x(t-1) — α ∇ f_reg[x(t-1)]</p><p id="4e3c" class="mx my jf bd mz na nb nc nd ne nf lw dk translated">x(t)= x(t-1)—α∇f[x(t-1)]—αw ' x(t-1)</p></blockquote><p id="1923" class="pw-post-body-paragraph lb lc jf ld b le ng kg lg lh nh kj lj lk ni lm ln lo nj lq lr ls nk lu lv lw ij bi translated">如果定义<em class="mv"> w' = w/α，你会发现这相当于重量衰减。</em></p><p id="cfb8" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld jg">常见的深度学习库通常实现后者的 L2 正则化。然而，</strong> <a class="ae lx" href="https://arxiv.org/abs/1711.05101" rel="noopener ugc nofollow" target="_blank"> <strong class="ld jg">文章</strong> </a> <strong class="ld jg">显示，这种等价只适用于 SGD，不适用于 Adam 这样的自适应优化器！</strong></p><p id="5a71" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">在这篇文章的最后一部分，我将解释为什么 L2 正则化不等同于 Adam 的权重衰减，Adam 和 AdamW 之间的区别是什么，以及为什么使用 AdamW 可以给出更好的概化模型。</p><h1 id="7ba8" class="ly lz jf bd ma mb mc md me mf mg mh mi kl mj km mk ko ml kp mm kr mn ks mo mp bi translated">3)阿达姆</h1><p id="b61f" class="pw-post-body-paragraph lb lc jf ld b le mq kg lg lh mr kj lj lk ms lm ln lo mt lq lr ls mu lu lv lw ij bi translated">让我们再来看看亚当算法。</p><figure class="nm nn no np gt is gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/a7ef3bedecf398572a9d16f608d27519.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*BOPnuP6VP0JVnJsoCdTo-g.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Taken from “Fixing Weight Decay Regularization in Adam” by Ilya Loshchilov, Frank Hutter.</figcaption></figure><p id="4872" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">第 6 行中的紫色项显示了 Adam(不是 AdamW)中的 L2 正则化，因为它通常在深度学习库中实现。正则化项被添加到成本函数中，然后该成本函数被导出以计算梯度<em class="mv"> g </em>。然而，如果在这一点上添加权重衰减项，梯度及其平方的移动平均值(<em class="mv"> m </em>和<em class="mv"> v </em>)不仅跟踪损失函数<em class="mv">的梯度，还跟踪正则化项</em>！</p><p id="bf58" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">如果我们将第 6、7 和 8 行插入第 12 行(现在忽略帽子^，因为<em class="mv"> t </em>被假定为大，因此<em class="mv"> β^t=0 </em>)，权重的更新如下所示:</p><figure class="nm nn no np gt is gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/7d3efeb9e512b6db5f40e84506f96e04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*IZsdzylBb5T4kHsZf48nbw.png"/></div></figure><p id="50ed" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated"><strong class="ld jg">如您所见，重量衰减也通过<em class="mv"> sqrt(v) </em>进行归一化。如果某个重量的梯度很大(或变化很大)，则相应的<em class="mv"> v </em>也很大，并且重量比梯度小且变化缓慢的重量调整得少！这意味着 L2 正则化不能像预期的那样工作，也不如 SGD 有效，这就是为什么 SGD 产生的模型概括得更好，并且已经用于大多数最新的结果。</strong></p><p id="7f2b" class="pw-post-body-paragraph lb lc jf ld b le lf kg lg lh li kj lj lk ll lm ln lo lp lq lr ls lt lu lv lw ij bi translated">因此，作者提出了 Adam 的改进版本，称为 AdamW，其中权重衰减仅在控制参数式步长之后执行(参见第 12 行中的绿色项)。权重衰减或正则化项不会在移动平均值中结束，因此仅与权重本身成比例。作者通过实验表明，AdamW 产生更好的训练损失，并且模型比用 Adam 训练的模型概括得更好，从而允许新版本与具有动量的随机梯度下降竞争。这意味着在未来，研究人员和工程师可能不必经常在 SGD 和 Adam 之间切换。请记住这一点，下次您训练模型时:)</p></div></div>    
</body>
</html>