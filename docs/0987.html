<html>
<head>
<title>How to train Tensorflow models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何训练张量流模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-traine-tensorflow-models-79426dabd304?source=collection_archive---------0-----------------------#2017-07-18">https://towardsdatascience.com/how-to-traine-tensorflow-models-79426dabd304?source=collection_archive---------0-----------------------#2017-07-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2ef9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用GPU</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/2080b22c3c28f572e5451f49e24d7035.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xBOA9lse6tu_0jpE3aFrUQ.jpeg"/></div></div></figure><p id="2fa6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">近年来，机器学习领域取得了重大进展。这种进步很大程度上可以归功于图形处理单元(GPU)的使用越来越多，以加速机器学习模型的训练。特别是，额外的计算能力导致了<strong class="kt ir">深度学习</strong>的普及——使用复杂的多层神经网络来创建模型，能够从大量未标记的训练数据中进行特征检测。</p><h1 id="7f8d" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">GPU简介</h1><p id="61d7" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">GPU非常适合深度学习，因为它们被设计来处理的计算类型恰好与深度学习中遇到的计算类型相同。图像、视频和其他图形都表示为矩阵，因此当您执行任何操作(如放大效果或相机旋转)时，您所做的只是对矩阵应用一些数学变换。</p><p id="48d4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">实际上，这意味着与中央处理器(CPU)相比，GPU更擅长执行矩阵运算和其他几种高级数学转换。这使得深度学习算法在GPU上的运行速度比CPU快好几倍。学习时间通常可以从几天缩短到几个小时。</p><h1 id="4cf8" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">机器学习中的GPU</h1><p id="eab8" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">那么，如何使用GPU来完成机器学习任务呢？在这篇文章中，我们将探索一个支持GPU的AWS实例的设置，以在Tensorflow中训练神经网络。</p><p id="4409" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，在AWS控制面板中创建一个新的EC2实例。</p><p id="f64d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们将使用Ubuntu Server 16.04 LTS (HVM)作为操作系统，但是这个过程在任何64位Linux发行版上都应该是相似的。</p><p id="2cd9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于实例类型，选择g2.2xlarge这些是通过NVIDIA GRID GPU启用的。也有几个这样的GPU的实例，但利用一个以上需要额外的设置，这将在本文稍后讨论。</p><p id="7685" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">使用您首选的安全设置完成设置。</p><p id="241e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一旦设置和创建完成，SSH进入您的实例。</p><p id="9cc5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Python应该已经存在于系统中，所以安装所需的库:</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="640d" class="mp lo iq ml b gy mq mr l ms mt">sudo apt-get update<br/>sudo apt-get install python-pip python-dev</span></pre><p id="a2db" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，安装启用GPU支持的Tensorflow。最简单的方法是:</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="75f9" class="mp lo iq ml b gy mq mr l ms mt">pip install tensorflow-gpu</span></pre><p id="ba80" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">但是，对于某些安装，这可能会失败。如果发生这种情况，还有一个替代方案:</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="ef73" class="mp lo iq ml b gy mq mr l ms mt">export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.1-cp27-none-linux_x86_64.whl<br/>sudo pip install --upgrade $TF_BINARY_URL</span></pre><p id="1e08" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果在TF安装过程中得到一个<code class="fe mu mv mw ml b">locale.Error: unsupported locale setting</code>，请输入:</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="ce35" class="mp lo iq ml b gy mq mr l ms mt">export LC_ALL=C</span></pre><p id="21bd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">然后，重复安装过程。</p><p id="0ffc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果不再出现错误，TF安装就结束了。然而，为了让GPU加速正常工作，我们仍然必须安装Cuda工具包和cuDNN。</p><p id="c0cb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，让我们安装Cuda工具包。</p><p id="d37b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">开始之前，请注意安装过程将下载大约3gb的数据。</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="cc54" class="mp lo iq ml b gy mq mr l ms mt">wget "http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.44-1_amd64.deb"<br/>sudo dpkg -i cuda-repo-ubuntu1604_8.0.44-1_amd64.deb<br/>sudo apt-get update<br/>sudo apt-get install cuda</span></pre><p id="a366" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">安装CUDA工具包后，下载<a class="ae mx" href="https://developer.nvidia.com/cudnn" rel="noopener ugc nofollow" target="_blank"> cuDNN Library for Linux </a>(注意，您需要注册加速计算开发者计划)并将其复制到您的EC2实例中。</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="83ee" class="mp lo iq ml b gy mq mr l ms mt">sudo tar -xvf cudnn-8.0-linux-x64-v5.1.tgz -C /usr/local<br/>export PATH=/usr/local/cuda/bin:$PATH<br/>export LD_LIBRARY_PATH="$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64"<br/>export CUDA_HOME=/usr/local/cuda</span></pre><p id="6ba7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后，设置过程已经结束，我们可以测试安装了:</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="e333" class="mp lo iq ml b gy mq mr l ms mt">python<br/>&gt;&gt;&gt; import tensorflow as tf<br/>&gt;&gt;&gt; sess = tf.Session()</span></pre><p id="f6ed" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">你应该看到<code class="fe mu mv mw ml b">Found device 0 with properties: name: GRID K520</code></p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="9786" class="mp lo iq ml b gy mq mr l ms mt">&gt;&gt;&gt; hello_world = tf.constant("Hello, world!")<br/>&gt;&gt;&gt; print sess.run(hello_world)</span></pre><p id="f5a4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">将显示<code class="fe mu mv mw ml b">Hello, world!</code></p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="ffc3" class="mp lo iq ml b gy mq mr l ms mt">&gt;&gt;&gt; print sess.run(tf.constant(123)*tf.constant(456))</span></pre><p id="388d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><code class="fe mu mv mw ml b">56088</code>是正确答案。</p><p id="53bd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">系统现在准备好利用带有Tensorflow的GPU。</p><p id="013b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对Tensorflow代码的更改应该是最小的。如果TensorFlow操作同时具有CPU和GPU实现，则将操作分配给设备时，GPU设备将优先。</p><p id="767c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果您想在自己选择的设备上运行一个特定的操作，而不是使用默认的，您可以使用<code class="fe mu mv mw ml b">with tf.device</code>创建一个设备上下文。这将强制该上下文中的所有操作具有相同的设备分配。</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="42c7" class="mp lo iq ml b gy mq mr l ms mt"># Creates a graph.<br/>with tf.device('/gpu:0'):<br/> a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')<br/> b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')<br/> c = tf.matmul(a, b)<br/># Creates a session with log_device_placement set to True.<br/>sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))<br/># Runs the op.<br/>print sess.run©</span></pre><p id="cd85" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果您想在多个GPU上运行TensorFlow，可以以多塔的方式构建一个模型，并将每个塔分配给不同的GPU。例如:</p><pre class="kg kh ki kj gt mk ml mm mn aw mo bi"><span id="ab08" class="mp lo iq ml b gy mq mr l ms mt"># Creates a graph.<br/>c = []<br/>for d in ['/gpu:2', '/gpu:3']:<br/> with tf.device(d):<br/> a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3])<br/> b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2])<br/> c.append(tf.matmul(a, b))<br/>with tf.device('/cpu:0'):<br/> sum = tf.add_n(c)<br/># Creates a session with log_device_placement set to True.<br/>sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))<br/># Runs the op.<br/>print sess.run(sum)</span></pre><h1 id="e2c0" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">利用GPU的优势</h1><p id="3020" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">出于基准测试的目的，我们将使用卷积神经网络(CNN)来识别图像，这是作为<a class="ae mx" href="https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10" rel="noopener ugc nofollow" target="_blank"> Tensorflow教程</a>的一部分提供的。CIFAR-10分类是机器学习中常见的基准问题。任务是将RGB 32x32像素图像分为10类。</p><p id="ad9e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们比较在几种流行的配置上训练该模型的性能:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/434e7fd3d1f2fc530229a7ed21bccc17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w6n2g5sbrvSrxZd4DvamrQ.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/45f987732839a5c7155a0735809b2b77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xnivNi-jtYvPaCFnjzWXBw.jpeg"/></div></div></figure><h1 id="862d" class="ln lo iq bd lp lq lr ls lt lu lv lw lx jw ly jx lz jz ma ka mb kc mc kd md me bi translated">结果</h1><p id="6adb" class="pw-post-body-paragraph kr ks iq kt b ku mf jr kw kx mg ju kz la mh lc ld le mi lg lh li mj lk ll lm ij bi translated">如结果所示，在这个特定示例中，16个CPU的能力与1个GPU的能力相当。在撰写本文时，同样的训练时间，使用GPU也要便宜18%。</p><p id="3483" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="mz">由</em><a class="ae mx" href="https://www.dataart.com/industry/iot-and-m2m-solutions?utm_source=medium&amp;utm_medium=social&amp;utm_campaign=i-spring-2018" rel="noopener ugc nofollow" target="_blank"><em class="mz">data art</em></a><em class="mz">的高级建筑师尼古拉·哈巴罗夫撰写。</em></p></div></div>    
</body>
</html>