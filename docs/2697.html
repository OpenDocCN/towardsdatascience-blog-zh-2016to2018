<html>
<head>
<title>Basics of Image Classification in Machine Learning Using Open Source Frameworks in IBM PowerAI (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 IBM PowerAI 开源框架的机器学习中的图像分类基础(第 2 部分)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/basics-of-image-classification-in-machine-learning-using-open-source-frameworks-in-ibm-powerai-b4291dc40d25?source=collection_archive---------2-----------------------#2018-02-23">https://towardsdatascience.com/basics-of-image-classification-in-machine-learning-using-open-source-frameworks-in-ibm-powerai-b4291dc40d25?source=collection_archive---------2-----------------------#2018-02-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/dce63e52f5f54f6184b54b325e3d0fe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I6V_7IJnihuy79_ArPJFGQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><a class="ae kc" href="https://www.ibm.com/power" rel="noopener ugc nofollow" target="_blank">IBM Power Systems</a></figcaption></figure><h1 id="3178" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">介绍</h1><p id="5c64" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">图像分类已经成为展示机器学习的关键试点用例之一。在之前的<a class="ae kc" rel="noopener" target="_blank" href="/machine-learning-with-ibm-powerai-getting-started-with-image-classification-part-1-6219e3c6a9fa">文章</a>中，我介绍了机器学习，IBM PowerAI，在 IBM Power 平台上运行图像分类程序时比较了 GPU 和 CPU 的性能。在本文中，我们来看看如何检查神经网络任何内层的输出，并通过使用 Nvidia DIGITS 来训练您自己的模型。</p><h1 id="98a7" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">观察隐藏层参数</h1><p id="5d09" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">直到 20 世纪 80 年代，研究人员才发现给神经网络增加更多的层可以极大地提高其性能。这种具有几个隐藏层的神经网络如今在包括图像分类在内的几个用例中很常见。与名称所表明的相反，可以观察隐藏层中的相关参数。</p><h1 id="4a30" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">卷积神经网络体系结构</h1><p id="321b" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">现在你可能知道，卷积神经网络(CNN)是一种深度神经网络，用于图像分类时会产生相当准确的结果。<br/> <br/>在工科学校学习数字信号处理的时候，你一定会碰到卷积这个术语。简单来说，两个信号的卷积是两个信号函数的乘积的积分，在其中一个函数被反转和移位之后。在我们的例子中，每个输入图像都是像素值的矩阵。要查看隐藏层中如何执行卷积的可视化表示，请考虑以下示例。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/0e7de8a67e0c197106c87d417e45b499.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/1*ZCjPUFrB6eHPRi4eyP6aaA.gif"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Source: <a class="ae kc" href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/" rel="noopener ugc nofollow" target="_blank">https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/</a></figcaption></figure><p id="f36b" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">在本例中，橙色矩阵(3x3)称为滤镜，用于计算原始图像(5X5 像素矩阵)的卷积输出。结果被称为激活图或功能图。应当理解，根据所应用的滤波器，可以修改和训练输出特征图，以获得期望的输出。</p><p id="7700" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">在现代 CNN 中，滤波器是在训练过程中自动学习的，但是我们确实根据所使用的架构指定了某些参数(如下所示)。如果你需要更详细的分析，请访问这个<a class="ae kc" href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/" rel="noopener ugc nofollow" target="_blank">博客</a>。</p><p id="e7e7" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">在我们的例子中，使用了 AlexNet 的一个版本，这是我们所依赖的标准架构。在下面的代码中，我们阅读了网络的结构。CNN 包含两个有序字典；</p><p id="616c" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">a) <code class="fe mj mk ml mm b"><strong class="ld ir">Net.blobs</strong></code>为输入数据；</p><p id="3ddc" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">a.它有以下参数–批量大小、通道尺寸、高度和宽度</p><p id="668d" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">b) <code class="fe mj mk ml mm b"><strong class="ld ir">Net.params</strong></code>是具有权重和偏差参数的斑点向量；</p><p id="d5eb" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">a.权重表示连接的强度。接近零的权重表示输入和输出之间的良好相关性。</p><p id="4d41" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">b.偏差表示预测值与实际值之间的差距，对于预测值进入下一步非常重要。</p><p id="0815" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">c.它具有以下参数——权重的输出通道、输入通道、滤波器高度和滤波器宽度，以及偏差的一维输出通道。</p><p id="e23b" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">让我们试着把这些打印出来。</p><pre class="ma mb mc md gt mn mm mo mp aw mq bi"><span id="61ee" class="mr ke iq mm b gy ms mt l mu mv"># for each layer, show the output shape</span><span id="140b" class="mr ke iq mm b gy mw mt l mu mv">for layer_name, blob in net.blobs.iteritems():</span><span id="9aa7" class="mr ke iq mm b gy mw mt l mu mv">print layer_name + ‘\t’ + str(blob.data.shape)</span></pre><p id="f939" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">这是输出。</p><pre class="ma mb mc md gt mn mm mo mp aw mq bi"><span id="0fa5" class="mr ke iq mm b gy ms mt l mu mv">data (50, 3, 227, 227)</span><span id="d998" class="mr ke iq mm b gy mw mt l mu mv">conv1 (50, 96, 55, 55)</span><span id="5fae" class="mr ke iq mm b gy mw mt l mu mv">pool1 (50, 96, 27, 27)</span><span id="b516" class="mr ke iq mm b gy mw mt l mu mv">norm1 (50, 96, 27, 27)</span><span id="679e" class="mr ke iq mm b gy mw mt l mu mv">conv2 (50, 256, 27, 27)</span><span id="e1a6" class="mr ke iq mm b gy mw mt l mu mv">pool2 (50, 256, 13, 13)</span><span id="9181" class="mr ke iq mm b gy mw mt l mu mv">norm2 (50, 256, 13, 13)</span><span id="0d73" class="mr ke iq mm b gy mw mt l mu mv">conv3 (50, 384, 13, 13)</span><span id="946f" class="mr ke iq mm b gy mw mt l mu mv">conv4 (50, 384, 13, 13)</span><span id="7803" class="mr ke iq mm b gy mw mt l mu mv">conv5 (50, 256, 13, 13)</span><span id="41e0" class="mr ke iq mm b gy mw mt l mu mv">pool5 (50, 256, 6, 6)</span><span id="0c1f" class="mr ke iq mm b gy mw mt l mu mv">fc6 (50, 4096)</span><span id="c096" class="mr ke iq mm b gy mw mt l mu mv">fc7 (50, 4096)</span><span id="8e59" class="mr ke iq mm b gy mw mt l mu mv">fc8 (50, 1000)</span><span id="803a" class="mr ke iq mm b gy mw mt l mu mv">prob (50, 1000)</span></pre><p id="b4df" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">和；</p><pre class="ma mb mc md gt mn mm mo mp aw mq bi"><span id="8647" class="mr ke iq mm b gy ms mt l mu mv">for layer_name, param in net.params.iteritems():</span><span id="b19e" class="mr ke iq mm b gy mw mt l mu mv">print layer_name + ‘\t’ + str(param[0].data.shape), str(param[1].data.shape)</span></pre><p id="0a3c" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">这是输出。</p><pre class="ma mb mc md gt mn mm mo mp aw mq bi"><span id="d746" class="mr ke iq mm b gy ms mt l mu mv">conv1 (96, 3, 11, 11) (96,)</span><span id="23f3" class="mr ke iq mm b gy mw mt l mu mv">conv2 (256, 48, 5, 5) (256,)</span><span id="7c1e" class="mr ke iq mm b gy mw mt l mu mv">conv3 (384, 256, 3, 3) (384,)</span><span id="7095" class="mr ke iq mm b gy mw mt l mu mv">conv4 (384, 192, 3, 3) (384,)</span><span id="3c51" class="mr ke iq mm b gy mw mt l mu mv">conv5 (256, 192, 3, 3) (256,)</span><span id="1b69" class="mr ke iq mm b gy mw mt l mu mv">fc6 (4096, 9216) (4096,)</span><span id="d43c" class="mr ke iq mm b gy mw mt l mu mv">fc7 (4096, 4096) (4096,)</span><span id="bd17" class="mr ke iq mm b gy mw mt l mu mv">fc8 (1000, 4096) (1000,)</span></pre><p id="9b76" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">如你所见，我们这里有四维数据。这里有一个函数来可视化这些数据；</p><pre class="ma mb mc md gt mn mm mo mp aw mq bi"><span id="97ea" class="mr ke iq mm b gy ms mt l mu mv">def vis_square(data):<br/>“””Take an array of shape (n, height, width) or (n, height, width, 3)<br/> and visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)”””<br/> <br/> # normalize data for display<br/> data = (data — data.min()) / (data.max() — data.min())<br/> <br/> # force the number of filters to be square<br/> n = int(np.ceil(np.sqrt(data.shape[0])))<br/> padding = (((0, n ** 2 — data.shape[0]),<br/> (0, 1), (0, 1)) # add some space between filters<br/> + ((0, 0),) * (data.ndim — 3)) # don’t pad the last dimension (if there is one)<br/> data = np.pad(data, padding, mode=’constant’, constant_values=1) # pad with ones (white)<br/> <br/> # tile the filters into an image<br/> data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))<br/> data = data.reshape((n * data.shape[1], n * data.shape[3]) +  data.shape[4:])<br/> <br/> plt.imshow(data); plt.axis(‘off’)</span></pre><p id="33d1" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">在这里，您可以看到层 conv1 中的滤波器；</p><pre class="ma mb mc md gt mn mm mo mp aw mq bi"><span id="a308" class="mr ke iq mm b gy ms mt l mu mv"># the parameters are a list of [weights, biases]</span><span id="531d" class="mr ke iq mm b gy mw mt l mu mv">filters = net.params[‘conv1’][0].data</span><span id="be10" class="mr ke iq mm b gy mw mt l mu mv">vis_square(filters.transpose(0, 2, 3, 1))</span></pre><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/7fea1fdbeb4871d2f7f9fab2a593417e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*xet_IbsPTRG8GFhi4O9zjQ.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Filters in a layer</figcaption></figure><p id="bbb7" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">这里，我们看到前 36 个滤波器的校正响应；</p><pre class="ma mb mc md gt mn mm mo mp aw mq bi"><span id="7bc1" class="mr ke iq mm b gy ms mt l mu mv">feat = net.blobs[‘conv1’].data[0, :36]</span><span id="e67c" class="mr ke iq mm b gy mw mt l mu mv">vis_square(feat)</span></pre><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/36f3f8b936dac9103382a32e7fc7287c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*go1xfXQxBxI4AByRIqx7Xw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Rectified output</figcaption></figure><p id="5a5e" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">在这里，我们看到第五层的输出，在池化之后；</p><pre class="ma mb mc md gt mn mm mo mp aw mq bi"><span id="9e82" class="mr ke iq mm b gy ms mt l mu mv">feat = net.blobs[‘pool5’].data[0]</span><span id="02a5" class="mr ke iq mm b gy mw mt l mu mv">vis_square(feat)</span></pre><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/5eff27912f4386225b9112f480a9b45f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*Kcaw8d32vA3QRZ27DYEE9Q.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Output of the fifth layer after pooling</figcaption></figure><p id="d72f" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">第一个完全连接的层是“fc6 ”,它是一个整流输出。使用此代码显示所有非负值的直方图；</p><pre class="ma mb mc md gt mn mm mo mp aw mq bi"><span id="3292" class="mr ke iq mm b gy ms mt l mu mv">feat = net.blobs[‘fc6’].data[0]</span><span id="b6ea" class="mr ke iq mm b gy mw mt l mu mv">plt.subplot(2, 1, 1)</span><span id="1296" class="mr ke iq mm b gy mw mt l mu mv">plt.plot(feat.flat)</span><span id="917b" class="mr ke iq mm b gy mw mt l mu mv">plt.subplot(2, 1, 2)</span><span id="72e3" class="mr ke iq mm b gy mw mt l mu mv">_ = plt.hist(feat.flat[feat.flat &gt; 0], bins=100)</span></pre><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi my"><img src="../Images/5ed1a3e40112a0fc10041ddb886c5605.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*L2u-jIrLXEaIQ7ueqxI7nw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Histogram of rectified output — More explanation in this <a class="ae kc" rel="noopener" target="_blank" href="/activation-functions-neural-networks-1cbd9f8d91d6">blog</a></figcaption></figure><p id="00cb" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">这里，我们看到了所有预测类的最终概率值的直方图。这里最高的峰值显示了最高的预测类别，在我们的例子中，是猩猩。还显示了其他次要的簇峰。</p><pre class="ma mb mc md gt mn mm mo mp aw mq bi"><span id="1b7b" class="mr ke iq mm b gy ms mt l mu mv">feat = net.blobs[‘prob’].data[0]</span><span id="3064" class="mr ke iq mm b gy mw mt l mu mv">plt.figure(figsize=(15, 3))</span><span id="6f80" class="mr ke iq mm b gy mw mt l mu mv">plt.plot(feat.flat)</span><span id="4f66" class="mr ke iq mm b gy mw mt l mu mv">[&lt;matplotlib.lines.Line2D at 0x7f09587dfb50&gt;]</span></pre><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/b1ce19369d937c22ec3ae7e8bf228690.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q_6b3ZTJHrSzI65IYxMTew.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">The top peak here shows the top predicted class, in our case, orangutan</figcaption></figure><h1 id="77f6" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">如何训练自己的机器学习模型？</strong></h1><p id="f496" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><strong class="ld ir">英伟达是什么数字？</strong></p><p id="a03d" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated"><strong class="ld ir"> Nvidia </strong>深度学习 GPU 训练系统(<strong class="ld ir"> DIGITS </strong>)是一个应用程序，用于对图像进行分类，执行分割和对象检测任务。这是一个基于 GUI 的应用程序，与 Caffe 接口。下载和安装程序可以在他们的网站上找到。Github 上也有稳定版和其他测试版。DIGITS 服务器安装在我在这个演示中使用的容器中。安装后，可以从端口 5000 访问 GUI。</p><p id="c3b7" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">下一步是从网上下载一个样本数据集到我在虚拟机中创建的目录(/DIGITS)中。这个数据集被称为 CIFAR-100。它包含 100 个图像类别，每个类别包含 600 个图像。每个类有 500 个训练图像和 100 个测试图像。CIFAR-100 中的 100 个类被分成 20 个超级类。每个图像都有一个“精细”标签(它所属的类)和一个“粗糙”标签(它所属的超类)。</p><p id="e87d" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">下面是它包含的内容的简要说明；</p><p id="e8e5" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">1) Labels.txt:该文件包含训练数据集中的类的列表。</p><p id="79f7" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">2) Train:该目录包含用于训练的图像。</p><p id="fee0" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">3) Train.txt:该文件包含训练文件到类之间的映射列表。标签是按位置排列的，即 labels.txt 文件中的第一个标签用数字 0 表示，第二个用数字 1 表示，依此类推。</p><p id="ec31" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">4)测试:该目录包含用于测试训练质量的图像。</p><p id="77e6" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">5) Test.txt:这个文件包含测试文件和类之间的映射列表。标签是按位置排列的，即 labels.txt 文件中的第一个标签用数字 0 表示，第二个用数字 1 表示，依此类推。</p><pre class="ma mb mc md gt mn mm mo mp aw mq bi"><span id="0213" class="mr ke iq mm b gy ms mt l mu mv">root@JARVICENAE-0A0A1841:~/DIGITS# python -m digits.download_data cifar100 .</span></pre><p id="cf3d" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">输出；</p><pre class="ma mb mc md gt mn mm mo mp aw mq bi"><span id="1c10" class="mr ke iq mm b gy ms mt l mu mv">Downloading url=http://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz …</span><span id="f9f6" class="mr ke iq mm b gy mw mt l mu mv">Uncompressing file=cifar-100-python.tar.gz …</span><span id="05f8" class="mr ke iq mm b gy mw mt l mu mv">Extracting images file=./cifar-100-python/train …</span><span id="162e" class="mr ke iq mm b gy mw mt l mu mv">Extracting images file=./cifar-100-python/test …</span><span id="24d6" class="mr ke iq mm b gy mw mt l mu mv">Dataset directory is created successfully at ‘.’</span><span id="16bb" class="mr ke iq mm b gy mw mt l mu mv">Done after 65.3251469135 seconds.</span></pre><p id="eea2" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">让我们来看看下载的数据集。虽然我没有显示上面列出的其他目录，但假设它们已经下载并存在。</p><pre class="ma mb mc md gt mn mm mo mp aw mq bi"><span id="7310" class="mr ke iq mm b gy ms mt l mu mv">root@JARVICENAE-0A0A1841:~/DIGITS# ls fine/train | head</span><span id="0c5a" class="mr ke iq mm b gy mw mt l mu mv">apple</span><span id="9677" class="mr ke iq mm b gy mw mt l mu mv">aquarium_fish</span><span id="70fe" class="mr ke iq mm b gy mw mt l mu mv">baby</span><span id="729c" class="mr ke iq mm b gy mw mt l mu mv">bear</span><span id="040e" class="mr ke iq mm b gy mw mt l mu mv">beaver</span><span id="3a7d" class="mr ke iq mm b gy mw mt l mu mv">bed</span><span id="8f77" class="mr ke iq mm b gy mw mt l mu mv">bee</span><span id="c249" class="mr ke iq mm b gy mw mt l mu mv">beetle</span><span id="2cbf" class="mr ke iq mm b gy mw mt l mu mv">bicycle</span><span id="b896" class="mr ke iq mm b gy mw mt l mu mv">bottle</span></pre><p id="7c78" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">让我们用下载的预训练数据集(CIFAR-100)创建一个新的分类数据集。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi na"><img src="../Images/bf0882614e58e76b6902d5cb0bf49a41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TNc0N8vEKxTII9tbx1I4eA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">New Image Classification Dataset on DIGITS</figcaption></figure><p id="856e" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">这里,/root/DIGITS/fine/train 路径是我们数据集的路径。还要注意“单独的测试图像文件夹”选项，并指定/root/DIGITS/fine/test 目录。您还可以为此数据集指定一个名称，例如“Cifar100”(未在上面的屏幕截图中显示)。</p><p id="3b64" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">当您单击 Create 时，将启动一个创建培训数据库的新作业，如下所示。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nb"><img src="../Images/3fad5fde44d6515c60fecbad69ecb707.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gulfqiG2DPkHvh8XPRQr-g.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Job status</figcaption></figure><p id="39d5" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">上图中右侧窗格显示了相关作业的状态。完成后，您的 DIGITS 主屏幕现在应该显示该数据集可供使用。</p><h1 id="c314" class="kd ke iq bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">创建新的图像分类模型</strong></h1><p id="2e5b" class="pw-post-body-paragraph lb lc iq ld b le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">让我们用我们创建的 CIFAR-100 数据集创建一个名为“分类图像”的新图像分类模型。我们将为该模型使用预构建的 AlexNet 神经网络架构。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nc"><img src="../Images/725eecd3231f89a9997224a05d294c08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MeqIuVhI525B43uB1ScUQQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">New image classification model</figcaption></figure><p id="ff65" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">单击“Create ”(创建)后，一个新的作业会像以前一样启动。下面的屏幕截图显示了名为“Train Caffe Model”的作业的状态。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nd"><img src="../Images/7446b100d8f4d162c4abf0cad61a1b68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ytl8v6sigFvK12ttB9yrYA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Job status of new image classification model</figcaption></figure><p id="2a07" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">随着培训的进行，工作状态将在下图中更新。随着时间的推移，我能够看到准确性的提高。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ne"><img src="../Images/a72ea8d409338b780f94627473a17029.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GQDiX9pPqZxx3fHvPJ-TuA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Training your model</figcaption></figure><p id="1df2" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">一段时间后，当作业完成时，您将能够上传测试图像并根据您的模型对其进行分类。一个示例图像(一个青苹果)正在上传，结果立即可见。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nf"><img src="../Images/fb08fe5d94b5d358d83b70a0f4b6a929.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5N9PclzbvWTOpLwL9v8Q9A.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Sample image classification</figcaption></figure><p id="59f4" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">对于像 CIFAR-100 这样的小数据集来说，这是相当好的精度，当使用较大的数据集时，可以预期更好的精度值。</p><p id="4ad3" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">我想写一个更短的第三部分来展示火炬的好处。时间会证明一切。</p><p id="5d99" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated"><em class="ng">如果你喜欢这首曲子，请鼓掌👏🏻(可以不止一次鼓掌)！你也可以在网上的某个地方分享，这样其他人也可以阅读。</em></p><p id="59c3" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">本网站上的帖子是我自己的，不一定代表 IBM 的立场、策略或观点。</p><p id="3779" class="pw-post-body-paragraph lb lc iq ld b le me lg lh li mf lk ll lm mg lo lp lq mh ls lt lu mi lw lx ly ij bi translated">作者:<a class="ae kc" href="https://www.linkedin.com/in/upendra-rajan-b208602a/" rel="noopener ugc nofollow" target="_blank">乌彭德拉·拉詹</a></p></div></div>    
</body>
</html>