<html>
<head>
<title>Linear Regression on Boston Housing Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">波士顿住房数据的线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-regression-on-boston-housing-dataset-f409b7e4a155?source=collection_archive---------2-----------------------#2018-10-05">https://towardsdatascience.com/linear-regression-on-boston-housing-dataset-f409b7e4a155?source=collection_archive---------2-----------------------#2018-10-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/11a0e4fa5809e5a572374ff5a5d37c5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FHQOSHMMT07CbXpklk1Ehw.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Credits: <a class="ae kc" href="http://www.wbur.org/radioboston/2013/09/18/bostons-housing-challenge" rel="noopener ugc nofollow" target="_blank">http://www.wbur.org/radioboston/2013/09/18/bostons-housing-challenge</a></figcaption></figure><p id="abab" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我之前的博客中，我介绍了线性回归和梯度下降的基础知识。为了获得动手操作的线性回归，我们将采用原始数据集并应用我们所学的概念。</p><p id="efc5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将获取包含波士顿不同房屋信息的住房数据集。这些数据最初是 UCI 机器学习知识库的一部分，现在已经被删除。我们也可以从 scikit-learn 库中访问这些数据。该数据集中有 506 个样本和 13 个特征变量。目标是使用给定的特征来预测房屋的价格值。</p><p id="bdfc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以让我们开始吧。</p><p id="1eb1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们将导入所需的库。</p><figure class="lb lc ld le gt jr"><div class="bz fp l di"><div class="lf lg l"/></div></figure><p id="7b83" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们将从<code class="fe lh li lj lk b">scikit-learn</code>库中加载住房数据并理解它。</p><figure class="lb lc ld le gt jr"><div class="bz fp l di"><div class="lf lg l"/></div></figure><p id="7705" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们打印出<code class="fe lh li lj lk b">boston_dataset</code>的值来理解它包含的内容。<code class="fe lh li lj lk b">print(boston_dataset.keys())</code>慨然</p><pre class="lb lc ld le gt ll lk lm ln aw lo bi"><span id="92ea" class="lp lq iq lk b gy lr ls l lt lu">dict_keys(['data', 'target', 'feature_names', 'DESCR'])</span></pre><ul class=""><li id="f473" class="lv lw iq kf b kg kh kk kl ko lx ks ly kw lz la ma mb mc md bi translated"><em class="me">数据</em>:包含各种房屋的信息</li><li id="823e" class="lv lw iq kf b kg mf kk mg ko mh ks mi kw mj la ma mb mc md bi translated"><em class="me">目标</em>:房价</li><li id="3113" class="lv lw iq kf b kg mf kk mg ko mh ks mi kw mj la ma mb mc md bi translated"><em class="me">特征名称</em>:特征的名称</li><li id="848c" class="lv lw iq kf b kg mf kk mg ko mh ks mi kw mj la ma mb mc md bi translated"><em class="me">描述</em>:描述数据集</li></ul><p id="55ca" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用<code class="fe lh li lj lk b">boston_dataset.DESCR</code>了解更多功能，所有功能的描述如下:</p><pre class="lb lc ld le gt ll lk lm ln aw lo bi"><span id="9ad1" class="lp lq iq lk b gy lr ls l lt lu"><strong class="lk ir">CRIM</strong>: Per capita crime rate by town<br/><strong class="lk ir">ZN</strong>: Proportion of residential land zoned for lots over 25,000 sq. ft<br/><strong class="lk ir">INDUS</strong>: Proportion of non-retail business acres per town<br/><strong class="lk ir">CHAS</strong>: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)<br/><strong class="lk ir">NOX</strong>: Nitric oxide concentration (parts per 10 million)<br/><strong class="lk ir">RM</strong>: Average number of rooms per dwelling<br/><strong class="lk ir">AGE</strong>: Proportion of owner-occupied units built prior to 1940<br/><strong class="lk ir">DIS</strong>: Weighted distances to five Boston employment centers<br/><strong class="lk ir">RAD</strong>: Index of accessibility to radial highways<br/><strong class="lk ir">TAX</strong>: Full-value property tax rate per $10,000<br/><strong class="lk ir">PTRATIO</strong>: Pupil-teacher ratio by town<br/><strong class="lk ir">B</strong>: 1000(Bk — 0.63)², where Bk is the proportion of [people of African American descent] by town<br/><strong class="lk ir">LSTAT</strong>: Percentage of lower status of the population<br/><strong class="lk ir">MEDV</strong>: Median value of owner-occupied homes in $1000s</span></pre><p id="11d7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">变量<code class="fe lh li lj lk b">MEDV</code>表示的房屋价格是我们的<strong class="kf ir"><em class="me"/></strong>目标变量，剩下的是<strong class="kf ir"> <em class="me">特征变量</em> </strong>，我们将基于这些变量来预测房屋的价值。</p><p id="e833" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们现在将使用<code class="fe lh li lj lk b">pd.DataFrame</code>将数据加载到 pandas 数据帧中。然后我们使用<code class="fe lh li lj lk b">head()</code>打印前 5 行数据</p><figure class="lb lc ld le gt jr"><div class="bz fp l di"><div class="lf lg l"/></div></figure><figure class="lb lc ld le gt jr gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/f850285930e2f83e67706ecb88015a81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*5KmVaL6NijJI3rWZrbGvnA.png"/></div></figure><p id="8920" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以看到数据中缺少目标值<code class="fe lh li lj lk b">MEDV</code>。我们创建一个新的目标值列，并将其添加到 dataframe 中。</p><figure class="lb lc ld le gt jr"><div class="bz fp l di"><div class="lf lg l"/></div></figure><h2 id="0740" class="lp lq iq bd ml mm mn dn mo mp mq dp mr ko ms mt mu ks mv mw mx kw my mz na nb bi translated"><strong class="ak">数据预处理</strong></h2><p id="77ab" class="pw-post-body-paragraph kd ke iq kf b kg nc ki kj kk nd km kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">加载数据后，最好查看数据中是否有任何缺失值。我们使用<code class="fe lh li lj lk b">isnull()</code>计算每个特征的缺失值的数量</p><figure class="lb lc ld le gt jr"><div class="bz fp l di"><div class="lf lg l"/></div></figure><p id="fa77" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是，该数据集中没有缺失值，如下所示。</p><figure class="lb lc ld le gt jr gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/7adc86814da37ee10e312810ebdbc6fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:216/format:webp/1*ocVa9y_BJyW7a6ldTHSFIQ.png"/></div></figure><h2 id="4c43" class="lp lq iq bd ml mm mn dn mo mp mq dp mr ko ms mt mu ks mv mw mx kw my mz na nb bi translated"><strong class="ak">探索性数据分析</strong></h2><p id="73b3" class="pw-post-body-paragraph kd ke iq kf b kg nc ki kj kk nd km kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">探索性数据分析是训练模型前非常重要的一步。在本节中，我们将使用一些可视化工具来理解目标变量与其他特征之间的关系。</p><p id="ef8d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们先画出目标变量<code class="fe lh li lj lk b">MEDV</code>的分布。我们将使用<code class="fe lh li lj lk b">seaborn</code>库中的<code class="fe lh li lj lk b">distplot</code>函数。</p><figure class="lb lc ld le gt jr"><div class="bz fp l di"><div class="lf lg l"/></div></figure><figure class="lb lc ld le gt jr gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/f82c901beb271b1b9144758c6178211d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*1pVtTg-mmUbGRTkuXeTvkQ.png"/></div></figure><p id="cc5d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们看到<code class="fe lh li lj lk b">MEDV</code>的值呈正态分布，很少有异常值。</p><p id="5539" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们创建一个相关矩阵来度量变量之间的线性关系。可以通过使用 pandas 数据帧库中的<code class="fe lh li lj lk b">corr</code>函数来形成相关矩阵。我们将使用 seaborn 库中的<code class="fe lh li lj lk b">heatmap</code>函数来绘制相关矩阵。</p><figure class="lb lc ld le gt jr"><div class="bz fp l di"><div class="lf lg l"/></div></figure><figure class="lb lc ld le gt jr gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/ae99d295a9297949c0f26bf2fbb7355d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*Fbfj8xjr-PwQnfjQ4CBY_g.png"/></div></figure><p id="3582" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">相关系数范围从-1 到 1。如果该值接近 1，则意味着这两个变量之间有很强的正相关性。当它接近-1 时，变量具有很强的负相关性。</p><h2 id="3b52" class="lp lq iq bd ml mm mn dn mo mp mq dp mr ko ms mt mu ks mv mw mx kw my mz na nb bi translated"><strong class="ak">观察:</strong></h2><ul class=""><li id="14e1" class="lv lw iq kf b kg nc kk nd ko nk ks nl kw nm la ma mb mc md bi translated">为了拟合线性回归模型，我们选择那些与我们的目标变量<code class="fe lh li lj lk b">MEDV</code>高度相关的特征。通过查看相关矩阵，我们可以看到<code class="fe lh li lj lk b">RM</code>与<code class="fe lh li lj lk b">MEDV</code> (0.7)有很强的正相关性，而 as <code class="fe lh li lj lk b">LSTAT</code>与<code class="fe lh li lj lk b">MEDV</code> (-0.74)有很强的负相关性。</li><li id="a425" class="lv lw iq kf b kg mf kk mg ko mh ks mi kw mj la ma mb mc md bi translated">为线性回归模型选择特征的重要一点是检查多重共线性。特征<code class="fe lh li lj lk b">RAD</code>、<code class="fe lh li lj lk b">TAX</code>具有 0.91 的相关性。这些特征对彼此之间有很强的相关性。我们不应该同时选择这两个特征来训练模型。查看这个以获得解释。具有-0.75 相关性的特征<code class="fe lh li lj lk b">DIS</code>和<code class="fe lh li lj lk b">AGE</code>也是如此。</li></ul><p id="a297" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基于以上观察我们将<code class="fe lh li lj lk b">RM</code>和<code class="fe lh li lj lk b">LSTAT</code>作为我们的特征。使用散点图，让我们看看这些特性如何随<code class="fe lh li lj lk b">MEDV</code>变化。</p><figure class="lb lc ld le gt jr"><div class="bz fp l di"><div class="lf lg l"/></div></figure><figure class="lb lc ld le gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nn"><img src="../Images/d80a53acbed5013703ae4ff93679b56a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vtUji1IIN5U-xrgC46yDuw.png"/></div></div></figure><h2 id="edc3" class="lp lq iq bd ml mm mn dn mo mp mq dp mr ko ms mt mu ks mv mw mx kw my mz na nb bi translated"><strong class="ak">观察:</strong></h2><ul class=""><li id="16b4" class="lv lw iq kf b kg nc kk nd ko nk ks nl kw nm la ma mb mc md bi translated">价格随着 RM 值的线性增加而增加。很少有异常值，数据似乎上限为 50。</li><li id="fbce" class="lv lw iq kf b kg mf kk mg ko mh ks mi kw mj la ma mb mc md bi translated">随着物价的上涨，价格有下降的趋势。尽管它看起来并不完全是一条直线。</li></ul><h2 id="8a60" class="lp lq iq bd ml mm mn dn mo mp mq dp mr ko ms mt mu ks mv mw mx kw my mz na nb bi translated"><strong class="ak">准备用于训练模型的数据</strong></h2><p id="89d5" class="pw-post-body-paragraph kd ke iq kf b kg nc ki kj kk nd km kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">我们使用 numpy 库提供的<code class="fe lh li lj lk b">np.c_</code>来连接<code class="fe lh li lj lk b">LSTAT</code>和<code class="fe lh li lj lk b">RM</code>列。</p><figure class="lb lc ld le gt jr"><div class="bz fp l di"><div class="lf lg l"/></div></figure><h2 id="f97b" class="lp lq iq bd ml mm mn dn mo mp mq dp mr ko ms mt mu ks mv mw mx kw my mz na nb bi translated"><strong class="ak">将数据分成训练集和测试集</strong></h2><p id="081d" class="pw-post-body-paragraph kd ke iq kf b kg nc ki kj kk nd km kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">接下来，我们将数据分成训练集和测试集。我们用 80%的样本训练模型，用剩下的 20%进行测试。<em class="me">我们这样做是为了评估模型在未知数据上的表现</em>。为了分割数据，我们使用 scikit-learn 库提供的<code class="fe lh li lj lk b">train_test_split</code>函数。最后，我们打印出训练集和测试集的大小，以验证拆分是否正确发生。</p><figure class="lb lc ld le gt jr"><div class="bz fp l di"><div class="lf lg l"/></div></figure><pre class="lb lc ld le gt ll lk lm ln aw lo bi"><span id="3db2" class="lp lq iq lk b gy lr ls l lt lu">(404, 2) <br/>(102, 2)<br/>(404,)<br/>(102,)</span></pre><h2 id="ec18" class="lp lq iq bd ml mm mn dn mo mp mq dp mr ko ms mt mu ks mv mw mx kw my mz na nb bi translated"><strong class="ak">训练和测试模型</strong></h2><p id="48a5" class="pw-post-body-paragraph kd ke iq kf b kg nc ki kj kk nd km kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">我们使用 scikit-learn 的<code class="fe lh li lj lk b">LinearRegression</code>在训练集和测试集上训练我们的模型。</p><figure class="lb lc ld le gt jr"><div class="bz fp l di"><div class="lf lg l"/></div></figure><h2 id="64a5" class="lp lq iq bd ml mm mn dn mo mp mq dp mr ko ms mt mu ks mv mw mx kw my mz na nb bi translated"><strong class="ak">模型评估</strong></h2><p id="6707" class="pw-post-body-paragraph kd ke iq kf b kg nc ki kj kk nd km kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">我们将使用 RMSE 和 R2 分数来评估我们的模型。</p><figure class="lb lc ld le gt jr"><div class="bz fp l di"><div class="lf lg l"/></div></figure><pre class="lb lc ld le gt ll lk lm ln aw lo bi"><span id="c894" class="lp lq iq lk b gy lr ls l lt lu"><strong class="lk ir">The model performance for training set</strong> <br/>-------------------------------------- <br/>RMSE is 5.6371293350711955 <br/>R2 score is 0.6300745149331701   </span><span id="b7c4" class="lp lq iq lk b gy no ls l lt lu"><strong class="lk ir">The model performance for testing set</strong> <br/>-------------------------------------- <br/>RMSE is 5.137400784702911<br/>R2 score is 0.6628996975186952</span></pre><p id="122b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是一个好的开始。在接下来的博客中，我们将探讨提高模型性能的方法。</p><p id="aaa3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">完整的 Jupyter 笔记本可以在<a class="ae kc" href="https://github.com/animesh-agarwal/Machine-Learning-Datasets/blob/master/boston-housing/Linear_Regression.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h2 id="5167" class="lp lq iq bd ml mm mn dn mo mp mq dp mr ko ms mt mu ks mv mw mx kw my mz na nb bi translated"><strong class="ak">结论</strong></h2><p id="7507" class="pw-post-body-paragraph kd ke iq kf b kg nc ki kj kk nd km kn ko ne kq kr ks nf ku kv kw ng ky kz la ij bi translated">在这个故事中，我们对波士顿住房数据集应用了线性回归的概念。我建议也尝试其他数据集。</p><p id="3e99" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里有几个可以查找数据的地方</p><ul class=""><li id="b559" class="lv lw iq kf b kg kh kk kl ko lx ks ly kw lz la ma mb mc md bi translated"><a class="ae kc" href="https://www.kaggle.com/datasets" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/datasets</a></li><li id="c2ae" class="lv lw iq kf b kg mf kk mg ko mh ks mi kw mj la ma mb mc md bi translated"><a class="ae kc" href="https://toolbox.google.com/datasetsearch" rel="noopener ugc nofollow" target="_blank">https://toolbox.google.com/datasetsearch</a></li><li id="50b5" class="lv lw iq kf b kg mf kk mg ko mh ks mi kw mj la ma mb mc md bi translated"><a class="ae kc" href="https://archive.ics.uci.edu/ml/datasets.html" rel="noopener ugc nofollow" target="_blank">https://archive.ics.uci.edu/ml/datasets.html</a></li></ul><p id="87c1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">感谢阅读！！</p><p id="cb89" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本系列的下一部分，我们将讨论多项式回归。请继续关注这个空间。</p></div></div>    
</body>
</html>