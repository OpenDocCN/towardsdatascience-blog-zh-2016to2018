<html>
<head>
<title>Linear algebra cheat sheet for deep learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于深度学习的线性代数备忘单</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-algebra-cheat-sheet-for-deep-learning-cd67aba4526c?source=collection_archive---------0-----------------------#2017-03-04">https://towardsdatascience.com/linear-algebra-cheat-sheet-for-deep-learning-cd67aba4526c?source=collection_archive---------0-----------------------#2017-03-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="dd6c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">常用操作初学者指南</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b1306b0f16a600418464e40ef850d8e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XlZoLDzJkT3PR-v969keXQ.png"/></div></div></figure><p id="7072" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在杰瑞米·霍华德出色的<a class="ae ln" href="http://course.fast.ai/" rel="noopener ugc nofollow" target="_blank">深度学习课程</a>中，我意识到我对先决条件有点生疏，我的模糊性影响了我理解反向传播等概念的能力。我决定就这些话题整理几个维基页面来提高我的理解。这里是深度学习中使用的一些更常见的线性代数运算的非常基本的介绍。<strong class="kt ir">新</strong>:查看<a class="ae ln" href="http://ml-cheatsheet.readthedocs.io" rel="noopener ugc nofollow" target="_blank">机器学习备忘单</a>了解更多主题。</p><h2 id="37cb" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">什么是线性代数？</h2><p id="37d4" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">在深度学习的背景下，线性代数是一个数学工具箱，为同时操作多组数字提供了有用的技术。它提供了像向量和矩阵(电子表格)这样的结构来保存这些数字，以及如何加、减、乘、除这些数字的新规则。</p><h2 id="e938" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">为什么有用？</h2><p id="e4d7" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">它把复杂的问题变成简单、直观、有效计算的问题。这是一个线性代数如何实现更快的速度和更简单的例子。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="4c50" class="lo lp iq mn b gy mr ms l mt mu"><em class="mv"># Multiply two arrays </em><br/>x = [1,2,3]<br/>y = [2,3,4]<br/>product = []<br/>for i in range(len(x)):<br/>    product.append(x[i]*y[i])</span><span id="b186" class="lo lp iq mn b gy mw ms l mt mu"><em class="mv"># Linear algebra version</em><br/>x = numpy.array([1,2,3])<br/>y = numpy.array([2,3,4])<br/>x * y</span></pre><p id="facb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">初始化数组后，线性代数方法的速度提高了 3 倍。</p><h2 id="86a2" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated"><strong class="ak">在深度学习中是如何使用的？</strong></h2><p id="7200" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">神经网络将权重存储在矩阵中。线性代数让矩阵运算变得快速简单，尤其是在 GPU 上训练的时候。事实上，GPU 是在考虑向量和矩阵运算的情况下创建的。与图像可以表示为像素阵列类似，视频游戏使用巨大的、不断发展的矩阵来产生引人注目的游戏体验。GPU 不是逐个处理像素，而是并行处理整个像素矩阵。</p><h1 id="797b" class="mx lp iq bd lq my mz na lt nb nc nd lw jw ne jx lz jz nf ka mc kc ng kd mf nh bi translated">向量</h1><p id="9164" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">向量是数字或术语的一维数组。在几何学中，向量存储了一个点的潜在变化的大小和方向。向量[3，-2]表示向右 3，向下 2。一维以上的向量称为矩阵。</p><h2 id="0c47" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">向量记法</h2><p id="8cb6" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">有多种方法来表示向量。这里有一些你可能会在阅读中遇到的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/c90f27d22da220259b8d4d82e914b47e.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*TKIHYegDrAPNowYwfSUIIA.png"/></div></figure><h2 id="2cec" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">几何中的向量</h2><p id="9723" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">向量通常表示从一个点开始的运动。它们存储了一个点的潜在变化的<strong class="kt ir">幅度</strong>和<strong class="kt ir">方向</strong>。向量[-2，5]表示向左移动 2 个单位，向上移动 5 个单位。<a class="ae ln" href="http://mathinsight.org/vector_introduction" rel="noopener ugc nofollow" target="_blank">来源</a>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/334649e1047f24af0591a5fe93c92d4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*KvtcBmg81-SuT60g8VVckw.png"/></div><figcaption class="nk nl gj gh gi nm nn bd b be z dk">v = [-2, 5]</figcaption></figure><p id="c59f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">矢量可以应用于空间中的任何一点。向量的方向等于向上移动 5°和向左移动 2°所产生的斜边的斜率。它的大小等于斜边的长度。</p><h2 id="5827" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">标量运算</h2><p id="5060" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">标量运算涉及一个向量和一个数。通过对向量中的所有值进行加、减或乘运算，可以就地修改向量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi no"><img src="../Images/2778c91426679d4432f864cfd3051dd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/format:webp/1*g7cc0GkA7xrkhoh-__Ok3g.png"/></div><figcaption class="nk nl gj gh gi nm nn bd b be z dk">Scalar addition</figcaption></figure><h2 id="00aa" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">元素式操作</h2><p id="9dea" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">在像加、减、除这样的元素运算中，位置对应的值被组合起来产生一个新的向量。向量 A 中的第一个值与向量 b 中的第一个值配对，第二个值与第二个值配对，依此类推。这意味着向量必须有相等的维数才能完成运算。*</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi np"><img src="../Images/1da459b850cf20df7eb97be1d6133cb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*FOAYY9lvg1FPfiHIhm7z5Q.png"/></div><figcaption class="nk nl gj gh gi nm nn bd b be z dk">Vector addition</figcaption></figure><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="586e" class="lo lp iq mn b gy mr ms l mt mu">y = np.array([1,2,3])<br/>x = np.array([2,3,4])<br/>y + x = [3, 5, 7]<br/>y - x = [-1, -1, -1]<br/>y / x = [.5, .67, .75]</span></pre><p id="a07e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">*有关 numpy 中<a class="ae ln" href="https://docs.scipy.org/doc/numpy-1.10.0/user/basics.broadcasting.html" rel="noopener ugc nofollow" target="_blank">广播</a>的详细信息，请参见下文。</p><h2 id="cf2b" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">矢乘法</h2><p id="2ee4" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">矢量乘法有两种类型:点积和哈达玛积。</p><h2 id="557f" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">点积</h2><p id="d90c" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">两个向量的点积是一个标量。向量和矩阵的点积(矩阵乘法)是深度学习中最重要的运算之一。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/d334a3c7cfee0189e63cf5700b548023.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*m5enBfhctMzed5ian-YDDQ.png"/></div></figure><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="4540" class="lo lp iq mn b gy mr ms l mt mu">y = np.array([1,2,3])<br/>x = np.array([2,3,4])<br/>np.dot(y,x) = 20</span></pre><h2 id="9c6a" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">哈达玛乘积</h2><p id="79d0" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">哈达玛乘积是逐元素乘法，它输出一个向量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/bc22c17d2247d4956cfe41417af87227.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*pU5dS3VF0f6xvEhziE-x6A.png"/></div></figure><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="cf07" class="lo lp iq mn b gy mr ms l mt mu">y = np.array([1,2,3])<br/>x = np.array([2,3,4])<br/>y * x = [2, 6, 12]</span></pre><h2 id="26a3" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">向量场</h2><p id="7a97" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">向量场显示了如果我们对点<em class="mv"> (x，y) </em>应用像加法或乘法这样的向量函数，该点会假设移动多远。给定空间中的一个点，矢量场显示了我们提出的在图中的多个点处的<strong class="kt ir"> <em class="mv">功率</em> </strong>和<strong class="kt ir"> <em class="mv">方向</em> </strong>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/c288b3d1947ea430b974c734602698e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*rAhajNrQkK9-rdt7gdt2hw.png"/></div><figcaption class="nk nl gj gh gi nm nn bd b be z dk"><a class="ae ln" href="https://en.wikipedia.org/wiki/Vector_field" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="035b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个向量场很有趣，因为它根据起点向不同的方向移动。原因是该字段后面的向量存储类似于<em class="mv"> 2x </em>或<em class="mv"> x </em>的项，而不是类似于-2 和 5 的标量值。对于图上的每个点，我们将 x 坐标插入到<em class="mv"> 2x </em>或<em class="mv"> x </em>中，并绘制一个从起点到新位置的箭头。向量场对于可视化机器学习技术(如梯度下降)非常有用。</p><h1 id="594b" class="mx lp iq bd lq my mz na lt nb nc nd lw jw ne jx lz jz nf ka mc kc ng kd mf nh bi translated">矩阵</h1><p id="4b86" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">矩阵是数字或术语的矩形网格(类似于 Excel 电子表格)，具有特殊的加法、减法和乘法规则。</p><h2 id="e86c" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">矩阵维度</h2><p id="1778" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">我们用<em class="mv">行和</em>列来描述矩阵的维数。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/cb74fc0f98e0d34304a9feff2535f122.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*x3aV7Yi3kkxRdN6hakkEfA.png"/></div></figure><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="df1c" class="lo lp iq mn b gy mr ms l mt mu">a = np.array([<br/> [1,2,3], <br/> [4,5,6]<br/>])<br/>a.shape == (2,3)</span><span id="05a9" class="lo lp iq mn b gy mw ms l mt mu">b = np.array([<br/> [1,2,3]<br/>])<br/>b.shape == (1,3)</span></pre><h2 id="b91e" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">矩阵标量运算</h2><p id="efaa" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">对矩阵的标量运算与对向量的运算方式相同。只需将标量应用于矩阵中的每个元素——加、减、除、乘等。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/b58f6ee47c37e582ecede00cb0ab89a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*vCxvsA9nqxwQw2PCk368-g.png"/></div><figcaption class="nk nl gj gh gi nm nn bd b be z dk">Matrix scalar addition</figcaption></figure><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="7f70" class="lo lp iq mn b gy mr ms l mt mu">a = np.array(<br/>[[1,2], <br/> [3,4]])<br/>a + 1<br/>[[2,3], <br/> [4,5]]</span></pre><h2 id="79fb" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">矩阵元素运算</h2><p id="9176" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">为了加、减或除两个矩阵，它们必须有相等的维数。*我们以元素方式组合相应的值，以生成新的矩阵。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/c4e49a39a6550c7c387748485c206e06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*C2_V94g-ePcO4oritMulIA.png"/></div></figure><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="25a7" class="lo lp iq mn b gy mr ms l mt mu">a = np.array([<br/> [1,2],<br/> [3,4]<br/>])<br/>b = np.array([<br/> [1,2],<br/> [3,4]<br/>])</span><span id="661c" class="lo lp iq mn b gy mw ms l mt mu">a + b<br/>[[2, 4],<br/> [6, 8]]</span><span id="926a" class="lo lp iq mn b gy mw ms l mt mu">a — b<br/>[[0, 0],<br/> [0, 0]]</span></pre><h2 id="36e6" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">数字广播*</h2><p id="00f9" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">我不能逃避谈论这个，因为它在实践中非常相关。在 numpy 中，通过一种叫做<a class="ae ln" href="https://docs.scipy.org/doc/numpy-1.10.0/user/basics.broadcasting.html" rel="noopener ugc nofollow" target="_blank">广播</a>的机制放宽了元素操作的维度要求。如果每个矩阵中的相应维度(行与行、列与列)满足以下要求，则两个矩阵是兼容的:</p><ol class=""><li id="a3fa" class="nw nx iq kt b ku kv kx ky la ny le nz li oa lm ob oc od oe bi translated">尺寸相等，或</li><li id="4ddb" class="nw nx iq kt b ku of kx og la oh le oi li oj lm ob oc od oe bi translated">一个维度的大小为 1</li></ol><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="377e" class="lo lp iq mn b gy mr ms l mt mu">a = np.array([<br/> [1],<br/> [2]<br/>])<br/>b = np.array([<br/> [3,4],<br/> [5,6]<br/>])<br/>c = np.array([<br/> [1,2]<br/>])</span><span id="3f34" class="lo lp iq mn b gy mw ms l mt mu"># Same no. of rows<br/># Different no. of columns<br/># but <strong class="mn ir">a</strong> has one column so this works<br/>a * b<br/>[[ 3, 4],<br/> [10, 12]]</span><span id="e3a0" class="lo lp iq mn b gy mw ms l mt mu"># Same no. of columns<br/># Different no. of rows<br/># but <strong class="mn ir">c</strong> has one row so this works<br/>b * c<br/>[[ 3, 8],<br/> [5, 12]]</span><span id="515d" class="lo lp iq mn b gy mw ms l mt mu"># Different no. of columns<br/># Different no. of rows<br/># but both <strong class="mn ir">a</strong> and <strong class="mn ir">c</strong> meet the <br/># size 1 requirement rule<br/>a + c<br/>[[2, 3],<br/> [3, 4]]</span></pre><p id="ae1e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在更高的维度——3D，4D，事情会变得更奇怪，但现在我们不会担心这个。了解 2D 的运作是一个良好的开端。</p><h2 id="9078" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">矩阵 Hadamard 积</h2><p id="a3c5" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">矩阵的 Hadamard 乘积是一种元素运算。位置对应的值相乘产生新的矩阵。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/6d7015cbc6a80927b7e7a63829e0945b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*mMMLhITl5GIPE036wwuWeQ.png"/></div></figure><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="b14e" class="lo lp iq mn b gy mr ms l mt mu">a = np.array(<br/>[[2,3],<br/> [2,3]])<br/>b = np.array(<br/>[[3,4],<br/> [5,6]])</span><span id="3a9e" class="lo lp iq mn b gy mw ms l mt mu"># Uses python's multiply operator<br/>a * b<br/>[[ 6, 12],<br/> [10, 18]]</span></pre><p id="b86e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在 numpy 中，只要矩阵和向量的维数满足广播的要求，就可以取它们的 Hadamard 积。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/1f868a108e990fa2af294801c008577e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*oUldHfVCEt9GCOUlcZS0Bg.png"/></div></figure><h2 id="81e3" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">矩阵转置</h2><p id="5c5f" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">神经网络经常处理不同大小的权重和输入，其中维数不满足矩阵乘法的要求。矩阵转置提供了一种“旋转”其中一个矩阵的方法，以便操作符合乘法要求并可以继续。转置矩阵有两个步骤:</p><ol class=""><li id="23db" class="nw nx iq kt b ku kv kx ky la ny le nz li oa lm ob oc od oe bi translated">将矩阵向右旋转 90 度</li><li id="1e0e" class="nw nx iq kt b ku of kx og la oh le oi li oj lm ob oc od oe bi translated">颠倒每行中元素的顺序(例如，[a b c]变成[c b a])</li></ol><p id="0aac" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">举个例子，把矩阵<strong class="kt ir"> M </strong>转置成<strong class="kt ir"> T </strong>:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/35a745b93faf1ebebb5aa3d8c48dc725.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*OAMY1Ih28NwKvjK8IeNjAg.png"/></div></figure><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="4654" class="lo lp iq mn b gy mr ms l mt mu">a = np.array([<br/>   [1, 2], <br/>   [3, 4]])</span><span id="b200" class="lo lp iq mn b gy mw ms l mt mu">a.T<br/>[[1, 3],<br/> [2, 4]]<br/></span></pre><h1 id="1cbc" class="mx lp iq bd lq my mz na lt nb nc nd lw jw ne jx lz jz nf ka mc kc ng kd mf nh bi translated">矩阵乘法</h1><p id="f42b" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">矩阵乘法指定了一组将矩阵相乘以生成新矩阵的规则。</p><h2 id="b1af" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">规则</h2><p id="0ff4" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">并非所有矩阵都适合乘法。此外，对最终矩阵输出的尺寸也有要求。<a class="ae ln" href="https://www.khanacademy.org/math/precalculus/precalc-matrices/properties-of-matrix-multiplication/a/properties-of-matrix-multiplication" rel="noopener ugc nofollow" target="_blank">来源</a>。</p><ol class=""><li id="3285" class="nw nx iq kt b ku kv kx ky la ny le nz li oa lm ob oc od oe bi translated">第一个 矩阵的<strong class="kt ir"> <em class="mv">列数必须等于第二个</em> </strong>矩阵的<strong class="kt ir"> <em class="mv">行数</em></strong></li><li id="0a9b" class="nw nx iq kt b ku of kx og la oh le oi li oj lm ob oc od oe bi translated">一个 M×N 矩阵和一个 N×K 矩阵的乘积是一个 M×K 矩阵。新矩阵取第一个 的<strong class="kt ir"> <em class="mv">行和第二个</em> </strong>的<strong class="kt ir"> <em class="mv">列</em></strong></li></ol><h2 id="d05d" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">步伐</h2><p id="bef0" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">矩阵乘法依靠点积来乘以各种行和列的组合。下图取自汗学院的优秀线性代数课程，矩阵 C 中的每个条目都是矩阵 A 中的一行和矩阵 b 中的一列的点积。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi on"><img src="../Images/73692f2863ce5e3ed04781c91d9aa4bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*6VfYsZRssGbVVY88ap_wzA.png"/></div><figcaption class="nk nl gj gh gi nm nn bd b be z dk"><a class="ae ln" href="https://www.khanacademy.org/math/precalculus/precalc-matrices/properties-of-matrix-multiplication/a/properties-of-matrix-multiplication" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="a9e7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">操作<strong class="kt ir"><em class="mv">a1</em><em class="mv">B1</em></strong>意味着我们取矩阵<em class="mv"> A (1，7) </em>中第一行和矩阵<em class="mv"> B (3，5)中第一列的点积。</em></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/e807091fe4f08b57be6ad90142f35b7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*SPSizSebvVRh8xQf9wsoew.png"/></div></figure><p id="0ab0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这是另一种看待它的方式:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi op"><img src="../Images/bd60b42fa8a0e8903798452e92c7364d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1174/format:webp/1*xu8Eqqn9Xx60Uz7DlZy14Q.png"/></div></figure><h2 id="3ebd" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">用这些例子测试你自己</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oq"><img src="../Images/2bab97f31166461f4dfdecfaf2e19ac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-P3n80ucmqXM6e0euVqOFQ.png"/></div></div></figure><h2 id="13fc" class="lo lp iq bd lq lr ls dn lt lu lv dp lw la lx ly lz le ma mb mc li md me mf mg bi translated">numpy 矩阵乘法</h2><p id="af8d" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated">Numpy 使用函数<code class="fe or os ot mn b">np.dot(A,B)</code>进行向量和矩阵乘法。它还有一些其他有趣的特性和陷阱，所以我鼓励你在使用前阅读文档<a class="ae ln" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><pre class="kg kh ki kj gt mm mn mo mp aw mq bi"><span id="0d7d" class="lo lp iq mn b gy mr ms l mt mu">a = np.array([<br/> [1, 2]<br/> ])<br/>a.shape == (1,2)</span><span id="b864" class="lo lp iq mn b gy mw ms l mt mu">b = np.array([<br/> [3, 4],<br/> [5, 6]<br/> ])<br/>b.shape == (2,2)</span><span id="8aad" class="lo lp iq mn b gy mw ms l mt mu"># Multiply<br/>mm = np.dot(a,b)<br/>mm == [13, 16]<br/>mm.shape == (1,2)</span></pre><h1 id="74d7" class="mx lp iq bd lq my mz na lt nb nc nd lw jw ne jx lz jz nf ka mc kc ng kd mf nh bi translated">教程</h1><p id="a0f3" class="pw-post-body-paragraph kr ks iq kt b ku mh jr kw kx mi ju kz la mj lc ld le mk lg lh li ml lk ll lm ij bi translated"><a class="ae ln" href="https://www.khanacademy.org/math/linear-algebra" rel="noopener ugc nofollow" target="_blank">可汗学院线性代数</a> <br/> <a class="ae ln" href="http://www.deeplearningbook.org/contents/part_basics.html" rel="noopener ugc nofollow" target="_blank">深度学习书籍数学部分</a> <br/> <a class="ae ln" href="https://www.coursera.org/learn/machine-learning/resources/JXWWS" rel="noopener ugc nofollow" target="_blank">吴恩达的课程笔记</a> <br/> <a class="ae ln" href="https://betterexplained.com/articles/linear-algebra-guide/" rel="noopener ugc nofollow" target="_blank">线性代数讲解</a> <br/> <a class="ae ln" href="http://blog.stata.com/2011/03/03/understanding-matrices-intuitively-part-1/" rel="noopener ugc nofollow" target="_blank">矩阵讲解</a> <br/> <a class="ae ln" href="http://www.holehouse.org/mlclass/03_Linear_algebra_review.html" rel="noopener ugc nofollow" target="_blank">线性代数入门</a> <br/> <a class="ae ln" href="https://minireference.com/static/tutorials/linear_algebra_in_4_pages.pdf" rel="noopener ugc nofollow" target="_blank">迷你参考线性代数 4 页</a></p></div></div>    
</body>
</html>