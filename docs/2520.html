<html>
<head>
<title>Creating a movie recommender using Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用卷积神经网络创建电影推荐器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/creating-a-movie-recommender-using-convolutional-neural-networks-be93e66464a7?source=collection_archive---------7-----------------------#2018-02-04">https://towardsdatascience.com/creating-a-movie-recommender-using-convolutional-neural-networks-be93e66464a7?source=collection_archive---------7-----------------------#2018-02-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="f57c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在网飞上看完你最喜欢的电视剧或YouTube上的视频后，你必须做出一个重要的决定，接下来我该看什么？很多时候你都是从自己喜欢的视频点播平台的推荐系统得到一些帮助。这些平台花费大量的时间和精力(参见:<a class="ae kl" href="https://dl.acm.org/citation.cfm?id=2843948" rel="noopener ugc nofollow" target="_blank">网飞推荐系统:算法、商业价值和创新</a> &amp; <a class="ae kl" href="https://static.googleusercontent.com/media/research.google.com/de//pubs/archive/45530.pdf" rel="noopener ugc nofollow" target="_blank">用于YouTube推荐的深度神经网络</a>)让你的用户体验尽可能愉快，增加你在平台上的总观看时间。但是即使有这些帮助，你如何选择呢？我通常会选择最吸引我的视频缩略图/海报。考虑到这一点，我构建了一个电影推荐器，它只接受电影缩略图/海报作为输入。让我们看看那是什么样子。</p><h2 id="ecb0" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated"><strong class="ak">主旨</strong></h2><p id="b684" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">主要思想是创建电影海报图像数据集，并从在<a class="ae kl" href="http://image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>上训练的预训练<a class="ae kl" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a> <strong class="jp ir"> </strong> (ConvNet)中提取特征。我将使用提取的特征来推荐给定目标电影海报的5个最相似的电影海报。为了验证这种方法，我将使用鞋子图像数据集做同样的事情。</p><h2 id="1c90" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated"><strong class="ak">第一步:网络抓取电影海报</strong></h2><p id="7f5f" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">首先我需要一些电影海报，我决定使用Kaggle上的<a class="ae kl" href="https://www.kaggle.com/tmdb/tmdb-movie-metadata/data" rel="noopener ugc nofollow" target="_blank"> TMDB 5000电影数据集</a>。有了数据集中提供的信息，我使用web scraping通过Python库<a class="ae kl" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank"> BeautifulSoup </a>从IMDB下载海报图像。我将海报id添加到每张图片的名称中，并将所有4911张成功下载的图片存储在一个文件夹中。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi lk"><img src="../Images/df7bcf1f707e2ccec74989cf3176313c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kNgogNwNlEs_BMN2wj-OyA.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk"><em class="ma">Image from: </em><a class="ae kl" href="https://www.kaggle.com/tmdb/tmdb-movie-metadata/data" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/tmdb/tmdb-movie-metadata/data</a></figcaption></figure><p id="085e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就是完整的<a class="ae kl" href="https://github.com/kkmlcode/webscraping/blob/master/WebScraping.ipynb" rel="noopener ugc nofollow" target="_blank"> WebScraping.ipynb </a>笔记本。</p><h2 id="5b73" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">第二步:推荐人</h2><p id="8899" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">我对基于海报图像的视觉方面寻找类似的电影海报感兴趣，因此我将使用ConvNets。就视觉识别而言，ConvNets目前是首选型号。对于我的推荐者，我不会从零开始训练一个ConvNet。但是在ImageNet上使用预先训练好的模型。从而节省时间并具有开箱即用的最新模型。这就叫<a class="ae kl" href="http://cs231n.github.io/transfer-learning/" rel="noopener ugc nofollow" target="_blank">“迁移学习”</a>。推荐者我会用Inception-v3模型。选择这种型号的原因之一是与VGG16或VGG19型号相比，输出阵列相对较小。使得处理内存中的所有内容变得更加容易。我感兴趣的是模型学习的特征，而不是类别概率。识别形状、图案等的预学习层。希望能提出有意义的建议。出于这个原因，我删除了输出层，并将ConvNet的其余部分作为电影海报的特征提取器。请参见此处的示例，了解每个图层或节点基于面部图像数据集可以了解的内容。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mb"><img src="../Images/d6d6d6428a3eb52c67b1c758ce0c486b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S7FwUd5xGL0GE8ovt_fHlQ.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk"><em class="ma">Image from: </em><a class="ae kl" href="https://cdn.edureka.co/blog/wp-content/uploads/2017/05/Deep-Neural-Network-What-is-Deep-Learning-Edureka.png" rel="noopener ugc nofollow" target="_blank"><em class="ma">https://cdn.edureka.co/blog/wp-content/uploads/2017/05/Deep-Neural-Network-What-is-Deep-Learning-Edureka.png</em></a></figcaption></figure><p id="9497" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于推荐器的实现，我使用带有TensorFlow的<a class="ae kl" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>作为后端。对于数据集中的每个图像，我保存模型最后一个隐藏层的展平输出数组。有了这个新的特征数组，我可以根据数组之间的欧氏距离来计算目标图像/海报的x个最近邻。为了将结果与基线进行比较，我还将使用给定目标海报的原始展平图像数组显示x个最近邻。我不会分享我所有的代码，但会在这个博客中分享一些代码片段。</p><p id="1438" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="mc">选择模型特征图层:</em></p><pre class="ll lm ln lo gt md me mf mg aw mh bi"><span id="fef1" class="km kn iq me b gy mi mj l mk ml">from keras.models import Model<br/>from keras.applications.inception_v3 import InceptionV3<br/>from keras.models import Model</span><span id="c923" class="km kn iq me b gy mm mj l mk ml">selectedlayer = "..."<br/>base_modelv3 = InceptionV3(weights='imagenet', include_top=False)<br/>model= Model(inputs=base_modelv3.input,  outputs=base_modelv3.get_layer(selectedlayer).output)</span></pre><p id="8f25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="mc">从图像中提取特征:</em></p><pre class="ll lm ln lo gt md me mf mg aw mh bi"><span id="4fc6" class="km kn iq me b gy mi mj l mk ml">from os import listdir<br/>from keras.preprocessing.image import load_img<br/>from keras.preprocessing.image import img_to_array</span><span id="cfc0" class="km kn iq me b gy mm mj l mk ml">def preprocess_input(x):<br/>    x /= 255.<br/>    x -= 0.5<br/>    x *= 2.<br/>    return x</span><span id="3bef" class="km kn iq me b gy mm mj l mk ml">def load_photos_predict(directory):<br/> images = []<br/> for name in listdir(directory):<br/>  # load an image from file<br/>  filename = directory + '/' + name<br/>  image = load_img(filename, target_size=(299, 299))<br/>  # convert the image pixels to a numpy array<br/>  image = img_to_array(image)<br/>  # reshape data for the model<br/>  image = np.expand_dims(image, axis=0)<br/>  # prepare the image for the  model<br/>  image = preprocess_input(image)<br/>  # get image id<br/>  image_id = name.split('.')[0]<br/>  feature = model.predict(image).ravel()<br/>  images.append((image_id, image, feature))<br/> return images</span></pre><p id="8810" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="mc">查找最近邻居:</em></p><pre class="ll lm ln lo gt md me mf mg aw mh bi"><span id="345c" class="km kn iq me b gy mi mj l mk ml">from sklearn.neighbors import NearestNeighbors<br/>import pandas as pd<br/>import numpy</span><span id="12d7" class="km kn iq me b gy mm mj l mk ml">nn_num = 6<br/>X = list(results[“modelfeatures”])</span><span id="2f24" class="km kn iq me b gy mm mj l mk ml">nbrs = NearestNeighbors(n_neighbors=nn_num, algorithm=’ball_tree’, metric=”euclidean”, n_jobs = -1).fit(X)</span></pre><h2 id="729c" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated"><strong class="ak">第三步:结果</strong></h2><p id="fafa" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">让我们来看看基于詹姆斯·邦德电影《幽灵》的推荐。我将展示基于原始展平图像阵列的5个推荐，以及基于Inception-v3模型的提取特征阵列的5个推荐。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mn"><img src="../Images/b3276d258fa8994588ad7ece62960571.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dv1f4mOi66XYJ8ehtda6Ow.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Recommender based on raw image array vs ConvNet features for James Bond — Specter</figcaption></figure><p id="e307" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">尽管我没有定义明确的评估标准，也没有利用A/B测试来确定哪种推荐方法是最好的，但直觉上，模型结果似乎稍好一些。该模型甚至推荐了一部额外的邦德电影《永不说永不》作为它的第四个推荐。让我们再看一部电影，印第安纳琼斯和水晶头骨王国。</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mn"><img src="../Images/4beb0034d53e68ad83ae3120462dba50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZuBbb0_Xc6qsvdVM5zJwng.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Recommender based on raw image array vs ConvNet features for Indiana Jones and the Kingdom of the Crystal Skull</figcaption></figure><p id="690f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该模型推荐印第安纳琼斯和最后的十字军东征作为其第一推荐，这看起来很好。其他的就不太合适了，但是ConvNet特性的表现似乎又比只使用原始图像数组作为输入要好。</p><p id="bc48" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="mc">显示结果功能:</em></p><pre class="ll lm ln lo gt md me mf mg aw mh bi"><span id="ec44" class="km kn iq me b gy mi mj l mk ml">import matplotlib.pyplot as plt</span><span id="0f03" class="km kn iq me b gy mm mj l mk ml">def udfsimular(indices, table):<br/> neighbours = []<br/> for i in range(len(indices)): <br/> t = indices[i]<br/> idv = table[(table.index == t)].iloc[0][‘ID’]<br/> neighbours.append(idv)<br/> return neighbours</span><span id="f15f" class="km kn iq me b gy mm mj l mk ml">def udfidfpathh(ids,directory):<br/> paths = []<br/> for i in range(len(ids)): <br/> t = ids[i]<br/> filename = wdir + directory + t + “.jpg”<br/> paths.append(filename)<br/> return paths</span><span id="2655" class="km kn iq me b gy mm mj l mk ml">def show5recommendations(name, table, NearestN,  idnr, directory, columnfeature):<br/>    key = table[(table.ID == idnr)].iloc[0][columnfeature]<br/>    distances, indices = NearestN.kneighbors(key)<br/>    listindices = pd.DataFrame(indices).values.tolist()<br/>    listindices2 = listindices[0]<br/>    ids = udfsimular(listindices2, table)<br/>    paths2 = udfidfpathh(ids,directory)<br/>    fig, ((ax1, ax2, ax3, ax4, ax5, ax6)) = plt.subplots(nrows=1, ncols=6, sharex=True, sharey=True, figsize=(14,3))<br/>    # Doing each of these manually (ugh)<br/>    ax1.imshow(mpimg.imread(paths2[0]))<br/>    ax1.set_title(r"$\bf{" + str(name) + "}$"+"\n Targer:\n"+ ids[0])<br/>    ax1.set_yticklabels([])<br/>    ax2.imshow(mpimg.imread(paths2[1]))<br/>    ax2.set_title("Rec 1:\n"+ ids[1])<br/>    ax3.imshow(mpimg.imread(paths2[2]))<br/>    ax3.set_title("Rec 2:\n"+ ids[2])<br/>    ax4.imshow(mpimg.imread(paths2[3]))<br/>    ax4.set_title("Rec 3:\n"+ ids[3])<br/>    ax5.imshow(mpimg.imread(paths2[4]))<br/>    ax5.set_title("Rec 4:\n"+ ids[4])<br/>    ax6.imshow(mpimg.imread(paths2[5]))<br/>    ax6.set_title("Rec 5:\n"+ ids[5])</span></pre><h2 id="f457" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated"><strong class="ak">步骤4:使用鞋子图像验证推荐器</strong></h2><p id="b108" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">既然我们已经看到了它对电影海报的效果，让我们使用一个不同的数据集。像亚马逊、Zalando和其他网上商店这样的网站使用类似的技术向你推荐产品。例如，你要找的商品缺货，他们想向你推荐类似的产品。所以让我们用鞋的图像。我使用的数据集是从Zappos50K的<a class="ae kl" href="http://www.zappos.com/" rel="noopener ugc nofollow" target="_blank">收集的目录图像的</a><a class="ae kl" href="http://vision.cs.utexas.edu/projects/finegrained/utzap50k/" rel="noopener ugc nofollow" target="_blank"> UT Zappos50K </a>。我用了1882张鞋子图片。</p><p id="e579" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，让我们在这个数据集上重复同样的方法，看看“黑色开口高跟鞋”的结果是什么:</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mo"><img src="../Images/713686278d593642597b41d4d4cce8e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m10KNS6_vjYRz_S8ww4lFA.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Recommender based on raw image array vs ConvNet features for a black open high heel shoe</figcaption></figure><p id="3754" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基于提取的特征，模型显然学会了区分鞋子的不同图案。而正常阵列的建议显然不知道什么是开鞋。运动鞋怎么样:</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="gh gi mp"><img src="../Images/20f626b9837d695093571cabc4d0204f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vsIo2elz8cKlUmkPF4QnTg.png"/></div></div><figcaption class="lw lx gj gh gi ly lz bd b be z dk">Recommender based on raw image array vs ConvNet features for a sneaker shoe</figcaption></figure><p id="c800" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">再次推荐。</p><p id="e405" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">那么，为什么这些结果比电影海报的结果要好呢？</strong></p><p id="046a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Inception-v3模型在ImageNet上进行训练，以区分1000个类预测。模型被训练的图像每个图像有一个对象/类。它接受训练的1000个班级中有一个甚至被称为“<a class="ae kl" href="http://imagenet.stanford.edu/synset?wnid=n04120489" rel="noopener ugc nofollow" target="_blank">跑鞋</a>”。预测每个图像的一个对象是模型被训练的目的，也应该是模型做得最好的。而电影海报在对象、文本等的数量上要复杂得多。因此，使用在不同图像数据集上训练的模型可以为电影海报产生更好的结果。</p><h2 id="1d54" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated"><strong class="ak">最后备注</strong></h2><p id="37ac" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">正如我们所看到的，仅使用电影海报结合预先训练的ConvNets来创建电影推荐器确实会产生一些不错的推荐。结果略好于仅使用原始图像阵列。对于鞋子，这种方法已经显示了一些非常好的建议。看到ConvNets的纯视觉识别功能已经可以做什么是很有趣的。根据推荐器创建的预期目的或行业，这似乎是一个很好的附加功能，可以添加到用于开发最先进的推荐系统的功能集中。</p></div></div>    
</body>
</html>