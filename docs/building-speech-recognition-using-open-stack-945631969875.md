# 使用开放堆栈构建语音识别

> 原文：<https://towardsdatascience.com/building-speech-recognition-using-open-stack-945631969875?source=collection_archive---------2----------------------->

语音识别是新的用户界面，将带来我们与应用程序和机器交互方式的范式转变。说“关掉微波炉”，“订购我的每周用品”比使用触摸和点击界面以及(重新)学习应用程序界面要容易得多。事实上，语音是人类开发的原始通信协议。我们并没有进化到通过点击苹果/三星设备来交流。

我最近实现了一个语音识别系统。我对这个领域缺乏好的和简单的博客/帖子感到非常沮丧。希望这篇文章能消除人们的疑虑，引导试图首次创建语音识别系统的人朝着正确的方向前进。

首先，你创建自动语音识别系统的动机是什么？我可以想到一些创建自己的 ASR 的情况:

1.  您的应用程序有一个语音识别用例，主要用于零/低带宽环境。因此，将 ASR 作为您的应用程序的一部分供离线使用是有意义的。
2.  您所在的行业受到监管，如医疗或金融行业，个人身份信息不能发送到苹果/谷歌/微软服务器进行转录。
3.  你想做一个 ASR 系统，在小词汇量上转录非母语外国口音。

在大多数其他情况下，将你的应用程序与苹果/谷歌/微软现有的语音 API 集成是完全有意义的。(注意，亚马逊 Alexa 不是一种语音转录技术)毕竟，这些科技巨头可以在庞大的语料库上训练他们的语音模型，你可以期待他们的转录中真的很低的 WER(单词错误率)。

我试过苹果的 ASR speech kit，还不错。我没有尝试过谷歌，但尝试过必应语音 API，对它的转录质量印象深刻。

好吧，如果谷歌/微软/苹果的语音 API 不能满足你的需求，那么你应该自己开发。

在这篇文章中，我将回顾使用传统的基于 GMM/DNN-HMM 模型的语音识别堆栈。高斯混合模型(GMM)/深度神经网络(DNN)用于模拟语音中的音素。音素是语音的原子单位，英语中大约有 40 个音素。隐马尔可夫模型(HMM)用于基于音素序列生成单词。ASR 的最新技术状态是使用递归神经网络实现的，其中通过使用允许预测字符级转录的目标函数来丢弃音素:[连接主义者时间分类](http://www.cs.toronto.edu/~graves/icml_2006.pdf) (CTC)。

以下是开源 ASR 的主要竞争者:

*   卡尔迪
*   CMU 狮身人面像

还有其他竞争者，如 HTK、Julius、ISIP，但我没有把他们包括在我的分析中，原因有很多->不是严格的开源，不容易实现，转录质量差等等。

**易于实施**

CMU 斯芬克斯轻而易举地击败了卡尔迪。CMU·斯芬克斯的教程很容易理解。另一方面，我发现 Kaldi 的实现又密集又困难。最初，我甚至很难在我的机器上实现一个简单的数字识别设置。有了 CMU·斯芬克斯，我在阅读的几个小时内就准备好了。

**支持移动设备**

CMU 狮身人面像再次击败了卡尔迪。CMU Sphinx 拥有易于实现的 iOS 和 Android SDK(pocket Sphinx)。卡尔迪实际上没有。原因是 Kaldi 创建了大约 5–7G 的巨大 FST 模型文件，这些文件在实时搜索和查询以生成转录时计算量非常大。

**转录质量**

卡尔迪打败了 CMU·斯芬克斯，这就是我坚持使用卡尔迪的原因。对于我的应用用例的一小部分词汇来说，卡尔迪一直胜过 CMU·斯芬克斯。

我知道这是一篇很长的文章，但是希望这篇文章能为你选择合适的栈来构建你自己的 ASR 系统提供一些指导。