<html>
<head>
<title>NLP For Topic Modeling &amp; Summarization Of Legal Documents.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">法律文档主题建模和摘要的自然语言处理。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/nlp-for-topic-modeling-summarization-of-legal-documents-8c89393b1534?source=collection_archive---------1-----------------------#2018-01-25">https://towardsdatascience.com/nlp-for-topic-modeling-summarization-of-legal-documents-8c89393b1534?source=collection_archive---------1-----------------------#2018-01-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/6b293910039dbe58ab4ff150a6fba3b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WhUSm-j7JM826cPHQbp2Zw.jpeg"/></div></div></figure><div class=""/><p id="f454" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi kw translated">你有没有想过律师是如何有效地处理一系列法庭陈述的？他们如何绕开法律文件的总体背景，以便在最终不得不着手处理之前弄清楚需要注意什么。看起来很容易，除非你有一个3000页的文档，里面有突出的细节。这就是这个项目背后的动机，从法律文档的pdf中自动建模主题并总结关键上下文。</p><p id="c03e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该项目旨在从双方签订的一份长达5页的<strong class="ka jc">商标和域名协议</strong>中自动建立话题模型，以提取对双方有利或不利的话题上下文。这种方法包括:从文档的pdf副本中提取文本，清理提取的文本，从文档中建模主题，并显示可视摘要。注意，这里采用的方法可以扩展到几乎所有保存为pdf格式的文档。</p><p id="a8b9" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">从PDF文档中提取文本</strong></p><p id="9902" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi kw translated">双方之间的法律协议以pdf文档的形式提供。首先使用下面显示的函数从pdf文档中提取文本。该函数使用python库<a class="ae lf" href="https://github.com/euske/pdfminer" rel="noopener ugc nofollow" target="_blank"> <em class="lg"> pdf-miner </em> </a> <em class="lg">从pdf文档中提取除图像之外的所有字符(尽管我可以修改以适应这一点)。</em>该函数只接受主目录中pdf文档的名称，从中提取所有字符，并将提取的文本作为字符串的python列表输出。</p><figure class="li lj lk ll gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lh"><img src="../Images/bb981cec34d458a8b7e4c0dd86be4059.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xLuQc0Vx4GGhp7HdRaBxCw.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Figure showing the function that extracts texts from a pdf document</figcaption></figure><p id="9028" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">清理提取文本</strong></p><p id="a589" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi kw translated">从pdf文档中提取的文本包含需要删除的无用字符。这些字符降低了我们的模型的有效性，因为它们提供了不必要的计数比。下面的函数使用了一系列的<a class="ae lf" href="https://en.wikipedia.org/wiki/Regular_expression" rel="noopener ugc nofollow" target="_blank"> <strong class="ka jc"> <em class="lg">正则表达式</em> </strong> </a> <em class="lg"> </em>搜索和替换函数以及一个列表理解来用空格替换这些字符。以下函数用于此过程，显示的结果文档仅包含字母数字字符。</p><figure class="li lj lk ll gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lq"><img src="../Images/a6a81dcf1475247ad8dcdcc157233467.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bEZA0IsbWUEFiV_ZlnreCg.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Figure showing code which replaces document coding with blank space</figcaption></figure><figure class="li lj lk ll gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lr"><img src="../Images/123341abd1ef618d1fbe549f36f60f69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_BEcuY8oMN0bWcoh44lCzQ.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Figure showing code which replaces non-alpha characters with blank space</figcaption></figure><p id="521a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">主题建模</strong></p><p id="c22b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi kw translated"><span class="l kx ky kz bm la lb lc ld le di"> T </span>使用scikit-learn模块<a class="ae lf" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank"> <em class="lg">计数矢量器</em> </a>进行最小参数调整，将干净文档表示为DocumentTermMatrix。这是因为建模要求将字符串表示为整数。CountVectorizer显示删除停用字词后，某个字词在列表中出现的次数。</p><figure class="li lj lk ll gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ls"><img src="../Images/890e00a837b0b5837982b8f0d2d608a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wvcR_0nUfwsU6o7VKZappA.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Figure showing how the CountVectorizer is fitted on the document with stop-words</figcaption></figure><p id="edbb" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">文档术语矩阵被格式化为pandas数据框架，以便浏览数据集，如下所示。该数据框显示了文档中每个术语的单词出现次数。在没有格式化为数据帧的情况下，文档术语矩阵作为稀疏矩阵存在，并且应该使用<strong class="ka jc"> <em class="lg"> todense() </em> </strong>或<strong class="ka jc"> <em class="lg"> toarray()将其转换为密集矩阵。</em>T13】</strong></p><figure class="li lj lk ll gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lt"><img src="../Images/1e1c9357d123dbf6cfac779254d6112e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2uGPK-woSl2rA8e4Hmh2Pg.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Figure showing a cross-section of the output from the CountVectorizer</figcaption></figure><p id="3d5d" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该文档术语矩阵被用作由<a class="ae lf" href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html" rel="noopener ugc nofollow" target="_blank"> <em class="lg">潜在狄利克雷分配</em> </a> <em class="lg">算法</em>用于主题建模的输入数据。现在这个LDA算法有几个不同的实现，但是对于这个项目，我将使用<a class="ae lf" href="http://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"><em class="lg">scikit-learn</em></a><em class="lg"/>实现。另一个非常著名的LDA实现是Radim Rehurek的<a class="ae lf" href="https://radimrehurek.com/gensim/" rel="noopener ugc nofollow" target="_blank"> gensim </a>。这适合于由计数矢量器输出的文档术语矩阵。该算法适合于隔离五个不同的主题上下文，如下面的代码所示。这个值肯定可以根据您想要从建模中获得的粒度级别进行更改。</p><figure class="li lj lk ll gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lu"><img src="../Images/0a3150c62019c88819f7f7639389d1c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bkYSqC8BUu_XPaP5kJu_yw.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Figure showing how the LDA model was fitted on the DocumentTermMatrix with 5 topics</figcaption></figure><p id="1a95" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下面的代码使用<a class="ae lf" href="https://github.com/amueller/mglearn" rel="noopener ugc nofollow" target="_blank"> <em class="lg"> mglearn </em> </a>库来显示每个特定主题模型中的前10个单词。人们可以很容易地从每个主题所呈现的单词中总结出结论。</p><figure class="li lj lk ll gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lv"><img src="../Images/d3d2010423519d58e55bbd1aa1e381da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HLHN-JyqoFPuXNg1gvN8Gw.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Figure showing the 5 topics from LDA and the most common words in each topic</figcaption></figure><p id="b706" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从以上结果来看，显然主题2与商标所有权协议条款和条件有很大关系。话题1谈论涉及签名和一些义务的当事人之间的协议。ECLIPSE一词似乎在所有五个主题中都很普遍，这表明了它在整个文档中的相关性。</p><p id="55f4" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这一结果与文件<strong class="ka jc">(商标和域名协议)非常一致。</strong></p><p id="4cde" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了更细致地观察每个主题，我们提取每个主题模型的句子进行简要总结。下面的代码从主题1和主题4中提取了前4个句子。</p><figure class="li lj lk ll gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lw"><img src="../Images/30af22f070a793c708b565673556a22d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xOKGjaWKc50dkDH1VQVS9Q.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Figure showing sentences within Topic model 1 and 4</figcaption></figure><p id="c23e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Topic-1中的句子讨论了根据纽约市的法律将商标转让给eclipse的问题。</p><p id="b659" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，题目4中的句子清楚地表明了域名和商标协议的生效日期。</p><p id="074c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">结果可视化</strong></p><p id="a440" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi kw translated"><span class="l kx ky kz bm la lb lc ld le di"> T </span>何<a class="ae lf" href="https://github.com/bmabey/pyLDAvis" rel="noopener ugc nofollow" target="_blank">T5】pyl DavisT7】库用于可视化主题模型。请注意主题1和主题4之间的关系有多密切，主题2、主题3和主题5之间的距离有多远。这些主题(2、3和5)捕获了法律文档中相对不同的主题，并且是那些应该更仔细观察的主题，因为它们在组合时会提供文档的更宽视图:</a></p><figure class="li lj lk ll gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lx"><img src="../Images/8f3a8d49779fe243cdb2b416b03a7c63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hKodmKBSksF86AiL3EdSQA.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Figure showing how distinct each modelled topic is from one another</figcaption></figure><p id="97f9" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从下图可以看出，话题5指的是双方之间的协议、义务和签名，而话题3谈论的是域名、头衔和商标。</p><figure class="li lj lk ll gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ly"><img src="../Images/5cfea0b6f565840a1d3c599e4e6b1cc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0rK4UDXVJ9t4exr2GePnDg.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Figure showing the words which are most frequent in Topic-3</figcaption></figure><figure class="li lj lk ll gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lz"><img src="../Images/a745c31eebe1aa90cac08917724d4a19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BtBxTpA8J2wgyvjYaoSYCw.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Figure showing the words which are most frequent in Topic-3</figcaption></figure><p id="c657" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">还为整个法律文档生成了一个<a class="ae lf" href="https://github.com/amueller/word_cloud" rel="noopener ugc nofollow" target="_blank"> wordcloud </a>，以记录文档中最常出现的术语，如下图所示。这通常与主题建模的结果一致，因为像<em class="lg">商标、协议、域名、eclipse等</em>这样的词被视为重复出现，因此更加醒目。</p><figure class="li lj lk ll gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ma"><img src="../Images/ff0947243a256c4f6d63df84d083fdc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nu1HvjMF9VA81sq5e2xfYg.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">A wordcloud showing the most occurrent words/phrases in the legal document</figcaption></figure><p id="1884" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">结论</strong></p><p id="47e1" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi kw translated"><span class="l kx ky kz bm la lb lc ld le di"> B </span> y将通过潜在狄利克雷分配模型获得的主题2、3和5与为法律文件生成的词云相结合，我们可以有把握地推断出该文件是双方之间对商标域名转让的简单法律约束。</p><p id="f7b2" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这个项目遵循一个简单的方法来从pdf文档中提取文本，这个项目可以修改以从图像文件中提取文本。jpeg。png)，从而可以在文档快照上进行主题建模和摘要。该项目显示了机器学习如何应用于法律部门，通常用于提供主题的文档摘要。</p><p id="fb8c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这个项目的一个更实际的应用是在小说、教科书等的章节上进行文本摘要，它已经被证明是非常有效的。</p><h2 id="3d4f" class="mb mc jb bd md me mf dn mg mh mi dp mj kj mk ml mm kn mn mo mp kr mq mr ms mt bi translated">用于此分析的代码(IPython笔记本)的链接可以在我的github页面上找到:<a class="ae lf" href="https://github.com/chibueze07/Machine-Learning-In-Law/tree/master" rel="noopener ugc nofollow" target="_blank">https://github . com/chibueze 07/Machine-Learning-In-Law/tree/master</a></h2></div></div>    
</body>
</html>