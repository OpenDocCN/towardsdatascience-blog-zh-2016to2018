<html>
<head>
<title>Tutorial: Alphabet Recognition Through Gestures — A Deep Learning and OpenCV Application</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">教程:通过手势识别字母——深度学习和 OpenCV 应用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tutorial-alphabet-recognition-deeplearning-opencv-97e697b8fb86?source=collection_archive---------3-----------------------#2018-07-08">https://towardsdatascience.com/tutorial-alphabet-recognition-deeplearning-opencv-97e697b8fb86?source=collection_archive---------3-----------------------#2018-07-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="cee6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意:文章过时了。我更改了我的 GitHub 用户名，结果 GitHub 列表不显示。请在此访问<a class="ae kl" href="https://github.com/acl21/Alphabet_Recognition_Gestures" rel="noopener ugc nofollow" target="_blank">项目代码。</a></p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><p id="00b1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一个关于如何构建深度学习应用程序的教程，该应用程序可以实时识别由感兴趣的对象(在这种情况下是瓶盖)书写的字母表。</p><h1 id="766b" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">项目描述</h1><p id="5ac9" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">深度学习技术能力的一个流行演示是图像数据中的对象识别。</p><p id="a2f1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">python 中的这个深度学习应用程序通过网络摄像头实时捕捉的手势来识别字母表。允许用户使用感兴趣的对象(在这种情况下是水瓶盖)在屏幕上书写字母表。</p><p id="23b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以访问完整的项目代码:</p><div class="lw lx gp gr ly lz"><a href="https://github.com/acl21/Alphabet_Recognition_Gestures" rel="noopener  ugc nofollow" target="_blank"><div class="ma ab fo"><div class="mb ab mc cl cj md"><h2 class="bd ir gy z fp me fr fs mf fu fw ip bi translated">ACL 21/Alphabet _ Recognition _ 手势</h2><div class="mg l"><h3 class="bd b gy z fp me fr fs mf fu fw dk translated">更新]:我将不再关注与回购相关的问题或邮件，因为我目前非常忙…</h3></div><div class="mh l"><p class="bd b dl z fp me fr fs mf fu fw dk translated">github.com</p></div></div></div></a></div><h1 id="7158" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">工作示例</h1><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="mn mo l"/></div></figure><h1 id="ce38" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">代码要求</h1><p id="b630" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">代码在 Python 版本中，使用 OpenCV 和 Keras 库。</p><p id="14ca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">跟随<a class="ae kl" href="https://medium.com/@akshaychandra21/how-to-install-opencv-and-keras-in-python-3-6-f5f721f0d0b3" rel="noopener">这篇中帖</a>在 Python 3 中安装 OpenCV 和 Keras。</p><h1 id="e23e" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">数据描述</h1><p id="b982" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">机器学习和深度学习的对象识别的“扩展 Hello World”是用于手写字母识别的<a class="ae kl" href="https://www.kaggle.com/crawford/emnist" rel="noopener ugc nofollow" target="_blank"> EMNIST </a>数据集。它是<a class="ae kl" href="https://en.wikipedia.org/wiki/MNIST_database" rel="noopener ugc nofollow" target="_blank"> MNIST </a>数据集的扩展版本(物体识别的“Hello World”)。</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi mp"><img src="../Images/0a3484e27f36898581eb8efc62426768.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OVWotVv5nxRFEtRzwhsMUA.png"/></div></div></figure><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/d3c52573533087523f01cd6a56b0869a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*RctvQPFWV881-QDuVh1UDw.png"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk">The letter ‘e’ is stored in a 28 x 28 numpy array as shown above.</figcaption></figure><h1 id="f7ac" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">代码解释</h1><h2 id="79bc" class="nb ku iq bd kv nc nd dn kz ne nf dp ld jy ng nh lh kc ni nj ll kg nk nl lp nm bi translated">步骤 1:训练一个多层感知器模型</h2><p id="e6fd" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated"><strong class="jp ir"> 1.1 负载数据</strong></p><p id="5e79" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们使用 Python 的<em class="nn"> mnist </em>库来加载数据。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><p id="1cd4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在让我们准备好数据，以供模型使用。将数据分成训练集和测试集，标准化图像和其他初步的东西。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><p id="cc3d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 1.2 定义模型</strong></p><p id="521a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在 Keras 中，模型被定义为一系列层。我们首先初始化一个“序列模型”,然后添加包含各自神经元的层。下面的代码做了同样的事情。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><p id="baa5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如预期的那样，该模型采用 28 x 28 像素(我们展平图像，并将每个像素传递到一维向量中)作为输入。模型的输出必须是对其中一个字母的决策，因此我们将输出层设置为 26 个神经元(决策是根据概率做出的)。</p><p id="208a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 1.3 编译模型</strong></p><p id="28d7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">既然模型已经定义好了，我们就可以编译它了。编译模型使用了后台(所谓的后端)的高效数值库，如 Theano 或 TensorFlow。</p><p id="fb89" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里，我们指定了训练网络所需的一些属性。通过训练，我们试图找到最佳的权重集来对输入做出决策。我们必须指定用于评估一组权重的损失函数、用于搜索网络的不同权重的优化器以及我们希望在训练期间收集和报告的任何可选指标。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><p id="734e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 1.4 拟合模型</strong></p><p id="4367" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这里，我们使用模型检查点来训练模型，这将帮助我们保存最佳模型(根据我们在上一步中定义的指标最佳)。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><p id="7154" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 1.5 评估模型</strong></p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><p id="3390" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该模型在 EMNIST 数据集上的测试精度为<strong class="jp ir"> 91.1% </strong>。</p><p id="62d4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 1.6 把所有东西放在一起</strong></p><p id="73f2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将所有步骤放在一起，我们得到了构建一个基于 EMNIST 数据的体面的 MLP 模型所需的完整代码。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><h2 id="2336" class="nb ku iq bd kv nc nd dn kz ne nf dp ld jy ng nh lh kc ni nj ll kg nk nl lp nm bi translated">步骤 2:训练卷积神经网络模型</h2><p id="6b25" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated"><strong class="jp ir"> 2.1 和 2.2 —加载数据并定义模型</strong></p><p id="1a9f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这两个步骤与我们在构建 MLP 模型时实施的步骤完全相同。</p><p id="e650" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 2.3 定义模型</strong></p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><p id="c12b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">出于超出本教程范围的原因，我定义了上面的 CNN 架构来解决手头的问题。要了解更多关于 CNN 的信息，请访问<a class="ae kl" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">这个教程页面</a>，它是最好的！</p><p id="7898" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 2.3 编译模型</strong></p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Unlike the MLP model, this time I am using the ADADELTA optimizer</figcaption></figure><p id="1f82" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 2.4 适合车型</strong></p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><p id="55cd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要了解模型变量<strong class="jp ir"><em class="nn"/></strong>和<strong class="jp ir"> <em class="nn">历元</em> </strong>如何影响出模型性能，请访问<a class="ae kl" rel="noopener" target="_blank" href="/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9">本</a>。</p><p id="9785" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 2.5 评估模型</strong></p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><p id="7164" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该模型在 EMNIST 数据集上的测试精度为<strong class="jp ir"> 93.1% </strong>。</p><p id="b758" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 2.6 把所有东西放在一起</strong></p><p id="e59c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将所有这些放在一起，我们得到了构建一个基于 EMNIST 数据训练的像样的 CNN 模型所需的完整代码。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><h2 id="6874" class="nb ku iq bd kv nc nd dn kz ne nf dp ld jy ng nh lh kc ni nj ll kg nk nl lp nm bi translated">第三步:初始化东西</h2><p id="20c3" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">在我们研究识别代码之前，让我们初始化一些东西。</p><p id="c94e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我们加载在前面步骤中构建的模型。然后我们创建一个字母字典，<strong class="jp ir"> <em class="nn"> blueLower </em> </strong>和<strong class="jp ir"> <em class="nn"> blueUpper </em> </strong>边界来检测蓝色瓶盖，一个<strong class="jp ir"> <em class="nn"> kernal </em> </strong>来平滑沿途的事物，一个空的<strong class="jp ir"> <em class="nn">黑板</em> </strong>来存储白色的文字(就像 EMNIST 数据集中的字母表)，一个 deque 来存储所有的<strong class="jp ir"> <em class="nn">点</em></strong></p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><h2 id="4f2f" class="nb ku iq bd kv nc nd dn kz ne nf dp ld jy ng nh lh kc ni nj ll kg nk nl lp nm bi translated">第四步:捕捉文字</h2><p id="fb69" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">一旦我们开始逐帧读取输入的视频，我们就试图找到蓝色的瓶盖，并将其用作一支笔。我们使用 OpenCV 的<strong class="jp ir"> <em class="nn"> cv2。VideoCapture() </em> </strong>从视频文件或网络摄像头实时逐帧(使用 while 循环)读取视频的方法。在这种情况下，我们将 0 传递给方法以从网络摄像头读取数据。下面的代码演示了同样的情况。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><p id="ac18" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦我们开始读取网络摄像头馈送，我们就会借助<strong class="jp ir"> <em class="nn"> cv2.inRange() </em> </strong>方法不断在帧中寻找蓝色对象，并使用事先初始化的<em class="nn"> blueUpper </em>和<em class="nn"> blueLower </em>变量。一旦我们找到轮廓，我们做一系列的图像操作，并使其平滑。平滑只是让我们的生活更轻松。如果你想知道更多关于这些操作——侵蚀、变形和扩张，请查看<a class="ae kl" href="https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_morphological_ops/py_morphological_ops.html" rel="noopener ugc nofollow" target="_blank">这个</a>。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><p id="1b9b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦我们找到轮廓(当找到轮廓时，<strong class="jp ir"> <em class="nn"> if </em> </strong>条件通过)，我们使用轮廓的中心(蓝色帽)在屏幕上绘制它的移动。下面的代码做了同样的事情。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><p id="84ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面的代码检查是否找到了轮廓，如果是，它取最大的一个(假设是瓶盖)，使用<strong class="jp ir"><em class="nn">cv2 . minenclosingcircle()</em></strong>和<strong class="jp ir"> <em class="nn"> cv2.circle() </em> </strong>方法围绕它画一个圆，借助<strong class="jp ir"><em class="nn">cv2 . moments()</em></strong>方法得到找到的轮廓的中心。最后，中心被存储在一个名为<strong class="jp ir"> <em class="nn">点</em> </strong>的 deque 中，这样我们就可以将它们全部连接起来，形成一个完整的文字。</p><p id="13c0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们在<strong class="jp ir"> <em class="nn">框架</em> </strong>和<strong class="jp ir"> <em class="nn">黑板</em> </strong>上显示图纸。一个用于外部显示，另一个将其传递给模型。</p><p id="dfec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="nn">注意:我已经写了一个关于建立一个绘图环境的简短教程，它允许我们像在一个画图应用程序中一样绘图，在这里查看</em><a class="ae kl" href="https://medium.com/@akshaychandra21/tutorial-webcam-paint-opencv-dbe356ab5d6c" rel="noopener"><em class="nn"/></a><em class="nn">以清楚地理解正在发生的事情。</em></p><h2 id="6283" class="nb ku iq bd kv nc nd dn kz ne nf dp ld jy ng nh lh kc ni nj ll kg nk nl lp nm bi translated">第五步:刮掉书写内容，并将其传递给模型</h2><p id="1a63" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">一旦用户写完了，我们就把之前存储的点连接起来，放在黑板上，然后传给模型。</p><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><p id="1d1b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我们停止书写时，控制进入这个<strong class="jp ir"> <em class="nn"> elif </em> </strong> <em class="nn"> </em>块(因为没有检测到轮廓)。一旦我们验证了<strong class="jp ir"> <em class="nn">点</em> </strong> deque 不为空，我们现在就可以确定写入已经完成。现在我们取<strong class="jp ir"> <em class="nn">黑板</em> </strong>图像，再做一次快速轮廓搜索(刮掉字迹)。找到后，我们对其进行适当的剪切，调整其大小以满足我们构建的模型的输入尺寸要求，即 28 x 28 像素。然后传给两个模特。</p><h2 id="b6c7" class="nb ku iq bd kv nc nd dn kz ne nf dp ld jy ng nh lh kc ni nj ll kg nk nl lp nm bi translated">步骤 6:显示模型预测</h2><figure class="mi mj mk ml gt mm"><div class="bz fp l di"><div class="no mo l"/></div></figure><p id="bdc0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我们在<strong class="jp ir"> <em class="nn">帧</em> </strong>窗口上显示我们的模型做出的预测。然后我们使用<strong class="jp ir"> <em class="nn"> cv2.imshow() </em> </strong>方法显示它。当我们进入 循环从网络摄像头读取数据时，脱离<strong class="jp ir"> <em class="nn">后，我们释放摄像头并破坏所有窗口。</em></strong></p><h1 id="d540" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">执行</h1><p id="a10b" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated"><strong class="jp ir"> 1。下载数据</strong></p><p id="5e07" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从<a class="ae kl" href="https://github.com/akshaychandra21/Alphabet_Recognition_RealTime/tree/master/data" rel="noopener ugc nofollow" target="_blank">这里</a>下载数据文件夹，放入你的项目目录。</p><p id="80f8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 2。建立 MLP 模型</strong></p><pre class="mi mj mk ml gt np nq nr ns aw nt bi"><span id="df2a" class="nb ku iq nq b gy nu nv l nw nx">&gt; python mlp_model_builder.py</span></pre><p id="981a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 3。建立 CNN 模型</strong></p><pre class="mi mj mk ml gt np nq nr ns aw nt bi"><span id="87ec" class="nb ku iq nq b gy nu nv l nw nx">&gt; python cnn_model_builder.py</span></pre><p id="6568" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 4。运行引擎文件</strong></p><pre class="mi mj mk ml gt np nq nr ns aw nt bi"><span id="d634" class="nb ku iq nq b gy nu nv l nw nx">&gt; python alphabet_recognition.py</span></pre><p id="c0b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 5。抓起蓝色瓶盖</strong></p><p id="37c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">玩得开心点。</p><h1 id="3bd2" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">结论</h1><p id="819c" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">在本教程中，我们建立了两个深度学习模型，一个 MLP 模型和一个 CNN 模型，在著名的 EMNIST 数据上进行训练。并用这些模型来实时预测我们感兴趣的物体所写的字母。我鼓励你调整两个模型的架构，看看它们如何影响你的预测。</p><p id="b19f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">希望这个教程是有趣的。感谢阅读。</p><p id="6d8a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">活也让别人活！<br/>答</p><figure class="mi mj mk ml gt mm gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi ny"><img src="../Images/2b28c922887a00ebcfb1f977377dc1b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xZ_FBBzP9xsr8HB3vVxBLg.jpeg"/></div></div><figcaption class="mx my gj gh gi mz na bd b be z dk">Photo by <a class="ae kl" href="https://unsplash.com/photos/BVyNlchWqzs?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Amador Loureiro</a> on <a class="ae kl" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure></div></div>    
</body>
</html>