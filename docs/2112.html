<html>
<head>
<title>Battle of the Deep Learning frameworks — Part I: 2017, even more frameworks and interfaces</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习框架之战——第一部分:2017，更多框架和接口</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/battle-of-the-deep-learning-frameworks-part-i-cff0e3841750?source=collection_archive---------1-----------------------#2017-12-19">https://towardsdatascience.com/battle-of-the-deep-learning-frameworks-part-i-cff0e3841750?source=collection_archive---------1-----------------------#2017-12-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="e129" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">深度学习的格局在不断变化。Theano是第一个被广泛采用的深度学习框架，由深度学习的先驱之一Yoshua Bengio领导的<a class="ae kl" href="https://mila.quebec/" rel="noopener ugc nofollow" target="_blank"> MILA </a>创建和维护。然而，事情发生了变化。今年9月，MILA宣布在发布最新版本后，将不会在2018年对Theano进行进一步的开发工作。这个消息并不意外。在过去的几年中，不同的开源Python深度学习框架被引入，通常由大型科技公司之一开发或支持，其中一些获得了很多关注。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/cc5a0bccc6c362fc482b563832e68e3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dYjDEI0mLpsCOySKUuX1VA.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">State of open source deep learning frameworks in 2017</figcaption></figure><p id="b10d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">目前，谷歌的<a class="ae kl" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>似乎是最常用的深度学习框架——基于Github stars &amp; forks和堆栈溢出活动。一些人预计，随着TensorFlow的推出，谷歌将主导市场多年。然而，看起来其他框架也吸引了越来越多的热情用户。最值得一提的可能是<a class="ae kl" href="http://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>的引进和成长。PyTorch由脸书等公司于2017年1月推出。它是流行的Torch框架(用C实现，用Lua封装)的移植，Torch二进制文件用GPU加速的Python封装。</p><p id="6e87" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">除了GPU加速和内存的有效使用，PyTorch流行背后的主要驱动力是动态计算图的使用。这些动态计算图已经被其他鲜为人知的深度学习框架使用，如Chainer。这些动态图的优点在于，这些图是由运行定义的(“由运行定义”)，而不是传统的“定义并运行”。特别是在输入可能变化的情况下，例如对于文本这样的非结构化数据，这是非常有用和高效的。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lc"><img src="../Images/fcdab3e90e6af3177714b06646bc6fe3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*5PLIVNA5fIqEC8-kZ260KQ.gif"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">PyTorch dynamic computational graph — source: <a class="ae kl" href="http://pytorch.org/about/" rel="noopener ugc nofollow" target="_blank">http://pytorch.org/about/</a></figcaption></figure><p id="9fa9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其他科技巨头也没有坐以待毙。微软开发了一个名为CNTK的内部深度学习框架，并在更名为<a class="ae kl" href="https://www.microsoft.com/en-us/cognitive-toolkit/" rel="noopener ugc nofollow" target="_blank">微软认知工具包</a>后于2017年正式推出2.0版本。2017年，脸书也推出了<a class="ae kl" href="https://caffe2.ai/" rel="noopener ugc nofollow" target="_blank">咖啡馆2 </a>。它是著名的Caffe框架的继承者。最初的<a class="ae kl" href="http://caffe.berkeleyvision.org/" rel="noopener ugc nofollow" target="_blank"> Caffe </a>框架是由Berkeley Vision and Learning Center开发的，在它的社区、它在计算机视觉中的应用以及它的模型动物园(一组预先训练好的模型)中非常受欢迎。然而，似乎咖啡2还没有步咖啡的后尘。</p><p id="89a5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">另一个流行的深度学习框架是<a class="ae kl" href="https://mxnet.apache.org/" rel="noopener ugc nofollow" target="_blank"> MXNet </a>，由微软和亚马逊支持。MXNet已经存在一段时间了，但是当MXNet被称为深度学习框架时，我经常听到人们回应“那不是R的深度学习框架吗？”。是的，但不止如此。它实际上支持许多语言，从C++到Python、JavaScript、Go，事实上还有MXNet突出的地方是它的可伸缩性和性能(请继续关注第二部分，在那里我们将比较最流行的框架的速度和其他指标)。</p><p id="afe0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些只是众多框架中的一小部分。其他开源深度学习框架包括Deeplearning4j和Dlib(基于C++的)。同样在2017年，谷歌的DeepMind发布了Sonnet(基于TensorFlow构建的高级面向对象库)。其他值得一提的框架还有H20.ai和Spark。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ld"><img src="../Images/bf0f70aa7969bc900eca3d9cccd45ddd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2JOMxpGbJqxcOsC9ox4mDw.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Straightforward model building with Keras — source: <a class="ae kl" href="https://github.com/keras-team/keras" rel="noopener ugc nofollow" target="_blank">https://github.com/keras-team/keras</a></figcaption></figure><p id="a80a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">除了所有这些框架，我们还有包装在一个或多个框架周围的接口。深度学习最广为人知和广泛使用的界面毫无疑问是<a class="ae kl" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>。Keras是一个高级深度学习API，用Python编写，由谷歌深度学习研究员Franç ois Chollet创建。谷歌在2017年宣布选择Keras作为TensorFlow的高层API。这意味着Keras将包含在下一个TensorFlow版本中。除了TensorFlow，Keras还可以使用Theano或CNTK作为后端。</p><p id="13c0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Keras很强大，因为通过堆叠多个层来创建深度学习模型真的很简单。当使用Keras时，用户不需要做层背后的数学计算。这似乎是快速原型制作的理想选择，Keras也是Kaggle竞赛中的流行工具。</p><p id="3617" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，一方面，我们目前有高级别的Keras API，可以让您轻松构建简单和高级的深度学习模型，另一方面，低级别的TensorFlow框架可以让您在构建模型时更加灵活。两者都有谷歌的支持。正如预期的那样，竞争并没有坐以待毙，2017年10月，微软和亚马逊的AWS联合发布了Gluon API。Gluon是一个高级Python深度学习接口，它包装了MXNet，很快它还将包括微软的CNTK。胶子是Keras的直接竞争对手，尽管AWS声称他们强烈支持所有深度学习框架，但他们当然将赌注押在胶子上，以实现人工智能的民主化。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi le"><img src="../Images/3357bb1b67cff99f99f15486e6cf0e24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QOaBo36ic0lW9Lu5Vp2fuQ.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Stacking convolutional and dense layers and parameter initialization with Gluon</figcaption></figure><p id="1b0c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">令人惊讶的是，如今TensorFlow最大的竞争对手似乎是PyTorch。随着社区对PyTorch越来越感兴趣，例如，在Kaggle的最新比赛中，用户经常选择使用PyTorch作为他们解决方案的一部分，并且它也被用于最新的研究论文中，因此<a class="ae kl" href="https://research.googleblog.com/2017/10/eager-execution-imperative-define-by.html" rel="noopener ugc nofollow" target="_blank"> TensorFlow于2017年10月推出了Eager Execution </a>。TensorFlow的“运行定义”界面。通过此次发布，谷歌希望赢回爱上PyTorch及其动态图形的用户。</p><p id="b758" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于热门深度学习课程fast.ai的开发者来说，这种变化来得太晚了。9月，<a class="ae kl" href="http://www.fast.ai/2017/09/08/introducing-pytorch-for-fastai/" rel="noopener ugc nofollow" target="_blank"> fast.ai宣布从Keras &amp; TensorFlow切换到PyTorch </a>。fast.ai的创始研究员、Kaggle的前总裁兼首席科学家杰瑞米·霍华德认为PyTorch将能够保持领先地位。只有时间能证明一切。</p><p id="4b48" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有了这些深度学习框架，新来者选择一个框架可能会很有挑战性。坦率地说，即使是经验丰富的研究人员和开发人员也很难跟上最新的发展。一个积极的消息是<a class="ae kl" href="https://onnx.ai/" rel="noopener ugc nofollow" target="_blank">开放神经网络交换(ONNX) </a>的发布。ONNX于2017年9月宣布，并于12月发布了V1，是一种表示深度学习模型的开放格式。这允许用户更容易地在不同的框架之间移动模型。例如，它允许您构建PyTorch模型，并使用MXNet运行该模型进行推理。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi lf"><img src="../Images/5a1bad96a4770ddff8378ab34c1815a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w7gPJDgMcB_9ztlOIK2dEw.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Open Neural Network Exchange (ONNX) Github page — source: <a class="ae kl" href="https://github.com/onnx/onnx" rel="noopener ugc nofollow" target="_blank">https://github.com/onnx/onnx</a></figcaption></figure><p id="1bd6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">ONNX是由微软、AWS和脸书等公司推出的。谷歌不在这个名单中并不令人惊讶。ONNX从一开始就支持Caffe2、Microsoft Cognitive Toolkit、MXNet和PyTorch，但是与其他开源项目一样，社区也已经为TensorFlow添加了一个转换器。</p><p id="b1e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2017年有很多令人兴奋的发展，这类似于深度学习和人工智能领域的快速发展。很难预测新的一年会发生什么。我们可能会看到一些整合，不过，大型科技公司肯定会希望使用和推广自己的技术。很高兴看到不同的框架，由不同的技术巨头支持，推动彼此更快地创新。在第二部分中，我们将根据不同的度量标准，如速度、内存使用、可移植性和可伸缩性，更详细地比较不同的框架。</p></div></div>    
</body>
</html>