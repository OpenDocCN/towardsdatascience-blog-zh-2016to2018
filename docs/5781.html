<html>
<head>
<title>Choosing the right Encoding method-Label vs OneHot Encoder</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">选择正确的编码方法——标签与 OneHot 编码器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/choosing-the-right-encoding-method-label-vs-onehot-encoder-a4434493149b?source=collection_archive---------1-----------------------#2018-11-09">https://towardsdatascience.com/choosing-the-right-encoding-method-label-vs-onehot-encoder-a4434493149b?source=collection_archive---------1-----------------------#2018-11-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d004" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">您选择的编码如何在您的预测模型中发挥重要作用</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/dd0da56b56a9c21d05f04d901ea45b50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d1tead56fBEuxi-MuNhU8w.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Gateway Of India- Mumbai, India Pic by Rahil Hussain Shaikh</figcaption></figure><p id="964f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在最大似然模型中，我们经常需要将分类的，即文本特征转换成数字表示。两种最常见的方法是使用标签编码器或 OneHot 编码器。然而，大多数 ML 新手并不熟悉编码的选择对他们的模型的影响，通过在正确的场景中使用正确的编码，模型的准确性可能会有很大的变化。</p><h2 id="1339" class="lr ls iq bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">在这篇文章中，我们将一步一步来</h2><ol class=""><li id="9a05" class="mk ml iq kx b ky mm lb mn le mo li mp lm mq lq mr ms mt mu bi translated">了解标签和 OneHot 编码。</li><li id="54c9" class="mk ml iq kx b ky mv lb mw le mx li my lm mz lq mr ms mt mu bi translated">Python 中使用标注和一次热编码对预测准确性影响的实际示例。</li></ol><h2 id="a26e" class="lr ls iq bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">了解标签和 OneHot 编码。</h2><p id="27c9" class="pw-post-body-paragraph kv kw iq kx b ky mm jr la lb mn ju ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">让我们了解 Label 和一个 hot 编码器的工作原理，并进一步了解如何在 python 中使用这些编码器，以及它们对预测的影响</p><h2 id="9134" class="lr ls iq bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">标签编码器:</h2><p id="a84e" class="pw-post-body-paragraph kv kw iq kx b ky mm jr la lb mn ju ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">使用 Sklearn 库可以实现 Python 中的标签编码。Sklearn 提供了一个非常有效的工具，用于将分类特征的级别编码成数值。用 0 和 n_classes-1 之间的值对标签进行编码，其中 n 是不同标签的数量。如果某个标签重复，它会将之前分配的相同值分配给。</p><p id="860e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">考虑下面的例子:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/e295c1da62da537aff9db386a45df1f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*r0WcEqO9IQa8RAYxXv7Kxg.png"/></div></figure><p id="357c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果我们必须将这些数据传递给模型，我们需要使用 Label Encoder 将 Country 列编码成它的数字表示。应用标签编码器后，我们将得到如下结果</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/f1e3cdf1f9cd6b14ebf88893a84c0fde.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*hAtLlQ5SnF1WM6Vaa5u7gw.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">The categorical values have been converted into numeric values.</figcaption></figure><p id="9f64" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这就是标签编码的全部内容。但是取决于数据，标签编码引入了新的问题。例如，我们将一组国家名称编码成数字数据。这实际上是分类数据，行与行之间没有任何关系。</p><p id="1671" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这里的问题是，由于同一列中有不同的数字，模型会将数据误解为某种顺序，即 0 &lt; 1 &lt;2。</p><p id="60b2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">该模型可能会得出一种相关性，如随着国家数量的增加，人口也会增加，但这显然可能不是其他一些数据或预测集中的情况。为了克服这个问题，我们使用一个热编码器。</p><h2 id="763d" class="lr ls iq bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">一个热编码器:</h2><p id="99d6" class="pw-post-body-paragraph kv kw iq kx b ky mm jr la lb mn ju ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">现在，正如我们已经讨论过的，根据我们拥有的数据，我们可能会遇到这样的情况，在标签编码后，我们可能会混淆我们的模型，认为某一列具有某种顺序或层次结构的数据，而我们显然没有它。为了避免这种情况，我们对该专栏进行了“一个酒店编码”。</p><p id="0d4e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一种热编码的做法是，获取一个包含分类数据的列，该列已经过标签编码，然后将该列拆分为多个列。数字由 1 和 0 代替，这取决于哪一列有什么值。在我们的示例中，我们将得到四个新列，每个国家一列—日本、美国、印度和中国。</p><p id="47ca" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于第一列值为日本的行,“日本”列将为“1 ”,其他三列为“0”。同样，对于第一列值为美国的行,“美国”列为“1 ”,其他三列为“0 ”,依此类推。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/e43d77079d58aa69a3748a4196ad7dc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*8aykqjTyz2wpN70FXb3A4A.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">OneHot encoded country values.</figcaption></figure><h2 id="6355" class="lr ls iq bd lt lu lv dn lw lx ly dp lz le ma mb mc li md me mf lm mg mh mi mj bi translated">关于使用标注和一个热编码对预测的影响的 Python 实例。</h2><p id="abfe" class="pw-post-body-paragraph kv kw iq kx b ky mm jr la lb mn ju ld le na lg lh li nb lk ll lm nc lo lp lq ij bi translated">我们将使用医疗成本个人数据集来预测基于各种特征的汽车医疗费用，您可以从<a class="ae nk" href="https://www.kaggle.com/mirichoi0218/insurance/home" rel="noopener ugc nofollow" target="_blank">这里</a>下载数据集。本博客使用的数据只是一个样本数据，但通过均方根误差评估预测结果，可以清楚地看到预测结果的差异，rmse 越接近 0，模型预测越好。</p><p id="601a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们将运行 xgboost 回归算法模型(您可以使用您选择的任何回归算法),并使用标签编码器预测价格，然后使用一个热编码器并比较结果。</p><p id="acaa" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我从 insurance.csv 文件中取出了最后 37 条记录，并创建了一个新的文件 insuranceTest.csv，以预测对看不见的数据的收费。</p><p id="4c76" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">代码片段:</strong></p><pre class="kg kh ki kj gt nl ng nm nn aw no bi"><span id="7c4c" class="lr ls iq ng b gy np nq l nr ns">import pandas as pd<br/>import numpy as np<br/>import xgboost<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import LabelEncoder<br/>from math import sqrt<br/>from sklearn.metrics import mean_squared_error</span><span id="bcef" class="lr ls iq ng b gy nt nq l nr ns">data = pd.read_csv('D://Blogs//insurance.csv')</span><span id="ce62" class="lr ls iq ng b gy nt nq l nr ns">testdata = pd.read_csv('D://Blogs//insuranceTest.csv')</span><span id="7e36" class="lr ls iq ng b gy nt nq l nr ns">mergedata = data.append(testdata)<br/>testcount = len(testdata)<br/>count = len(mergedata)-testcount<br/>X_cat = mergedata.copy()<br/>X_cat = mergedata.select_dtypes(include=['object'])<br/>X_enc = X_cat.copy()</span><span id="af51" class="lr ls iq ng b gy nt nq l nr ns">#ONEHOT ENCODING BLOCK</span><span id="09e7" class="lr ls iq ng b gy nt nq l nr ns">#X_enc = pd.get_dummies(X_enc, columns=['sex','region','smoker'])<br/><br/>#mergedata = mergedata.drop(['sex','region','smoker'],axis=1)</span><span id="f089" class="lr ls iq ng b gy nt nq l nr ns">#END ENCODING BLOCK</span><span id="2f63" class="lr ls iq ng b gy nt nq l nr ns"># =============================================================================<br/># #LABEL ENCODING BLOCK<br/># <br/>X_enc = X_enc.apply(LabelEncoder().fit_transform) #<br/>mergedata = mergedata.drop(X_cat.columns, axis=1)<br/># #END LABEL ENCODING BLOCK<br/># <br/># =============================================================================</span><span id="c653" class="lr ls iq ng b gy nt nq l nr ns">FinalData = pd.concat([mergedata,X_enc], axis=1)<br/>train = FinalData[:count]<br/>test = FinalData[count:]<br/>trainy = train['charges'].astype('int')<br/>trainx = train.drop(['charges'], axis=1)</span><span id="2711" class="lr ls iq ng b gy nt nq l nr ns">test = test.drop(['charges'], axis=1)<br/>X_train,X_test, y_train,y_test = train_test_split(trainx, trainy, test_size=0.3)</span><span id="e0d6" class="lr ls iq ng b gy nt nq l nr ns">clf = xgboost.XGBRegressor()<br/>clf.fit(X_train,y_train)<br/>y_testpred= clf.predict(X_test)<br/>y_pred = clf.predict(test)</span><span id="46c0" class="lr ls iq ng b gy nt nq l nr ns">dftestpred = pd.DataFrame(y_testpred)<br/>dfpred = pd.DataFrame(y_pred)</span><span id="072f" class="lr ls iq ng b gy nt nq l nr ns">rms = sqrt(mean_squared_error(y_test, y_testpred))</span><span id="028c" class="lr ls iq ng b gy nt nq l nr ns">print("RMSE:", rms)</span></pre><p id="3fcc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">RMSE 的产量:RMSE:18960 . 688888886867</p><p id="b681" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，让我们取消注释代码片段中的一个热编码器块，注释标签编码器块见 RMSE</p><pre class="kg kh ki kj gt nl ng nm nn aw no bi"><span id="daaa" class="lr ls iq ng b gy np nq l nr ns">import pandas as pd<br/>import numpy as np<br/>import xgboost<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import accuracy_score, confusion_matrix<br/>from sklearn.preprocessing import LabelEncoder<br/>from math import sqrt<br/>from sklearn.metrics import mean_squared_error</span><span id="5ae3" class="lr ls iq ng b gy nt nq l nr ns">data = pd.read_csv('D://Blogs//insurance.csv')</span><span id="c855" class="lr ls iq ng b gy nt nq l nr ns">testdata = pd.read_csv('D://Blogs//insuranceTest.csv')</span><span id="72da" class="lr ls iq ng b gy nt nq l nr ns">mergedata = data.append(testdata)<br/>testcount = len(testdata)<br/>count = len(mergedata)-testcount<br/>X_cat = mergedata.copy()<br/>X_cat = mergedata.select_dtypes(include=['object'])<br/>X_enc = X_cat.copy()</span><span id="38c5" class="lr ls iq ng b gy nt nq l nr ns">#ONEHOT ENCODING BLOCK</span><span id="570c" class="lr ls iq ng b gy nt nq l nr ns">X_enc = pd.get_dummies(X_enc, columns=['sex','region','smoker'])</span><span id="e570" class="lr ls iq ng b gy nt nq l nr ns">mergedata = mergedata.drop(['sex','region','smoker'],axis=1)</span><span id="7c85" class="lr ls iq ng b gy nt nq l nr ns">#END ENCODING BLOCK</span><span id="e15a" class="lr ls iq ng b gy nt nq l nr ns"># =============================================================================<br/># #LABEL ENCODING BLOCK<br/># <br/>#X_enc = X_enc.apply(LabelEncoder().fit_transform) #<br/>#mergedata = mergedata.drop(X_cat.columns, axis=1)<br/># #END LABEL ENCODING BLOCK<br/># <br/># =============================================================================</span><span id="db0c" class="lr ls iq ng b gy nt nq l nr ns">FinalData = pd.concat([mergedata,X_enc], axis=1)<br/>train = FinalData[:count]<br/>test = FinalData[count:]<br/>trainy = train['charges'].astype('int')<br/>trainx = train.drop(['charges'], axis=1)</span><span id="c4f1" class="lr ls iq ng b gy nt nq l nr ns">test = test.drop(['charges'], axis=1)<br/>X_train,X_test, y_train,y_test = train_test_split(trainx, trainy, test_size=0.3)</span><span id="21b6" class="lr ls iq ng b gy nt nq l nr ns">clf = xgboost.XGBRegressor()<br/>clf.fit(X_train,y_train)<br/>y_testpred= clf.predict(X_test)<br/>y_pred = clf.predict(test)</span><span id="e479" class="lr ls iq ng b gy nt nq l nr ns">dftestpred = pd.DataFrame(y_testpred)<br/>dfpred = pd.DataFrame(y_pred)</span><span id="e32f" class="lr ls iq ng b gy nt nq l nr ns">rms = sqrt(mean_squared_error(y_test, y_testpred))</span><span id="c211" class="lr ls iq ng b gy nt nq l nr ns">print("RMSE:", rms)</span></pre><p id="de9e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">RMSE 的产量:RMSE:18360 . 688888868617</p><p id="68b4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">一个热编码器的 RMSE 小于标签编码器，这意味着使用一个热编码器可以提供更好的精度，因为我们知道 RMSE 越接近 0，精度越好，同样不要担心这么大的 RMSE，因为我说过这只是一个样本数据，帮助我们了解标签和一个热编码器对我们模型的影响。</p><p id="6875" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你觉得这篇文章有用，给它一个<strong class="kx ir">掌声</strong>和<strong class="kx ir">与你的朋友分享</strong>。</p><p id="1adf" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> <em class="nu">谢谢</em> </strong></p></div></div>    
</body>
</html>