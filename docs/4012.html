<html>
<head>
<title>[ Paper Summary ] Real-time differentiation of adenomatous and hyperplastic diminutive colorectal polyps during analysis of unaltered videos of standard colonoscopy using a deep learning model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">[论文摘要]在使用深度学习模型分析标准结肠镜检查的未改变视频期间，实时区分腺瘤性和增生性小结肠直肠息肉</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/paper-summary-real-time-differentiation-of-adenomatous-and-hyperplastic-diminutive-colorectal-b1f726d97edd?source=collection_archive---------13-----------------------#2018-07-09">https://towardsdatascience.com/paper-summary-real-time-differentiation-of-adenomatous-and-hyperplastic-diminutive-colorectal-b1f726d97edd?source=collection_archive---------13-----------------------#2018-07-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/413d5c31565a0c167bb869b7cd173789.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*KrNmzqLhUErjR6wlksY1Rg.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">GIF from this <a class="ae jy" href="https://giphy.com/gifs/ghr-lMFfNhNxsveCI" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="33a9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同样，越来越多的这些论文显示了深度学习可以为医疗保健行业提供什么。</p><blockquote class="kx ky kz"><p id="9755" class="jz ka la kb b kc kd ke kf kg kh ki kj lb kl km kn lc kp kq kr ld kt ku kv kw ij bi translated"><strong class="kb ir">T3】</strong></p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="lp lq l"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Paper from this <a class="ae jy" href="https://www.ncbi.nlm.nih.gov/pubmed/29066576" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="3627" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">摘要</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/fced5eb5ea5e2973b0e432e371958ca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*hSqA79K2Yyhw_y06Qfd9Bg.png"/></div></figure><p id="4704" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">计算机辅助系统有助于以高精度区分小腺瘤和增生性息肉。在本文中，作者展示了一个使用卷积神经网络对息肉进行分类的示例。</p><p id="6672" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="la">关于这个问题已经知道了什么？/有什么新发现？</em>T9】</strong></p><p id="9f81" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">总的来说，专家取得了良好的结果，但是社区内镜专家未能保持一些有价值的内镜创新(PIVI)指南的保存和整合。人工智能可能会对这些领域有所帮助。本文的作者展示了一个使用案例，其中使用深度学习可以实现实时分类。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="fb27" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">简介</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ls"><img src="../Images/48bbc1df388df37d5b419f81ddfbcf55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*37y8zmfs1kQU2A0N8zniGw.png"/></div></div></figure><p id="179e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在结肠镜检查期间，内窥镜专家做出不同的决定，例如癌症类型的分类和切除或保留的区域。在手术过程中，图像分析可以帮助内窥镜专家。目前，图像分析在精确确定具有最小癌症风险的微小病变的组织学方面取得了成功。(反过来，这也有经济上的好处。).然而，这些方法通常依赖于操作员，因此在某些情况下，社区医生的准确性低于可接受的性能阈值。</p><p id="63d6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">为了克服这些问题，已经研究了不同的成本有效的方法。其中一个成果是 NBI 国际结肠直肠内窥镜(NICE)分类系统。这个系统是为了帮助没有丰富经验的内窥镜专家而开发的。但是这种方法不能解决诸如无柄锯齿状息肉(SSPs)的问题。</p><p id="d35d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">自动图像分析更近的发展被开发以改进肿瘤检测。传统的图像分析技术依赖于手工制作的特征，并且它们在某些情况下并不健壮。但是深度学习的发展有可能克服这些问题。本文作者利用深度卷积神经网络对不同类型的多边形进行分类。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="4618" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">方法</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi lx"><img src="../Images/8858057e771e5ead87bcd53a8fd9e4a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gIcsLMTuh0lfrAqfmrB0Zg.png"/></div></div></figure><p id="a9de" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">使用奥林巴斯结肠镜上捕获的 NBI 视频，本文的作者成功地训练了一个深度卷积神经网络。并且所有使用的数据在用于本研究之前都被去识别。</p><p id="3fb4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">DCNN 的一个优点是，人类不必为模型的成功表现制作手工特征。并且大致的网络架构可以在上面看到。(他们使用 SGD，mini batch 128，以及执行翻转的数据扩充。)最后，息肉分为两类:常规腺瘤或锯齿状病变。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/2c62ee4d19626d2bb164c61fb53addeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*pKr44GRQRgFIV7MTzeQ00g.png"/></div></figure><p id="061e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，关于框架的一个有趣的事实是可信度的概念。其中它表示模型的置信水平。如果可信度低于 50 %,这些预测将被排除在准确性计算之外。所有使用的视频都是 10-20 秒，中间值为 16 秒。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="4e79" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi lz"><img src="../Images/1808f1a7fc5859b5eb13e73a9ae7beea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2behfa-BwnbwdPlYBR55jw.png"/></div></div></figure><p id="7bf8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">125 个息肉视频被用作测试集，然而在这些数据中，只有 106 个被用于计算模型的准确性，因为它们具有足够高的可信度。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/80a3f9d9be426e755fcee8b93a5a5f07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*IUoYN6H4ROIjVQDBwkTu4A.png"/></div></figure><p id="652c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于 106 个息肉，准确率为 94%，识别腺瘤的灵敏度为 98%，特异性为 83%，阴性预测值为 97%，阳性预测值为 90%。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="f765" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">讨论</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi mb"><img src="../Images/9ff103ae3222776a705102398356e0da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IOw8HWXD2Gyyve3xKN0ZJQ.png"/></div></div></figure><p id="bdf1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">结肠直肠癌是美国癌症死亡的第三大原因，结肠镜检查不仅在该疾病的识别中而且在该疾病的治疗中起着关键作用。虽然不是结肠镜检查的所有方面都可以被软件取代，但是息肉的检测和组织学的预测是软件可以发挥作用的两个方面。这篇论文的作者已经表明，使用人工智能来高精度地执行这些任务是可能的。(甚至足以说，该模型比一些社区内窥镜专家表现得更好。).</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="8c32" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">遗言</strong></p><p id="254a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">尽管本文作者在测量精度时丢弃了一些测试数据，但本文提供了有希望的结果。写得非常好。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="59be" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="19da" class="mc md iq kb b kc kd kg kh kk me ko mf ks mg kw mh mi mj mk bi translated">Byrne MF，e. (2018)。在分析标准结肠镜检查的未改变视频期间，腺瘤性和增生性小结肠直肠息肉的实时鉴别… — PubMed — NCBI。Ncbi.nlm.nih.gov。检索于 2018 年 7 月 9 日，来自<a class="ae jy" href="https://www.ncbi.nlm.nih.gov/pubmed/29066576" rel="noopener ugc nofollow" target="_blank">https://www.ncbi.nlm.nih.gov/pubmed/29066576</a></li></ol></div></div>    
</body>
</html>