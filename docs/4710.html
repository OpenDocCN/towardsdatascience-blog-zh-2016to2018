<html>
<head>
<title>Uncovering Hidden Trends in AirBnB Reviews using Data Science</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用数据科学揭示 AirBnB 评论中的隐藏趋势</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/uncovering-hidden-trends-in-airbnb-reviews-11eb924f2fec?source=collection_archive---------9-----------------------#2018-09-01">https://towardsdatascience.com/uncovering-hidden-trends-in-airbnb-reviews-11eb924f2fec?source=collection_archive---------9-----------------------#2018-09-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/9445a3d9b798c9bb9d965ca8719350f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OJrZJowi6KStPXtP"/></div></div></figure><h1 id="6b3e" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">欢迎来到词汇世界</h1><p id="6bd5" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在做情感挖掘的研究时，我熟悉了主观词汇的重要概念。词典的应用是情感分析的两种主要方法之一。它包括从文本中出现的单词或短语的语义方向计算情感。</p><h1 id="5cbf" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">R 中可用的词典:</h1><p id="ca17" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated"><strong class="ky ir"> qdap 的<em class="lu">极性</em>()函数</strong>:使用来自 hash _ 情操 _ 刘虎(IL @CHI 极性(+/-)词研究的 U)的词典</p><p id="c296" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated"><strong class="ky ir"/></p><ul class=""><li id="fbdc" class="ma mb iq ky b kz lv ld lw lh mc ll md lp me lt mf mg mh mi bi translated"><strong class="ky ir"> NRC </strong> —根据 8 种情绪的单词，如“愤怒”或“喜悦”以及阳性/阴性</li><li id="1efe" class="ma mb iq ky b kz mj ld mk lh ml ll mm lp mn lt mf mg mh mi bi translated"><strong class="ky ir">并</strong> —标记为肯定或否定的词</li><li id="9db9" class="ma mb iq ky b kz mj ld mk lh ml ll mm lp mn lt mf mg mh mi bi translated"><strong class="ky ir"> AFINN </strong> —得分从-5 到 5 的单词</li></ul><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/e2b3ba21be137c64c5dd019a2f1308d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*BJWs9TRCsuBQLgB3zLN2QA.png"/></div></figure><p id="b9ad" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated"><a class="ae mt" href="https://anthrosource.onlinelibrary.wiley.com/doi/pdf/10.1525/aa.1950.52.2.02a00290" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">省力原则</strong> </a> <strong class="ky ir"> </strong>使有限的词库变得有用。</p><p id="8b66" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">您可以根据自己的需要随时修改词典！</p><h1 id="3925" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">1.定义业务问题</h1><p id="d02f" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">这是我最喜欢的，也是任何项目成功的最重要的一步:问正确的问题。一些领域的理解或与领域专家的交流确实有助于定义一个合适的问题陈述。</p><p id="9880" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">你应该很清楚自己的数据，并且有充分的理由去挖掘情感，而不仅仅是因为这听起来很酷！；)</p><p id="3e33" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">例如，通常在调查中，消费者被要求在一定范围内对产品进行评级。在这种情况下，<strong class="ky ir">一个有序的评级足以确定消费者对产品的情绪</strong>，这里的情绪分析就有点过了。如果你<strong class="ky ir">想</strong> <strong class="ky ir">知道消费者喜欢或不喜欢产品的什么，</strong> <strong class="ky ir">使用开放式问题</strong>，并使用回答提取有意义的见解。</p><p id="f076" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">在这个博客中，我们将找出哪些住房属性(例如，餐馆、地铁站附近、卫生、安全等。)根据总体客户评价带来良好的租赁体验。</p><h1 id="a028" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">2.识别文本来源</h1><p id="f72a" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">从任何网站获取顾客评论的流行方式之一是通过<strong class="ky ir">网络搜集。用 R 或者 Python 都可以。我会在我的下一篇博客中保留这个话题。目前，<strong class="ky ir">我选择了一个数据集，其中有 1000 条关于波士顿 AirBnB 租赁的用户评论</strong>。</strong></p><pre class="mp mq mr ms gt mu mv mw mx aw my bi"><span id="0808" class="mz jz iq mv b gy na nb l nc nd"><em class="lu"># Upload dataset in R (available as .rds file)</em> <br/>&gt; bos_reviews &lt;- readRDS("bos_reviews.rds", refhook = NULL)</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="ab gu cl ne"><img src="../Images/0e83b951416af7c62a2f5d7bbf5b538d.png" data-original-src="https://miro.medium.com/v2/0*ff-Ym-Ue6qMeFLNB"/></div></figure><h1 id="a6f6" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">3.组织和清理文本</h1><p id="5b54" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在这一步，我们将使用两种不同的词汇(<strong class="ky ir"> Polarity </strong>和<strong class="ky ir"> BING </strong>)来确定所收集的房屋评论的情感得分。</p><h2 id="b0e9" class="mz jz iq bd ka nf ng dn ke nh ni dp ki lh nj nk km ll nl nm kq lp nn no ku np bi translated">基于简单 Qdap 的极性评分</h2><p id="1584" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">从进行情绪分析开始是一种合理的方法，因为它让您熟悉数据，并帮助您设定期望，以更好地解决业务问题。为此，来自<em class="lu"> qdap </em>封装的<a class="ae mt" href="https://www.rdocumentation.org/packages/qdap/versions/2.2.9/topics/polarity" rel="noopener ugc nofollow" target="_blank">极性</a>功能非常有用。它允许我们将文本分为正面或负面。</p><pre class="mp mq mr ms gt mu mv mw mx aw my bi"><span id="96fa" class="mz jz iq mv b gy na nb l nc nd"><em class="lu"># Check out the boston reviews polarity overall polarity score</em> </span><span id="34a1" class="mz jz iq mv b gy nq nb l nc nd">&gt; bos_pol &lt;- polarity(bos_reviews)  <br/>&gt; bos_pol all total.sentences total.words ave.polarity sd.polarity stan.mean.polarity all 1000 70481 0.902 0.502 1.799 </span><span id="9642" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Summary for all reviews</em> <br/>&gt; summary(bos_pol$all$polarity) <br/>   Min. 1st Qu. Median  Mean  3rd Qu.  Max.   NA's <br/>-0.9712 0.6047  0.8921 0.9022 1.2063  3.7510   1  </span><span id="418f" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Kernel density plot of polarity score for all reviews</em> <br/>&gt; ggplot(bos_pol$all, aes(x = polarity, y = ..density..)) + theme_gdocs() + geom_histogram(binwidth = 0.25, fill = "#bada55", colour = "grey60") + geom_density(size = 0.75)</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nr"><img src="../Images/cd86d6c38f7247816fb5252e3fe4614e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Bywrj1U7bzwNIIv0.png"/></div></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">The above graph shows that the median polarity score is greater than zero, i.e., the reviews tend to be positive. Notice that the reviews do not center on zero: this is known as <strong class="bd nw">grade inflation</strong>. There are two possible causes for this. First,<strong class="bd nw"> social norms </strong>may lead respondents to be pleasant instead of neutral<em class="nx">.</em> The second reason could be <strong class="bd nw">feature-based sentiment,</strong><em class="nx"> </em>where an author may write, “the bed was comfortable and nice, but the kitchen was dirty and gross” and the sentiment encompasses multiple “features” simultaneously, thereby skewing the average score.</figcaption></figure><h2 id="02c6" class="mz jz iq bd ka nf ng dn ke nh ni dp ki lh nj nk km ll nl nm kq lp nn no ku np bi translated">TidyText 的必应词典</h2><p id="00fb" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在这里，我们将直接从名为“comments”的 review 列创建 word data。</p><pre class="mp mq mr ms gt mu mv mw mx aw my bi"><span id="6f65" class="mz jz iq mv b gy na nb l nc nd">&gt; library(tidytext) <br/>&gt; library(tidyr) <br/>&gt; library(dplyr)  </span><span id="4ce2" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Use unnest_tokens to make text lowercase &amp; tokenize reviews into single words.</em> <br/>&gt; tidy_reviews &lt;- bos_reviews %&gt;% unnest_tokens(word, comments) </span><span id="380c" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Group by and mutate to capture original word order within each group of a corpus.</em> <br/>&gt; tidy_reviews &lt;- tidy_reviews %&gt;% group_by(id) %&gt;% mutate(original_word_order = seq_along(word))  </span><span id="adcc" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Quick review</em> <br/>&gt; tidy_reviews <br/>A tibble: 70,834 x 3 <br/>Groups: id [1,000] <br/>id               word         original_word_order <br/>1 1               my                  1 <br/>2 1            daughter               2 <br/>3 1              and                  3 <br/>4 1               i                   4 <br/>5 1              had                  5 <br/>6 1               a                   6 <br/>7 1           wonderful               7 <br/>8 1             stay                  8 <br/>9 1             with                  9 <br/>10 1            maura                 10 </span><span id="8545" class="mz jz iq mv b gy nq nb l nc nd"># ... with 70,824 more rows <br/><em class="lu"># Load stopwords lexicon</em> <br/>&gt; data("stop_words") </span><span id="7fd4" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Perform anti-join to remove stopwords</em> <br/>&gt; tidy_reviews_without_stopwords &lt;- tidy_reviews %&gt;% anti_join(stop_words)  </span><span id="b841" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Getting the correct lexicon</em> &gt; bing &lt;- get_sentiments(lexicon = "bing")  </span><span id="577a" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Calculating polarity for each review</em> &gt; pos_neg &lt;- tidy_reviews_without_stopwords %&gt;% inner_join(bing) %&gt;% count(sentiment) %&gt;% spread(sentiment, n, fill = 0) %&gt;% mutate(polarity = positive - negative) </span><span id="fcd5" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Checking outcome</em> <br/>&gt; summary(pos_neg) <br/>    id              negative         positive         polarity <br/>Min. : 1.0       Min. : 0.0000      Min. : 0.00     Min. :-11.000 <br/>1st Qu.: 253.0   1st Qu.: 0.0000    1st Qu.: 3.00   1st Qu.: 2.000 Median : 498.0   Median : 0.0000    Median : 4.00   Median : 4.000 Mean : 500.4     Mean : 0.6139      Mean : 4.97     Mean : 4.356 <br/>3rd Qu.: 748.0   3rd Qu.: 1.0000    3rd Qu.: 7.00   3rd Qu.: 6.000 Max. :1000.0     Max. :14.0000      Max. :28.00     Max. : 26.000 </span><span id="e549" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Kernel density plot of Tidy Sentiment score for all reviews</em> <br/>&gt; ggplot(pos_neg, aes(x = polarity, y = ..density..)) + geom_histogram(binwidth = 0.25, fill = "#bada55", colour = "grey60") + geom_density(size = 0.75)</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/289294b1b9584c0bee4ef1cdd3cc6fd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/0*ZOrEVgZnkPBp7Lu6.png"/></div><figcaption class="ns nt gj gh gi nu nv bd b be z dk">Based on the polarity distribution for both Qdap’s polarity score and TidyText’s BING, we can say that the comments are tending towards positive.</figcaption></figure><h1 id="f1c1" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">4.创建基于极性的语料库</h1><p id="3eb2" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在极性检查之后，我们需要创建一个大的文本集，用于下一步的特征提取。</p><p id="2113" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated"><strong class="ky ir"> a .根据步骤 2 中计算出的极性得分，将所有 1，000 条意见分为正面和负面意见。</strong></p><pre class="mp mq mr ms gt mu mv mw mx aw my bi"><span id="aeaa" class="mz jz iq mv b gy na nb l nc nd"><em class="lu"># Add polarity column to the reviews</em><br/>&gt; bos_reviews_with_pol &lt;- bos_reviews %&gt;% mutate(polarity = bos_pol$all$polarity)<br/><br/><em class="lu"># Subset positive comments based on polarity score</em><br/>&gt; pos_comments &lt;- bos_reviews_with_pol %&gt;% filter(polarity &gt; 0) %&gt;% pull(comments)<br/><br/><em class="lu"># Subset negative comments based on polarity score</em><br/>&gt; neg_comments &lt;- bos_reviews_with_pol %&gt;% filter(polarity &lt; 0) %&gt;% pull(comments)</span></pre><p id="3c74" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated"><strong class="ky ir"> b .将正面和负面评论折叠成两个较大的文档。</strong></p><pre class="mp mq mr ms gt mu mv mw mx aw my bi"><span id="af0b" class="mz jz iq mv b gy na nb l nc nd"><em class="lu"># Paste and collapse the positive comments</em> <br/>&gt; pos_terms &lt;- paste(pos_comments, collapse = " ")  </span><span id="9e47" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Paste and collapse the negative comments </em> <br/>&gt; neg_terms &lt;- paste(neg_comments, collapse = " ")  </span><span id="7df6" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Concatenate the positive and negative terms</em> <br/>&gt; all_terms &lt;- c(pos_terms, neg_terms)</span></pre><p id="2015" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated"><strong class="ky ir"> c .创建词频逆文档频率(TFIDF)加权词频文档矩阵(TDM)。</strong></p><p id="56b1" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">这里，不是计算单词在语料库中的频率，而是对过度使用的术语惩罚 TDM 中的值，这有助于减少无信息的单词。</p><pre class="mp mq mr ms gt mu mv mw mx aw my bi"><span id="5983" class="mz jz iq mv b gy na nb l nc nd"><em class="lu"># Pipe a VectorSource Corpus</em> <br/>&gt; all_corpus &lt;- all_terms %&gt;% VectorSource() %&gt;% VCorpus()  </span><span id="f433" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Simple TFIDF TDM</em> <br/>&gt; all_tdm &lt;- TermDocumentMatrix(all_corpus, control = list( weighting = weightTfIdf, removePunctuation = TRUE, stopwords = stopwords(kind = "en")))  </span><span id="df89" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Examine the TDM </em> <br/>&gt; all_tdm &lt;&gt; Non-/sparse entries: 4348/5582 Sparsity: 56% Maximal term length: 372 Weighting: term frequency - inverse document frequency (normalized) (tf-idf) </span><span id="137e" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Matrix</em> <br/>&gt; all_tdm_m &lt;- as.matrix(all_tdm)  </span><span id="d91a" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Column names</em> <br/>&gt; colnames(all_tdm_m) &lt;- c("positive", "negative")</span></pre><h1 id="e39a" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">5.提取特征</h1><p id="9902" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在这一步中，我们将从 TDM 中提取关键的住房特征，从而得出正面和负面的评价。</p><pre class="mp mq mr ms gt mu mv mw mx aw my bi"><span id="ae01" class="mz jz iq mv b gy na nb l nc nd"><em class="lu"># Top positive words</em> <br/>&gt; order_by_pos &lt;- order(all_tdm_m[, 1], decreasing = TRUE)  </span><span id="3fec" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Review top 10 positive words</em> <br/>&gt; all_tdm_m[order_by_pos, ] %&gt;% head(n = 10) </span><span id="dd7f" class="mz jz iq mv b gy nq nb l nc nd">DocsTerms       positive     negative <br/>walk           0.004565669       0 <br/>definitely     0.004180255       0 <br/>staying        0.003735547       0 <br/>city           0.003290839       0 <br/>wonderful      0.003112956       0 <br/>restaurants    0.003053661       0 <br/>highly         0.002964720       0 <br/>station        0.002697895       0 <br/>enjoyed        0.002431070       0 <br/>subway         0.002401423       0  </span><span id="6bb3" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Top negative words</em> <br/>&gt; order_by_neg &lt;- order(all_tdm_m[, 2], decreasing = TRUE)  </span><span id="12a9" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Review top 10 negative words</em> <br/>&gt; all_tdm_m[order_by_neg, ] %&gt;% head(n = 10) </span><span id="32fc" class="mz jz iq mv b gy nq nb l nc nd">DocsTerms       positive      negative <br/>condition           0        0.002162942 <br/>demand              0        0.001441961 <br/>disappointed        0        0.001441961 <br/>dumpsters           0        0.001441961 <br/>hygiene             0        0.001441961 <br/>inform              0        0.001441961 <br/>nasty               0        0.001441961 <br/>safety              0        0.001441961 <br/>shouldve            0        0.001441961 <br/>sounds              0        0.001441961</span></pre><h1 id="6d3a" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">6.分析特征</h1><p id="d490" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">让我们比较一下通过 WordClouds 获得<strong class="ky ir">正面和负面评价</strong>的房屋特征。</p><p id="636d" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated"><strong class="ky ir"> a .对比云</strong></p><pre class="mp mq mr ms gt mu mv mw mx aw my bi"><span id="bd5c" class="mz jz iq mv b gy na nb l nc nd">&gt; comparison.cloud(all_tdm_m, max.words = 20, colors = c("darkblue","darkred"))</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nz"><img src="../Images/5a8ce2a912519e08c778d32c46e48b34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8idd2Mx7UjbiCMD4.png"/></div></div></figure><p id="5734" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated"><strong class="ky ir"> b .缩放后的对比云</strong></p><p id="48b7" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">通过这种可视化，我们将在执行语料库子集之前，通过将评论分数调整回零，修复<strong class="ky ir">等级膨胀</strong>对租赁评论极性分数的影响。这意味着一些先前的正面评论可能会成为负面子部分的一部分，反之亦然，因为平均值变为零。</p><pre class="mp mq mr ms gt mu mv mw mx aw my bi"><span id="9f10" class="mz jz iq mv b gy na nb l nc nd"><em class="lu"># Scale/center &amp; append</em> <br/>&gt; bos_reviews$scaled_polarity &lt;- scale(bos_pol$all$polarity)  </span><span id="3c26" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Subset positive comments</em> <br/>&gt; pos_comments &lt;- subset(bos_reviews$comments, bos_reviews$scaled_polarity &gt; 0)  </span><span id="e38d" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Subset negative comments</em> <br/>&gt; neg_comments &lt;- subset(bos_reviews$comments, bos_reviews$scaled_polarity &lt; 0)  </span><span id="a77e" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Paste and collapse the positive comments</em> <br/>&gt; pos_terms &lt;- paste(pos_comments, collapse = " ")  </span><span id="e002" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Paste and collapse the negative comments</em> <br/>&gt; neg_terms &lt;- paste(neg_comments, collapse = " ")  </span><span id="dd56" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Organize</em> <br/>&gt; all_terms&lt;- c(pos_terms, neg_terms)  </span><span id="e5cb" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># VCorpus</em> <br/>&gt; all_corpus &lt;- VCorpus(VectorSource(all_terms)) </span><span id="34a9" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># TDM</em> <br/>&gt; all_tdm &lt;- TermDocumentMatrix( all_corpus, control = list( weighting = weightTfIdf, removePunctuation = TRUE, stopwords = stopwords(kind = "en")))  </span><span id="c8e6" class="mz jz iq mv b gy nq nb l nc nd"># Column names <br/>&gt; all_tdm_m &lt;- as.matrix(all_tdm) <br/>&gt; colnames(all_tdm_m) &lt;- c("positive", "negative")  </span><span id="ab5b" class="mz jz iq mv b gy nq nb l nc nd"># Comparison cloud <br/>&gt; comparison.cloud(all_tdm_m, max.words = 100, colors = c("darkblue", "darkred"))</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oa"><img src="../Images/54a6096dfda44b59f45a1e1f482ed99b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Bpf-_Y83zeOo647n.png"/></div></div></figure><p id="38ed" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">除了上面的分析，我还想评估一个作者在写正面评论和负面评论时付出的努力之间的相关性。这是通过绘制正面和负面评论的字数来完成的。</p><pre class="mp mq mr ms gt mu mv mw mx aw my bi"><span id="f49a" class="mz jz iq mv b gy na nb l nc nd"><em class="lu"># Create effort</em> <br/>&gt; effort &lt;- tidy_reviews_without_stopwords %&gt;% count(id) </span><span id="6989" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Inner join</em> <br/>&gt; pos_neg_with_effort &lt;- inner_join(pos_neg, effort) </span><span id="e3e0" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Review</em> <br/>&gt; pos_neg_with_effort  <br/>A tibble: 953 x 5 Groups: id [?] <br/>id      negative     positive      polarity     n <br/>1 1         0            4             4        26 <br/>2 2         0            3             3        27 <br/>3 3         0            3             3        16 <br/>4 4         0            6             6        32 <br/>5 5         0            2             2         8 <br/>6 6         0            3             3        21 <br/>7 7         0            5             5        18 <br/>8 8         0            2             2        10 <br/>9 9         0            4             4        12 <br/>10 10       1           15            14        46 <br/><em class="lu"># ... with 943 more rows </em> </span><span id="3425" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Add pol</em> <br/>&gt; pos_neg_pol &lt;- pos_neg_with_effort %&gt;% mutate(pol = ifelse(polarity &gt;= 0, "Positive", "Negative"))  </span><span id="56c0" class="mz jz iq mv b gy nq nb l nc nd"><em class="lu"># Plot</em> <br/>&gt; ggplot(pos_neg_pol, aes(polarity,n, color = pol)) + geom_point(alpha = 0.25) + geom_smooth (method = "lm", se = FALSE) + ggtitle("Relationship between word effort &amp; polarity")</span></pre><figure class="mp mq mr ms gt jr gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/5503065929c4c58cbfad9c5dde52321c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/0*JPYoezNLl3l5nYZk.png"/></div></figure><h1 id="275f" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">7.得出结论</h1><p id="2e60" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">不足为奇的是，顶级<strong class="ky ir">正面</strong>词汇包括:</p><ul class=""><li id="7486" class="ma mb iq ky b kz lv ld lw lh mc ll md lp me lt mf mg mh mi bi translated">步行</li><li id="9f05" class="ma mb iq ky b kz mj ld mk lh ml ll mm lp mn lt mf mg mh mi bi translated">装备精良</li><li id="8397" class="ma mb iq ky b kz mj ld mk lh ml ll mm lp mn lt mf mg mh mi bi translated">饭店</li><li id="a27c" class="ma mb iq ky b kz mj ld mk lh ml ll mm lp mn lt mf mg mh mi bi translated">地铁</li><li id="eb62" class="ma mb iq ky b kz mj ld mk lh ml ll mm lp mn lt mf mg mh mi bi translated">站</li></ul><p id="9492" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">相比之下，最负面的<strong class="ky ir">术语包括:</strong></p><ul class=""><li id="d8f4" class="ma mb iq ky b kz lv ld lw lh mc ll md lp me lt mf mg mh mi bi translated">自动过账</li><li id="3645" class="ma mb iq ky b kz mj ld mk lh ml ll mm lp mn lt mf mg mh mi bi translated">垃圾箱</li><li id="d810" class="ma mb iq ky b kz mj ld mk lh ml ll mm lp mn lt mf mg mh mi bi translated">肮脏的</li><li id="5b51" class="ma mb iq ky b kz mj ld mk lh ml ll mm lp mn lt mf mg mh mi bi translated">卫生</li><li id="4b7a" class="ma mb iq ky b kz mj ld mk lh ml ll mm lp mn lt mf mg mh mi bi translated">安全</li><li id="c5fc" class="ma mb iq ky b kz mj ld mk lh ml ll mm lp mn lt mf mg mh mi bi translated">声音</li></ul><p id="79ce" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">同样，可以看出作者会花更多的精力来写一篇更强有力的正面或负面评论。这话多么真实啊！</p><p id="3d64" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">我确信，有了更大的数据集，我们可以挖掘出比这个小案例研究更深刻的见解。</p><h1 id="88e0" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">非常感谢您的阅读！</h1><p id="3939" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">我写这篇博客的目的是与所有有志成为数据科学家的人分享情绪分析的基本概念，但我们不能就此止步！我想我已经准备好为我的作品集做一个更精细的情感挖掘项目了，:D，你呢？</p><p id="79b4" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">请在下面的评论中分享你的想法/反馈。</p><p id="733a" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">也可以在<a class="ae mt" href="https://www.linkedin.com/in/gupta-sakshi/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>上和我联系。</p><p id="c505" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated">继续编码。干杯！</p><p id="ce0b" class="pw-post-body-paragraph kw kx iq ky b kz lv lb lc ld lw lf lg lh lx lj lk ll ly ln lo lp lz lr ls lt ij bi translated"><em class="lu">(首发@www.datacritics.com) </em></p></div></div>    
</body>
</html>