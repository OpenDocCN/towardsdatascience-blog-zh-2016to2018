<html>
<head>
<title>Visualizing intermediate activation in Convolutional Neural Networks with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 Keras 的卷积神经网络中间激活可视化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/visualizing-intermediate-activation-in-convolutional-neural-networks-with-keras-260b36d60d0?source=collection_archive---------1-----------------------#2018-11-02">https://towardsdatascience.com/visualizing-intermediate-activation-in-convolutional-neural-networks-with-keras-260b36d60d0?source=collection_archive---------1-----------------------#2018-11-02</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/72ad85a242faf7fbfb14b842d22c8d82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WzPoc2NIyUp0ry8gjvu_bA.jpeg"/></div></div></figure><p id="855f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在本文中，我们将使用 Keras 和 Python 来训练一个简单的<a class="ae kz" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">卷积神经网络，以完成分类任务。为此，我们将使用一组非常小而简单的图片，包括 100 张圆形图片、100 张正方形图片和 100 张三角形图片，这些图片是我在 Kaggle 中找到的。这些将被分成训练集和测试集(工作目录中的文件夹)并传送到网络。</a></p><p id="262b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最重要的是，我们将复制 Franç ois Chollet 在他的书<a class="ae kz" href="https://www.manning.com/books/deep-learning-with-python" rel="noopener ugc nofollow" target="_blank"> Deep Learning with Python </a>中的一些工作，以便了解我们的层结构如何根据每个中间激活的可视化来处理数据，这包括显示网络中卷积和池层输出的特征地图。</p><blockquote class="la lb lc"><p id="be7e" class="kb kc ld kd b ke kf kg kh ki kj kk kl le kn ko kp lf kr ks kt lg kv kw kx ky im bi translated">这意味着我们将可视化每个激活层的结果。</p></blockquote><p id="8aea" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将进行得非常快，因为我们在这里并不专注于用 Keras 做 CNN 的详细解释。</p><p id="ac79" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们首先导入所有需要的库:</p><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="8349" class="lq lr it lm b gy ls lt l lu lv">%matplotlib inline</span><span id="0361" class="lq lr it lm b gy lw lt l lu lv">import glob<br/>import matplotlib<br/>from matplotlib import pyplot as plt<br/>import matplotlib.image as mpimg<br/>import numpy as np<br/>import imageio as im<br/>from keras import models<br/>from keras.models import Sequential<br/>from keras.layers import Conv2D<br/>from keras.layers import MaxPooling2D<br/>from keras.layers import Flatten<br/>from keras.layers import Dense<br/>from keras.layers import Dropout<br/>from keras.preprocessing import image<br/>from keras.preprocessing.image import ImageDataGenerator<br/>from keras.callbacks import ModelCheckpoint</span></pre><p id="f80c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这些是我们的训练图像:</p><h2 id="eae4" class="lq lr it bd lx ly lz dn ma mb mc dp md km me mf mg kq mh mi mj ku mk ml mm mn bi translated">环</h2><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="9079" class="lq lr it lm b gy ls lt l lu lv">images = []<br/>for img_path in glob.glob('training_set/circles/*.png'):<br/>    images.append(mpimg.imread(img_path))</span><span id="a363" class="lq lr it lm b gy lw lt l lu lv">plt.figure(figsize=(20,10))<br/>columns = 5<br/>for i, image in enumerate(images):<br/>    plt.subplot(len(images) / columns + 1, columns, i + 1)<br/>    plt.imshow(image)</span></pre><figure class="lh li lj lk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mo"><img src="../Images/def04a1068367f714c7661e5de136963.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*spjwSnktphXLwpv1tZaDaA.png"/></div></div></figure><h2 id="a306" class="lq lr it bd lx ly lz dn ma mb mc dp md km me mf mg kq mh mi mj ku mk ml mm mn bi translated"><strong class="ak">正方形</strong></h2><p id="0962" class="pw-post-body-paragraph kb kc it kd b ke mp kg kh ki mq kk kl km mr ko kp kq ms ks kt ku mt kw kx ky im bi translated">(代码和上面差不多，完整代码见<a class="ae kz" href="https://github.com/gabrielpierobon/cnnshapes/blob/master/README.md" rel="noopener ugc nofollow" target="_blank">这里</a>)</p><figure class="lh li lj lk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mo"><img src="../Images/4cf2def2c885b00e9d1cbd93ac102abf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tiX2os7TdHLghF3Qt1GtKg.png"/></div></div></figure><h2 id="cc4a" class="lq lr it bd lx ly lz dn ma mb mc dp md km me mf mg kq mh mi mj ku mk ml mm mn bi translated">三角形</h2><figure class="lh li lj lk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mu"><img src="../Images/f03359ddfdbc6ff84fb5d78d42841a85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VvniKWnw6t1Qlyx9IdiA2w.png"/></div></div></figure><p id="8df1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">图像形状是 28 像素乘 28 像素的 RGB 比例(尽管它们可能只是黑白的)。</p><p id="eced" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在让我们继续进行卷积神经网络的构建。通常，我们用<code class="fe mv mw mx lm b">Sequential()</code>开始模型:</p><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="d18d" class="lq lr it lm b gy ls lt l lu lv"># Initialising the CNN<br/>classifier = Sequential()</span></pre><p id="a9c2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们指定我们的卷积层，并添加<code class="fe mv mw mx lm b">MaxPooling</code>进行下采样，添加<code class="fe mv mw mx lm b">Dropout</code>防止过度拟合。我们使用<code class="fe mv mw mx lm b">Flatten</code>，并以 3 个单元的<code class="fe mv mw mx lm b">Dense</code>层结束，每个类一个(圆形[0]，正方形[1]，三角形[1])。我们指定<code class="fe mv mw mx lm b">softmax</code>作为我们最后的激活函数，这是为多类分类建议的。</p><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="bf94" class="lq lr it lm b gy ls lt l lu lv"># Step 1 - Convolution<br/>classifier.add(Conv2D(32, (3, 3), padding='same', input_shape = (28, 28, 3), activation = 'relu'))<br/>classifier.add(Conv2D(32, (3, 3), activation='relu'))<br/>classifier.add(MaxPooling2D(pool_size=(2, 2)))<br/>classifier.add(Dropout(0.5)) # antes era 0.25</span><span id="305d" class="lq lr it lm b gy lw lt l lu lv"># Adding a second convolutional layer<br/>classifier.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))<br/>classifier.add(Conv2D(64, (3, 3), activation='relu'))<br/>classifier.add(MaxPooling2D(pool_size=(2, 2)))<br/>classifier.add(Dropout(0.5)) # antes era 0.25</span><span id="dd43" class="lq lr it lm b gy lw lt l lu lv"># Adding a third convolutional layer<br/>classifier.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))<br/>classifier.add(Conv2D(64, (3, 3), activation='relu'))<br/>classifier.add(MaxPooling2D(pool_size=(2, 2)))<br/>classifier.add(Dropout(0.5)) # antes era 0.25</span><span id="765a" class="lq lr it lm b gy lw lt l lu lv"># Step 3 - Flattening<br/>classifier.add(Flatten())</span><span id="8de9" class="lq lr it lm b gy lw lt l lu lv"># Step 4 - Full connection<br/>classifier.add(Dense(units = 512, activation = 'relu'))<br/>classifier.add(Dropout(0.5)) <br/>classifier.add(Dense(units = 3, activation = 'softmax'))</span></pre><p id="1c7c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">对于这种类型的图像，我可能会构建一个过于复杂的结构，这一点在我们查看特征地图时会很明显，但是，对于本文来说，它有助于我准确展示每个图层将做什么。我确信我们可以用更少的层次和更少的复杂性获得相同或更好的结果。</p><p id="c7b4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们来看看我们的模型总结:</p><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="2aa2" class="lq lr it lm b gy ls lt l lu lv">classifier.summary()</span></pre><figure class="lh li lj lk gt ju gh gi paragraph-image"><div class="gh gi my"><img src="../Images/5e9b01b4fe4e53bc0f316d897744120a.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*uQybwCcqKbBNSgeQutzOSQ.png"/></div></figure><p id="d19f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们利用<code class="fe mv mw mx lm b">rmsprop</code>作为我们的优化器、<code class="fe mv mw mx lm b">categorical_crossentropy</code>作为我们的损失函数来编译模型，并且我们指定<code class="fe mv mw mx lm b">accuracy</code>作为我们想要跟踪的度量:</p><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="b549" class="lq lr it lm b gy ls lt l lu lv"># Compiling the CNN<br/>classifier.compile(optimizer = 'rmsprop',<br/>                   loss = 'categorical_crossentropy', <br/>                   metrics = ['accuracy'])</span></pre><p id="251f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">此时，我们需要将我们的图片转换成模型可以接受的形状。为此，我们使用<code class="fe mv mw mx lm b">ImageDataGenerator</code>。我们启动它，并用<code class="fe mv mw mx lm b">.flow_from_directory</code>来填充我们的图像。工作目录中有两个主要文件夹，称为<code class="fe mv mw mx lm b">training_set</code>和<code class="fe mv mw mx lm b">test_set</code>。其中每个都有 3 个子文件夹，分别叫做<code class="fe mv mw mx lm b">circles</code>、<code class="fe mv mw mx lm b">squares</code>和<code class="fe mv mw mx lm b">triangles</code>。我已经向<code class="fe mv mw mx lm b">training_set</code>发送了每种形状的 70 张图片，向<code class="fe mv mw mx lm b">test_set</code>发送了 30 张图片。</p><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="be5a" class="lq lr it lm b gy ls lt l lu lv">train_datagen = ImageDataGenerator(rescale = 1./255)<br/>test_datagen = ImageDataGenerator(rescale = 1./255)</span><span id="af7c" class="lq lr it lm b gy lw lt l lu lv">training_set = train_datagen.flow_from_directory('training_set',<br/>                                                 target_size = (28,<br/>                                                 28),<br/>                                                 batch_size = 16,<br/>                                                 class_mode =<br/>                                                     'categorical')</span><span id="4402" class="lq lr it lm b gy lw lt l lu lv">test_set = test_datagen.flow_from_directory('test_set',<br/>                                            target_size = (28, 28),<br/>                                            batch_size = 16,<br/>                                            class_mode =<br/>                                                 'categorical')</span></pre><p id="16b2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该模型将训练 30 个时期，但我们将使用<code class="fe mv mw mx lm b">ModelCheckpoint</code>来存储最佳表现时期的权重。我们将指定<code class="fe mv mw mx lm b">val_acc</code>作为用于定义最佳模型的指标。这意味着我们将保留测试集上在准确性方面得分最高的时期的权重。</p><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="b3d3" class="lq lr it lm b gy ls lt l lu lv">checkpointer = ModelCheckpoint(filepath="best_weights.hdf5", <br/>                               monitor = 'val_acc',<br/>                               verbose=1, <br/>                               save_best_only=True)</span></pre><h2 id="4bb6" class="lq lr it bd lx ly lz dn ma mb mc dp md km me mf mg kq mh mi mj ku mk ml mm mn bi translated">训练模型</h2><p id="81fe" class="pw-post-body-paragraph kb kc it kd b ke mp kg kh ki mq kk kl km mr ko kp kq ms ks kt ku mt kw kx ky im bi translated">现在是训练模型的时候了，这里我们包括了<code class="fe mv mw mx lm b">callback</code>到<code class="fe mv mw mx lm b">checkpointer</code></p><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="5209" class="lq lr it lm b gy ls lt l lu lv">history = classifier.fit_generator(training_set,<br/>                                   steps_per_epoch = 100,<br/>                                   epochs = 20,<br/>                                   callbacks=[checkpointer],<br/>                                   validation_data = test_set,<br/>                                   validation_steps = 50)</span></pre><p id="b537" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该模型训练 20 个时期，并在时期 10 达到其最佳性能。我们得到以下消息:</p><blockquote class="la lb lc"><p id="0382" class="kb kc ld kd b ke kf kg kh ki kj kk kl le kn ko kp lf kr ks kt lg kv kw kx ky im bi translated">` Epoch 00010: val_acc 从 0.93333 提高到 0.95556，将模型保存到 best_weights.hdf5 `中</p></blockquote><p id="c4e6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在此之后，对于下一个时段，模型没有改进，因此时段 10 的权重是存储的权重——这意味着我们现在有一个存储该特定时段的权重的<code class="fe mv mw mx lm b">hdf5</code>文件，其中测试集的准确度为 95.6%</p><p id="3bbd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将确保我们的分类器装载了最好的权重</p><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="dcfa" class="lq lr it lm b gy ls lt l lu lv">classifier.load_weights('best_weights.hdf5')</span></pre><p id="1068" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最后，让我们保存最终模型以备后用:</p><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="ef5e" class="lq lr it lm b gy ls lt l lu lv">classifier.save('shapes_cnn.h5')</span></pre><h2 id="141d" class="lq lr it bd lx ly lz dn ma mb mc dp md km me mf mg kq mh mi mj ku mk ml mm mn bi translated">显示训练过程中的损耗和精度曲线</h2><p id="0d8d" class="pw-post-body-paragraph kb kc it kd b ke mp kg kh ki mq kk kl km mr ko kp kq ms ks kt ku mt kw kx ky im bi translated">现在让我们检查一下我们的模型在 30 个时期的表现:</p><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="32c6" class="lq lr it lm b gy ls lt l lu lv">acc = history.history['acc']<br/>val_acc = history.history['val_acc']<br/>loss = history.history['loss']<br/>val_loss = history.history['val_loss']</span><span id="80bf" class="lq lr it lm b gy lw lt l lu lv">epochs = range(1, len(acc) + 1)</span><span id="d6c6" class="lq lr it lm b gy lw lt l lu lv">plt.plot(epochs, acc, 'bo', label='Training acc')<br/>plt.plot(epochs, val_acc, 'b', label='Validation acc')<br/>plt.title('Training and validation accuracy')<br/>plt.legend()</span><span id="db51" class="lq lr it lm b gy lw lt l lu lv">plt.figure()</span><span id="8f7b" class="lq lr it lm b gy lw lt l lu lv">plt.plot(epochs, loss, 'bo', label='Training loss')<br/>plt.plot(epochs, val_loss, 'b', label='Validation loss')<br/>plt.title('Training and validation loss')<br/>plt.legend()</span><span id="53be" class="lq lr it lm b gy lw lt l lu lv">plt.show()</span></pre><figure class="lh li lj lk gt ju gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/636a968fa1ae269bca7b72fdc9419ac9.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*QHmHxvNX40T9k9QH2vE6FA.png"/></div></figure><p id="58fd" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以看到，在纪元 10 之后，模型开始过度拟合。不管怎样，我们保留了性能最好的 epoch 的结果。</p><h2 id="5339" class="lq lr it bd lx ly lz dn ma mb mc dp md km me mf mg kq mh mi mj ku mk ml mm mn bi translated">班级</h2><p id="962c" class="pw-post-body-paragraph kb kc it kd b ke mp kg kh ki mq kk kl km mr ko kp kq ms ks kt ku mt kw kx ky im bi translated">现在让我们弄清楚分配给每个图形集的类别号，因为这是模型产生预测的方式:</p><p id="c908" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">圆:0 <br/>正方形:1 <br/>三角形:2</p><h2 id="d27b" class="lq lr it bd lx ly lz dn ma mb mc dp md km me mf mg kq mh mi mj ku mk ml mm mn bi translated">预测看不见的图像的类别</h2><p id="79a9" class="pw-post-body-paragraph kb kc it kd b ke mp kg kh ki mq kk kl km mr ko kp kq ms ks kt ku mt kw kx ky im bi translated">通过训练和存储我们的模型，我们可以从测试集中加载一个简单的看不见的图像，并查看它是如何分类的:</p><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="3d91" class="lq lr it lm b gy ls lt l lu lv">img_path = 'test_set/triangles/drawing(2).png'</span><span id="38a6" class="lq lr it lm b gy lw lt l lu lv">img = image.load_img(img_path, target_size=(28, 28))<br/>img_tensor = image.img_to_array(img)<br/>img_tensor = np.expand_dims(img_tensor, axis=0)<br/>img_tensor /= 255.</span><span id="0243" class="lq lr it lm b gy lw lt l lu lv">plt.imshow(img_tensor[0])<br/>plt.show()</span><span id="c005" class="lq lr it lm b gy lw lt l lu lv">print(img_tensor.shape)</span></pre><figure class="lh li lj lk gt ju gh gi paragraph-image"><div class="gh gi na"><img src="../Images/372d2de78cfe5d413a47f3613d0c13d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*e9_0QYeZUZrvxMuRdRhA1w.png"/></div></figure><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="4f94" class="lq lr it lm b gy ls lt l lu lv"># predicting images<br/>x = image.img_to_array(img)<br/>x = np.expand_dims(x, axis=0)</span><span id="5e24" class="lq lr it lm b gy lw lt l lu lv">images = np.vstack([x])<br/>classes = classifier.predict_classes(images, batch_size=10)<br/>print("Predicted class is:",classes)</span><span id="a51a" class="lq lr it lm b gy lw lt l lu lv"><strong class="lm iu">&gt; Predicted class is: [2]</strong></span></pre><p id="39f5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">预测是类[2]，它是一个三角形。</p><p id="1af0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">到目前为止一切顺利。我们现在进行这篇文章最重要的部分</p><h1 id="f8e8" class="nb lr it bd lx nc nd ne ma nf ng nh md ni nj nk mg nl nm nn mj no np nq mm nr bi translated">可视化中间激活</h1><p id="1d49" class="pw-post-body-paragraph kb kc it kd b ke mp kg kh ki mq kk kl km mr ko kp kq ms ks kt ku mt kw kx ky im bi translated">引用弗朗索瓦·乔莱(Franç ois Chollet)在他的书《用 Python 进行深度学习》(这一节我会大量引用他的话):</p><p id="a138" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">中间激活<em class="ld">“有助于理解连续的 convnet 层如何转换其输入，以及初步了解各个 convnet 滤波器的意义。”</em></p><p id="3fa3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="ld">“conv nets 所学的表征非常适合可视化，很大程度上是因为它们是视觉概念的表征。可视化中间激活包括在给定特定输入的情况下，显示网络中各种卷积和池化图层输出的特征地图(图层的输出通常称为其激活，即激活函数的输出)。这给出了输入如何被分解成由网络学习的不同滤波器的视图。每个通道对相对独立的要素进行编码，因此可视化这些要素地图的正确方法是将每个通道的内容独立绘制为 2D 图像。”</em></p><p id="265d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来，我们将获得一个输入图像——一个三角形的图片，而不是网络被训练的图像的一部分。</p><p id="6d59" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="ld">“为了提取我们想要查看的特征地图，我们将创建一个 Keras 模型，该模型将成批图像作为输入，并输出所有卷积和池层的激活。为此，我们将使用 Keras 类模型。使用两个自变量实例化模型:输入张量(或输入张量列表)和输出张量(或输出张量列表)。产生的类是一个 Keras 模型，就像顺序模型一样，将指定的输入映射到指定的输出。使模型类与众不同的是，它允许具有多个输出的模型，而不像顺序输出。”</em></p><h2 id="0220" class="lq lr it bd lx ly lz dn ma mb mc dp md km me mf mg kq mh mi mj ku mk ml mm mn bi translated">从输入张量和输出张量列表实例化模型</h2><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="b42f" class="lq lr it lm b gy ls lt l lu lv">layer_outputs = [layer.output for layer in classifier.layers[:12]] <br/># Extracts the outputs of the top 12 layers</span><span id="8dec" class="lq lr it lm b gy lw lt l lu lv">activation_model = models.Model(inputs=classifier.input, outputs=layer_outputs) # Creates a model that will return these outputs, given the model input</span></pre><p id="c91c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">当输入图像时，该模型返回原始模型中的层激活值。</p><h2 id="38f9" class="lq lr it bd lx ly lz dn ma mb mc dp md km me mf mg kq mh mi mj ku mk ml mm mn bi translated">在预测模式下运行模型</h2><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="f5e3" class="lq lr it lm b gy ls lt l lu lv">activations = activation_model.predict(img_tensor) <br/># Returns a list of five Numpy arrays: one array per layer activation</span></pre><p id="2ea4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">例如，这是图像输入的第一卷积层的激活:</p><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="e38c" class="lq lr it lm b gy ls lt l lu lv">first_layer_activation = activations[0]<br/>print(first_layer_activation.shape)</span><span id="dbb6" class="lq lr it lm b gy lw lt l lu lv"><strong class="lm iu">(1, 28, 28, 32)</strong></span></pre><p id="19d5" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这是一张 28 × 28 的特征图，有 32 个通道。让我们尝试绘制原始模型的第一层的激活的第四个通道</p><pre class="lh li lj lk gt ll lm ln lo aw lp bi"><span id="3d1e" class="lq lr it lm b gy ls lt l lu lv">plt.matshow(first_layer_activation[0, :, :, 4], cmap='viridis')</span></pre><figure class="lh li lj lk gt ju gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/fce5f41469a1b99d2bb825ab21dbaf6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:492/format:webp/1*d4r5HHgymc90u28UbAIkOg.png"/></div></figure><p id="13ad" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">甚至在我们试图解释这种激活之前，让我们画出同一图像在每一层的所有激活</p><h2 id="cf85" class="lq lr it bd lx ly lz dn ma mb mc dp md km me mf mg kq mh mi mj ku mk ml mm mn bi translated">在每个中间激活中可视化每个通道</h2><p id="9959" class="pw-post-body-paragraph kb kc it kd b ke mp kg kh ki mq kk kl km mr ko kp kq ms ks kt ku mt kw kx ky im bi translated">这部分的完整代码可以在<a class="ae kz" href="https://github.com/gabrielpierobon/cnnshapes/blob/master/README.md" rel="noopener ugc nofollow" target="_blank">这里</a>找到</p><figure class="lh li lj lk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nt"><img src="../Images/174f7f924a4e6b8d8dfed94a01cacd34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F4s70_mZCqYX4b_YjUX_DA.png"/></div></div></figure><figure class="lh li lj lk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nu"><img src="../Images/34898ceaf86b963d89aa2a5d8997f68b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*66Nrn-WDavML1WU9xg_mqg.png"/></div></div></figure><figure class="lh li lj lk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nt"><img src="../Images/dd939198ee8a0db8c25031fd6a1491e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kynvS9TmOJZ4nZpyKxiSNw.png"/></div></div></figure><figure class="lh li lj lk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nv"><img src="../Images/f6315536b5d0aa1546bfa5856995f7ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SWBdDNc8MYTz5TWWFlsIrA.png"/></div></div></figure><figure class="lh li lj lk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nw"><img src="../Images/4582cd1c99da9da336b18a8c89478274.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-PVr5nYb491fjoYDMp5C7g.png"/></div></div></figure><figure class="lh li lj lk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nu"><img src="../Images/44b481794b12ad8eee8900edbacbd82a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gdNI3X-YgB0vqPuAlEk_uA.png"/></div></div></figure><figure class="lh li lj lk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nv"><img src="../Images/26c38cc4dcb7cfeeba226504973a7b60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-H2VpbwJycNxZbKT82xR1Q.png"/></div></div></figure><figure class="lh li lj lk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nv"><img src="../Images/138a3c5c48a19831613748e43f6d1dbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K-i1rLHNYhK_Oo5HbZb8yw.png"/></div></div></figure><figure class="lh li lj lk gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nx"><img src="../Images/ba041e3d9536815fa98a8c3c30bb83d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b3Tl2CKxMvBC-Y28uNZU-g.png"/></div></div></figure><p id="ac6d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这就是了！让我们试着解释一下发生了什么:</p><ul class=""><li id="6fb0" class="ny nz it kd b ke kf ki kj km oa kq ob ku oc ky od oe of og bi translated">第一层可以说是保留了三角形的完整形状，尽管有几个滤镜没有被激活，留为空白。在该阶段，激活保留了初始图片中几乎所有的信息。</li><li id="4828" class="ny nz it kd b ke oh ki oi km oj kq ok ku ol ky od oe of og bi translated">随着我们越来越深入，激活变得越来越抽象，越来越难以视觉解释。他们开始编码更高层次的概念，如单个边框、角和角度。更高的呈现携带越来越少的关于图像的视觉内容的信息，以及越来越多的关于图像类别的信息。</li><li id="a092" class="ny nz it kd b ke oh ki oi km oj kq ok ku ol ky od oe of og bi translated">如上所述，模型结构过于复杂，以至于我们可以看到我们最后的层实际上根本没有激活，在这一点上没有什么需要学习的。</li></ul><p id="98ba" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">原来就是这样！我们已经看到了卷积神经网络如何发现一些基本图形中的模式，以及它如何将信息从一层传递到另一层。</p><p id="cade" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae kz" href="https://github.com/gabrielpierobon/cnnshapes/blob/master/README.md" rel="noopener ugc nofollow" target="_blank">完整代码在此</a>。</p></div></div>    
</body>
</html>