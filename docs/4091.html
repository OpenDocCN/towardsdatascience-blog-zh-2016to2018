<html>
<head>
<title>Serving Image-Based Deep Learning Models with TensorFlow-Serving’s RESTful API</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 TensorFlow-Serving 的 RESTful API 服务基于图像的深度学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/serving-image-based-deep-learning-models-with-tensorflow-servings-restful-api-d365c16a7dc4?source=collection_archive---------1-----------------------#2018-07-18">https://towardsdatascience.com/serving-image-based-deep-learning-models-with-tensorflow-servings-restful-api-d365c16a7dc4?source=collection_archive---------1-----------------------#2018-07-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="dd93" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何在网络中提供端到端的 Tensorflow 模型？</h2></div><p id="7cf9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">TensorFlow-Serving 是一个有用的工具，由于它的新近性和相当小众的用例，它没有太多的在线教程。在这里，我将展示一个解决方案，演示 TensorFlow 的端到端实现——在基于图像的模型上提供服务，涵盖从将图像转换为 Base64 到将 TensorFlow 模型服务器与深度神经网络集成的所有内容。</p><p id="1878" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本教程中，提供了一个最小的工作示例——这个实现可以很容易地扩展到包括 Docker 容器、Bazel 构建、批量推理和模型解耦。这里的主要焦点是理解使用 TensorFlow-Serving 的一般要求，独立于任何可选的附加功能。使用 TensorFlow-Serving 的 RESTful 版本，与 gRPC 版本相反，我们实现了 predict 函数，但是也可以使用 classify 和 regression。</p><p id="8c37" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你想在 Jupyter 笔记本上查看这个教程，请<a class="ae lb" href="https://github.com/tmlabonte/tendies/blob/master/minimum_working_example/tendies-basic-tutorial.ipynb" rel="noopener ugc nofollow" target="_blank">点击这里</a>。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h1 id="06c4" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">概观</h1><p id="0588" class="pw-post-body-paragraph kf kg iq kh b ki mb jr kk kl mc ju kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">在最基本的层面上，TensorFlow-Serving 允许开发人员将客户端请求和数据与独立于客户端系统的深度学习模型相集成。这样做的好处包括客户端能够对数据进行推断，而不必实际安装 TensorFlow，甚至不必与实际模型有任何联系，并且能够用一个模型实例为多个客户端提供服务。</p><p id="0bbd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的管道将是这样的:</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="gh gi mg"><img src="../Images/7b7522dcb303792301880fd54c32a8a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rVMqevPW_TJtUZYswBWEIA.png"/></div></div></figure><p id="7af8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">特别要注意的是，图像必须作为一个<a class="ae lb" href="https://i.imgflip.com/2eot7o.jpg" rel="noopener ugc nofollow" target="_blank"> Base64 编码的字符串</a>从客户端传递到服务器。这是因为 JSON 没有其他方法来表示图像(除了张量的数组表示，这很快就会失控)。图像也必须作为张量从原型传递到生成器。这是可以修改的，但是最好保持任何预处理和后处理与模型本身分离。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h1 id="b3c7" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">计算机网络服务器</h1><p id="6856" class="pw-post-body-paragraph kf kg iq kh b ki mb jr kk kl mc ju kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">导出用于服务的 TensorFlow 模型可能是该过程中最令人困惑的部分，因为这涉及到几个步骤。</p><ol class=""><li id="400b" class="ms mt iq kh b ki kj kl km ko mu ks mv kw mw la mx my mz na bi translated">将图形导出为 ProtoBuf 格式。这将保存 GraphDef 和变量，并表示训练好的模型。为了导出基于图像的模型，我们必须在图形的开头和结尾注入位串转换层，因为我们要求我们的推理函数只处理张量。</li><li id="f4c3" class="ms mt iq kh b ki nb kl nc ko nd ks ne kw nf la mx my mz na bi translated">将 ProtoBuf 包装在 SavedModel 中。这一步是必要的，因为 TensorFlow-Serving 的 RESTful API 是通过 SavedModelBuilder 实现的。我们将导入我们的 GraphDef，然后提取输入和输出的 TensorInfo 来定义我们的预测签名定义。</li></ol><p id="f90f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用<a class="ae lb" href="https://github.com/tmlabonte/CycleGAN-TensorFlow" rel="noopener ugc nofollow" target="_blank"> CycleGAN </a>作为使用示例。首先，导入一些有用的库:</p><pre class="mh mi mj mk gt ng nh ni nj aw nk bi"><span id="cfa7" class="nl lk iq nh b gy nm nn l no np">import tensorflow as tf<br/>import argparse<br/>import sys<br/>sys.path.insert(0, “../CycleGAN-TensorFlow”)<br/>import model</span></pre><p id="a16a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这里，我们实例化一个 CycleGAN 并注入我们的第一层。</p><pre class="mh mi mj mk gt ng nh ni nj aw nk bi"><span id="8ad3" class="nl lk iq nh b gy nm nn l no np">graph = tf.Graph()<br/><br/><strong class="nh ir">with</strong> graph.as_default():<br/>    <em class="nq"># Instantiate a CycleGAN</em><br/>    cycle_gan = model.CycleGAN(ngf=64, norm="instance", image_size=64)<br/><br/>    <em class="nq"># Create placeholder for image bitstring</em><br/>    <em class="nq"># This is the injection of the input bitstring layer</em><br/>    input_bytes = tf.placeholder(tf.string, shape=[], name="input_bytes")</span></pre><p id="a04f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们将位串预处理为一个浮点张量批，以便它可以在模型中使用。</p><pre class="mh mi mj mk gt ng nh ni nj aw nk bi"><span id="8096" class="nl lk iq nh b gy nm nn l no np"><strong class="nh ir">with</strong> graph.as_default(): <br/>    input_bytes = tf.reshape(input_bytes, [])<br/>    <br/>    <em class="nq"># Transform bitstring to uint8 tensor</em><br/>    input_tensor = tf.image.decode_png(input_bytes, channels=3)<br/>    <br/>    <em class="nq"># Convert to float32 tensor</em><br/>    input_tensor = tf.image.convert_image_dtype(input_tensor,  dtype=tf.float32)<br/>    <br/>    <em class="nq"># Ensure tensor has correct shape</em><br/>    input_tensor = tf.reshape(input_tensor, [64, 64, 3])<br/>    <br/>    <em class="nq"># CycleGAN's inference function accepts a batch of images</em><br/>    <em class="nq"># So expand the single tensor into a batch of 1</em><br/>    input_tensor = tf.expand_dims(input_tensor, 0)</span></pre><p id="f647" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们将张量输入模型并保存其输出。</p><pre class="mh mi mj mk gt ng nh ni nj aw nk bi"><span id="5074" class="nl lk iq nh b gy nm nn l no np"><strong class="nh ir">with</strong> graph.as_default():<br/>    <em class="nq"># Get style transferred tensor</em><br/>    output_tensor = cycle_gan.G.sample(input_tensor)</span></pre><p id="d1d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">后推理，我们将浮点张量转换回一个位串。这是输出层的注入:</p><pre class="mh mi mj mk gt ng nh ni nj aw nk bi"><span id="dd77" class="nl lk iq nh b gy nm nn l no np"><strong class="nh ir">with</strong> graph.as_default():    <br/>    <em class="nq"># Convert to uint8 tensor</em><br/>    output_tensor = tf.image.convert_image_dtype(output_tensor, tf.uint8)<br/>    <br/>    <em class="nq"># Remove the batch dimension</em><br/>    output_tensor = tf.squeeze(output_tensor, [0])<br/>    <br/>    <em class="nq"># Transform uint8 tensor to bitstring</em><br/>    output_bytes = tf.image.encode_png(output_tensor)<br/>    output_bytes = tf.identity(output_bytes, name="output_bytes")<br/>    <br/>    <em class="nq"># Instantiate a Saver</em><br/>    saver = tf.train.Saver()</span></pre><p id="3290" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">既然我们已经将位串层注入到我们的模型中，我们将加载我们的火车检查点并将图保存为 ProtoBuf。在对该服务器进行编码之前，我对 CycleGAN 进行了 10，000 步的训练，并将检查点文件保存在我的本地机器上，我将在该会话中访问该文件。</p><pre class="mh mi mj mk gt ng nh ni nj aw nk bi"><span id="083a" class="nl lk iq nh b gy nm nn l no np"><em class="nq"># Start a TensorFlow session</em><br/><strong class="nh ir">with</strong> tf.Session(graph=graph) <strong class="nh ir">as</strong> sess:<br/>        sess.run(tf.global_variables_initializer())<br/><br/>        <em class="nq"># Access variables and weights from last checkpoint</em><br/>        latest_ckpt = tf.train.latest_checkpoint("../CycleGAN-TensorFlow/checkpoints/20180628-1208")<br/>        saver.restore(sess, latest_ckpt)<br/><br/>        <em class="nq"># Export graph to ProtoBuf</em><br/>        output_graph_def = tf.graph_util.convert_variables_to_constants(sess, graph.as_graph_def(), [output_bytes.op.name])<br/>        tf.train.write_graph(output_graph_def, "../CycleGAN-TensorFlow/protobufs", "model_v1", as_text=<strong class="nh ir">False</strong>)</span></pre><p id="85b6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">至此，我们完成了第一步！在第二步中，我们将把 ProtoBuf 包装在一个 SavedModel 中，以使用 RESTful API。</p><pre class="mh mi mj mk gt ng nh ni nj aw nk bi"><span id="24ce" class="nl lk iq nh b gy nm nn l no np"><em class="nq"># Instantiate a SavedModelBuilder</em><br/><em class="nq"># Note that the serve directory is REQUIRED to have a model version subdirectory</em><br/>builder = tf.saved_model.builder.SavedModelBuilder("serve/1")<br/><br/><em class="nq"># Read in ProtoBuf file</em><br/><strong class="nh ir">with</strong> tf.gfile.GFile("../CycleGAN-TensorFlow/protobufs/model_v1", "rb") <strong class="nh ir">as</strong> protobuf_file:<br/>    graph_def = tf.GraphDef()<br/>    graph_def.ParseFromString(protobuf_file.read())<br/><br/><em class="nq"># Get input and output tensors from GraphDef</em><br/><em class="nq"># These are our injected bitstring layers</em><br/>[inp, out] = tf.import_graph_def(graph_def, name="", return_elements=["input_bytes:0", "output_bytes:0"])</span></pre><p id="dfb9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们定义我们的签名定义，它期望模型的输入和输出的张量信息。当我们保存模型时，我们会得到一个“No assets”消息，但是这没关系，因为我们的图和变量已经保存在 ProtoBuf 中了。</p><pre class="mh mi mj mk gt ng nh ni nj aw nk bi"><span id="a770" class="nl lk iq nh b gy nm nn l no np"><em class="nq"># Start a TensorFlow session with our saved graph</em><br/><strong class="nh ir">with</strong> tf.Session(graph=out.graph) <strong class="nh ir">as</strong> sess:<br/>        <em class="nq"># Signature_definition expects a batch</em><br/>        <em class="nq"># So we'll turn the output bitstring into a batch of 1 element</em><br/>        out = tf.expand_dims(out, 0)<br/><br/>        <em class="nq"># Build prototypes of input and output bitstrings</em><br/>        input_bytes = tf.saved_model.utils.build_tensor_info(inp)<br/>        output_bytes = tf.saved_model.utils.build_tensor_info(out)<br/><br/>        <em class="nq"># Create signature for prediction</em><br/>        signature_definition = tf.saved_model.signature_def_utils.build_signature_def(<br/>            inputs={"input_bytes": input_bytes},<br/>            outputs={"output_bytes": output_bytes},<br/>            method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME)<br/><br/>        <em class="nq"># Add meta-information</em><br/>        builder.add_meta_graph_and_variables(<br/>            sess, [tf.saved_model.tag_constants.SERVING],<br/>            signature_def_map={<br/>                tf.saved_model.signature_constants.<br/>                DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature_definition<br/>            })<br/><br/><em class="nq"># Create the SavedModel</em><br/>builder.save()</span></pre><p id="2102" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就是这样！命令行返回的是 SavedModel 的路径，它用于构建 TensorFlow 模型服务器。serve/1 中的“variables”文件夹将是空的，但这没关系，因为我们的变量已经保存在 ProtoBuf 中了。</p><p id="d495" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">截至 2018 年 7 月，Python 3 不支持 TensorFlow 服务，但<a class="ae lb" href="https://github.com/tensorflow/serving/issues/700" rel="noopener ugc nofollow" target="_blank">有人提出了解决方案</a>。安装 Python 3 TensorFlow 服务 API，包括:</p><pre class="mh mi mj mk gt ng nh ni nj aw nk bi"><span id="901f" class="nl lk iq nh b gy nm nn l no np">pip install tensorflow-serving-api-python3</span></pre><p id="f021" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我们可以用下面的命令从 bash 运行这个 TensorFlow 模型服务器:</p><pre class="mh mi mj mk gt ng nh ni nj aw nk bi"><span id="f091" class="nl lk iq nh b gy nm nn l no np">tensorflow_model_server --rest_api_port=8501 --model_name=saved_model --model_base_path=$(path)</span></pre><p id="5112" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中$(path)是服务器目录的路径。我的例子是/mnt/c/Users/Tyler/Desktop/tendies/minimum _ working _ example/serve。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h1 id="7253" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">客户</h1><p id="e6b4" class="pw-post-body-paragraph kf kg iq kh b ki mb jr kk kl mc ju kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">客户端的工作是接受图像作为输入，将其转换为 Base64，使用 JSON 将其传递给服务器，并解码响应。首先，导入一些有用的库:</p><pre class="mh mi mj mk gt ng nh ni nj aw nk bi"><span id="5592" class="nl lk iq nh b gy nm nn l no np"><strong class="nh ir">import</strong> <strong class="nh ir">base64</strong><br/><strong class="nh ir">import</strong> <strong class="nh ir">requests</strong><br/><strong class="nh ir">import</strong> <strong class="nh ir">json</strong><br/><strong class="nh ir">import</strong> <strong class="nh ir">argparse</strong></span></pre><p id="554d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将执行从高斯噪声图像到正弦噪声图像的风格转换。这是高斯图像:</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/230b47e606406274ffeebd9d31040dd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*5XLvRKLnIwkVWGTqwctm-Q.png"/></div></figure><p id="883d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们将打开图像并将其转换为 Base64。</p><pre class="mh mi mj mk gt ng nh ni nj aw nk bi"><span id="e3f2" class="nl lk iq nh b gy nm nn l no np"><em class="nq"># Open and read image as bitstring</em><br/>input_image = open("images/gaussian.png", "rb").read()<br/>print("Raw bitstring: " + str(input_image[:10]) + " ... " + str(input_image[-10:]))<br/><br/><em class="nq"># Encode image in b64</em><br/>encoded_input_string = base64.b64encode(input_image)<br/>input_string = encoded_input_string.decode("utf-8")<br/>print("Base64 encoded string: " + input_string[:10] + " ... " + input_string[-10:])</span></pre><p id="ca31" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">发送到 TensorFlow 模型服务器的 JSON 数据必须以一种非常特殊的方式构建。这种方法将<a class="ae lb" href="https://www.tensorflow.org/serving/api_rest" rel="noopener ugc nofollow" target="_blank">略有不同</a>用于分类和回归。对于图像预测调用，我们的 JSON 主体必须如下所示:</p><pre class="mh mi mj mk gt ng nh ni nj aw nk bi"><span id="e7ae" class="nl lk iq nh b gy nm nn l no np">{<br/>  "instances": [<br/>                  {"b64": "iVBORw"},<br/>                  {"b64": "pT4rmN"},<br/>                  {"b64": "w0KGg2"}<br/>                 ]<br/>}</span></pre><p id="3ffe" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为我们只向服务器发送一张图片，所以这很简单。我们可以像这样创建 JSON 数据:</p><pre class="mh mi mj mk gt ng nh ni nj aw nk bi"><span id="087e" class="nl lk iq nh b gy nm nn l no np"><em class="nq"># Wrap bitstring in JSON</em><br/>instance = [{"b64": input_string}]<br/>data = json.dumps({"instances": instance})<br/>print(data[:30] + " ... " + data[-10:])</span></pre><p id="90ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是我们向 TensorFlow 模型服务器发送 POST 请求所需的全部内容。这是一个同步调用，所以客户端将暂停，直到它收到来自服务器的响应(当您想知道为什么您的代码在发布一个非常大的图像后停止时，这很有用)。</p><pre class="mh mi mj mk gt ng nh ni nj aw nk bi"><span id="e026" class="nl lk iq nh b gy nm nn l no np">json_response = requests.post("http://localhost:8501/v1/models/saved_model:predict", data=data)</span></pre><p id="452f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了解释响应，我们以相反的顺序执行上述步骤。为了从 JSON 响应中获取 base64 编码的图像，我们必须访问:</p><ol class=""><li id="588f" class="ms mt iq kh b ki kj kl km ko mu ks mv kw mw la mx my mz na bi translated">对应于响应字典中“预测”的值。</li><li id="8517" class="ms mt iq kh b ki nb kl nc ko nd ks ne kw nf la mx my mz na bi translated">结果数组中的第一个条目。</li><li id="aeb4" class="ms mt iq kh b ki nb kl nc ko nd ks ne kw nf la mx my mz na bi translated">结果字典中对应于“b64”的值。</li></ol><p id="5fe3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我们将把这个值解码成一个原始的位串。</p><pre class="mh mi mj mk gt ng nh ni nj aw nk bi"><span id="ae6d" class="nl lk iq nh b gy nm nn l no np"><em class="nq"># Extract text from JSON</em><br/>response = json.loads(json_response.text)<br/><br/><em class="nq"># Interpret bitstring output</em><br/>response_string = response["predictions"][0]["b64"]<br/>print("Base64 encoded string: " + response_string[:10] + " ... " + response_string[-10:])<br/><br/><em class="nq"># Decode bitstring</em><br/>encoded_response_string = response_string.encode("utf-8")<br/>response_image = base64.b64decode(encoded_response_string)<br/>print("Raw bitstring: " + str(response_image[:10]) + " ... " + str(response_image[-10:]))<br/><br/><em class="nq"># Save inferred image</em><br/><strong class="nh ir">with</strong> open("images/sinusoidal.png", "wb") <strong class="nh ir">as</strong> output_file:<br/>    output_file.write(response_image)</span></pre><p id="12b6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">成功！这是合成图像，它在我们的原始图像上添加了正弦噪声模式。</p><figure class="mh mi mj mk gt ml gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/ed5bf7458c96a64c1741cea62423c98f.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*cGcV8t4JZY2tCo2t0mIEJw.png"/></div></figure></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><h1 id="956e" class="lj lk iq bd ll lm ln lo lp lq lr ls lt jw lu jx lv jz lw ka lx kc ly kd lz ma bi translated">结论</h1><p id="1410" class="pw-post-body-paragraph kf kg iq kh b ki mb jr kk kl mc ju kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">感谢跟随本教程；希望对你有帮助！这款笔记本基于我的 TensorFlow 分布式图像服务库的最小工作示例，您可以在这里下载<a class="ae lb" href="https://github.com/tmlabonte/tendies" rel="noopener ugc nofollow" target="_blank"/>。如果您有兴趣将这个库与 TensorFlow 对象检测 API 甚至您自己的模型集成在一起，请查看本文的<a class="ae lb" href="https://medium.com/@tmlabonte/integrating-tensorflow-distributed-image-serving-with-the-tensorflow-object-detection-api-5f62d80bce4c" rel="noopener">续集。更多关于我的博文和信息，请访问我的</a><a class="ae lb" href="https://tmlabonte.github.io" rel="noopener ugc nofollow" target="_blank">网站</a>。</p></div></div>    
</body>
</html>