<html>
<head>
<title>25 Lights</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">25盏灯</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/25-lights-c4cc2c3f1832?source=collection_archive---------12-----------------------#2017-10-02">https://towardsdatascience.com/25-lights-c4cc2c3f1832?source=collection_archive---------12-----------------------#2017-10-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ad72" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">第一部分:问题介绍和简单解决方案</h2></div><p id="b7f8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第二部分:<a class="ae lb" rel="noopener" target="_blank" href="/25-lights-part-ii-e021b66e449b">使用真实世界的数据</a></p><p id="42f9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在是进入机器学习的绝佳时机。有一些工具和资源可以帮助任何拥有一些编码技能和需要解决的问题的人去做有趣的工作。我一直在关注针对程序员的<a class="ae lb" href="http://course.fast.ai" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">实用深度学习</strong> </a> <strong class="kh ir"> </strong>和大卫·西尔维的<strong class="kh ir"> </strong> <a class="ae lb" href="https://www.youtube.com/watch?v=2pWv7GOvuf0" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">强化学习课程</strong></a><strong class="kh ir"/><a class="ae lb" href="https://www.youtube.com/watch?v=vq2nnJ4g6N0&amp;t=2s" rel="noopener ugc nofollow" target="_blank"><strong class="kh ir">没有博士学位的机器学习</strong> </a> <strong class="kh ir"> </strong>是对深度学习技术的极好介绍。这些，连同所有链接自《黑客新闻》的论文和<a class="ae lb" href="https://www.youtube.com/user/keeroyz" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">两分钟论文</strong> </a> <strong class="kh ir"> </strong>都激励我尝试一些想法。</p><p id="1fad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我过去曾做过物联网设备的设置过程，通过BTLE从iPhone连接到它。依赖单一通道进行设置的漏洞之一是<a class="ae lb" href="https://en.wikipedia.org/wiki/Man-in-the-middle_attack" rel="noopener ugc nofollow" target="_blank">中间人攻击</a>。击败MitM的一种方法是对交换的公钥使用带外认证。这可以通过在设备的发光二极管上编码一个随机的位模式，并从手机的摄像头中读取它们来实现。这将是Apple Watch设置协议的一个不太复杂的版本，但仍然非常有效。</p><p id="59c0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我正在考虑的设备在前面有一个5x5的灯阵列。2 ⁵可以编码33，554，432种可能性，非常适合密钥交换验证。现在的挑战是找到一种从图像中自动提取位模式的方法。</p><p id="f5b4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我尝试改编了Fast.ai MOOC早期使用的VGG16 net。我尝试了几轮培训，并应用标准建议来微调网络。这未能产生有意义的结果。VGG16和像它一样的深网在识别单一类别方面很棒，但我不确定它是否能跟踪25盏灯。在第二部分中，我展示了类似VGG16的网络是如何工作的。休息之后，思考和阅读其他项目和<a class="ae lb" href="https://arxiv.org/pdf/1412.6622.pdf" rel="noopener ugc nofollow" target="_blank">技术</a>，我遇到了<a class="ae lb" href="https://en.wikipedia.org/wiki/Autoencoder" rel="noopener ugc nofollow" target="_blank">自动编码器</a>。自动编码器是一种神经网络，它将输入编码成较小的向量，然后将该向量解码回原始大小。损失函数用于比较输入和输出之间的差异。然后，可以训练自动编码器来最小化损失。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/ededcc6856a70afe01efdf81fdefe714.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P7aFcjaMGLwzTvjW3sD-5Q.jpeg"/></div><figcaption class="lk ll gj gh gi lm ln bd b be z dk">Autoencoder diagram from the Keras blog</figcaption></figure><p id="1946" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">自动编码器不是最复杂的技术，但最好从简单的解决方案开始。<a class="ae lb" href="https://blog.keras.io/building-autoencoders-in-keras.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kh ir">在Keras中构建auto encoders</strong></a><strong class="kh ir"/>是一个很好的介绍，我在这里的探索紧随那个帖子。</p><h1 id="e377" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">图象生成</h1><p id="5185" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">为了训练自动编码器，我们需要一些图像。下面是绘制我们想要识别的图像的Python代码。幸运的是，我们可以很容易地生成训练所需的图像。真实世界的图像将很难获得这里所需要的数量。</p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="ml mm l"/></div></figure><h1 id="9ee8" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">简单自动编码器</h1><p id="b2ad" class="pw-post-body-paragraph kf kg iq kh b ki mg jr kk kl mh ju kn ko mi kq kr ks mj ku kv kw mk ky kz la ij bi translated">现在我们有了图像生成器，我们可以制作一个非常简单的自动编码器。这几乎与Keras博客中的第一个自动编码器<a class="ae lb" href="https://blog.keras.io/building-autoencoders-in-keras.html" rel="noopener ugc nofollow" target="_blank">相同。</a></p><figure class="ld le lf lg gt lh"><div class="bz fp l di"><div class="ml mm l"/></div></figure><p id="b14a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在批量大小为128的500次迭代之后，我们得到0.1012的损失。这大约是autoencoder博客中第一次尝试的损失水平。这是我们看到的。输入图像在顶部，解码在底部。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mn"><img src="../Images/12836da2bb42c20f0ea89655326a2461.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Wi4gXUmDqntMbFl9M6Mkg.png"/></div></div></figure><p id="5c97" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这看起来没有我希望的那么好，但是请注意点颜色的细微变化。再给它几千次迭代吧。</p><p id="430b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">5000次迭代得到0.0031的损失。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi ms"><img src="../Images/0a19ccc7a5e9c138d536871d73b0796b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ACbssc-FYiW6dWiNs2n4FA.png"/></div></div></figure><p id="16cd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这还差不多。现在又多了5000，应该不错。</p><p id="7751" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">迭代10000次后，损耗为0.000288。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="mo mp di mq bf mr"><div class="gh gi mt"><img src="../Images/e68e950566bb1f3698044c39977d122b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PZHWHO5o23y_zbsxaiqBhw.png"/></div></div></figure><p id="7d6b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它看起来不错，但这种简单的网络经不起真实世界的输入。看看我的下一篇文章，我将展示如何识别照片中的点图案。然后如何用CoreML在iPhone上运行网络。</p><h2 id="65c6" class="mu lp iq bd lq mv mw dn lu mx my dp ly ko mz na ma ks nb nc mc kw nd ne me nf bi translated">第二部分:<a class="ae lb" rel="noopener" target="_blank" href="/25-lights-part-ii-e021b66e449b">使用真实世界的数据</a></h2></div></div>    
</body>
</html>