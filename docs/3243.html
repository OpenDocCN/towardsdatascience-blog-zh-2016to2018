<html>
<head>
<title>Elmo Embeddings in Keras with TensorFlow hub</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带TensorFlow hub的Keras中的Elmo嵌入</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/elmo-embeddings-in-keras-with-tensorflow-hub-7eb6f0145440?source=collection_archive---------1-----------------------#2018-04-24">https://towardsdatascience.com/elmo-embeddings-in-keras-with-tensorflow-hub-7eb6f0145440?source=collection_archive---------1-----------------------#2018-04-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="5d93" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">新发布的<a class="ae kl" href="https://www.tensorflow.org/hub/" rel="noopener ugc nofollow" target="_blank"> Tensorflow hub </a>提供了一个简单的接口，可以使用现有的机器学习模型进行迁移学习。然而，有时启动Keras并快速构建模型原型也是不错的。通过一些修复，很容易将Tensorflow hub模型与Keras集成在一起！</p><p id="6f6a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://arxiv.org/pdf/1802.05365.pdf" rel="noopener ugc nofollow" target="_blank">在<a class="ae kl" href="http://allennlp.org/elmo" rel="noopener ugc nofollow" target="_blank"> Allen NLP </a>开发的ELMo嵌入</a>，是Tensorflow Hub上许多优秀的预训练模型之一。ELMo嵌入从双向LSTM的内部状态中学习，并表示输入文本的上下文特征。在各种各样的自然语言处理任务中，它的表现都优于GloVe和Word2Vec嵌入。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi km"><img src="../Images/09b01a5f299c41d32050e50f59ba4e46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*gpBBcQbdtIceERjJ784j1A.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">A bidirectional LSTM is trained on a large text corpus, and the internal states are combined to calculate rich, context sensitive features of text.</figcaption></figure><p id="7e69" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是我们在<a class="ae kl" href="http://strong.io" rel="noopener ugc nofollow" target="_blank"> Strong Analytics </a>的团队最近使用Keras中最先进的ELMo嵌入技术制作的一个NLP模型的原型。</p><p id="f853" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我们加载一些数据:</p><pre class="kn ko kp kq gt ky kz la lb aw lc bi"><span id="2d0a" class="ld le iq kz b gy lf lg l lh li"># Load all files from a directory in a DataFrame.<br/>def load_directory_data(directory):<br/>  data = {}<br/>  data["sentence"] = []<br/>  data["sentiment"] = []<br/>  for file_path in os.listdir(directory):<br/>    with tf.gfile.GFile(os.path.join(directory, file_path), "r") as f:<br/>      data["sentence"].append(f.read())<br/>      data["sentiment"].append(re.match("\d+_(\d+)\.txt", file_path).group(1))<br/>  return pd.DataFrame.from_dict(data)<br/><br/># Merge positive and negative examples, add a polarity column and shuffle.<br/>def load_dataset(directory):<br/>  pos_df = load_directory_data(os.path.join(directory, "pos"))<br/>  neg_df = load_directory_data(os.path.join(directory, "neg"))<br/>  pos_df["polarity"] = 1<br/>  neg_df["polarity"] = 0<br/>  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)<br/><br/># Download and process the dataset files.<br/>def download_and_load_datasets(force_download=False):<br/>  dataset = tf.keras.utils.get_file(<br/>      fname="aclImdb.tar.gz", <br/>      origin="http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz", <br/>      extract=True)<br/><br/>  train_df = load_dataset(os.path.join(os.path.dirname(dataset), <br/>                                       "aclImdb", "train"))<br/>  test_df = load_dataset(os.path.join(os.path.dirname(dataset), <br/>                                      "aclImdb", "test"))<br/><br/>  return train_df, test_df<br/><br/># Reduce logging output.<br/>tf.logging.set_verbosity(tf.logging.ERROR)<br/><br/>train_df, test_df = download_and_load_datasets()<br/>train_df.head()</span></pre><p id="1e69" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们接下来处理我们的数据。注意，要使用字符串作为Keras模型的输入，我们需要创建一个numpy对象数组。我已经将这些数据限制为内存的前150个字(ELMo嵌入是计算密集型的，所以使用GPU！).</p><pre class="kn ko kp kq gt ky kz la lb aw lc bi"><span id="df12" class="ld le iq kz b gy lf lg l lh li"># Create datasets (Only take up to 150 words)<br/>train_text = train_df['sentence'].tolist()<br/>train_text = [' '.join(t.split()[0:150]) for t in train_text]<br/>train_text = np.array(train_text, dtype=object)[:, np.newaxis]<br/>train_label = train_df['polarity'].tolist()</span><span id="b993" class="ld le iq kz b gy lj lg l lh li">test_text = test_df['sentence'].tolist()<br/>test_text = [' '.join(t.split()[0:150]) for t in test_text]<br/>test_text = np.array(test_text, dtype=object)[:, np.newaxis]<br/>test_label = test_df['polarity'].tolist()</span></pre><p id="d70f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要在Keras中实例化Elmo嵌入，我们首先必须创建一个自定义层，以确保嵌入权重是可训练的:</p><pre class="kn ko kp kq gt ky kz la lb aw lc bi"><span id="50f3" class="ld le iq kz b gy lf lg l lh li">class ElmoEmbeddingLayer(Layer):<br/>    def __init__(self, **kwargs):<br/>        self.dimensions = 1024<br/>        self.trainable = True<br/>        super(ElmoEmbeddingLayer, self).__init__(**kwargs)</span><span id="c416" class="ld le iq kz b gy lj lg l lh li">def build(self, input_shape):<br/>        self.elmo = hub.Module('<a class="ae kl" href="https://tfhub.dev/google/elmo/2'" rel="noopener ugc nofollow" target="_blank">https://tfhub.dev/google/elmo/2'</a>, trainable=self.trainable, name="{}_module".format(self.name))</span><span id="f8ad" class="ld le iq kz b gy lj lg l lh li">self.trainable_weights += K.tf.trainable_variables(scope="^{}_module/.*".format(self.name))<br/>        super(ElmoEmbeddingLayer, self).build(input_shape)</span><span id="36c1" class="ld le iq kz b gy lj lg l lh li">def call(self, x, mask=None):<br/>        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),<br/>                      as_dict=True,<br/>                      signature='default',<br/>                      )['default']<br/>        return result</span><span id="050e" class="ld le iq kz b gy lj lg l lh li">def compute_mask(self, inputs, mask=None):<br/>        return K.not_equal(inputs, '--PAD--')</span><span id="1233" class="ld le iq kz b gy lj lg l lh li">def compute_output_shape(self, input_shape):<br/>        return (input_shape[0], self.dimensions)</span></pre><p id="ec61" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们可以使用ElmoEmbeddingLayer构建和训练我们的模型:</p><pre class="kn ko kp kq gt ky kz la lb aw lc bi"><span id="d74f" class="ld le iq kz b gy lf lg l lh li">input_text = layers.Input(shape=(1,), dtype=tf.string)<br/>embedding = ElmoEmbeddingLayer()(input_text)<br/>dense = layers.Dense(256, activation='relu')(embedding)<br/>pred = layers.Dense(1, activation='sigmoid')(dense)</span><span id="3c55" class="ld le iq kz b gy lj lg l lh li">model = Model(inputs=[input_text], outputs=pred)</span><span id="e190" class="ld le iq kz b gy lj lg l lh li">model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])<br/>model.summary()</span><span id="fad9" class="ld le iq kz b gy lj lg l lh li">model.fit(train_text, <br/>          train_label,<br/>          validation_data=(test_text, test_label),<br/>          epochs=5,<br/>          batch_size=32)</span></pre><p id="3506" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">就是这样！tensorflow hub上有很多很棒的模型，一定要全部试用！</p><p id="6176" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">点击这里查看IPython笔记本:<a class="ae kl" href="https://github.com/strongio/keras-elmo/blob/master/Elmo%20Keras.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/strong io/keras-Elmo/blob/master/Elmo % 20 keras . ipynb</a>'</p></div><div class="ab cl lk ll hu lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ij ik il im in"><p id="1e04" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="lr">想和芝加哥的顶级数据科学家团队一起从事各种行业中具有挑战性的NLP、机器学习和AI工作吗？我们正在招聘有才华的数据科学家和工程师！</em>T13】</strong></p><p id="4fdb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<a class="ae kl" href="http://strong.io" rel="noopener ugc nofollow" target="_blank"> strong.io </a>了解更多信息，并在<a class="ae kl" href="https://careers.strong.io/" rel="noopener ugc nofollow" target="_blank"> careers.strong.io </a>申请</p></div></div>    
</body>
</html>