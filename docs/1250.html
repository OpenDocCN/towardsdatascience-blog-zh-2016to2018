<html>
<head>
<title>Handwritten digit recognition with MNIST on iOS with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras在iOS上使用MNIST进行手写数字识别</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/handwritten-digit-recognition-with-mnist-on-ios-with-keras-e85e194f9fa5?source=collection_archive---------1-----------------------#2017-08-15">https://towardsdatascience.com/handwritten-digit-recognition-with-mnist-on-ios-with-keras-e85e194f9fa5?source=collection_archive---------1-----------------------#2017-08-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="5e66" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><em class="kl">或者:如何在iOS中使用一个Keras深度学习神经网络？</em></h1><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/f6772700519c21165b5f7bc9c64191b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4TJWlK-FPhskEIJshfEx5g.jpeg"/></div></div></figure><p id="dedb" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">本教程展示了在Tensorflow上使用<a class="ae lw" href="https://keras.io" rel="noopener ugc nofollow" target="_blank"> Keras </a>构建和训练的卷积神经网络模型的使用。我将展示如何将该模型集成到iOS中，并通过apple为iOS11引入的新CoreML和Vision Api在代码中访问该模型(本教程中为Objective-C)。我在mnist数据集上训练了这个模型，以便创建一个可以识别手写数字的应用程序。</p><blockquote class="lx ly lz"><p id="6583" class="ky kz ma la b lb lc ld le lf lg lh li mb lk ll lm mc lo lp lq md ls lt lu lv ij bi translated"><strong class="la ir">对于那些TL；博士:我感觉你- &gt; </strong> <a class="ae lw" href="https://github.com/boaerosuke/digitrecognition_ios" rel="noopener ugc nofollow" target="_blank"> <strong class="la ir">下面是代码！</strong>T9】</a></p></blockquote><p id="a18a" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">对于那些不熟悉Tensorflow和Keras的人，我建议从那里开始尝试一些教程和代码，然后再回到这里。</p><p id="2b30" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">对于那些对深度学习主题完全陌生的人，我肯定会推荐你去看看<a class="ae lw" href="https://www.youtube.com/watch?v=oYbVFhK_olY" rel="noopener ugc nofollow" target="_blank"> Sentdex </a>、<a class="ae lw" href="https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A" rel="noopener ugc nofollow" target="_blank"> Siraj </a>来自<a class="ae lw" href="http://machinelearningmastery.com/blog/" rel="noopener ugc nofollow" target="_blank"> Machine Learning Mastery </a>或<a class="ae lw" href="http://www.deepschool.io" rel="noopener ugc nofollow" target="_blank"> deepschool.io </a>的家伙们的一些不错的Keras教程，然后再回到这里。</p><p id="415d" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在我们开始之前:这里有一些关于我如何为这个教程设置我的工作站的提示。在继续学习本教程之前，请确保您的计算机上已经运行了所有这些程序。安装过程可能需要一些时间，所以请确保你没有和你的另一半计划冲突😉</p><p id="5823" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="la ir">本教程的先决条件:</strong></p><ul class=""><li id="a10a" class="me mf iq la b lb lc lf lg lj mg ln mh lr mi lv mj mk ml mm bi translated"><a class="ae lw" href="https://www.tensorflow.org/install/" rel="noopener ugc nofollow" target="_blank"> Tensorflow(版本1.2.1) </a></li><li id="7f0c" class="me mf iq la b lb mn lf mo lj mp ln mq lr mr lv mj mk ml mm bi translated">Python 2.7</li><li id="d9e3" class="me mf iq la b lb mn lf mo lj mp ln mq lr mr lv mj mk ml mm bi translated"><a class="ae lw" href="https://keras.io" rel="noopener ugc nofollow" target="_blank"> Keras 2(版本2.0.6) </a></li><li id="7893" class="me mf iq la b lb mn lf mo lj mp ln mq lr mr lv mj mk ml mm bi translated"><a class="ae lw" href="https://pypi.python.org/pypi/coremltools" rel="noopener ugc nofollow" target="_blank"> coremltools(版本0.5.1) </a></li><li id="d027" class="me mf iq la b lb mn lf mo lj mp ln mq lr mr lv mj mk ml mm bi translated">MacOS Sierra 10.12.4+</li><li id="dec7" class="me mf iq la b lb mn lf mo lj mp ln mq lr mr lv mj mk ml mm bi translated">Xcode 9 Beta(开发者帐户可用)</li><li id="dcc6" class="me mf iq la b lb mn lf mo lj mp ln mq lr mr lv mj mk ml mm bi translated">iOS 11测试版(如果你想在iPhone上测试，可以选择。模拟器完全足够)</li></ul><h2 id="e7ff" class="ms jo iq bd jp mt mu dn jt mv mw dp jx lj mx my kb ln mz na kf lr nb nc kj nd bi translated">好吧，如果你做到了这一点，有些东西你会很熟悉，这真的很好！</h2><h2 id="7037" class="ms jo iq bd jp mt mu dn jt mv mw dp jx lj mx my kb ln mz na kf lr nb nc kj nd bi translated">KERAS + MNIST数据集</h2><blockquote class="ne"><p id="9ac4" class="nf ng iq bd nh ni nj nk nl nm nn lv dk translated">如何在Keras中加载和训练MNIST数据集？</p></blockquote><p id="69f0" class="pw-post-body-paragraph ky kz iq la b lb no ld le lf np lh li lj nq ll lm ln nr lp lq lr ns lt lu lv ij bi translated">Keras框架已经提供了一个可以下载的MNIST数据集。它包含60，000张手写图像，可用于训练神经网络。请参见MNIST数据集中手写数字的一些示例。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/ffd037522841904fd297f1bd7e59059f.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*UKXLbb40YjviJWerqz3D2Q.png"/></div><figcaption class="nu nv gj gh gi nw nx bd b be z dk">Handwritten Digits from the MNIST dataset</figcaption></figure><p id="d64a" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">您可以自由选择构建您自己的模型，并实现您自己的卷积网络或您在Keras中构建的任何其他网络或模型。但是为了加快速度，<a class="ae lw" href="https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py" rel="noopener ugc nofollow" target="_blank">下载</a>Keras github仓库中的卷积网络mnist示例。这是一个完全可行的例子，可以用来玩和学习。它下载mnist数据集并重塑矩阵，以适应神经网络。我在我的Mac上训练了这个模型，花了将近一个小时，因为我没有安装带GPU支持的TensorFlow。</p><p id="447b" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">如果您下载了<strong class="la ir"> cnn_example_mnist.py </strong>，请确保进行以下更改:</p><h2 id="6a55" class="ms jo iq bd jp mt mu dn jt mv mw dp jx lj mx my kb ln mz na kf lr nb nc kj nd bi translated">1.检查输入形状</h2><p id="7e06" class="pw-post-body-paragraph ky kz iq la b lb ny ld le lf nz lh li lj oa ll lm ln ob lp lq lr oc lt lu lv ij bi translated">数据的<strong class="la ir"> input_shape </strong>应该定义为<strong class="la ir"><em class="ma">channels _ last</em></strong><em class="ma">。</em>这将确保CoreML能够识别模型的输入数据，从而能够将<strong class="la ir"> CIImages </strong>传递给模型。否则你需要知道如何将一个<strong class="la ir"> UIImage </strong>转换成一个<strong class="la ir"> MLMultiarray </strong>来将你的图像传递给模型。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="bfca" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">由于模型将在<strong class="la ir"> 28x28大小的图像</strong>上训练，请记住，我们将在稍后的应用程序代码中采用该大小的图像。</p><h2 id="0d28" class="ms jo iq bd jp mt mu dn jt mv mw dp jx lj mx my kb ln mz na kf lr nb nc kj nd bi translated">2.保存模型</h2><blockquote class="ne"><p id="2d23" class="nf ng iq bd nh ni nj nk nl nm nn lv dk translated">如何在Keras中保存我训练好的mnist模型？</p></blockquote><p id="7033" class="pw-post-body-paragraph ky kz iq la b lb no ld le lf np lh li lj nq ll lm ln nr lp lq lr ns lt lu lv ij bi translated">在您训练您的模型之前，请确保它将在完成训练后自动保存。在代码的最后添加这一行。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="28a5" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">Keras提供这个调用来保存训练好的模型。如果你已经完成了，你就可以运行这个脚本了。它将下载，训练和保存您的新模型在同一个目录中。</p><h2 id="e495" class="ms jo iq bd jp mt mu dn jt mv mw dp jx lj mx my kb ln mz na kf lr nb nc kj nd bi translated">KERAS + coremltools</h2><blockquote class="ne"><p id="70a0" class="nf ng iq bd nh ni nj nk nl nm nn lv dk translated">如何将我训练好的keras .h5模型转换成CoreML？mlmodel？</p></blockquote><p id="1512" class="pw-post-body-paragraph ky kz iq la b lb no ld le lf np lh li lj nq ll lm ln nr lp lq lr ns lt lu lv ij bi translated">幸运的是，苹果支持用Keras构建的机器学习模型。然而，本教程发布时的coremltools版本并不正式支持Keras 2.0.6。但它仍然有效！我面临的唯一问题是将<strong class="la ir">输出_描述</strong>定义为与<strong class="la ir"> <em class="ma">输出1 </em> </strong>不同的东西。</p><blockquote class="lx ly lz"><p id="40dd" class="ky kz ma la b lb lc ld le lf lg lh li mb lk ll lm mc lo lp lq md ls lt lu lv ij bi translated">如果你知道如何解决这个问题，请写在评论中，我会更新代码</p></blockquote><p id="9644" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="la ir">谈论模型的输出:</strong>模型将输出一个<em class="ma">独热数组</em>，其槽数与我们拥有的类数一样多。在iOS中，输出将是一个MLMultiArray，它相当于Numpy数组。</p><p id="efaa" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">复制这段代码并编辑作者字段。coreml_model 使得向模型中添加一些元信息成为可能，这样如果你分享你的模型，那些支持你的模型的人就知道如何使用它。稍后我们将看到这将如何在我们的Xcode项目中显示。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="6fa9" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">如果您在转换由某些字段引起的模型时遇到问题，您也可以省去它们，只使用<strong class="la ir"><em class="ma">coreml _ model . save(' keras _ mnist _ CNN . ml model ')</em></strong></p><blockquote class="lx ly lz"><p id="e51e" class="ky kz ma la b lb lc ld le lf lg lh li mb lk ll lm mc lo lp lq md ls lt lu lv ij bi translated"><strong class="la ir">此时你应该已经转换了。您目录中的mlmodel。如果有，就好好享受，休息一下。</strong></p></blockquote><h2 id="18fd" class="ms jo iq bd jp mt mu dn jt mv mw dp jx lj mx my kb ln mz na kf lr nb nc kj nd bi translated"><strong class="ak">。mlmodel + Xcode </strong></h2><ol class=""><li id="780a" class="me mf iq la b lb ny lf nz lj of ln og lr oh lv oi mk ml mm bi translated">现在开始一个新的Xcode项目，选择<strong class="la ir">单视图应用</strong></li><li id="283c" class="me mf iq la b lb mn lf mo lj mp ln mq lr mr lv oi mk ml mm bi translated">想怎么命名就怎么命名，并确保语言设置为<strong class="la ir">目标-C </strong></li><li id="8c5d" class="me mf iq la b lb mn lf mo lj mp ln mq lr mr lv oi mk ml mm bi translated">现在在你的<strong class="la ir">项目导航器左侧</strong>点击你的项目。在<strong class="la ir"> General </strong>下向下滚动到<strong class="la ir">链接的框架和库。</strong>这是您添加CoreML框架和Vision框架的地方。</li></ol><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi oj"><img src="../Images/bdbee187b32c5c472d1a94dc0a8157e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sgca-qBeg7u3h3XcOgc2Jw.png"/></div></div></figure><p id="918b" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">4.点击<strong class="la ir"> cmd+b </strong>来测试你的项目是否设置正确，是否可以正确构建。如果成功，只需拖动新创建的。mlmodel到项目中。Xcode 9能够将其识别为mlmodel。如果您在项目导航器中单击它，它将如下所示:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ok"><img src="../Images/5ccd5372aacb2f1a133655a7093d72ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m8U5WbaMt2XqIh9z-YrlEA.png"/></div></div></figure><p id="6b5e" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">看到我们在coremltools脚本中传递的信息了吗？很酷吧？</p><p id="f279" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="la ir">注意:如果您的Xcode无法识别型号，并向您显示类似这张图片的内容，那么您可能没有使用Xcode 9 </strong></p><p id="af87" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">如果你的模型的输入是一个多阵列而不是一个图像，那么你应该仔细检查你的模型的输入形状是否真的被设置到<strong class="la ir">通道最后</strong>，如上所述<strong class="la ir">。</strong></p><p id="bf96" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">您还应该确保在转换脚本中正确初始化了coremlmodel，并正确设置了<strong class="la ir"> input_names=['image'] </strong>和<strong class="la ir">image _ input _ names = ' image '</strong>。</p><p id="860d" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">Xcode应该自动生成mlmodel的Objective-C模型类。如果不是:</p><blockquote class="ne"><p id="fc51" class="nf ng iq bd nh ni nj nk nl nm nn lv dk translated">为什么Xcode没有生成我的Objective-C模型类？</p></blockquote><p id="2408" class="pw-post-body-paragraph ky kz iq la b lb no ld le lf np lh li lj nq ll lm ln nr lp lq lr ns lt lu lv ij bi translated">我还不知道，可能是个bug。但是要修复它，只需点击右边的复选框，将模型添加到目标中。这将触发构建过程并生成模型类。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/364ac8144922f72282f9a77e1a72c53b.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*ftXCZsJ0aZFEn45N_uUL1w.png"/></div></figure><h2 id="9100" class="ms jo iq bd jp mt mu dn jt mv mw dp jx lj mx my kb ln mz na kf lr nb nc kj nd bi translated">绘图应用程序</h2><p id="7cb5" class="pw-post-body-paragraph ky kz iq la b lb ny ld le lf nz lh li lj oa ll lm ln ob lp lq lr oc lt lu lv ij bi translated">你可以选择<a class="ae lw" href="https://github.com/boaerosuke/digitrecognition_ios" rel="noopener ugc nofollow" target="_blank">在github </a>上下载我的代码，然后摆弄这些代码，或者参考位于raywenderlich.com<a class="ae lw" href="https://www.raywenderlich.com/18840/how-to-make-a-simple-drawing-app-with-uikit" rel="noopener ugc nofollow" target="_blank">的旧的黄金绘图应用教程，然后完全自己构建它(这是我一直推荐的)。</a></p><p id="5988" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在这一点上，你应该通过检查我的代码或自己构建应用程序来理解如何用手指在嵌入在UIImageView中的UIImage上书写。</p><h2 id="8482" class="ms jo iq bd jp mt mu dn jt mv mw dp jx lj mx my kb ln mz na kf lr nb nc kj nd bi translated"><strong class="ak">图像预测</strong></h2><p id="0abb" class="pw-post-body-paragraph ky kz iq la b lb ny ld le lf nz lh li lj oa ll lm ln ob lp lq lr oc lt lu lv ij bi translated">对于下一步，我们首先从清单开始:</p><ul class=""><li id="acf6" class="me mf iq la b lb lc lf lg lj mg ln mh lr mi lv mj mk ml mm bi translated">您已经在Xcode项目中正确设置了模型</li><li id="1385" class="me mf iq la b lb mn lf mo lj mp ln mq lr mr lv mj mk ml mm bi translated">模型输入是28x28灰度图像</li><li id="3ed4" class="me mf iq la b lb mn lf mo lj mp ln mq lr mr lv mj mk ml mm bi translated">模型输出是一个大小为10倍的多阵列</li><li id="bf34" class="me mf iq la b lb mn lf mo lj mp ln mq lr mr lv mj mk ml mm bi translated">如上所述，您已经将CoreML框架和Vision框架导入到您的项目中</li><li id="e9b9" class="me mf iq la b lb mn lf mo lj mp ln mq lr mr lv mj mk ml mm bi translated">您有一个UIImageView，可以用手指在上面进行绘制</li></ul><p id="4522" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><strong class="la ir">预测过程如下:</strong>导入<strong class="la ir"> CoreML.h </strong>和<strong class="la ir"> Vision.h </strong>的头文件以及自动生成的模型类的头文件:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="e493" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">当我测试应用程序时，我发现如果我们在将图像传递到视觉框架之前，自己将图像缩小到28x28，我们会获得更好的预测结果。尽管框架会自动为我们进行缩放。您可以使用这个助手方法无缝地将UIImage缩放到所需的大小:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="a36a" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在我们缩放了<strong class="la ir"> UIImage </strong>之后，它需要被转换成<strong class="la ir"> CIImage </strong>这是我们需要的格式，以便将其传递给视觉框架。</p><p id="76a4" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">在缩放和转换图像之后，我们使用<strong class="la ir"> MLModel </strong>类来初始化我们自己创建的模型，作为它的<strong class="la ir"> MLModel </strong>版本。这将被传递给我们的<strong class="la ir"> VNCoreMLModel </strong>，它将被Vision框架使用。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="9d09" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">既然我们已经创建了图像和模型，我们需要构建预测请求。我们将使用<strong class="la ir"> VNCoreMLRequest </strong>并用我们新构建的<strong class="la ir"> VNCoreMLModel </strong>初始化它。该请求用completition handler初始化，该处理器接收我们的深度学习模型的预测结果。</p><p id="4366" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在棘手的是:</p><blockquote class="ne"><p id="471f" class="nf ng iq bd nh ni nj nk nl nm nn lv dk translated">如何从CoreML Vision framework获得一个热门的多阵列预测结果？</p></blockquote><p id="da91" class="pw-post-body-paragraph ky kz iq la b lb no ld le lf np lh li lj nq ll lm ln nr lp lq lr ns lt lu lv ij bi translated">当任务完成时，completition处理程序中的<strong class="la ir"> VNRequest </strong>在其<em class="ma">结果数组</em>属性中携带结果。在大多数情况下，数组中的每个结果都是所谓的<strong class="la ir">VNCoreMLFeatureValueObservation。这就是我们要找的东西。这个观察类包含一个<strong class="la ir"> MLFeature </strong>，我们可以通过观察<em class="ma"> featureValue </em>属性检索它。而那个<em class="ma">特征值</em>的<strong class="la ir">多数组值</strong>就是我们想要的10长度双多数组输出1。</strong></p><p id="c599" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated"><em class="ma">瞧！</em>🎉</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="4538" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">由于在我们的多阵列中有10个从0到9的神经元，与其他神经元相比，激发最多的神经元也具有最高的double值。该神经元在多阵列中的位置表示模型预测的数量。因此，如果最高值在索引8处，则预测数也是8，以此类推。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi om"><img src="../Images/36309021cb2d97732b7b1f3aeeeaf9bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E0ll9BTfHI1D9fUcG_T7bA.png"/></div></div><figcaption class="nu nv gj gh gi nw nx bd b be z dk">One-Hot Array Values</figcaption></figure><p id="33f0" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在，我们已经准备好了请求，也知道了如何获得结果，我们已经准备好了图像，我们可以组合所有内容并开始执行请求。</p><p id="d1ee" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们初始化一个<strong class="la ir"> VNImageRequestHandler </strong>，它接受我们之前创建的<strong class="la ir"> CIImage </strong>和一个包含图像选项的字典(我创建字典是为了将它传递给处理程序，但将它留空，因为我认为这里不需要选项)。</p><p id="1199" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">我们现在可以在新创建的请求处理器上调用<em class="ma"> performRequests </em>,并将放入数组中的请求传递给它。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="a4cf" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">就是这样！VNImageHandler将启动请求并调用completition处理程序，让我们知道我们的模型在想什么。</p><h2 id="fe74" class="ms jo iq bd jp mt mu dn jt mv mw dp jx lj mx my kb ln mz na kf lr nb nc kj nd bi translated">下面是完整的predictDigit方法:</h2><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="od oe l"/></div></figure><p id="6aa3" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">现在，如果我们测试应用程序，它可能会检测到至少一些我们在屏幕上绘制的数字，但不是所有的数字。请随意改进模型或使用更好的模型。请在评论中告诉我们。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi on"><img src="../Images/d5c525166af2c68e4c78029d235cd2d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*85o8rJYctX2iTCx34wiyig.png"/></div></figure><p id="1d0a" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">为了测试问题，我添加了原始mnist数据集的两个图像。它们总是被正确预测。</p><blockquote class="ne"><p id="aec3" class="nf ng iq bd nh ni nj nk nl nm nn lv dk translated">为什么要用黑色背景和白色来画画？</p></blockquote><p id="d6b8" class="pw-post-body-paragraph ky kz iq la b lb no ld le lf np lh li lj nq ll lm ln nr lp lq lr ns lt lu lv ij bi translated">这纯粹是为了改进预测。mnist数据集主要是深色背景上的白色数字。即使输入图像被转换成灰度，我们对训练集的输入越熟悉，得到的结果就越好。但是，如果我们只是在另一个训练集上训练我们的模型，使它独立于颜色，这可以得到改善。但就目前而言，我认为在iOS上尝试深度学习是一个良好的开端。</p><h1 id="e725" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">下一步是什么？</h1><p id="3f28" class="pw-post-body-paragraph ky kz iq la b lb ny ld le lf nz lh li lj oa ll lm ln ob lp lq lr oc lt lu lv ij bi translated">尝试示例应用程序。使用Keras构建您自己的模型，并将其传递给示例应用程序。你现在已经有了解决几个机器学习问题的工具。关于核心ML的更多信息和一个将<strong class="la ir"> caffemodel </strong>集成到iOS的例子，我强烈推荐<a class="ae lw" href="https://medium.com/towards-data-science/introduction-to-core-ml-conversion-tool-d1466bf10018" rel="noopener">gal Foppolo</a>的教程。</p><p id="cfb4" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv ij bi translated">另一个类似的项目可以在<a class="ae lw" href="https://github.com/hwchong/MNIST_DRAW" rel="noopener ugc nofollow" target="_blank">这里</a>找到。这个程序使用从UIImage到MLMultiarray的转换作为输入，并使用这里的相同模型接收可比较的结果，所以也去看看这个程序吧！</p><h2 id="d329" class="ms jo iq bd jp mt mu dn jt mv mw dp jx lj mx my kb ln mz na kf lr nb nc kj nd bi translated">希望这篇教程对iOS上刚接触深度学习和神经网络的人有所帮助。现在继续制作你自己的机器学习应用程序吧！</h2><div class="oo op gp gr oq or"><a href="https://github.com/boaerosuke/digitrecognition_ios" rel="noopener  ugc nofollow" target="_blank"><div class="os ab fo"><div class="ot ab ou cl cj ov"><h2 class="bd ir gy z fp ow fr fs ox fu fw ip bi translated">boaerosuke/digitre cognition _ IOs</h2><div class="oy l"><h3 class="bd b gy z fp ow fr fs ox fu fw dk translated">digitrecognition_ios -使用Tensorflow/Keras的深度学习:基于mnist-dataset和卷积的数字识别…</h3></div><div class="oz l"><p class="bd b dl z fp ow fr fs ox fu fw dk translated">github.com</p></div></div><div class="pa l"><div class="pb l pc pd pe pa pf kw or"/></div></div></a></div></div></div>    
</body>
</html>