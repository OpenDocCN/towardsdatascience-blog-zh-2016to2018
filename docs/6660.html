<html>
<head>
<title>Introduction to Data Preprocessing in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的数据预处理导论</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d?source=collection_archive---------0-----------------------#2018-12-25">https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d?source=collection_archive---------0-----------------------#2018-12-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1fff" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">数据预处理初学者指南</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/6f272e12b1fc81925cb74545c18c5365.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zZ_rpah3i7xBNKkt84GZUQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@markusspiske?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Markus Spiske</a> on <a class="ae kv" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="2918" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">数据预处理是机器学习中不可或缺的一步，因为数据的质量和从中获得的有用信息会直接影响模型的学习能力；因此，在将数据输入模型之前，对数据进行预处理是非常重要的。</p><p id="2cbe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我将在本文中介绍的概念是-</p><ol class=""><li id="8371" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">处理空值</li><li id="8869" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">标准化</li><li id="41bf" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">处理分类变量</li><li id="5162" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">一键编码</li><li id="2e55" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">多重共线性</li></ol><p id="4258" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以获得完整的代码(。ipynb) <a class="ae kv" href="https://github.com/Dhairya10/Medium_Data_Preprocessing" rel="noopener ugc nofollow" target="_blank">这里</a></p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="2572" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">处理空值—</h1><p id="87e5" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">在任何真实世界的数据集中，总是很少有空值。无论是回归、分类还是任何其他类型的问题，都没有关系，没有模型能够独自处理这些 NULL 或 NaN 值，因此我们需要干预。</p><blockquote class="nk"><p id="039a" class="nl nm iq bd nn no np nq nr ns nt lr dk translated">在 python 中，NULL 用 NaN 表示。所以不要混淆这两者，它们可以互换使用。</p></blockquote><p id="9727" class="pw-post-body-paragraph kw kx iq ky b kz nu jr lb lc nv ju le lf nw lh li lj nx ll lm ln ny lp lq lr ij bi translated">首先，我们需要检查我们的数据集中是否有空值。我们可以使用 isnull()方法来实现。</p><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="2da4" class="oe mo iq oa b gy of og l oh oi">df.isnull()      <br/># Returns a boolean matrix, if the value is NaN then True otherwise False</span><span id="312d" class="oe mo iq oa b gy oj og l oh oi">df.isnull().sum() <br/># Returns the column names along with the number of NaN values in that particular column</span></pre><p id="a20e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们有各种方法来处理这个问题。解决这个问题最简单的方法是删除包含空值的行或列。</p><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="8a9c" class="oe mo iq oa b gy of og l oh oi">df.dropna()</span></pre><p id="de87" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">dropna()接受各种参数，比如—</p><ol class=""><li id="9bb0" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">axis —如果要删除行，我们可以指定 axis = 0；如果要删除列，我们可以指定 axis=1。</li><li id="6d66" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">how —如果我们指定 how = 'all ',那么只有当所有值都是 NaN 时，才会删除行和列。默认情况下，how 设置为“any”。</li><li id="8905" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">thresh——它确定阈值，因此如果我们指定 thresh=5，那么具有少于 5 个实数值的行将被丢弃。</li><li id="598e" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">subset-如果我们有 4 列 A、B、C 和 D，那么如果我们指定 subset=['C']，那么只有 C 值为 NaN 的行将被删除。</li><li id="8544" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">就地-默认情况下，不会对数据框进行任何更改。因此，如果您希望这些更改反映到您的数据帧中，那么您需要使用 inplace = True。</li></ol><p id="7dca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是，从数据集中删除行和列并不是最佳选择，因为这会导致大量信息丢失。如果您有 300，000 个数据点，那么删除 2-3 行不会对您的数据集产生太大影响，但是如果您只有 100 个数据点，并且其中 20 个数据点对于特定字段具有 NaN 值，那么您不能简单地删除这些行。在现实世界的数据集中，某个特定字段有大量 NaN 值的情况经常发生。</p><p id="966c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，假设我们从调查中收集数据，那么可能会有一个可选字段，假设 20%的人留为空白。因此，当我们获得数据集时，我们需要了解剩余的 80%的数据仍然是有用的，因此，与其丢弃这些值，我们需要以某种方式替换缺失的 20%的值。我们可以在<strong class="ky ir">插补的帮助下做到这一点。</strong></p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h2 id="4942" class="oe mo iq bd mp ok ol dn mt om on dp mx lf oo op mz lj oq or nb ln os ot nd ou bi translated">插补—</h2><p id="2e0c" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">插补就是简单地替换我们数据集缺失值的过程。我们可以通过定义我们自己的定制函数来实现这一点，或者我们可以通过使用 sklearn 提供的<strong class="ky ir">simple imputr</strong>类来简单地执行插补。</p><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="0636" class="oe mo iq oa b gy of og l oh oi">from sklearn.impute import SimpleImputer<br/>imputer = SimpleImputer(missing_values=np.nan, strategy='mean')<br/>imputer = imputer.fit(df[['Weight']])<br/>df['Weight'] = imputer.transform(df[['Weight']])</span></pre><p id="2dd9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">。这里使用的值</strong>返回数据帧的 numpy 表示。<br/>仅返回数据框中的值，轴标签将被移除。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="9cbe" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">标准化—</h1><p id="a601" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">这是另一个完整的预处理步骤。在标准化中，我们转换我们的值，使平均值为 0，标准差为 1。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/84ba38e34be9d5e08ec8bf71a894308e.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/1*Bqb-yfE-VNLhBQTee0Xa3g.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ow">Image by author</em></figcaption></figure><p id="76f4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">考虑上面的数据帧，这里我们有 2 个数值:<strong class="ky ir">年龄</strong>和<strong class="ky ir">体重</strong>。因为年龄是以年为单位，体重是以公斤为单位，所以它们不在一个等级上，因为体重更有可能大于年龄；因此，我们的模型将赋予权重更多的权重，这不是理想的情况，因为年龄也是一个不可或缺的因素。为了避免这个问题，我们执行标准化。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/980d852d929155388b138f7911e3377d.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*qwpzqVh-PVENHa6q1qZ8kQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ow">Image by author</em></figcaption></figure><p id="19d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">简单来说，我们只需计算这些值的平均值和标准差，然后对于每个数据点，我们只需减去平均值，然后除以标准差。</p><p id="75b4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">示例— </strong></p><p id="f42a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">考虑数据帧 1 中的列年龄。为了标准化该列，我们需要计算平均值和标准偏差，然后我们将使用上述公式转换每个年龄值。</p><p id="23b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们不需要手动完成这个过程，因为 sklearn 提供了一个名为<strong class="ky ir"> StandardScaler 的函数。</strong></p><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="c537" class="oe mo iq oa b gy of og l oh oi">from sklearn.preprocessing import StandardScaler<br/>std = StandardScaler()<br/>X = std.fit_transform(df[['Age','Weight']])</span></pre><p id="709a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里需要注意的重要一点是，我们需要标准化训练和测试数据。</p><ul class=""><li id="3c34" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr oy ly lz ma bi translated">fit_transform 相当于先使用 fit，再使用 transform。</li><li id="2733" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr oy ly lz ma bi translated">fit 函数计算平均值和标准差，transform 函数实际上标准化数据集，我们可以使用 fit_transform 函数在一行代码中完成此过程。</li></ul><blockquote class="oz pa pb"><p id="27d2" class="kw kx pc ky b kz la jr lb lc ld ju le pd lg lh li pe lk ll lm pf lo lp lq lr ij bi translated">这里要注意的另一件重要的事情是，当处理测试数据时，我们将只使用 transform 方法。</p></blockquote></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="2203" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">处理分类变量—</h1><p id="392e" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">处理分类变量是机器学习的另一个重要方面。分类变量基本上是离散而非连续的变量。例如，商品的颜色是一个离散变量，而价格是一个连续变量。</p><p id="97ae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">分类变量进一步分为两种类型—</p><ul class=""><li id="762c" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr oy ly lz ma bi translated"><strong class="ky ir">有序分类变量</strong> —这些变量可以排序。ex——T 恤衫的尺寸。我们可以说 M &lt; L &lt; XL。</li><li id="3d3e" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr oy ly lz ma bi translated"><strong class="ky ir">名义分类变量</strong> —这些变量不能排序。前——t 恤的颜色。我们不能说蓝色是绿色，因为比较这两种颜色没有任何意义，因为它们没有任何关系。</li></ul><blockquote class="nk"><p id="89e4" class="nl nm iq bd nn no pg ph pi pj pk lr dk translated"><strong class="ak">这里需要注意的重要一点是，我们需要不同地预处理序数和名词性分类变量。</strong></p></blockquote></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h2 id="e7a0" class="oe mo iq bd mp ok ol dn mt om on dp mx lf oo op mz lj oq or nb ln os ot nd ou bi translated"><strong class="ak">处理有序分类变量— </strong></h2><p id="c99e" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">首先，我们需要创建一个数据框架。</p><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="b09c" class="oe mo iq oa b gy of og l oh oi">df_cat = pd.DataFrame(data = <br/>                     [['green','M',10.1,'class1'],<br/>                      ['blue','L',20.1,'class2'],<br/>                      ['white','M',30.1,'class1']])<br/>df_cat.columns = ['color','size','price','classlabel']</span></pre><p id="f1c8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，列“size”和“classlabel”是顺序分类变量，而“color”是名义分类变量。</p><p id="55db" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有两个非常简单和整洁的技术来转换顺序 cv。</p><ol class=""><li id="4618" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">使用 map()函数—</li></ol><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="79e3" class="oe mo iq oa b gy of og l oh oi">size_mapping = {'M':1,'L':2}<br/>df_cat['size'] = df_cat['size'].map(size_mapping)</span></pre><p id="d88f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里 M 将用 1 代替，L 用 2 代替。</p><p id="d0e7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">2.使用标签编码器—</p><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="6be3" class="oe mo iq oa b gy of og l oh oi">from sklearn.preprocessing import LabelEncoder<br/>class_le = LabelEncoder()<br/>df_cat['classlabel'] =<br/>class_le.fit_transform(df_cat['classlabel'].values)</span></pre><p id="4364" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里，class1 用 0 表示，class2 用 1 表示。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h2 id="e343" class="oe mo iq bd mp ok ol dn mt om on dp mx lf oo op mz lj oq or nb ln os ot nd ou bi translated"><strong class="ak">处理名词性分类变量的方式不正确— </strong></h2><p id="1743" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">大多数人犯的<strong class="ky ir">最大错误</strong>是他们无法区分序数型和名义型简历。因此，如果您对名义变量使用相同的 map()函数或 LabelEncoder，那么模型将认为名义变量之间存在某种关系。</p><p id="11c4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以如果我们使用 map()来映射颜色，就像-</p><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="4441" class="oe mo iq oa b gy of og l oh oi">col_mapping = {'Blue':1,'Green':2}</span></pre><p id="be30" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后根据模型，绿色&gt;蓝色，这是一个毫无意义的假设，模型会给出考虑这种关系的结果。所以，虽然你会用这种方法得到结果，但它们不会是最佳的。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h2 id="61f2" class="oe mo iq bd mp ok ol dn mt om on dp mx lf oo op mz lj oq or nb ln os ot nd ou bi translated"><strong class="ak">处理名义分类变量的正确方法— </strong></h2><p id="90e1" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">处理名义 cv 的正确方法是使用一键编码。使用独热编码最简单的方法是使用 get_dummies()函数。</p><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="d4c3" class="oe mo iq oa b gy of og l oh oi">df_cat = pd.get_dummies(df_cat[['color','size','price']])</span></pre><p id="2844" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这里，我们传递了“size”和“price”以及“color ”,但是 get_dummies()函数非常聪明，它将只考虑字符串变量。所以它只是转换“颜色”变量。</p><p id="c116" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，你一定想知道这到底是什么一次性编码。所以让我们试着去理解它。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="8c30" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">一键编码—</h1><p id="08a1" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">因此，在一键编码中，我们主要做的是创建“n”列，其中 n 是名义变量可以接受的唯一值的数量。</p><p id="5c9d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如，在这里，如果颜色可以是蓝色、绿色和白色，那么我们将只创建三个新列，即颜色 _ 蓝色、颜色 _ 绿色和颜色 _ 白色，如果颜色是绿色，那么颜色 _ 蓝色和颜色 _ 白色列的值将是 0，颜色 _ 绿色列的值将是 1。</p><p id="8ead" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，在 n 列中，只有一列的值为 1，其余的列的值都为 0。</p><p id="f3e4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一键编码是一个非常酷和简洁的技术，但是只有一个问题与之相关，那就是多重共线性。因为你们一定都认为这是一个相当沉重的词，所以一定很难理解，所以让我来验证一下你们新形成的信念。多重共线性确实是一个有点棘手但极其重要的统计学概念。这里的好处是，我们不需要真正理解多重共线性的所有本质细节，我们只需要关注它将如何影响我们的模型。因此，让我们深入了解多重共线性的概念，以及它将如何影响我们的模型。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="97bf" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated"><strong class="ak">多重共线性及其影响— </strong></h1><p id="d933" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">当我们的数据集中存在彼此高度依赖的要素时，就会出现多重共线性。在这种情况下，我们有一些特征-</p><p id="c715" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">color_blue，color_green 和 color_white，这些都是相互依赖的，并且会影响我们的模型。</p><blockquote class="nk"><p id="ba06" class="nl nm iq bd nn no np nq nr ns nt lr dk translated">如果数据集存在多重共线性，则无法使用权重向量来计算特征重要性。</p><p id="90ba" class="nl nm iq bd nn no np nq nr ns nt lr dk translated">多重共线性会影响我们模型的可解释性。</p></blockquote><p id="8e28" class="pw-post-body-paragraph kw kx iq ky b kz nu jr lb lc nv ju le lf nw lh li lj nx ll lm ln ny lp lq lr ij bi translated">我认为，在机器学习的背景下，这些信息已经足够了。但是，如果您仍然不相信，您可以访问下面的链接，了解与多重共线性相关的数学和逻辑。</p><div class="pl pm gp gr pn po"><a href="https://newonlinecourses.science.psu.edu/stat501/node/344/" rel="noopener  ugc nofollow" target="_blank"><div class="pp ab fo"><div class="pq ab pr cl cj ps"><h2 class="bd ir gy z fp pt fr fs pu fu fw ip bi translated">12.1 -什么是多重共线性？| STAT 501</h2><div class="pv l"><h3 class="bd b gy z fp pt fr fs pu fu fw dk translated">如课程概述中所述，只要回归模型中有两个或多个预测因子，就存在多重共线性…</h3></div><div class="pw l"><p class="bd b dl z fp pt fr fs pu fu fw dk translated">newonlinecourses.science.psu.edu</p></div></div><div class="px l"><div class="py l pz qa qb px qc kp po"/></div></div></a></div><p id="f23f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，我们已经了解了多重共线性的含义，接下来让我们尝试了解如何识别它。</p><ul class=""><li id="520f" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr oy ly lz ma bi translated">识别多重共线性的最简单方法是绘制一对图，您可以观察不同要素之间的关系。如果两个要素之间存在线性关系，则它们之间存在强相关性，并且数据集中存在多重共线性。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi qd"><img src="../Images/802a65bbb5b0a2dc4f3eac5b9723ad4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*c3Qc9uds4Nofk1NEw8aIng.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ow">Image by author</em></figcaption></figure><p id="f69c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此处(体重，BP)与(BSA，BP)密切相关。您也可以使用相关矩阵来检查特征的紧密相关性。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi qe"><img src="../Images/0135b4bba26f965bef9e118a3e890624.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*3Tt8Ja8NHo-hu_3Wh201hw.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk"><em class="ow">Image by author</em></figcaption></figure><p id="2a6d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以观察到，体重与 BP、BSA 与 BP 之间存在很强的协整关系(0.950)(0.875)。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h2 id="f3b6" class="oe mo iq bd mp ok ol dn mt om on dp mx lf oo op mz lj oq or nb ln os ot nd ou bi translated">避免多重共线性的简单技巧-</h2><p id="547e" class="pw-post-body-paragraph kw kx iq ky b kz nf jr lb lc ng ju le lf nh lh li lj ni ll lm ln nj lp lq lr ij bi translated">我们可以使用 drop_first=True 来避免多重共线性问题。</p><pre class="kg kh ki kj gt nz oa ob oc aw od bi"><span id="1f60" class="oe mo iq oa b gy of og l oh oi">df_cat = pd.get_dummies(df_cat[['color','size','price']],drop_first=True)</span></pre><p id="89a9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里 drop_first 将删除第一列颜色。所以这里蓝色将被去掉，我们只有绿色和白色。</p><p id="09c9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里需要注意的重要一点是，我们不会丢失任何信息，因为如果 color_green 和 color_white 都是 0，那么这意味着颜色一定是蓝色的。因此，我们只能借助这两栏来推断全部信息，因此这三栏之间的强相关性被打破了。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="5ced" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">说完这些，我们就到了本文的结尾。非常感谢你阅读它。</p><p id="f8fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以获得完整的代码()。ipynb) <a class="ae kv" href="https://github.com/Dhairya10/Medium_Data_Preprocessing" rel="noopener ugc nofollow" target="_blank">此处为</a></p><p id="9609" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你愿意，你可以鼓掌。这是免费的。</p><p id="e1a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我的<a class="ae kv" href="https://www.linkedin.com/in/dhairya-kumar/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>、<a class="ae kv" href="https://twitter.com/DhairyaKumar16" rel="noopener ugc nofollow" target="_blank"> Twitter </a>和<a class="ae kv" href="https://github.com/Dhairya10" rel="noopener ugc nofollow" target="_blank"> Github </a> <br/>你可以登陆我的<a class="ae kv" href="https://alpha-dev.in/" rel="noopener ugc nofollow" target="_blank">网站</a>了解更多关于我和我的工作。</p></div></div>    
</body>
</html>