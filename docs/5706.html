<html>
<head>
<title>An Introduction to Bayesian Inference a mathematical venture</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯推理导论数学冒险</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-introduction-to-bayesian-inference-a-mathematical-venture-9919a2937f28?source=collection_archive---------8-----------------------#2018-11-04">https://towardsdatascience.com/an-introduction-to-bayesian-inference-a-mathematical-venture-9919a2937f28?source=collection_archive---------8-----------------------#2018-11-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="792a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">嗨，这是我的第一篇博客文章，所以如果我在写文章时犯了任何错误或错过了任何惯例，请在评论中告诉我。(关于内容的礼貌反馈总是被邀请的:)。</p><p id="8b9a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi kl translated"><span class="l km kn ko bm kp kq kr ks kt di">在</span>统计领域，统计学家和数据科学家采用了两种著名的方法来解决现实世界的预测问题，这两种方法被称为频率主义方法和贝叶斯方法。</p><p id="c05c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">黄金贝叶斯法则告诉我们:</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="ab gu cl kz"><img src="../Images/d9651112816a81aaa6a18604517af4e6.png" data-original-src="https://miro.medium.com/v2/0*paAsAT9UvBwSDVfQ"/></div></figure><p id="4a72" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中 W 是统计模型的参数，该模型对数据 d 后面的分布进行建模。基于相同的表示，让我们来定义什么是频率主义者和贝叶斯方法？</p><p id="516e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">频率主义方法是一种统计学家认为存在一个参数的真实值，概率是根据频率来定义的方法。遵循贝叶斯方法的统计学家认为，参数没有真实值，但参数本身遵循特定的分布，只有数据是真实的。</p><p id="957c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我们将关注线性回归的贝叶斯版本。那么，现在让我们正确定义贝叶斯推理。</p><p id="90b0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">贝叶斯推断是一种方法，其中我们定义了具有某种分布的某些参数的先验。这种分布可以认为相当于我们手中已有的问题知识。使用与我们的问题相关的数据进一步更新该分布，这导致了称为后验分布的新分布。后验分布是我们对问题的先验知识和来自数据集的数据的组合。</p><p id="e597" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是，当大多数人都在使用频率主义方法时，我们为什么还需要贝叶斯方法呢？这个问题的答案如下:</p><ol class=""><li id="7835" class="lc ld iq jp b jq jr ju jv jy le kc lf kg lg kk lh li lj lk bi translated">让我们定义一个参数θ的先验，我们想要计算<em class="ll"> P( 99 &lt; θ &lt; 100) </em>这只能在贝叶斯方法的情况下计算，因为频率主义方法给我们一个点估计。</li><li id="7feb" class="lc ld iq jp b jq lm ju ln jy lo kc lp kg lq kk lh li lj lk bi translated">与频率主义方法相比，贝叶斯方法提供了更多的概括。</li><li id="7600" class="lc ld iq jp b jq lm ju ln jy lo kc lp kg lq kk lh li lj lk bi translated">贝叶斯方法避免了过度拟合。</li></ol><p id="1e4c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">等等，那我们为什么不用贝叶斯？，让我们先了解一下贝叶斯方法的缺点。</p><ol class=""><li id="79fe" class="lc ld iq jp b jq jr ju jv jy le kc lf kg lg kk lh li lj lk bi translated">我们必须假设一个先验，这可能是一个非常费力的过程，因为我们假设的分布可能不接近原始分布。这导致后验估计的扰动。</li><li id="128a" class="lc ld iq jp b jq lm ju ln jy lo kc lp kg lq kk lh li lj lk bi translated">在一些甚至大多数情况下，后验概率的计算是难以处理的(这是其不受欢迎的主要原因之一)</li></ol><p id="9272" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在让我们推导出我们最喜欢的线性回归的贝叶斯版本。</p><p id="f2e5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们先设置问题:</p><p id="8f14" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">等式 1 表示可观察到的数据集为<em class="ll"> xᵢ </em>和<em class="ll"> yᵢ.</em></p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/046380908ca54ecbf44d42480650a017.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/0*HAsh5tm5uCz7RoQ-"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 1</figcaption></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/c7092f4350274b290d359c844474fa3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:232/0*32Om7JLL3V2Dlnd1"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 2</figcaption></figure><p id="01c6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果<em class="ll"> W </em>代表回归模型的权重，而<em class="ll"> Y₁、Y₂,…、Yₙ </em>是由参数 w 给出的独立随机变量，则 Yᵢ可以定义为:</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/6c9616afb719f8ad8c2e19dce47ad5a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:290/0*zVG-TzW4kCcF32ZN"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 3. Description of Random Variable Y.</figcaption></figure><p id="0fa1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的权重(参数)的先验分布由下式给出:</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/4f13f6a1fa2d5181116f421585079794.png" data-original-src="https://miro.medium.com/v2/resize:fit:208/0*m4e8-8SjSgzEfG_i"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 4. Description of the distribution of W.</figcaption></figure><p id="5611" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中<em class="ll"> C </em>是协方差矩阵，因为 w 是多元高斯，因为 Xᵢ是<em class="ll"> d </em>维的。</p><p id="a202" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们希望每个维度上的权重相互正交，因此我们可以将其定义为 b⁻ I，其中 b 是多元精度矩阵。精度只不过是方差的倒数和 b &gt; 0。</p><p id="d73a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，我们的权重遵循以下分布:</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/99c5886fdc1c049c4347e1fff40eed8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:248/0*bxN-jJJCuqZZG5mP"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 5. Refined notation for distribution of W</figcaption></figure><p id="2b7a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">类似地，我们也可以精确地表示 Y 的分布:</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/e4a3c37a4013569f540aa565195fd9ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:306/0*b_d1GKY4OZhaEM_t"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 6. Refined notation for distribution of Y</figcaption></figure><p id="442c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中 a⁻ = σ</p><p id="5822" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在贝叶斯推理中，我们估计后验分布 P(W/D ),它由下式给出:</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="ab gu cl kz"><img src="../Images/d9651112816a81aaa6a18604517af4e6.png" data-original-src="https://miro.medium.com/v2/0*paAsAT9UvBwSDVfQ"/></div></figure><p id="a510" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在哪里</p><p id="6618" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">P(D/W)是可能性。</p><p id="e5eb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">P(W)是先验分布。</p><p id="d374" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">P(D)就是证据。</p><p id="2101" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在首先让我们计算最大似然估计(MLE 实际上是一种解决线性回归的常用方法，因为它假设参数有一个给定的真值) :</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/4d9e835293c9cd614c6bbc27fcffe3c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:416/0*kLv-heezxY1nerue"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 7. Computation of MLE estimate of the weights</figcaption></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/186db02e137a5d1e8cd6977a775f5aed.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/0*EeozJiyMyt5on_ZB"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 8.</figcaption></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi md"><img src="../Images/f1cdcb45aed7f3a7797cff7c35f1f2ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/0*rEbr95_3Q2q7hzHN"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 9.</figcaption></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi me"><img src="../Images/d1e30917a8eea584c4916a5624d9bee1.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/0*LsCvFqoULXtTteNY"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 10.</figcaption></figure><p id="1c6e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，如果我们将所有项相乘，那么我们可以将乘积转换为指数幂的和，这将更容易处理。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/1977e41a284b1d55bf52f871831709f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/0*CTsBBK-iDRai0J0o"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 11</figcaption></figure><p id="3c7f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们现在将把它转换成矢量化符号，因为这样更容易计算梯度。考虑以下变化:</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/89315268d7703369ff9e53846f898dc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:140/0*4WVxKYmC0IPO5keD"/></div></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/e0101578d28b91663c2b96972dacc0d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:144/0*kPoJ3-umIJN1In6i"/></div></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/fcacff6dffb1430b73c1dd936f6279f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/0*U0m0Z70xHAps9pBb"/></div></figure><p id="dedb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，等式 11 中的求和变为:</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/b3ddf41cedb047168dfe199b835cb4ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/0*05O_l0sf3zBY44q1"/></div></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/a002e14b3444a606b28d38037bc39b7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:388/0*3GNgl-N3CeNT2zJY"/></div></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/5885c60c9768b06d90c6e702253a63cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:464/0*60tgFaWBbUPLpdVp"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 12</figcaption></figure><p id="d293" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了估计等式 12 的最大值，需要找到它对变量 w 的导数。通过最小化ϕ.可以获得相同的结果现在我们来计算ϕ对 w 的导数</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/49d435e5e3180f3d279c400fb50d53ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:246/0*0HefygH67WCEjq4N"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 13</figcaption></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/990b1aea8939e68c670fc78484160a6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/0*CkNFFDRAeAAseZ1U"/></div></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/24197f44a6f681d7dc0e1a57b11b8034.png" data-original-src="https://miro.medium.com/v2/resize:fit:390/0*c9d334z6-qVer1Sq"/></div></figure><p id="97fb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">∇ϕ称为梯度向量，它包含 w 的每一维的偏导数</p><p id="6e69" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我们设置∇ϕ = 0 时，可以找到等式 13 的最小值。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/7994ad764be3a9ab909710ba3cbb7121.png" data-original-src="https://miro.medium.com/v2/resize:fit:244/0*GIXc4izLaQs0IWNd"/></div></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/5070a30c56d8a1028f077c3a7667b0e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:268/0*EVoNvD5reaKRcUFM"/></div></figure><p id="0062" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(xᵗx)⁻ xᵗ被称为伪逆，它非常接近 x⁻，因为 x 是一个<em class="ll"> n </em> x <em class="ll"> d </em>矩阵，因此它是不可逆的。所以，我们不能用等式 14。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/a20dd00947c078f8b140b2b6e7215aa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:160/0*OMjVPYzMhwO8ltsc"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 14</figcaption></figure><p id="973f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们通过计算黑森∇ ϕ w.r.t 对 w 的二阶导数来验证这一点</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/b20aa3c2188564064a19f016fcdee295.png" data-original-src="https://miro.medium.com/v2/resize:fit:160/0*6EsW0T4Q2gryWw6O"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 15</figcaption></figure><p id="6430" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了使一阶导数成为最小值，Hessian 矩阵应该是半正定矩阵。矩阵 xᵗx 确实是半正定的，因为它本质上是可逆的，并且是其内部元素的平方。因此，我们确信我们已经找到了极小点。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/d1f18e06e888bc817f838dc77b3ff931.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/0*yPxp8xiH64pISclx"/></div></figure><p id="9ca6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，现在我们可以根据权重预测 y 的值，如下所示:</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/8f4fbd18a5f0ef0bd42498d227dbd8e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:246/0*UtwUXIQCG5xJmzwQ"/></div></figure><p id="5f16" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们已经完成了可能性的计算，让我们继续计算后验分布。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="ab gu cl kz"><img src="../Images/d9651112816a81aaa6a18604517af4e6.png" data-original-src="https://miro.medium.com/v2/0*paAsAT9UvBwSDVfQ"/></div></figure><p id="bbb2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们知道，使用 P(D/W)和 P(W ),我们可以通过对可能性和先验的乘积进行积分来获得 P(D)。因此，我们可以丢弃来自后验计算的证据，因为它将是一个常数。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/4d2043620889fae56ee20915f34d54bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/0*HS-HhtQQDeORLeCR"/></div></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/f1d90483ffe928d5043a26b7033f4216.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/0*fRIEg3fRtqIWCSg-"/></div></figure><p id="0081" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里，左边的指数对应于似然，第二个指数对应于先验(我已经从两个等式中删除了乘数常数，因为它们是正的，不会影响计算。)</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/32f90783f427d915d2b1e7ae1f5d6930.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/0*ccQD-HUrR4-v5dH0"/></div></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/f9d2386e08383fa1ba51dad684cc4b79.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/0*x-3UXF2HBsMLhfrs"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 16</figcaption></figure><p id="6150" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们希望我们的后验概率本质上是多元高斯的。也许通过比较等式 17 和等式 16 的参数，我们可以很容易地估计该高斯函数的参数。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/b6b5df259f3d702636ce125a6603b10c.png" data-original-src="https://miro.medium.com/v2/resize:fit:378/0*P0TfApt1ZsVyILRw"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 17</figcaption></figure><p id="0008" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过比较这些等式，我们得到:</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi my"><img src="../Images/abe54ac2de95a71d851a7236da2bfe5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:230/0*qCioKNNKikAtbs-s"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 18</figcaption></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/82adc270a96f2d20ecc56dfd1d9c2dd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:272/0*nrlZtx_h69enyt1q"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Equation 19</figcaption></figure><p id="24d4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，根据等式 19，我们可以获得均值等式:</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi na"><img src="../Images/5e0b52068fd5d2f27b347885280e9260.png" data-original-src="https://miro.medium.com/v2/resize:fit:174/0*pen5Mtodw2YD5EiU"/></div></figure><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/9e4e4f0093624fd75c926a2ffe5db35b.png" data-original-src="https://miro.medium.com/v2/resize:fit:206/0*z-7RNOkVQpTwRG13"/></div></figure><p id="81df" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们有了后验分布的均值和精度(方差),但在得出结论之前，我们需要验证ψ的逆是否存在。</p><p id="1f1d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从 MLE 计算中我们知道 xᵗx 是半正定的，现在我们加上 bI，其中 b 是协方差矩阵，因此它默认是半正定的。所以这使得ψ是半正定的，因此是可逆的。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/3513ce0f4f3c1c6b4017b3f63b3cf54a.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/0*lcySbSoZKDgdANHy"/></div></figure><p id="fac5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">MAP 估计表明它本质上是 MLE 和先验的结合。先验的增加有助于映射 n 避免过度拟合，因此这被称为正则化参数。</p><p id="b764" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们结束了计算参数的 MAP 估计。现在，我们可以用它来预测任意 x 值的 y 值。在下一篇文章中，我们将讨论朴素贝叶斯算法的贝叶斯版本。我希望这篇文章是有帮助的。</p><p id="5498" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">谢谢你。</p></div></div>    
</body>
</html>