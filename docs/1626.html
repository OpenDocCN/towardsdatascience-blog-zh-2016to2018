<html>
<head>
<title>Stan vs PyMc3 (vs Edward)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">斯坦vs PyMc3 (vs爱德华)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/stan-vs-pymc3-vs-edward-1d45c5d6da77?source=collection_archive---------1-----------------------#2017-09-28">https://towardsdatascience.com/stan-vs-pymc3-vs-edward-1d45c5d6da77?source=collection_archive---------1-----------------------#2017-09-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="3ad1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">神圣的三位一体说到贝氏。我将提供我使用前两个包的经验和我对第三个包的高水平看法(在实践中没有使用过)。当然，还有疯子(变得无关紧要的老教授)，他们实际上做了自己的吉布斯采样。</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="kq kr l"/></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">My reaction to people writing their own samplers</figcaption></figure><p id="13a0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是我对这三个部分的30秒介绍。您可以为数据指定创成式模型。您将数据作为观察值输入，然后它从数据的后面为您取样。神奇！</p><p id="8e07" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Stan是我使用的第一种概率编程语言。如果你来自统计学背景，这将是最有意义的。可以做mu~N(0，1)这样的事情。文档是绝对惊人的。就个人而言，我不介意使用Stan参考作为贝叶斯学习的介绍，因为它向您展示了如何对数据建模。例子相当广泛。</p><p id="a04d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">另一方面，PyMC3是专门为Python用户设计的。如今，大多数数据科学社区都在向Python迁移，所以这根本不是问题。您可以在下面看到一个代码示例。语法没有Stan那么好，但仍然可行。我真的不喜欢你不得不再次命名变量，但这是在后端使用theano的副作用。<code class="fe kw kx ky kz b">pm.sample</code>部分只是从后面取样。我喜欢这样一个事实，即使我有一个离散变量要采样，它也不会被扰乱，这是Stan到目前为止做不到的。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi la"><img src="../Images/2aae1d8037b346b4ed45dc01197fd705.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CBg3QmCr4H7a_941z3ra7w.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">PyMC3 sample code</figcaption></figure><p id="21d8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">就文档而言，在我看来没有Stan那么广泛，但是<a class="ae lh" href="http://docs.pymc.io/examples.html" rel="noopener ugc nofollow" target="_blank">的例子</a>真的很好。结合Thomas Wiecki的<a class="ae lh" href="http://twiecki.github.io/" rel="noopener ugc nofollow" target="_blank">博客</a>，你就有了一个完整的Python数据分析指南。</p><p id="87e9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">PyMC3成为我的(贝叶斯)工具的原因只有一个，那就是<code class="fe kw kx ky kz b">pm.variational.advi_minibatch</code>函数。当贝叶斯模型必须处理相当大量的数据(大约10000多个数据点)时，它真的很难处理。变分推理是进行近似贝叶斯推理的一种方式。Stan和PyMC3都有这个。但PyMC3采取了额外的步骤来扩展它，以便能够使用小批量的数据，这使我成为了它的粉丝。</p><h2 id="fddb" class="li lj iq bd lk ll lm dn ln lo lp dp lq jy lr ls lt kc lu lv lw kg lx ly lz ma bi translated">数学(可选)</h2><p id="6b6c" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">稍微了解一下数学，变分推理所做的是最大化数据log p(y)的对数概率的下限。</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi mg"><img src="../Images/d7debb91b6e4e3b740aa83a3e599500e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AF5CDa5fPGc8HBMqS8dSAg.png"/></div></div><figcaption class="ks kt gj gh gi ku kv bd b be z dk">Variational Bayes Equations</figcaption></figure><p id="5be4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们试图通过改变建议分布q(z_i)和q(z_g)的超参数来最大化这个下限。z_i指的是数据实例y_i本地的隐藏变量，而z_g是全局隐藏变量。上次我用PyMC3检查时，它只能处理所有隐藏变量都是全局变量的情况(这里我可能错了)。</p><p id="fe25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本质上，我觉得PyMC3做得还不够，它让我把它当作一个真正的优化问题。第二项可以近似为</p><figure class="kl km kn ko gt kp gh gi paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="gh gi mh"><img src="../Images/fef73bbdc7d593d0713740c5200e94cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BlDAno25kolEIo-amL7mkg.png"/></div></div></figure><p id="6ba4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中N是小批量的大小，N是整个集合的大小。这是Matthew Hoffman 在这篇<a class="ae lh" href="http://www.columbia.edu/~jwp2128/Papers/HoffmanBleiWangPaisley2013.pdf" rel="noopener ugc nofollow" target="_blank">论文中所写内容的精髓。我想指定模型/联合概率，让theano简单地优化q(z_i)，q(z_g)的超参数。<strong class="jp ir">这就是GPU加速真正发挥作用的地方。</strong> Stan在这方面确实落后了，因为它没有使用theano/ tensorflow作为后端。</a></p><h2 id="cba8" class="li lj iq bd lk ll lm dn ln lo lp dp lq jy lr ls lt kc lu lv lw kg lx ly lz ma bi translated">爱德华</h2><p id="2bd5" class="pw-post-body-paragraph jn jo iq jp b jq mb js jt ju mc jw jx jy md ka kb kc me ke kf kg mf ki kj kk ij bi translated">到目前为止，我对爱德华一直保持沉默。我没有在实践中使用过爱德华。我觉得主要原因是它没有好的文档和例子来轻松地使用它。的确，我可以将PyMC3或Stan模型直接提供给Edward，但是听起来我需要编写Edward特定的代码来使用Tensorflow加速。我有一种感觉，Edward可能在做随机变量推理，但遗憾的是文档和例子没有达到PyMC3和Stan那样的水平。然而，我必须说，当谈到贝叶斯学习的未来时，Edward是最有前途的(由于在贝叶斯深度学习方面所做的大量工作)。</p><p id="e7cd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">总之，PyMC3对我来说是这些天的明显赢家。如果我不必时不时接触到theano框架，那就太好了，但除此之外，它确实是一个很好的工具。我希望看到Edward或PyMC3迁移到Keras或Torch后端，因为这意味着我们可以建模(和调试得更好)。快乐造型！</p><figure class="kl km kn ko gt kp"><div class="bz fp l di"><div class="mi kr l"/></div></figure></div><div class="ab cl mj mk hu ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="ij ik il im in"><p id="f0ae" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">看这里是我的关于机器学习和深度学习的<a class="ae lh" href="https://www.udemy.com/course/machine-learning-and-data-science-2021/?referralCode=E79228C7436D74315787" rel="noopener ugc nofollow" target="_blank">课程</a>(使用代码DEEPSCHOOL-MARCH到85折)。</p></div></div>    
</body>
</html>