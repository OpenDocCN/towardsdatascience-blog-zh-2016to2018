<html>
<head>
<title>Behavioral Cloning: Make a car drive itself…</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">行为克隆:让汽车自动驾驶…</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/my-learning-from-udacity-sdc-nanodegree-do-we-really-need-a-complex-cnn-and-hours-of-training-4f80e28af90b?source=collection_archive---------5-----------------------#2018-04-14">https://towardsdatascience.com/my-learning-from-udacity-sdc-nanodegree-do-we-really-need-a-complex-cnn-and-hours-of-training-4f80e28af90b?source=collection_archive---------5-----------------------#2018-04-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/9bde4ac6048f0d53ef3af6ac824c96b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FF80H0RCGDLRoq8Dv5RNPA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Driving Car on Simulator Provided By Udacity</figcaption></figure><p id="8f0a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">是的，像往常一样，我从几十个卷积层和六个密集层的复杂CNN架构开始，因为Keras(感谢Keras团队让tensorflow变得如此简单)使创建神经网络变得更容易。我是开玩笑的:-)我刚开始使用类似于NVIDIA的架构，它有五个卷积层和三个完全连接的层，以及大量的训练数据，通过放大左、右相机拍摄的每幅图像等。顺便说一下，我已经使用Udacity提供的数据集来训练我的模型。</p><p id="2fdf" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">是啊，看起来像是我完成了一件大事，对吧？但是，我们需要像NVIDIA CNN架构这样的复杂CNN架构吗？NVIDIA CNN架构用于现实生活场景、数小时的培训时间和大量数据，以便在Udacity为该项目提供的模拟器上运行我们的汽车？</p><p id="1964" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们来讨论一下…</p><p id="91b4" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们需要什么来确定可驾驶区域和预测转向角度，以便我们的车辆在模拟器上平稳行驶而不会出现任何故障？</p><p id="98aa" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">对于识别转向角度的汽车，我们需要像道路边缘这样的特征。在CNN中，这样的高级特征是在初始层提取的。</p><p id="3405" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">记住这一点，我开始减少我的NVIDIA CNN模型的层数。我尝试了三个卷积层和三个致密层。然后我尝试了两个卷积层和两个致密层，最后一次尝试是一个卷积层和一个致密层。使用最后一种配置，我能够在大约五分钟的较短训练时间内达到与我以前的试验相似的性能。</p><p id="88cd" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我这个项目的最终模型由单一卷积层，然后是下降层，最大池层和单一密集层组成，如下所示</p><figure class="lb lc ld le gt jr gh gi paragraph-image"><div class="gh gi la"><img src="../Images/b6c975126effd31290d8f99d45fba9b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*iOBbCcGF0q2_K_I7AW70zw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Model used for training CNN for project 3</figcaption></figure><ul class=""><li id="17e1" class="lf lg iq ke b kf kg kj kk kn lh kr li kv lj kz lk ll lm ln bi translated">正在生成数据集:-</li></ul><p id="5643" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为了生成这个模型的数据集，我通过使中心图像的原始转向角的转向角为-ve，拍摄了所有的中心摄像机图像及其翻转的对应物。翻转图像是为了平衡数据集，以便模型不会偏向任何特定条件。为了将恢复数据添加到我的数据集，我通过将左相机图像的转向角偏移0.4并将右相机图像的转向角偏移-0.3来拍摄所有的右和左相机图像。我生成的数据集的分布如下所示</p><figure class="lb lc ld le gt jr gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/0ab455cb19b154593492f619e2c88a7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/0*zsy7UWRiAAFv9vBf.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Steering angle distribution of generated dataset</figcaption></figure><p id="2e40" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们可以看到数据集几乎是平衡的。由于我们的大部分赛道是直的，我保留了更多0°转向角的样本。</p><ul class=""><li id="6e57" class="lf lg iq ke b kf kg kj kk kn lh kr li kv lj kz lk ll lm ln bi translated">处理图像:-</li></ul><p id="54c9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">下图包含了每台相机拍摄的一些图像样本</p><figure class="lb lc ld le gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lp"><img src="../Images/d760fa3dc5da56bdaa867134fbf02046.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UxkzBDTNe6M3E7CPUySl8A.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Image samples from each camera</figcaption></figure><p id="533d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为了训练我们的模型，我们不需要上面图像中的所有细节，比如自然风景，天空，环境等等。我遵循的第一条基本原则是向网络提供你想让它看到的细节。为了去掉多余的细节，我从顶部裁剪了80像素，从底部裁剪了20像素。</p><p id="5a6c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">裁剪后的图像示例如下</p><figure class="lb lc ld le gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/eb1020c61e8ff7572177adce2b567a47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kf5RRi-FQzTd5oje78AZFg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Cropped Images</figcaption></figure><p id="5542" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">然后我把图片的大小调整到32 X 32，因为这将使模型更快，我们在这个场景中不需要低层次的细节。在对调整过大小的图像进行标准化之后，这些图像被作为输入传递给CNN。</p><ul class=""><li id="c5a2" class="lf lg iq ke b kf kg kj kk kn lh kr li kv lj kz lk ll lm ln bi translated">过度拟合:-</li></ul><p id="bdb9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在训练模型时，我发现该模型在训练集上具有低的均方误差，但是在验证集上具有高的均方误差。这意味着模型过度拟合。</p><p id="c8fc" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为了克服过度拟合，我添加了dropout层和maxpooling层，然后是卷积层，并将epoches数减少到2。</p><p id="8eea" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">有了这个模型，我可以在一号赛道和二号赛道上驾驶车辆。</p><p id="8d54" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我在模型中使用的参数</p><ul class=""><li id="8d12" class="lf lg iq ke b kf kg kj kk kn lh kr li kv lj kz lk ll lm ln bi translated">历元数= 2</li><li id="054e" class="lf lg iq ke b kf lr kj ls kn lt kr lu kv lv kz lk ll lm ln bi translated">使用的优化器- Adam</li><li id="0fe4" class="lf lg iq ke b kf lr kj ls kn lt kr lu kv lv kz lk ll lm ln bi translated">学习率-默认值为0.001</li><li id="f392" class="lf lg iq ke b kf lr kj ls kn lt kr lu kv lv kz lk ll lm ln bi translated">验证数据分割- 0.2</li><li id="144a" class="lf lg iq ke b kf lr kj ls kn lt kr lu kv lv kz lk ll lm ln bi translated">生成器批量= 32</li><li id="85c2" class="lf lg iq ke b kf lr kj ls kn lt kr lu kv lv kz lk ll lm ln bi translated">修正系数- 0.4和-0.3</li><li id="c800" class="lf lg iq ke b kf lr kj ls kn lt kr lu kv lv kz lk ll lm ln bi translated">使用的损失函数- MSE(均方差，因为它对于回归问题是有效的)。</li><li id="6cd1" class="lf lg iq ke b kf lr kj ls kn lt kr lu kv lv kz lk ll lm ln bi translated">激活函数- RELU</li><li id="be9e" class="lf lg iq ke b kf lr kj ls kn lt kr lu kv lv kz lk ll lm ln bi translated">下降- 40%(在第一个激活层之后，以combact过度拟合)</li><li id="6954" class="lf lg iq ke b kf lr kj ls kn lt kr lu kv lv kz lk ll lm ln bi translated">使用的数据集-由Udacity提供(除原始数据集外无其他图像)。</li></ul><p id="7f32" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">自主模式下的轨道1视频:-</p><figure class="lb lc ld le gt jr"><div class="bz fp l di"><div class="lw lx l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Track 1</figcaption></figure><p id="4599" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">自动模式下的轨道2视频:-</p><figure class="lb lc ld le gt jr"><div class="bz fp l di"><div class="lw lx l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Track 2</figcaption></figure><p id="bfa1" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">该模型能够在第二条赛道上驾驶，而无需为第二条赛道重新训练。因此，我们可以说，这是足够普遍的，而不是过度拟合。</p><p id="1951" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">链接到该项目的github库。</p></div></div>    
</body>
</html>