<html>
<head>
<title>Measuring the Power of a Classifier With VC Dimension</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用VC维度量分类器的能力</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/measuring-the-power-of-a-classifier-c765a7446c1c?source=collection_archive---------3-----------------------#2018-04-23">https://towardsdatascience.com/measuring-the-power-of-a-classifier-c765a7446c1c?source=collection_archive---------3-----------------------#2018-04-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="e2ca" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用VC维度量算法的表达能力</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/bce8d5d886002f7ac6a7281729b50de4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*8F1SfLiNaCmWLsHp4r42Qg.gif"/></div></div></figure><p id="0708" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为数据选择分类器时，一个显而易见的问题是“这个分类器可以分类什么类型的数据？”。例如，如果您知道您的点可以很容易地由一条直线分隔，您可能会选择简单的线性分类器，而如果您知道您的点将在许多独立的组中，您可能会选择更强大的分类器，如随机森林或多层感知器。这个基本问题可以使用分类器的<strong class="kw iu"> VC维度</strong>来回答，这是计算学习理论中的一个概念，它正式量化了分类算法的能力。</p><p id="c23d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">分类器的VC维由Vapnik和Chervonenkis定义为分类算法可以<strong class="kw iu">粉碎</strong> [ <a class="ae lq" href="https://epubs.siam.org/doi/10.1137/1116025" rel="noopener ugc nofollow" target="_blank"> 1 </a>的最大点集的基数(大小)。这似乎是一个简单的定义，但很容易被误解，所以我现在将在这里更详细地解释定义中的关键术语。为了简单起见，我们将使用2-D例子，但是这些想法推广到任何数量的维度。</p></div><div class="ab cl lr ls hx lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="im in io ip iq"><h2 id="18e0" class="ly lz it bd ma mb mc dn md me mf dp mg ld mh mi mj lh mk ml mm ll mn mo mp mq bi translated">打碎一组点</h2><p id="1917" class="pw-post-body-paragraph ku kv it kw b kx mr ju kz la ms jx lc ld mt lf lg lh mu lj lk ll mv ln lo lp im bi translated">平面上的<strong class="kw iu"> N </strong>点的配置就是<strong class="kw iu"> N </strong>点的任意放置。为了使<em class="mw">的VC维数至少为</em> <strong class="kw iu"> N </strong>，分类器必须能够粉碎<strong class="kw iu"> N </strong>点的<em class="mw">单个</em>配置。为了<strong class="kw iu">粉碎</strong>点的配置，分类器必须能够针对点的正负的每一种可能的<strong class="kw iu">分配</strong>，完美地划分平面，使得正点与负点分离。对于一个有<strong class="kw iu"> N </strong>个点的配置，有<strong class="kw iu">个2^N </strong>个可能的正或负赋值，因此分类器必须能够正确地分离每个点。</p><p id="4f59" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在下面的例子中，我们展示了线性分类器的VC维至少是 3，因为它可以粉碎这种3点的配置。在肯定和否定的2 = 8个可能赋值的每一个中，分类器能够完美地分离两个类别。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mx"><img src="../Images/21c6e3e64745bc17d2a140eb1c179b9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oDSXjoDFP2qfmX2rIKpHIg.png"/></div></div></figure><p id="32d1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在，我们表明线性分类器比4低。在这种4点配置中，分类器不能在至少一个赋值中分割正类和负类。在这种情况下，需要两条线来分隔这两个类。我们实际上需要证明<em class="mw">不存在</em>一个可以被粉碎的4点构型，但是同样的逻辑适用于其他构型，所以，为了简洁起见，这个例子已经足够好了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/57c2161f4ae82b301356b15c71882b77.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*pZHXiLtBcrLDlvaArUtDRw.png"/></div></figure><p id="72eb" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">既然我们现在已经表明线性分类器的VC维数是<em class="mw">至少是</em> 3，并且<em class="mw">低于</em> 4，我们可以最终得出结论，它的VC维数是<em class="mw">正好是</em> 3。再次记住，为了有一个VC维度为<strong class="kw iu"> N </strong>，分类器必须只粉碎<em class="mw">N个点的单个</em>配置——可能会有许多分类器不能粉碎的<strong class="kw iu"> N </strong>个点的其他配置。</p></div><div class="ab cl lr ls hx lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="im in io ip iq"><h2 id="4d74" class="ly lz it bd ma mb mc dn md me mf dp mg ld mh mi mj lh mk ml mm ll mn mo mp mq bi translated">VC维的应用</h2><p id="4f25" class="pw-post-body-paragraph ku kv it kw b kx mr ju kz la ms jx lc ld mt lf lg lh mu lj lk ll mv ln lo lp im bi translated">既然你已经知道什么是风险资本维度，以及如何找到它，那么理解它的实际含义也是很重要的。在大多数情况下，一个分类器的确切VC维并不重要。更确切地说，它更多地用于根据算法的复杂性对不同类型的算法进行分类；例如，简单分类器类可以包括基本形状，如直线、圆形或矩形，而复杂分类器类可以包括诸如多层感知器、提升树或其他非线性分类器的分类器。分类算法的复杂度与其VC维直接相关，与偏差和方差之间的权衡相关。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/4e8bedd2e2023217ea99e0c531f55100.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*4frB4J8LAy4D4TRWn0SNEQ.png"/></div></figure><p id="ad3f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在这张图片中，我们看到了模型复杂性的影响。在底部，每个<strong class="kw iu"> S_i </strong>代表一组在VC维度或复杂度上相似的模型。在上图中，VC尺寸在x轴上测量为<strong class="kw iu"> h </strong>。观察到随着复杂性的增加，你从适应不足过渡到适应过度；增加复杂性直到某一点都是好的，在这之后，你开始过度适应训练数据。</p><p id="7c4d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">另一种思考方式是通过偏差和方差。低复杂度模型将具有高偏差和低方差；虽然它的表达能力低，导致高偏差，但它也非常简单，因此它具有非常可预测的性能，导致低方差。相反，复杂的模型将具有较低的偏差，因为它具有更多的表达能力，但是将具有较高的方差，因为基于样本训练数据有更多的参数要调整。通常，具有较高VC维度的模型将需要更多的训练数据来正确训练，但将能够识别数据中更复杂的关系。</p><p id="1c98" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在模型的某种复杂程度上，偏差和方差之间会存在一个理想的平衡，用垂直虚线表示，在这个水平上，你对你的数据既不会欠拟合也不会过拟合。换句话说，你应该选择一个分类器，它的复杂程度对于你的分类任务来说<em class="mw">刚好</em>足够——少了会导致欠拟合，多了会导致过拟合。</p></div></div>    
</body>
</html>