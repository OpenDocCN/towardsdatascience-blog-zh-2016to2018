<html>
<head>
<title>Photoshop 2.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Photoshop 2.0</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/photoshop-2-0-a49990e483?source=collection_archive---------5-----------------------#2017-12-05">https://towardsdatascience.com/photoshop-2-0-a49990e483?source=collection_archive---------5-----------------------#2017-12-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7753" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如果说软件 2.0 是深度学习，Photoshop 2.0 就是 GAN</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/88dc105280f3a866a5f8993e36f48c14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jQSzce3v1OMlPAWBRpQNyQ.png"/></div></div></figure><h1 id="f4d7" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">Photoshop 1.0 是什么？</h1><p id="aa2e" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">我们可以使用<strong class="ll ir"> Photoshop </strong>来“改变”图像，比如照片、下载的图标或扫描的艺术品。改变图像包括做一些事情，比如<strong class="ll ir">改变图像内的颜色</strong>，<strong class="ll ir">修改图像的尺寸</strong>和<strong class="ll ir">比例</strong>，或者将一张图片“放入”另一张图片。</p><p id="89f4" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">需要多少时间？那<strong class="ll ir">完美呢？</strong>你还是设法做到了。那很好。</p><h1 id="8753" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">甘家擅长什么？甘是如何有所作为的？</h1><p id="132a" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated"><strong class="ll ir">生成性对抗网络</strong>擅长将图像从一个领域翻译到另一个领域。</p><p id="1b23" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">比如:从用户草图生成猫。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mk"><img src="../Images/3ac54f78c541e029f6e0e4337b408431.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tJRy5Chmk4XymxwN.png"/></div></div></figure><p id="93ff" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">我们所有人都不擅长编辑照片。但有时我们必须自己去做。假设你想改变头发的颜色或者尝试不同的发型，该怎么做呢？如果你不熟悉这些工具，就很难把图像转换成你想要的样子。</p><p id="5578" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">GANs 可以将你的草图转换成逼真的图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/46b7bebe4160ea7eced7f50a31f7696e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*KiVRYLvcdJUuQNvdjTk3lQ.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">Semantic label Map</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/da53ef7fe95c2b197ce6a0a757268d3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*ouW47ErPPZeew3Wb7dyqEQ.png"/></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">Real Image</figcaption></figure><p id="4f88" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><strong class="ll ir">生成器</strong>可以将<strong class="ll ir">语义标签图</strong>翻译成<strong class="ll ir">逼真的图像</strong>，而鉴别器 D 旨在将真实图像与翻译后的图像区分开来。</p><h1 id="cb7a" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">pix2pix 架构</h1><p id="685f" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">pix2pix 方法是一个<strong class="ll ir">条件 GAN 框架</strong>，用于在给定输入语义标签图的情况下对真实图像的条件分布进行建模。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/eb7bc9c1d515a7508dc447cc712a8844.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FbVRnbyqkcQ8Uweq.jpg"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">Conditional GANs</figcaption></figure><p id="cd11" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><strong class="ll ir">条件 GAN</strong>是 GAN 框架的扩展。这里我们有条件信息 Y，它描述了数据的某些方面。例如，如果我们在处理人脸，Y 可以描述头发颜色或性别等属性。</p><p id="726d" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">当生成高分辨率图像时，结果不令人满意。所以为了提高<strong class="ll ir">的真实感</strong>和<strong class="ll ir">的分辨率</strong>，开发了一种新的架构。</p><p id="b0d9" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">开发了一个<strong class="ll ir">粗到精生成器</strong>、一个<strong class="ll ir">多尺度鉴别器</strong>架构和一个鲁棒的<strong class="ll ir">对抗学习目标函数</strong>。</p><h1 id="2b2b" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated"><strong class="ak">粗到精发生器</strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ca"><img src="../Images/62903876f5cf14fa66f0a07e60b52d1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kbUnszRlGyGVNpR2SI003w.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">Network architecture of the generator.</figcaption></figure><p id="de60" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">生成器由<strong class="ll ir">全局生成器网络(G1) </strong>和<strong class="ll ir">局部增强器网络(G2)组成。</strong></p><p id="bdae" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><strong class="ll ir">全局生成器(G1) </strong>从语义图中提取降采样输入，并生成低分辨率输出。<strong class="ll ir">局部增强器(G2) </strong>组合来自生成器和原始标签图的特征图，以产生最终输出。</p><p id="0338" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">为了以更高的分辨率合成图像，可以使用<strong class="ll ir">附加的局部增强器网络</strong>。</p><p id="9716" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><strong class="ll ir">生成器</strong> G={G1，G2}，<strong class="ll ir">输出图像分辨率</strong> =2048×1024</p><p id="89b2" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated"><strong class="ll ir">生成器</strong> G={G1，G2，G3}，<strong class="ll ir">输出图像分辨率</strong> =4096×2048</p><p id="7071" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">在训练过程中，我们首先训练全局生成器，然后按照分辨率的顺序训练局部增强器。然后我们一起微调所有的网络。</p><h1 id="b707" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated"><strong class="ak">多刻度鉴别器</strong></h1><p id="ffdb" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated">多尺度鉴别器由<strong class="ll ir"> 3 个鉴别器(D1，D2，D3) </strong>组成，它们具有相同的网络结构，但在不同的图像尺度下工作。</p><p id="0ebe" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">他们接受过训练，能够以<strong class="ll ir"> 3 种不同的比例区分真实图像和合成图像。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/653ffd064583edbcf6122c06b146080d.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*BqZSPAnTAT8hauCeGokZeQ.png"/></div></figure><p id="b93e" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">在最粗尺度下工作的鉴别器具有最大的感受野。另一方面，以最精细的尺度操作的那个引导生成器产生更精细的细节。</p><h1 id="92a6" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated"><strong class="ak">对抗性学习目标函数</strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/d8fc84bc65e43be552c652f199e2b469.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*AkFyVd2DMlYP_BWxKVg21Q.png"/></div></figure><p id="325e" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">基于鉴别器的特征匹配损失是不可行的。从鉴别器的多个层提取特征，并学习匹配来自真实和合成图像的这些中间表示。</p><h1 id="5429" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated">学习实例级特征嵌入</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/27dec67d2b50060d24f30209af2e3670.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*5Xyk9jtUmp6KiEPRVEybpw.png"/></div></figure><p id="995d" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">添加<strong class="ll ir">低维特征通道</strong>作为生成器的输入，可以产生<strong class="ll ir">多样的</strong>图像，并允许<strong class="ll ir">实例级控制</strong>。</p><p id="0b4c" class="pw-post-body-paragraph lj lk iq ll b lm mf jr lo lp mg ju lr ls mh lu lv lw mi ly lz ma mj mc md me ij bi translated">训练一个<strong class="ll ir">编码器网络</strong>来为地面真实图像中的每个对象实例找到低维特征向量。然后，我们将这些特征与标签图连接起来，生成最终的图像。我们可以通过操作不同的特征来产生不同的输出。</p><h1 id="0584" class="kr ks iq bd kt ku kv kw kx ky kz la lb jw lc jx ld jz le ka lf kc lg kd lh li bi translated"><strong class="ak">结果</strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mv"><img src="../Images/0718d340dbbddb8f86ef2351c762804c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SoKBok6NZv7vDBghEh1yaA.png"/></div></div><figcaption class="mm mn gj gh gi mo mp bd b be z dk">Semantic labels → Cityscapes street views</figcaption></figure><h2 id="a0b2" class="mw ks iq bd kt mx my dn kx mz na dp lb ls nb nc ld lw nd ne lf ma nf ng lh nh bi translated">参考</h2><p id="b23c" class="pw-post-body-paragraph lj lk iq ll b lm ln jr lo lp lq ju lr ls lt lu lv lw lx ly lz ma mb mc md me ij bi translated"><a class="ae ni" href="https://tcwang0509.github.io/pix2pixHD/" rel="noopener ugc nofollow" target="_blank">https://tcwang0509.github.io/pix2pixHD/</a></p></div></div>    
</body>
</html>