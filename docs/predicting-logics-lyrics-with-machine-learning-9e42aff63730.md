# 用机器学习预测逻辑的歌词

> 原文：<https://towardsdatascience.com/predicting-logics-lyrics-with-machine-learning-9e42aff63730?source=collection_archive---------2----------------------->

从中学开始，当我第一次听到他的歌曲“[我所做的一切](https://www.youtube.com/watch?v=eIGh4Nc1fAM)”时，逻辑就对我的生活产生了显著的影响。这首歌所属的混音带，*年轻的辛纳特拉*，单枪匹马地让我成为了各种形式的嘻哈音乐的粉丝，向我介绍了我以前从未想过要听的新旧风格。我可以把那个项目中的每一首歌都与初中和高中时的一种特殊感觉或时刻联系起来，无论那是一段无比快乐的时光还是可怕的悲伤。因此，我从来没有遇到过我不喜欢的诗歌或歌曲，所以当我在 5 月份参加的数据科学课上被分配到这个项目时，我立即知道我应该关注哪个音乐家。

与我得到的任何其他编码实验室相比，这个实验室对我来说是最有趣和令人兴奋的，所以我认为写它会很有趣！我将遍历我编写的 Python 代码，然后讨论这个实现的一些优点和缺点，以及将来如何改进它。当然，还要特别感谢加州理工大学分校的 Dennis Sun 教授，感谢他提供了出色的解决方案和帮助，并为探索数据科学分配了如此出色的实验室！

不过，在我们开始之前，明智的做法是 [***访问此网页***](http://setosa.io/ev/markov-chains/)*快速了解马尔可夫链及其工作原理——这对理解如何处理这个问题至关重要。简单来说，*如果我们将天气建模为马尔可夫链，预测明天的天气将只取决于今天的条件。**

# *构建算法*

*这个实现的关键是创建一个[二元模型](https://en.wikipedia.org/wiki/Bigram) [马尔可夫链](https://en.wikipedia.org/wiki/Markov_chain)来表示英语。更具体地说，我们的链将是一个 dictionary 对象，其中每个键都是一个惟一的元组，由一个单词及其后面的单词组成。使用二元模型而不是单个单词(unigrams)允许我们提高生成的行的准确性和可读性，因为它定义了我们的模型，使得**句子中的下一个单词是基于前两个单词预测的，而不仅仅是前一个单词**(稍后有更多细节)。*

## *获取数据*

*真正的第一步是收集我们将要分析的所有歌词。为了做到这一点，我在网上搜集了 Logic 每首歌的歌词链接，然后浏览每个链接，收集所有相关的文本。最终结果是一个列表，其中每个元素都是一个字符串，包含一首歌的所有歌词。*

*Web scraping Logic’s lyrics.*

*每个网页的 URL 只在尾部的页码上有所不同，所以我可以轻松地使用第一个`for`循环遍历两个页面。我制作的`soup`变量是来自`[BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)`库的一个对象；它使得从网站上解析和提取数据变得异常简单。在`requests`库的帮助下，我能够将每个网页的完整 HTML 代码传递给`soup`。页面上的第一个表格包含了我们需要的所有链接，以便获得每首逻辑歌曲的歌词，所以我使用了另一个`for`循环来遍历表格中的每一行；因为 HTML 中的超链接由`a`和`href`标记表示，所以我能够搜索这些标记来找到每个链接并将其附加到一个`links`列表中。下一组`for`循环用于迭代我刚刚获得的每一个`links`，以获取每首歌曲中的每一段文本，最终让我将每一组`song_text`添加到一个综合的`lyrics`列表中。我不得不使用`time.sleep`函数来确保我不会因为太快发出大量请求而被阻止或禁止。*

## *创建链*

*终于到了挖掘并开始构建我们的马尔可夫链的时候了。我们编写了一个函数，它遍历 Logic 的所有歌词中的每个单词，以便通过检查两个单词的每个序列并创建每个序列后面的所有单词的列表来生成模型。为了更有效、更实用的遍历，我们使用`"<START>"`、`"<END>"`和`"<N>"`标签分别表示歌曲的开始、结束和换行符。*

*Training our Markov Chain.*

*这个`train_markov_chain`函数接收我们之前创建的`lyrics`列表。我们用键`(None, "<START>")`初始化我们的`chain`来标记一首歌曲的开始。你可能已经猜到了，我们从`None`关键词开始，因为在一首歌的第一个词之前没有任何词。遍历每首歌曲，我们用自定义标签替换歌曲文本中的所有换行符，然后创建一个`last_2`变量来跟踪迭代过程中遇到的当前/最近的键。然后，`for`歌曲歌词中的每一个`word`，我们通过将`word`连接到当前调来将它插入到我们的链中，然后更新当前调以反映我们正在移动到下一个`word`的事实。如果这个新键在链中还不存在，我们可以简单地用一个空列表来创建它，以反映它以前没有被见过的事实。一旦歌曲中的最后一首`word`被处理完，我们就加上一个`“<END>”`标签，然后继续我们集合中的下一首歌曲。*

## *预测歌词*

*一旦我们构建并返回了表示马尔可夫链的字典，我们就可以进入算法的最后一部分:生成预测的歌词。从`(None, "<START>")`键(我们链中的第一个键)开始，我们随机抽样列表中与该键相关的一个单词，然后移动我们当前正在检查的键，以说明我们刚刚抽样的单词。我们继续这个过程，直到最后遇到`"<END>"`标签。*

*Predicting new Logic lyrics.*

*因此，在将所有这些代码放在一起之后，我们可以`print(generate_new_lyrics(chain))`在控制台中显示我们预测的歌词。如果你想自己运行所有这些代码，你可以查看我的 [GitHub 库](https://github.com/hanskamin/predicting-logics-lyrics)来访问 Python 文件和 Jupyter 笔记本。*

*然而，需要注意的是，因为我使用简单的随机抽样来创建新的歌词，所以我也随机选择了我实际接收到的输出。有少数情况下，我收到的输出少于一行，甚至只有一个单词，但大多数时候，算法打印出了大量的预测歌词。尽管如此，在搜索了我从该算法的多次运行中收到的输出后，我得到了一些非常好的歌词，从原始的妙语到彻头彻尾的滑稽讽刺。下面你会发现我最喜欢的几个，我相信所有这些都非常符合 Logic 的风格(除了一些有趣和/或怪异的，我觉得有义务包括在内)。*

> *“在她爱抽烟的日子里，是的，她渐渐消失了”*
> 
> *“所以我对这种景象直喘粗气，黑夜是我的分工”*
> 
> *“我会告诉他们如何行动，我会站起来，然后在后面”*
> 
> *"赞美黑耶稣，现在他们叫警察了，看在我是道具的份上"*
> 
> *“我很清楚他生来就有热量，岩石比混凝土更坚固”*
> 
> *“宝贝女儿我能找到人性吗？”*
> 
> *“把我的一切都丢到街上，更别说热了”*
> 
> *"这位先生最好知道联邦调查局在窃听"*
> 
> *"我的生活不属于我，我需要你来拯救我"*
> 
> *“每个人都在寻找街道，更不用说热”*
> 
> *"我会一直说唱你们所有人？我离开是有原因的*
> 
> *“哦，我的，我的，我的，感觉这邪恶的氛围”*
> 
> *“但我乘公共汽车离开我的问题，上帝帮助我解决它们”*
> 
> *"现在我祈祷有人来拯救我，不管你相信什么是对的"*
> 
> *“你会失去一切，就像一个该死的国王”*
> 
> *“卒往往在没有拨号音的情况下继续”*
> 
> *“是啊，知道吗？我会让死去的总统代表我*
> 
> *"我所过的生活，只是一个门面"*
> 
> *"她不想再哭了，穷困潦倒，不知天高地厚"*
> 
> *“我看到自己在卢浮宫，我知道我的心在捉弄我”*
> 
> *"我觉得我在扼杀我的梦想，生命在消逝"*
> 
> *“为什么没人想说我会说唱”*
> 
> *"就像魔术师在路边胡言乱语"*
> 
> *"我工作室里的朋友，我在公路上漫步"*
> 
> *“这说唱是另一天，另一本书”*
> 
> *“我见过好人，他们能像其他人一样下雨”*
> 
> *"我知道从哪里开始杀人"*
> 
> *"哟，我会保留所有这些新的剩余残渣"*
> 
> *“相信我，女孩，我不会生气，如果你听到不同的人说谎”*
> 
> *"人们认为他们和他一样高，他们还没准备好喝更多的酒"*
> 
> *"任何和我一起骑车的人现在都想这样"*

# *分析我们的结果:优势和劣势*

*通过观察我们的 bigram 实现和 unigram 实现的许多输出，我们可以得出一些重要的结论:*

1.  *我们模型的预测是准确的，但经常被重复利用。值得注意的是，我们预测的许多台词与 Logic 实际编写的台词几乎相同，即一首诗/歌中的半句台词与另一首诗/歌中的半句台词相结合。这是可以预料的，因为使用二元模型在预测的单词中产生较少的可变性，这是由于基于前两个单词而不是最近的一个单词进行预测，导致来自相同逻辑歌词的三个或更多单词的序列。简单地说，*用双字代替单个单词增加了可读性和与逻辑风格的相似性，但降低了创造性。**
2.  ***我们的型号速度较慢，产出较少。**unigram 模型运行速度更快，因为表示其马尔可夫链的 dictionary 对象的键要少得多。我们的模型有更多的键，因为它必须处理两个单词的元组。此外，正如我前面提到的，有时我收到的输出很少甚至没有，而且通常比我从 unigram 实现中收到的要少。这可以归因于当前两个单词的基础上，下一个单词的可能性较少。*

*那么，我们该何去何从呢？我们强调了实施的优势和劣势；我们如何减轻这些缺点并使我们的模型变得更好？识别限制我们建立的模型的中心马尔可夫假设是发现优秀设计的关键。*

# *找到更好的方法*

*用马尔可夫链对情况建模需要假设情况本身满足一个关键陈述:对下一个状态的预测只取决于当前状态的状态，而不是情况历史的其余部分。例如，使用马尔可夫链预测明天的天气需要得出这样的结论，即过去两周或更长时间的天气对明天的情况没有影响——我想我们都同意这听起来很牵强。因此，即使使用二元模型帮助我们降低了模型中这一假设的重要性，它的影响仍然普遍存在，削弱了我们的结果。我们需要找到一种替代模型的方法，至少可以减少假设。*

*一个**递归神经网络**是我们可以使用的替代的一个例子。虽然我不会在这里详细介绍 rnn，主要是因为我自己仍然只是对它们进行了初步的了解，但我将提供一些简要的说明。rnn 的两个关键特征是，它们不假设所有输入都是相互独立的，并且它们能够保存它们所处理的内容的历史，这两个特征对于改进我们的模型都是必要的。关于 rnn 如何工作以及如何实现它们的更多信息，请查看[维基百科页面](https://en.wikipedia.org/wiki/Recurrent_neural_network)以及[本教程](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)；我将从这两者中学习，最终更新我的代码以获得更好的预测。*

*如果你已经做到了这一步，感谢你阅读并一瞥我对机器学习日益增长的兴趣！数据科学作为一个整体已经有如此多的迷人和创造性的应用。随着我在更多项目中的工作和作为一名开发人员的不断进步，我期待着进一步探索许多细微差别和错综复杂的细节。毕竟，正如罗辑曾经写的(以及他之前的保罗·布兰特)，当月球上有脚印时，天空怎么可能是极限？*

*![](img/bc2577280dadc4987be082840e3ddcca.png)*

*Philadelphia, June 2013*

> *特别感谢我的姐姐 [Kelsi Kamin](https://medium.com/u/57442ca8258d?source=post_page-----9e42aff63730--------------------------------) 在我写这篇文章的时候给了我动力和建设性的反馈！*