# 神经网络=黑盒？

> 原文：<https://towardsdatascience.com/neural-networks-black-box-b20723f9a417?source=collection_archive---------4----------------------->

如你所知，我是一个机器学习爱好者。具体地说，是神经网络。

在过去的几个月里，我读了很多关于 NNs 的文章。我得出了一个结论:

> 没有一个真正让你看到 NNs 是怎么学习的。

## 示例#1

[福布斯](http://news.mit.edu/2017/explained-neural-networks-deep-learning-0414)，*解释:神经网络*

在这篇文章中，作者说:

> “训练数据被输入到底层，即输入层，然后通过后续层，以复杂的方式相乘并相加，直到最终到达输出层，进行彻底的转换。

哇，*情结*确实帮助我理解了 NNs 是如何学习的…然后:

> 在训练期间，不断调整权重和阈值，直到具有相同标签的训练数据始终产生相似的输出。"

我有这个想法…模糊地。

## 实施例 2

[哈佛商业评论](https://hbr.org/2017/01/deep-learning-will-radically-change-the-ways-we-interact-with-technology)，深度学习将从根本上…

> “然而，要使神经网络有用，它需要训练。为了训练神经网络，一组虚拟神经元被绘制出来，并被分配一个随机的数字“权重”，该权重决定神经元如何对新数据(数字化的对象或声音)做出反应。

嗯，我想这是有道理的。

> “最终，经过充分的训练，神经网络将始终如一地识别语音或图像中的正确模式。”

哦，再一次，它关上了正确解释神经网络如何学习的大门…

## 实施例 3

[NYT](https://www.nytimes.com/2016/12/14/magazine/the-great-ai-awakening.html?_r=0) ，伟大的人工智能觉醒

> “训练是一个过程，通过这个过程，在 blob 中挖掘出一系列错综复杂的隧道，这些隧道将任何给定的输入连接到其正确的输出。”

我想我不喜欢隐喻数学方法。在这种情况下，一个 NN。

> “他们*【权重】*必须独立证明他们是否也擅长挑选狗和除颤器，(…)

对(？).

> (…)但让神经网络如此灵活的一点是，每个单独的单元都可以对不同的预期结果做出不同的贡献。"

尽管如此，我还是没有亲眼看到真正的学习。总之。

# 我的观点是:

> 了解机器如何学习。

真的！

神经网络训练(涉及梯度下降、反向传播等方法)很有意思。这也有点不可思议，因为数字开始自我调整，试图找到最大预测的最佳路径。

我知道这些文章并不是要向你展示这一点，因为它们的目标受众(这显然不是技术或教育)。

但我想，即便如此，我还是想看看里面的一些东西。