<html>
<head>
<title>From Keras model to Angular application</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从 Keras 模型到角度应用</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/from-keras-model-to-angular-application-491d3f6c4455?source=collection_archive---------10-----------------------#2018-07-09">https://towardsdatascience.com/from-keras-model-to-angular-application-491d3f6c4455?source=collection_archive---------10-----------------------#2018-07-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/da70aac2c6017a7494e7ced93cc7651a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*VYfLA0MSPpuphGCDoZGUcg.png"/></div></figure><h1 id="2556" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">介绍</h1><p id="12e4" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><a class="ae lq" rel="noopener" target="_blank" href="/how-to-deploy-machine-learning-models-with-tensorflow-part-1-make-your-model-ready-for-serving-776a14ec3198">与 TensorFlow 合作服务</a>我想，如果也能为 Keras 模特服务，那就太棒了。<a class="ae lq" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>的优势是显而易见的——它大大简化了模型开发，并允许比纯 TensorFlow 框架更快地尝试模型。</p><p id="69ae" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">另一个动机是，我想让客户端独立于庞大的 TensorFlow 框架，并使用非常有限的一部分服务功能。当然，我想直观地显示结果，而不需要通过枯燥的 JSON 输出:-)</p><h2 id="4cae" class="lw jv iq bd jw lx ly dn ka lz ma dp ke ld mb mc ki lh md me km ll mf mg kq mh bi translated">用 TensorFlow 服务 Keras 模型</h2><p id="b00a" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">Keras 提供高级神经网络 API，能够在<a class="ae lq" href="https://github.com/tensorflow/tensorflow" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>、<a class="ae lq" href="https://github.com/Microsoft/cntk" rel="noopener ugc nofollow" target="_blank"> CNTK </a>或<a class="ae lq" href="https://github.com/Theano/Theano" rel="noopener ugc nofollow" target="_blank"> Theano </a>之上运行。基本上，它抽象了那些框架，更容易理解和学习，并且允许你用更少的代码做更多的事情。</p><p id="adb3" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated"><a class="ae lq" href="https://github.com/tensorflow/serving" rel="noopener ugc nofollow" target="_blank"> TensorFlow Serving </a>是一款用于托管机器学习模型的软件。它的主要用途—高性能生产服务。它是用 C++编写的，使用了客户端用于计算的<a class="ae lq" href="https://www.tensorflow.org/serving/architecture_overview" rel="noopener ugc nofollow" target="_blank"> Servables </a>的概念。</p><h2 id="f56d" class="lw jv iq bd jw lx ly dn ka lz ma dp ke ld mb mc ki lh md me km ll mf mg kq mh bi translated">如何与 TensorFlow 服务器对话</h2><p id="81d1" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">TensorFlow Serving 提供<a class="ae lq" href="https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/prediction_service.proto" rel="noopener ugc nofollow" target="_blank"> gRPC API </a>用于执行回归、预测和推理任务。这种 gRPC API 比 HTTP 协议上的 REST API 具有更好的性能，但是不能被 Web 应用程序简单地使用。因此，在我看来，gRPC 是内部客户的完美选择，但是它应该被一个向外部世界提供 REST API 的服务所包装。</p><h1 id="03a9" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">犬种检测器</h1><p id="da8a" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">对于我的示例应用程序，我使用了一个<a class="ae lq" href="https://github.com/Vetal1977/aind2-dog-project" rel="noopener ugc nofollow" target="_blank">狗品种检测器</a>，它是我在 Udacity 纳米学位课程期间实现的。我们想要解决的问题是给定一幅狗的图像进行品种检测。该模型利用了卷积神经网络(CNN)架构，并在<a class="ae lq" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet 数据集</a>模型上进行预训练(我选择了<a class="ae lq" href="https://arxiv.org/abs/1608.06993" rel="noopener ugc nofollow" target="_blank"> DenseNet 201 </a>)。该模型是用 Keras 库实现的。</p><p id="d189" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">应用的第二部分是一个<a class="ae lq" href="https://nodejs.org/en/" rel="noopener ugc nofollow" target="_blank"> Node.js </a>服务，包装 TensorFlow 服务的 gRPC API，对外提供 REST API。该服务尽可能少地依赖 TensorFlow 它使用修改过的<a class="ae lq" href="https://developers.google.com/protocol-buffers/" rel="noopener ugc nofollow" target="_blank"> protobufs </a>文件和<a class="ae lq" href="https://www.npmjs.com/package/grpc" rel="noopener ugc nofollow" target="_blank"> gRPC 库</a>来处理服务器请求。因此，我们不需要在这里安装任何巨大的 TensorFlow 包。</p><p id="a473" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">最后一部分是一个非常简单(也不太好)的<a class="ae lq" href="https://angular.io/" rel="noopener ugc nofollow" target="_blank"> Angular </a>应用程序，它允许选择狗的图像，向我们的包装服务发送请求，并显示品种。</p><p id="06b9" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">代码可以在我的<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>中找到。如果你觉得有用，可以随意复制、修改和使用:-)</p><h1 id="1aa8" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">从模型到应用</h1><p id="4223" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">让我们深入研究一下实现细节。这里有 3 个主要部分:</p><ul class=""><li id="03f5" class="mi mj iq ku b kv lr kz ls ld mk lh ml ll mm lp mn mo mp mq bi translated">使用 Keras 创建和训练模型，并为 TensorFlow 服务做准备</li><li id="7696" class="mi mj iq ku b kv mr kz ms ld mt lh mu ll mv lp mn mo mp mq bi translated">实现一个向外界提供 REST API 的包装器服务</li><li id="b8ae" class="mi mj iq ku b kv mr kz ms ld mt lh mu ll mv lp mn mo mp mq bi translated">创建一个简单的狗品种预测和结果显示的应用程序</li></ul><h2 id="0f74" class="lw jv iq bd jw lx ly dn ka lz ma dp ke ld mb mc ki lh md me km ll mf mg kq mh bi translated">犬种检测器模型</h2><p id="339c" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我不想用很多代码把文章弄乱。相反，我将提供实现的链接，并解释我遇到的主要挑战。</p><p id="bc8a" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">我创建模型的方法相当简单(你可以在<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/master/model_serving/dog_breed_detector_trainer.py" rel="noopener ugc nofollow" target="_blank"><em class="mw">dog _ breed _ detector _ trainer . py</em></a>中遵循它)，Francois Chollet 在<a class="ae lq" href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html" rel="noopener ugc nofollow" target="_blank"> Keras 博客</a>中对此做了很好的解释。这些步骤是:</p><ul class=""><li id="6e8d" class="mi mj iq ku b kv lr kz ls ld mk lh ml ll mm lp mn mo mp mq bi translated">用权重加载预训练的 DenseNet 201，不加载顶层，并从预训练的网络中提取所谓的瓶颈特征。我已经在<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/master/model_serving/data_extractor.py" rel="noopener ugc nofollow" target="_blank"><em class="mw">data _ extractor . py</em></a>中实现了这个。</li><li id="f52f" class="mi mj iq ku b kv mr kz ms ld mt lh mu ll mv lp mn mo mp mq bi translated">创建一个简单的顶层模型，该模型使用提取的要素作为输入，并且只有全局平均池和完全连接的图层。模型本身在<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/master/model_serving/dog_breed_detector_model.py" rel="noopener ugc nofollow" target="_blank"><em class="mw">dog _ breed _ detector _ model . py</em></a>中实现。</li><li id="05de" class="mi mj iq ku b kv mr kz ms ld mt lh mu ll mv lp mn mo mp mq bi translated">训练顶级模特并保存检查点。这里 可以找到<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/56150effa31b6c9483d5abd36f8e2727eb082984/model_serving/dog_breed_detector_trainer.py#L77" rel="noopener ugc nofollow" target="_blank"> <em class="mw">。</em></a></li><li id="06d1" class="mi mj iq ku b kv mr kz ms ld mt lh mu ll mv lp mn mo mp mq bi translated">创建“连接”预训练的 DenseNet 201 和训练的顶部模型的最终模型。这在<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/master/model_serving/final_model.py" rel="noopener ugc nofollow" target="_blank"><em class="mw">final _ model . py</em></a>中实现。</li><li id="9660" class="mi mj iq ku b kv mr kz ms ld mt lh mu ll mv lp mn mo mp mq bi translated">为 TensorFlow 服务准备并保存最终模型。你可以在这里 找到<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/56150effa31b6c9483d5abd36f8e2727eb082984/model_serving/dog_breed_detector_trainer.py#L61" rel="noopener ugc nofollow" target="_blank"> <em class="mw">。</em></a></li></ul><p id="e95f" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">主要挑战是找到一种合适的方法将 Keras 模型转换为 TensorFlow，并为 TensorFlow 服务做准备。基本上，我们这里有两个任务:将 Keras 模型转换为<a class="ae lq" href="https://www.tensorflow.org/programmers_guide/estimators" rel="noopener ugc nofollow" target="_blank"> TF 估计器</a>，并将估计器导出为 TensorFlow 服务。</p><p id="e7ea" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">从<a class="ae lq" href="https://developers.googleblog.com/2017/11/announcing-tensorflow-r14.html" rel="noopener ugc nofollow" target="_blank">版本 1.4 </a>开始，我们可以将 Keras 模型转换为 TF 估计量——只需调用<a class="ae lq" href="https://www.tensorflow.org/api_docs/python/tf/keras/estimator/model_to_estimator" rel="noopener ugc nofollow" target="_blank"> model_to_estimator() </a>函数，就大功告成了！</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="ba5a" class="lw jv iq nc b gy ng nh l ni nj">tf_estimator = model_to_estimator(keras_model=model)</span></pre><p id="e2e4" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">现在，我们可以保存估计器，用于这里描述的<a class="ae lq" href="https://www.tensorflow.org/programmers_guide/saved_model" rel="noopener ugc nofollow" target="_blank"/>。这只是一个对<a class="ae lq" href="https://www.tensorflow.org/api_docs/python/tf/estimator/BaselineClassifier#export_savedmodel" rel="noopener ugc nofollow" target="_blank"> export_savedmodel() </a>函数的调用，带有一个用于服务的<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/56150effa31b6c9483d5abd36f8e2727eb082984/model_serving/dog_breed_detector_trainer.py#L42" rel="noopener ugc nofollow" target="_blank">接收器函数。这样一个函数在最终模型之上创建了一个附加层，并负责输入解析。在我们的例子中，它将输入的 JPEG 图像转换成一个 3D 张量，可以被模型使用。</a></p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="2674" class="lw jv iq nc b gy ng nh l ni nj">tf_estimator.export_savedmodel(export_dir,<br/>    serving_input_receiver_fn,<br/>    strip_default_attrs=True)</span></pre><p id="37eb" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">为了创建、训练和准备服务模型，首先安装<em class="mw"> unzip </em>(用于解压缩下载的带有狗图像的档案):</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="35b6" class="lw jv iq nc b gy ng nh l ni nj">sudo apt-get update<br/>sudo apt-get install unzip</span></pre><p id="5688" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">然后克隆存储库，切换到模型服务目录，下载并解压缩狗图像，并训练模型:</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="f956" class="lw jv iq nc b gy ng nh l ni nj">git clone <a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras.git" rel="noopener ugc nofollow" target="_blank">https://github.com/Vetal1977/tf_serving_keras.git</a></span><span id="0791" class="lw jv iq nc b gy nk nh l ni nj">cd tf_serving_keras/model_serving</span><span id="1166" class="lw jv iq nc b gy nk nh l ni nj">curl <a class="ae lq" href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip" rel="noopener ugc nofollow" target="_blank">https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip</a> --output dogImages.zip</span><span id="3a9b" class="lw jv iq nc b gy nk nh l ni nj">unzip dogImages.zip<br/>mv dogImages dog_images<br/>rm dogImages.zip</span><span id="d3c0" class="lw jv iq nc b gy nk nh l ni nj">python dog_breed_detector_trainer.py</span></pre><p id="1995" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">我的环境包括:</p><ul class=""><li id="898f" class="mi mj iq ku b kv lr kz ls ld mk lh ml ll mm lp mn mo mp mq bi translated">康达 4.3.14</li><li id="d2e5" class="mi mj iq ku b kv mr kz ms ld mt lh mu ll mv lp mn mo mp mq bi translated">Python 3.5.4</li><li id="5dfa" class="mi mj iq ku b kv mr kz ms ld mt lh mu ll mv lp mn mo mp mq bi translated">TensorFlow 1.8 的 GPU 版本</li><li id="5e06" class="mi mj iq ku b kv mr kz ms ld mt lh mu ll mv lp mn mo mp mq bi translated">Keras 2.1.6</li></ul><h2 id="fd30" class="lw jv iq bd jw lx ly dn ka lz ma dp ke ld mb mc ki lh md me km ll mf mg kq mh bi translated">Node.js 包装服务</h2><p id="ba05" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">第二个组件是一个<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/tree/master/detector-api" rel="noopener ugc nofollow" target="_blank">包装器服务</a>，它向外界提供 RESTful API，并将 gRPC 与 TensorFlow 服务器对话。附加要求—尽可能减少对 TensorFlow 的依赖。我为服务实现选择了 Node.js 和 Typescript。</p><p id="414a" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">第一步是准备 proto bufs——我把它们从<a class="ae lq" href="https://github.com/tensorflow/serving/tree/master/tensorflow_serving/apis" rel="noopener ugc nofollow" target="_blank">官方仓库</a>中拿出来，扔掉所有我不需要的东西。你可以在这里修改我的版本<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/tree/master/detector-api/src/protos" rel="noopener ugc nofollow" target="_blank"/>。我动态加载 protobufs，即在运行时，然后创建一个预测服务，如下所示:</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="4784" class="lw jv iq nc b gy ng nh l ni nj">this.tfServing = grpc.load(this.PROTO_PATH).tensorflow.serving;<br/>this.client = new this.tfServing.PredictionService(<br/>    this.tfServerUrl, grpc.credentials.createInsecure());</span></pre><p id="d766" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">动态加载的优点是——您不需要通过每次修改 protobufs 来重新生成 Typescript 代码。缺点是性能下降。因为我只加载了一次 protobufs，所以这个缺点并不严重。</p><p id="7d7d" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">现在，当通过 REST 接口调用服务时，我们获取输入数据(图像作为 base64 编码的字符串)并向 TensorFlow 服务器创建 gRPC 请求—请在<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/56150effa31b6c9483d5abd36f8e2727eb082984/detector-api/src/services/tf.serving.client.ts#L48" rel="noopener ugc nofollow" target="_blank">源</a>中找到详细信息。</p><p id="bd2f" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">包装器服务是一个<a class="ae lq" href="https://expressjs.com/" rel="noopener ugc nofollow" target="_blank"> Node.js express </a>应用程序，使用<a class="ae lq" href="https://github.com/inversify/InversifyJS" rel="noopener ugc nofollow" target="_blank"><em class="mw">inverisfy</em></a>进行依赖注入，使用<a class="ae lq" href="https://github.com/inversify/inversify-express-utils" rel="noopener ugc nofollow" target="_blank"> <em class="mw"> inverisfy express 实用程序</em> </a>进行 REST API 实现。</p><p id="c46f" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">我的服务的 API 基本路径是<em class="mw"> /api/v1 </em>，我的控制器实现了唯一的端点<em class="mw"> /predict_breed </em>，它允许图片上传并在 TensorFlow 服务器上调用狗的品种预测。要构建一个项目，请执行以下命令(我假设您已经克隆了 repo):</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="3f76" class="lw jv iq nc b gy ng nh l ni nj">cd tf_serving_keras/detector-api<br/>npm install<br/>npm build</span></pre><p id="0b01" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">我的环境包括节点 8.11.3 和 npm 6.1.0。</p><h2 id="82fa" class="lw jv iq bd jw lx ly dn ka lz ma dp ke ld mb mc ki lh md me km ll mf mg kq mh bi translated">角度应用</h2><p id="27fd" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">最后一部分是一个简单的<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/tree/master/detector-app" rel="noopener ugc nofollow" target="_blank">角度应用</a>，带有一个按钮来选择一个图像目录和一个区域，用于显示带有预测品种名称的图像。这里没有什么新奇的东西——我使用<a class="ae lq" href="https://angular.io/guide/quickstart" rel="noopener ugc nofollow" target="_blank">这个指南</a>创建了一个新的 Angular 项目，并根据我的需要扩展了代码。</p><p id="4884" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">与包装器服务对话的客户端在<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/master/detector-app/src/app/services/detector.service.api.client.ts" rel="noopener ugc nofollow" target="_blank"><em class="mw">detector . service . API . client . ts</em></a>中实现。实现的注意事项——我有一个<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/master/detector-app/src/app/services/detector.service.client.ts" rel="noopener ugc nofollow" target="_blank">抽象类</a>,它声明了一个预测方法和它的两个实现——上面提到了其中一个，第二个是我尝试使用一个全新的<a class="ae lq" href="https://www.tensorflow.org/serving/api_rest" rel="noopener ugc nofollow" target="_blank">tensor flow Serving RESTful API</a>。稍后我会提供一些评论。</p><p id="e8e9" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">我们需要注意<a class="ae lq" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS" rel="noopener ugc nofollow" target="_blank"> CORS </a>机制。<a class="ae lq" href="https://angular.io/guide/http" rel="noopener ugc nofollow" target="_blank"> Angular HttpClient </a>依赖于<a class="ae lq" href="https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest" rel="noopener ugc nofollow" target="_blank"> XMLHttpRequest </a>，我不得不将<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/b5b88be4988ebbc15e254822a83d859f9b5ec382/detector-api/src/api/detector.controller.ts#L43" rel="noopener ugc nofollow" target="_blank">的后续头</a>添加到我的<em class="mw"> Node.js 包装服务</em>中，以获得应用程序中的响应:</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="b712" class="lw jv iq nc b gy ng nh l ni nj">'Access-Control-Allow-Origin': '*'</span></pre><p id="7691" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">这是一个典型的应用程序屏幕，上面有狗的图像和预测的品种:</p><figure class="mx my mz na gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="nm nn di no bf np"><div class="gh gi nl"><img src="../Images/a6c8c85b5afc251b8058190ea4df0d70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NjqPHWtD0XBm5q1eRk45ow.png"/></div></div></figure><p id="de0d" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">要构建一个项目，执行以下命令(我假设您已经克隆了 repo):</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="b7be" class="lw jv iq nc b gy ng nh l ni nj">cd tf_serving_keras/detector-app<br/>npm install<br/>npm build</span></pre><h1 id="3865" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">使用 Docker 进行本地测试</h1><p id="1e7c" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">老实说，我懒得分别启动和运行所有 3 个组件:-) <a class="ae lq" href="https://docs.docker.com/" rel="noopener ugc nofollow" target="_blank"> Docker </a>和<a class="ae lq" href="https://docs.docker.com/compose/" rel="noopener ugc nofollow" target="_blank"> Docker Compose </a>让我的生活更轻松。我需要 3 个 Docker 容器——一个用于托管我的模型的 TensorFlow 服务，一个用于包装服务，一个用于我的应用程序。我安装了以下版本:Docker 18.03.1-ce 和 Docker Compose 1.21.2。</p><h2 id="4114" class="lw jv iq bd jw lx ly dn ka lz ma dp ke ld mb mc ki lh md me km ll mf mg kq mh bi translated">TensorFlow 服务的 Docker 图像</h2><p id="2731" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">在创建 Docker 映像之前，您必须有一个为 TensorFlow 服务的导出模型——请参见上文如何操作。<a class="ae lq" rel="noopener" target="_blank" href="/how-to-deploy-machine-learning-models-with-tensorflow-part-2-containerize-it-db0ad7ca35a7">上次</a>为 TensorFlow 服务创建 Docker 容器花费了很多精力。从那以后事情发生了变化，现在我们可以用<em class="mw"> apt-get </em>安装服务组件，而不需要克隆存储库和自己构建服务器。</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="1aaf" class="lw jv iq nc b gy ng nh l ni nj">echo "deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list</span><span id="49bc" class="lw jv iq nc b gy nk nh l ni nj">curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -</span><span id="aa15" class="lw jv iq nc b gy nk nh l ni nj">sudo apt-get update &amp;&amp; sudo apt-get install tensorflow-model-server</span></pre><p id="94cb" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">我创建了一个<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/master/model_serving/Dockerfile" rel="noopener ugc nofollow" target="_blank"> Dockerfile </a>，在这里我执行了那些命令，复制了为服务模型准备的内容并启动了服务器。如果要创建 Docker 映像，请执行以下命令:</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="3f9d" class="lw jv iq nc b gy ng nh l ni nj">cd tf_serving_keras/model_serving<br/>&lt;activate your Python environment&gt;<br/>python dog_breed_detector_trainer.py<br/>docker build -t model-serving:latest -f Dockerfile .</span></pre><h2 id="9d65" class="lw jv iq bd jw lx ly dn ka lz ma dp ke ld mb mc ki lh md me km ll mf mg kq mh bi translated">Node.js 包装服务的 Docker 图像</h2><p id="ae84" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">包装器服务的<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/master/detector-api/Dockerfile" rel="noopener ugc nofollow" target="_blank"> Dockerfile </a>基于节点 8.11.3 镜像。它将源文件复制到映像，构建它们并启动服务。没什么特别的，都是标准的。</p><h2 id="45e1" class="lw jv iq bd jw lx ly dn ka lz ma dp ke ld mb mc ki lh md me km ll mf mg kq mh bi translated">角度应用的 Docker 图像</h2><p id="580e" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我的应用程序的<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/master/detector-app/Dockerfile" rel="noopener ugc nofollow" target="_blank"> Dockerfile </a>使用了<a class="ae lq" href="https://docs.docker.com/develop/develop-images/multistage-build/" rel="noopener ugc nofollow" target="_blank">多阶段构建</a>。首先，我们使用 Node 8.11.3 image 构建应用程序，然后使用 Nginx image 将其隐藏在 Nginx 服务器后面，这在生产环境中很有意义。</p><h2 id="1059" class="lw jv iq bd jw lx ly dn ka lz ma dp ke ld mb mc ki lh md me km ll mf mg kq mh bi translated">将它们组合在一起</h2><p id="ae2a" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们不会也不应该一个接一个地创建 3 个 Docker 容器。相反，我们将它们组合在一起，并用 Docker Compose 使它们彼此可见。在<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/master/docker.compose.yaml" rel="noopener ugc nofollow" target="_blank"> docker-compose </a>文件中，我有 3 个服务，属于同一个网络。应用依赖于包装器服务，包装器服务依赖于 TensorFlow 服务。这些服务公开了容器端口，并且可以通过它们的名称相互通信。</p><p id="b3d9" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">要运行完整的应用程序，请执行唯一的命令</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="057e" class="lw jv iq nc b gy ng nh l ni nj">cd tf_serving_keras<br/>docker-compose -f docker.compose.yaml up</span></pre><p id="14a0" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">打开浏览器，进入<em class="mw">本地主机</em>。您应该能够看到应用程序，选择图像并看到结果。不要忘记关闭容器</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="c3b3" class="lw jv iq nc b gy ng nh l ni nj">docker-compose -f docker.compose.yaml down</span></pre><h1 id="0b87" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">尝试 TensorFlow Serving 1.8 及其 RESTful API</h1><p id="c37a" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">当我准备好我的实现时，我发现从 1.8 版本开始 TensorFlow 服务也提供了 RESTful API。这是一个相当新的功能，我想尝试一下。</p><p id="df62" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">不幸的是，它有一些问题。首先，对于 CORS 机制，您必须有一种特殊的代理，因为您不能更改服务器代码。最受欢迎的是<a class="ae lq" href="https://github.com/Rob--W/cors-anywhere" rel="noopener ugc nofollow" target="_blank"> cors-anywhere </a>。我创建了一个<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/tree/master/cors-anywhere" rel="noopener ugc nofollow" target="_blank">小包装器</a>并将其打包到 Docker 容器中。如前所述，我在应用程序中实现了一个<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/master/detector-app/src/app/services/detector.service.tf.client.ts" rel="noopener ugc nofollow" target="_blank">客户端</a>，它通过 REST 直接与 TensorFlow 服务器对话。</p><p id="1fc5" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">其次，应该将图像数据包含在发送给服务器的 JSON 对象中。对于大图像，这不是一个正确的方法，我总是倾向于使用<em class="mw">多部分/形式数据</em>来实现这个目的。</p><p id="a53c" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">如果您想尝试，请查看客户端源代码，并使用</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="b1aa" class="lw jv iq nc b gy ng nh l ni nj">docker-compose -f docker.compose.cors.yaml up</span></pre><h1 id="f7e8" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">GPU 支持</h1><p id="2995" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">如果你有一台装有 NVidia 显卡的电脑，并且安装了 CUDA 和 CUDnn 库，那么我们也可以在 Docker 中使用它们。但是我们需要做一些准备:</p><ul class=""><li id="6890" class="mi mj iq ku b kv lr kz ls ld mk lh ml ll mm lp mn mo mp mq bi translated">确保 Docker Compose 的版本至少是 1.19.0</li><li id="1189" class="mi mj iq ku b kv mr kz ms ld mt lh mu ll mv lp mn mo mp mq bi translated"><a class="ae lq" href="https://github.com/nvidia/nvidia-container-runtime" rel="noopener ugc nofollow" target="_blank">安装 NVidia 容器运行时</a>。我使用了以下命令:</li></ul><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="4639" class="lw jv iq nc b gy ng nh l ni nj">curl -s -L https://nvidia.github.io/nvidia-container-runtime/gpgkey | \<br/>  sudo apt-key add -</span><span id="1f04" class="lw jv iq nc b gy nk nh l ni nj">distribution<strong class="nc ir">=$(</strong>. /etc/os-release;echo $ID$VERSION_ID<strong class="nc ir">)</strong></span><span id="a19c" class="lw jv iq nc b gy nk nh l ni nj">curl -s -L https://nvidia.github.io/nvidia-container-runtime/$distribution/nvidia-container-runtime.list | \<br/>  sudo tee /etc/apt/sources.list.d/nvidia-container-runtime.list</span><span id="de98" class="lw jv iq nc b gy nk nh l ni nj">sudo apt-get update</span><span id="bbea" class="lw jv iq nc b gy nk nh l ni nj">sudo apt-get install nvidia-container-runtime</span></pre><ul class=""><li id="1215" class="mi mj iq ku b kv lr kz ls ld mk lh ml ll mm lp mn mo mp mq bi translated"><a class="ae lq" href="https://github.com/nvidia/nvidia-container-runtime#docker-engine-setup" rel="noopener ugc nofollow" target="_blank">通过 Docker </a>注册该运行时。我对守护程序配置文件使用了该方法:</li></ul><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="c706" class="lw jv iq nc b gy ng nh l ni nj">sudo tee /etc/docker/daemon.json &lt;&lt;EOF<br/>{<br/>    "runtimes": {<br/>        "nvidia": {<br/>            "path": "/usr/bin/nvidia-container-runtime",<br/>            "runtimeArgs": []<br/>        }<br/>    }<br/>}<br/>EOF<br/>sudo pkill -SIGHUP dockerd</span></pre><p id="dc79" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">现在快跑</p><pre class="mx my mz na gt nb nc nd ne aw nf bi"><span id="0417" class="lw jv iq nc b gy ng nh l ni nj">docker-compose -f docker.compose.gpu.yaml up</span></pre><p id="fda5" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated">你应该得到一个 GPU 驱动的应用程序版本。你可以在资源库中找到支持 GPU 的<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/master/model_serving/Dockerfile.gpu" rel="noopener ugc nofollow" target="_blank"> Dockerfile </a>和<a class="ae lq" href="https://github.com/Vetal1977/tf_serving_keras/blob/master/docker.compose.gpu.yaml" rel="noopener ugc nofollow" target="_blank"> Docker-compose </a>文件。</p><p id="07ba" class="pw-post-body-paragraph ks kt iq ku b kv lr kx ky kz ls lb lc ld lt lf lg lh lu lj lk ll lv ln lo lp ij bi translated"><strong class="ku ir">注意</strong>:可能需要几个小时才能看到系统启动并运行。原因是——我们仍然需要编译 TensorFlow 的 GPU 版本来创建一个合适的 Docker 图像。</p><h1 id="a43a" class="ju jv iq bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">结论</h1><p id="748c" class="pw-post-body-paragraph ks kt iq ku b kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">对我来说，实现从 Keras 模型到 UI 的完整深度学习应用程序是一次很好的体验。我尝试和使用了一些新的东西，并且为了在本地运行和测试所有东西，我需要解决一些挑战。我希望这对您的目的也有用:-)</p></div></div>    
</body>
</html>