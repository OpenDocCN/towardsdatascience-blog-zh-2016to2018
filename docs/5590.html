<html>
<head>
<title>How to Engineer Your Way Out of Slow Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何走出缓慢的模式</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-engineer-your-way-out-of-slow-models-e62568f02fde?source=collection_archive---------8-----------------------#2018-10-28">https://towardsdatascience.com/how-to-engineer-your-way-out-of-slow-models-e62568f02fde?source=collection_archive---------8-----------------------#2018-10-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/5bf0d5ed9ac1fd1041314822799ccb01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sI03rFHDEkZttdKX43RDag.jpeg"/></div></div></figure><p id="9b8a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">你刚刚完成了你那个伟大的神经网络架构的设计。它有数量惊人的 300 个完全连接的层，与 200 个各有 20 个通道的卷积层交织在一起，其结果被作为一个光荣的<a class="ae kz" href="https://en.wikipedia.org/wiki/Bidirectional_recurrent_neural_networks" rel="noopener ugc nofollow" target="_blank">双向</a> <a class="ae kz" href="https://machinelearningmastery.com/stacked-long-short-term-memory-networks/" rel="noopener ugc nofollow" target="_blank">堆叠</a> <a class="ae kz" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank"> LSTM </a>的种子，并受到少量<a class="ae kz" href="http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/" rel="noopener ugc nofollow" target="_blank">关注</a>。训练后，你获得了 99.99%的准确率，你就可以把它投入生产了。</p><p id="e58c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">但是随后您意识到生产约束不允许您使用这个工具进行推理。你需要在 200 毫秒内完成推断。</p><p id="0b5c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">换句话说，你需要砍掉一半的层，放弃使用卷积，让我们不要开始昂贵的 LSTM…</p><p id="6d4f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">要是你能让那个神奇的模型更快就好了！</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi la"><img src="../Images/b314863945cfed0ba782e67f87f910d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tJMHl13JTiN4Sg9j7_YuVQ.jpeg"/></div></div></figure><h1 id="3ce5" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">有时候你可以</h1><p id="560e" class="pw-post-body-paragraph kb kc it kd b ke md kg kh ki me kk kl km mf ko kp kq mg ks kt ku mh kw kx ky im bi translated">在塔布拉，我们做到了。嗯，不完全是…让我解释一下。</p><p id="2dd3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们的一个模型必须预测一个项目的点击率，或者换句话说，用户喜欢一篇推荐文章并点击它的概率。</p><p id="e758" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该模型有多个模态作为输入，每个模态都经历不同的转换。其中一些是:</p><ul class=""><li id="7f03" class="mi mj it kd b ke kf ki kj km mk kq ml ku mm ky mn mo mp mq bi translated">分类特征:这些特征<a class="ae kz" href="https://engineering.taboola.com/using-word2vec-better-embeddings-categorical-features/" rel="noopener ugc nofollow" target="_blank">嵌入</a>到一个密集的表示中</li><li id="1c5f" class="mi mj it kd b ke mr ki ms km mt kq mu ku mv ky mn mo mp mq bi translated">图像:像素通过卷积层和全连接层</li><li id="c2dd" class="mi mj it kd b ke mr ki ms km mt kq mu ku mv ky mn mo mp mq bi translated">文本:在被标记后，文本通过 LSTM，接着是<a class="ae kz" href="https://arxiv.org/abs/1703.03130" rel="noopener ugc nofollow" target="_blank">自我关注</a></li></ul><p id="c674" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">然后，这些处理过的模态通过完全连接的层，以学习模态之间的交互，最后，它们通过<a class="ae kz" href="https://engineering.taboola.com/uncertainty-ctr-prediction-one-model-clarify" rel="noopener ugc nofollow" target="_blank"> MDN </a>层。</p><p id="7281" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">可想而知，这种模式很慢。</p><p id="1327" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们决定坚持模型的预测能力，而不是修整组件，并提出了一个工程解决方案。</p><h1 id="8707" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">如果可以的话，请把我藏起来</h1><p id="7b65" class="pw-post-body-paragraph kb kc it kd b ke md kg kh ki me kk kl km mf ko kp kq mg ks kt ku mh kw kx ky im bi translated">让我们把重点放在图像组件上。该组件的输出是图像的学习表示。换句话说，给定一个图像，图像组件输出一个嵌入。</p><p id="d9a9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">该模型是确定性的，因此给定相同的图像将导致相同的嵌入。这是很昂贵的，所以我们可以缓存它。我来详细说说我们是怎么实现的。</p><h1 id="2632" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">(缓存的，而不是模型的)架构</h1><figure class="lb lc ld le gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mw"><img src="../Images/804f7d07422b451e3adbe4f8da596bf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z7uK0SVlX6-qQUU_eEJKDw.png"/></div></div></figure><ul class=""><li id="b5bc" class="mi mj it kd b ke kf ki kj km mk kq ml ku mm ky mn mo mp mq bi translated">我们使用一个<a class="ae kz" href="http://cassandra.apache.org/" rel="noopener ugc nofollow" target="_blank"> Cassandra </a>数据库作为缓存，将图像 URL 映射到它的嵌入。</li><li id="afb3" class="mi mj it kd b ke mr ki ms km mt kq mu ku mv ky mn mo mp mq bi translated">查询 Cassandra 的服务叫做 EmbArk(嵌入存档，<a class="ae kz" href="https://techcrunch.com/2017/05/20/the-bizarre-naming-trends-that-modern-startups-follow/" rel="noopener ugc nofollow" target="_blank">当然拼错了</a>)。这是一个<a class="ae kz" href="https://grpc.io/" rel="noopener ugc nofollow" target="_blank"> gRPC </a>服务器，它从客户端获取图像 URL，并从 Cassandra 检索嵌入内容。在缓存未命中时，EmbArk 发送一个异步请求来嵌入该映像。为什么是异步？因为我们需要尽可能快地对结果做出反应。鉴于它不能等待图像被嵌入，它返回一个特殊的 OOV(不在词汇表中)嵌入。</li><li id="dbcc" class="mi mj it kd b ke mr ki ms km mt kq mu ku mv ky mn mo mp mq bi translated">我们选择使用的异步机制是<a class="ae kz" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank">Kafka</a>——一个用作消息队列的流媒体平台。</li><li id="a4c6" class="mi mj it kd b ke mr ki ms km mt kq mu ku mv ky mn mo mp mq bi translated">下一个链接是 KFC (Kafka 前端客户端)—我们实现的 Kafka 消费者，用于将消息同步传递到嵌入服务，并将结果嵌入保存在 Cassandra 中。</li><li id="1828" class="mi mj it kd b ke mr ki ms km mt kq mu ku mv ky mn mo mp mq bi translated">嵌入服务被称为视网膜。它从肯德基获得一个图像 URL，下载它，预处理它，并评估卷积层以获得最终的嵌入。</li><li id="93ab" class="mi mj it kd b ke mr ki ms km mt kq mu ku mv ky mn mo mp mq bi translated">使用<a class="ae kz" href="https://linkerd.io/" rel="noopener ugc nofollow" target="_blank">链接器</a>完成所有组件的负载平衡。</li><li id="1b0c" class="mi mj it kd b ke mr ki ms km mt kq mu ku mv ky mn mo mp mq bi translated">EmbArk，KFC，Retina，Linkerd 在<a class="ae kz" href="https://www.docker.com/" rel="noopener ugc nofollow" target="_blank"> Docker </a>内部运行，由<a class="ae kz" href="https://www.nomadproject.io/" rel="noopener ugc nofollow" target="_blank"> Nomad </a>编排。这使我们可以根据自己的需要轻松扩展每个组件。</li></ul><p id="c722" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这种架构最初用于图像。在证明了它的价值之后，我们决定将它用于其他组件，比如文本。</p><p id="52f0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">EmbArk 对迁移学习来说也是一个很好的解决方案。假设我们相信图像的内容具有预测 CTR 的良好信号。因此，一个被训练用来对图像中的物体进行分类的模型，比如<a class="ae kz" href="https://ai.googleblog.com/2016/03/train-your-own-image-classifier-with.html" rel="noopener ugc nofollow" target="_blank">《盗梦空间》</a>，对于我们的需求来说是有价值的。我们可以将 Inception 加载到 Retina 中，告诉我们打算训练的模型，我们要使用 Inception 嵌入，就这样。</p><p id="14f9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">不仅提高了推理时间，还改进了训练过程。只有当我们不想进行端到端的训练时，这才是可能的，因为梯度不能通过 EmbArk 反向传播。</p><p id="9379" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">所以当你在生产中使用模型时，你应该使用 EmbArk，对吗？嗯，不总是…</p><figure class="lb lc ld le gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mx"><img src="../Images/6be9413539d267ce1abe263f9d09998d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JAX1bI6k_rW13EmEqg_aRA.jpeg"/></div></div></figure><h1 id="aa5a" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">警告</h1><p id="f668" class="pw-post-body-paragraph kb kc it kd b ke md kg kh ki me kk kl km mf ko kp kq mg ks kt ku mh kw kx ky im bi translated">这里有三个非常严格的假设。</p><h2 id="0962" class="my lg it bd lh mz na dn ll nb nc dp lp km nd ne lt kq nf ng lx ku nh ni mb nj bi translated">1.新输入的 OOV 嵌入不是一件大事</h2><p id="0b61" class="pw-post-body-paragraph kb kc it kd b ke md kg kh ki me kk kl km mf ko kp kq mg ks kt ku mh kw kx ky im bi translated">当我们第一次看到一幅图像时，我们不会有它的嵌入，这不会伤害我们。</p><p id="f230" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在我们的生产系统中，这是可以的，因为在很短的时间内，同一项目的 CTR 会被评估多次。我们每隔几分钟就创建一个我们想要推荐的商品列表，所以即使一个商品因为非最佳点击率预测而没有进入列表，它也会在下一个周期出现。</p><h2 id="36d0" class="my lg it bd lh mz na dn ll nb nc dp lp km nd ne lt kq nf ng lx ku nh ni mb nj bi translated">2.新投入的比率很低</h2><p id="6bd4" class="pw-post-body-paragraph kb kc it kd b ke md kg kh ki me kk kl km mf ko kp kq mg ks kt ku mh kw kx ky im bi translated">的确，在 Taboola，我们一直都有很多新商品。但是相对于我们需要对已知项目进行的推理数量来说，这并不算多。</p><h2 id="c134" class="my lg it bd lh mz na dn ll nb nc dp lp km nd ne lt kq nf ng lx ku nh ni mb nj bi translated">3.嵌入不会经常改变</h2><p id="3699" class="pw-post-body-paragraph kb kc it kd b ke md kg kh ki me kk kl km mf ko kp kq mg ks kt ku mh kw kx ky im bi translated">因为嵌入是缓存的，所以我们相信它们不会随时间而改变。如果是这样，我们将需要执行缓存失效，并使用 Retina 重新计算嵌入。如果这种情况经常发生，我们将失去架构的优势。对于像 inception 或语言建模这样的情况，这种假设成立，因为语义不会随着时间的推移而显著改变。</p><h1 id="948a" class="lf lg it bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">一些最后的想法</h1><p id="f2f8" class="pw-post-body-paragraph kb kc it kd b ke md kg kh ki me kk kl km mf ko kp kq mg ks kt ku mh kw kx ky im bi translated">有时，使用最先进的模型会因其计算需求而产生问题。通过缓存中间结果(嵌入),我们能够克服这一挑战，并且仍然享受最先进的结果。</p><p id="a64b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这种解决方案并不适合所有人，但是如果上述三个假设适用于您的应用程序，您可以考虑使用类似的架构。</p><p id="77ca" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">通过使用微服务范式，该公司的其他团队能够使用 EmbArk 来满足 CTR 预测之外的需求。例如，一个团队使用 EmbArk 来获得图像和文本嵌入，以检测不同项目之间的重复。但是我会把这个故事留给另一篇文章…</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><p id="af48" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">【engineering.taboola.com】<em class="nr"><em class="nr">最初由我在</em> <a class="ae kz" href="https://engineering.taboola.com/engineer-way-slow-models" rel="noopener ugc nofollow" target="_blank"> <em class="nr">发表。</em></a></em></p></div></div>    
</body>
</html>