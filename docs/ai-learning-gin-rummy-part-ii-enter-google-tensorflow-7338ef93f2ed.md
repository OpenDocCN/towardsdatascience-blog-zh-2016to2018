# 人工智能学习金拉米，第二部分(输入 Google TensorFlow)

> 原文：<https://towardsdatascience.com/ai-learning-gin-rummy-part-ii-enter-google-tensorflow-7338ef93f2ed?source=collection_archive---------1----------------------->

上一篇描述的[手造策略可以用它的手评估函数来表示:](https://medium.com/@markfasciano/learning-gin-rummy-part-i-75aef02c94ba)

```
E = Wh
```

其中 ***E*** 是代表手牌评价(或你手中牌的相对值……值越高越想保留)的 1×52 矩阵， ***W*** 是应用于手牌的权重的 52×52 矩阵， ***h*** 是代表手牌的 1×52 矩阵。我们如何从上一篇文章中描述的代表手的 4 x 13 矩阵发展到这里的 1 x 52 矩阵？我刚刚展平了 4 x 13 的矩阵。 ***W*** 然后，表示该副牌中的每张牌与该副牌中其他每张牌的关系。

您可能会注意到，这与之前描述的卷积矩阵不同，后者只是考虑了水平和垂直相邻的 2-3 个单元。然而，一个 52×52 的矩阵可以计算出与应用于手中每张牌的卷积矩阵相同的函数。

那么我如何从之前的 7 x 7 卷积矩阵:

![](img/79435742c75b4258c23193610567f359.png)

一个 52 x 52 的矩阵来计算同样的函数？手工做起来并不难，但是输入 w 的所有 2704 个值会很无聊，而且计算机科学家很懒。用机器学习帮我搞清楚不是更好吗？为什么不用谷歌投入 TensorFlow 的数百万美元研发资金在这里工作呢？

## 谷歌张量流

谷歌的[机器学习开源库](https://www.tensorflow.org)有方便的 Python 库，以及一些非常漂亮的介绍文档，包括一个非常有用的注释系统，实现了监督学习手写数字 MNIST 数据集的线性模型，这是一个研究机器学习计算机视觉的热门领域。

我使用 TensorFlow 的目标非常简单:计算出一个 52 x 52 的矩阵，它与我在 gin rummy hand evaluator 上计算的 7 x 7 卷积矩阵具有相同的功能。所以有几件事可以让 TensorFlow 继续下去:

1.  设置培训数据
2.  建立输入、输出和参数
3.  建立模型
4.  指定要优化的损失函数

## 金拉米培训数据

我使用的训练数据是 1)玩家的手牌(4 x 13 矩阵)和 2)结果手牌评估(也是 4 x 13 矩阵)的配对。在我手工构建的系统中，这是使用上面的卷积矩阵计算的。为了生成这些训练数据，我让 gin rummy 程序自己玩了几千场游戏，每次它评估一手牌时，它都会保存手牌/手牌评估对。例如，假设我们有一手牌:

![](img/6600831a9b0d9a7fee59c933c5d40bc5.png)

并且手工构建的系统生成以下手工评估:

![](img/581c1d1c386fad6df9cbe4e73e375c36.png)

因此，训练数据总计有几千对，就像这两个一样，只是它们不是像上面那样的 4 x 13 矩阵(更容易阅读)，而是扁平的 1 x 52 矩阵。

## 张量流的输入、输出和参数

告诉 TensorFlow 哪个是输入(手牌)哪个是输出(手牌评估或牌组值)的代码很容易指定:

```
# Model input and output
h = tf.placeholder(tf.float32, [None, 52], name="hand")       # h = hand
d = tf.placeholder(tf.float32, [None, 52], name="deck_value") # d = deck value
```

这里的参数是 W，52 x 52 矩阵，它的种子是随机值:

```
# Model parameter
W = tf.Variable(tf.random_normal([52, 52], stddev=0.35), name="weights")
```

## 模型

我为这个小练习选择的模型是一个简单的线性模型，E = Wh。TensorFlow 的便利之处在于能够使用声明性方法来设置神经网络，而不是必须对它们进行功能性编程。

```
# Model
linear_model = tf.matmul(h, W) 
```

## 损失和优化器

损失函数是一个标量，当它的机器学习算法应用优化器来引导它找到解决方案时，它测量参数的试验版本 ***W*** 之间的差异。损失测量是平方和。优化器是梯度下降，许多机器学习应用程序中使用的标准优化器。你需要为梯度下降提供一个增量/减量参数，在找到一个可以收敛到这个解的解之前，我不得不做一些实验。

```
# Loss
loss = tf.reduce_sum(tf.square(linear_model - d)) # Optimizer
optimizer = tf.train.GradientDescentOptimizer(0.0001)  
train = optimizer.minimize(loss) 
```

## 矩阵学习结果

那么 ***W*** ，得到的 52×52 矩阵是什么样子的呢？用色标显示矩阵，深绿色代表较高的数字:

![](img/eddef9f47cc72e4bff8409f05597ff98.png)

很高兴我不用把这些都输入进去。

## 下一站:更有趣的机器学习

TensorFlow 的这个用法非常简单，是如何使用它的一个很好的例子。然而，它本身并没有解决一个有趣的问题，它只是给作为程序员的我提供了一个便利。更有趣的是发现一种比我亲手制作的金拉米游戏玩得更好的算法。这种新算法会考虑更多的游戏信息。它如何学习？它必须和自己玩很多很多的游戏…