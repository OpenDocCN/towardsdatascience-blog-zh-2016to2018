<html>
<head>
<title>ConvNets Series. Spatial Transformer Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ConvNets系列。空间变压器网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convnets-series-spatial-transformer-networks-cff47565ae81?source=collection_archive---------0-----------------------#2017-09-19">https://towardsdatascience.com/convnets-series-spatial-transformer-networks-cff47565ae81?source=collection_archive---------0-----------------------#2017-09-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="38ab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">空间转换器是不同模块集合中的另一个乐高积木。它通过应用可学习的仿射变换然后进行插值来消除图像的空间不变性。STN模块可以放在卷积神经网络(CNN)中，它主要靠自己工作。</p><p id="fecf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个项目的完整代码可以在GitHub上找到:【https://github.com/dnkirill/stn_idsia_convnet T2】</p><p id="5df0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">为了对STN做什么有一些直觉，请看下面我的项目中的两个演示:</strong></p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi kn"><img src="../Images/9ad6e8c4896a26fd942ba59c2166dbe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/1*gdq8TIMWLvHzODiXgBywHw.gif"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Left image: an original input image from traffic signs dataset. Right image: same image transformed by STN. <strong class="bd kz">Spatial transformers learn what part of an image is the most important and scale or rotate the image to focus on this part.</strong></figcaption></figure><p id="c09e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本帖中，我们将回顾STN模块的内部工作，并将其与<strong class="jp ir">一个对德国交通标志数据集</strong>进行分类的卷积神经网络结合使用。我们将构建它们:STN和分类器。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi kn"><img src="../Images/a4ce776ff576a71627f0618fddd70d2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/1*J6FfW3t-opkKM1RU00yH9A.gif"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Another example of STN learning and transformation. This is just the first epoch of training. It is clear how the STN learns the sign representation and focuses on the sign itself.</figcaption></figure><p id="2997" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">STN检测甚至在更困难的情况下也能工作(例如，图像上的两个标志)。不过，最重要的是，STN确实提高了分类器的准确性(在我的例子中是IDSIA)。</p><h1 id="8e50" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">空间变压器网络的绝对最小速成课程</h1><p id="76f4" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">卷积神经网络的问题在于它缺乏对输入变化的鲁棒性。这些变化包括比例、视点变化、背景混乱以及更多的变化。一些不变性可以通过池化操作来实现，池化操作只是对导致信息丢失的特征图进行下采样。</p><p id="0e3e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不幸的是，由于标准2×2池的小感受野，它仅在更靠近输出层的较深层中提供空间不变性。此外，池化不提供任何旋转或缩放不变性。凯文·扎克卡在他的帖子中对这个事实<a class="ae km" href="https://kevinzakka.github.io/2017/01/18/stn-part2/" rel="noopener ugc nofollow" target="_blank">提供了一个很好的解释。</a></p><p id="d3cc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使模型对这些变化稳健的基本且最常用的方法是像我们在<a class="ae km" href="https://medium.com/towards-data-science/convnets-series-image-processing-tools-of-the-trade-36e168836f0c" rel="noopener">上一篇文章</a>中所做的那样扩充数据集:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi md"><img src="../Images/0a57446bd8f861c05504b544af5e0974.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*hzaHuJqTOAbEbcqr9d-Hmg.gif"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Augmented images. In this post, we will use no augmentations at all.</figcaption></figure><p id="1db1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种方法没有错，但是我们可能希望开发一种更加智能和自动化的方法来准备图像。这种方法应该有助于分类器得出正确的、更确定的预测。这就是空间转换器网络或STN模块发挥作用的地方。<strong class="jp ir">通俗地说，STN是一种旋转或缩放输入图像或特征地图的机制，目的是聚焦在目标对象上，并消除旋转变化</strong>。STNs最显著的特征之一是它们的模块化(模块可以被注入到模型的任何部分)以及它们能够在不修改初始模型的情况下用单个反向传播算法进行训练。</p><p id="5aee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是另一张图片，让你对STN有一个直观的认识:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/cf1ad92752b1aedfe24564c19a3749e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*Sacp8VpjqC0EBaFJs5fjjQ.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Cluttered MNIST example from the <a class="ae km" href="http://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf" rel="noopener ugc nofollow" target="_blank">original paper</a>. Cluttered MNIST (left) original image, target object detected by STN (center), transformed image (right).</figcaption></figure><p id="f70b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果我们排除学习部分，STN模块可以归结为以下过程:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi mj"><img src="../Images/d82a74e6fcd88b2d2b8787e23ab92b6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xlcB8KNrlOnkDxxplyTqgA.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Four steps of applying a STN transformation given that the transformation matrix 𝛳 is defined.</figcaption></figure><p id="47d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在下一节中，我们将更深入地探讨这一过程，并更仔细地观察转换的每一步。</p><h1 id="3e08" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">STN:转型的步骤</h1><p id="706c" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated"><strong class="jp ir">第一步。</strong>定义描述线性变换本身的变换矩阵𝛳(θ)。θ可定义如下:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/88dee309540adf01f6a6850837cbd126.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*v_7bX9Zt821mGCXaLk4JZw.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Affine transformation matrix theta.</figcaption></figure><p id="eb2b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不同的矩阵对应不同的变换。我们最感兴趣的是这四个:</p><ul class=""><li id="7d59" class="ml mm iq jp b jq jr ju jv jy mn kc mo kg mp kk mq mr ms mt bi translated"><strong class="jp ir">身份</strong>(输出相同的图像)。这是θ的初始值。在这种情况下，θ矩阵是对角的:<br/> <code class="fe mu mv mw mx b">theta = np.array([[1.0, 0, 0], [0, 1.0, 0]])</code></li><li id="9b48" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated"><strong class="jp ir">旋转</strong>(逆时针旋转45°)。<code class="fe mu mv mw mx b">cos(45º) = 1/sqrt(2) ≈ 0.7</code>:<br/>T2】</li><li id="597d" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated"><strong class="jp ir">放大。</strong> <br/>(放大2倍)放大中心:<br/> <code class="fe mu mv mw mx b">theta = np.array([[0.5, 0, 0], [0, 0.5, 0]])</code></li><li id="93d8" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated"><strong class="jp ir">缩小。</strong> <br/>缩小中心(放大2倍):<br/> <code class="fe mu mv mw mx b">theta = np.array([[2.0, 0, 0], [0, 2.0, 0]])</code></li></ul><p id="7901" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第二步。</strong>我们不是将变换直接应用于初始图像，而是生成一个与初始图像大小相同的采样网格<code class="fe mu mv mw mx b">U</code>。网格是覆盖整个输入图像空间的一组索引<code class="fe mu mv mw mx b">(x_t, y_t)</code>。它不包含任何颜色信息。这在代码中有更好的解释:</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="4fb4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于张量流的特殊性，<code class="fe mu mv mw mx b">x_t</code>和<code class="fe mu mv mw mx b">y_t</code>赋值可能看起来很麻烦。Numpy翻译做得更好:</p><p id="3e3b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe mu mv mw mx b">x_t, y_t = np.meshgrid(np.linspace(-1, 1, width), np.linspace(-1, 1, height))</code></p><p id="833e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第三步。</strong>将线性变换矩阵应用于我们初始化的meshgrid，以获得新的一组采样点。变换网格的每个点可以定义为θ与坐标<code class="fe mu mv mw mx b">(x_t, y_t)</code>和偏置项的矩阵向量乘积:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/8efba3341d26b2054a636a36035c0fa9.png" data-original-src="https://miro.medium.com/v2/resize:fit:336/format:webp/1*TMulJREb-fRWupKkD0nFZw.png"/></div></figure><p id="2dec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第四步。</strong>使用初始特征图、转换网格(见步骤3)和您选择的可微分插值函数(如双线性函数)产生采样输出<code class="fe mu mv mw mx b">V</code>。插值是必需的，因为我们需要将采样的结果(像素的分数)映射到像素值(整数)。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ng"><img src="../Images/19f71a571fa6f4a6b13954683025d762.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_xWxkSReMy6gqIJUshOGVA.jpeg"/></div></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Sampling and interpolation</figcaption></figure><p id="713f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">学习问题。</strong>如果我们以某种方式为每个输入图像提供正确的θ，我们可以开始使用我们刚刚描述的过程。事实上，我们希望从数据中推导出θ，我们确实可以做到！<strong class="jp ir">首先，</strong>我们需要确保交通标志分类器的损失可以反向传播到采样器并通过采样器。<strong class="jp ir">其次，</strong>我们定义了关于<code class="fe mu mv mw mx b">U</code>和<code class="fe mu mv mw mx b">G</code>(网格)的梯度:这就是插值函数必须可微或次可微的原因。第三，我们计算<code class="fe mu mv mw mx b">x</code>和<code class="fe mu mv mw mx b">y</code>相对于θ的偏导数。<a class="ae km" href="http://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf" rel="noopener ugc nofollow" target="_blank">如果真的好奇的话，梯度计算见原文。</a></p><p id="6a9c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们定义了一个<strong class="jp ir">定位神经网络</strong>(回归器)，其唯一的任务是学习，然后使用我们通过采样器反向传播的损失为给定图像产生正确的θ。</p><p id="d410" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">这种方法的神奇之处在于，我们得到了一个可微分的带记忆(通过可学习的权重)的自包含模块，它可以放在CNN的任何部分。</strong></p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi kn"><img src="../Images/40bd2e3a11688a12c06726079e7eef1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/1*kVrijD46V84DPp2jLweU1Q.gif"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">See how 𝛳 changes while the STN learns the representation of the main object (a traffic sign) in images .</figcaption></figure><p id="fab2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">简而言之，这就是STN。以下是最初论文中的STN方案:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/5e133956e2f454820ef2c1cd66e26f63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*4DNdutuMrmjfuy3JiTiEHg.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Spatial Transformer with the locnet from the <a class="ae km" href="http://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf" rel="noopener ugc nofollow" target="_blank">original paper.</a></figcaption></figure><p id="fd74" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如你所见，我们已经涵盖了STN的所有构建模块:本地化网络、meshgrid生成器和采样器。在下一部分中，我们将训练一个张量流分类器，它将STN作为其图形的一部分。</p><h1 id="0c6f" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">TensorFlow模型概述</h1><p id="fba6" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">这个模型的代码太长了，无法在这篇文章中一一列出，但是可以在github资源库中免费获得:<br/><a class="ae km" href="https://github.com/dnkirill/stn_idsia_convnet" rel="noopener ugc nofollow" target="_blank">https://github.com/dnkirill/stn_idsia_convnet</a></p><p id="8463" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我更倾向于关注一些重要的代码和模型训练。</p><p id="46f5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">首先</strong>，由于最终任务是对交通标志进行分类，我们需要定义和训练分类器本身。选择很多:从LeNet到你能想象到的任何新的顶级网络。在这个项目中，受<a class="ae km" href="https://github.com/Moodstocks/gtsrb.torch" rel="noopener ugc nofollow" target="_blank"> Moodstocks对STN </a>(在Torch中实现)的研究的启发，我使用了一个类似IDSIA的网络。</p><p id="df55" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">第二个</strong>，我们定义并训练STN模块，该模块将一幅原始图像作为输入，用采样器对其进行变换，并产生另一幅图像(或一批图像)。该图像然后被分类器用作输入。请注意，STN可以很容易地从DAG中分离出来，并由原始图像批处理生成器替换。这种被放置在CNN的任何部分的能力是STN的主要优点之一。</p><p id="2852" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是组合网络的概述:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/b743995e2cd607a7efe392559f410f26.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*Tts5ZBE7sEtoNkaS2hv0_Q.png"/></div><figcaption class="kv kw gj gh gi kx ky bd b be z dk">Spatial transformer network outputs images to IDSIA traffic signs classifier and trains using a single backprop algorithm.</figcaption></figure><p id="75ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">DAG的这一部分使用一批原始图像作为输入，通过STN模块对它们进行转换，将转换后的数据传输到分类器(IDSIA)并输出logits:</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="23c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">假设我们有计算logits的方法(STN + IDSIA网络)，下一步是计算损失(我们使用交叉熵或logloss损失函数作为分类问题的默认选择):</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="da6f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来是定义更多的ops —我们基本上初始化TensorFlow的DAG的ops。我们需要选择一个优化器和训练op，将损失反向传播回输入层:</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="6652" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我以更高的学习率(0.02)开始:这有助于将更强的梯度信息传播到STN的定位网络，该定位网络位于整个网络的“前”层，否则可能训练非常慢(由于<a class="ae km" href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem" rel="noopener ugc nofollow" target="_blank">消失梯度问题</a>)。学习率的初始值越小，网络就越难放大到更小的交通标志。</p><p id="f08c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae km" href="http://ruder.io/optimizing-gradient-descent/index.html#adam" rel="noopener ugc nofollow" target="_blank"> Adam optimizer </a>(结合自适应学习率并保持过去梯度的指数衰减平均值)与学习率的分段常数一起使用。学习率衰减使用<code class="fe mu mv mw mx b">boundaries</code>(批次数量)切换到较小的学习率。</p><p id="9184" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用一个非常简单的声明将输出logits(网络的前向通道)的DAG部分添加到图中:</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="bf5e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个简单的声明展开了整个网络，即STN + IDSIA。下一节将讨论它们。</p><h1 id="24b8" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">IDSIA分类器网络</h1><p id="4ed0" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">我的灵感来自Moodstocks的研究和来自IDSIA瑞士人工智能集团的<a class="ae km" href="http://www.idsia.ch/~juergen/nn2012traffic.pdf" rel="noopener ugc nofollow" target="_blank">初始论文</a>，其中他们使用了一组CNN来击败这个数据集的最先进的分数。我从系综中提取了单个网络架构的蓝图，并在TensorFlow中用我自己的术语定义了它。分类器的配置如下所示:</p><ul class=""><li id="adcc" class="ml mm iq jp b jq jr ju jv jy mn kc mo kg mp kk mq mr ms mt bi translated">第1层:卷积(批量归一化，relu，dropout)。<strong class="jp ir">内核</strong> : 7x7，100个滤镜。<strong class="jp ir">输入</strong> : 32x32x1(一批256个)。<strong class="jp ir">输出</strong> : 32x32x100。</li><li id="6123" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第2层:最大池化。<strong class="jp ir">输入</strong> : 32x32x100。<strong class="jp ir">输出</strong> : 16x16x100。</li><li id="8024" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第三层:卷积(批量归一化，relu，dropout)。<strong class="jp ir">内核</strong> : 5x5，150滤镜。<strong class="jp ir">输入</strong> : 16x16x100(一批256)。<strong class="jp ir">输出</strong> : 16x16x150。</li><li id="431c" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第4层:最大池化。<strong class="jp ir">输入</strong> : 16x16x150。<strong class="jp ir">输出</strong> : 8x8x150。</li><li id="6390" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第五层:卷积(批量归一化，relu，dropout)。<strong class="jp ir">内核</strong> : 5x5，250滤镜。<strong class="jp ir">输入</strong> : 16x16x100(一批256)。<strong class="jp ir">输出</strong> : 16x16x150。</li><li id="349f" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第6层:最大池化。<strong class="jp ir">输入</strong> : 8x8x250。<strong class="jp ir">输出</strong> : 4x4x250。</li><li id="32aa" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第7层:多比例要素的附加池。conv层1、2和3的内核大小分别为8、4和2。</li><li id="fac5" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第8层:多尺度特征的展平和拼接。<strong class="jp ir">输入</strong>:2x2x 100；2x2x1502x2x250。<strong class="jp ir">输出</strong>:全连通层的特征向量400+600+1000 = 2000。</li><li id="cce6" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第9层:全连接(批量归一化，relu，dropout)。<strong class="jp ir">输入</strong> : 2000个特征(一批256个)。300个神经元。</li><li id="2a2c" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第10层:Logits层(批量标准化)。<strong class="jp ir">输入</strong> : 300个特征。输出:logit(43类)。</li></ul><p id="27a1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下图可以说明这一点:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/e30e2bcb1560760d1dcdb313e1ad13a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*zUkDeONN9Sy-Y40u4LyIVw.png"/></div></figure><p id="e56f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如您所见，每个卷积层的激活随后被合并，并针对全连接层进行扁平化。这是<strong class="jp ir">多尺度特征</strong>的例子，它们<strong class="jp ir">确实</strong>提高了最终得分。</p><p id="6bb4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如我们前面所讨论的,<code class="fe mu mv mw mx b">conv1</code>的输入来自STN的输出。</p><h1 id="82c6" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">TensorFlow中的空间转换器</h1><p id="4b62" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">TensorFlow models zoo包含一个STN的实现，它将用于我们的模型:<a class="ae km" href="https://github.com/tensorflow/models/tree/master/transformer" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/models/tree/master/transformer</a>。</p><p id="5c6e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的任务是定义和训练本地化网络，为<code class="fe mu mv mw mx b">transformer</code>提供theta，并将STN模块注入TensorFlow的DAG。<code class="fe mu mv mw mx b">transformer</code>生成网格并提供变换和插值功能。</p><p id="71a4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本地化网络的配置如下:</p><p id="ff47" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">loc net的卷积层数:</strong></p><ul class=""><li id="b097" class="ml mm iq jp b jq jr ju jv jy mn kc mo kg mp kk mq mr ms mt bi translated">第1层:最大池化。<strong class="jp ir">输入</strong> : 32x32x1。<strong class="jp ir">输出</strong> : 16x16x1。</li><li id="4f6c" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第二层:卷积(relu，批量归一化)。<strong class="jp ir">内核</strong> : 5x5，100个滤镜。<strong class="jp ir">输入</strong> : 16x16x1(一批256个)。<strong class="jp ir">输出</strong> : 16x16x100。</li><li id="a709" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第3层:最大池化。<strong class="jp ir">输入</strong> : 16x16x100。<strong class="jp ir">输出</strong> : 8x8x100。</li><li id="5606" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第四层:卷积(批量归一化，relu)。<strong class="jp ir">内核</strong> : 5x5，200滤镜。<strong class="jp ir">输入</strong> : 8x8x100(一批256个)。<strong class="jp ir">输出</strong> : 8x8x200。</li><li id="485b" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第5层:最大池化。输入:8x8x200。输出:4x4x200。</li><li id="8845" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第6层:多比例要素的附加池。conv层1和2的内核大小分别为4和2。</li><li id="d494" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第7层:多尺度特征的展平和拼接。<strong class="jp ir">输入</strong>:2x2x 100；2x2x200。<strong class="jp ir">输出</strong>:全连通层的特征向量400+800 = 1200。</li></ul><p id="b3fb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">全连接LocNet: </strong></p><ul class=""><li id="c01f" class="ml mm iq jp b jq jr ju jv jy mn kc mo kg mp kk mq mr ms mt bi translated">第8层:全连接(批量归一化，relu，dropout)。<strong class="jp ir">输入</strong> : 1200个特征(一批256个)。100个神经元。</li><li id="513d" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第9层:Logits定义仿射变换的2×3矩阵theta。权重被初始化为零，偏差被初始化为恒等式变换:<code class="fe mu mv mw mx b">[[1.0, 0, 0], [0, 1.0, 0]]</code>。</li><li id="aa7c" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">第10层:变压器:网格生成器和采样器。该逻辑在<code class="fe mu mv mw mx b">spatial_transformer.py</code>中实现。此图层输出与原始图层(32x32x1)尺寸相同的变换图像，并对其应用仿射变换(例如，放大或旋转的图像)。</li></ul><p id="22e0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">locnet的卷积层的结构类似于IDSIA(尽管locnet由2个conv层而不是3个组成，并且我们首先对输入图像进行下采样)。完全连接层的图示更值得注意:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/e260020aef36bd449b8ee243b04ae54f.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*iyIs7rsZOTr6gSaNMHW3sg.png"/></div></figure><h1 id="a61a" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">培训和结果</h1><p id="d430" class="pw-post-body-paragraph jn jo iq jp b jq ly js jt ju lz jw jx jy ma ka kb kc mb ke kf kg mc ki kj kk ij bi translated">带有STN模块的CNN的问题是需要监控两个网络的过度匹配。这使得训练变得棘手和不稳定。另一方面，增加一点增强数据(尤其是增强亮度)确实可以避免两个网络过度拟合。无论如何，利大于弊:我们在<strong class="jp ir">没有任何增强的情况下得到很好的结果</strong>，STN+IDSIA比没有这个模块的IDSIA性能好0.5–1%。</p><p id="4612" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下参数用于训练:</p><figure class="ko kp kq kr gt ks"><div class="bz fp l di"><div class="nd ne l"/></div></figure><p id="c03b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">即使仅仅过了10个时期，我们也能在验证集上得到<code class="fe mu mv mw mx b">accuracy = 99.3</code>。CNN仍然过拟合，但是过拟合的影响可以通过图像增强来减少。事实上，通过添加额外的扩充，我在10个时期后得到了验证集上的<code class="fe mu mv mw mx b">accuracy = 99.6</code>(尽管训练时间显著增加)。</p><p id="aedd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是训练的结果(<code class="fe mu mv mw mx b">idsia_1</code>是单个IDSIA网络，<code class="fe mu mv mw mx b">idsia_stn</code>是STN+IDSIA)。准确度是德国交通标志数据集的整体验证准确度，而不是STN:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/5e8e6b38db11cc1779a5504bdb1d8abb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*HZzIuIX8D4_jL07_ph9ZCQ.png"/></div></figure><p id="77a3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">STN+IDSIA优于单个IDSIA网络，尽管它需要更多的时间来训练。请注意，上图中的认证准确度是按批次计算的，而不是按整个认证集计算的。</p><p id="78fa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，下面是STN转换器训练后的输出示例:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/0f934bcaa155482a64c468a90b79719d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*se1mJNX5xeS8rzBMBfII9g.png"/></div></figure><p id="f46f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">STN确实抓住了图像的本质，并专注于交通标志，而不是背景或其他特征。</p><p id="fc2c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">最后，让我们回顾一下:</strong></p><ul class=""><li id="60f5" class="ml mm iq jp b jq jr ju jv jy mn kc mo kg mp kk mq mr ms mt bi translated">STN是一个可微分的模块，可以注入到卷积神经网络中。默认选择是将它放在输入层的正“后”，使其学习最佳变换矩阵theta，从而最小化主分类器的损失函数(在我们的例子中，这是IDSIA)。</li><li id="96ab" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">STN的采样器将仿射变换应用于输入图像(或特征地图)。</li><li id="cfa6" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">STNs可以被视为图像增强的替代方案，图像增强是CNN实现空间不变性的默认方式。</li><li id="8d04" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">向CNN添加一个或多个stn会使训练更加困难和不稳定:现在你不得不监控两个(而不是一个)网络的过度适应。这似乎是为什么stn还没有被广泛使用的原因。</li><li id="5bfe" class="ml mm iq jp b jq my ju mz jy na kc nb kg nc kk mq mr ms mt bi translated">用一些数据增强(特别是光照条件增强)训练的stn表现更好，并且不会过度拟合。</li></ul><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi kn"><img src="../Images/42cb31e89ef7940c94004eac354ed203.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/1*J7UKQmTZNzjmgN4Aib8tIA.gif"/></div></figure></div></div>    
</body>
</html>