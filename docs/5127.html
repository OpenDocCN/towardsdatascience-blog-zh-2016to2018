<html>
<head>
<title>Exploring Melbourne’s Myki Data with AWS Athena</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 AWS Athena 探索墨尔本的 Myki 数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/exploring-melbournes-myki-data-with-aws-athena-511410d2e461?source=collection_archive---------4-----------------------#2018-09-28">https://towardsdatascience.com/exploring-melbournes-myki-data-with-aws-athena-511410d2e461?source=collection_archive---------4-----------------------#2018-09-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="8924" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用无服务器 SQL 查询对 S3 CSV 数据进行简单分析</h2></div><p id="3d5b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">编辑:应维多利亚数据中心的要求，本文中讨论的数据链接已被删除。</p><p id="44a4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作为墨尔本居民和 Myki 公共交通票价系统的日常通勤者(无可奉告)，当我听说 2018 年墨尔本数据大会<a class="ae lc" href="http://www.datasciencemelbourne.com/datathon/" rel="noopener ugc nofollow" target="_blank">的数据集将是大规模的真实世界 Myki 使用数据时，我很感兴趣。关于我们熙熙攘攘的城市如何使用公共交通网络，我们能收集到什么样的深刻见解？让我们来了解一下！最重要的是，我们将检查它，而不需要从 CSV 转换，甚至不需要将它移出 S3。</a></p><p id="0a8b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是我从这个 18 亿行的数据集中收集到的一些快速统计数据，SQL 查询只需几秒钟就能运行，比一杯咖啡的费用要低得多:</p><ul class=""><li id="88bc" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated">票价包括 65.65%的全票价，33.65%的付费优惠票价，以及少得可怜的 0.69%的免费乘车优惠</li><li id="eb66" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">周日，维多利亚州老年人优惠卡持有者最喜欢去的地方是博克斯山火车站</li></ul><h2 id="594f" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ko ma mb mc ks md me mf kw mg mh mi mj bi translated">AWS 雅典娜</h2><p id="34d7" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated"><a class="ae lc" href="https://aws.amazon.com/athena/" rel="noopener ugc nofollow" target="_blank"> AWS Athena </a>是一个完全托管的无服务器查询服务，允许您对存储在 S3 存储桶中的数据运行 SQL 查询——有点像魔术。基于<a class="ae lc" href="https://hive.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Hive </a>和脸书的<a class="ae lc" href="https://prestodb.io/" rel="noopener ugc nofollow" target="_blank"> Presto </a>，Athena 让你定义(甚至发现)你的数据模式，然后立即开始运行查询。你所支付的只是雅典娜运行你的查询所需要的数据，以及在 S3 存储这些数据的费用。</p><p id="ca8e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，首先让我们获取数据，将其放入 S3，并准备我们的模式。</p><h2 id="488d" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ko ma mb mc ks md me mf kw mg mh mi mj bi translated">在 S3 准备我们的 Myki 数据</h2><p id="2dc6" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">要先看一眼并探索数据文件，请查看这个公开的 S3 链接:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="2f26" class="lr ls iq mu b gy my mz l na nb"><em class="lb">Edit: by request of Data Victoria, links to the data discussed in this article have been removed.</em></span><span id="2e3f" class="lr ls iq mu b gy nc mz l na nb">(bucket contents is 25.4gb)</span><span id="ca25" class="lr ls iq mu b gy nc mz l na nb">---</span><span id="f835" class="lr ls iq mu b gy nc mz l na nb">Once again, so many thanks to Data Science Melbourne for organising the Melbourne Datathon and providing the data. Thanks also to PTV for releasing the dataset.</span><span id="a083" class="lr ls iq mu b gy nc mz l na nb"><a class="ae lc" href="http://www.datasciencemelbourne.com/datathon/" rel="noopener ugc nofollow" target="_blank">http://www.datasciencemelbourne.com/datathon/</a><br/><a class="ae lc" href="https://www.ptv.vic.gov.au/" rel="noopener ugc nofollow" target="_blank">https://www.ptv.vic.gov.au/</a></span></pre><p id="1466" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是我们今天感兴趣的文件的简要描述:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="5c9c" class="lr ls iq mu b gy my mz l na nb"><a class="ae lc" href="https://tomwwright-myki-data.s3.ap-southeast-2.amazonaws.com/lst.html?prefix=events/" rel="noopener ugc nofollow" target="_blank">events/</a>         # our myki usage dataset is in here<br/> <a class="ae lc" href="https://tomwwright-myki-data.s3.ap-southeast-2.amazonaws.com/lst.html?prefix=Samp_0/" rel="noopener ugc nofollow" target="_blank">Samp_0/</a>        # data is split into ten chunks<br/>  ScanOffTransaction/  # myki 'touch on' events when people board<br/>  ScanOnTransaction/   # myki 'touch off' events from disembarking<br/>   2015/        # year partitions<br/>   ...<br/>   2017/<br/>    Week1/      # week partitions<br/>    ...<br/>    Week52/<br/>     <a class="ae lc" href="https://tomwwright-myki-data.s3.ap-southeast-2.amazonaws.com/Samp_0/ScanOffTransaction/2017/Week53/QID3530164_20180713_12510_0.txt.gz" rel="noopener ugc nofollow" target="_blank">QID3530164_20180713_12510_0.txt.gz</a>    # data!<br/> <a class="ae lc" href="https://tomwwright-myki-data.s3.ap-southeast-2.amazonaws.com/lst.html?prefix=Samp_1/" rel="noopener ugc nofollow" target="_blank">Samp_1/</a><br/> ...<br/> <a class="ae lc" href="https://tomwwright-myki-data.s3.ap-southeast-2.amazonaws.com/lst.html?prefix=Samp_9/" rel="noopener ugc nofollow" target="_blank">Samp_9/</a><br/><a class="ae lc" href="https://tomwwright-myki-data.s3.ap-southeast-2.amazonaws.com/lst.html?prefix=calendar/" rel="noopener ugc nofollow" target="_blank">calendar/</a>       # map dates to week numbers, days of week, etc.<br/><a class="ae lc" href="https://tomwwright-myki-data.s3.ap-southeast-2.amazonaws.com/lst.html?prefix=cardtypes/" rel="noopener ugc nofollow" target="_blank">cardtypes/</a>      # myki fare types: full fare, concession, etc.<br/><a class="ae lc" href="https://tomwwright-myki-data.s3.ap-southeast-2.amazonaws.com/lst.html?prefix=stops/" rel="noopener ugc nofollow" target="_blank">stops/</a>          # links stop information to a stop id</span></pre><p id="ca54" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为自己创建一个存储桶并复制数据！(如果您想更好地了解数据，可以随意复制其中一个<code class="fe nd ne nf mu b">Samp_X</code>目录)</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="9d69" class="lr ls iq mu b gy my mz l na nb">aws s3 mb s3://mediumreader-myki-data<br/>aws s3 cp --recursive s3://bucket-no-longer-exists/ s3://mediumreader-myki-data/</span></pre><p id="b65a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">轻松点。现在，我们告诉 AWS Athena 我们的数据是什么样子，以便它可以查询它——我们使用 AWS Glue 中的数据目录来完成这一点，它与 Athena 集成在一起。</p><h2 id="e6f1" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ko ma mb mc ks md me mf kw mg mh mi mj bi translated">在 AWS Glue 数据目录中准备我们的数据模式</h2><p id="2c86" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated"><a class="ae lc" href="https://aws.amazon.com/glue/" rel="noopener ugc nofollow" target="_blank"> AWS Glue </a>是亚马逊完全托管的 ETL(提取、转换、加载)服务，可以轻松地从各种数据源准备和加载数据，以进行分析和批处理。今天，我们只对数据目录使用 Glue 感兴趣，因为这将允许我们在刚刚转储到 S3 的 Myki 数据上定义一个模式。AWS Glue 通过提供数据“爬虫”使这变得容易，这些爬虫可以窥视我们的数据并自动发现我们的大量模式。</p><ul class=""><li id="22d5" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated">导航到<em class="lb"> AWS 胶水</em></li><li id="a1a5" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">从菜单中选择<em class="lb">爬虫</em></li><li id="6437" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">选择<em class="lb">添加爬虫</em></li></ul><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ng"><img src="../Images/b0a3947991947bf40c159bc06d26faaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0VTgZGu7eVSwXhR3UYMoSw.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Getting started by adding a crawler to discover our schema</figcaption></figure><ul class=""><li id="0027" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated">命名我们的爬虫<em class="lb"> myki_crawler </em></li><li id="e7a8" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">点击<em class="lb">下一步，</em>这里我们不需要任何可选配置</li></ul><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ns"><img src="../Images/488ed8251aaa1c5005f771387b7d3531.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7qKuhIdcbEyOotAIbQG7cQ.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Naming our crawler, other optional config is fine as defaults</figcaption></figure><ul class=""><li id="6831" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated"><em class="lb"> S3 </em>数据仓库</li><li id="e38f" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><em class="lb">我的账户中指定的路径</em></li><li id="c783" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">对于我来说，Include path 是<em class="lb">S3://tomwwright-myki-data/</em>，替换为您之前在复制数据时调用的 bucket</li><li id="a5ae" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">将<em class="lb">排除模式</em>留空，对于这个数据集，我们只清理爬虫发现的我们不想要的垃圾</li><li id="411d" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">点击<em class="lb">下一步，s </em>选择<em class="lb">否</em>添加另一个数据存储，再次点击<em class="lb">下一步</em></li></ul><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nt"><img src="../Images/32e23a4be2078b754e360ac59c7107e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9LZZNwfMKUBRcxvHZzGQYA.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Pointing our crawler at our S3 data bucket</figcaption></figure><ul class=""><li id="248d" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated">选择<em class="lb">创建一个 IAM 角色</em>(除非您已经为 Glue 准备好了角色)</li><li id="e2b1" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">输入<em class="lb"> MykiCrawler </em>作为名字——或者随便你怎么想，我是一个中等职位，不是你的母亲</li><li id="32b8" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">点击<em class="lb">下一个</em></li></ul><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nu"><img src="../Images/fc769d88bb2458a4a256841011f9b922.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1trrijeOyaCxl_a9VKM_qg.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Creating an IAM role to give our crawler access to our bucket</figcaption></figure><ul class=""><li id="9061" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated">选择“按需运行”作为频率，我们只想运行一次</li><li id="0ed5" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">点击<em class="lb">下一个</em></li></ul><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nv"><img src="../Images/4c448a43f1d3851c029eae83c3948cae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9ShWVaMSBDhqHju-S1WlCQ.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">We just want to run it the once anyway…</figcaption></figure><ul class=""><li id="922b" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated">选择<em class="lb">添加数据库</em>，姑且称之为<em class="lb"> myki </em>，不需要任何的可选配置，点击<em class="lb">创建</em></li><li id="5a56" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">保持所有可选配置不变</li><li id="4661" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">点击<em class="lb">下一个</em></li><li id="f585" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated">点击<em class="lb">完成！</em></li></ul><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nw"><img src="../Images/6fe44bc1db6607737d50fdf16a24eedb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*14--H0SVW-7KsHYdUUM7KA.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Creating a database for the tables discovered by the crawler</figcaption></figure><p id="79ad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你应该已经回到 AWS Glue 的爬虫屏幕，所以选择<em class="lb"> myki_crawler </em>并点击<em class="lb"> Run crawler </em>。根据我的经验，跑步大概需要 7 分钟，所以你可以喝杯咖啡或者散散步。</p><p id="cc4e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦爬虫完成，我们将能够在<em class="lb">数据库- &gt;表</em>下查看发现的表。我们要做的第一件事是删除一些垃圾表，这些垃圾表是爬虫通过检查我们的 S3 桶中的一些非数据文件而创建的——删除所有分类为<em class="lb"> Unknown </em>的表，如下面的截图所示。我们本来可以通过忽略将它们复制到 bucket 中，或者将它们添加到 crawler 的 exclude paths 配置中来省去这个麻烦。哦，好吧，很容易删除它们。</p><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nx"><img src="../Images/fd634eaaeef3962ed36f3f292a97fd83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VJF6OnV6pMbuAUMB5Q8Mbg.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Deleting junk tables the crawler inadvertently created by scanning everything in the bucket — that’s our bad, oops.</figcaption></figure><p id="2d8a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">打开日历表，我们可以看到爬虫为我们发现的所有好东西:数据格式、分隔符、记录计数、列类型等等。缺少的一点是列名，因为 myki 数据文件中没有该信息。下面你会发现一些我们需要应用的列标签(不一定是全部)，以便能够为我们的表编写可读的查询。选择一个表并点击右上角的<em class="lb">编辑模式</em>来更新列。</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="989b" class="lr ls iq mu b gy my mz l na nb">table: calendar</span><span id="60f3" class="lr ls iq mu b gy nc mz l na nb">1  col0   bigint   dateid<br/>2  col1   string   date<br/>3  col2   bigint   year<br/>6  col5   string   month<br/>13 col12  string   daytype  # 'Weekday', 'Weekend', 'Public Holiday'<br/>16 col15  string   dayofweek</span><span id="b79e" class="lr ls iq mu b gy nc mz l na nb">---</span><span id="e885" class="lr ls iq mu b gy nc mz l na nb">table: cardtypes</span><span id="664e" class="lr ls iq mu b gy nc mz l na nb">1  col0   bigint   typeid<br/>2  col1   string   typedesc<br/>3  col2   string   paidorfree  # 'Paid', 'Free'<br/>4  col3   string   concession  # 'Full Fare', 'Concession'</span><span id="e091" class="lr ls iq mu b gy nc mz l na nb">---</span><span id="bbdb" class="lr ls iq mu b gy nc mz l na nb">table: events</span><span id="2dd6" class="lr ls iq mu b gy nc mz l na nb">1  col0   bigint   mode<br/>2  col1   string   date<br/>3  col2   string   datetime<br/>4  col3   bigint   cardid<br/>5  col4   bigint   cardtypeid<br/>6  col5   bigint   vehicleid</span><span id="8cbe" class="lr ls iq mu b gy nc mz l na nb">8  col7   string   routeid<br/>9  col8   string   stopid<br/>10 partition_0     samplenum<br/>11 partition_1     onoroff  # 'ScanOffTransaction', 'ScanOnTra...on'<br/>12 partition_2     year<br/>13 partition_3     week</span><span id="4b42" class="lr ls iq mu b gy nc mz l na nb">---</span><span id="90ac" class="lr ls iq mu b gy nc mz l na nb">table: stops</span><span id="5cdc" class="lr ls iq mu b gy nc mz l na nb">1  col0   bigint   stopid<br/>2  col1   string   name<br/>3  col2   string   longname<br/>4  col3   string   stoptype<br/>5  col4   string   suburb<br/>6  col5   bigint   postcode<br/>10 col9   double   lat<br/>11 col10  double   long</span></pre><p id="8e0e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有了我们的列名，我们终于准备好做一些查询了！</p><h2 id="5b4b" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ko ma mb mc ks md me mf kw mg mh mi mj bi translated">用 AWS Athena 查询我们的模式</h2><p id="cfd8" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">通过点击 Athena 服务，我们发现自己首先出现在查询编辑器屏幕上。酷，让我们选择我们的<code class="fe nd ne nf mu b">myki</code>数据库并插入一个简单的计数查询！</p><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ny"><img src="../Images/49f9331b7d8dc666173b51fe59089189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cKmF38mAfqtSGomeyZPuNg.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">AWS Athena’s Query Editor makes it simple to develop queries against our Myki schema</figcaption></figure><p id="51a6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我们得到一个我们真正满意的查询时，我们可以点击<code class="fe nd ne nf mu b">Save as</code>并给它一个名字，然后我们可以很容易地找到它并在<code class="fe nd ne nf mu b">Saved Queries</code>下再次运行它。Athena 还允许我们在<code class="fe nd ne nf mu b">History</code>下访问我们的查询历史，在那里我们可以下载任何查询结果。</p><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi nz"><img src="../Images/65b41d030356330908fc067c795d83de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A6QppCC7qjrVMmvtgDF6KA.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">AWS Athena’s query history allows us to find our past queries and download the results</figcaption></figure><p id="672f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里需要注意的一个重要指标是 Athena 查询所扫描的<em class="lb"> </em> <strong class="kh ir">数据</strong>，因为 Athena 的<a class="ae lc" href="https://aws.amazon.com/athena/pricing/" rel="noopener ugc nofollow" target="_blank">定价直接(且仅)与 Athena 在运行查询的过程中读取的数据量相关:</a></p><blockquote class="oa ob oc"><p id="4dd7" class="kf kg lb kh b ki kj jr kk kl km ju kn od kp kq kr oe kt ku kv of kx ky kz la ij bi translated">“Amazon Athena 会根据扫描的字节数向您收费，四舍五入到最接近的兆字节，每次查询最少 10MB。</p><p id="e47a" class="kf kg lb kh b ki kj jr kk kl km ju kn od kp kq kr oe kt ku kv of kx ky kz la ij bi translated">扫描每 TB 数据 5 美元”</p></blockquote><p id="1ed5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于它操作的是普通的平面文件，Athena 很难智能地处理它所扫描的数据，通常它需要读取模式指定的构成表的所有文件。除非在创建模式时，指定了<strong class="kh ir">分区</strong>来定义映射到目录的“列”, Athena 可以使用这些目录来智能地判断对于给定的查询应该扫描哪些数据。举例来说，回想一下我们数据的文件夹结构:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="6f12" class="lr ls iq mu b gy my mz l na nb"><a class="ae lc" href="https://tomwwright-myki-data.s3.ap-southeast-2.amazonaws.com/lst.html?prefix=events/" rel="noopener ugc nofollow" target="_blank">events/</a>         # our myki usage dataset is in here<br/> <a class="ae lc" href="https://tomwwright-myki-data.s3.ap-southeast-2.amazonaws.com/lst.html?prefix=Samp_0/" rel="noopener ugc nofollow" target="_blank">Samp_0/</a>        # data is split into ten chunks<br/>  ScanOffTransaction/  # myki 'touch on' events when people board<br/>  ScanOnTransaction/   # myki 'touch off' events from disembarking<br/>   2015/        # year partitions<br/>   ...<br/>   2017/<br/>    Week1/      # week partitions<br/>    ...<br/>    Week52/<br/>     <a class="ae lc" href="https://tomwwright-myki-data.s3.ap-southeast-2.amazonaws.com/Samp_0/ScanOffTransaction/2017/Week53/QID3530164_20180713_12510_0.txt.gz" rel="noopener ugc nofollow" target="_blank">QID3530164_20180713_12510_0.txt.gz</a>    # data!<br/> <a class="ae lc" href="https://tomwwright-myki-data.s3.ap-southeast-2.amazonaws.com/lst.html?prefix=Samp_1/" rel="noopener ugc nofollow" target="_blank">Samp_1/</a><br/> ...<br/> <a class="ae lc" href="https://tomwwright-myki-data.s3.ap-southeast-2.amazonaws.com/lst.html?prefix=Samp_9/" rel="noopener ugc nofollow" target="_blank">Samp_9/</a><br/><a class="ae lc" href="https://tomwwright-myki-data.s3.ap-southeast-2.amazonaws.com/lst.html?prefix=calendar/" rel="noopener ugc nofollow" target="_blank">calendar/</a>       # map dates to week numbers, days of week, etc.<br/><a class="ae lc" href="https://tomwwright-myki-data.s3.ap-southeast-2.amazonaws.com/lst.html?prefix=cardtypes/" rel="noopener ugc nofollow" target="_blank">cardtypes/</a>      # myki fare types: full fare, concession, etc.<br/><a class="ae lc" href="https://tomwwright-myki-data.s3.ap-southeast-2.amazonaws.com/lst.html?prefix=stops/" rel="noopener ugc nofollow" target="_blank">stops/</a>          # links stop information to a stop id</span></pre><p id="e379" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的<code class="fe nd ne nf mu b">events</code>文件夹由一系列子文件夹组成，这些子文件夹按照几个关键列整齐地划分我们的事件数据:一个编号的样本文件夹，无论它是一个接触式事件还是触发式事件，年份和星期。幸运的是，我们的 AWS Glue crawler 足够聪明，能够注意到所有这些，并且已经在我们的模式中组织了所有这些！不错！</p><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi og"><img src="../Images/f5166513bff2e74d55d78e9c6da7dac9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oHOXS0ofK3AfcqGZySzxMQ.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">You can view partitions for a table in the AWS Glue Data Catalogue</figcaption></figure><p id="6c6c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了说明这些分区的重要性，我用<em class="lb">两个不同的查询</em>计算了 2016 年使用的唯一 Myki 卡的数量(顺便说一下，大约 740 万张):一个使用数据中<code class="fe nd ne nf mu b">date</code>列的<code class="fe nd ne nf mu b">LIKE</code>操作符，另一个使用我们的<code class="fe nd ne nf mu b">year</code>分区列。</p><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi oh"><img src="../Images/b6e8ac74733d63e7a68a956c022c8eb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wT86KDT5ZqN8HoXla0fHLA.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">The power of partitioning: Athena scans only the relevant data for 2016, less than 30% of the entire dataset</figcaption></figure><p id="37ce" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们使用<code class="fe nd ne nf mu b">date LIKE '2016%'</code>的第一个查询必须扫描整个<code class="fe nd ne nf mu b">events</code>表，总共 25gb，因为 Athena 无法确定哪些文件中可能有匹配行。此查询的成本约为 0.12 美元。</p><p id="d5be" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们使用<code class="fe nd ne nf mu b">year = '2016'</code>的第二个查询能够检索我们的结果，并且只扫描 8g 的<code class="fe nd ne nf mu b">events</code>数据！这是因为<code class="fe nd ne nf mu b">year</code>是映射到我们的 S3 数据中特定键模式的分区列之一。该查询的成本约为 0.04 美元，运行时间不到三分之一！</p><p id="be87" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用分区智能地组织数据是能够在 Athena 上运行快速且经济高效的查询的关键。好吧，我们继续！</p><h2 id="223a" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ko ma mb mc ks md me mf kw mg mh mi mj bi translated">触发的热门站点</h2><p id="1492" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">所以，我的第一个想法是，人们使用 Myki 会去哪里？用 SQL 回答这个问题似乎很简单，让我们从获得最受欢迎的站点列表开始。</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="3e4d" class="lr ls iq mu b gy my mz l na nb"># top 20 stop ids for touch-off events </span><span id="a8e2" class="lr ls iq mu b gy nc mz l na nb">select stopid, count(*) as count<br/>from events<br/>where onoroff = 'ScanOffTransaction'<br/>group by stopid<br/>order by count desc<br/>limit 20;</span></pre><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi oi"><img src="../Images/d6a27a735cd0ac92e1116799fa8f95cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yc8GyLsvt1JfSewvTNGyaA.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Touch-off events aggregated by the stop ID</figcaption></figure><p id="9e9f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">很好，我们可以用我们的<code class="fe nd ne nf mu b">stops</code>表来连接这个，以获得一个更易于阅读的表示，就这么做吧。</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="dc49" class="lr ls iq mu b gy my mz l na nb"># select our top stops like before, then join to our stops table</span><span id="5297" class="lr ls iq mu b gy nc mz l na nb">with topstops (stopid, count) as (<br/>  select stopid, count(*) as count<br/>  from events<br/>  where onoroff = 'ScanOffTransaction'<br/>  group by stopid<br/>)<br/>select topstops.stopid, stops.longname, stops.suburb, topstops.count<br/>from topstops left outer join stops<br/>on topstops.stopid = stops.stopid<br/>order by topstops.count desc<br/>limit 20;</span></pre><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi oj"><img src="../Images/1a0f83b22385fc0ed84e0f5eab4dd9f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mos6IZ0reZsyUm1UpVgORQ.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Results of running our “top touch-off stops” query</figcaption></figure><p id="d322" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">嗯。有一堆<code class="fe nd ne nf mu b">stopid</code>行遗漏了<code class="fe nd ne nf mu b">stops</code>信息……对我来说，鉴于它们是最受欢迎的车站，并且有正确的数字，我的猜测是<code class="fe nd ne nf mu b">64xxx</code>站是城市环路铁路站，也许<code class="fe nd ne nf mu b">24001</code>是里士满站？</p><p id="fa10" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">除此之外，这些结果对我来说是有意义的，看到所有的顶级车站都是火车站一点也不奇怪。</p><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ok"><img src="../Images/d15b15221a9ed1c3e7dab78d0827691d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rp8tcAsQdphviwAYcPRqTQ.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Melbourne’s City Loop — map courtesy of <a class="ae lc" href="https://static.ptv.vic.gov.au/PDFs/Maps/Network-maps/1535090671/PTV_MetropolitanTrainNetworkMap_August2018.pdf" rel="noopener ugc nofollow" target="_blank">Public Transport Victoria</a></figcaption></figure><h2 id="005a" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ko ma mb mc ks md me mf kw mg mh mi mj bi translated">票价类型的细分</h2><p id="71f3" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">似乎总是有一些关于向各种群体提供优惠公共交通出行的肆意支出的喋喋不休。全价票和优惠票的细目是什么？同样，看起来很简单。让我们首先根据<code class="fe nd ne nf mu b">events</code>表中的卡类型进行汇总。</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="c2e5" class="lr ls iq mu b gy my mz l na nb"># aggregate our touch-on events by the card type used</span><span id="8202" class="lr ls iq mu b gy nc mz l na nb">select cardtypeid, count(*) as count<br/>from events<br/>where onoroff = 'ScanOnTransaction'<br/>group by cardtypeid<br/>order by count desc</span></pre><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi ol"><img src="../Images/7bf12f66773cc14ddc86ec4b8b538a68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MjFup3hg0QVJlEjkqmIVuw.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Touch-on events aggregated by the card type ID</figcaption></figure><p id="d783" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">很好，所以和上次一样，让我们加入到我们的<code class="fe nd ne nf mu b">cardtypes</code>表中来，以提供更多人类可读的信息:</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="9464" class="lr ls iq mu b gy my mz l na nb"># aggregate by card type as before, then join to card types<br/># information to determine concession and paying status</span><span id="ce9f" class="lr ls iq mu b gy nc mz l na nb">with cardtypecounts (cardtypeid, count) as (<br/>  select cardtypeid, count(*) as count<br/>  from events<br/>  where onoroff = 'ScanOnTransaction'<br/>  group by cardtypeid<br/>)<br/>select cardtypecounts.cardtypeid, cardtypes.typedesc, cardtypes.concession, cardtypes.paidorfree, cardtypecounts.count<br/>from cardtypecounts left outer join cardtypes<br/>on cardtypecounts.cardtypeid = cardtypes.typeid<br/>order by cardtypecounts.count desc;</span></pre><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi om"><img src="../Images/5c2f44cb115993f6f1ce91389193f2bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Eg7ecMxC0V4Etm2biu3jnA.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Top fare types and concession / paying status</figcaption></figure><p id="7249" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">全价乘客看起来占了绝大多数，是最常见(但标签模糊)优惠票价类型的 4 倍多。但是列表的其余部分是由各种不同的特许权类型组成的，所以可能不会这么简单。唯一进入前 14 名的免费乘车类型是<code class="fe nd ne nf mu b">Employee Travel Pass</code>——有道理。</p><p id="0127" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们通过再次汇总来进行更高层次的观察，我对全价、优惠和免费的总体细分很好奇。</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="20dc" class="lr ls iq mu b gy my mz l na nb"># further aggregating our query by concession and paying<br/># statuses</span><span id="5e6a" class="lr ls iq mu b gy nc mz l na nb">with cardtypecounts (cardtypeid, count) as (<br/>  select cardtypeid, count(*) as count<br/>  from events<br/>  where onoroff = 'ScanOnTransaction'<br/>  group by cardtypeid<br/>)<br/>select cardtypes.concession, cardtypes.paidorfree, sum(cardtypecounts.count) as count<br/>from cardtypecounts left outer join cardtypes<br/>on cardtypecounts.cardtypeid = cardtypes.typeid<br/>group by cardtypes.concession, cardtypes.paidorfree <br/>order by count desc;</span></pre><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi on"><img src="../Images/6720e35cbb27df306ac15017e456f546.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fx0LNqj0FnLA6bb96jZxRw.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Full-fare vs. concession vs. free fare types</figcaption></figure><p id="514f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好吧，这就是全貌:65.65%的全价票，33.65%的付费优惠票，以及少得可怜的 0.69%的免费乘车优惠票。</p><h2 id="06a3" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ko ma mb mc ks md me mf kw mg mh mi mj bi translated">老年人的最佳周日目的地</h2><p id="c682" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">最后，让我们尝试一些稍微具体的东西。在一个星期天，我们的高级公共交通用户喜欢去哪里？</p><p id="6041" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">加入我们的<code class="fe nd ne nf mu b">calendar</code>表将允许我们确定哪些日期是<code class="fe nd ne nf mu b">Sunday</code>，我们之前对票价类型的查询显示<code class="fe nd ne nf mu b">cardtypeid = 9</code>是我们需要寻找的<code class="fe nd ne nf mu b">Victorian Seniors Concession</code>票价类型。厉害！</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="4816" class="lr ls iq mu b gy my mz l na nb"># selecting touch-on events that were on a Sunday using a Victorian Seniors<br/># Concession fare</span><span id="b4e8" class="lr ls iq mu b gy nc mz l na nb">select stopid, count(*) as count<br/>from events, calendar<br/>where onoroff = 'ScanOffTransaction'<br/>and events.date = calendar.date<br/>and events.cardtypeid = 9<br/>and calendar.dayofweek = 'Sunday'<br/>group by events.stopid;</span></pre><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi oo"><img src="../Images/4f0c5b9202f9daae7b1ce974a6105d8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GCggtr7q5K24_nPf0KRhWQ.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Touch-on events on a Sunday by seniors, aggregated by the stop ID</figcaption></figure><p id="d768" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在就像我们的第一个查询一样，加入到<code class="fe nd ne nf mu b">stops</code>来给我们一些人类可读的信息。再次记住有些止损点似乎错过了他们的信息…</p><pre class="mp mq mr ms gt mt mu mv mw aw mx bi"><span id="76f4" class="lr ls iq mu b gy my mz l na nb"># join or sunday seniors stops to stops information</span><span id="ea8b" class="lr ls iq mu b gy nc mz l na nb">with seniorsundaystops (stopid, count) as (<br/>  select stopid, count(*) as count<br/>  from events, calendar<br/>  where onoroff = 'ScanOffTransaction'<br/>  and events.date = calendar.date<br/>  and events.cardtypeid = 9<br/>  and calendar.dayofweek = 'Sunday'<br/>  group by events.stopid<br/>)<br/>select seniorsundaystops.stopid, stops.longname, stops.suburb, seniorsundaystops.count<br/>from seniorsundaystops left outer join stops<br/>on seniorsundaystops.stopid = stops.stopid<br/>order by seniorsundaystops.count desc;</span></pre><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi op"><img src="../Images/05a71bc0957ba2b799b732bad0c2c681.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m1XI96LtiV67yRHcg3FDew.png"/></div></div></figure><p id="9724" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们神秘的未命名站点(几乎可以肯定是城市环路站点)仍然领先，但显然我们挥舞着 Myki 的老年人喜欢在 Box Hill，Caulfield 和 Footscray 度过时光。谁知道呢。</p><h2 id="ae63" class="lr ls iq bd lt lu lv dn lw lx ly dp lz ko ma mb mc ks md me mf kw mg mh mi mj bi translated">包扎</h2><p id="4630" class="pw-post-body-paragraph kf kg iq kh b ki mk jr kk kl ml ju kn ko mm kq kr ks mn ku kv kw mo ky kz la ij bi translated">花点时间想想这种技术有多酷是有好处的，因为一旦你投入进去，就很容易忘记。能够运行带有连接的 SQL 查询，只针对位于 S3 的 CSV 文件。令人印象深刻。</p><p id="c26e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个 Myki 数据也不是一个可以分析的小数目。超过 18 亿行，我们能够在不到 10 秒的时间内处理它。而且它的成本非常低。本文中列出的查询扫描了大约 145 千兆字节的 S3 数据，总共花费了我巨大的…</p><p id="2f5d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi">$0.75</p><p id="8a3e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">查询愉快！汤姆</p><figure class="mp mq mr ms gt nh gh gi paragraph-image"><div role="button" tabindex="0" class="ni nj di nk bf nl"><div class="gh gi oq"><img src="../Images/f8e35f2c9fa62cc59a8c4ee85783acbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g34gyF4JHRVpCx9aviu0hA.png"/></div></div><figcaption class="no np gj gh gi nq nr bd b be z dk">Counting our data — it’s a decent bit to be crunching in under 10 seconds and paying next to nothing for</figcaption></figure></div></div>    
</body>
</html>