<html>
<head>
<title>Encoding Categorical Features</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">编码分类特征</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/encoding-categorical-features-21a2651a065c?source=collection_archive---------1-----------------------#2018-09-12">https://towardsdatascience.com/encoding-categorical-features-21a2651a065c?source=collection_archive---------1-----------------------#2018-09-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/067f655f9f113fb81524f40dd58ab3eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5uXHXtM_dNOPnGBXxDbQ3w.jpeg"/></div></div></figure><h1 id="3630" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">介绍</h1><p id="f42f" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">在机器学习项目中，一个重要的部分是特征工程。在数据集中看到分类特征是非常常见的。然而，我们的机器学习算法只能读取数值。将分类特征编码成数值是非常重要的。</p><p id="c96f" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">在这里，我们将介绍分类特征的三种不同编码方式:</p><p id="72ce" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">1.标签编码器和 OneHotEncoder</p><p id="dd77" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">2.字典矢量器</p><p id="ce23" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">3.熊猫有假人</p><p id="942a" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">为了您的方便，完整的代码可以在我的<a class="ae lz" href="https://github.com/liuy14/Kidney_Disease_Detection" rel="noopener ugc nofollow" target="_blank"> github </a>中找到。</p><h1 id="fb88" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">数据集</h1><p id="97af" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">我们在这里使用的数据集来自<a class="ae lz" href="https://archive.ics.uci.edu/ml/datasets/chronic_kidney_disease" rel="noopener ugc nofollow" target="_blank"> UCI 机器学习资源库</a>。它用于以各种血液指标为特征，预测患者是否有肾脏疾病。我们用熊猫来读取数据。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="12aa" class="mj jz iq mf b gy mk ml l mm mn"># load data<br/>df = pd.read_csv(‘datasets/chronic_kidney_disease.csv’, header=None, <br/> names=[‘age’, ‘bp’, ‘sg’, ‘al’, ‘su’, ‘rbc’, ‘pc’, ‘pcc’, ‘ba’, ‘bgr’, ‘bu’, ‘sc’, ‘sod’, ‘pot’, <br/> ‘hemo’, ‘pcv’, ‘wc’, ‘rc’, ‘htn’, ‘dm’, ‘cad’, ‘appet’, ‘pe’, ‘ane’, ‘class’])</span><span id="7f47" class="mj jz iq mf b gy mo ml l mm mn"># head of df<br/>df.head(10)</span></pre><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mp"><img src="../Images/910707a7f41e74c69d17ee96585272ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e1kC8s1_lHpq8QgXdxo0sg.png"/></div></div></figure><p id="9fa9" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">从表中可以看出，我们有几个分类特征，如“rbc”(红细胞)、“pc”(脓细胞)、“pcc”(脓细胞团块)等。很明显，数据集包含缺失的值，但是因为这超出了本博客的主题范围，所以我们在这里不讨论如何进行。但是填充缺失的值是必要的，并且应该在编码分类特征之前完成。您可以参考我的<a class="ae lz" href="https://github.com/liuy14/Kidney_Disease_Detection" rel="noopener ugc nofollow" target="_blank"> github </a>了解如何填写缺失值。准备好分类编码的完整数据集如下所示。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mq"><img src="../Images/8237c6242cd74afffafe4936292064e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j8Z6Y7Be9kIdrD_aPekjAw.png"/></div></div></figure><h1 id="1e52" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">标签编码器&amp; OneHotEncoder</h1><p id="ae92" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">labelEncoder 和 OneHotEncoder 只对分类特征有效。我们首先需要使用布尔掩码提取类别特征。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="0a31" class="mj jz iq mf b gy mk ml l mm mn"># Categorical boolean mask<br/>categorical_feature_mask = X.dtypes==object</span><span id="e4b8" class="mj jz iq mf b gy mo ml l mm mn"># filter categorical columns using mask and turn it into a list<br/>categorical_cols = X.columns[categorical_feature_mask].tolist()</span></pre><p id="c27d" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">LabelEncoder 将指定特征下的每个类转换成一个数值。让我们一步一步来看看怎么做。</p><p id="b647" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">实例化标签编码器对象:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="2965" class="mj jz iq mf b gy mk ml l mm mn"># import labelencoder<br/>from sklearn.preprocessing import LabelEncoder</span><span id="78e6" class="mj jz iq mf b gy mo ml l mm mn"># instantiate labelencoder object<br/>le = LabelEncoder()</span></pre><p id="225e" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">对每个分类列应用标签编码器:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="8a2a" class="mj jz iq mf b gy mk ml l mm mn"># apply le on categorical feature columns<br/>X[categorical_cols] = X[categorical_cols].apply(lambda col: le.fit_transform(col))</span><span id="e5ae" class="mj jz iq mf b gy mo ml l mm mn">X[categorical_cols].head(10)</span></pre><p id="1aab" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">请注意，标签编码器的输出仍然是一个数据帧。结果如下所示:</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/8e0fe7995ef53976590ac0d5bf670a3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*wdBlWX7tSq5WUarg_rKinQ.png"/></div></figure><p id="5e63" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">正如我们所看到的，所有的分类特征列都是二进制类。但是如果分类特征是多类的，标签编码器将为不同的类返回不同的值。参见下面的示例，“邻域”功能有多达 24 个类。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/9abc43c622b6e64b5528a20dde4154ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*a0LfmA26PIqrfZ0-VrqqlA.png"/></div></figure><p id="e109" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">在这种情况下，只使用标签编码器不是一个好的选择，因为它为不同的类带来了自然的顺序。例如，在“邻域”功能下，a 类的值为 5，而 b 类的值为 24，那么 b 类的值是否比 a 类大？答案显然是否定的。因此，允许模型学习，这种结果将导致较差的性能。因此，对于包含多类特征的数据帧，需要 OneHotEncoder 的进一步处理。让我们看看做这件事的步骤。</p><p id="3fac" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">实例化 OneHotEncoder 对象:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="b6f8" class="mj jz iq mf b gy mk ml l mm mn"># import OneHotEncoder<br/>from sklearn.preprocessing import OneHotEncoder</span><span id="8784" class="mj jz iq mf b gy mo ml l mm mn"># instantiate OneHotEncoder<br/>ohe = OneHotEncoder(categorical_features = categorical_feature_mask, sparse=False ) <br/># categorical_features = boolean mask for categorical columns<br/># sparse = False output an array not sparse matrix</span></pre><p id="7447" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">我们需要使用 OneHotEncoder 中的掩码来指定分类特征。<code class="fe mt mu mv mf b">sparse=False</code>参数输出一个非稀疏矩阵。</p><p id="d87a" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">对数据帧应用 OneHotEncoder:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="a278" class="mj jz iq mf b gy mk ml l mm mn"># apply OneHotEncoder on categorical feature columns<br/>X_ohe = ohe.fit_transform(X) # It returns an numpy array</span></pre><p id="0aed" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">请注意，输出是 numpy 数组，而不是 dataframe。对于分类特征下的每个类，都会为其创建一个新列。例如，为十个二元类分类特征创建了 20 列。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/9e43f77b405e6fdf125301f2efcc63a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*w8uIBZaNMr4Zr9X5AYpEsA.png"/></div></figure><h1 id="d319" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">字典矢量器</h1><p id="7dd3" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">正如我们所见，LabelEncoder 和 OneHotEncoder 通常需要作为两步程序一起使用。更方便的方法是使用字典矢量器，它可以同时完成这两个步骤。</p><p id="e176" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">首先，我们需要将数据帧转换成字典。这可以通过熊猫<code class="fe mt mu mv mf b"><a class="ae lz" href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_dict.html" rel="noopener ugc nofollow" target="_blank">to_dict</a></code>的方法来实现。</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="0b8b" class="mj jz iq mf b gy mk ml l mm mn"># turn X into dict<br/>X_dict = X.to_dict(orient='records') # turn each row as key-value pairs</span><span id="46a8" class="mj jz iq mf b gy mo ml l mm mn"># show X_dict<br/>X_dict</span></pre><p id="e970" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">需要<code class="fe mt mu mv mf b">orient='records'</code>将数据帧转换成<code class="fe mt mu mv mf b">{column:value}</code>格式。结果是一个字典列表，其中每个字典代表一个样本。注意，在这种情况下，我们不需要提取分类特征，我们可以将整个数据帧转换成字典。这是与 LabelEncoder 和 OneHotEncoder 相比的一个优势。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/64a20d6a0e4bb4bba1129ba56cbff9b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*Qv7kCRIodAe_UZDobunxkw.png"/></div></figure><p id="3778" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">现在我们实例化一个字典矢量器:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="dcca" class="mj jz iq mf b gy mk ml l mm mn"># DictVectorizer<br/>from sklearn.feature_extraction import DictVectorizer</span><span id="7106" class="mj jz iq mf b gy mo ml l mm mn"># instantiate a Dictvectorizer object for X<br/>dv_X = DictVectorizer(sparse=False) <br/># sparse = False makes the output is not a sparse matrix</span></pre><p id="427f" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated"><code class="fe mt mu mv mf b">sparse=False</code>使输出成为非稀疏矩阵。</p><p id="d33f" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">字典矢量器对转换后的字典进行拟合和转换:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="1798" class="mj jz iq mf b gy mk ml l mm mn"># apply dv_X on X_dict<br/>X_encoded = dv_X.fit_transform(X_dict)</span><span id="3885" class="mj jz iq mf b gy mo ml l mm mn"># show X_encoded<br/>X_encoded</span></pre><p id="f228" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">结果是一个 numpy 数组:</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi my"><img src="../Images/120266c019dcca5c50415be93b67dcf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*GZE_3HzGgNq6qsI1CyOI8g.png"/></div></figure><p id="00b3" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">每行代表一个样本，每列代表一个特征。如果我们想知道每一列的特性，我们可以检查这个字典矢量器的词汇表:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="02f9" class="mj jz iq mf b gy mk ml l mm mn"># vocabulary<br/>vocab = dv_X.vocabulary_</span><span id="b4ac" class="mj jz iq mf b gy mo ml l mm mn"># show vocab<br/>vocab</span></pre><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/5320feeab0c3aa81b7e23a3dee316e9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:352/format:webp/1*3s-JILdyTZ0JoH5rVkIoAg.png"/></div></figure><h1 id="61fd" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">拿假人</h1><p id="2a7c" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">Pandas get_dummies 方法是一个非常直接的一步程序，用于获取分类特征的虚拟变量。其优势在于，您可以直接将其应用于数据帧，其中的算法将识别分类特征并对其执行获取虚拟对象操作。下面是如何做到这一点:</p><pre class="ma mb mc md gt me mf mg mh aw mi bi"><span id="f8b8" class="mj jz iq mf b gy mk ml l mm mn"># Get dummies<br/>X = pd.get_dummies(X, prefix_sep='_', drop_first=True)</span><span id="cc21" class="mj jz iq mf b gy mo ml l mm mn"># X head<br/>X.head()</span></pre><p id="2ce3" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated"><code class="fe mt mu mv mf b">prefix_sep='_'</code>使得每个类都有一个唯一的名字，用分隔符隔开。<code class="fe mt mu mv mf b">drop_first=True</code>从生成的虚拟特征中删除一列。目的是避免多重共线性。结果如下:</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi na"><img src="../Images/4ce9a993c8a6c56e930b1dc649a6a88e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SN2Zm8mTWNf4UwMGsl_NGw.png"/></div></div></figure><h1 id="ccea" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">结论</h1><p id="a778" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">LabelEncoder 和 OneHotEncoder 通常需要作为两步方法一起使用来对分类特征进行编码。LabelEncoder 输出 dataframe 类型，而 OneHotEncoder 输出 numpy 数组。OneHotEncoder 可以选择输出稀疏矩阵。DictVectorizer 是一种编码和支持稀疏矩阵输出的一步方法。熊猫得到假人的方法是迄今为止编码分类特征最直接和最简单的方法。输出将保持数据帧类型。</p><p id="88fa" class="pw-post-body-paragraph kw kx iq ky b kz lu lb lc ld lv lf lg lh lw lj lk ll lx ln lo lp ly lr ls lt ij bi translated">在我看来，第一选择是熊猫拿假人。但是如果分类特征的数量很大，DictVectorizer 将是一个很好的选择，因为它支持稀疏矩阵输出。</p></div></div>    
</body>
</html>