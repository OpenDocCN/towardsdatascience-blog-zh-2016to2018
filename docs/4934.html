<html>
<head>
<title>“DOG BREEDS IMAGES CLASSIFICATION”</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">“犬种图像分类”</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60?source=collection_archive---------10-----------------------#2018-09-16">https://towardsdatascience.com/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60?source=collection_archive---------10-----------------------#2018-09-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="737e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">建立一个最先进的图像分类器。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/83a78ff68d7a0f37f199990dc8f4528c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*F5ZM40ejiJ84ZMkJMhp4Kw.jpeg"/></div></figure><p id="5da7" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">欢迎来到第二集的第二部分，我们将讨论<strong class="kp ir">狗的品种分类</strong>问题。我们有 120 种狗的图片需要分类。在我们开始之前，我想感谢<a class="ae lj" href="https://twitter.com/jeremyphoward" rel="noopener ugc nofollow" target="_blank"><strong class="kp ir"/></a>和<a class="ae lj" href="https://twitter.com/math_rachel" rel="noopener ugc nofollow" target="_blank"> <strong class="kp ir">雷切尔·托马斯</strong> </a>为民主化人工智能所做的努力。感谢牛逼的<a class="ae lj" href="http://www.fast.ai/" rel="noopener ugc nofollow" target="_blank"> <strong class="kp ir"> fast.ai </strong> </a>社区和<a class="ae lj" href="https://twitter.com/samcharrington" rel="noopener ugc nofollow" target="_blank"><strong class="kp ir">Sam Charrington</strong></a>for the online<a class="ae lj" href="https://www.youtube.com/playlist?list=PLILZm3MRkvH8Tfx91Z0CHtYluSOTEJdkr" rel="noopener ugc nofollow" target="_blank"><strong class="kp ir">TWiML&amp;AI x fast . AI 学习小组会议</strong> </a>。</p><p id="0097" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了充分利用这个博客系列，请按照以下顺序随意探索这个系列的第一部分:- <a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-1-e9cc80d81a9d">狗和猫的图像分类</a></p><ol class=""><li id="7d81" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60">犬种图像分类</a></li><li id="2056" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889">多标签图像分类</a></li><li id="265b" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-4-1-time-series-analysis-a23217418bf1">利用神经网络进行时间序列分析</a></li><li id="21f8" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/nlp-sentiment-analysis-on-imdb-movie-dataset-fb0c4d346d23" rel="noopener">IMDB 电影数据集上的 NLP 情感分析</a></li><li id="9c12" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-1-movie-recommendation-using-fastai-a53ed8e41269">电影推荐系统的基础</a></li><li id="7ca4" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-2-collaborative-filtering-from-scratch-1877640f514a">从零开始协同过滤</a></li><li id="c6d0" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-3-collaborative-filtering-using-neural-network-48e49d7f9b36">使用神经网络的协同过滤</a></li><li id="e910" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/fast-ai-season-1-episode-6-1-write-philosophy-like-nietzsche-using-rnn-8fe70cfb923c" rel="noopener">像尼采一样写哲学</a></li><li id="fd09" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/fast-ai-season-1-episode-7-1-performance-of-different-neural-networks-on-cifar-10-dataset-c6559595b529" rel="noopener">不同神经网络在 Cifar-10 数据集上的性能</a></li><li id="cc08" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://medium.com/hackernoon/single-object-detection-e65a537a1c31" rel="noopener">检测图像中最大物体的 ML 模型 Part-1 </a></li><li id="3074" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://medium.com/hackernoon/single-object-detection-part-2-2deafc911ce7" rel="noopener">检测图像中最大物体的 ML 模型 Part-2 </a></li></ol><p id="d7b1" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">没看过前一集的，请点击这里查看<a class="ae lj" href="https://medium.com/@GeneAshis/fast-ai-season-1-episode-2-1-e9cc80d81a9d" rel="noopener">第 2.1 集</a>。为了节省您的时间，我将在这里快速浏览最后一集。下面是我们构建一个最先进的分类器的步骤</p><ol class=""><li id="fdf2" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li lp lq lr ls bi translated">启用数据扩充并设置<code class="fe ly lz ma mb b"> PRECOMPUTE = TRUE.</code></li><li id="c945" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated">使用<code class="fe ly lz ma mb b"> lr_find() </code>找到损失仍在明显改善的最高学习率</li><li id="60d6" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated">从预先计算的几个时期的激活中训练最后一层。</li><li id="160a" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated">用<code class="fe ly lz ma mb b">CYCLE_LEN=1</code>训练数据增强的最后一层(即<code class="fe ly lz ma mb b">PRECOMPUTE=FALSE</code>)2-3 个历元。</li><li id="d6d0" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated">解冻所有层。</li><li id="9fc2" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated">将前几层设置为比下几层更低的学习速率，并对其进行训练。</li><li id="2edb" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated">再次使用<code class="fe ly lz ma mb b">lr_find()</code>。</li><li id="1a6f" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated">用<code class="fe ly lz ma mb b"> cycle_mult=2</code>训练全网，直到过拟合。</li></ol><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mc md l"/></div></figure><p id="93db" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">所以在这篇博文中，我们将讨论狗的品种识别。到这个 kaggle 数据集的链接出现在<a class="ae lj" href="https://www.kaggle.com/c/dog-breed-identification" rel="noopener ugc nofollow" target="_blank">这里</a>。主要目的是对 120 个品种的狗图像进行分类。</p><p id="f540" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> 1。下载数据并导入包。</strong></p><p id="a5df" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">所以要开始，我们必须下载数据。为了轻松获得这些数据，我们将使用 kaggle api。要了解更多关于这个 API 的信息，请点击查看<a class="ae lj" href="https://github.com/Kaggle/kaggle-api" rel="noopener ugc nofollow" target="_blank">。但是底线是</a></p><ul class=""><li id="f7ba" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li me lq lr ls bi translated"><strong class="kp ir">安装 kaggle api </strong></li><li id="f2c1" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li me lq lr ls bi translated"><strong class="kp ir">导入它</strong></li><li id="5e1c" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li me lq lr ls bi translated"><strong class="kp ir">并用它将数据下载到你想要的路径</strong>。下面的快照中已经执行了提到的步骤。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi mf"><img src="../Images/b8564487ca939fcd46ed1db28d065c55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bb1IIKrBmb7qeQhLUwlpbA.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">Downloading data done right</figcaption></figure><p id="429d" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">接下来，让我们导入所有必需的包:-</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><p id="f119" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><code class="fe ly lz ma mb b"><a class="ae lj" href="https://www.npmjs.com/package/glob" rel="noopener ugc nofollow" target="_blank">glob</a></code>包将使用 shell 使用的模式匹配文件。在下面的代码中，我们可以看到 glob 有助于获取上述路径中的所有文件。在下面的要点中从第 7 行开始提到了输出。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><p id="a24a" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> 2。检查 GPU 可用性并解压缩下载的文件</strong></p><p id="c64b" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">要确保 GPU 对您可用，请运行以下命令。这些应该返回 true。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">Cuda done right</figcaption></figure><p id="fbee" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">下载完所有文件后，下面的代码有助于解压这些文件。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">unzipppp</figcaption></figure><p id="21f5" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> 3。使用熊猫熟悉数据</strong></p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp md l"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">import PANDAS as 🐼</figcaption></figure><p id="6123" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在让我们检查数据。拉开<code class="fe ly lz ma mb b"> train and test zip files</code>的拉链后，我们会知道它有 120 种狗的图片。<code class="fe ly lz ma mb b">Sample_submission.csv</code> files 告诉我们竞赛在提交过程中期望的文件内容。让我们看看<code class="fe ly lz ma mb b">labels.csv </code>文件的内容。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><p id="a5ae" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">它包含狗的所有图像的<code class="fe ly lz ma mb b">image_id</code>和狗所属的<code class="fe ly lz ma mb b">breed or labels</code>。<code class="fe ly lz ma mb b">labels.csv</code>为训练和测试数据集中的图像提供品种。这种变通方法使生活变得更加轻松。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/7ae518202733603ede3176b7763cc91f.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*y8QhSCnMcMpAa8y27LTDvQ.png"/></div></figure><p id="71a6" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">让我们检查一下一个特定品种有多少只狗。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/ab62ced019fbd29bee2aed79465e3a26.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*yBTTsjY62kxO3eIgfz7TsQ.png"/></div></figure><p id="1389" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上面的输出显示了 120 种狗的品种，并以降序显示了对应于每种狗的图像数量。对不起，我不能在一张快照中容纳所有的品种。</p><p id="a1cf" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">通常，我们有一个训练、验证和测试数据集。我们在训练数据集上训练我们的模型，同时在验证数据集上预测它。这涉及到参数调整，以提高验证数据集的准确性。最后，当我们确信我们的模型是好的，我们用它来预测未知的数据集，即测试数据集。这个过程有助于防止过度拟合。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">vaidation dataset done right</figcaption></figure><p id="8d94" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上面的第一行设置了 label.csv 文件的路径。第 2 行打开文件并计算数据集除标题之外的行数，因此减 1。这为我们提供了 csv 文件中的行数或图像数。第 3 行中的<code class="fe ly lz ma mb b">get_cv_idxs(n) </code>将随机返回 20%的数据，用作<strong class="kp ir">验证数据集</strong>。这将返回我们将用作验证数据集的文件的索引。让我们交叉核对这一个。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><p id="51c4" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">！！！似乎是合法的！！！验证数据集的大小实际上是总数据集大小的 20%。</p><p id="8d41" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在，我们将使用预先训练好的<code class="fe ly lz ma mb b">resnext_101_64 </code>架构来构建我们的模型。</p><p id="8e96" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">当我写这篇博客的时候，fastai 库中没有预训练的<code class="fe ly lz ma mb b">resnext_101_64</code>架构的权重，所以我们必须将其下载到这个位置<code class="fe ly lz ma mb b">'/usr/local/lib/python3.6/dist-packages/fastai/weights' </code>，然后运行我们的模型，否则它会抛出一个错误消息<code class="fe ly lz ma mb b">weights not found </code>。按照下面代码中解释的步骤进行操作。</p><blockquote class="ms mt mu"><p id="b9dd" class="kn ko mv kp b kq kr jr ks kt ku ju kv mw kx ky kz mx lb lc ld my lf lg lh li ij bi translated">获得预训练模型权重的步骤</p></blockquote><ul class=""><li id="8980" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li me lq lr ls bi translated">使用中提到的链接(第 3 行)将预训练模型下载到任何位置。</li><li id="30ab" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li me lq lr ls bi translated">将其移动到上述位置。(第 20 行)</li><li id="7975" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li me lq lr ls bi translated">将上述位置作为您的当前目录。(第 23 行)</li><li id="f81f" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li me lq lr ls bi translated">并解压文件。(第 27 行)</li><li id="265f" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li me lq lr ls bi translated">回到你存放数据的地方。(第 41 行)</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">resnext101 weights</figcaption></figure><p id="01e5" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">注意:- <em class="mv"> </em> </strong> <em class="mv">将来，如果发生新的 fastai 代码更新，可能会考虑上述步骤，因此该步骤可能是可选的。</em></p><p id="b081" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在继续下一步之前，决定图像的大小、使用的架构以及要考虑的批量大小。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><p id="12e1" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> 4。按照 FASTAI 格式设置数据</strong></p><p id="8df9" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了按照 fastai 格式设置数据，我们编写以下代码。请注意，之前我们曾经为<a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-1-e9cc80d81a9d">狗与猫分类器</a>做了<code class="fe ly lz ma mb b">ImageClassfierData.from_paths()</code>，因为我们在单独的文件夹中指定了数据。在这种情况下，文件夹的名称就是标签的名称。</p><p id="b276" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">但是在这里，我们将数据(图像)呈现在 train 和 test 文件夹中，文件名汇总在<code class="fe ly lz ma mb b">labels.csv</code>文件中。labels.csv 文件包含训练和测试数据集中每个图像的标签/品种，因此我们选择如下所示的<code class="fe ly lz ma mb b">ImageClassfierData.from_csv(...) </code>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><p id="f0da" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">参数</strong> <code class="fe ly lz ma mb b"><strong class="kp ir">ImageClassfierData.from_csv(...)</strong></code> <strong class="kp ir">为:</strong></p><ul class=""><li id="0183" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li me lq lr ls bi translated"><code class="fe ly lz ma mb b">PATH</code>是数据的根路径(用于存储训练模型、预计算值等)。还包含所有的数据。</li><li id="ffe9" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li me lq lr ls bi translated"><code class="fe ly lz ma mb b">'train'</code> —包含训练数据的文件夹。</li><li id="4962" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li me lq lr ls bi translated"><code class="fe ly lz ma mb b">labels.csv</code>文件中有不同狗狗图片的标签。</li><li id="59e1" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li me lq lr ls bi translated"><code class="fe ly lz ma mb b">val_idxs </code>有验证数据。它指示已经放入验证数据集中的 labels.csv 中的索引号。</li><li id="6a57" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li me lq lr ls bi translated"><code class="fe ly lz ma mb b">test_name='test' </code>是<code class="fe ly lz ma mb b">test </code>数据集。</li><li id="12fb" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li me lq lr ls bi translated">文件名实际上在末尾有一个<code class="fe ly lz ma mb b">.jpg</code>，在<code class="fe ly lz ma mb b">labels.csv</code>文件中没有提到，因此我们有<code class="fe ly lz ma mb b">suffix=’.jpg’</code>。这将把<code class="fe ly lz ma mb b">.jpg</code>添加到文件名的末尾。</li><li id="8f0f" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li me lq lr ls bi translated"><code class="fe ly lz ma mb b">tfms </code>是我们要申请的数据增强的转换。</li></ul><p id="a4e6" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">上面已经创建了数据对象。使用<code class="fe ly lz ma mb b">data </code>对象，我们可以检查<code class="fe ly lz ma mb b">train_ds</code>(训练数据集)。要知道使用数据对象还能访问什么，写<code class="fe ly lz ma mb b">data. </code>并按 tab 键。将出现一个下拉菜单，显示<code class="fe ly lz ma mb b">data </code>对象的属性。下面提到的<code class="fe ly lz ma mb b">fnames </code>告诉我们训练数据集中存在的文件名。</p><p id="5bfc" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">让我们检查图像是否位于正确的位置:-</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><p id="2881" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">图像的输出如下所示。正如我们所看到的，狗的图像占据了大部分的画面，因此不用担心变换(<code class="fe ly lz ma mb b">tfms</code>)阶段的裁剪或缩放技术。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/8a2584eb18119f6438daa0440a675aee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*DZzw7wHgEOJIjJhyDZqJyg.png"/></div></figure><p id="48e9" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">下面的第 6 行将文件名映射到文件的大小，并将其存储在<code class="fe ly lz ma mb b">size_d</code>中。<code class="fe ly lz ma mb b">size_d </code>是一个字典，其中键是文件名，值是每个文件的维度。第 8 行有<code class="fe ly lz ma mb b">zip(*) </code>命令，帮助解压行和列，并保存在<code class="fe ly lz ma mb b">row_sz </code>和<code class="fe ly lz ma mb b">col_sz</code>中。</p><p id="7d9c" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">图像的大小是:-</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><p id="78b8" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">检查下面 1 号线<code class="fe ly lz ma mb b">train dataset</code>和<code class="fe ly lz ma mb b">test dataset </code>以及 5 号线<code class="fe ly lz ma mb b">number of data classes/dog breeds</code>和<code class="fe ly lz ma mb b">what are the first five breed of dogs</code>的尺寸。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><p id="ed53" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在进一步讨论之前，让我们检查一下我们正在建模的数据的维度。这只是为了检查的目的。因此:-</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi na"><img src="../Images/9eda2c09705b469b513004393b49de02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dxJI4Niuz9svo6eGQDU4Jg.png"/></div></div></figure><p id="8040" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在上面的直方图中，我们可以看到，我们有 5000 个尺寸约为 500 像素的图像，很少有图像大于 1000 像素。在下面的直方图中，我们只检查尺寸低于 1000 像素的图像。它还显示了有多少特定尺寸的图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nb"><img src="../Images/8caeec0db5238af5130c8a6052d5af5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VVf3KmYZbEX3JMU-awWxmQ.png"/></div></div></figure><p id="27b7" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir"> 5。建立一个最先进的分类器。</strong></p><p id="e58a" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">等待结束了。最终呈现在你面前的是最先进的分类器。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><p id="9df8" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">对于最先进的分类器，需要遵循几个步骤。它们如下:</p><blockquote class="ms mt mu"><p id="4e40" class="kn ko mv kp b kq kr jr ks kt ku ju kv mw kx ky kz mx lb lc ld my lf lg lh li ij bi translated"><strong class="kp ir"> 5.1)启用数据扩充并设置 PRECOMPUTE =TRUE。</strong></p></blockquote><p id="08ad" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">出于一致性目的，让我们调整数据的大小。<code class="fe ly lz ma mb b">get_data()</code>有正常的几行代码。第一个是<code class="fe ly lz ma mb b">Setup data augmentation</code>，另一个是<code class="fe ly lz ma mb b">Format your data </code>，我们把 image_size 和 batch_size 传递给这个函数。当我们开始处理新的数据集时，如果我们先处理小图像，那么一切都会变得非常快。因此我们从尺寸<code class="fe ly lz ma mb b">sz=224 and bs=64 </code>开始。之后我们可以增加尺寸。如果在增加大小时我们看到<code class="fe ly lz ma mb b">Cuda Out of Memory error</code>，重启内核，将批处理大小设置为较小的值，然后再次运行。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><p id="3fc0" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><em class="mv">现在让我们用 precompute=True </em>设置神经网络:-</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="gh gi nc"><img src="../Images/c40297bb3524ee5d8697b34ea9782513.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZVGHiS7swTn6FrxAuPMYNQ.png"/></div></div></figure><p id="f931" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">当使用<code class="fe ly lz ma mb b">ConvLearner.pretrained(…)</code>声明架构时，预计算被设置为 True，这表示它实现了来自预训练网络的激活。预训练网络是已经学会识别某些事物的网络。对于我们的狗品种识别案例研究，使用的预训练网络(<code class="fe ly lz ma mb b">RESNEXT101_64</code>)已经学会对 ImageNet 数据集中 120 万张图像的 1000 个类别进行分类。因此，采取倒数第二层(因为这是一层，有所有必要的信息来计算出图像是什么)，并保存这些激活。卷积神经网络有称为“激活”的东西激活是丰富的功能。激活是一个数字，表示“这个特性在这个地方，具有这个置信度(概率)”。为每个图像保存这些激活，这些被称为预计算激活。现在，当创建新的分类器时，利用这些预先计算的激活，并基于这些激活快速训练模型。因此要实现这个设置<code class="fe ly lz ma mb b">precompute=True</code>。</p><p id="556e" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">预训练方法从<code class="fe ly lz ma mb b">arch </code>模型中创建我们的新神经网络。同时，它做如下两件事:-</p><ul class=""><li id="d227" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li me lq lr ls bi translated">它所做的是，它保留除最后一层之外的所有层(最后一层是输出层，在 Imagenet 的情况下，它给出 1000 个类别内的概率)。</li><li id="cf51" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li me lq lr ls bi translated">最后一层被添加的几个层所取代，这些层以输出层结束，输出层给出了所有 120 种犬种的概率。</li></ul><p id="1785" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">所以最初一切都是<code class="fe ly lz ma mb b">frozen </code>和<code class="fe ly lz ma mb b">precompute=True</code>，因此我们所学的都是我们添加的图层。与<code class="fe ly lz ma mb b">precompute=True </code>一样，<br/>数据增强没有做任何事情，因为我们每次都显示完全相同的激活。<code class="fe ly lz ma mb b">precompute=True</code>所做的是预先计算图像有多少看起来像激活的东西。<code class="fe ly lz ma mb b">Precomputed activations</code>是我们不打算训练的每个冻结层中使用的激活函数的输出。这有助于我们在最后加速新添加的完全连接层的训练。我们只预计算网络倒数第二层的激活。在所有层上执行都是存储密集型的。</p><blockquote class="ms mt mu"><p id="d5dd" class="kn ko mv kp b kq kr jr ks kt ku ju kv mw kx ky kz mx lb lc ld my lf lg lh li ij bi translated"><strong class="kp ir"> 5.2)使用</strong> <code class="fe ly lz ma mb b"><strong class="kp ir">lr_find()</strong></code> <strong class="kp ir">找到损失仍在明显改善的最高学习率</strong></p></blockquote><p id="60ec" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">以下命令有助于找到最佳学习率。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/3739defb5bfbd0f42dc7ba6a644acdb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*QTmI9royRJyyeydkrNvmJg.png"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><p id="e369" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">该命令产生如下图所示的图形，该图显示了学习率随着迭代次数的增加而增加的事实。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/53d8e454f6dd479aa1d666f109d3fee8.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*8Bi1SRE-af_cHqy2niPJeQ.png"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><p id="776f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">该命令绘制了损耗与学习率的关系，给出的结果表明，随着学习率的增加，损耗达到最小值，然后出现一个点，在该点之后，损耗超过最小值，因此损耗变得更大。因此，我们必须选择一个与最小损失相对应的学习率。但是此时的学习率已经太高了，所以我们从学习率表上的最小损失点后退一步，选择它作为最佳学习率。这里是<code class="fe ly lz ma mb b">0.01</code>。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/8420386ad58a562bc80bc16ba501d7b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*dSe_sfZTexuuvbhtZOiaMg.png"/></div></figure><blockquote class="ms mt mu"><p id="e7a3" class="kn ko mv kp b kq kr jr ks kt ku ju kv mw kx ky kz mx lb lc ld my lf lg lh li ij bi translated">5.3) <strong class="kp ir">从几个时期的预计算激活中训练最后一层。</strong></p></blockquote><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/786f7a46f46cc8dd9d2a894e8491dd70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*rgE-0vB3ASI167aYUHpz0g.png"/></div></figure><p id="4ca4" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这里，我们选择最佳学习率(<code class="fe ly lz ma mb b">0.01</code>)并训练 NN 的最后一层(因为预计算=真且第一层被冻结)，即它们的权重将被更新，以最小化模型的损失。使用这种技术，我们达到了<code class="fe ly lz ma mb b">92%</code>的精度。但是有一点点过度拟合，因为我们的验证损失大于训练损失。为了避免这种情况，我们引入了<code class="fe ly lz ma mb b">Dropout </code>、<code class="fe ly lz ma mb b">Data Augmentation</code>和<code class="fe ly lz ma mb b">training on larger images</code>。</p><blockquote class="ms mt mu"><p id="df4e" class="kn ko mv kp b kq kr jr ks kt ku ju kv mw kx ky kz mx lb lc ld my lf lg lh li ij bi translated">5.4) <strong class="kp ir">在 CYCLE_LEN=1 的 2-3 个历元内，训练最后一层的数据扩充。</strong></p></blockquote><ul class=""><li id="126f" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li me lq lr ls bi translated"><strong class="kp ir">辍学</strong></li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/154e18ebf122a05294b5cdd20b1976d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*ximEUd-S-moSR9glyeOwqg.png"/></div></figure><p id="32a8" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><code class="fe ly lz ma mb b">ps </code>是漏失参数。它指的是随机丢弃 50%的神经元。这有助于神经网络防止过度学习，从而防止过度拟合。正如我们可以看到的，此时我们的精度已经下降到了<code class="fe ly lz ma mb b">91.6%</code>，但好消息是我们的验证损失小于训练损失，这是一个明确的迹象，表明我们没有过度拟合。</p><ul class=""><li id="e526" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li me lq lr ls bi translated"><strong class="kp ir">数据扩充</strong></li></ul><p id="587b" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了进一步改进模型，我们需要更多的数据，因此通过设置<code class="fe ly lz ma mb b">learn.precompute=False</code>打开数据扩充。通过设置<code class="fe ly lz ma mb b">precompute=False,</code>,我们仍然只训练我们在最后添加的层，因为它被冻结了，但是数据增加现在正在工作，因为它实际上从头开始经历和重新计算所有的激活。cycle_len 的概念在<a class="ae lj" href="https://medium.com/@GeneAshis/fast-ai-season-1-episode-2-1-e9cc80d81a9d" rel="noopener">上一集</a>已经详细讨论过了。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/64a52d7500a1833820068ca867062f87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*HnLHRRz_Xe87FSUPhhx-8A.png"/></div></figure><p id="fd19" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">后<strong class="kp ir">数据增加</strong>我们看到<code class="fe ly lz ma mb b">92.17%</code>的精确度增加，没有任何过度拟合。</p><p id="0996" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">注意:- </strong> An <code class="fe ly lz ma mb b">epoch </code>是一次通过数据，a <code class="fe ly lz ma mb b">cycle </code>是一个周期中出现的时期数。所以这里 cycle 基本上和 epoch 是一样的。</p><ul class=""><li id="3006" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li me lq lr ls bi translated"><strong class="kp ir">在较大的图像上训练是防止过度拟合的最好方法。</strong></li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/cc2e451c5ff7b54adb870685953fd0b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*5NQSEFJl2XcalSHG_2e96g.png"/></div></figure><p id="377e" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">现在我们看到了拟合不足的情况，因为验证损失比训练损失低得多。我们的主要目标应该是使 val_loss 和 trn_loss 尽可能接近，同时注意精度。</p><p id="5e18" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><code class="fe ly lz ma mb b">Cycle_len=1</code>可能太短了。让我们设置<code class="fe ly lz ma mb b">cycle_mult=2</code>以找到更好的参数。这将有助于防止不合身。当我们拟合不足时，这意味着<code class="fe ly lz ma mb b">cycle_len=1</code>太短(在它有机会放大并选择最佳参数之前，学习率被重置)。<code class="fe ly lz ma mb b">cycle_mult</code>的概念已经在<a class="ae lj" href="https://medium.com/@GeneAshis/fast-ai-season-1-episode-2-1-e9cc80d81a9d" rel="noopener">这里详细讨论过</a>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/2aba63efa24b99cd51414fa17fb0c5d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*rPH3qkcKLC6ugO8mcNeDSA.png"/></div></figure><p id="e005" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">让我们为更多的时代训练它。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/69438375f7eae26bc97670c65310071b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*jHBHqDyUf1xlUfDYws5MWQ.png"/></div></figure><p id="0b69" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">！！！但是等等！！！</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl md l"/></div></figure><p id="a1ef" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如果您仔细观察输出，我们的 val_loss 仍然略高于 trn_loss。这是否意味着它的过度拟合，对我们的神经网络有害。让我们来听听专家的意见，看看为什么一点点过度拟合是好的。查看下面的链接。</p><div class="nm nn gp gr no np"><a href="http://forums.fast.ai/t/determining-when-you-are-overfitting-underfitting-or-just-right/7732/5?u=ashis" rel="noopener  ugc nofollow" target="_blank"><div class="nq ab fo"><div class="nr ab ns cl cj nt"><h2 class="bd ir gy z fp nu fr fs nv fu fw ip bi translated">确定你什么时候过度适应，什么时候不适应，什么时候刚刚好？</h2><div class="nw l"><h3 class="bd b gy z fp nu fr fs nv fu fw dk translated">过拟合 if:训练损失&gt;验证损失恰到好处 if 训练损失~验证损失问题:我们应该如何…</h3></div><div class="nx l"><p class="bd b dl z fp nu fr fs nv fu fw dk translated">forums.fast.ai</p></div></div><div class="ny l"><div class="nz l oa ob oc ny od kl np"/></div></div></a></div><p id="d7b8" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">除此之外，这个数据集类似于 ImageNet 数据集。所以训练卷积层帮助不大。因此，我们不打算解冻所有的层。最后，我们正在做<code class="fe ly lz ma mb b">TTA</code> ( <a class="ae lj" href="https://medium.com/@GeneAshis/fast-ai-season-1-episode-2-1-e9cc80d81a9d" rel="noopener">测试时间增加</a>)并得到预测概率。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mo md l"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/99bfa6be3dec6b799aee33e586d289e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*J90OFC7rMBet7eAAArLZWQ.png"/></div></figure><p id="fe1e" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在最后一步，我们计算精度和损失。很高兴看到我们的模型在测试数据集上获得了<code class="fe ly lz ma mb b">93.3%</code>的准确性，这简直是<strong class="kp ir">令人兴奋的</strong>。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nl md l"/></div></figure><p id="0c9d" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这就是我们如何得到最先进的结果，我的朋友。</p><p id="1c0f" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">附:随着我继续学习其他课程，这篇博文将会更新和改进。如果你对源代码感兴趣，请点击  <em class="mv">查看</em> <a class="ae lj" href="https://github.com/CaptainAshis/Deep_Learning-Experiment/blob/master/Dog%20Breed%20Identification%20Kaggle/dog_breed_updated.ipynb" rel="noopener ugc nofollow" target="_blank"> <em class="mv">。</em></a></p><p id="fc13" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated"><strong class="kp ir">甲乙丙</strong> - <em class="mv">一直在鼓掌。👏 👏👏👏👏</em>😃😃😃😃😃😃😃😃😃<em class="mv">👏 👏👏👏👏 👏</em></p><p id="a6db" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">感谢大卫·罗宾逊的激励😃😃😃😃😃😃</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="of md l"/></div></figure><p id="0493" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">为了充分利用这个博客系列，请按照以下顺序随意探索这个系列的第一部分</p><ol class=""><li id="b4a8" class="lk ll iq kp b kq kr kt ku kw lm la ln le lo li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-1-e9cc80d81a9d">狗 Vs 猫图像分类</a></li><li id="2172" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-2-2-dog-breed-classification-5555c0337d60">犬种图像分类</a></li><li id="e22b" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-3-a-case-of-multi-label-classification-a4a90672a889">多标签图像分类</a></li><li id="9e97" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-4-1-time-series-analysis-a23217418bf1">利用神经网络进行时间序列分析</a></li><li id="3852" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/nlp-sentiment-analysis-on-imdb-movie-dataset-fb0c4d346d23" rel="noopener">IMDB 电影数据集上的 NLP 情感分析</a></li><li id="f3bf" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-1-movie-recommendation-using-fastai-a53ed8e41269">电影推荐系统的基础</a></li><li id="b6d0" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-2-collaborative-filtering-from-scratch-1877640f514a">从零开始协同过滤</a></li><li id="12bd" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" rel="noopener" target="_blank" href="/fast-ai-season-1-episode-5-3-collaborative-filtering-using-neural-network-48e49d7f9b36">使用神经网络的协同过滤</a></li><li id="6c52" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/fast-ai-season-1-episode-6-1-write-philosophy-like-nietzsche-using-rnn-8fe70cfb923c" rel="noopener">像尼采一样写哲学</a></li><li id="f898" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://geneashis.medium.com/fast-ai-season-1-episode-7-1-performance-of-different-neural-networks-on-cifar-10-dataset-c6559595b529" rel="noopener">不同神经网络在 Cifar-10 数据集上的性能</a></li><li id="25af" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://medium.com/hackernoon/single-object-detection-e65a537a1c31" rel="noopener">检测图像中最大物体的 ML 模型 Part-1 </a></li><li id="94d1" class="lk ll iq kp b kq lt kt lu kw lv la lw le lx li lp lq lr ls bi translated"><a class="ae lj" href="https://medium.com/hackernoon/single-object-detection-part-2-2deafc911ce7" rel="noopener">检测图像中最大物体的 ML 模型 Part-2 </a></li></ol><p id="7ecf" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">如果您有任何问题，请随时联系<a class="ae lj" href="http://forums.fast.ai/" rel="noopener ugc nofollow" target="_blank"> fast.ai 论坛</a>或 Twitter:<a class="ae lj" href="https://twitter.com/ashiskumarpanda" rel="noopener ugc nofollow" target="_blank">@ ashiskumarpanda</a></p></div></div>    
</body>
</html>