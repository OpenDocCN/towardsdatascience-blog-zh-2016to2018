<html>
<head>
<title>A n00bs guide to Apache Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark的n00bs指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/apache-spark-101-3f961c89b8c5?source=collection_archive---------1-----------------------#2017-06-04">https://towardsdatascience.com/apache-spark-101-3f961c89b8c5?source=collection_archive---------1-----------------------#2017-06-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="7fdb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我写这篇指南是为了帮助我理解Spark的基本底层功能，它在Hadoop生态系统中的位置，以及它如何在Java和Scala中工作。我希望它能像帮助我一样帮助你。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/8e34dd2c2ec7b8a9b3700ae441a6250c.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*Pa7PO1v7bANI7C-eHMS_PQ.png"/></div></figure><h1 id="ad08" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">什么是火花？</h1><p id="5fed" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">Spark是一个通用计算引擎，在内存框架中。它允许您以脚本方式在各种语言中执行实时和批处理工作，具有强大的容错能力。你为什么要关心火花是什么？坦率地说，它解决了Hadoop MapReduce的许多缺点，比Hadoop MapReduce快10到100倍。 Spark是数据科学的大事；使用Spark的一些著名组织有:亚马逊、NASA喷气推进实验室、IBM和日立。这篇文章的目标是给你一个关于Spark提供的功能，它的基本内部工作的快速概述，并让你对Spark有多棒有所了解。</p><h1 id="5c70" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">激发大数据环境中的背景</h1><p id="ca72" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">Spark被设计为与外部集群管理器或它自己的独立管理器一起工作。Spark也依赖于分布式存储系统来运行，它从该系统中调用它想要使用的数据。支持以下系统:</p><h2 id="a12d" class="lx ku iq bd kv ly lz dn kz ma mb dp ld jy mc md lh kc me mf ll kg mg mh lp mi bi translated">集群管理器:</h2><ul class=""><li id="96f4" class="mj mk iq jp b jq lr ju ls jy ml kc mm kg mn kk mo mp mq mr bi translated">Spark独立管理器</li><li id="bedc" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated">Hadoop纱线</li><li id="6ac1" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated">阿帕奇Mesos</li></ul><h2 id="ea44" class="lx ku iq bd kv ly lz dn kz ma mb dp ld jy mc md lh kc me mf ll kg mg mh lp mi bi translated">分布式存储系统:</h2><ul class=""><li id="008c" class="mj mk iq jp b jq lr ju ls jy ml kc mm kg mn kk mo mp mq mr bi translated">Hadoop分布式文件系统(HDFS)</li><li id="b47d" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated">MapR文件系统(MapR-FS)</li><li id="ac0e" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated">卡桑德拉</li><li id="0d04" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated">OpenStack Swift</li><li id="92f9" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated">亚马逊S3</li><li id="6cef" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated">条纹羚</li></ul><p id="49fa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">出于健康的原因，我将只关注Hadoop生态系统环境中的Spark。</p><p id="6236" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Spark Core提供了一个平台，解决了Hadoop MapReduce的许多缺点，因为它允许我们不再需要将任务分解为小的atom作业，也不再需要与在分布式系统开发上构建解决方案的复杂性进行争论。</p><p id="ab4d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="mx">赛门铁克注:</em> </strong>术语<em class="mx"> Hadoop </em>可互换使用，指<em class="mx"> Hadoop生态系统</em>或<em class="mx"> Hadoop MapReduce </em>或<em class="mx"> Hadoop HDFS </em>。在网上看到“Spark取代Hadoop”或“Spark是新的Hadoop”的说法是很常见的，然后倾向于相信他们的意思是Spark正在取代所有的Hadoop服务，但是！他们真正的意思是，Spark正在许多用例中扮演Hadoop MapReduce功能的角色。</p><p id="37d9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Spark Core非常通用，在设计时就考虑到了Hadoop生态系统；它可以与MapReduce一起工作，或者为PIG、HIVE和SEARCH提供一个替代平台。参见图1</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi my"><img src="../Images/d09e7cb398777c11f0f83995018c35c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z0Vm749Pu6mHdlyPsznMRg.png"/></div></div></figure><h2 id="70da" class="lx ku iq bd kv ly lz dn kz ma mb dp ld jy mc md lh kc me mf ll kg mg mh lp mi bi translated">Spark Core还带来了自己的一套有用的API:</h2><p id="7b74" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated"><strong class="jp ir"> Spark Streaming: </strong>管理来自各种来源的实时数据。它允许通过在实时流上实现ML Lib和Graphx来计算实时结果。</p><p id="552a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">GraphX: 一个非常强大的处理图形并行计算的库。不要把这个和“Power Point graphs”混淆，这个库是关于数学中的一个领域，叫做图论和对象间成对关系的建模。</p><p id="144e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> ML Lib: </strong>在原生分布式环境中对大型数据集运行机器学习算法的库。与Python或Matlab中更强大的机器学习库相比，该库仍处于起步阶段。</p><p id="dfd2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> Spark SQL: </strong>允许使用SQL采石场来挖掘非关系分布式数据库。</p><p id="396b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Spark Steaming、GraphX、MLLib和Spark SQL都将在适当的时候获得自己的文章，但与此同时，请不要犹豫，去查阅官方文档<a class="ae lw" href="http://spark.apache.org/docs/latest/streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank">【1】</a><a class="ae lw" href="http://spark.apache.org/docs/latest/graphx-programming-guide.html" rel="noopener ugc nofollow" target="_blank">【2】</a><a class="ae lw" href="http://spark.apache.org/docs/latest/ml-guide.html" rel="noopener ugc nofollow" target="_blank">【3】</a><a class="ae lw" href="http://spark.apache.org/docs/latest/sql-programming-guide.html" rel="noopener ugc nofollow" target="_blank">【4】</a>。</p><h1 id="d7f9" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">什么会产生火花，火花？</h1><p id="bfaa" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">在最高的抽象层次上，Spark由三个组件组成，这三个组件使它成为唯一的Spark；司机、执行者和DAG。</p><h1 id="d2a3" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">司机和执行者</h1><p id="bb8a" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">Spark采用主从架构。驱动程序协调许多分布式工作器，以便以分布式方式执行任务，而资源管理器处理资源分配以完成任务。</p><h2 id="fef9" class="lx ku iq bd kv ly lz dn kz ma mb dp ld jy mc md lh kc me mf ll kg mg mh lp mi bi translated">驾驶员</h2><p id="1b90" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">把它想象成“管弦乐队”。驱动程序是主方法运行的地方。它将程序转换成任务，然后将任务调度给执行器。司机有三种不同的方式与执行者沟通；Broadcast、Take、DAG——这些稍后会详细说明。</p><h2 id="ea5b" class="lx ku iq bd kv ly lz dn kz ma mb dp ld jy mc md lh kc me mf ll kg mg mh lp mi bi translated">执行者——“工人”</h2><p id="2b3b" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">执行器在JVM实例中执行驱动程序委派的任务。执行器在Spark应用程序开始时启动，通常在应用程序的整个生命周期内运行。这种方法允许在应用程序的整个生命周期中，当不同的任务被载入和执行时，数据被持久化在内存中。</p><p id="a718" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">与此形成鲜明对比的是，Hadoop MapReduce中的JVM工作环境会针对每个任务关闭和打开。其结果是，Hadoop必须在每个任务的开始和结束时对磁盘执行读写操作。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nd"><img src="../Images/eb98189ad7b94351d0f847ebabf7ff76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sCv4GPI4qThyFL8Ej3-D9w.png"/></div></div></figure><h2 id="fedd" class="lx ku iq bd kv ly lz dn kz ma mb dp ld jy mc md lh kc me mf ll kg mg mh lp mi bi translated">驱动程序与执行器的通信</h2><p id="5575" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">驱动程序可以通过几种方法与执行器通信。作为开发人员或数据科学家，了解不同类型的通信及其用例非常重要。</p><ol class=""><li id="7c6e" class="mj mk iq jp b jq jr ju jv jy ne kc nf kg ng kk nh mp mq mr bi translated">广播动作:驱动程序将必要的数据传输给每个执行器。此操作最适用于一百万条记录以下的数据集，即+/-1gb的数据。这项行动可能会成为一项非常昂贵的任务。</li><li id="7ab7" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk nh mp mq mr bi translated">采取行动:驱动程序从所有执行者那里获取数据。这个动作可能是非常昂贵和危险的动作，因为驱动程序可能耗尽存储器，并且网络可能变得不堪重负。</li><li id="fa33" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk nh mp mq mr bi translated">DAG动作:这是三个动作中花费最少的一个。它将控制流逻辑从驱动程序传输到执行器。</li></ol><h2 id="7d02" class="lx ku iq bd kv ly lz dn kz ma mb dp ld jy mc md lh kc me mf ll kg mg mh lp mi bi translated">系统要求</h2><p id="6921" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">Spark比Hadoop MapReduce有相当大的性能增益，但它也有较高的操作成本，因为它在内存中操作，并需要高带宽网络环境(建议+10Gb/s)。建议Spark集群中的内存至少应与您需要处理的数据量一样大。如果没有足够的内存来完成一项任务，Spark有几种方法可以将数据溢出到磁盘上。<a class="ae lw" href="https://spark.apache.org/docs/0.9.1/hardware-provisioning.html" rel="noopener ugc nofollow" target="_blank">了解更多硬件要求和建议。</a></p><h1 id="6cc5" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">达格</h1><p id="cb5d" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">DAG是一个有向无环图，它概括了从A点到b点所需的一系列步骤。Hadoop MapReduce与大多数其他计算引擎一样，独立于DAG工作。这些独立于DAG的计算引擎依赖于HIVE或PIG等脚本平台将作业链接在一起，以实现所需的结果。Spark在比较中的强大之处在于它能够识别DAG并主动管理DAG。这使得Spark能够优化作业流以获得最佳性能，并允许回滚和作业冗余功能。</p><p id="4d45" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请看图3。我将通过讨论DAG的组件来详细说明它是如何工作的。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi ni"><img src="../Images/d9383d957591fd6b957c2819d2eaa73f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WGXwt6BVCEyknQZh7_Vpzw.png"/></div></div></figure><h2 id="a23d" class="lx ku iq bd kv ly lz dn kz ma mb dp ld jy mc md lh kc me mf ll kg mg mh lp mi bi translated">1)来源</h2><p id="5aab" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">数据源可以是Spark支持的任何数据源。其中包括:HDFS、关系数据库、CSV文件等。稍后您将看到，我们在环境上下文设置中对此进行了定义。</p><h2 id="a324" class="lx ku iq bd kv ly lz dn kz ma mb dp ld jy mc md lh kc me mf ll kg mg mh lp mi bi translated">2) RDD</h2><p id="61a5" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">弹性分布式数据集本质上是不能改变的数据集。这些实体存在于记忆中，并且本质上是不可改变的。由于这种不变性；在现有RDD上执行每次转换后，都会创建一个新的RDD。这种设计的结果是冗余；如果在DAGs执行中的任何一点出现故障，则可以回滚到正常工作状态，并重新尝试失败的操作/转换。</p><p id="4262" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">原始形式的rdd没有模式，但是可以使用一种叫做DataFrames的东西来扩展。DataFrames向其中包含的数据集添加模式功能；这在处理关系数据集时非常有用。</p><h2 id="69b7" class="lx ku iq bd kv ly lz dn kz ma mb dp ld jy mc md lh kc me mf ll kg mg mh lp mi bi translated">3)转型</h2><p id="b18d" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">转变把一个RDD变成了另一个RDD。一些示例转换包括:</p><ol class=""><li id="2bac" class="mj mk iq jp b jq jr ju jv jy ne kc nf kg ng kk nh mp mq mr bi translated">地图</li><li id="2b6a" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk nh mp mq mr bi translated">reduceByKey</li><li id="b199" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk nh mp mq mr bi translated">GroupByKey</li><li id="7ad1" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk nh mp mq mr bi translated">JoinByKey</li><li id="eb45" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk nh mp mq mr bi translated">SparkSQL</li></ol><h2 id="907e" class="lx ku iq bd kv ly lz dn kz ma mb dp ld jy mc md lh kc me mf ll kg mg mh lp mi bi translated">4)行动</h2><p id="e926" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">动作是检索数据以回答问题的任何东西。一些例子是:数一数，各取所需。</p><p id="3b19" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">执行DAG <br/>  Spark做了一件叫做懒惰评估的事情。DAG本身是由转换构建的，但是在调用动作之前什么也不会发生。当一个动作被执行时，Spark将查看DAG，然后在它需要执行什么工作来达到它被要求做的动作步骤的上下文中优化它。当DAG最终被执行时，驱动程序向集群上的执行器发出转换命令。</p><h1 id="e7f8" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">阿帕奇水槽API</h1><p id="d0cb" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">Apache Flume的开发理念是允许开发人员使用适用于非分布式编程的相同代码创建可以在分布式系统上运行的程序。换句话说，Apache Flume允许我们编写可以在单线程和多线程机器上运行的代码，没有任何问题。Apache Flume的含义是，我们现在可以在本地机器上运行代码并进行调试，同时确保它可以在我们的Spark Hadoop集群上运行。更进一步的含义是，您可以从集群中提取数据，并在本地机器上运行它，以进行测试和开发。</p><p id="20a5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="mx">支持以下语言:</em></p><ul class=""><li id="e160" class="mj mk iq jp b jq jr ju jv jy ne kc nf kg ng kk mo mp mq mr bi translated">斯卡拉</li><li id="c2c9" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated">Java 语言(一种计算机语言，尤用于创建网站)</li><li id="f65b" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated">计算机编程语言</li><li id="14af" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated">稀有</li></ul><p id="7b8a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了演示Spark的一些内部工作方式，我将在ScalaFlume和JavaFlume中运行一个字数统计示例。</p><h2 id="2561" class="lx ku iq bd kv ly lz dn kz ma mb dp ld jy mc md lh kc me mf ll kg mg mh lp mi bi translated">在Scala中</h2><p id="7407" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">第1到2行初始化我们的Spark上下文并定义我们的源。在第3行，我们定义了初始RDD。在第4到6行中，我们定义了我们的RDD的转换，并定义了一些新的RDDS。注意第7行，没有代码被执行；只有我们的达格人建立起来了。在第7行，我们终于有了一个执行转换的动作。值得注意的是，分布在集群中的唯一工作是蓝色的，因为那些lambda表达式是由执行程序运行的转换！其他一切都在驱动程序上执行。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nj"><img src="../Images/8aa694f8f08836fc71b5765f373b51ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IIKtyB7GbAb8pV2Vgu99XA.png"/></div></div></figure><p id="3f75" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="mx"> Scala宣传侧记:</em> </strong> Scala是一种构建在JVM编译器之上的令人惊叹的语言。它为具有OOP背景的开发人员提供了一个环境，使他们能够轻松地适应函数式编程思维，这是分布式计算编程的最佳选择。Scala通过同时支持面向对象和函数式编程范例来做到这一点。你为什么要在乎？Spark是使用Scala构建的，因此Spark中的最新特性将总是首先在Scala中实现。与其他语言相比，Scala在处理大型数据集时也提供了最好的性能——举个例子:Scala大约比Python快10到225倍，这取决于用例。Scala也被数据科学和分布式计算领域的一些大公司使用，比如亚马逊和谷歌。我希望这段宣传已经说服了你，至少给Scala一个好奇的眼神。</p><h2 id="1324" class="lx ku iq bd kv ly lz dn kz ma mb dp ld jy mc md lh kc me mf ll kg mg mh lp mi bi translated">在JAVA中</h2><p id="c79d" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">蓝色突出显示的代码是转换并构建DAG。更重要的是，注意本质上每个转换都是一个对象，然后被发送到所有的分布式执行器。这也发生在Scala示例中，但是lambda表达式隐藏了这一层交互。在驱动程序执行第27行中的动作代码(用红色突出显示)之前，集群中的执行器不会执行转换对象。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nk"><img src="../Images/4e5075796dd7d338ff0fcfe64a31eda4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2xgojFiqysEhQivDUFo1YA.png"/></div></div></figure><h1 id="2a19" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">结论</h1><p id="661c" class="pw-post-body-paragraph jn jo iq jp b jq lr js jt ju ls jw jx jy lt ka kb kc lu ke kf kg lv ki kj kk ij bi translated">最后，我希望这篇文章能够帮助您理解Spark成为如此有趣和强大的数据科学和数据工程平台的基础。</p><p id="9596" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇文章的要点应该是:</p><ul class=""><li id="10bb" class="mj mk iq jp b jq jr ju jv jy ne kc nf kg ng kk mo mp mq mr bi translated">Spark Core可以与Hadoop MapReduce并行工作，或者取代它。</li><li id="e087" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated">Spark比其他计算引擎快！火花速度来自于这样一个事实，即认知的DAG，并可以优化它；它通过在整个作业中保持JVM状态，将数据保存在内存中，最终目标是最小化对磁盘的I/O。</li><li id="6d76" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated">Spark有一些很棒的数据科学和数据工程API，用于机器学习、图论、数据流和SQL。</li><li id="bdbe" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated">Spark中需要认知的主要组件是驱动程序和执行程序。这两个组件通过由Spark直接管理的DAG进行操作。有一种称为转换的东西，它构建DAG并从现有的RDD生成新的RDD。RDD是一个不可变的数据实体，它提供:借助DAG实现冗余和回滚功能。DAG仅在动作被执行后才被执行。</li><li id="5e0f" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated">Apache Flume允许您在本地机器上用少数几种成熟的编程语言编写程序，用于开发和调试目的。同样的Apache Flume代码可以部署到一个分布式系统中，不需要任何修改。Scala太棒了。</li></ul><h1 id="fa43" class="kt ku iq bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">文献学</h1><ul class=""><li id="4247" class="mj mk iq jp b jq lr ju ls jy ml kc mm kg mn kk mo mp mq mr bi translated"><a class="ae lw" href="https://www.youtube.com/watch?v=x8xXXqvhZq8&amp;t=1251s" rel="noopener ugc nofollow" target="_blank">面向Java和Scala开发人员的Apache Spark简介— Ted Malaska (Cloudera) </a></li><li id="c3c8" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated"><a class="ae lw" href="https://www.youtube.com/watch?v=SxAxAhn-BDU" rel="noopener ugc nofollow" target="_blank">什么是阿帕奇Spark？</a></li><li id="b768" class="mj mk iq jp b jq ms ju mt jy mu kc mv kg mw kk mo mp mq mr bi translated"><a class="ae lw" href="http://spark.apache.org/docs/latest/index.html" rel="noopener ugc nofollow" target="_blank">官方文件</a></li></ul></div></div>    
</body>
</html>