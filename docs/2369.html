<html>
<head>
<title>Using LSTMs to forecast time-series</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用LSTMs预测时间序列</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-lstms-to-forecast-time-series-4ab688386b1f?source=collection_archive---------1-----------------------#2018-01-17">https://towardsdatascience.com/using-lstms-to-forecast-time-series-4ab688386b1f?source=collection_archive---------1-----------------------#2018-01-17</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/73bfb7d1441949619ee3889d7d0bc18e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*BhRL4xdIz3g6n6Ul"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae kf" href="https://unsplash.com/@nick604?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Nick Chong</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="c46e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有几种时间序列预测技术，如自回归(AR)模型、移动平均(MA)模型、霍尔特-温特斯、ARIMA等。，不一而足。那么，还有什么必要用另一个像LSTM-RNN这样的模型来预测时间序列呢？这是一个非常合理的问题，以下是我能想到的理由(如果你知道更多，我很想知道，请在下面回答)—</p><ul class=""><li id="b955" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated">RNN(LSTM)非常擅长在输入特征空间中提取模式，其中输入数据跨越长序列。鉴于LSTM的门控结构具有操纵其记忆状态的能力，它们是解决这类问题的理想选择。</li><li id="dc73" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">LSTMs几乎可以无缝地模拟具有多个输入变量的问题。我们需要的只是一个3D输入向量，它需要被输入到LSTM的输入形状中。只要我们找到一种方法，将所有的输入变量转换成三维矢量形式，我们就可以很好地使用LSTM。这在时间序列预测中增加了很大的好处，在这种情况下，经典的线性方法可能很难适应多变量或多输入预测问题(此处对多变量预测的补充说明—请记住，当我们使用多变量数据进行预测时，我们还需要“未来多变量”数据来预测未来的结果！)</li><li id="5ff5" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">总的来说，在使用LSTM的方法时，我发现它们在建模问题时提供了很大的灵活性——这意味着我们可以很好地控制时间序列的几个参数。特别是我们可以—</li><li id="5c3e" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">灵活使用seq2seq LSTM模型的多种组合来预测时间序列——多对一模型(当我们希望在给定所有先前输入的情况下预测当前时间步长时有用),多对多模型(当我们希望在给定所有先前输入的情况下一次预测多个未来时间步长时有用)以及这些模型的其他几种变体。我们可以定制一些东西，例如，在当前步骤进行预测的回顾窗口的大小，我们希望预测未来的时间步骤的数量，将当前预测反馈到窗口中以在下一个时间步骤进行预测(这种技术也称为向前移动窗口)等等。</li></ul><p id="90b7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一方面，在使用LSTM(或任何DNN架构)时，有一些常见的缺点需要小心——需要大量数据，需要调整多个超参数等。，我也看到一些文章提到LSTM并不擅长自回归类型的序列。所以不要全信这个。</p><p id="dbcc" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用一个简单的正弦波作为模型数据集来模拟时间序列预测。你可以在我的github简介中找到我自己对这个例子<a class="ae kf" href="https://goo.gl/wC9ZaG" rel="noopener ugc nofollow" target="_blank">的实现。这个例子的核心思想和数据取自</a><a class="ae kf" href="http://www.jakob-aungiers.com/articles/a/LSTM-Neural-Network-for-Time-Series-Prediction" rel="noopener ugc nofollow" target="_blank">的博客</a>，但为了便于理解，我做了自己的修改。</p><p id="b3b6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">那么我们给定的数据是什么样的呢？下面是整个正弦波数据集的曲线图。</p><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ls"><img src="../Images/0727d8e2fbc3605f13f833257b8e1b59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xeOsFYvMxSr4q6xpkPzP0w.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">fig 1: Plot of entire sine wave data</figcaption></figure><p id="ad05" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> <em class="lx">在我们深入研究细节之前，先简要介绍一下整体方法— </em> </strong></p><ol class=""><li id="2efa" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld ly lk ll lm bi translated">使用大小为50的向前移动窗口，这意味着我们将使用前50个数据点作为输出输入X来预测y1-第51个数据点。接下来，我们将使用1到51个数据点之间的窗口作为输入X来预测y2，即第52个数据点，依此类推…这是前50个数据点的图—</li></ol><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi lz"><img src="../Images/b0d76b07390a4ec4f327e2e167c833a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XnPyiRLMVv8aXnTpssqY7A.png"/></div></div></figure><p id="b5d3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.使用两层LSTM架构和密集输出层进行预测。</p><p id="babb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3.我们将查看预测输出的几种方法，a .)<strong class="ki iu"><em class="lx"/></strong>逐步预测测试数据集，<strong class="ki iu"> <em class="lx"> b.) </em> </strong>通过向前移动一步，将先前的预测反馈到输入窗口，然后在当前时间步进行预测。</p><p id="ff35" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> <em class="lx">现在让我们深入细节— </em> </strong></p><p id="ee61" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">数据准备— </strong></p><ol class=""><li id="7e93" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld ly lk ll lm bi translated">使用minmax scaler标准化数据(参见下面的代码片段)</li></ol><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/85966f9bb81a8470a495102c32609c5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*Zm94y7ANHM3fZO52O55KZw.png"/></div></figure><p id="a5be" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.将移动窗口大小固定为50。为此，我们使用pandas shift函数，按照我们指定的数字移动整个列。在下面的代码片段中，我们将列<strong class="ki iu"> <em class="lx">向上</em> </strong>移动了1(因此使用了-1。如果我们想将<strong class="ki iu"> <em class="lx">向下</em> </strong>移动1，我们必须使用+1)，然后将其连接到原始数据。</p><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/73c108f1962342904c6863003ec4dd52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*lf94HRX6bJ_EbFJ6j1xPVA.png"/></div></figure><p id="16bf" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我试图在下面的一个玩具数据集上说明这一点，上面的循环 的<strong class="ki iu"> <em class="lx">是如何为3的<em class="lx">窗口大小</em>工作的。</em></strong></p><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/c48d5ce235bc2fdad7697aacb73b669a.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*gTMvMRL-H4HEtkTXjKYomg.png"/></div></figure><p id="77e0" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lx">注意——在上面的代码片段中，我们删除了所有包含Nan值的行。</em></p><p id="08db" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果仔细观察玩具数据集，您会发现它以我们希望输入到LSTM中的方式模拟了输入数据。上表中的最后一列成为目标<em class="lx"> y </em>，前三列成为我们的输入<em class="lx"> x1、x2 </em>和<em class="lx"> x3 </em>特征。如果你熟悉在自然语言处理中使用LSTM，那么你可以把它看作是一个长度为3的句子的固定序列，每个序列包含3个单词，我们的任务是预测第4个单词。</p><p id="e380" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">3.为LSTM准备3D输入矢量。记住，LSTM的输入向量是3D数组:(样本数，时间步数，特征数)。在这种情况下，我们有<em class="lx">时间步数= 50 </em>和<em class="lx">数量_特征= 1 </em>(扩展我们在上一点中看到的相同类比，我发现这在理解为什么输入形状必须是这样非常有用——比方说，我们在一个句子中有50个单词，每个单词由一个单词向量表示。因此，我们需要50个时间步长来遍历句子中的每个单词向量，作为每个时间步长的LSTM的输入。每个观察有一个句子，因此<em class="lx"> num_features = 1 </em>。像这样，我们需要迭代训练数据中的所有句子，以提取所有句子中单词之间的模式。这也正是我们在时间序列预测中想要的—我们想要识别窗口中每个先前值之间存在的所有模式，以预测当前时间步长！)</p><p id="15a6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">模型架构— </strong></p><p id="d6f4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是所使用的模型架构，这一点不言而喻—(它是一个双层堆叠的LSTM层，第一个LSTM在每个时间步的输出被馈送到第二个LSTM)</p><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div class="gh gi md"><img src="../Images/b8ef1b1b2c58e3e780f8942735b30513.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*nCzsQLPkX8zEIZycJs-3kQ.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Model architecture</figcaption></figure><p id="6979" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu">做预测— </strong></p><ol class=""><li id="10d1" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld ly lk ll lm bi translated">逐步预测测试数据(参考下面的代码片段)。这很简单。给定从训练数据中学习到的所有参数，我们使用它们来一次一个地预测所有的测试序列。</li></ol><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div class="gh gi me"><img src="../Images/89ebc85f5319828dfca9500a9d4d80a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*-h736oQFTVeuZgOsJ8otXA.png"/></div></figure><p id="95c8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="lx">预测值与实际值</em>的曲线几乎相互重叠，以至于我们无法区分下图中的蓝色曲线和红色曲线。</p><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/e3de1e588869181a2b5c537c7a6f9596.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*KY_9XidLPRfyIy18mtj6aw.png"/></div></figure><p id="c375" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">然而，以上通常不是进行预测的现实方式，因为我们不会有所有可用的未来窗口序列。</p><p id="83e2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.因此，如果我们想要预测未来的多个时间步长，那么更现实的方法是一次预测未来的一个时间步长，并将该预测反馈到后面的输入窗口，同时在窗口开始时弹出第一个观察值(以便窗口大小保持不变)。参考下面做这部分的代码片段—(如果你浏览我上面提到的github链接中的代码，代码中的注释是不言自明的)—</p><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/185f3a1c71d8c19c4be7c933988d2482.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*6O2NdVjTAJRUgo5_wLkxzg.png"/></div></figure><p id="989f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用这个预测模型，结果绘制如下—</p><figure class="lt lu lv lw gt ju gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/4247076e11617fb6025ea97b80ad2d6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*ZI1_G2b76qwaXZ1pu3PD6g.png"/></div></figure><p id="a533" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">可以看出，可以理解的是，我们试图预测的时间越远，在每个时间步上建立在先前预测误差上的误差就越大。然而，该函数的行为仍然像一个阻尼正弦波！正如我前面说过的，这是任何时间序列问题的更现实的模型，因为我们没有所有的未来序列。</p><p id="aba7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个代码可以很好地扩展到预测任何时间序列。请注意，您可能需要注意数据准备的其他方面，如在将数据提供给LSTM进行预测之前，对序列进行去趋势化、差分以使数据稳定等。</p><p id="17ea" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">就是这样！希望这篇文章对使用LSTM预测时间序列有一个很好的理解。如果这篇文章中有一些摘录，请鼓掌表示感谢:)</p></div></div>    
</body>
</html>