<html>
<head>
<title>Random Forest Learning-Essential Understanding</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">随机森林学习-基本理解</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/random-forest-learning-essential-understanding-1ca856a963cb?source=collection_archive---------2-----------------------#2017-08-15">https://towardsdatascience.com/random-forest-learning-essential-understanding-1ca856a963cb?source=collection_archive---------2-----------------------#2017-08-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/9870519d497a6bf18bcd86fbf23ca311.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RZ1RKBwhLxZM6SRX5Nc4Rw.png"/></div></div></figure><p id="07d1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> &gt; &gt;使用&gt; &gt; </strong>决策树模型进行参数化</p><p id="2b20" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> &gt; &gt;集成了&gt; &gt; </strong>三种技法，</p><blockquote class="kw kx ky"><p id="2b51" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir"> 1。</strong>一种采样技术</p><p id="740b" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir"> 2。子空间法，和</strong></p><p id="60be" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir"> 3。集合方法</strong></p><p id="a347" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir">优化</strong>模型构建</p></blockquote><p id="248a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> **抽样方法** := </strong> <strong class="ka ir">自举</strong>；采用<strong class="ka ir">随机</strong>抽样方法，用<strong class="ka ir">替换</strong>。</p><p id="b856" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> **子空间法** := </strong>也采用了<strong class="ka ir">随机</strong>的采样方式，</p><p id="1e52" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但是有助于提取更小的特征子集(子空间)。</p><p id="7f5d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有助于基于它们构建决策树。</p><p id="9517" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为随机森林构造选择决策树。</p><p id="84c0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> **集合方法**:= </strong>基于<strong class="ka ir">打包</strong>方法；帮助构建<strong class="ka ir">分类器</strong>。</p><h1 id="fb05" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">1.1随机森林(RF)</h1><p id="fcc3" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">树木可以是</p><blockquote class="kw kx ky"><p id="84c4" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir"> 1。分类树</strong></p><p id="049c" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir"> 2。回归树</strong></p></blockquote><p id="0746" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此RF可以应用于两者。</p><ul class=""><li id="352f" class="mg mh iq ka b kb kc kf kg kj mi kn mj kr mk kv ml mm mn mo bi translated"><strong class="ka ir">决策树</strong>为<strong class="ka ir">测试</strong>阶段提供<strong class="ka ir">单个</strong>训练好的决策树分类器。</li><li id="ebe1" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">但是<strong class="ka ir"> RF </strong>为<strong class="ka ir">测试</strong>阶段提供<strong class="ka ir">多个</strong>训练好的DT分类器。</li><li id="33ab" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">这一特性使得RF比常规DT学习更受青睐。</li></ul><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mu"><img src="../Images/38bfb206cb616cee3c1692d48fe2bb28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1afuFrLP1talkzXk5425bA.png"/></div></div><figcaption class="mz na gj gh gi nb nc bd b be z dk">The construction of a Decision Tree using 1-D data domain &amp; bootstrap sampling.</figcaption></figure><h1 id="aacd" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">平行结构</h1><ul class=""><li id="14fb" class="mg mh iq ka b kb mb kf mc kj nd kn ne kr nf kv ml mm mn mo bi translated"><strong class="ka ir">并行化</strong>是RF对<strong class="ka ir"> <em class="kz">增强分类性能</em> </strong>的贡献属性之一。</li><li id="4028" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">DT可以在<strong class="ka ir">的同时</strong>建立，用于RF建模的分类。</li><li id="9c38" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">这种射频并行结构有助于<strong class="ka ir">大数据分类。</strong></li></ul><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ng"><img src="../Images/1df033f541165233478dfbb09f0bbcfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wirwWILVOTxVWkuf-MaBMw.png"/></div></div><figcaption class="mz na gj gh gi nb nc bd b be z dk">The parallelization feature of the random forest technique</figcaption></figure><h1 id="0156" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">模型参数</h1><ul class=""><li id="d975" class="mg mh iq ka b kb mb kf mc kj nd kn ne kr nf kv ml mm mn mo bi translated">RF的参数化包括<strong class="ka ir"> DT型号</strong>的<strong class="ka ir">参数化</strong>，因为它内部采用了另一个。</li><li id="2240" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">因此，RF模型由DT的参数组成，但也有更多的<strong class="ka ir">新</strong>参数。</li></ul><p id="3e5b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">例如，<strong class="ka ir">特征子集</strong>中的#个，选择用于构建RF的#个DTs</p><h1 id="03c6" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">增益/损失函数</h1><ul class=""><li id="46db" class="mg mh iq ka b kb mb kf mc kj nd kn ne kr nf kv ml mm mn mo bi translated">参数的优化基于</li></ul><blockquote class="kw kx ky"><p id="3693" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir"> 1。自举采样</strong></p><p id="8461" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir"> 2。子空间整合</strong></p></blockquote><p id="de1f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在模型建筑中</p><ul class=""><li id="ea87" class="mg mh iq ka b kb kc kf kg kj mi kn mj kr mk kv ml mm mn mo bi translated">树构建使用与DTs中使用的<strong class="ka ir">相同的量化度量</strong>来选择最佳特征，例如。</li></ul><blockquote class="kw kx ky"><p id="4af7" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir"> 1。熵</strong></p><p id="5ca0" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir"> 2。基尼杂质</strong></p><p id="2ba5" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir"> 3。信息增益</strong></p></blockquote><h1 id="0724" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">自举和装袋</h1><ul class=""><li id="87d8" class="mg mh iq ka b kb mb kf mc kj nd kn ne kr nf kv ml mm mn mo bi translated">为了优化分类目标，</li></ul><blockquote class="kw kx ky"><p id="ec24" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir"> 1。统计措施，</strong></p><p id="8da3" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir"> 2。自举，</strong></p><p id="bb58" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir"> 3。装袋</strong></p></blockquote><p id="f8fb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在射频学习中起着重要的作用。</p><h1 id="9bb9" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">1.1.4.1自举</h1><ul class=""><li id="98cd" class="mg mh iq ka b kb mb kf mc kj nd kn ne kr nf kv ml mm mn mo bi translated">BS是一种简单的随机化技术。</li><li id="7785" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">它在射频方面的效果<strong class="ka ir">非常出色。</strong></li><li id="ccbb" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">它通过随机选择从一组数据中选择<strong class="ka ir">几个</strong> <strong class="ka ir">子集</strong>，但与原始数据集中的观测值完全相同，只是用 <strong class="ka ir">替换</strong><strong class="ka ir">。</strong></li><li id="6f7c" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">所以有些观察值可以在数据集的一个子集里多次出现<strong class="ka ir"/>。</li><li id="7598" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">概念:-</li></ul><blockquote class="nh"><p id="f6cb" class="ni nj iq bd nk nl nm nn no np nq kv dk translated">在每个中间节点&amp; DT的叶子上最大化“类距离”。</p></blockquote><ul class=""><li id="0150" class="mg mh iq ka b kb nr kf ns kj nt kn nu kr nv kv ml mm mn mo bi translated"><strong class="ka ir"> BS </strong>应用于射频算法的<strong class="ka ir">训练阶段</strong>。</li></ul><h1 id="03fa" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">1.1.4.2重叠细化</h1><ul class=""><li id="d452" class="mg mh iq ka b kb mb kf mc kj nd kn ne kr nf kv ml mm mn mo bi translated">BS给数据域带来了一些影响。</li><li id="dacb" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">BS生成<strong class="ka ir">多个域</strong>，其中<strong class="ka ir">类</strong>可能比原始数据域更加<strong class="ka ir">孤立</strong>。</li><li id="efe4" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">这些<strong class="ka ir">隔离数据域</strong>中的类可以通过<strong class="ka ir">单个拆分<strong class="ka ir">轻松分离</strong>。</strong></li><li id="82a7" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">有时候我们可能不需要分裂。</li></ul><h1 id="23df" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">1.1.4.3装袋</h1><ul class=""><li id="112d" class="mg mh iq ka b kb mb kf mc kj nd kn ne kr nf kv ml mm mn mo bi translated">指BS样本给出的<strong class="ka ir">预测</strong>(分类)<strong class="ka ir">响应</strong>的<strong class="ka ir">平均</strong>，得到<strong class="ka ir">最终</strong>预测结果。</li><li id="dfc3" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">套袋来自<strong class="ka ir"> <em class="kz">自举聚集。</em>T51】</strong></li><li id="8342" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">BS用“<strong class="ka ir"> <em class="kz">简单类重叠细化</em> </strong>”创建<strong class="ka ir">多个</strong>域，这些域帮助创建<strong class="ka ir">多个分类模型</strong>，多个分类模型允许<strong class="ka ir">测试算法</strong>高效地评估分类器的<strong class="ka ir">性能。</strong></li><li id="92b9" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">在RF算法的<strong class="ka ir">测试阶段</strong>应用Bagging。</li></ul><h1 id="c084" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">1.2随机森林学习模型</h1><ul class=""><li id="331e" class="mg mh iq ka b kb mb kf mc kj nd kn ne kr nf kv ml mm mn mo bi translated">实现<strong class="ka ir">参数化</strong>目标&amp;优化<strong class="ka ir">目标。</strong></li></ul><h1 id="6ca1" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">1.2.1参数化</h1><ul class=""><li id="058a" class="mg mh iq ka b kb mb kf mc kj nd kn ne kr nf kv ml mm mn mo bi translated">参数，</li></ul><blockquote class="kw kx ky"><p id="a97f" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir"> 1。使用自举生成的域数量— A. </strong></p><p id="d600" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir"> 2。每个节点(域)的子空间大小— B. </strong></p><p id="4431" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><strong class="ka ir"> 3。域分割的阈值— C. </strong></p></blockquote><ul class=""><li id="72df" class="mg mh iq ka b kb kc kf kg kj mi kn mj kr mk kv ml mm mn mo bi translated"><strong class="ka ir">参数化的目标</strong>:-</li></ul><blockquote class="nh"><p id="05cc" class="ni nj iq bd nk nl nm nn no np nq kv dk translated">我们需要找到或建议参数的可能值。</p></blockquote><ul class=""><li id="921c" class="mg mh iq ka b kb nr kf ns kj nt kn nu kr nv kv ml mm mn mo bi translated"><strong class="ka ir"> A </strong>的通常值是<strong class="ka ir"> 10 </strong>。</li></ul><p id="7887" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但是进行“<strong class="ka ir">交叉验证</strong>并确定一个合适的<strong class="ka ir">取值范围是合适的。</strong></p><ul class=""><li id="54f0" class="mg mh iq ka b kb kc kf kg kj mi kn mj kr mk kv ml mm mn mo bi translated">对于B选择，有<strong class="ka ir"> 2个约束。</strong></li><li id="4765" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">第一个建议是<strong class="ka ir"> n &lt; &lt; p </strong> &amp;它必须在DT的整个构建过程中保持不变。</li><li id="27bb" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">第二constriant，<strong class="ka ir">n&lt;= sqrt(p)；</strong>我们在原始数据域中有<strong class="ka ir"> p个特性</strong>。其中有n个是好的。良率在<strong class="ka ir"> n/p. </strong>其中<strong class="ka ir">特征之一</strong>为<strong class="ka ir">最佳</strong>之一，其良率为<strong class="ka ir"> 1/n. </strong></li></ul><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/7a5ee0fa738567d1e5d854922231cd32.png" data-original-src="https://miro.medium.com/v2/resize:fit:388/format:webp/1*epbwvcen8XedKb3QXEkQaA.png"/></div></figure><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nx"><img src="../Images/b28851ca7292f9525ee94ec8268d59f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cbrCdWE8dAFqz4RprsTXTA.png"/></div></div></figure><ul class=""><li id="6b27" class="mg mh iq ka b kb kc kf kg kj mi kn mj kr mk kv ml mm mn mo bi translated">人们使用<strong class="ka ir"> sqrt(p) </strong>作为特征的<strong class="ka ir"> #进行随机选择。</strong></li></ul><h1 id="729e" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">优化</h1><blockquote class="nh"><p id="e550" class="ni nj iq bd nk nl ny nz oa ob oc kv dk translated">一旦选择了参数，模型就被参数化了。那么必须优化参数。</p></blockquote><ul class=""><li id="b086" class="mg mh iq ka b kb nr kf ns kj nt kn nu kr nv kv ml mm mn mo bi translated">但是在RF参数化&amp;优化中<strong class="ka ir">嵌套</strong>，&amp;它们是同时<strong class="ka ir">执行的。</strong></li><li id="e360" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">已经在树的每个节点进行了优化<strong class="ka ir">。</strong></li><li id="f1db" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">RF优化的主要参与者是<strong class="ka ir">基尼指数(熵)</strong>&amp;<strong class="ka ir">信息增益</strong>。</li></ul><h1 id="220d" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">1.3随机森林学习算法</h1><ul class=""><li id="39a9" class="mg mh iq ka b kb mb kf mc kj nd kn ne kr nf kv ml mm mn mo bi translated">像其他机器学习算法一样，由3部分组成；<strong class="ka ir"> <em class="kz">培训、验证和测试。</em>T45】</strong></li><li id="2f0d" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated"><strong class="ka ir">交叉验证</strong>已经<strong class="ka ir">包含在<strong class="ka ir">培训协议</strong>中。</strong></li><li id="3ff3" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated">所以射频技术不需要<strong class="ka ir">不需要</strong>T54】单独的T56】验证算法。</li></ul><h2 id="9493" class="od le iq bd lf oe of dn lj og oh dp ln kj oi oj lr kn ok ol lv kr om on lz oo bi translated">简单地说:-</h2><blockquote class="nh"><p id="72ab" class="ni nj iq bd nk nl ny nz oa ob oc kv dk translated">RF学习为我们提供了几个空间(最佳特征组合)，在这些空间中可以执行最佳的领域划分&amp;可以获得高的分类精度。</p></blockquote><ul class=""><li id="2bb2" class="mg mh iq ka b kb nr kf ns kj nt kn nu kr nv kv ml mm mn mo bi translated">因此，射频分类目标只分为<strong class="ka ir"/><strong class="ka ir">训练&amp;测试</strong>算法。</li></ul><h1 id="4e33" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">1.3.1训练算法</h1><ul class=""><li id="c727" class="mg mh iq ka b kb mb kf mc kj nd kn ne kr nf kv ml mm mn mo bi translated">这提供了一种<strong class="ka ir">系统化的</strong>方法来开发<strong class="ka ir">多分类器</strong> (DTs)，以便测试算法使用多分类器来选择<strong class="ka ir">对新数据进行分类的最佳方式。</strong></li></ul><h2 id="77f1" class="od le iq bd lf oe of dn lj og oh dp ln kj oi oj lr kn ok ol lv kr om on lz oo bi translated">第一步::—</h2><p id="f2f9" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">— <strong class="ka ir">为给定数据创建多个</strong>子空间。</p><p id="7aef" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> r &lt; = sqrt(p) </strong></p><blockquote class="kw kx ky"><p id="2d9c" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><em class="iq"> p = #特性；</em></p><p id="f27f" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated"><em class="iq"> r =子空间尺寸</em></p></blockquote><h2 id="341b" class="od le iq bd lf oe of dn lj og oh dp ln kj oi oj lr kn ok ol lv kr om on lz oo bi translated">第二步::—</h2><p id="118a" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">—我们有<strong class="ka ir">明显更小的r </strong> ( <strong class="ka ir"> <em class="kz">维度子空间</em> </strong>)，因此我们可以使用DT构建过程为<strong class="ka ir">根节点</strong>找到<strong class="ka ir">最佳特征</strong> &amp; <strong class="ka ir">最佳分裂位置(</strong>域划分)。</p><blockquote class="nh"><p id="f0e9" class="ni nj iq bd nk nl ny nz oa ob oc kv dk translated">[但是我们不对这个子空间执行这个过程，所以跳到下一步]</p></blockquote><h2 id="9ad0" class="od le iq bd lf oe op dn lj og oq dp ln kj or oj lr kn os ol lv kr ot on lz oo bi translated">第三步::—</h2><p id="d5e3" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">— <strong class="ka ir">随机改变</strong>子空间<strong class="ka ir"/>使用引导样本&amp;创建多个<strong class="ka ir">引导子空间</strong>，其中<strong class="ka ir">重叠细化</strong>发生在数据域中。</p><h2 id="654e" class="od le iq bd lf oe of dn lj og oh dp ln kj oi oj lr kn ok ol lv kr om on lz oo bi translated">第四步::——</h2><p id="4441" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">—通过应用DT算法为每个引导子空间寻找最佳特征和最佳分裂位置来为DTs构建节点。</p><h2 id="5503" class="od le iq bd lf oe of dn lj og oh dp ln kj oi oj lr kn ok ol lv kr om on lz oo bi translated">第五步::—</h2><p id="25e2" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">—现在，每个引导样本都有一个DT(分类器)。</p><p id="809c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">——这些树可以被<strong class="ka ir">测试</strong>算法用来<strong class="ka ir">分类</strong>新的数据。</p><p id="f63c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">射频相对于DT的优势，</strong></p><blockquote class="kw kx ky"><p id="67b4" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated">1.在测试空间<strong class="ka ir">=&gt;</strong><strong class="ka ir">将增加</strong>和<strong class="ka ir">的分类精度。</strong></p><p id="2137" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated">2.bootstrap样本用于多个DTs，这将有助于通过<strong class="ka ir">重叠细化增加<strong class="ka ir">分类边界</strong>的<strong class="ka ir">锐化</strong>。</strong></p><p id="407f" class="jy jz kz ka b kb kc kd ke kf kg kh ki la kk kl km lb ko kp kq lc ks kt ku kv ij bi translated">3.为了在整个空间中找到最佳特征&amp;最佳分割位置而进行的<strong class="ka ir">穷举搜索</strong>被<strong class="ka ir">通过子空间搜索<strong class="ka ir"> = &gt; </strong> <strong class="ka ir">消除</strong>在<strong class="ka ir"> bootstrap采样中很小的附加计算成本</strong>。</strong> ( <em class="iq">计算优势</em>)</p></blockquote><h1 id="390d" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">测试算法</h1><ul class=""><li id="f5c7" class="mg mh iq ka b kb mb kf mc kj nd kn ne kr nf kv ml mm mn mo bi translated">测试要求<strong class="ka ir">整个</strong>射频可以<strong class="ka ir">在早期使用几个自举样本(10) </strong>构建。然后<strong class="ka ir">贴标过程</strong>就可以开始了。</li><li id="6baa" class="mg mh iq ka b kb mp kf mq kj mr kn ms kr mt kv ml mm mn mo bi translated"><strong class="ka ir">步骤</strong>，</li></ul><h2 id="cddb" class="od le iq bd lf oe of dn lj og oh dp ln kj oi oj lr kn ok ol lv kr om on lz oo bi translated">1.功能选择:</h2><p id="4a47" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">来自<strong class="ka ir">输入数据</strong>的<strong class="ka ir">正确的特征序列</strong>必须是“<strong class="ka ir">观察到的</strong>”。</p><h2 id="b210" class="od le iq bd lf oe of dn lj og oh dp ln kj oi oj lr kn ok ol lv kr om on lz oo bi translated">2.树选择:</h2><p id="4735" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">我们有N个射频分类器。所以我们<strong class="ka ir">推送</strong>新的数据<strong class="ka ir">根据</strong>的特性通过所有的&amp;DTs获取其类标签。</p><h2 id="17d0" class="od le iq bd lf oe of dn lj og oh dp ln kj oi oj lr kn ok ol lv kr om on lz oo bi translated">3.装袋:</h2><p id="42bb" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated">上一步选择的树用于寻找获得的结果的<strong class="ka ir">集合(<strong class="ka ir">套袋技术</strong></strong></p><p id="f1f0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi ou translated"><span class="l ov ow ox bm oy oz pa pb pc di"> F </span>最后，我们可以通过<strong class="ka ir"> <em class="kz">表决机制</em> </strong>得出新的观察属于一个特定的标签。</p><figure class="mv mw mx my gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pd"><img src="../Images/88f30a26ded30af7abc561e5428cde44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W70TAcPDXVexTL6JNED6OA.png"/></div></div></figure><figure class="mv mw mx my gt jr gh gi paragraph-image"><div class="gh gi pe"><img src="../Images/a59e57cea7df8cf45e108171990df735.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*V1gaYbSzecaGE7s6WVIcsQ.png"/></div></figure><h1 id="4158" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">随机森林可扩展性</h1><ul class=""><li id="0f77" class="mg mh iq ka b kb mb kf mc kj nd kn ne kr nf kv ml mm mn mo bi translated">在典型的<strong class="ka ir">数据科学应用中，</strong></li></ul><p id="cd3c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> #的特性是固定的。</strong></p><p id="080b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">RF技术从中选择一个子空间，并基于bootstrapping构建“<strong class="ka ir">深度优先决策树</strong>”来构造RF。</p><ul class=""><li id="b4ba" class="mg mh iq ka b kb kc kf kg kj mi kn mj kr mk kv ml mm mn mo bi translated">但是在<strong class="ka ir">大数据中，</strong></li></ul><p id="5953" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">功能集可以动态“增长”。</strong></p><ul class=""><li id="d35b" class="mg mh iq ka b kb kc kf kg kj mi kn mj kr mk kv ml mm mn mo bi translated">这个问题可以通过构建“宽度优先决策树”来解决。这里的DTs是在<strong class="ka ir">并行</strong>中构建的。</li></ul><p id="3ea0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然而，在<strong class="ka ir">深度优先</strong> &amp; <strong class="ka ir">传统RF </strong>中，DT是在一个DT被完全构建之后构建的。</p><h1 id="e611" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated"><strong class="ak">参考:- </strong></h1><p id="8280" class="pw-post-body-paragraph jy jz iq ka b kb mb kd ke kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv ij bi translated"><strong class="ka ir"> <em class="kz">大数据分类的机器学习模型与算法，Shan Suthaharan第十一章——随机森林学习</em> </strong></p></div></div>    
</body>
</html>