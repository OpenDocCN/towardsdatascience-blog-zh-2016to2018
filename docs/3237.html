<html>
<head>
<title>ConvNets Series. Actual Project Prototyping with Mask R-CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ConvNets 系列。使用 Mask R-CNN 的实际项目原型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convnets-series-actual-project-prototyping-with-mask-r-cnn-dbcd0b4ab519?source=collection_archive---------5-----------------------#2018-04-23">https://towardsdatascience.com/convnets-series-actual-project-prototyping-with-mask-r-cnn-dbcd0b4ab519?source=collection_archive---------5-----------------------#2018-04-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="fe07" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</h1><p id="ef3e" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">这个 ConvNets 系列从德国交通标志的玩具数据集进展到我被要求解决的一个更实际的现实生活问题:<strong class="kn ir">“有没有可能实现一种深度学习魔法，仅使用照片作为单一输入，来区分<em class="lj">好的</em>质量的菜肴和<em class="lj">差的</em>质量的菜肴？”</strong>。简而言之，企业希望这样:</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/b7e784325d2eb8836cf29aed961e5907.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*U1DYB3vbT3MMfIMa0l11vQ.png"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">When a business looks at ML through pink glasses, they imagine this</figcaption></figure><p id="8b72" class="pw-post-body-paragraph kl km iq kn b ko lw kq kr ks lx ku kv kw ly ky kz la lz lc ld le ma lg lh li ij bi translated">这是一个不适定问题的例子:由于 done 的定义非常模糊(更不用说实现了)，所以无法确定解决方案是否存在，以及该解决方案是否唯一且稳定。虽然这篇文章不是关于有效的沟通或项目管理，但有一点是必要的:<strong class="kn ir">你永远不应该参与范围很小的项目。处理这种不确定性的一个行之有效的方法是首先建立一个定义良好的原型，然后再构建剩下的任务。这就是我们采取的策略。</strong></p><h1 id="7827" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">问题定义</h1><p id="9edc" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在我的原型中，我专注于菜单中的单个项目——煎蛋卷——并构建了一个可扩展的数据管道，输出煎蛋卷的感知“质量”。可以概括为这样:</p><ul class=""><li id="9644" class="mb mc iq kn b ko lw ks lx kw md la me le mf li mg mh mi mj bi translated"><strong class="kn ir">问题类型:</strong>多类分类，质量的 6 个离散类:<code class="fe mk ml mm mn b">[good, broken_yolk, overroasted, two_eggs, four_eggs, misplaced_pieces]</code>。</li><li id="c023" class="mb mc iq kn b ko mo ks mp kw mq la mr le ms li mg mh mi mj bi translated"><strong class="kn ir">数据集:</strong> 351 张手动采集的各种煎蛋的 DSLR 相机照片。Train/val/test: 139/32/180 洗牌照片。</li><li id="7684" class="mb mc iq kn b ko mo ks mp kw mq la mr le ms li mg mh mi mj bi translated"><strong class="kn ir">标签:</strong>给每张照片分配一个主观质量等级。</li><li id="eb08" class="mb mc iq kn b ko mo ks mp kw mq la mr le ms li mg mh mi mj bi translated"><strong class="kn ir">度量:</strong>分类交叉熵。</li><li id="377e" class="mb mc iq kn b ko mo ks mp kw mq la mr le ms li mg mh mi mj bi translated"><strong class="kn ir">必要的领域知识:</strong>一个“好”的煎蛋的定义是三个鸡蛋，蛋黄未破裂，一些培根，没有烧焦的碎片，中间有一片欧芹。此外，它的组成应该是视觉上正确的，例如，不应该有分散的碎片。</li><li id="56fc" class="mb mc iq kn b ko mo ks mp kw mq la mr le ms li mg mh mi mj bi translated"><strong class="kn ir">done 的定义:</strong>原型开发两周之后测试集上的最佳可能交叉熵。</li><li id="2803" class="mb mc iq kn b ko mo ks mp kw mq la mr le ms li mg mh mi mj bi translated"><strong class="kn ir">结果可视化:</strong>测试集低维数据表示的 t-SNE。</li></ul><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi mt"><img src="../Images/959c1be9b642400a74bae9f9dc4bb25f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Lu59Q4iGBT7qg4u-hKt5Uw.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Input images as they are captured with camera</figcaption></figure><p id="4796" class="pw-post-body-paragraph kl km iq kn b ko lw kq kr ks lx ku kv kw ly ky kz la lz lc ld le ma lg lh li ij bi translated">主要目标是<em class="lj">使用神经网络分类器获得并组合提取的信号</em>，并让分类器做出关于测试集中项目的类别概率的 softmax 预测。这样的目标将使这个原型可行，并可用于以后的使用。以下是我们提取并发现有用的信号:</p><ul class=""><li id="5db5" class="mb mc iq kn b ko lw ks lx kw md la me le mf li mg mh mi mj bi translated">关键成分面膜(Mask R-CNN): <em class="lj">信号#1。</em></li><li id="48fa" class="mb mc iq kn b ko mo ks mp kw mq la mr le ms li mg mh mi mj bi translated">按每种成分分组的关键成分计数(基本上是不同成分计数的矩阵):<em class="lj">信号#2。</em></li><li id="1db8" class="mb mc iq kn b ko mo ks mp kw mq la mr le ms li mg mh mi mj bi translated">背景被删除的煎蛋卷板的 RGB 作物。为了简单起见，我决定暂时不将它们添加到模型中。这可能是最明显的信号:只需使用一些奇特的损失函数在这些图像上训练一个 ConvNet 分类器，并在低维嵌入中采用从选定的典范图像到当前图像的 L2 距离。不幸的是，我没有机会测试这个假设，因为我只限于训练集中的 139 个样本。</li></ul><h1 id="df20" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">50K 管道概述</h1><p id="5992" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我省略了几个重要的阶段，如数据发现和探索性分析、基线解决方案和主动标记(这是我自己对受<a class="ae my" href="https://www.youtube.com/watch?v=S1UUR4FlJ84" rel="noopener ugc nofollow" target="_blank">多边形-RNN 演示视频</a>启发的半监督实例注释的花哨名称)以及 Mask R-CNN 的管道(在后面的帖子中会有更多相关内容)。为了拥抱整个管道，这里是它的 50K 英尺视图:</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi mz"><img src="../Images/085e8262433b634e29aea010c3e09d6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b9vQhMcGUA5hq_SwYzAKUQ.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">We are mostly interested in the Mask R-CNN and classification stages of the pipeline</figcaption></figure><p id="22c5" class="pw-post-body-paragraph kl km iq kn b ko lw kq kr ks lx ku kv kw ly ky kz la lz lc ld le ma lg lh li ij bi translated">对于这篇文章的其余部分，我将重点关注三个阶段:[1]屏蔽 R-CNN 的成分屏蔽推理，[2]基于 Keras 的 ConvNet 分类器，[3]t-SNE 的结果可视化。</p><h1 id="e2e2" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">阶段 1:屏蔽 R-CNN 和屏蔽推理</h1><p id="9bee" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">口罩 R-CNN (MRCNN)最近得到了大量的报道和炒作。从最初的<a class="ae my" href="https://arxiv.org/abs/1703.06870" rel="noopener ugc nofollow" target="_blank">脸书的论文</a>开始，到 Kaggle 上的<a class="ae my" href="https://www.kaggle.com/c/data-science-bowl-2018" rel="noopener ugc nofollow" target="_blank">数据科学碗 2018 </a>，Mask R-CNN 证明了自己是实例分割(对象感知分割)的强大架构。我使用的基于 Keras 的<a class="ae my" href="https://github.com/matterport/Mask_RCNN" rel="noopener ugc nofollow" target="_blank"> Matterport 的 MRCNN 的实现</a>绝对是一种享受。代码结构良好，文档清晰，开箱即用，尽管比我预期的要慢。</p><p id="d03a" class="pw-post-body-paragraph kl km iq kn b ko lw kq kr ks lx ku kv kw ly ky kz la lz lc ld le ma lg lh li ij bi translated">MRCNN 中的一段话:</p><blockquote class="na nb nc"><p id="b2a0" class="kl km lj kn b ko lw kq kr ks lx ku kv nd ly ky kz ne lz lc ld nf ma lg lh li ij bi translated">MRCNN 由两个明确的部分组成:主干网络<strong class="kn ir"/><em class="iq"/>和网络头部<strong class="kn ir"/><em class="iq"/>从而继承了更快的 R-CNN 架构。基于特征金字塔网络(FPN)或 ResNet101 的卷积骨干网络作为整个图像的特征提取器。在此之上是区域建议网络(RPN ),它对头部的多尺度 RoI(感兴趣区域)进行采样。网络头进行边界框识别和应用于每个 RoI 的掩模预测。在两者之间，RoIAlign 图层将 RPN 提取的多尺度要素与输入精确对齐。</p></blockquote><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/40a40bc89105abc80990f04e5c109952.png" data-original-src="https://miro.medium.com/v2/resize:fit:922/format:webp/1*ThnTPZE0mtebI--OtspEFA.png"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">MRCNN framework as presented in the original paper</figcaption></figure><p id="5c42" class="pw-post-body-paragraph kl km iq kn b ko lw kq kr ks lx ku kv kw ly ky kz la lz lc ld le ma lg lh li ij bi translated"><strong class="kn ir">对于实际应用，尤其是原型制作，预训练的 ConvNet 至关重要。</strong>在许多现实生活场景中，数据科学家的标注数据集非常有限，甚至没有任何标注。相比之下，<em class="lj">conv net 需要大的标记数据集来收敛</em>(例如，ImageNet 数据集包含 1.2M 的标记图像)。这就是<a class="ae my" href="http://cs231n.github.io/transfer-learning/" rel="noopener ugc nofollow" target="_blank">迁移学习</a>帮助的地方:一种策略是冻结卷积层的权重，只重新训练分类器。为了避免模型过度拟合，Conv 图层权重冻结对于小数据集非常重要。</p><p id="509f" class="pw-post-body-paragraph kl km iq kn b ko lw kq kr ks lx ku kv kw ly ky kz la lz lc ld le ma lg lh li ij bi translated">以下是我在一个时期的训练后得到的样本:</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nh"><img src="../Images/175237c3b48102c62edffe903f5dfd6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3w9Jo-lcflGFsaYaWr80kg.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">The result of instance segmentation: all key ingredients are detected</figcaption></figure><p id="c07e" class="pw-post-body-paragraph kl km iq kn b ko lw kq kr ks lx ku kv kw ly ky kz la lz lc ld le ma lg lh li ij bi translated">下一步(<em class="lj">处理分类器</em>的推断数据，在我的 50K 管道视图中)是裁剪包含盘子的图像部分，并从该裁剪中提取每种成分的 2D 二进制掩码:</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ni"><img src="../Images/0b25f2c16fce35d560aa2931eee2f6a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kzQ7iRL-jHZmugl6E0xOwA.png"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Cropped image with the target dish and its key ingredients as binary masks</figcaption></figure><p id="19a6" class="pw-post-body-paragraph kl km iq kn b ko lw kq kr ks lx ku kv kw ly ky kz la lz lc ld le ma lg lh li ij bi translated">这些二进制掩码然后被组合成一个 8 通道图像(正如我为 MRCNN 定义的 8 个掩码类)——这就是我的<em class="lj">信号#1 </em>:</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/e44e93b8bb9f39d3f617eda6ebdf198f.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*aiacmxaGyzR0JHzlxDOJXg.png"/></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">Signal #1: 8-channel image composed of binary masks. Colors are just for better visualization</figcaption></figure><p id="e550" class="pw-post-body-paragraph kl km iq kn b ko lw kq kr ks lx ku kv kw ly ky kz la lz lc ld le ma lg lh li ij bi translated">对于<em class="lj">信号#2 </em>，我从 MRCNN 推断中计算了每种成分的数量，并将其打包到每种作物的特征向量中。</p><h1 id="6890" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">阶段 2:基于 Keras 的 ConvNet 分类器</h1><p id="f29e" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">CNN 分类器是使用 Keras 从头开始实现的。我心中的目标是融合几个信号(<em class="lj">信号#1 </em>和<em class="lj">信号#2 </em>，以及在未来添加更多数据)，并让网络对菜肴的质量等级做出预测。以下架构是实验性的，离理想状态还很远:</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nk"><img src="../Images/5999862190c632b8da720cb92208d678.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ih8hl4sBpkVG3IQRUvv_8A.jpeg"/></div></div></figure><p id="bbf1" class="pw-post-body-paragraph kl km iq kn b ko lw kq kr ks lx ku kv kw ly ky kz la lz lc ld le ma lg lh li ij bi translated">关于分类器架构的几点观察和评论:</p><ul class=""><li id="c3cb" class="mb mc iq kn b ko lw ks lx kw md la me le mf li mg mh mi mj bi translated"><strong class="kn ir">多尺度卷积模块</strong>:最初我为卷积层选择了一个 5x5 的内核，但是这个决定只给了我一个满意的分数。用几种不同核的卷积层<code class="fe mk ml mm mn b">AveragePooling2D</code>得到了更好的结果:3x3，5x5，7x7，11x11。在每一层之前增加了额外的 1x1 卷积层，以减少维数。这个组件有点类似于<a class="ae my" href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf" rel="noopener ugc nofollow" target="_blank"> Inception 模块</a>，尽管我克制自己不去构建一个深度网络。</li><li id="cf98" class="mb mc iq kn b ko mo ks mp kw mq la mr le ms li mg mh mi mj bi translated"><strong class="kn ir">更大的内核:</strong>我使用了更大的内核大小，因为更大的尺度特征可以很容易地从输入图像中提取出来(输入图像本身可以被视为具有 8 个过滤器的激活层——每个成分的二进制掩码基本上是一个过滤器)。</li><li id="451f" class="mb mc iq kn b ko mo ks mp kw mq la mr le ms li mg mh mi mj bi translated"><strong class="kn ir">信号融合:</strong>我的简单实现只使用了一层非线性来合并两个特征集:处理过的二进制掩码(信号#1)和成分计数(信号#2)。尽管很幼稚，添加信号#2 为分数提供了一个很好的提升(交叉熵从<code class="fe mk ml mm mn b">0.8</code>提高到<code class="fe mk ml mm mn b">[0.7, 0.72]</code>)</li><li id="ed4e" class="mb mc iq kn b ko mo ks mp kw mq la mr le ms li mg mh mi mj bi translated"><strong class="kn ir">逻辑:</strong>根据张量流，这是应用<code class="fe mk ml mm mn b">tf.nn.softmax_cross_entropy_with_logits</code>计算批次损失的层。</li></ul><h1 id="002f" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">阶段 3:t-SNE 的结果可视化</h1><p id="4d5f" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">对于测试集结果可视化，我使用了 t-SNE，一种用于数据可视化的流形学习技术。t-SNE 使用非常显著的非凸损失函数来最小化低维嵌入数据点和原始高维数据的联合概率之间的 KL 散度。你绝对应该读一下<a class="ae my" href="https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf" rel="noopener ugc nofollow" target="_blank">的原始论文</a>，它信息量极大，写得很好。</p><p id="d6bd" class="pw-post-body-paragraph kl km iq kn b ko lw kq kr ks lx ku kv kw ly ky kz la lz lc ld le ma lg lh li ij bi translated">为了可视化测试集分类结果，我推断了测试集图像，提取了分类器的 logits 层，并对该数据集应用了 t-SNE。虽然我应该用不同的困惑值来玩，但结果看起来还是不错的。动画 GIF:</p><figure class="ll lm ln lo gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nl"><img src="../Images/b5cfbc7c44da88d0ce020093bfc8f23a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*OXE2tG1b2pcJqJcizGqgFA.gif"/></div></div><figcaption class="ls lt gj gh gi lu lv bd b be z dk">t-SNE of the test set predictions by the classifier</figcaption></figure><p id="fcff" class="pw-post-body-paragraph kl km iq kn b ko lw kq kr ks lx ku kv kw ly ky kz la lz lc ld le ma lg lh li ij bi translated">虽然不完美，但这种方法确实有效。尽管如此，仍有许多需要改进的地方:</p><ul class=""><li id="0001" class="mb mc iq kn b ko lw ks lx kw md la me le mf li mg mh mi mj bi translated"><strong class="kn ir">更多数据。</strong> ConvNets 需要大量数据，而我只有 139 个样本用于训练。像数据增强这样的技巧工作得很好(我使用了一个<a class="ae my" href="https://en.wikipedia.org/wiki/Dihedral_group" rel="noopener ugc nofollow" target="_blank"> D4，或二面角，对称群</a>增强，产生了 2K+增强图像)，但更多的真实数据对于良好的性能至关重要。</li><li id="da87" class="mb mc iq kn b ko mo ks mp kw mq la mr le ms li mg mh mi mj bi translated"><strong class="kn ir">合适的损失函数。</strong>为了简单起见，我使用了开箱即用的分类交叉熵损失。我会切换到一个更合适的损失函数，一个更好地利用类内方差的函数。一开始一个好的选择可能是三重损失(详见<a class="ae my" href="https://arxiv.org/pdf/1703.07737.pdf" rel="noopener ugc nofollow" target="_blank"> FaceNet 论文</a>)。</li><li id="ea22" class="mb mc iq kn b ko mo ks mp kw mq la mr le ms li mg mh mi mj bi translated"><strong class="kn ir">更好的整体分类器架构。</strong>当前的分类器基本上是一个原型，其目标是解释输入的二进制掩码并将多个特征集组合成一个推理管道。</li><li id="3165" class="mb mc iq kn b ko mo ks mp kw mq la mr le ms li mg mh mi mj bi translated"><strong class="kn ir">更好的标注。我在手动图像标记(6 个质量等级)上相当马虎:分类器在十几个测试集图像上胜过了我自己！</strong></li></ul></div><div class="ab cl nm nn hu no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="ij ik il im in"><p id="d9ef" class="pw-post-body-paragraph kl km iq kn b ko lw kq kr ks lx ku kv kw ly ky kz la lz lc ld le ma lg lh li ij bi translated"><strong class="kn ir">超越与自省。</strong>在实践中，企业没有数据、没有注释、没有清晰明确的技术任务需要完成的情况非常普遍(我们应该停止否认这一事实)。这是一件好事(否则，他们为什么需要你？):您的工作是拥有工具、足够多的多 GPU 硬件、业务和技术专业知识的组合、预训练的模型以及为业务带来价值所需的一切。</p><p id="6230" class="pw-post-body-paragraph kl km iq kn b ko lw kq kr ks lx ku kv kw ly ky kz la lz lc ld le ma lg lh li ij bi translated">从小处着手:可以用乐高积木搭建的工作原型可以提高进一步对话的效率——作为一名数据科学家，你的工作就是向企业推荐这种方法。</p></div></div>    
</body>
</html>