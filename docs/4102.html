<html>
<head>
<title>Naive-Bayes Tweet Polarity Predictor on Malaysia’s 14th General Election</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">朴素贝叶斯推文极性预测马来西亚第 14 届大选</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/naive-bayes-tweet-polarity-predictor-on-malaysias-14th-general-election-3a3679094b5e?source=collection_archive---------12-----------------------#2018-07-18">https://towardsdatascience.com/naive-bayes-tweet-polarity-predictor-on-malaysias-14th-general-election-3a3679094b5e?source=collection_archive---------12-----------------------#2018-07-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e000" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">马来西亚最具标志性选举的初级数据科学任务</h2></div><p id="91ca" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我第一次在 Udacity 上了解朴素贝叶斯分类器时，我想到了这个迷你项目。NB 上有很多在线教程，但我不知道他们为什么主要做垃圾邮件分类(比如，10 个博客中有 9 个都在写 NB 垃圾邮件过滤)。</p><p id="fc06" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那时，我的祖国马来西亚正在迎来她历史上最重要的选举，所以我想出了这个主意，说——我们为什么不在选举前做一个推特分析，使用 NB 作为极性预测器？</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi lb"><img src="../Images/6c2d564512b5582c4aec8e41d39f41a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/0*rIDFuk5tSdhHOQ7p.jpg"/></div></figure><p id="3a50" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于其简单性，NB 在文本分类和情感分析中是众所周知的算法，但是对于 NLP 上下文中的 NB 来说，最大的缺点是它只对单词的出现感兴趣，而忽略了单词之间的相关性(因此得名“naive”)。因此，通过使用 NB，我们只能从“词汇袋”的角度来看待我们的上下文，考虑<em class="lj">发生</em>超过<em class="lj">相关性</em>。</p><h1 id="fb9e" class="lk ll iq bd lm ln lo lp lq lr ls lt lu jw lv jx lw jz lx ka ly kc lz kd ma mb bi translated">NB 在做什么？</h1><p id="7321" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">简单来说，我想把 NB 解释为一个“向前-向后”的过程。</p><ol class=""><li id="969f" class="mh mi iq kh b ki kj kl km ko mj ks mk kw ml la mm mn mo mp bi translated">“向前”的过程——<strong class="kh ir">给定这句话在<em class="lj"> C1 </em>类中，一个单词<em class="lj"> w1 </em>出现的次数是多少？</strong></li><li id="a388" class="mh mi iq kh b ki mq kl mr ko ms ks mt kw mu la mm mn mo mp bi translated">“逆向”过程— <strong class="kh ir">给定一个单词<em class="lj"> w1 </em>包含在句子中，这个句子在<em class="lj"> C1 </em>类中的概率是多少？</strong></li></ol><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mv"><img src="../Images/71600c0f2f59f71c0ff0d046c3851b98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PqKl5rr6i5QQMIXr.jpg"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Naive-Bayes tutorial on Udacity’s course.</figcaption></figure><p id="7706" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就是为什么出现在 NB 中很重要——某个类中某个单词出现的次数越多，它在我们进行预测时的影响就越大。</p><p id="2a3f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Udacity 的<a class="ae ne" href="https://www.udacity.com/course/intro-to-machine-learning--ud120" rel="noopener ugc nofollow" target="_blank">本课程</a>中的 NB 教程给出了关于 NB 的简短、简明、清晰的解释。</p><h1 id="ab44" class="lk ll iq bd lm ln lo lp lq lr ls lt lu jw lv jx lw jz lx ka ly kc lz kd ma mb bi translated">收集推文</h1><p id="4f7c" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">首先，我们需要准备我们的原材料——在这种情况下，我们自己收集 tweets。所以我有一个用于抓取推文的<a class="ae ne" href="https://github.com/gudgud96/polarity-prediction-msia-ge14/blob/master/twitter_scraper.py" rel="noopener ugc nofollow" target="_blank"> twitter_scraper.py </a>脚本。</p><p id="4df4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我使用<a class="ae ne" href="http://www.tweepy.org/" rel="noopener ugc nofollow" target="_blank"> tweepy </a>进行抓取部分，所以需要一个 API 密匙进行授权和设置。在这个项目中，我只是收集了与我最亲爱的总理(哦，对不起，现在是前总理)相关的推文，所以极性分析主要针对我们亲爱的前总理。</p><p id="97ea" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你还需要一个听众来倾听收集到的推文流，并决定你想要如何处理它们。在我的例子中，我获取 tweet 并将其传递给<a class="ae ne" href="http://textblob.readthedocs.io/en/dev/" rel="noopener ugc nofollow" target="_blank"> TextBlob </a>进行极性和主观性评分，并将其写入一个. csv 文件。</p><p id="d0b1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，把你的听众连接到信息流上，让它为你抓取推文！一旦你收集了足够多的推文，简单地停止这个过程(我只收集了 300 条推文，哈哈)。</p><p id="140e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">经验教训:推文主要是马来语，极性得分只是做得不好。所以最后我决定自己在训练和测试数据上手动标注每条推文的类别——这就是为什么我只收集了 300 条推文。</p><h1 id="a4f2" class="lk ll iq bd lm ln lo lp lq lr ls lt lu jw lv jx lw jz lx ka ly kc lz kd ma mb bi translated">构建 NB 模型</h1><p id="c375" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">在进入测试部分之前，我构建了一些东西:</p><ol class=""><li id="b939" class="mh mi iq kh b ki kj kl km ko mj ks mk kw ml la mm mn mo mp bi translated">字典——在抓取的推文中出现的所有单词。我只是使用 TextBlob 来标记我的每条 tweet，并收集它们。</li><li id="4718" class="mh mi iq kh b ki mq kl mr ko ms ks mt kw mu la mm mn mo mp bi translated">频率表——统计每个单词在给定类别中的出现次数，w <em class="lj"> i </em>。用每个类别中出现的次数除以单词 w <em class="lj"> i </em>的总出现次数，我们得到<strong class="kh ir">先验概率</strong>——给定一个单词，它在某个类别中出现的概率。或者，P(C|w <em class="lj"> i </em>)。</li></ol><p id="64e2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们在数据集中进行了预计算，我们知道:</p><blockquote class="nf ng nh"><p id="b0c1" class="kf kg lj kh b ki kj jr kk kl km ju kn ni kp kq kr nj kt ku kv nk kx ky kz la ij bi translated"><em class="iq"> P(C=0) = 182/300 = 0.6067 </em></p><p id="5a72" class="kf kg lj kh b ki kj jr kk kl km ju kn ni kp kq kr nj kt ku kv nk kx ky kz la ij bi translated"><em class="iq"> P(C=1) = 118/300 = 0.3933 </em></p></blockquote><p id="5495" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于 tweet 中的每个单词，从表中检索其频率，并在列表中附加每个类别中每个单词的先验概率:</p><p id="b0c2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">取所有先验概率的乘积(numpy 在这里通过<em class="lj"> prod() </em>方法做得很好)。你得到两个概率，<em class="lj"> p0 </em>和<em class="lj"> p1 </em>。</p><p id="52d6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">将<em class="lj"> pk </em>乘以 P(C=k)就得到<strong class="kh ir">后验概率</strong>。比较它们，较高的概率决定了推文的类别。</p><p id="5583" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对每条推文重复这个过程，你就可以使用 NB 分类器预测推文的极性了！</p><h1 id="d442" class="lk ll iq bd lm ln lo lp lq lr ls lt lu jw lv jx lw jz lx ka ly kc lz kd ma mb bi translated">调查的结果</h1><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi nl"><img src="../Images/433782d4859c6a6ee9cafd30a300f430.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*knUjll_X5g201kHu.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Results for my test set</figcaption></figure><p id="76ac" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我隔离了 20 条推文作为测试集，NB 分类器达到了<strong class="kh ir"> 90%的准确率</strong> (18/20 正确)。</p><p id="1f68" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看看分类器犯了哪两条推文的错误。</p><blockquote class="nf ng nh"><p id="30ef" class="kf kg lj kh b ki kj jr kk kl km ju kn ni kp kq kr nj kt ku kv nk kx ky kz la ij bi translated"><em class="iq">tgok video tu aku tak kesian dkat tun m TP kesian dkat Najib。kesian nampak desperito Sgt nak jatuhkan tun m .</em></p></blockquote><p id="91b8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">看着视频，我不同情敦·马哈蒂尔，但我同情纳吉布，看到他如此不顾一切地想扳倒敦·马哈蒂尔。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi nm"><img src="../Images/5d1b87334b40a64f67df0a998bede38b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*12UlCk9fcYy8KykI.jpg"/></div></div></figure><p id="aab1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于理解上下文的我们来说，这条推文很明显属于 0 类，即反纳吉布类，但我们的分类器却相反。</p><p id="ab68" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看看哪些词决定了这条推文在分类器中的类别:</p><blockquote class="nf ng nh"><p id="4916" class="kf kg lj kh b ki kj jr kk kl km ju kn ni kp kq kr nj kt ku kv nk kx ky kz la ij bi translated"><em class="iq">视频+ tu + aku + tak + tun + m +纳吉+ nak + tun + m </em></p></blockquote><p id="e2cf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">显然，术语“Tun M”应该组合在一起而不是分开，因为分开它可能传达不同的结果。此外，tweet 中决定的最重要的词应该是“kesian”(怜悯)，我们在决定词中没有看到这个词。</p><p id="66a6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于我们失败的另一条推文:</p><blockquote class="nf ng nh"><p id="8586" class="kf kg lj kh b ki kj jr kk kl km ju kn ni kp kq kr nj kt ku kv nk kx ky kz la ij bi translated"><em class="iq">国民阵线</em></p></blockquote><p id="01ad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对我们来说，这应该属于支持纳吉布的阶层，因为纳吉布的政党国民阵线的标签。然而，在我们的实现中，hashtags 是被清理的，所以在这里要学习的另一课是选择哪些内容要清理，哪些不要清理。</p><p id="7ce8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">单词“lahanat”(诅咒的一个粗鲁的单词)是我们的分类器将此归类为反纳吉类的主要原因。然而，我将得出结论，这条推文很难分类，因为我们只有两个有意义的词，每个代表一个类别，我们没有任何额外的信息。</p><h1 id="d73e" class="lk ll iq bd lm ln lo lp lq lr ls lt lu jw lv jx lw jz lx ka ly kc lz kd ma mb bi translated">结论</h1><p id="ed78" class="pw-post-body-paragraph kf kg iq kh b ki mc jr kk kl md ju kn ko me kq kr ks mf ku kv kw mg ky kz la ij bi translated">总的来说，我应该说 NB 分类器仍然做得相当好，前提是我们只有 300 条人工注释的训练推文。</p><p id="b158" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当然，还有很大的改进空间——首先是<strong class="kh ir">增加训练集</strong>的大小，但是我现在想不出这个领域有任何其他方法可以自动化注释过程。</p><p id="46bc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">令人震惊的是，在选举前，大多数推文都是反纳吉布的。毫无疑问，我们一直认为马来社群仍然会支持纳吉和国阵，但事实证明，推特上的马来网民告诉我们一个不同的故事。</p><p id="1dd4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我要说的是，这是我工作和学习的一个有趣而简单的迷你项目，它与我和我的祖国非常相关。此外，写这篇文章有助于澄清我所学到的 NB 的概念，并迫使我用简单的语言来表达它们，就像<a class="ae ne" href="https://mattyford.com/blog/2014/1/23/the-feynman-technique-model" rel="noopener ugc nofollow" target="_blank">费曼技巧</a>中建议的那样。所以，让我们期待更多的到来！</p><p id="a34b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对代码感兴趣？通过我的<a class="ae ne" href="https://github.com/gudgud96/polarity-prediction-msia-ge14/" rel="noopener ugc nofollow" target="_blank"> GitHub 回购</a>结账。</p></div></div>    
</body>
</html>