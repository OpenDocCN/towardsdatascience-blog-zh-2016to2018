<html>
<head>
<title>Naive Bayes in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的朴素贝叶斯</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/naive-bayes-in-machine-learning-f49cc8f831b4?source=collection_archive---------1-----------------------#2017-11-06">https://towardsdatascience.com/naive-bayes-in-machine-learning-f49cc8f831b4?source=collection_archive---------1-----------------------#2017-11-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/9614ad98395d1852d82262c77f4e9e96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I2rfafFMuFU48vePW9j0Ww.jpeg"/></div></div></figure><div class=""/><p id="a268" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">贝叶斯定理在概率论和统计学中有许多用途。你有极小的可能从未听说过这个定理。原来这个定理已经找到了进入机器学习世界的方法，形成了一个高度修饰的算法。在本文中，我们将学习所有关于朴素贝叶斯算法的知识，以及它在机器学习中用于不同目的的变体。</p><p id="f247" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你可能已经猜到了，这需要我们从概率的角度来看待事物。就像在机器学习中，我们有属性、反应变量和预测或分类。使用该算法，我们将处理数据集中变量的概率分布，并在给定新实例的属性的情况下，预测响应变量属于特定值的概率。让我们从回顾贝叶斯定理开始。</p><h2 id="56c0" class="kw kx jb bd ky kz la dn lb lc ld dp le kj lf lg lh kn li lj lk kr ll lm ln lo bi translated">贝叶斯定理</h2><p id="b03a" class="pw-post-body-paragraph jy jz jb ka b kb lp kd ke kf lq kh ki kj lr kl km kn ls kp kq kr lt kt ku kv ij bi translated">这使我们能够根据与前一事件相关的任何事件的先验知识来检查事件的概率。因此，举例来说，如果我们知道房子周围的设施，与不知道房子的位置相比，我们可以更好地评估房子价格高的可能性。贝叶斯定理就是这么做的。</p><figure class="lv lw lx ly gt is gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/5fd6c9d968e5bd04c4348af31c4b9900.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*c0PJICLo_oPqKODuKnSIHQ.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Image taken from Wikipedia</figcaption></figure><p id="f5bf" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">上面的等式给出了贝叶斯定理的基本表示。这里A和B是两个事件,</p><p id="0b1f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc"> <em class="md"> P(A|B):假设B已经发生，事件A发生的条件概率。这也被称为后验概率。</em> </strong></p><p id="7129" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc"> <em class="md"> P(A)和P(B):A和B互不考虑的概率。</em>T9】</strong></p><p id="b485" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc"> <em class="md"> P(B|A):假设A已经发生，事件B发生的条件概率。</em>T13】</strong></p><p id="649e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，让我们看看这如何很好地适应机器学习的目的。</p><p id="a68a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">以一个简单的机器学习问题为例，我们需要从一组给定的属性(在训练示例中)中学习我们的模型，然后形成一个假设或与一个响应变量的关系。然后，给定新实例的属性，我们使用这个关系来预测响应。<em class="md">使用贝叶斯定理，在给定一组新属性的情况下，可以构建一个预测响应变量属于某类的概率的学习器。</em></p><p id="0c64" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">再次考虑前面的等式。现在，假设A是响应变量，B是输入属性。所以根据等式，我们有</p><p id="1edb" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc"> P(A|B) </strong>:给定输入属性，响应变量属于特定值的条件概率。<strong class="ka jc">这也被称为后验概率。</strong></p><p id="89de" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc"> P(A) </strong> : <strong class="ka jc">响应变量的先验概率。</strong></p><p id="e905" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">P(B):训练数据或证据的概率。</p><p id="1eeb" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">P(B|A):这就是训练数据的似然性。</p><p id="64b2" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，上述等式可以改写为</p><figure class="lv lw lx ly gt is gh gi paragraph-image"><div class="gh gi me"><img src="../Images/7a9ba116d37e15cd3ffc4b1d02ce8c5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*n4D8BKlVCurNg1xKshTsxg.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Image taken from Wikipedia</figcaption></figure><p id="4010" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们来看一个问题，其中属性的数量等于n，响应是一个布尔值，即它可以是两个类中的一个。此外，属性是分类的(我们的例子中有两个类别)。现在，为了训练分类器，我们需要为实例和响应空间中的所有值计算P(B|A)。<strong class="ka jc"> <em class="md">这意味着，我们将需要计算2*(2^n -1)，用于学习这个模型的参数。在大多数实际的学习领域，这显然是不现实的。例如，如果有30个布尔属性，那么我们将需要估计超过30亿个参数。</em> </strong></p><h2 id="b745" class="kw kx jb bd ky kz la dn lb lc ld dp le kj lf lg lh kn li lj lk kr ll lm ln lo bi translated">朴素贝叶斯算法</h2><p id="14a0" class="pw-post-body-paragraph jy jz jb ka b kb lp kd ke kf lq kh ki kj lr kl km kn ls kp kq kr lt kt ku kv ij bi translated">为了实用，需要降低上述贝叶斯分类器的复杂性。<strong class="ka jc"> <em class="md">朴素贝叶斯算法通过对训练数据集做出条件独立性的假设来做到这一点。这大大降低了上述问题的复杂性，只有2n。</em></strong></p><p id="e595" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc"> <em class="md">条件独立性假设说明，给定随机变量X，Y，Z，我们说X是条件独立于Y给定Z的，当且仅当支配X的概率分布独立于Y给定Z的值</em> </strong></p><p id="ce46" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">换句话说，给定<em class="md"> Z </em>，X和Y是有条件独立的当且仅当，给定<em class="md"> Z </em>发生的知识，关于<em class="md"> X </em>是否发生的知识不提供关于<em class="md"> Y </em>发生的可能性的信息，并且关于<em class="md"> Y </em>是否发生的知识不提供关于<em class="md"> X </em>发生的可能性的信息。</p><blockquote class="mf mg mh"><p id="5060" class="jy jz md ka b kb kc kd ke kf kg kh ki mi kk kl km mj ko kp kq mk ks kt ku kv ij bi translated">这种假设使得贝叶斯算法显得幼稚。</p></blockquote><p id="5b37" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">给定n个不同的属性值，可能性现在可以写成</p><figure class="lv lw lx ly gt is gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/1f5de7ec082d408ed9bb43e3a07441c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*2M9bpdqhlzJ2kEAloHTBSg.png"/></div></figure><p id="0dc4" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这里，X代表属性或特征，Y是响应变量。现在，P(X|Y)等于给定Y的每个属性X的概率分布的乘积。</p><h2 id="5e89" class="kw kx jb bd ky kz la dn lb lc ld dp le kj lf lg lh kn li lj lk kr ll lm ln lo bi translated">最大化后验概率</h2><p id="467d" class="pw-post-body-paragraph jy jz jb ka b kb lp kd ke kf lq kh ki kj lr kl km kn ls kp kq kr lt kt ku kv ij bi translated">我们感兴趣的是找到后验概率或P(Y|X)。现在，对于Y的多个值，我们需要计算每个值的表达式。</p><p id="06bf" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">给定一个新的实例Xnew，我们需要计算Y取任何给定值的概率，给定Xnew的观察属性值，给定从训练数据估计的分布P(Y)和P(X|Y)。</p><p id="6dcb" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">那么，我们如何预测响应变量的类别，基于我们得到的P(Y|X)的不同值。我们简单地取这些值中最可能的或最大的。因此，这个过程也被称为最大化后验概率。T29】</p><h2 id="23b3" class="kw kx jb bd ky kz la dn lb lc ld dp le kj lf lg lh kn li lj lk kr ll lm ln lo bi translated">最大化可能性</h2><p id="7b4a" class="pw-post-body-paragraph jy jz jb ka b kb lp kd ke kf lq kh ki kj lr kl km kn ls kp kq kr lt kt ku kv ij bi translated"><strong class="ka jc"> <em class="md">如果我们假设响应变量是均匀分布的</em> </strong>，也就是说它同样有可能得到任何响应，那么我们可以进一步简化算法。在这种假设下，先验或P(Y)变成一个常数值，即1/响应的类别。</p><p id="9ec3" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc"> <em class="md">由于，先验和证据现在都独立于响应变量，这些可以从方程中去掉。因此，最大化后验概率就归结为最大化似然问题。</em> </strong></p><h2 id="1759" class="kw kx jb bd ky kz la dn lb lc ld dp le kj lf lg lh kn li lj lk kr ll lm ln lo bi translated">特征分布</h2><p id="d4e5" class="pw-post-body-paragraph jy jz jb ka b kb lp kd ke kf lq kh ki kj lr kl km kn ls kp kq kr lt kt ku kv ij bi translated">如上所述，我们需要从训练集中估计响应变量的分布，或者假设均匀分布。类似地，<strong class="ka jc"> <em class="md">为了估计特征分布的参数，必须假设分布或从训练集</em> </strong>生成特征的非参数模型。这种假设被称为事件模型。这些假设的变化产生了用于不同目的的不同算法。<strong class="ka jc">对于连续分布，高斯朴素贝叶斯是首选算法。</strong> <strong class="ka jc">为离散特征，多项式和伯努利分布为流行</strong>。对这些变化的详细讨论超出了本文的范围。</p><p id="978b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">朴素贝叶斯分类器在复杂的情况下工作得非常好，尽管有简化的假设和天真。<strong class="ka jc"> <em class="md">这些分类器的优点在于，它们需要少量的训练数据来估计分类所需的参数。</em> </strong> <strong class="ka jc"> <em class="md">这是文本分类的算法选择。</em> </strong>这是朴素贝叶斯分类器背后的基本思想，你需要开始实验算法。</p></div><div class="ab cl mm mn hu mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="ij ik il im in"><p id="acad" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你喜欢这篇文章，一定要为下面的这篇文章鼓掌以示支持，如果你有任何问题，请留言，我会尽力回答。</p><p id="7050" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了更加了解机器学习的世界，<strong class="ka jc">跟我来</strong>。这是最好的办法，等我多写点这样的文章就知道了。</p><p id="ddff" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">也可以在<a class="ae mt" href="https://twitter.com/Prashant_1722" rel="noopener ugc nofollow" target="_blank"> <strong class="ka jc"> Twitter </strong> </a>，<a class="ae mt" href="mailto:pr.span24@gmail.com" rel="noopener ugc nofollow" target="_blank"> <strong class="ka jc">直接发邮件给我</strong> </a>或者<a class="ae mt" href="https://www.linkedin.com/in/prashantgupta17/" rel="noopener ugc nofollow" target="_blank"> <strong class="ka jc">在linkedin </strong> </a>上找我。我很乐意收到你的来信。</p><p id="17f7" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">乡亲们，祝你们有美好的一天:)</p></div></div>    
</body>
</html>