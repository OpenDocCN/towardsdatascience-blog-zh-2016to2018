<html>
<head>
<title>Building A Linear Regression with PySpark and MLlib</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 PySpark 和 MLlib 构建线性回归</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-linear-regression-with-pyspark-and-mllib-d065c3ba246a?source=collection_archive---------0-----------------------#2018-05-01">https://towardsdatascience.com/building-a-linear-regression-with-pyspark-and-mllib-d065c3ba246a?source=collection_archive---------0-----------------------#2018-05-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/bf1cf587e55db695c9e92c1e845df759.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OEcCpDJeuXIaqWqYYGS-kQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo credit: Pixabay</figcaption></figure><p id="b762" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><a class="ae la" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>已经成为机器学习和数据科学最常用和最受支持的开源工具之一。</p><p id="4789" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在这篇文章中，我将帮助你开始使用<a class="ae la" href="https://spark.apache.org/docs/2.2.0/ml-classification-regression.html#linear-regression" rel="noopener ugc nofollow" target="_blank"> Apache Spark 的 spark.ml 线性回归</a>来预测波士顿房价。我们的数据来自<a class="ae la" href="https://www.kaggle.com/c/boston-housing/data" rel="noopener ugc nofollow" target="_blank"> Kaggle 竞赛:波士顿郊区的房屋价值</a>。对于每个房屋观察，我们有以下信息:</p><p id="92d8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">各城镇的人均犯罪率。</p><p id="911e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> ZN </strong> —面积超过 25，000 平方英尺的住宅用地比例</p><p id="54e5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> INDUS </strong> —每个城镇非零售商业亩数比例。</p><p id="04ef" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> CHAS </strong> —查尔斯河虚拟变量(= 1，如果区域边界为河流；否则为 0)。</p><p id="76f0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> NOX </strong> —氮氧化物浓度(百万分之一)。</p><p id="72fd" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> RM </strong> —每个住宅的平均房间数。</p><p id="1afb" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">年龄</strong>—1940 年前建造的自有住房比例。</p><p id="0ba2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">DIS  —到五个波士顿就业中心的加权平均距离。</p><p id="1061" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> RAD </strong> —放射状公路可达性指标。</p><p id="4a6d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">税</strong> —每 1 万美元的全价值财产税税率。</p><p id="8153" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">pt ratio</strong>——按城镇划分的学生/教师比率。</p><p id="0177" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">黑人</strong> — 1000(Bk — 0.63)其中 Bk 是按城镇划分的黑人比例。</p><p id="0efe" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> LSTAT </strong> —较低的人口地位(百分比)。</p><p id="7501" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> MV </strong> —以千美元为单位的自有住房的中值。这是目标变量。</p><p id="4385" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">输入数据集包含各种房屋的详细信息。根据提供的信息，目标是提出一个模型来预测该地区给定房屋的中值。</p><h1 id="6e3d" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">加载数据</h1><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="cad6" class="mi lc iq me b gy mj mk l ml mm">from pyspark import SparkConf, SparkContext<br/>from pyspark.sql import SQLContext<br/>sc= SparkContext()<br/>sqlContext = SQLContext(sc)</span><span id="1d0b" class="mi lc iq me b gy mn mk l ml mm">house_df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('boston.csv')<br/>house_df.take(1)</span></pre><p id="df49" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"><em class="mo">【Row(CRIM = 0.00632，ZN=18.0，INDUS=2.309999943，CHAS=0，NOX=0.537999988，RM=6.574999809，AGE = 65.19999695，DIS=4.090000153，RAD=1，TAX=296，PT = 15.30000019</em></strong></p><h1 id="d68e" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">数据探索</h1><p id="1a15" class="pw-post-body-paragraph kc kd iq ke b kf mp kh ki kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz ij bi translated">以树格式打印模式。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="7258" class="mi lc iq me b gy mj mk l ml mm">house_df.cache()<br/>house_df.printSchema()</span><span id="9ad6" class="mi lc iq me b gy mn mk l ml mm">root<br/> |-- CRIM: double (nullable = true)<br/> |-- ZN: double (nullable = true)<br/> |-- INDUS: double (nullable = true)<br/> |-- CHAS: integer (nullable = true)<br/> |-- NOX: double (nullable = true)<br/> |-- RM: double (nullable = true)<br/> |-- AGE: double (nullable = true)<br/> |-- DIS: double (nullable = true)<br/> |-- RAD: integer (nullable = true)<br/> |-- TAX: integer (nullable = true)<br/> |-- PT: double (nullable = true)<br/> |-- B: double (nullable = true)<br/> |-- LSTAT: double (nullable = true)<br/> |-- MV: double (nullable = true)</span></pre><p id="e1c9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">执行描述性分析</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="374d" class="mi lc iq me b gy mj mk l ml mm">house_df.describe().toPandas().transpose()</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/83b563a81d950ddd6eedfe7467fffe48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*J0cCorDPfuRG1mTA76CoyA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 1</figcaption></figure><p id="1512" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">散点图是粗略确定多个自变量之间是否存在线性相关性的一个很好的方法。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="adea" class="mi lc iq me b gy mj mk l ml mm">import pandas as pd</span><span id="f53d" class="mi lc iq me b gy mn mk l ml mm">numeric_features = [t[0] for t in house_df.dtypes if t[1] == 'int' or t[1] == 'double']<br/>sampled_data = house_df.select(numeric_features).sample(False, 0.8).toPandas()<br/>axs = pd.scatter_matrix(sampled_data, figsize=(10, 10))<br/>n = len(sampled_data.columns)<br/>for i in range(n):<br/>    v = axs[i, 0]<br/>    v.yaxis.label.set_rotation(0)<br/>    v.yaxis.label.set_ha('right')<br/>    v.set_yticks(())<br/>    h = axs[n-1, i]<br/>    h.xaxis.label.set_rotation(90)<br/>    h.set_xticks(())</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/62cc0c64e3443ce967c008a0f7e53dfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*SayZJVPd5ZFlGEM0_MPn5w.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 2</figcaption></figure><p id="3458" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">很难看到。让我们找出自变量和目标变量之间的相关性。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="996b" class="mi lc iq me b gy mj mk l ml mm">import six<br/>for i in house_df.columns:<br/>    if not( isinstance(house_df.select(i).take(1)[0][0], six.string_types)):<br/>        print( "Correlation to MV for ", i, house_df.stat.corr('MV',i))</span><span id="4494" class="mi lc iq me b gy mn mk l ml mm">Correlation to MV for  CRIM -0.3883046116575088<br/>Correlation to MV for  ZN 0.36044534463752903<br/>Correlation to MV for  INDUS -0.48372517128143383<br/>Correlation to MV for  CHAS 0.17526017775291847<br/>Correlation to MV for  NOX -0.4273207763683772<br/>Correlation to MV for  RM 0.695359937127267<br/>Correlation to MV for  AGE -0.37695456714288667<br/>Correlation to MV for  DIS 0.24992873873512172<br/>Correlation to MV for  RAD -0.3816262315669168<br/>Correlation to MV for  TAX -0.46853593528654536<br/>Correlation to MV for  PT -0.5077867038116085<br/>Correlation to MV for  B 0.3334608226834164<br/>Correlation to MV for  LSTAT -0.7376627294671615<br/>Correlation to MV for  MV 1.0</span></pre><p id="f9a3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">相关系数范围从–1 到 1。当接近 1 时，说明有很强的正相关性；例如，当房间数量增加时，中值往往会增加。当系数接近–1 时，说明有很强的负相关性；当处于较低地位的人口比例上升时，中间值往往会下降。最后，系数接近零意味着没有线性相关性。</p><p id="a297" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">目前，我们将保留所有变量。</p><p id="0e4f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为机器学习准备数据。我们只需要两列—功能和标签(“MV”):</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="e7bb" class="mi lc iq me b gy mj mk l ml mm">from pyspark.ml.feature import VectorAssembler</span><span id="c649" class="mi lc iq me b gy mn mk l ml mm">vectorAssembler = VectorAssembler(inputCols = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PT', 'B', 'LSTAT'], outputCol = 'features')<br/>vhouse_df = vectorAssembler.transform(house_df)<br/>vhouse_df = vhouse_df.select(['features', 'MV'])<br/>vhouse_df.show(3)</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/69081621ea6b5bb16818d9b5845ef265.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*2oZlS8Gmr-5aE7G7Mkye-w.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 3</figcaption></figure><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="c477" class="mi lc iq me b gy mj mk l ml mm">splits = vhouse_df.randomSplit([0.7, 0.3])<br/>train_df = splits[0]<br/>test_df = splits[1]</span></pre><h1 id="50ec" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">线性回归</h1><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="9834" class="mi lc iq me b gy mj mk l ml mm">from pyspark.ml.regression import LinearRegression</span><span id="a161" class="mi lc iq me b gy mn mk l ml mm">lr = LinearRegression(featuresCol = 'features', labelCol='MV', maxIter=10, regParam=0.3, elasticNetParam=0.8)<br/>lr_model = lr.fit(train_df)<br/>print("Coefficients: " + str(lr_model.coefficients))<br/>print("Intercept: " + str(lr_model.intercept))</span></pre><p id="86d0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> <em class="mo">系数:【0.0，0.007302310571175137，-0.03286303124593804，1.413473328268，-7.919323668，5.21692169246</em></strong></p><p id="5c80" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">对训练集的模型进行总结，并打印出一些指标:</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="9062" class="mi lc iq me b gy mj mk l ml mm">trainingSummary = lr_model.summary<br/>print("RMSE: %f" % trainingSummary.rootMeanSquaredError)<br/>print("r2: %f" % trainingSummary.r2)</span></pre><p id="f319" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"><em class="mo">RMSE:4.675914<br/>R2:0.743627</em></strong></p><p id="43b8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">RMSE 测量模型预测值和实际值之间的差异。然而，RMSE 本身是没有意义的，直到我们与实际的“MV”值进行比较，如平均值、最小值和最大值。经过这样的比较，我们的 RMSE 看起来还不错。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="00c8" class="mi lc iq me b gy mj mk l ml mm">train_df.describe().show()</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/8d1202dc0fd12f2d3e4f90cd9d4f7b0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/1*jD1wKExTqGlBZPFfT1hp0Q.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 4</figcaption></figure><p id="bf15" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">r 的平方为 0.74 表明，在我们的模型中，大约 74%的“MV”可变性可以用该模型来解释。这与 Scikit-Learn 的<a class="ae la" rel="noopener" target="_blank" href="/simple-and-multiple-linear-regression-in-python-c928425168f9">结果一致。还不错。然而，我们必须小心，训练集上的性能可能不是测试集上性能的良好近似。</a></p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="1bc8" class="mi lc iq me b gy mj mk l ml mm">lr_predictions = lr_model.transform(test_df)<br/>lr_predictions.select("prediction","MV","features").show(5)</span><span id="e109" class="mi lc iq me b gy mn mk l ml mm">from pyspark.ml.evaluation import RegressionEvaluator<br/>lr_evaluator = RegressionEvaluator(predictionCol="prediction", \<br/>                 labelCol="MV",metricName="r2")<br/>print("R Squared (R2) on test data = %g" % lr_evaluator.evaluate(lr_predictions))</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi my"><img src="../Images/7b4a9ce10f67e4e25fd9350db71cd560.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*cOmCy_2fMBf29JnMJTQsGg.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 5</figcaption></figure><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="4da6" class="mi lc iq me b gy mj mk l ml mm">test_result = lr_model.evaluate(test_df)<br/>print("Root Mean Squared Error (RMSE) on test data = %g" % test_result.rootMeanSquaredError)</span></pre><p id="f999" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> <em class="mo">测试数据的均方根误差(RMSE)= 5.52048</em></strong></p><p id="e55c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">果然，我们在测试集上取得了更差的 RMSE 和 R 平方。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="4ab2" class="mi lc iq me b gy mj mk l ml mm">print("numIterations: %d" % trainingSummary.totalIterations)<br/>print("objectiveHistory: %s" % str(trainingSummary.objectiveHistory))<br/>trainingSummary.residuals.show()</span></pre><p id="26b8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> <em class="mo">操作数:11 <br/>目标历史记录:【0.49999999999956，0.4281126976，069，304，0.22593628，5989，17，0.20326326，5959，582，0.1。546667</em></strong></p><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/1116c0c22e1614369c774a7336c06b88.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*VVLkb1ve4CvpIPGlu4JGwQ.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 6</figcaption></figure><p id="d246" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">使用我们的线性回归模型进行一些预测:</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="4208" class="mi lc iq me b gy mj mk l ml mm">predictions = lr_model.transform(test_df)<br/>predictions.select("prediction","MV","features").show()</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi na"><img src="../Images/9441d29d721087a3d219ba97fc68ee90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*8lbo0VIJe9230zsSAbLhYA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 7</figcaption></figure><h1 id="1ed2" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">决策树回归</h1><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="1033" class="mi lc iq me b gy mj mk l ml mm">from pyspark.ml.regression import DecisionTreeRegressor</span><span id="8d0b" class="mi lc iq me b gy mn mk l ml mm">dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'MV')<br/>dt_model = dt.fit(train_df)<br/>dt_predictions = dt_model.transform(test_df)<br/>dt_evaluator = RegressionEvaluator(<br/>    labelCol="MV", predictionCol="prediction", metricName="rmse")<br/>rmse = dt_evaluator.evaluate(dt_predictions)<br/>print("Root Mean Squared Error (RMSE) on test data = %g" % rmse)</span></pre><p id="726e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> <em class="mo">测试数据上的均方根误差(RMSE)= 4.39053</em></strong></p><p id="da03" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">特征重要性</strong></p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="c833" class="mi lc iq me b gy mj mk l ml mm">dt_model.featureImportances</span></pre><p id="2023" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> <em class="mo"> SparseVector(13，{0: 0.0496，1: 0.0，4: 0.0118，5: 0.624，6: 0.0005，7: 0.1167，8: 0.0044，10: 0.013，12: 0.1799}) </em> </strong></p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="f2fb" class="mi lc iq me b gy mj mk l ml mm">house_df.take(1)</span></pre><p id="928d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"><em class="mo">【Row(CRIM = 0.00632，ZN=18.0，INDUS=2.309999943，CHAS=0，NOX=0.537999988，RM=6.574999809，AGE = 65.19999695，DIS=4.090000153，RAD=1，TAX=296，PT = 15.30000019</em></strong></p><p id="69f5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">显然，在我们的数据中，房间数量是预测房屋中值价格的最重要特征。</p><h1 id="8115" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">梯度推进的树回归</h1><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="5929" class="mi lc iq me b gy mj mk l ml mm">from pyspark.ml.regression import GBTRegressor<br/>gbt = GBTRegressor(featuresCol = 'features', labelCol = 'MV', maxIter=10)<br/>gbt_model = gbt.fit(train_df)<br/>gbt_predictions = gbt_model.transform(test_df)<br/>gbt_predictions.select('prediction', 'MV', 'features').show(5)</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/5dead033e545da60d839b8a4a3194266.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*u9k96-tKkUoHga-D9RqHUw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 8</figcaption></figure><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="dee6" class="mi lc iq me b gy mj mk l ml mm">gbt_evaluator = RegressionEvaluator(<br/>    labelCol="MV", predictionCol="prediction", metricName="rmse")<br/>rmse = gbt_evaluator.evaluate(gbt_predictions)<br/>print("Root Mean Squared Error (RMSE) on test data = %g" % rmse)</span></pre><p id="5e37" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">测试数据的均方根误差(RMSE )= 4.19795</strong></p><p id="4c68" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">梯度推进的树回归在我们的数据上表现最好。</p><p id="f259" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">源代码可以在<a class="ae la" href="https://github.com/susanli2016/PySpark-and-MLlib/blob/master/Linear_regression_house.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。我很高兴听到任何反馈或问题。</p></div></div>    
</body>
</html>