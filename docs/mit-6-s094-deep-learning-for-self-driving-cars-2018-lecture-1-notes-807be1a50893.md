# 麻省理工 6。S094:自动驾驶汽车的深度学习 2018 讲座 1 笔记

> 原文：<https://towardsdatascience.com/mit-6-s094-deep-learning-for-self-driving-cars-2018-lecture-1-notes-807be1a50893?source=collection_archive---------1----------------------->

> [你可以在 Twitter @bhutanisanyam1](http://twitter.com/bhutanisanyam1) 上找到我，在 [Linkedin 上联系我这里](https://www.linkedin.com/in/sanyambhutani/)
> T5 这里和[这里](https://hackernoon.com/a-self-driving-new-year-2-d1bbc5a83570)是我学习自动驾驶汽车的两篇文章
> 
> 如果你想阅读更多的教程/笔记，请查看这篇文章
> 
> [你可以在这里找到降价文件](https://github.com/init27/MIT-6.S094-Deep-Learning-for-Self-Driving-Cars)
> 
> 这些是麻省理工学院第六学期第一课的笔记。S094:自动驾驶汽车的深度学习课程(2018)，由[莱克斯·弗里德曼](https://twitter.com/lexfridman)教授
> 
> [第二讲的笔记可以在这里找到](https://hackernoon.com/mit-6-s094-deep-learning-for-self-driving-cars-2018-lecture-2-notes-e283b9ec10a0)
> [第三讲的笔记可以在这里找到](https://hackernoon.com/mit-6-s094-deep-learning-for-self-driving-cars-2018-lecture-3-notes-deep-reinforcement-learning-fe9a8592e14a)
> [第四讲的笔记可以在这里找到](https://hackernoon.com/mit-6-s094-deep-learning-for-self-driving-cars-2018-lecture-4-notes-computer-vision-f591f14b3b99)
> [第五讲的笔记可以在这里找到](https://medium.com/@init_27/mit-6-s094-deep-learning-for-self-driving-cars-2018-lecture-5-notes-deep-learning-for-human-5cb0f53e4f15)

所有图片均来自讲座幻灯片。

![](img/ded6ac23faf453e10915b995f996ee3f.png)

深度学习:由于研究和 GPU 能力的进步，近年来对人工智能技术很有效的一套技术。SDC 是可以利用这些的系统。

教官们正在研发能够理解车内外环境的汽车。

竞赛:

![](img/d481baa4cafc3170d0c1212add461b63.png)

*   DeepTraffic:深度强化[学习](https://hackernoon.com/tagged/learning)竞赛，代码在浏览器中运行。2.0 版现在允许多代理培训。

![](img/4791471ae967dd08db96bcc0eb5b28a1.png)

*   SegFuse:动态驾驶场景分割比赛。给定原始视频，视频中汽车的运动学(运动)。训练集给了我们地面真实标签、像素级标签、场景分割和光流。目标:在基于图像的分割中表现得比现有技术更好。需求:机器人需要解释、理解和跟踪场景的细节。

![](img/c35e9999d17cb303fb21b2942f40b5ae.png)

*   深度碰撞:目标:使用深度 RL 避免高速碰撞避免。训练:1000 次跑步，训练一个汽车模型以 30 英里每小时以上的速度行驶，并由单目摄像机输入。

![](img/b754833a5c22b66270f3a2aece8959e4.png)

*   DeepTesla:使用大规模网络来训练端到端转向，使用单目视频作为训练的输入。

# 为什么是自动驾驶汽车？

目标:将数据驱动学习方法应用于自动驾驶汽车。

这是个人机器人的最大整合。

*   范围广:道路上有大量的车辆。
*   深刻:汽车和人之间的亲密关系。将你的生命托付给机器人，将控制权“转移”给汽车。该系统的生命临界性质是深刻的，将真正考验该系统的极限。

自主车辆:它是个人机器人，而不是感知控制。在某些情况下，这些系统需要人类通过控制转移来提供帮助。一个真正的感知系统具有与人类同等的动态本质，可能还需要几十年的时间。

![](img/221b98c00d415b3470b748a4847da3bb.png)

认知负荷:一个完全连接的 CNN 接收原始 3D 输入，以分析认知负荷、身体姿势估计和驾驶员的睡意。

辩君:完全自主需要在某些领域达到人类的智能水平。

# 以人为中心的人工智能方法

建议:在每个算法的设计中考虑人的存在。

*   感知控制可以处理 90%的情况。
*   人为控制:在 10%的情况下占主导地位。

![](img/6ebde9bf3dbbb16714ccf4bbaadc3b36.png)

# 为什么要深度学习？

深度学习在处理大量数据时表现非常好。由于人类生活直接依赖于机器，因此需要从真实世界数据中学习的技术。

*   感知/控制侧
*   以人为本的协作和互动。

# 什么是深度学习？

![](img/9ba5171bb797359ce9484c81e80d9fba.png)

人工智能:完成复杂目标的能力。

理解/推理:将复杂信息转化为简单有用信息的能力。

深度学习(表示学习或特征学习)能够获取没有任何意义的原始信息，并能够构建分层表示，以允许产生洞察力。

人工智能中最有能力的一个分支，能够从数据中推导出结构，从而获得洞察力。

# 表征学习

![](img/2c91bca6989ec69676609f41d464d548.png)

*   代表性很重要。地球中心对太阳中心。

![](img/8faa22824a4efbd45014179b1a120902.png)

*   笛卡尔坐标与极坐标区分圆和三角形

![](img/86889dd8b15bbeffdf8a1989b24f3ab9.png)

*   使用一个 1 层隐藏神经网络来分离蓝色和红色曲线。使用深度学习来实现函数的学习(使用原始输入来生成输出)
*   深度学习随着更多的数据而改进。
*   对边缘案例的概括是深度学习的主要挑战。

![](img/cb987521ca27985e1c4d0ee701498c51.png)

# 神经网络。

灵感大致来自人类生物神经元。

*   人类神经网络:1000 亿个神经元，1000 万亿个突触

![](img/d43690f2173c34915f4bac48eb470156.png)

*   最先进的 ResNet-52: 6 千万个突触。
*   差别是 7 个数量级的差别。
*   差异:

1.  人类神经没有堆叠，神经是堆叠的。
2.  无订单与有订单
3.  同步学习与异步学习
4.  未知学习 Vs 反向投影
5.  较慢的处理与较快的处理
6.  功耗更低，效率更低

相似性:两者都是大规模的分布式计算。

一个基本的神经元是简单的，连接单元允许更复杂的用例。

# 神经元:

1.  神经元由一组带权重的边的输入组成
2.  权重成倍增加
3.  增加了一个偏差
4.  非线性函数确定神经网络是否被激活。

## 神经网络的组合:

![](img/350af5a4d7d37b70e74d84d5be7772b8.png)

1.  前馈神经网络:成功的计算机视觉。
2.  轮回 NN:反馈到自身，有记忆。在时间序列相关数据方面取得成功，与人类非常相似(因此更难训练)。

普遍性:多个神经网络可以学习仅用一个隐藏网络层来逼近任何函数*

![](img/afa1f1e2b5d1d0ab4b0ff0060cd39d21.png)

*给出好的算法。

局限性:不在于网络的力量，而在于方法。

# 数字图书馆的类别

![](img/fa4313b6ee0deca19cca45cfce52c759.png)

1.  监督学习:需要人工标注数据。
2.  增强监督学习:人类+机器方法。
3.  半监督的
4.  无监督学习:机器输入。
5.  强化学习:机器输入。

当前正在使用:1，2

未来和更好的类别:3，4，5。

![](img/bd10e43468352c26507e07469de07ad0.png)

# DL 影响空间:

1.  定义和解决一个特殊的问题。例如:波士顿房价估计。
2.  通用智能(或者差不多):强化和无监督学习。

# 监督学习

训练阶段:1。输入数据 2。标签 3。数据训练

测试阶段:1。新数据 2。输入到学习系统 3。出产量

# 学问

![](img/d7a6f13e6b9bf7c197bdcc11068ab410.png)

*   正向传递:输入数据被送入神经网络，并生成预测。
*   反向传播:测量与预期输出的偏差并计算误差，根据误差的大小调整用于预测值的参数(超参数)。

![](img/f6b54f450eb8408785b799746da41100.png)

# 我们能做什么 DL？

![](img/0944bb9a3bcbb8f76d1eb5d9ccca614b.png)

1.  一对一映射。
2.  一对多
3.  多对多。
4.  异步多对多。

# 术语:

*   DL = NN(深度学习=神经网络)。
*   DL 是 ML(机器学习)的子集。
*   MLP:多层感知器。
*   DNN:深度神经网络。
*   RNN:循环神经网络。
*   LSTM:长期短期记忆。
*   CNN:卷积神经网络。
*   DBN:深度信仰网络。

神经网络操作:

*   盘旋
*   联营
*   激活功能
*   反向传播

# 激活功能

![](img/e5bf8797b3b7525b882711ec3ead7133.png)

1.  乙状结肠。缺点:渐变消失，不是零中心
2.  坦。缺点:渐变消失。
3.  雷鲁。缺点:不以零为中心

消失梯度:当神经网络的输出或梯度非常低，导致学习缓慢。

# 反向传播

神经网络的学习过程。目标:更新权重和偏差以减少损失函数。

子任务:

1.  向前传递以计算网络输出和错误。
2.  向后传递以计算梯度。
3.  从权重中减去权重梯度的一部分。

因为这个过程是模块化的，所以它是可并行的。

# 学问

![](img/5f53c844ce38c6e60b6b2f363dba81f2.png)

学习是一个优化的过程。

目标:通过更新权重和偏差来最小化损失函数。

使用的技术:小批量梯度下降和随机梯度下降。

# 学习挑战

*   损失函数是高度非线性的。

![](img/7d5a74673585d2b01b000f27f59bb647.png)

*   消失渐变。

![](img/d2c86381c362b6c56c91b2abb8dc12f3.png)

*   Dying ReLU:对于 0 个输入，导数= 0。

![](img/f8e278122409c56314343b3cd5614b80.png)

*   鞍点。

![](img/7ca3ed5aa422f73797370e61ef4737c7.png)

*   过度拟合:神经网络学习训练数据，但未能很好地推广到现实世界的数据。检测者:低训练误差但高测试误差。

# 正规化:

![](img/03205d21a2fa3b2247412d360e869ef2.png)

有助于归纳的技巧。

*   创建验证集:训练数据的子集
*   早期停止:保存一个检查点并评估神经网络在测试数据上的表现。

![](img/a0997eebc77028c3caa1d8b4831f99c9.png)

Dropout:随机删除一些节点(以及传入和传出节点)

*   用保持一个节点的概率(p)表示
*   输入节点 p 应该高得多。

目标:帮助更好地概括。

# 正则化权重惩罚:

*   L2 惩罚:被惩罚的平方重量:

1.  保持较小的权重，除非误差导数很高。
2.  防止拟合采样误差。
3.  更平滑的模型。
4.  对于两个相似的输入，权重被分配。

![](img/b70d8fbe8e964207c62194c558a0d685.png)

*   L1 处罚:处罚绝对重量:

1.  允许重量保持较大。

[神经网络游乐场:玩技术和练习](http://playground.tensorflow.org/)

# 深度学习突破

# 什么变了？

1.  计算能力增强。
2.  可用的大型有序数据集。
3.  GPU 利用中的算法与研究。
4.  软件和基础设施。
5.  财政支持。

# DL 很难

人类比较:

1.  人类视觉:发展了 5.4 亿年的数据。
2.  两足运动:230，000，000 年的数据。
3.  抽象思维:10 万年的数据。

神经网络:

1.  给像素数据增加失真，导致不正确的预测。
2.  视觉问题:照明度，姿势，遮挡，类内变异。

![](img/fe31b5718adeb5a934c18e6e8ba1d41d.png)![](img/f027c9da4e33cbf35770711e51b557a1.png)![](img/7f6da3d4938c8b4a775d9728d30bf6f7.png)

# 物体识别/分类:

目标:输入图像并预测输出

ImageNet:1400 多万个类别，21.8 万多个类别

竞赛:ILSVRC:

AlexNet (2012)在准确性方面有了显著的提升。

Resnet (2015):人类水平的表现被打败了。

微妙的例子:DL 离“人类概括能力”还很远

相同的架构，许多应用程序:我们可以改变预测层，根据需要对尽可能多的类进行预测。

![](img/086d29347bbf66d6c67d2108231dcd4a.png)

*   图像分类。
*   图像字幕。
*   对象定位。
*   图像分割。

# FCNN:

每个像素被分配一个类，它输入一个图像并产生另一个图像作为输出。

目标:图像到图像的映射。

使用案例:

![](img/e3a2e80c28e048826ff22a1e2317b1e1.png)

*   像素级全场景分割。

![](img/cb85c9586d2e98ed9af5795ad8de018c.png)

*   色彩映射。

![](img/310717a27578a9ced79a4ce6a1da141e.png)

*   物体检测。
*   背景去除。
*   Pix2PixHD:从语义标签地图生成高分辨率的照片级逼真图像。
*   RNN:处理序列

使用案例:

![](img/350df6cc1b49b75c0401413df76064b0.png)

*   手写生成
*   图像标题生成。
*   视频描述生成。
*   注意力转向建模。
*   有选择地注意绘画。

# **重大突破**

![](img/b2b241f2b709f479d950d49d85f0ae84.png)

*   乒乓对乒乓(2012):迈向 AGI 的一步。
*   AlphaGo (2016):从人类专家游戏中学到的
*   AlphaGo Zero (2017):击败 AlphaGo 和 Co，它在没有任何数据的情况下被训练！(它是通过与自己对抗练习而学会的)。
*   DeepStack (2017):首次击败职业扑克玩家(在单挑扑克中)

![](img/f4334e34183fb0fb07825fcc5e556218.png)

# 当前的缺点

*   定义好的奖励函数是困难的。(Coast Runner 的例子)，结果可能会令人惊讶。
*   缺乏鲁棒性:向像素添加噪声会导致错误的预测。

# 当前的挑战:

*   迁移学习:适用于密切相关的领域。挑战:跨领域迁移学习缺失。理性:对理性的理解或获得理解的能力
*   需要大量的数据。
*   需要带注释的数据。
*   不完全自动化:超参数调整
*   奖励:定义一个好的奖励函数是困难的。
*   透明性:神经网络大多是黑盒(即使在我们将引擎盖下的过程可视化之后)。
*   边缘案例:DL 不擅长处理边缘案例。(特别是涉及到自动驾驶的时候)。

# 回复:为什么是 DL？

将技术有效地应用于现实世界的问题是一个机会。(而 DL 在这些方面是最有效的)。

> [你可以在 Twitter @bhutanisanyam1](http://twitter.com/bhutanisanyam1) 上找到我，在 [Linkedin 上联系我这里](https://www.linkedin.com/in/sanyambhutani/)
> [这里](https://becominghuman.ai/a-self-driving-new-year-33284e592f35)和[这里](https://hackernoon.com/a-self-driving-new-year-2-d1bbc5a83570)是我学习自动驾驶汽车的两篇文章
> 
> [订阅我的时事通讯，获取深度学习、计算机视觉文章的每周精选列表](https://tinyletter.com/sanyambhutani)