<html>
<head>
<title>Another Twitter sentiment analysis with Python — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">另一个使用 Python 的 Twitter 情感分析—第 1 部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/another-twitter-sentiment-analysis-bb5b01ebad90?source=collection_archive---------1-----------------------#2017-12-07">https://towardsdatascience.com/another-twitter-sentiment-analysis-bb5b01ebad90?source=collection_archive---------1-----------------------#2017-12-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/77a78996b93869596ea0502c89d2c344.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YKs9I8cGzjxnpWyw"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo by <a class="ae kc" href="https://unsplash.com/@cbpsc1?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Clint Patterson</a> on <a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="3f1d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">距离我上次发帖已经有一段时间了。我不在灵媒期间，我的生活发生了很多事情。我最终鼓起勇气辞去了工作，加入了伦敦大会的数据科学沉浸式课程。</p><p id="e4f7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是我一生中的一个重大决定，但我不后悔。事实上，我认为这是我迄今为止做的最好的决定。这门课程相当紧张，但我很享受其中的每一点。我学到了很多更严谨的数据科学方法，最重要的是，我从导师和同学那里得到的反馈真的帮助我提高了。不容易但是绝对值得！</p><p id="0cd1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我目前在第八周，并为我的顶点项目做准备。正如标题所示，这将是关于 Twitter 的情绪分析。</p><p id="09ff" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">起初，我并不确定我应该为我的顶点做些什么，但毕竟，我感兴趣的领域是自然语言处理，Twitter 似乎是我 NLP 之旅的一个很好的起点。你可以从<a class="ae kc" href="https://prezi.com/view/W1D0h1w5DBQGWJNxEPTu/" rel="noopener ugc nofollow" target="_blank">这里</a>找到我最初的项目创意提案。</p><p id="2eca" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">给你一个关于这个项目的简要总结，它是关于建立一个可以检测情绪的模型，这样我就可以将这个模型应用到来自不同城市的推文中，并比较/分析来自不同城市的推文有多快乐。这是从我自己的好奇心开始的。对我来说，快乐是生活中相当重要的因素，我认为它很大程度上取决于你的环境。所以很自然地，我想看看不同城市的市民有多幸福。</p><h1 id="42b8" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak">训练数据</strong></h1><p id="ceb7" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">可以有许多不同的方法来进行情感分析，一些库提供了开箱即用的情感分析功能，你可以直接在文本上使用，但这并不有趣(是吗？).所以我决定训练我自己的模型，我可以将它应用到我收集的推文中。为了让一个模型有不错的性能，我需要一个相对较大的数据集来训练。用于训练的数据集，我选择的是源自斯坦福大学的“Sentiment140”。关于数据集的更多信息可以从链接中找到。【http://help.sentiment140.com/for-students/ T4】</p><p id="34b2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据集可以从下面的链接下载。<br/><a class="ae kc" href="http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip" rel="noopener ugc nofollow" target="_blank">http://cs . Stanford . edu/people/Alec MgO/training and test data . zip</a></p><p id="a272" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过查看链接中数据集的描述，可以找到每个字段的信息。</p><p id="60c9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">0 —推文的极性(0 =负，2 =中性，4 =正)<br/> 1 —推文的 id(2087)<br/>2—推文的日期(2009 年 5 月 16 日星期六 23:58:44 UTC)<br/>3—查询(lyx)。如果没有查询，那么这个值就是 NO_QUERY。<br/> 4 —发推文的用户(robotickilldozr) <br/> 5 —推文的文本(Lyx 很酷)</p><p id="1129" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好，我们先来看看数据</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="cd61" class="mn lc iq mj b gy mo mp l mq mr">import pandas as pd  <br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>cols = ['sentiment','id','date','query_string','user','text']<br/>df = pd.read_csv("./trainingandtestdata/training.1600000.processed.noemoticon.csv",header=None, names=cols)<br/># above line will be different depending on where you saved your data, and your file name<br/>df.head()</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ms"><img src="../Images/32b4347c153a67f1202eb8f40da97317.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a0vlk438fPQiUuRXPZ1Pow.png"/></div></div></figure><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="2ffe" class="mn lc iq mj b gy mo mp l mq mr">df.sentiment.value_counts()</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mt"><img src="../Images/0307232b827934957420dec9a1546b3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OyxXLInFtoVCcQItdBFiEg.png"/></div></div></figure><p id="5a59" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">数据集有 160 万个条目，没有空条目，重要的是对于“情绪”列，即使数据集描述提到了中性类，训练集也没有中性类。<br/> 50%的数据带有负标签，另外 50%带有正标签。我们可以看到在阶级划分上没有偏斜。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="8458" class="mn lc iq mj b gy mo mp l mq mr">df.drop(['id','date','query_string','user'],axis=1,inplace=True)</span></pre><p id="ba8f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我首先删除了不需要用于情感分析的列。</p><p id="3a8c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">“id”列是每条推文的唯一 ID<br/>“date”列是推文的日期信息<br/>“QUERY _ string”列指示推文是否使用任何特定的查询关键字收集，但是对于该列，100%的条目都具有值“NO _ QUERY”<br/>“user”列是发布推文的用户的 twitter 句柄名称</p><p id="d41f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我决定放弃四列以上。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="854c" class="mn lc iq mj b gy mo mp l mq mr">df[df.sentiment == 0].head(10)</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mu"><img src="../Images/ba1cb0149285ac735e9e8b2b84801d8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vyemxyPkfvYvCDQuBqCKrg.png"/></div></div></figure><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="82ca" class="mn lc iq mj b gy mo mp l mq mr">df[df.sentiment == 4].head(10)</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mv"><img src="../Images/393df48cac463751f0f124e94e47d406.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jv7tnsPe4J0jr3ycRVw5Xg.png"/></div></div></figure><p id="3a5e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过查看每个类的一些条目，似乎所有负类都是从 0 ~ 799999 索引，正类条目从 800000 开始到数据集的末尾。</p><h1 id="b862" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">数据准备</h1><p id="19b3" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">作为健全性检查的一种方式，让我们看看每个条目的文本列中字符串的长度。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="e0d1" class="mn lc iq mj b gy mo mp l mq mr">df['pre_clean_len'] = [len(t) for t in df.text]</span></pre><h1 id="b415" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">数据字典—初稿</h1><p id="bbb1" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">下面是数据集的数据字典的第一稿，但在我准备的过程中，这将需要更新。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="cede" class="mn lc iq mj b gy mo mp l mq mr">from pprint import pprint<br/>data_dict = {<br/>    'sentiment':{<br/>        'type':df.sentiment.dtype,<br/>        'description':'sentiment class - 0:negative, 1:positive'<br/>    },<br/>    'text':{<br/>        'type':df.text.dtype,<br/>        'description':'tweet text'<br/>    },<br/>    'pre_clean_len':{<br/>        'type':df.pre_clean_len.dtype,<br/>        'description':'Length of the tweet before cleaning'<br/>    },<br/>    'dataset_shape':df.shape<br/>}</span><span id="92ab" class="mn lc iq mj b gy mw mp l mq mr">pprint(data_dict)</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/5c1d8d821511b10552e137236d4bb3f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2tAzfVvDbzjtoZR0MZfGTg.png"/></div></div></figure><p id="180a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我还将使用方框图绘制 pre_clean_len，这样我可以看到每个条目中字符串长度的总体分布。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="b11f" class="mn lc iq mj b gy mo mp l mq mr">fig, ax = plt.subplots(figsize=(5, 5))<br/>plt.boxplot(df.pre_clean_len)<br/>plt.show()</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi my"><img src="../Images/2b60293230e8b7f92bb8ea53dbe4a4de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-ZzyJ7OkKfItVbOCz04zVQ.png"/></div></div></figure><p id="0e0d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这看起来有点奇怪，因为 twitter 的字符限制是 140。但是从上面的方框图来看，一些推文的长度远远超过了 140 个字符。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="4b57" class="mn lc iq mj b gy mo mp l mq mr">df[df.pre_clean_len &gt; 140].head(10)</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/95fba1ebd517b025e8c5299b6c29c452.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fGeLZO18aeQtYodh65qEfA.png"/></div></div></figure><p id="f706" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">看起来是时候打扫卫生了！</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi na"><img src="../Images/15400bc63f5dc2302863caff61722aac.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*Xhm9c9qDfXa3ZCQjiOvm_w.jpeg"/></div></figure><h1 id="a093" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">资料准备 1: HTML 解码</h1><p id="f9a9" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">看起来 HTML 编码没有被转换成文本，并以' &amp;amp '，' &amp;quot '等形式出现在文本字段中。将 HTML 解码为一般文本将是我数据准备的第一步。我会用 BeautifulSoup 来做这个。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="b853" class="mn lc iq mj b gy mo mp l mq mr">df.text[279]</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nb"><img src="../Images/e47c88d4ad75dc4e4cf7a39ed569015d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BKzuGkxv-KH8TAzBPEU12Q.png"/></div></div></figure><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="a76c" class="mn lc iq mj b gy mo mp l mq mr">from bs4 import BeautifulSoup<br/>example1 = BeautifulSoup(df.text[279], 'lxml')<br/>print example1.get_text()</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nc"><img src="../Images/a4ad99716d0bc61fc298521bca0d90ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fBCD9LCN_Nes6lHUaNQtOQ.png"/></div></div></figure><h1 id="cb32" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">数据准备 2: '@ '提及</h1><p id="ff5d" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">准备的第二部分是处理@提及。<br/>即使 another 携带了某种信息(该推文提到的另一个用户)，这些信息并没有为建立情感分析模型增加价值。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="7d01" class="mn lc iq mj b gy mo mp l mq mr">df.text[343]</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nd"><img src="../Images/c5deba4a0ee5f4006abcfd7ec1b3d840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RAboO5fQPreWSx0KeXGXqw.png"/></div></div></figure><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="c051" class="mn lc iq mj b gy mo mp l mq mr">import re<br/>re.sub(r'@[A-Za-z0-9]+','',df.text[343])</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ne"><img src="../Images/36059f3f27d4942f65f63240984f7540.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g1HBr-LuxEZuKVXEvsu_oA.png"/></div></div></figure><h1 id="4610" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">数据准备 3: URL 链接</h1><p id="7486" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">清理的第三部分是处理 URL 链接，与@ reference 相同，即使它携带一些信息，出于情感分析的目的，这可以被忽略。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="ef16" class="mn lc iq mj b gy mo mp l mq mr">df.text[0]</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nf"><img src="../Images/21e26aaa425af7895e3721a90c543c33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0sKBXlFrr2YA6a1VQvJ2vw.png"/></div></div></figure><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="26e2" class="mn lc iq mj b gy mo mp l mq mr">re.sub('https?://[A-Za-z0-9./]+','',df.text[0])</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ng"><img src="../Images/cd4733256aafe9e25d4c08fe16e00aae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vWF0U7BI6WvWAXbOxJr2LQ.png"/></div></div></figure><h1 id="d055" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">数据准备 4: UTF-8 BOM(字节顺序标记)</h1><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="091e" class="mn lc iq mj b gy mo mp l mq mr">df.text[226]</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nh"><img src="../Images/68caa30a620103634c3f91740bcc7d91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qVDyluMt7i7bykQaqHJx4g.png"/></div></div></figure><p id="0ae7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过查看上面的条目，我可以看到奇怪的字符模式“\xef\xbf\xbd”。经过一些研究，我发现这些是 UTF-8 炸弹。<br/>“UTF-8 BOM 是一个字节序列(EF BB BF)，它允许读者识别以 UTF-8 编码的文件。”</p><p id="d54c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过用“utf-8-sig”解码文本，这个 BOM 将被替换为 unicode 无法识别的特殊字符，然后我可以将它处理为“？”</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="cc5d" class="mn lc iq mj b gy mo mp l mq mr">testing = df.text[226].decode("utf-8-sig")<br/>testing</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nb"><img src="../Images/06f98d5fd585b1909d6886dc9f1596db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XjHTVKM_tjX3O50FU7ud8A.png"/></div></div></figure><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="5483" class="mn lc iq mj b gy mo mp l mq mr">testing.replace(u"\ufffd", "?")</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ni"><img src="../Images/973a574bff6cd0a83a5cbccd03303e75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T3032in98HDtUeySztdI4w.png"/></div></div></figure><h1 id="bdac" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">数据准备 5:标签/数字</h1><p id="c221" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">有时与 hashtag 一起使用的文本可以提供关于 tweet 的有用信息。将所有文本和标签一起删除可能有点冒险。所以我决定保持文本不变，只去掉“#”。我将在清理包括数字在内的所有非字母字符的过程中这样做。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="3f77" class="mn lc iq mj b gy mo mp l mq mr">df.text[175]</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nj"><img src="../Images/2c4c973b63f554292b861062b51458ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qLY_pRJkcT-Kc2RjkGsabA.png"/></div></div></figure><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="5e37" class="mn lc iq mj b gy mo mp l mq mr">re.sub("[^a-zA-Z]", " ", df.text[175])</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nk"><img src="../Images/9d85ce448f94db2fca7bb108b807c659.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WYfp7I0GZotz2hX7kOfdfg.png"/></div></div></figure><h1 id="01ac" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">定义数据清理功能</h1><p id="e533" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">有了以上五个数据清洗任务，我将首先定义数据清洗函数，然后将应用于整个数据集。当使用计数矢量器或 Tfidf 矢量器创建矩阵时，将在稍后阶段处理标记化、词干化/词元化、停用词。</p><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="a176" class="mn lc iq mj b gy mo mp l mq mr">from nltk.tokenize import WordPunctTokenizer<br/>tok = WordPunctTokenizer()<br/>pat1 = r'@[A-Za-z0-9]+'<br/>pat2 = r'https?://[A-Za-z0-9./]+'<br/>combined_pat = r'|'.join((pat1, pat2))</span><span id="d323" class="mn lc iq mj b gy mw mp l mq mr">def tweet_cleaner(text):<br/>    soup = BeautifulSoup(text, 'lxml')<br/>    souped = soup.get_text()<br/>    stripped = re.sub(combined_pat, '', souped)<br/>    try:<br/>        clean = stripped.decode("utf-8-sig").replace(u"\ufffd", "?")<br/>    except:<br/>        clean = stripped<br/>    letters_only = re.sub("[^a-zA-Z]", " ", clean)<br/>    lower_case = letters_only.lower()<br/>    # During the letters_only process two lines above, it has created unnecessay white spaces,<br/>    # I will tokenize and join together to remove unneccessary white spaces<br/>    words = tok.tokenize(lower_case)<br/>    return (" ".join(words)).strip()</span><span id="acf6" class="mn lc iq mj b gy mw mp l mq mr">testing = df.text[:100]</span><span id="1405" class="mn lc iq mj b gy mw mp l mq mr">test_result = []<br/>for t in testing:<br/>    test_result.append(tweet_cleaner(t))<br/>test_result</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nl"><img src="../Images/ce75ee04fa1f8350244f3a0a8e933fe7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JUoUsmZLSe3SvO-fKsNI9w.png"/></div></div></figure><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="86c9" class="mn lc iq mj b gy mo mp l mq mr">nums = [0,400000,800000,1200000,1600000]<br/>print "Cleaning and parsing the tweets...\n"<br/>clean_tweet_texts = []<br/>for i in xrange(nums[0],nums[1]):<br/>    if( (i+1)%10000 == 0 ):<br/>        print "Tweets %d of %d has been processed" % ( i+1, nums[1] )                                                                    <br/>    clean_tweet_texts.append(tweet_cleaner(df['text'][i]))</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nm"><img src="../Images/42688b169a0137520cfce4de0c5e7982.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*55atiW7013_oFPpGY1HNSg.png"/></div></div></figure><p id="5998" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">剩下的，你明白了，我把整个数据集分成四批，并清理它们。</p><h1 id="db83" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">将清理的数据保存为 csv</h1><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="c5b9" class="mn lc iq mj b gy mo mp l mq mr">clean_df = pd.DataFrame(clean_tweet_texts,columns=['text'])<br/>clean_df['target'] = df.sentiment<br/>clean_df.head()</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nn"><img src="../Images/0bd3cd99b1860398f427096c883ee869.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kPuw--LNMyr2-3kBAeczYg.png"/></div></div></figure><pre class="me mf mg mh gt mi mj mk ml aw mm bi"><span id="9d4d" class="mn lc iq mj b gy mo mp l mq mr">clean_df.to_csv('clean_tweet.csv',encoding='utf-8')<br/>csv = 'clean_tweet.csv'<br/>my_df = pd.read_csv(csv,index_col=0)<br/>my_df.head()</span></pre><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi no"><img src="../Images/ca481e68353968291be2221299c07280.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8IMHNecaQd4e72VRhSvJlw.png"/></div></div></figure><p id="b1ce" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于帖子越来越长，我将在这里停下来，并尝试在下一个帖子继续。如果你有任何问题，或意见，或建议，请不要犹豫留下评论！谢谢你。</p><p id="29ee" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以在 Github repo 下面找到 Jupyter 的笔记本文件。</p><p id="7193" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://github.com/tthustla/twitter_sentiment_analysis_part1/blob/master/Capstone_part2.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/tthustle sa/Twitter _ 情操 _ 分析 _ part 1/blob/master/Capstone _ part 2 . ipynb</a></p></div></div>    
</body>
</html>