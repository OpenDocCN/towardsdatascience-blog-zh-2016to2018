<html>
<head>
<title>Various Implementations of Collaborative Filtering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">协同过滤的各种实现</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/various-implementations-of-collaborative-filtering-100385c6dfe0?source=collection_archive---------0-----------------------#2017-12-28">https://towardsdatascience.com/various-implementations-of-collaborative-filtering-100385c6dfe0?source=collection_archive---------0-----------------------#2017-12-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="3bf6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">利用协同过滤构建推荐系统的不同方法比较</p><p id="e056" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们看到推荐系统在我们周围到处都在使用。这些系统正在个性化我们的网络体验，告诉我们买什么<strong class="jp ir">(亚马逊)</strong><em class="kl"/><strong class="jp ir">【网飞】</strong><strong class="jp ir">【脸书】</strong><em class="kl"/><strong class="jp ir">【Spotify】</strong>等等。这些推荐系统利用我们的购物/观看/收听模式，并根据我们的行为模式预测我们未来可能喜欢的东西。推荐系统最基本的模型是<strong class="jp ir">协同过滤模型</strong>，它基于这样一种假设，即人们喜欢与他们喜欢的其他事物相似的事物，以及被具有相似品味的其他人喜欢的事物。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/80245dcfa695937b047c4509d9a8b97d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6_NlX6CJYhtxzRM-t6ywkQ.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><strong class="bd lc">Figure 1:</strong> Example of collaborative filtering. <em class="ld">Reference: </em><a class="ae le" href="https://d4datascience.wordpress.com/category/predictive-analytics/" rel="noopener ugc nofollow" target="_blank"><em class="ld">here</em></a></figcaption></figure><p id="6cd6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">建立有针对性的推荐模型很容易，那么为什么不为自己的客户建立一个呢？我写这篇文章是为了让你更容易理解。</strong>本帖大部分内容灵感来源于<strong class="jp ir"> fast.ai深度学习part 1 v2课程。</strong></p><p id="0087" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里是笔记本的<a class="ae le" href="https://github.com/groverpr/Machine-Learning/blob/master/notebooks/02_Collaborative_Filtering.ipynb" rel="noopener ugc nofollow" target="_blank">链接，它实现了下面讨论的技术。</a></p><h1 id="ea97" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">介绍</h1><p id="856f" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">在这篇文章中，我讨论并比较了不同的协同过滤算法来预测电影的用户评分。为了进行比较，我使用了<a class="ae le" href="http://files.grouplens.org/datasets/movielens/ml-latest-small.zip" rel="noopener ugc nofollow" target="_blank"> MovieLens数据</a>，它有来自671个独立用户对9066部独立电影的100004个评分。读者可以将这篇文章视为一站式资源，了解如何在python上进行协同过滤，并在自己的数据集上测试不同的技术。 <em class="kl">(我也根据我的分析提供了我自己关于使用哪种技术的建议)。</em></p><p id="a262" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在进一步阅读之前，我希望您对协同过滤及其在推荐系统中的应用有基本的了解。如果没有，我强烈推荐你浏览下面的博客，这些博客是USF大学的一个学生写的:Shikhar Gupta</p><p id="a2d5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">博客:</strong>协同过滤和嵌入— <a class="ae le" href="https://medium.com/@shik1470/collaborative-filtering-and-embeddings-part-1-63b00b9739ce" rel="noopener">第一部分</a>和<a class="ae le" href="https://medium.com/@shik1470/collaborative-filtering-and-embeddings-part-2-919da17ecefb" rel="noopener">第二部分</a></p><h1 id="f01b" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">职位布局</h1><ul class=""><li id="2a20" class="mi mj iq jp b jq md ju me jy mk kc ml kg mm kk mn mo mp mq bi translated"><strong class="jp ir">协同过滤技术的类型<br/>基于记忆的<br/>基于模型的<br/> </strong> *矩阵分解<br/> *聚类<br/> <strong class="jp ir"> * </strong>深度学习</li><li id="545d" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated"><strong class="jp ir"> Python实现<br/>T11】惊喜包<br/>fast . ai库</strong></li><li id="2740" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated"><strong class="jp ir">比较和结论</strong></li></ul><h1 id="2b77" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated"><strong class="ak">协同过滤技术的类型</strong></h1><p id="5848" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">关于协同过滤(CF)已经做了很多研究，最流行的方法是基于<strong class="jp ir">低维因子模型</strong>(基于模型的矩阵分解。这些我会详细讨论)。CF技术大致分为两种类型:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi mw"><img src="../Images/0c4296fc1cc33d44cc29c5563c2fee03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7uW5hLXztSu_FOmZOWpB6g.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><strong class="bd lc">Figure 2:</strong> Types of collaborative filtering approaches. <em class="ld">Reference: </em><a class="ae le" href="https://en.wikipedia.org/wiki/Collaborative_filtering" rel="noopener ugc nofollow" target="_blank"><em class="ld">Wikipedia</em></a></figcaption></figure><p id="dbf8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">假设我们想向我们的产品用户推荐一件新商品(例如，向网飞的订户推荐一部电影，或者向亚马逊的在线买家推荐一件衣服)<em class="kl">。为此，我们可以使用下面讨论的许多技术中的一种。</em></p><h2 id="9206" class="mx lg iq bd lh my mz dn ll na nb dp lp jy nc nd lt kc ne nf lx kg ng nh mb ni bi translated"><strong class="ak"> 1。基于记忆的方法:</strong></h2><p id="50d8" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">Agnes Johannsdottir在她的<a class="ae le" href="https://cambridgespark.com/content/tutorials/implementing-your-own-recommender-systems-in-Python/index.html" rel="noopener ugc nofollow" target="_blank">博客</a>中引用</p><blockquote class="nj nk nl"><p id="ce0a" class="jn jo kl jp b jq jr js jt ju jv jw jx nm jz ka kb nn kd ke kf no kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="iq">基于记忆的协同过滤</em> </strong> <em class="iq">方法可以分为两个主要部分:</em> <strong class="jp ir"> <em class="iq"> </em> </strong> <em class="iq">用户-项目过滤和项目-项目过滤。一个</em> <strong class="jp ir"> <em class="iq">用户项目过滤</em> </strong> <em class="iq">取一个特定的用户，基于评分的相似性找到与该用户相似的用户，并推荐那些相似用户喜欢的项目。相比之下，</em> <strong class="jp ir"> <em class="iq">物品-物品过滤</em> </strong> <em class="iq">会取一个物品，找到喜欢过那个物品的用户，再找到那些用户或者类似用户也喜欢过的其他物品。它接受项目并输出其他项目作为推荐。</em></p><p id="4c7a" class="jn jo kl jp b jq jr js jt ju jv jw jx nm jz ka kb nn kd ke kf no kh ki kj kk ij bi translated"><em class="iq">物品-物品协同过滤:“喜欢这个物品的用户也喜欢……”<br/>用户-物品协同过滤:“和你相似的用户也喜欢……”</em></p></blockquote><p id="b0f8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基于记忆的方法与基于模型的技术<em class="kl">(等等，将在下一段讨论)</em>的关键区别在于，我们没有使用梯度下降(或任何其他优化算法)来学习任何参数。最近的用户或项目仅通过使用<strong class="jp ir">余弦相似度或皮尔逊相关系数</strong>来计算，它们仅基于算术运算。<br/> <strong class="jp ir">编辑:</strong>如上一段所述，不使用参数化机器学习方法的技术被归类为基于记忆的技术。因此，<strong class="jp ir">像KNN </strong>这样的非参数ML方法也应该属于基于记忆的方法。当我最初写这篇博客的时候，我用的是基于模型的方法，这是不对的。</p><p id="54e4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">引用于<a class="ae le" href="http://blog.ethanrosenthal.com/2015/11/02/intro-to-collaborative-filtering/" rel="noopener ugc nofollow" target="_blank">这篇</a>博客</p><blockquote class="nj nk nl"><p id="38dd" class="jn jo kl jp b jq jr js jt ju jv jw jx nm jz ka kb nn kd ke kf no kh ki kj kk ij bi translated"><em class="iq">一个常见的距离度量是</em> <strong class="jp ir"> <em class="iq">余弦相似度</em> </strong> <em class="iq">。如果将评级矩阵中给定用户(项目)的行(列)视为一个向量，则可以从几何角度考虑该指标。对于基于用户的协同过滤，两个用户的相似性被度量为两个用户的向量</em>  <em class="iq">之间的角度的</em> <strong class="jp ir"> <em class="iq">余弦。对于用户u和u’，余弦相似度为:</em></strong></p></blockquote><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi np"><img src="../Images/e121dbb5dc6c0d3afbb09da63606b4e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*73viZlaDodVK3_zBpvjy_g.png"/></div></div></figure><p id="5b93" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以通过取来自所有其他用户(u)的电影1评级的加权和来预测用户u对电影1的评级，其中加权是每个用户和用户u之间的相似性数</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/d49e6782b487034ecc1c77f8604d6608.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*p6BUZ6NT9QTVPebgk47ZwQ.png"/></div></figure><p id="1eb2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还应该通过u’(其他用户的)评级总数来标准化评级。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nr"><img src="../Images/d4f666395e70c732c28167ee241502d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*ksRXKDGtrvmerQ0H5s1cmg.png"/></div></figure><p id="0647" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">关于基于记忆的方法的最后一句话:</strong>由于不涉及训练或优化，这是一种易于使用的方法。但是当我们有稀疏的数据时，它的性能会下降，这阻碍了这种方法对于大多数现实世界问题的可伸缩性。</p><p id="8f5e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您有兴趣尝试这种方法，下面是展示python一步一步实现这种方法的精彩文章的链接。<br/> <em class="kl">(我没有在这里讨论实现，因为我个人会使用可扩展的基于模型的方法)</em></p><blockquote class="nj nk nl"><p id="7147" class="jn jo kl jp b jq jr js jt ju jv jw jx nm jz ka kb nn kd ke kf no kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="iq">链接1:</em></strong><em class="iq"/><a class="ae le" href="https://cambridgespark.com/content/tutorials/implementing-your-own-recommender-systems-in-Python/index.html" rel="noopener ugc nofollow" target="_blank"><em class="iq">用Python实现自己的推荐系统</em></a><em class="iq"><br/></em><strong class="jp ir"><em class="iq">链接2:</em></strong><em class="iq"/><a class="ae le" href="http://blog.ethanrosenthal.com/2015/11/02/intro-to-collaborative-filtering/" rel="noopener ugc nofollow" target="_blank"><em class="iq">推荐系统简介:协同过滤</em> </a></p></blockquote><h2 id="559d" class="mx lg iq bd lh my mz dn ll na nb dp lp jy nc nd lt kc ne nf lx kg ng nh mb ni bi translated"><strong class="ak"> 2。基于模型的方法</strong></h2><p id="8589" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">在这种方法中，使用机器学习算法来开发CF模型，以预测用户对未评级项目的评级。根据我的理解，这种方法中的算法可以进一步细分为3个子类型。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi ns"><img src="../Images/ab5544fb4cc298c90a684c0ca60fef0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0vyDJr3urOA6uy-39cr91g.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><strong class="bd lc">Figure 3. </strong>Types of model based collaborative filtering approaches</figcaption></figure><p id="873e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">编辑:</strong>组<strong class="jp ir">T5】名称<strong class="jp ir">基于上图的“基于聚类的算法</strong>有误。它没有生成集群。我们只是在KNN找到k个最接近的训练例子。“<strong class="jp ir">非参数方法</strong>”是更好的术语。</strong></p><h2 id="4340" class="mx lg iq bd lh my mz dn ll na nb dp lp jy nc nd lt kc ne nf lx kg ng nh mb ni bi translated"><strong class="ak">上述算法的简要说明:</strong></h2><ul class=""><li id="97da" class="mi mj iq jp b jq md ju me jy mk kc ml kg mm kk mn mo mp mq bi translated"><strong class="jp ir">矩阵分解(MF): </strong>这种模型背后的思想是，用户的态度或偏好可以由少量的隐藏因素来决定。我们可以称这些因素为<strong class="jp ir">嵌入。</strong></li></ul><blockquote class="nj nk nl"><p id="f6a3" class="jn jo kl jp b jq jr js jt ju jv jw jx nm jz ka kb nn kd ke kf no kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="iq">矩阵分解可以转化为一个带有损失函数和约束的优化问题。</em> </strong> <em class="iq">现在，约束是基于我们模型的属性来选择的。例如，对于非负矩阵分解，我们希望结果矩阵中有非负元素。</em></p></blockquote><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nt"><img src="../Images/732001430c61fb6211892ad6b6547174.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2i-GJO7JX0Yz6498jUvhEg.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><strong class="bd lc">Figure 4.</strong> Visualization of matrix factorization</figcaption></figure><p id="50b8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">嵌入:<br/>直观上，我们可以把嵌入理解为物品和用户的低维隐藏因素</strong>。例如，假设我们有5维<strong class="jp ir">(即上图<strong class="jp ir">中的D或n _ factors = 5</strong>)</strong>项目和用户的嵌入(随机选择# 5)。那么对于user-X &amp; movie-A，我们可以说这5个数字<strong class="jp ir">可能</strong>代表关于电影的5个不同特征，比如<em class="kl"/><strong class="jp ir"><em class="kl">【I】</em></strong><em class="kl">movie-A有多科幻</em><strong class="jp ir"><em class="kl">【ii)</em></strong><em class="kl">电影</em><strong class="jp ir"><em class="kl">【iii】</em></strong><em class="kl">有多新同样，用户嵌入矩阵中的5个数字可能表示，</em><strong class="jp ir"><em class="kl">(I)</em></strong><em class="kl">user-X有多喜欢科幻电影</em><strong class="jp ir"><em class="kl">(ii)</em></strong><em class="kl">user-X有多喜欢最近的电影……等等。</em>在上图中，user-X和movie-A矩阵的点积数值越大，意味着movie-A是user-X的好推荐。</p><p id="46c4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(我并不是说这些数字实际上代表了这样的信息。我们实际上不知道这些因素意味着什么。这只是建立一种直觉)</p><p id="ba8e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在USF大学的另一位同学Kerem Turgutlu的这篇博文中，可以了解更多关于嵌入的知识。<br/> <strong class="jp ir">链接:</strong>T3】结构化深度学习</p><p id="3d13" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">矩阵分解可以通过各种方法完成，并且有一些研究论文。在下一节中，将介绍正交分解(SVD)或概率分解(PMF)或非负分解(NMF)的python实现。</p><ul class=""><li id="32c3" class="mi mj iq jp b jq jr ju jv jy nu kc nv kg nw kk mn mo mp mq bi translated"><strong class="jp ir">非参数方法(KNN): </strong>这个想法和基于记忆的推荐系统是一样的。在基于内存的算法中，我们使用用户和/或项目之间的相似性，并将它们用作<strong class="jp ir">权重</strong>来预测用户和项目的评分。不同之处在于，这种方法中的相似性是基于无监督学习模型计算的，而不是基于皮尔逊相关或余弦相似性。在这种方法中，我们还将相似用户的数量限制为<strong class="jp ir"> k </strong>，这使得系统更具可扩展性。</li><li id="a58a" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated"><strong class="jp ir">神经网络/深度学习:</strong>有大量关于使用矩阵分解或相似矩阵的协同过滤的研究材料。但是缺乏在线材料来学习如何使用深度学习模型进行协同过滤。<strong class="jp ir">这是我在fast.ai深度学习part 1 v2中学到的东西。</strong></li></ul><p id="a69d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是解释当我们使用神经网络解决这个问题时会发生什么的可视化。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nx"><img src="../Images/299e80587b621ba338a134c408166de5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8416fX2CmKvHpTsR2A7MBg.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><strong class="bd lc">Figure 5.</strong> Matrix factorization and embeddings for neural net</figcaption></figure><p id="9a12" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以把这看作是矩阵分解方法的扩展。对于SVD或PCA，我们将原始稀疏矩阵分解成2个低秩正交矩阵的乘积。对于神经网络实现，我们不需要它们是正交的，我们希望我们的模型学习嵌入矩阵本身的值。对于特定的电影-用户组合，从嵌入矩阵中查找<strong class="jp ir">用户潜在特征</strong>和<strong class="jp ir">电影潜在特征</strong>。这些是进一步线性和非线性图层的输入值。我们可以将此输入传递给多个<strong class="jp ir"> relu、线性或sigmoid层</strong>并通过任何优化算法(Adam、SGD等)学习相应的权重。).</p><p id="b43c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi">___________________________________________________________________</p><h1 id="4e63" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated"><strong class="ak"> Python实现</strong></h1><p id="b8b5" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated"><strong class="jp ir"> Github回购链接:</strong> <a class="ae le" href="https://github.com/groverpr/Machine-Learning/blob/master/notebooks/02_Collaborative_Filtering.ipynb" rel="noopener ugc nofollow" target="_blank">此处</a></p><p id="643d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们看看上面讨论的<strong class="jp ir">算法的python实现。我研究了2个不同的python包，它们提供了各种算法供选择。</strong></p><h2 id="06cc" class="mx lg iq bd lh my mz dn ll na nb dp lp jy nc nd lt kc ne nf lx kg ng nh mb ni bi translated"><strong class="ak">(一)</strong> <a class="ae le" href="http://surprise.readthedocs.io/en/stable/getting_started.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">惊喜套餐</strong> </a> <strong class="ak"> : </strong></h2><p id="b0d3" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">这个软件包是专门开发来使基于协同过滤的推荐变得容易的。它有各种CF算法的默认实现。</p><blockquote class="nj nk nl"><p id="e7bd" class="jn jo kl jp b jq jr js jt ju jv jw jx nm jz ka kb nn kd ke kf no kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="iq">第一步:</em> </strong> <em class="iq">下载MovieLens数据并在熊猫df</em><a class="ae le" href="http://files.grouplens.org/datasets/movielens/ml-latest-small.zip" rel="noopener ugc nofollow" target="_blank"><em class="iq">http://files . group lens . org/datasets/movie lens/ml-latest-small . zip</em></a>中读取</p><p id="3289" class="jn jo kl jp b jq jr js jt ju jv jw jx nm jz ka kb nn kd ke kf no kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="iq">第二步:</em> </strong> <em class="iq">安装惊喜包通过</em> <code class="fe ny nz oa ob b">pip install scikit-surprise.</code> <em class="iq">加载数据到</em> <code class="fe ny nz oa ob b"><em class="iq">Dataset class</em></code></p></blockquote><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="oc od l"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><strong class="ak">Code chunk 1. </strong>Surprise dataloader</figcaption></figure><blockquote class="nj nk nl"><p id="053b" class="jn jo kl jp b jq jr js jt ju jv jw jx nm jz ka kb nn kd ke kf no kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="iq">第三步:</em> </strong> <em class="iq">现在在数据准备后实现任何MF算法都是运行1行代码那么简单。下面是奇异值分解(SVD)和非负矩阵分解(NMF)的代码和输出。该代码也可用于KNN，只需更改以下代码中的</em> <code class="fe ny nz oa ob b"><em class="iq">algo = KNNBasic()</em></code> <em class="iq">。(请查看维基百科上</em><a class="ae le" href="https://en.wikipedia.org/wiki/Singular-value_decomposition" rel="noopener ugc nofollow" target="_blank"><em class="iq">SVD</em></a><em class="iq">和</em><a class="ae le" href="https://en.wikipedia.org/wiki/Non-negative_matrix_factorization" rel="noopener ugc nofollow" target="_blank"><em class="iq">NMF</em></a><em class="iq">)</em></p></blockquote><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="oc od l"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><strong class="ak">Code chunk 2. </strong>SVD and NMF using Surprise</figcaption></figure><p id="8995" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">验证奇异值分解和NMF的RMSE分数</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi oe"><img src="../Images/ede4404aaa14ec477d5f90d05804933e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1SppxSmtTF2PKgQJ0eGPbw.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><strong class="bd lc">Figure 6.</strong> RMSE scores of SVD and NMF using Surprise</figcaption></figure><p id="e813" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">最佳RMSE = 0.8967 (SVD)，对应的均方误差为0.804 </strong></p><h2 id="3f8f" class="mx lg iq bd lh my mz dn ll na nb dp lp jy nc nd lt kc ne nf lx kg ng nh mb ni bi translated"><strong class="ak"> (b) </strong> <a class="ae le" href="https://github.com/fastai/fastai" rel="noopener ugc nofollow" target="_blank"> <strong class="ak"> fast.ai库</strong> </a> <strong class="ak"> : </strong></h2><p id="55cb" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">fast.ai是一个庞大的python库，它使具有基本编码技能的人可以轻松进行机器学习和深度学习。</p><h2 id="634c" class="mx lg iq bd lh my mz dn ll na nb dp lp jy nc nd lt kc ne nf lx kg ng nh mb ni bi translated"><strong class="ak">浅薄的学问</strong></h2><p id="7965" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">下面是为CF实现<strong class="jp ir">概率矩阵分解</strong>的5行代码。该实现利用了这样一个事实，即2个分解的矩阵只是嵌入矩阵，可以通过在神经网络中添加嵌入层来建模(我们可以称之为<strong class="jp ir">浅层学习</strong>)。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="oc od l"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><strong class="ak">Code chunk 3. </strong>Collaborative filtering using fast.ai (based on concept of PMF)</figcaption></figure><p id="ede8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">培训结果:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi of"><img src="../Images/c84b99f0defbb985961ed306ec70fe7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*NBVcRD7jriMipOX8Vu5hzQ.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><strong class="bd lc">Figure 7. </strong>Left: Training MSE, Right: Validation MSE. Rows: Epochs</figcaption></figure><p id="9938" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从PMF的fast.ai实现获得的最佳验证MSE是0.801，这接近于我们从SVD获得的结果。</p><h2 id="0dab" class="mx lg iq bd lh my mz dn ll na nb dp lp jy nc nd lt kc ne nf lx kg ng nh mb ni bi translated"><strong class="ak">深度学习</strong></h2><p id="48d8" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">我们可以向我们的神经网络添加更多的线性和非线性层，使其成为深度神经网络模型。</p><p id="5751" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用fast.ai制作用于协同过滤的深度神经网络的步骤</p><blockquote class="nj nk nl"><p id="f2fc" class="jn jo kl jp b jq jr js jt ju jv jw jx nm jz ka kb nn kd ke kf no kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="iq">第一步:</em> </strong> <em class="iq">加载数据到PyTorch数据加载器。fast.ai库建立在PyTorch之上。如果你想为特定格式的数据定制数据集类，在这里</em>  <em class="iq">学习</em> <a class="ae le" href="http://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class" rel="noopener ugc nofollow" target="_blank"> <em class="iq">。</em></a></p></blockquote><p id="7db6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我用了fast.ai的<code class="fe ny nz oa ob b">ColumnarModelData.from_data_frame</code>函数加载数据集。您还可以定义自己的数据加载器函数。<strong class="jp ir"> X </strong>具有关于<strong class="jp ir">用户Id、电影Id和时间戳</strong>的数据，而<strong class="jp ir"> Y </strong>仅具有关于<strong class="jp ir">收视率(目标变量)的数据。</strong></p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="oc od l"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><strong class="ak">Code chunk 4. </strong>Data-loader (fast.ai function)</figcaption></figure><blockquote class="nj nk nl"><p id="a100" class="jn jo kl jp b jq jr js jt ju jv jw jx nm jz ka kb nn kd ke kf no kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="iq">步骤2: </em> </strong> <em class="iq">定义自定义神经网络类(语法特定于PyTorch，但相同的逻辑也可用于Keras)。</em></p></blockquote><p id="90de" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们必须创建两个函数。<em class="kl"> </em> <strong class="jp ir"> __init__()，</strong>该类的构造函数为<strong class="jp ir"> </strong>和<strong class="jp ir"> forward()，</strong>该函数向前传递。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="oc od l"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><strong class="ak">Code chunk 5. </strong>Neural net on PyTorch</figcaption></figure><p id="91c3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">关于<strong class="jp ir">层</strong>的更多信息，这些层已经在正向通道中使用:</p><ul class=""><li id="e954" class="mi mj iq jp b jq jr ju jv jy nu kc nv kg nw kk mn mo mp mq bi translated"><code class="fe ny nz oa ob b">dropout</code>该层将删除具有给定概率参数的激活。激活有p1，p2概率变为0。这样做是为了减少过度拟合。</li><li id="ef4c" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated"><code class="fe ny nz oa ob b">embedding</code>该层为对应于唯一用户和唯一电影的嵌入创建查找表。该层中的值通过反向传播来更新。</li><li id="2036" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated"><code class="fe ny nz oa ob b">linear</code>加偏的线性矩阵乘法。</li><li id="e4db" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated"><code class="fe ny nz oa ob b">relu</code>使用非线性图层。</li><li id="ea82" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated"><code class="fe ny nz oa ob b">sigmoid</code>用于限制来自训练数据的预测评级b/w最小值和最大值。</li></ul><blockquote class="nj nk nl"><p id="9832" class="jn jo kl jp b jq jr js jt ju jv jw jx nm jz ka kb nn kd ke kf no kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="iq">第三步:</em> </strong> <em class="iq">模型拟合和预测。</em></p></blockquote><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="oc od l"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><strong class="ak">Code chunk 6. </strong>Training deep neural net (fast.ai functions)</figcaption></figure><p id="68f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">结果:</strong></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi og"><img src="../Images/5b3d36d28e1d2a1e27af7674a5714c68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*Z35VBYHc2ADsXXP9rWMPKA.png"/></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><strong class="bd lc">Figure 8. </strong>Left: Training MSE, Right: Validation MSE. Rows: Epochs</figcaption></figure><p id="ba65" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">最佳验证MSE = 0.7906。这是上面讨论的所有模型中最好的。</strong></p><h1 id="27f9" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated"><strong class="ak">比较和结论</strong></h1><p id="f13b" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">下面是从MovieLens 100k数据的不同方法获得的MSE图。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi oh"><img src="../Images/49ebfff651dab8652d8d1809ac83d83d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m3RBt1jz_ygwTNDv1cAJQw.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><strong class="bd lc">Figure 9. </strong>Comparison of MSE scores using different CF methods</figcaption></figure><p id="12dd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">神经网络(DL)和奇异值分解给出了最好的结果。与其他MF算法不同，神经网络实现也将在不经常使用的不平衡数据上表现良好。</p><p id="1337" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为你的产品/服务建立客户目标推荐系统是很有用的。最简单和研究充分的方法是协同过滤。我写这篇文章的目的是，读者可以在一个地方找到所有有用的资料，以及实现，而不是浏览技术研究论文和花费几个小时来学习协同过滤。</p><h1 id="0f1b" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated"><strong class="ak">参考资料和其他有用资源:</strong></h1><ol class=""><li id="b38a" class="mi mj iq jp b jq md ju me jy mk kc ml kg mm kk oi mo mp mq bi translated"><a class="ae le" href="https://github.com/groverpr/Machine-Learning/blob/master/notebooks/02_Collaborative_Filtering.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">我的GitHub回购链接与python实现</strong> </a></li><li id="259b" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk oi mo mp mq bi translated"><a class="ae le" href="http://www.cs.carleton.edu/cs_comps/0607/recommend/recommender/itembased.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">推荐系统</strong> </a></li><li id="96ac" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk oi mo mp mq bi translated"><a class="ae le" href="https://github.com/fastai/fastai/blob/master/courses/dl1/lesson5-movielens.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">协同过滤使用Fast.ai </strong> </a></li><li id="132e" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk oi mo mp mq bi translated"><a class="ae le" href="http://surprise.readthedocs.io/en/stable/getting_started.html#basic-usage" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">惊喜:用于推荐系统的Python scikit</strong></a></li><li id="a446" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk oi mo mp mq bi translated"><strong class="jp ir">协同过滤和嵌入—第一部分和第二部分<br/></strong>【https://medium.com/@shik1470/63b00b9739ce】T21<br/>T24】https://medium.com/@shik1470/919da17ecefb</li><li id="def4" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk oi mo mp mq bi translated"><a class="ae le" href="https://lazyprogrammer.me/tutorial-on-collaborative-filtering-and-matrix-factorization-in-python/" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir">Python中的协同过滤和矩阵分解教程</strong> </a></li><li id="42d7" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk oi mo mp mq bi translated"><strong class="jp ir">研究论文<br/></strong><a class="ae le" href="http://www.sciencedirect.com/science/article/pii/S1877050915007462" rel="noopener ugc nofollow" target="_blank">http://www . science direct . com/science/article/pii/s 1877050915007462</a><br/><a class="ae le" href="https://www.cs.toronto.edu/~amnih/papers/pmf.pdf" rel="noopener ugc nofollow" target="_blank">https://www.cs.toronto.edu/~amnih/papers/pmf.pdf</a></li></ol></div></div>    
</body>
</html>