<html>
<head>
<title>Mastering Deep Reinforcement Learning with OpenAI’s new ‘Spinning Up in Deep RL’ package</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 OpenAI 的新“在深度 RL 中旋转”包掌握深度强化学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/mastering-deep-reinforcement-learning-with-openais-new-spinning-up-in-deep-rl-package-b86b61ab6e54?source=collection_archive---------8-----------------------#2018-11-11">https://towardsdatascience.com/mastering-deep-reinforcement-learning-with-openais-new-spinning-up-in-deep-rl-package-b86b61ab6e54?source=collection_archive---------8-----------------------#2018-11-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/5f1c22885697b6ab96b85f9991f9e766.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2NuFPwyblr2JCDkFkD7fKQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">OpenAI Five</figcaption></figure><p id="f9eb" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><a class="ae la" href="https://en.wikipedia.org/wiki/Reinforcement_learning" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ir"> <em class="lb">强化学习</em> </strong> </a>是一种机器学习方法，用于教会智能体如何通过试错来解决任务。<strong class="ke ir"> <em class="lb">深度</em> </strong> <em class="lb"> </em> <strong class="ke ir"> <em class="lb">强化学习</em> </strong>是指强化学习与深度学习的结合。</p><p id="98da" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><a class="ae la" href="https://twitter.com/OpenAI" rel="noopener ugc nofollow" target="_blank"><strong class="ke ir"><em class="lb">open ai</em></strong></a>于 2018 年 11 月 8 日<em class="lb">在 Deep RL </em>  发布了他们的深度强化学习教育包<a class="ae la" href="https://blog.openai.com/spinning-up-in-deep-rl/" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ir"> <em class="lb">。他们的发布声明似乎对我很有吸引力，其中写道:</em></strong></a></p><p id="d57c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><em class="lb">“在</em><a class="ae la" href="https://twitter.com/OpenAI" rel="noopener ugc nofollow" target="_blank"><em class="lb">open AI</em></a><em class="lb">上，我们相信深度学习总体上——特别是深度强化学习——将在强大的人工智能技术的发展中发挥核心作用。虽然有许多资源可以让人们快速进入深度学习，但深度强化学习更具挑战性。我们设计了 Spinning Up 来帮助人们学习使用这些技术，并发展对它们的直觉。我们还看到，在 RL 中胜任可以帮助人们参与跨学科的研究领域，如</em><a class="ae la" href="https://blog.openai.com/concrete-ai-safety-problems/" rel="noopener ugc nofollow" target="_blank"><em class="lb">【AI 安全</em> </a> <em class="lb">，这涉及强化学习和其他技能的混合。很多人向我们寻求从头开始学习 RL 的指导，因此我们决定将我们提供的非正式建议正式化。”</em></p><figure class="ld le lf lg gt jr gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/4bd9e39c27495b396374a2c0e8b5690d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*hXqjSvWQ2OXjeqPalvGX7w.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Release tweet by OpenAI.</figcaption></figure><p id="b6f2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">因此，我决定快速浏览整个包，这里有一个简短的游览和对那些希望浏览完整包的人的一点建议。</p></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><h1 id="4602" class="lo lp iq bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">到底什么是'<strong class="ak">在深 RL 中向上旋转'</strong>？</h1><blockquote class="mm mn mo"><p id="f0eb" class="kc kd lb ke b kf kg kh ki kj kk kl km mp ko kp kq mq ks kt ku mr kw kx ky kz ij bi translated">“我们观察到，如果为他们提供正确的指导和资源，对机器学习经验很少或没有经验的人来说，快速成为实践者是可能的。Deep RL 中的 Spinning Up 正是基于这一需求而构建的。”</p></blockquote><p id="21e3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在深 RL 包装中旋转的<em class="lb">整体包括:</em></p><h2 id="0eeb" class="ms lp iq bd lq mt mu dn lu mv mw dp ly kn mx my mc kr mz na mg kv nb nc mk nd bi translated">RL 简介:</h2><p id="bf28" class="pw-post-body-paragraph kc kd iq ke b kf ne kh ki kj nf kl km kn ng kp kq kr nh kt ku kv ni kx ky kz ij bi translated">用短视频和适度详细的短笔记简单介绍强化学习。涵盖的主题有 RL  、<strong class="ke ir"> <em class="lb"> RL 算法</em> </strong>和<strong class="ke ir"> <em class="lb">中的<strong class="ke ir"/></em></strong><em class="lb"/><strong class="ke ir"><em class="lb">概念【策略优化简介</em> </strong>。</p><p id="33e2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我发现对于初学者来说，整个学习材料有点难以理解。关于强化学习基础知识有什么疑问，可以随时参考大卫·西尔弗的 RL <a class="ae la" href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ir">课程</strong> </a> <strong class="ke ir"> </strong>和讲座系列。</p><figure class="ld le lf lg gt jr"><div class="bz fp l di"><div class="nj nk l"/></div></figure><h2 id="919f" class="ms lp iq bd lq mt mu dn lu mv mw dp ly kn mx my mc kr mz na mg kv nb nc mk nd bi translated">Deep-RL 研究论文:</h2><p id="186f" class="pw-post-body-paragraph kc kd iq ke b kf ne kh ki kj nf kl km kn ng kp kq kr nh kt ku kv ni kx ky kz ij bi translated">这一领域的一些顶级研究论文是按主题排列的，进一步分为子主题。论文的整体安排是按照一个非常合适的顺序进行的，任何初学者都可以一篇接一篇地轻松阅读。</p><h2 id="cb96" class="ms lp iq bd lq mt mu dn lu mv mw dp ly kn mx my mc kr mz na mg kv nb nc mk nd bi translated">算法:</h2><p id="848c" class="pw-post-body-paragraph kc kd iq ke b kf ne kh ki kj nf kl km kn ng kp kq kr nh kt ku kv ni kx ky kz ij bi translated">一些顶级算法，如普通策略梯度和深度确定性策略梯度，已经在这个包中实现并准备使用。它们都是用 MLP(非递归)演员-评论家实现的，使它们适合于完全观察的、非基于图像的 RL 环境。这些算法的完整文档可以在<a class="ae la" href="https://spinningup.openai.com/en/latest/user/algorithms.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ir">这里</strong> </a>找到。</p><h2 id="ba1c" class="ms lp iq bd lq mt mu dn lu mv mw dp ly kn mx my mc kr mz na mg kv nb nc mk nd bi translated">实验和环境:</h2><p id="58be" class="pw-post-body-paragraph kc kd iq ke b kf ne kh ki kj nf kl km kn ng kp kq kr nh kt ku kv ni kx ky kz ij bi translated">各种实验和 OpenAI 环境都包含在这个包中。还为超参数调谐提供了一个实验网格。整个实验和环境的交互大部分可以通过命令行(Shell)来控制。</p><h2 id="49d1" class="ms lp iq bd lq mt mu dn lu mv mw dp ly kn mx my mc kr mz na mg kv nb nc mk nd bi translated">练习:</h2><p id="a7d9" class="pw-post-body-paragraph kc kd iq ke b kf ne kh ki kj nf kl km kn ng kp kq kr nh kt ku kv ni kx ky kz ij bi translated">一旦你完成了教材中面向学习的内容，最后会有几个<em class="lb">问题集</em>来测试你的技能。值得注意的是，还有一个为 OpenAI 的长期研究请求做贡献的选项。</p><h2 id="5c7b" class="ms lp iq bd lq mt mu dn lu mv mw dp ly kn mx my mc kr mz na mg kv nb nc mk nd bi translated"><strong class="ak">其他实用程序:</strong></h2><p id="f397" class="pw-post-body-paragraph kc kd iq ke b kf ne kh ki kj nf kl km kn ng kp kq kr nh kt ku kv ni kx ky kz ij bi translated">像<em class="lb">记录器</em>和<em class="lb">绘图仪</em>这样的实用程序随软件包提供，以便更好地监控和研究实验的输出和结果。</p></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><h1 id="d19e" class="lo lp iq bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">参考资料:</h1><p id="4646" class="pw-post-body-paragraph kc kd iq ke b kf ne kh ki kj nf kl km kn ng kp kq kr nh kt ku kv ni kx ky kz ij bi translated">这里的  <strong class="ke ir">可以参考官方文档<a class="ae la" href="https://spinningup.openai.com/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ir">。</strong></a></strong></p><p id="c238" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这个包的 GitHub 库可以在<a class="ae la" href="https://github.com/openai/spinningup" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ir">这里</strong> </a>找到。</p></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><h1 id="8e36" class="lo lp iq bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">建议:</h1><p id="bb62" class="pw-post-body-paragraph kc kd iq ke b kf ne kh ki kj nf kl km kn ng kp kq kr nh kt ku kv ni kx ky kz ij bi translated">这个包展示了高质量的学习内容，对你成为一个活跃的 RL 社区成员来说是绰绰有余的，主要是应用方面。但是对于强化学习和深度学习领域的初学者来说，其学习内容的许多部分(如研究论文和算法的实现)可能有点难以理解。在开始使用 OpenAI 的 Deep RL 包中的这个<em class="lb">之前，最好至少对这些领域的一些基本概念有一点了解。</em></p></div><div class="ab cl lh li hu lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="ij ik il im in"><p id="7938" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我希望你能从 OpenAI 的这个惊人的资源中开始你的深度强化学习之旅。如果你想为 Deep RL 推荐任何其他同样好或更好的学习资源，欢迎在下面的评论中提出来。</p></div></div>    
</body>
</html>