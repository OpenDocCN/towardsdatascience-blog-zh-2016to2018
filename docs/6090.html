<html>
<head>
<title>Identifying Higgs Bosons Amongst Background Noise (PySpark)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在背景噪音中识别希格斯玻色子</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/identifying-higgs-bosons-from-background-noise-pyspark-d7983234207e?source=collection_archive---------17-----------------------#2018-11-25">https://towardsdatascience.com/identifying-higgs-bosons-from-background-noise-pyspark-d7983234207e?source=collection_archive---------17-----------------------#2018-11-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/fd5ddefa53ece31340dd5aaca08f560c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M_J_21-qRO4q48x5SMIk4w.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Large Hadron Collider</figcaption></figure><h2 id="6223" class="kc kd iq bd ke kf kg dn kh ki kj dp kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">背景</h2><p id="f86a" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li kl lj lk ll kp lm ln lo kt lp lq lr ls ij bi translated">在这篇简短的博客中，解释什么是希格斯玻色子是非常困难的。然而，为了保持它的基本性，根据一个大爆炸理论，在一个叫做玻色子的导火索导致它爆炸之前，整个宇宙曾经是一个单一的粒子。希格斯玻色子是以物理学家彼得·希格斯的名字命名的，他在 1964 年和其他六位科学家一起提出了这种机制，这表明了这种粒子的存在。这种亚原子粒子是在大型强子对撞机的一次实验中产生的。彼得·希格斯将因此发现获得 2013 年的诺贝尔奖。</p><p id="5b7c" class="pw-post-body-paragraph ky kz iq la b lb lt ld le lf lu lh li kl lv lk ll kp lw ln lo kt lx lq lr ls ij bi translated">历史说够了。现在进行一些有趣的机器学习！这是一个分类问题，以区分产生希格斯玻色子的信号过程和不产生希格斯玻色子的背景过程。</p><h2 id="cb54" class="kc kd iq bd ke kf kg dn kh ki kj dp kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">资料组</h2><p id="c3a7" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li kl lj lk ll kp lm ln lo kt lp lq lr ls ij bi translated">网址:<a class="ae ly" href="http://archive.ics.uci.edu/ml/datasets/HIGGS#" rel="noopener ugc nofollow" target="_blank">http://archive.ics.uci.edu/ml/datasets/HIGGS#</a></p><p id="629f" class="pw-post-body-paragraph ky kz iq la b lb lt ld le lf lu lh li kl lv lk ll kp lw ln lo kt lx lq lr ls ij bi translated">这些数据是使用蒙特卡罗模拟产生的。前 21 个特征(第 2-22 列)是由加速器中的粒子探测器测量的运动特性。后 7 个特征是前 21 个特征的函数；这些是由物理学家得出的高级特征，有助于区分这两个类别。人们有兴趣使用深度学习方法来消除物理学家手动开发这些特征的需要。基准测试结果使用贝叶斯决策树从一个标准的物理包和 5 层神经网络提出了在原来的文件。最后 500，000 个示例用作测试集。</p><h2 id="6fbc" class="kc kd iq bd ke kf kg dn kh ki kj dp kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">导入库</h2><p id="98a5" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li kl lj lk ll kp lm ln lo kt lp lq lr ls ij bi translated">希格斯数据集是巨大的！因此，我们需要使用 Spark 来运行它。对于本文，我使用 Python 包装器 for Spark，或 PySpark。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="0079" class="kc kd iq me b gy mi mj l mk ml"><strong class="me ir">from</strong> <strong class="me ir">time</strong> <strong class="me ir">import</strong> time<br/><strong class="me ir">from</strong> <strong class="me ir">string</strong> <strong class="me ir">import</strong> split,strip<br/><strong class="me ir">from</strong> <strong class="me ir">plot_utils</strong> <strong class="me ir">import</strong> *</span><span id="c290" class="kc kd iq me b gy mm mj l mk ml"><strong class="me ir">from</strong> <strong class="me ir">pyspark.mllib.linalg</strong> <strong class="me ir">import</strong> Vectors<br/><strong class="me ir">from</strong> <strong class="me ir">pyspark.mllib.regression</strong> <strong class="me ir">import</strong> LabeledPoint<br/><br/><strong class="me ir">from</strong> <strong class="me ir">pyspark.mllib.tree</strong> <strong class="me ir">import</strong> GradientBoostedTrees <br/><strong class="me ir">from pyspark.mllib.tree</strong> <strong class="me ir">import </strong>GradientBoostedTreesModel<br/><strong class="me ir">from</strong> <strong class="me ir">pyspark.mllib.tree</strong> <strong class="me ir">import</strong> RandomForest, RandomForestModel<br/><br/><strong class="me ir">from</strong> <strong class="me ir">pyspark.mllib.util</strong> <strong class="me ir">import</strong> MLUtils</span></pre><h2 id="8b5c" class="kc kd iq bd ke kf kg dn kh ki kj dp kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">准备数据</h2><p id="7d1e" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li kl lj lk ll kp lm ln lo kt lp lq lr ls ij bi translated">接下来，我们对数据集中感兴趣的要素列表进行硬编码</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="8330" class="kc kd iq me b gy mi mj l mk ml">feature_text='lepton pT, lepton eta, lepton phi, missing energy magnitude, missing energy phi, jet 1 pt, jet 1 eta, jet 1 phi, jet 1 b-tag, jet 2 pt, jet 2 eta, jet 2 phi, jet 2 b-tag, jet 3 pt, jet 3 eta, jet 3 phi, jet 3 b-tag, jet 4 pt, jet 4 eta, jet 4 phi, jet 4 b-tag, m_jj, m_jjj, m_lv, m_jlv, m_bb, m_wbb, m_wwbb'</span><span id="fe05" class="kc kd iq me b gy mm mj l mk ml">features=[strip(a) <strong class="me ir">for</strong> a <strong class="me ir">in</strong> split(feature_text,',')]</span></pre><p id="2374" class="pw-post-body-paragraph ky kz iq la b lb lt ld le lf lu lh li kl lv lk ll kp lw ln lo kt lx lq lr ls ij bi translated">接下来，我们把数据转换成火花 RDD</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="4494" class="kc kd iq me b gy mi mj l mk ml">inputRDD=sc.textFile(path_to_data) #Replace with actual path</span><span id="c5a5" class="kc kd iq me b gy mm mj l mk ml">inputRDD.first()</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mn"><img src="../Images/b7b3cf801726cf4b8b37b553e2dbbd3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nKGgFWdZtcFvLixTfylGHg.png"/></div></div></figure><p id="089b" class="pw-post-body-paragraph ky kz iq la b lb lt ld le lf lu lh li kl lv lk ll kp lw ln lo kt lx lq lr ls ij bi translated">如果每行都是一个字符串，那么数据就没有用。因此，为了使用 PySpark 的机器学习库，我们需要用逗号将它分开，并将每个单元格分配给一个 LabeledPoint。第一列是目标，因此需要从模型特征中分离出来。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="9b34" class="kc kd iq me b gy mi mj l mk ml">Data=(inputRDD.map(<strong class="me ir">lambda</strong> line: [float(strip(x)) <strong class="me ir">for</strong> x <strong class="me ir">in</strong> line.split(',')]).map(<strong class="me ir">lambda</strong> line: LabeledPoint(line[0], line[1:])))</span><span id="bbd3" class="kc kd iq me b gy mm mj l mk ml">Data.first()</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mn"><img src="../Images/6ead9174652ba9b730e3a1ce2276c2e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6La5Kgown_8Ck-hnxRJUGA.png"/></div></div></figure><p id="d500" class="pw-post-body-paragraph ky kz iq la b lb lt ld le lf lu lh li kl lv lk ll kp lw ln lo kt lx lq lr ls ij bi translated">为了更清楚地看到过度拟合的影响，我们将数据的大小减少了 100 倍。然后，我们将 70%–30%分成培训和测试。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="04b0" class="kc kd iq me b gy mi mj l mk ml">Data1=Data.sample(False,0.01).cache()</span><span id="e89e" class="kc kd iq me b gy mm mj l mk ml">(trainingData,testData)=Data1.randomSplit([0.7,0.3])<br/><br/><strong class="me ir">print (</strong>'Sizes: Data1=<strong class="me ir">%d</strong>, trainingData=<strong class="me ir">%d</strong>, testData=<strong class="me ir">%d</strong>'%(Data1.count(),trainingData.cache().count(),testData.cache().count()))</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/7c0a45ee4b49d0f0a72f39a609b53ed7.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*gML77UeH1VUssYDXQtBkTg.png"/></div></figure><h2 id="721a" class="kc kd iq bd ke kf kg dn kh ki kj dp kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">梯度增强树</h2><p id="d8eb" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li kl lj lk ll kp lm ln lo kt lp lq lr ls ij bi translated">第一个分类器将使用梯度增强树来构建。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="1035" class="kc kd iq me b gy mi mj l mk ml">errors={} <strong class="me ir">for</strong> depth <strong class="me ir">in</strong> [1,3,6,10]:     <br/>    start=time()        <br/>    model=GradientBoostedTrees.trainClassifier(Data1,                                              <br/>            categoricalFeaturesInfo={}, numIterations=3)        <br/>    errors[depth]={}     <br/>    dataSets={'train':trainingData,'test':testData}     <br/>    <strong class="me ir">for</strong> name <strong class="me ir">in</strong> dataSets.keys():  <br/>        <em class="mp"># Calculate errors on train and test sets</em>           <br/>        data=dataSets[name]         <br/>        Predicted=model.predict(data.map(<strong class="me ir">lambda</strong> x: x.features))         <br/>        LabelsAndPredictions=(data.map(<strong class="me ir">lambda</strong> lp: <br/>                               lp.label).zip(Predicted))<br/>        Err=(LabelsAndPredictions.filter(<strong class="me ir">lambda</strong> (v,p):v != <br/>              p).count()/float(data.count()))         <br/>        errors[depth][name]=Err     <br/>    <strong class="me ir">print </strong>depth,errors[depth],int(time()-start),'seconds' <br/><strong class="me ir">print</strong> errors</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mq"><img src="../Images/2da835e42777aad99154372ebd4ebdf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QrjrM5cpKDvFPhq2jN4h3g.png"/></div></div></figure><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="3e83" class="kc kd iq me b gy mi mj l mk ml">B10=errors<br/>make_figure([B10],['10Trees'],Title='Boosting using 10<strong class="me ir">% o</strong>f data')</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/55ed395570e92fd086537618160772c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1142/format:webp/1*xurcnqeV2hcAdnUPslzAAg.png"/></div></figure><h2 id="c332" class="kc kd iq bd ke kf kg dn kh ki kj dp kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">随机森林</h2><p id="6e44" class="pw-post-body-paragraph ky kz iq la b lb lc ld le lf lg lh li kl lj lk ll kp lm ln lo kt lp lq lr ls ij bi translated">接下来，我们尝试随机森林分类器进行比较。</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="9b03" class="kc kd iq me b gy mi mj l mk ml">errors={}<br/><strong class="me ir">for</strong> depth <strong class="me ir">in</strong> [1,3,6,10,15,20]:<br/>    start=time()<br/>    model = RandomForest.trainClassifier(Data1, numClasses=2, <br/>           categoricalFeaturesInfo={}, numTrees=3,  <br/>           featureSubsetStrategy="auto", impurity='gini', <br/>           maxDepth=4, maxBins=32)<br/>    errors[depth]={}<br/>    dataSets={'train':trainingData,'test':testData}<br/>    <strong class="me ir">for</strong> name <strong class="me ir">in</strong> dataSets.keys():  <br/>        <em class="mp"># Calculate errors on train and test sets</em><br/>        data=dataSets[name]<br/>        Predicted=model.predict(data.map(<strong class="me ir">lambda</strong> x: x.features))<br/>        LabelsAndPredictions=(data.map(<strong class="me ir">lambda</strong> lp: <br/>                               lp.label).zip(Predicted))<br/>        Err=(LabelsAndPredictions.filter(<strong class="me ir">lambda</strong> (v,p):v != <br/>             p).count()/float(data.count()))<br/>        errors[depth][name]=Err<br/>    <strong class="me ir">print</strong> depth,errors[depth],int(time()-start),'seconds'<br/><strong class="me ir">print</strong> errors</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ms"><img src="../Images/0392b3a54e69bc135680dc555181966b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*csTreT3l20197mT-4asUAw.png"/></div></div></figure><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="3178" class="kc kd iq me b gy mi mj l mk ml">RF_10trees = errors<br/><em class="mp"># Plot Train/test accuracy vs Depth of trees graph</em><br/>make_figure([RF_10trees],['10Trees'],Title='Random Forests using 10<strong class="me ir">% o</strong>f data')</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/71fab3fe622f210a9d6df4575d54a5db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*zadETV8DPbr3D08u7K7Baw.png"/></div></figure><h2 id="81a3" class="kc kd iq bd ke kf kg dn kh ki kj dp kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">一起想象</h2><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="1951" class="kc kd iq me b gy mi mj l mk ml">make_figure([B10,RF_10trees],['B10','RF_10Trees'],Title='Random Forests using 10<strong class="me ir">% o</strong>f data')</span></pre><figure class="lz ma mb mc gt jr gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/a107e19681a471dec9107c1e88b43e36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*QVTpICDVZ_l6lX1dsrOVBA.png"/></div></figure></div></div>    
</body>
</html>