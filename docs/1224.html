<html>
<head>
<title>Machine Reasoning: distinguishing features</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器推理:区别特征</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-reasoning-distinguishing-features-beff5159d957?source=collection_archive---------2-----------------------#2017-08-12">https://towardsdatascience.com/machine-reasoning-distinguishing-features-beff5159d957?source=collection_archive---------2-----------------------#2017-08-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="11b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">辨别事物特征的能力是学习和推理的一个基本方面。鸟有翅膀，汽车有轮子，等等…</p><p id="99f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">“区分”意味着这些特征在描述和分类事物时是有用的。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/50723e6091ec6503ab47e8316f2475bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZalvxKsJ5n46KMAlV45NEQ.jpeg"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">by Piyushgiri Revagar</figcaption></figure><p id="488f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在“<a class="ae lc" href="https://medium.com/towards-data-science/a-basic-model-for-machine-learning-an-overview-3854ea77e919" rel="noopener">机器学习的基本模型</a>中，我们用符号模式观察了<em class="kl">机器推理</em>，并开始探索区别特征的概念。这是一个起点。我们在这里进一步探索更复杂形式的区别特征。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="ld le l"/></div></figure><blockquote class="lf lg lh"><p id="aba2" class="jn jo kl jp b jq jr js jt ju jv jw jx li jz ka kb lj kd ke kf lk kh ki kj kk ij bi translated">print(r . distincting(' ABC ')<br/>print(r . distincting(' ABC '，relation='is not '))</p></blockquote><pre class="kn ko kp kq gt ll lm ln lo aw lp bi"><span id="bb6e" class="lq lr iq lm b gy ls lt l lu lv">[['a'], ['a', 'b'], ['a', 'b', 'c'], ['b'], ['b', 'c'], ['c']]<br/>[['x'], ['x', 'y'], ['y'], ['n']]</span></pre><p id="cacd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以很容易地将它缩小到特征集中最大的掩码:</p><blockquote class="lf lg lh"><p id="d96d" class="jn jo kl jp b jq jr js jt ju jv jw jx li jz ka kb lj kd ke kf lk kh ki kj kk ij bi translated">print(top _ mask(r . distinguished(' ABC '))<br/>print(top _ mask(r . distinguished(' ABC '，relation='is not '))</p></blockquote><pre class="kn ko kp kq gt ll lm ln lo aw lp bi"><span id="14f8" class="lq lr iq lm b gy ls lt l lu lv">['a', 'b', 'c']<br/>['x', 'y']</span></pre><p id="df60" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">属性‘ABC’的模式确实具有模式<strong class="jp ir">‘a b c’</strong>，而那些不是‘ABC’的模式具有模式<strong class="jp ir">‘x y’</strong>。给定提供的模式，这些是事物的<em class="kl">区别特征。</em></p><p id="ca34" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦你确定了一个新模式的显著特征，确定它是否是一个事物就相对简单了:</p><blockquote class="lf lg lh"><p id="2c02" class="jn jo kl jp b jq jr js jt ju jv jw jx li jz ka kb lj kd ke kf lk kh ki kj kk ij bi translated">s0 = Symbolic(' u o I a b c ')<br/>r . determine(s0，' a b c ')</p></blockquote><pre class="kn ko kp kq gt ll lm ln lo aw lp bi"><span id="8d7a" class="lq lr iq lm b gy ls lt l lu lv">(True, 'has distinguishing features')</span></pre><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/25930ba0a2a6804a7b49b50f82f38ddc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*mf-zDRbORrug-ki20TJKzg.png"/></div></figure><h2 id="8127" class="lq lr iq bd lx ly lz dn ma mb mc dp md jy me mf mg kc mh mi mj kg mk ml mm mn bi translated">神经网络呢</h2><p id="bf4f" class="pw-post-body-paragraph jn jo iq jp b jq mo js jt ju mp jw jx jy mq ka kb kc mr ke kf kg ms ki kj kk ij bi translated">这与分类中使用的典型人工神经网络相比如何？分类是<em class="kl">决定一个输入是否是一个东西</em>的工作，所以这是一个恰当的比较。</p><p id="83a9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在“<a class="ae lc" href="https://chatbotslife.com/deep-learning-in-7-lines-of-code-7879a8ef8cfb" rel="noopener ugc nofollow" target="_blank">7行代码中的深度学习</a>”中，我们使用Tensorflow和tflearn对几个模式进行了分类，让我们重温一下这个并运行一些实验。</p><p id="f9c5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里是<a class="ae lc" href="https://github.com/ugik/notebooks/blob/master/tflearn%20toy%20ANN-3.ipynb" rel="noopener ugc nofollow" target="_blank">代码</a>，我们将输入以下模式:</p><pre class="kn ko kp kq gt ll lm ln lo aw lp bi"><span id="37bb" class="lq lr iq lm b gy ls lt l lu lv">features.append([[0, 1, 9, 3, 6], [0,1]])<br/>features.append([[0, 1, 7, 4, 2], [0,1]])<br/>features.append([[0, 1, 5, 0, 9], [0,1]])<br/>features.append([[1, 0, 4, 6, 7], [1,0]])<br/>features.append([[1, 0, 3, 7, 8], [1,0]])</span></pre><p id="3172" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">可以看到，符号模式<strong class="jp ir"> [0，1] </strong>对应于类[0，1]，模式<strong class="jp ir"> [1，0] </strong>对应于类[1，0]。让我们尝试对新数据进行分类:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="ld le l"/></div></figure><pre class="kn ko kp kq gt ll lm ln lo aw lp bi"><span id="acdc" class="lq lr iq lm b gy ls lt l lu lv">[[0.967603862285614, 0.0323960967361927]]       <strong class="lm ir"># wrong!</strong><br/>[[0.6647899746894836, 0.33520999550819397]]<br/>[[0.12406770884990692, 0.8759322762489319]]<br/>[[0.9999886751174927, 1.133059231506195e-05]]   <strong class="lm ir"># unclear</strong><br/>[[0.9999721050262451, 2.794429565255996e-05]]   <strong class="lm ir"># unclear</strong><br/>[[0.9997043013572693, 0.00029572920175269246]]  <strong class="lm ir"># wrong!</strong></span></pre><p id="2d11" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当符号与训练数据T26对齐时，我们的Tensorflow 2层神经网络T25表现相当好(使用小数据)，但在第一次测试数据中[非常]不正确。它非常确信模式[0，1，0，6，2]没有被归类为[0，1]，但它被归类为[0，1]。在缺少任何一类区别特征的输入上，它产生了不合理的高概率，并且在最后一个模式上，它错过了偏移区别特征。给定足够的训练数据，卷积网络应该可以克服符号偏移问题——这是另一项实验的成果。</p><p id="7c05" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们看看我们的符号库是如何对相同的数据进行推理的。笔记本这里是<a class="ae lc" href="https://github.com/ugik/symbolic/blob/master/symbolicTutorial-distinguishingFeatures.ipynb" rel="noopener ugc nofollow" target="_blank">这里是</a>。我们将把相同的模式添加到我们的Reason类中，并向它询问区别特征。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="ld le l"/></div></figure><pre class="kn ko kp kq gt ll lm ln lo aw lp bi"><span id="8e1e" class="lq lr iq lm b gy ls lt l lu lv">0.95668 secs</span><span id="0ca1" class="lq lr iq lm b gy mt lt l lu lv">{'is': <strong class="lm ir">[('0', ['_0']), ('1', ['_1'])]</strong>, <br/> 'is not': <strong class="lm ir">[('1', ['_0']), ('0', ['_1'])]</strong>}</span></pre><p id="5eda" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它推理出[0，1]和[1，0]是存在和不存在事物‘foo’的区别特征<em class="kl">，并完成了确定先前未见过的模式的简短工作:</em></p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="ld le l"/></div></figure><pre class="kn ko kp kq gt ll lm ln lo aw lp bi"><span id="cbb6" class="lq lr iq lm b gy ls lt l lu lv">(True, 'has distinguishing features')</span></pre><p id="55fe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的神经网络不仅弄错了这种模式，它也没有告诉我们<em class="kl">为什么</em>对它进行了错误的分类。这是一个关键点——机器决定，特别是在<em class="kl">中，推理的过程</em>应该是可解释的(内省的)。有人可能会说，所谓的“T8”快速思考“T9”决策通常是不可解释的，但“T10”不同于“T11”。</p><p id="cc50" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将CNN(卷积)结构应用于这些模式需要更多的实验，然而这将需要更多的训练数据。这是另一个重点——<em class="kl">从小数据学习</em>和’<a class="ae lc" href="http://web.mit.edu/jgross/Public/lake_etal_cogsci2011.pdf" rel="noopener ugc nofollow" target="_blank">一次性学习</a>。</p><p id="9ea1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如在<a class="ae lc" href="https://medium.com/towards-data-science/a-basic-model-for-machine-learning-an-overview-3854ea77e919" rel="noopener">概述</a>中提到的，我们希望能够应用自适应学习。我们需要我们的系统<em class="kl">在推理的时候</em>学习，纠正和强化输入。我们需要我们的模型不断发展，而不必随着每个新的输入而重建。</p><blockquote class="mu"><p id="2bc9" class="mv mw iq bd mx my mz na nb nc nd kk dk translated">这些推理的特性存在于幼儿和动物的学习过程中。他们在场是因为你今天学到了一些新东西。</p></blockquote></div><div class="ab cl nf ng hu nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="ij ik il im in"><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/8aa0c1ec95106b7db47891becb4b2a4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*oEbCy2RZNQwWzORS6cP5WQ.png"/></div></figure><h2 id="b204" class="lq lr iq bd lx ly lz dn ma mb mc dp md jy me mf mg kc mh mi mj kg mk ml mm mn bi translated">与众不同的特征或挑战</h2><p id="1c49" class="pw-post-body-paragraph jn jo iq jp b jq mo js jt ju mp jw jx jy mq ka kb kc mr ke kf kg ms ki kj kk ij bi translated">通常情况下，一个事物具有一组具有或关系的区别特征，而不是和关系。</p><p id="852b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">东西(a)是一辆汽车——它有一个汽油发动机</p><p id="e1f6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">东西(b)是一辆汽车——它有一个方向盘和一个汽油发动机</p><p id="150c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">东西(c)是一辆汽车——它有方向盘、挡风玻璃和电动引擎</p><p id="b2fc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以推理出“汽车”有方向盘、挡风玻璃和汽油发动机或电动发动机。这个区别特征在‘车’的判定上有或关系。</p><p id="97d8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">事实证明，这是一个很难解决的问题。先用我们的神经网络做实验，笔记本这里是<a class="ae lc" href="https://github.com/ugik/notebooks/blob/master/tflearn%20toy%20ANN-2.ipynb" rel="noopener ugc nofollow" target="_blank">这里是</a>。</p><p id="602d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们首先定义我们的训练数据，我们将[0，1]和[1，0]模式组合到同一个[0，1]类中，以区分每一个的方式为另一个类提供训练数据。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="ld le l"/></div></figure><p id="d701" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，类[1，0]的训练示例缺乏显著特征。接下来，我们尝试对新模式进行分类:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="ld le l"/></div></figure><pre class="kn ko kp kq gt ll lm ln lo aw lp bi"><span id="5c24" class="lq lr iq lm b gy ls lt l lu lv">[[0.14985743165016174, 0.8501425385475159]]<br/>[[0.0002913394710049033, 0.9997085928916931]]<br/>[[0.6994397640228271, 0.30056023597717285]]      <strong class="lm ir"># wrong</strong><br/>[[1.0, 1.7667502999322605e-14]]<br/>[[0.15181590616703033, 0.8481840491294861]]      <strong class="lm ir"># wrong</strong><br/>[[0.019126782193779945, 0.980873167514801]]      <strong class="lm ir"># wrong!</strong></span></pre><p id="0a9a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">毫不奇怪，我们的Tensorflow ANN不知道[0，1]或[1，0]特征。在最后一次输入中，它对不正确的分类有很高的可信度(可能是因为0的存在，但是<em class="kl">也不能解释为什么</em>会这样推理。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi nn"><img src="../Images/d150f367dd8b912047e608070489ec59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u12iZUJ5gU03y8a2fExxLg.png"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><a class="ae lc" href="https://upload.wikimedia.org/wikipedia/commons/e/e8/Juliadim2.png" rel="noopener ugc nofollow" target="_blank">https://upload.wikimedia.org/wikipedia/commons/e/e8/Juliadim2.png</a></figcaption></figure><h2 id="6bc4" class="lq lr iq bd lx ly lz dn ma mb mc dp md jy me mf mg kc mh mi mj kg mk ml mm mn bi translated">集合论继续…</h2><p id="e7c4" class="pw-post-body-paragraph jn jo iq jp b jq mo js jt ju mp jw jx jy mq ka kb kc mr ke kf kg ms ki kj kk ij bi translated">在我们的符号库中，我们再次使用集合论，这次是为了确定区别特征的或组合。</p><p id="0224" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们通过计算<em class="kl">模式列表</em>(对于一个属性)的不连续子集的集合，并计算每个子集的区别特征来达到子集的最佳组合。“最佳”是指我们在子集中寻找与其他特征相比最大/最全面的区别特征集合。</p><p id="a582" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">生成非连续列表子集的递归函数如下:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="ld le l"/></div></figure><p id="d50e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如:</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="ld le l"/></div></figure><pre class="kn ko kp kq gt ll lm ln lo aw lp bi"><span id="34d4" class="lq lr iq lm b gy ls lt l lu lv">[0, 1] [2, 3, 4]<br/>[0, 2] [1, 3, 4]<br/>[0, 3] [1, 2, 4]<br/>[0, 4] [1, 2, 3]<br/>[1, 2] [0, 3, 4]<br/>[1, 3] [0, 2, 4]<br/>[1, 4] [0, 2, 3]<br/>[2, 1] [0, 3, 4]<br/>...</span></pre><p id="8485" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">系列中不连续子集的数量产生了一个雄心勃勃的系列:</p><blockquote class="lf lg lh"><p id="3f30" class="jn jo kl jp b jq jr js jt ju jv jw jx li jz ka kb lj kd ke kf lk kh ki kj kk ij bi">2, 3, 10, 15, 41, 63, 162, 255, 637, 1023, 2509, 4095, 9907, 16383, 39202, 65535, 155381, 262143, 616665, 1048575, 2449867, 4194303, 9740685, 16777215, 38754731, 67108863, 154276027, 268435455, 614429671, 1073741823, 2448023842, 4294967295</p></blockquote><p id="37c8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">升级速度相当快。更多关于这个系列的信息可以在<a class="ae lc" href="https://oeis.org/A226881" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi no"><img src="../Images/524d04725390e1b657394f95b8b150cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pf839ef4t7q5vwecBoYr4Q.png"/></div></div></figure><p id="2c85" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">回到我们的符号库<a class="ae lc" href="https://github.com/ugik/symbolic/blob/master/symbolicTutorial-distinguishingFeatures.ipynb" rel="noopener ugc nofollow" target="_blank">示例</a>，我们再次提供模式，与之前的运行相同。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="ld le l"/></div></figure><pre class="kn ko kp kq gt ll lm ln lo aw lp bi"><span id="3049" class="lq lr iq lm b gy ls lt l lu lv">1.2334489999999931 secs</span><span id="0c9a" class="lq lr iq lm b gy mt lt l lu lv">{'is': [['0'], ['1']], 'is not': None}</span></pre><p id="10be" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它推理出符号[0]和[1]是有区别的特征，这是正确的，然而它需要进一步推理以理解[0，1]或[1，0]是有区别的。为此，我们将使用另一个函数:</p><blockquote class="lf lg lh"><p id="476a" class="jn jo kl jp b jq jr js jt ju jv jw jx li jz ka kb lj kd ke kf lk kh ki kj kk ij bi translated">r . distinguisingor(' foo ')</p></blockquote><pre class="kn ko kp kq gt ll lm ln lo aw lp bi"><span id="e7bd" class="lq lr iq lm b gy ls lt l lu lv">16.00546700000001 secs</span><span id="cc6f" class="lq lr iq lm b gy mt lt l lu lv"><strong class="lm ir">([('1', ['_0']), ('0', ['_1'])], <br/> [('0', ['_0']), ('1', ['_1'])])</strong></span></pre><p id="1ec9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它正确地推理出属性‘foo’中这些模式的区别特征是<strong class="jp ir">【1，0】</strong>或<strong class="jp ir">【0，1】</strong>，在这种情况下，它们的位置(偏移)也被记录，然而这对于特征的识别是次要的。</p><p id="ae95" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不像我们的神经网络，每个输入的位置<em class="kl">是关键的，使用这种方法区别特征的相对位置并不重要，例如(在模式前添加随机填充):</em></p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="ld le l"/></div></figure><pre class="kn ko kp kq gt ll lm ln lo aw lp bi"><span id="0b0f" class="lq lr iq lm b gy ls lt l lu lv">{'is': <strong class="lm ir">[['1'], ['0']]</strong>, 'is not': None}</span></pre><p id="b21a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">和我们的OR函数(带调试):</p><blockquote class="lf lg lh"><p id="9789" class="jn jo kl jp b jq jr js jt ju jv jw jx li jz ka kb lj kd ke kf lk kh ki kj kk ij bi translated">dis1，dis 2 = r . distinguisingor(' foo '，debug=True) <br/> top_mask(dis1)，top_mask(dis2)</p></blockquote><pre class="kn ko kp kq gt ll lm ln lo aw lp bi"><span id="bbd3" class="lq lr iq lm b gy ls lt l lu lv">31.367725 secs<br/><strong class="lm ir">0</strong> [('6', ['_0']), ('1', ['_1']), ('0', ['_2']), ('4', ['_3']), ('6', ['_4']), ('7', ['_5'])]<br/><strong class="lm ir">1</strong> [('8', ['_0']), ('9', ['_1']), ('1', ['_2']), ('1', ['_3']), ('0', ['_4'])]<br/><strong class="lm ir">2</strong> [('7', ['_0']), ('8', ['_1']), ('0', ['_2']), ('1', ['_3']), ('9', ['_4']), ('3', ['_5']), ('6', ['_6'])]<br/><strong class="lm ir">3</strong> [('4', ['_0']), ('0', ['_1']), ('1', ['_2']), ('7', ['_3']), ('4', ['_4']), ('2', ['_5'])]<br/><strong class="lm ir">4</strong> [('2', ['_0']), ('9', ['_1']), ('0', ['_2']), ('1', ['_3']), ('5', ['_4'])]<br/>[0, 1] -&gt; [['1'], ['1'], <strong class="lm ir">['1', '0']</strong>, ['0']]<br/>[2, 3, 4] -&gt; [['0'], <strong class="lm ir">['0', '1']</strong>, ['1']]</span><span id="8f1f" class="lq lr iq lm b gy mt lt l lu lv">(<strong class="lm ir">['1', '0']</strong>, <strong class="lm ir">['0', '1']</strong>)</span></pre><p id="bd7a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">简介:在与事物“foo”相关联的5个模式中，在所有不连续的子集(最小长度为2)中，模式组[0，1]和[2，3，4] <em class="kl">产生最大的区别特征集合</em>。</p><p id="b547" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">换句话说:事物‘foo’的这些子群彼此有最多的共同点，它们的共性由它们的区别性特征来表示。这些是事物的或特征。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi np"><img src="../Images/640d139412f4ad9feda8d99ceb716ea1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rqHDZ1JTV4Wq7dkehMNXyg.jpeg"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk"><a class="ae lc" href="https://upload.wikimedia.org/wikipedia/commons/b/b3/Mandel_zoom_07_satellite.jpg" rel="noopener ugc nofollow" target="_blank">https://upload.wikimedia.org/wikipedia/commons/b/b3/Mandel_zoom_07_satellite.jpg</a></figcaption></figure><h2 id="bce6" class="lq lr iq bd lx ly lz dn ma mb mc dp md jy me mf mg kc mh mi mj kg mk ml mm mn bi translated">思考绩效</h2><p id="a391" class="pw-post-body-paragraph jn jo iq jp b jq mo js jt ju mp jw jx jy mq ka kb kc mr ke kf kg ms ki kj kk ij bi translated">你可能已经注意到在一些例子中显示的运行时间，这是有意包含的。</p><pre class="kn ko kp kq gt ll lm ln lo aw lp bi"><span id="037d" class="lq lr iq lm b gy ls lt l lu lv">31.367725 secs</span></pre><p id="c6ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对一个有5个图案的东西的区别特征进行推理，每个图案有5-7个符号，需要大约30秒，这对于计算来说是永恒的。集合论计算的本质是，模式数量或大小的增加将对性能产生<em class="kl">非线性影响</em>。</p><p id="809f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们快速看一下10种模式的不连续子集的数量(最小子集长度为2):</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="ld le l"/></div></figure><pre class="kn ko kp kq gt ll lm ln lo aw lp bi"><span id="ca51" class="lq lr iq lm b gy ls lt l lu lv">10770</span></pre><p id="464a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">10，770个可能的子集中的每一个都需要计算一组区别特征，这本身就涉及额外的集合论工作。</p><blockquote class="mu"><p id="b30b" class="mv mw iq bd mx my mz na nb nc nd kk dk translated">首先让机器运转起来，然后进行优化。</p></blockquote><p id="7e1f" class="pw-post-body-paragraph jn jo iq jp b jq nq js jt ju nr jw jx jy ns ka kb kc nt ke kf kg nu ki kj kk ij bi translated">我们在进行实验时遵循这一法则，优化和提高性能的潜力总是存在的，我们首先想了解如何根据模式和表面基本概念进行推理。</p><p id="6d39" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里有几种优化方法:</p><ul class=""><li id="cecf" class="nv nw iq jp b jq jr ju jv jy nx kc ny kg nz kk oa ob oc od bi translated">ipython <em class="kl">笔记本相对较慢</em>，但对实验很有帮助，它不是一个性能环境</li><li id="45e1" class="nv nw iq jp b jq oe ju of jy og kc oh kg oi kk oa ob oc od bi translated">消除<em class="kl">冗余的非连续子集</em>有简单的方法，例如[0，2] [1，3，4]与[1，3，4] [0，2]是冗余的</li><li id="977a" class="nv nw iq jp b jq oe ju of jy og kc oh kg oi kk oa ob oc od bi translated">有一些方法可以避免对子集的整个分支进行计算，例如，如果子集[0，2] <em class="kl">没有产生有意义的区别特征</em>，那么它的所有超集([0，2，1]，[0，2，5]，[0，2，8]等等。)可以忽略</li><li id="3796" class="nv nw iq jp b jq oe ju of jy og kc oh kg oi kk oa ob oc od bi translated">进程<em class="kl">有利于并行化</em>，没有理由为什么单独的线程/进程可以通过不同的集合组工作</li></ul></div><div class="ab cl nf ng hu nh" role="separator"><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk nl"/><span class="ni bw bk nj nk"/></div><div class="ij ik il im in"><p id="d6a0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">直到下一次…</p></div></div>    
</body>
</html>