<html>
<head>
<title>Deep Autoencoders For Collaborative Filtering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于协同过滤的深度自动编码器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d?source=collection_archive---------0-----------------------#2018-04-15">https://towardsdatascience.com/deep-autoencoders-for-collaborative-filtering-6cf8d25bbf1d?source=collection_archive---------0-----------------------#2018-04-15</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0c4f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">预测用户对电影的评价——实用教程</h2></div><p id="39cb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">协同过滤是推荐系统使用的一种方法，通过从许多其他用户收集品味或偏好信息来预测特定用户的兴趣。协同过滤技术具有潜在的假设，即如果用户A与人B在一个问题上具有相同的品味或观点，则A更有可能在不同的问题上具有B的观点。</p><p id="bd32" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">在这篇文章中，你将学习如何根据一个用户的喜好以及观看并评价了同一部电影和其他电影的其他用户的喜好来预测这个用户对这部电影的评价。</strong></p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi le"><img src="../Images/a0e3481ba1eb3594cc581d35fd74ee74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QbU_DyUbjZaD11n8Gw4kng.jpeg"/></div></div></figure></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h2 id="8937" class="lx ly it bd lz ma mb dn mc md me dp mf kr mg mh mi kv mj mk ml kz mm mn mo mp bi translated">如果你喜欢这篇文章，想分享你的想法，问问题或保持联系，请随时通过<a class="ae mq" href="https://www.linkedin.com/in/artem-oppermann-929154199/?locale=en_US" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>与我联系。</h2></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h1 id="f93c" class="mr ly it bd lz ms mt mu mc mv mw mx mf jz my ka mi kc mz kd ml kf na kg mo nb bi translated">目录:</h1><ul class=""><li id="b373" class="nc nd it kk b kl ne ko nf kr ng kv nh kz ni ld nj nk nl nm bi translated">介绍</li><li id="e396" class="nc nd it kk b kl nn ko no kr np kv nq kz nr ld nj nk nl nm bi translated">深度自动编码器</li><li id="1442" class="nc nd it kk b kl nn ko no kr np kv nq kz nr ld nj nk nl nm bi translated">模型实现</li></ul><h1 id="c5a1" class="mr ly it bd lz ms ns mu mc mv nt mx mf jz nu ka mi kc nv kd ml kf nw kg mo nb bi translated"><strong class="ak"> 1。简介</strong></h1><p id="6c85" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr nx kt ku kv ny kx ky kz nz lb lc ld im bi translated">自动编码器是一种深度学习神经网络架构，在协作过滤领域实现了最先进的性能。在文章的第一部分，我会给你一个简单自动编码器及其扩展深度自动编码器背后的理论概述和基础数学。在第二部分中，我们将深入实践，我将一步一步向你展示如何在<em class="oa"> TensorFlow </em>中实现这一技术。在本文中，我将只包括和评论模型中最重要的部分。整个模型、输入管道和预处理可以在相应的<a class="ae mq" href="https://github.com/artem-oppermann/Deep-Autoencoders-For-Collaborative-Filtering" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中查看。</p><h1 id="d2dc" class="mr ly it bd lz ms ns mu mc mv nt mx mf jz nu ka mi kc nv kd ml kf nw kg mo nb bi translated">2.深度自动编码器</h1><h2 id="f2d3" class="lx ly it bd lz ma mb dn mc md me dp mf kr mg mh mi kv mj mk ml kz mm mn mo mp bi translated">自动编码器</h2><p id="c0e1" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr nx kt ku kv ny kx ky kz nz lb lc ld im bi translated">在我们关注深度自动编码器之前，我们应该讨论它的简单版本。自动编码器<strong class="kk iu"> </strong>是一种人工神经网络，用于学习一组输入数据的表示(编码)，通常是为了实现降维。</p><p id="94db" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在架构上，自动编码器的形式是一个前馈神经网络，具有一个输入层、一个隐藏层和一个输出层(图1)。输出层具有与输入层相同数量的神经元，用于重建其自身的输入。这使得自动编码器成为一种无监督学习的形式，这意味着不需要标记数据，只需要一组输入数据，而不是输入输出对。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi ob"><img src="../Images/873b4b23781c00085ad53fb6fe3cc4c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uz3sGf9XyLyD5AfcUE9n3w.png"/></div></div><figcaption class="oc od gj gh gi oe of bd b be z dk">Fig. 1. Typical AutoEncoder architecture.</figcaption></figure><p id="ec4a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">自动编码器的隐藏层比输入层小是很有用的。这种效果迫使模型通过学习数据中的相关性来创建隐藏层中数据的压缩表示。</p><p id="bbbb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从输入层到隐藏层的过渡被称为编码步骤，从隐藏层到输出层的过渡被称为解码步骤。我们也可以用数学方法将这些转换定义为映射:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi og"><img src="../Images/299ead54d8566d56c5772d3a8f868db5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*xFVV_IWWklbECNd58RiJHg.png"/></div></figure><p id="c3ff" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过将输入数据向量<strong class="kk iu"> <em class="oa"> x </em> </strong>乘以权重矩阵，添加偏置项，并对所得向量应用非线性运算<strong class="kk iu"> σ </strong>，例如sigmoid、tanh或整流线性单元，来实现映射。</p></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><blockquote class="oh oi oj"><p id="035c" class="ki kj oa kk b kl km ju kn ko kp jx kq ok ks kt ku ol kw kx ky om la lb lc ld im bi translated"><strong class="kk iu">即将推出:</strong> <em class="it">面向软件开发人员、数据分析师、学者和业内人士的高级深度学习教育</em></p><p id="8029" class="ki kj oa kk b kl km ju kn ko kp jx kq ok ks kt ku ol kw kx ky om la lb lc ld im bi translated"><em class="it">更多详情请看:</em><a class="ae mq" href="https://www.deeplearning-academy.com/" rel="noopener ugc nofollow" target="_blank"><em class="it">www.deeplearning-academy.com</em></a></p></blockquote><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi on"><img src="../Images/e610ab27a85f76f7836d01406052d725.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9WtNs-E4aUH5YRhBnPjouA.png"/></div></div><figcaption class="oc od gj gh gi oe of bd b be z dk"><a class="ae mq" href="https://www.deeplearning-academy.com/" rel="noopener ugc nofollow" target="_blank">www.deeplearning-academy.com</a></figcaption></figure></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h2 id="b6cb" class="lx ly it bd lz ma mb dn mc md me dp mf kr mg mh mi kv mj mk ml kz mm mn mo mp bi translated">自动编码器的训练</h2><p id="acfe" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr nx kt ku kv ny kx ky kz nz lb lc ld im bi translated">在训练时间期间，编码器获取输入数据样本<strong class="kk iu"> <em class="oa"> </em> x </strong>并将其映射到所谓的隐藏或潜在表示<strong class="kk iu"> z. <em class="oa"> </em> </strong>，然后解码器将<strong class="kk iu"> z </strong>映射到输出矢量<strong class="kk iu"/>x’，该矢量(在最佳情况下)是输入数据<strong class="kk iu"> x </strong>的精确表示。请注意，通常不可能精确重建输入<strong class="kk iu"> x </strong>。</p><p id="6182" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">具有输出<strong class="kk iu">x’</strong>训练包括应用随机梯度下降以最小化预定义损失，例如均方误差:</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/b510e1d7ed04935d8df3117e0eecc6c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*7832daxQNhPwfsG_KyNsxQ.png"/></div></figure><h2 id="9547" class="lx ly it bd lz ma mb dn mc md me dp mf kr mg mh mi kv mj mk ml kz mm mn mo mp bi translated">深度自动编码器</h2><p id="8f94" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr nx kt ku kv ny kx ky kz nz lb lc ld im bi translated">简单自动编码器的扩展是深度自动编码器(图2)。从图2中可以看出，它的简单配对部分的唯一区别是隐藏层的数量。</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="gh gi op"><img src="../Images/7b24314c09bfdad9546e8ba24d98daff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K4GE_EWyU1jKNJ4UmajGFQ.png"/></div></div><figcaption class="oc od gj gh gi oe of bd b be z dk">Fig. 2. Deep Autoencoder architecture.</figcaption></figure><p id="4efa" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">附加的隐藏层使自动编码器能够从数学上学习数据中更复杂的潜在模式。深度自动编码器的第一层可以学习原始输入中的一阶特征(例如图像中的边缘)。第二层可以学习与一阶特征的外观中的模式相对应的二阶特征(例如，在什么边缘倾向于一起出现方面——例如，形成轮廓或角检测器)。深度自动编码器的更深层倾向于学习甚至更高阶的特征。</p><p id="5e7d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">总而言之:我们需要额外的层来处理更复杂的数据——比如我们在协同过滤中使用的数据。</p><h1 id="af84" class="mr ly it bd lz ms ns mu mc mv nt mx mf jz nu ka mi kc nv kd ml kf nw kg mo nb bi translated">3.履行</h1><p id="c89a" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr nx kt ku kv ny kx ky kz nz lb lc ld im bi translated">如前所述，你将学会预测用户对电影的评价。为此，我们将使用著名的<em class="oa"> </em> <a class="ae mq" href="https://grouplens.org/datasets/movielens/" rel="noopener ugc nofollow" target="_blank"> <em class="oa">电影镜头</em>数据集。</a> <em class="oa"> MovieLens </em>是一个基于网络的推荐系统和在线社区，为用户推荐电影观看。</p><p id="3310" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">更具体地说，我们将使用<em class="oa"> ml-1m.zip </em>数据集，该数据集包含6，040 <em class="oa"> MovieLens </em>用户制作的约3，900部电影的1，000，209个匿名评级。我们需要的导入文件是<em class="oa"> ratings.dat. </em>这个文件包含1，000，209行，都具有以下格式:user _ id::movie _ id::rating:time _ stamp。</p><p id="f057" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">例如<em class="oa"> ratings.dat中的第一行:</em></p><pre class="lf lg lh li gt oq or os ot aw ou bi"><span id="769e" class="lx ly it or b gy ov ow l ox oy">1::595::5::978824268  </span></pre><p id="33c8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">意味着用户号。1给电影编号。595 a五星评级。时间戳可以忽略，因为它不会被使用。</p><p id="ed1a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们实现的深度学习模型需要特定的数据结构来进行训练和测试。这个数据结构是一个<em class="oa"> U </em> x <em class="oa"> M </em>矩阵，其中<em class="oa"> U </em>是用户数量，而<em class="oa"> M </em>是电影数量。每行<em class="oa"> i </em> ∈ <em class="oa"> U </em>是唯一的用户id，每列<em class="oa"> j </em> ∈ <em class="oa"> M </em>是唯一的电影id。这种矩阵的可视化可以在图3中看到</p><figure class="lf lg lh li gt lj gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/a85378a4ab7fb8f05efe7599e0d0688c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*FTNd5l6pXpVnGwHztQ1kgQ.png"/></div></figure><p id="a09a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这个矩阵中的每个条目都是用户对一部特定电影的评价。条目0表示用户没有给这部电影任何评价。例如，用户1给电影3的评级是4星，而电影1根本没有评级。</p><p id="031a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">由于本教程的重点是深度学习模型的实现，所以这里不介绍从<em class="oa"> ratings.dat </em>文件中制作用户电影矩阵的步骤。关于这个主题的更多问题，我想把你重定向到我的<a class="ae mq" href="https://github.com/artem-oppermann/Deep-Autoencoders-For-Collaborative-Filtering" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>，在那里你可以检查相应的python脚本。</p><h2 id="615c" class="lx ly it bd lz ma mb dn mc md me dp mf kr mg mh mi kv mj mk ml kz mm mn mo mp bi translated">训练和测试数据集</h2><p id="0a52" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr nx kt ku kv ny kx ky kz nz lb lc ld im bi translated">在模型可以被实现和训练之前，数据的另一个再处理步骤是必要的——将数据分成训练和测试数据集。这一步非常简单。到目前为止，我们有一个用户-电影矩阵，其中每一行都是评级列表。为了从该列表中获得训练集和测试集，我们必须从每一行中取出评级的子集，并且仅将它们用于训练，而将剩余的子集仅用于测试。</p><p id="ee99" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">作为所述过程的一个例子，让我们考虑仅由15部电影组成的小得多的数据集。特定用户可能给了这些电影以下评级:</p><pre class="lf lg lh li gt oq or os ot aw ou bi"><span id="90e3" class="lx ly it or b gy ov ow l ox oy">Movie Nr. : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15</span><span id="c30f" class="lx ly it or b gy pa ow l ox oy">Rating:     5 0 2 4 0 0 2 1 5  1  0  4  5  1  3</span></pre><p id="8fd4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请记住，0表示电影未分级。现在，我们将由前10部电影组成的子集作为训练集，并假设其余的电影尚未分级:</p><pre class="lf lg lh li gt oq or os ot aw ou bi"><span id="87b7" class="lx ly it or b gy ov ow l ox oy">Movie Nr. : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15</span><span id="ecc3" class="lx ly it or b gy pa ow l ox oy">Rating:     5 0 2 4 0 0 2 1 5  0  0  0  0  0  0</span></pre><p id="ee09" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因此，原始数据的最后5个电影分级被用作测试数据，而电影1-10被屏蔽为未分级:</p><pre class="lf lg lh li gt oq or os ot aw ou bi"><span id="946a" class="lx ly it or b gy ov ow l ox oy">Movie Nr. : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15</span><span id="5892" class="lx ly it or b gy pa ow l ox oy">Rating:     0 0 0 0 0 0 0 0 0  1  0  4  5  1  3</span></pre><p id="128b" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这只是一个简单的演示如何获得不同的集合。在最初的<em class="oa"> MovieLens </em>数据集中，我对每个用户只使用了10个电影评级进行测试，而其余的(绝大多数)用于模型的训练。</p><h2 id="3267" class="lx ly it bd lz ma mb dn mc md me dp mf kr mg mh mi kv mj mk ml kz mm mn mo mp bi translated">TensorFlow实现</h2><h2 id="de29" class="lx ly it bd lz ma mb dn mc md me dp mf kr mg mh mi kv mj mk ml kz mm mn mo mp bi translated">模型架构</h2><p id="db27" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr nx kt ku kv ny kx ky kz nz lb lc ld im bi translated">深度自动编码器被实现为一个类，具有所有必要的操作，如推理、优化、丢失、准确性等。在课堂上。</p><p id="8cde" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在构造函数中，为权重和偏差设置了内核初始化器。在下一步中，网络中的所有权重和偏差都被初始化。权重呈正态分布，平均值为0.0，方差为0.02，而偏差在开始时都设置为0.0。</p><p id="da2a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个特定的例子中，网络有三个隐藏层，每个包含128个神经元。输入层(和输出层)的大小对应于数据集中所有当前电影的数量。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="pb pc l"/></div></figure><h2 id="feda" class="lx ly it bd lz ma mb dn mc md me dp mf kr mg mh mi kv mj mk ml kz mm mn mo mp bi translated">培养</h2><p id="c186" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr nx kt ku kv ny kx ky kz nz lb lc ld im bi translated">给定输入数据样本<strong class="kk iu"> x </strong>(用户电影矩阵的一行)，进行计算网络输出的正向传递。隐藏层使用sigmoid作为激活函数。请注意，最后一层既没有非线性也没有偏置项。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="b821" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有了网络预测，我们可以计算这些预测和相应标签之间的损失(网络输入<strong class="kk iu"> x </strong>)。为了计算损失的平均值，我们还需要知道非零标签的数量，换句话说，就是用户在训练集中的总评分数。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="pb pc l"/></div></figure><p id="b4f7" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">网络的优化/训练步骤可能会显得有点棘手，让我们一步一步来讨论。给定一个输入<strong class="kk iu"> <em class="oa"> x </em> </strong>计算相应的输出。正如您可能已经注意到的，输入<strong class="kk iu"> <em class="oa"> x </em> </strong>中的大多数值都是零值，因为用户几乎肯定没有观看数据集中的所有5953部电影并对其进行评级。因此，建议不要直接使用网络的原始预测。相反，我们必须识别数据输入<strong class="kk iu"> <em class="oa"> x </em> </strong>中零值的索引，并将对应于这些索引的预测向量中的值也设置为零。这种对预测的操纵极大地减少了网络的训练时间，使网络有机会将其训练努力仅集中在用户实际做出的评级上。</p><p id="5e01" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这个步骤之后，可以计算损失以及正则化损失(可选)。AdamOptimizer将损失函数降至最低。请注意，该方法返回的是均方根误差(RMSE ),而不是均方误差(MSE ),测量精度更高。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="pb pc l"/></div></figure><h2 id="aae2" class="lx ly it bd lz ma mb dn mc md me dp mf kr mg mh mi kv mj mk ml kz mm mn mo mp bi translated">测试</h2><p id="fc38" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr nx kt ku kv ny kx ky kz nz lb lc ld im bi translated">在训练阶段的一些时期之后，神经网络已经多次看到每个用户的训练数据集中的所有评级。此时，模型应该已经学习了数据中的潜在隐藏模式以及用户的相应协作电影品味。给定用户评级训练样本<strong class="kk iu"> x </strong>，模型预测输出<strong class="kk iu">x’</strong>。该向量由输入<strong class="kk iu"> x </strong>的重建组成(如预期的那样)，但现在也包含输入<strong class="kk iu"> x </strong>中先前零额定值的值。这意味着该模型对尚未分级的电影进行了分级。这种评级对应于用户的喜好——模型从数据中识别和学习到的喜好。</p><p id="ee12" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了测量模型的准确性，需要训练和测试数据集。基于训练集进行预测。类似于训练阶段，我们仅考虑与测试集中非零值的索引相对应的输出值。</p><p id="4598" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，我们可以计算预测和实际评级之间的均方根误差损失(RMSE)。RMSE表示预测值和观察值之间差异的样本标准差。例如，0.5的RMSE意味着平均而言，预测评级偏离实际评级0.5颗星。</p><figure class="lf lg lh li gt lj"><div class="bz fp l di"><div class="pb pc l"/></div></figure><h2 id="5ece" class="lx ly it bd lz ma mb dn mc md me dp mf kr mg mh mi kv mj mk ml kz mm mn mo mp bi translated">培训结果</h2><p id="bedc" class="pw-post-body-paragraph ki kj it kk b kl ne ju kn ko nf jx kq kr nx kt ku kv ny kx ky kz nz lb lc ld im bi translated">最后一步是执行培训过程并检查模型的性能。在这一点上，我不会进入构建数据输入管道、图形、会话等的细节。因为这些步骤是众所周知的。对这个话题感兴趣的读者可以在我的<a class="ae mq" href="https://github.com/artem-oppermann/Deep-Autoencoders-For-Collaborative-Filtering/blob/master/train.py" rel="noopener ugc nofollow" target="_blank"> GitHub资源库</a>中查看这些步骤。</p><p id="db44" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这里，您可以观察前50个时期的训练和测试性能。在50个时期之后，我们在测试集上得到预测和实际评级之间的0.929星偏差。</p><pre class="lf lg lh li gt oq or os ot aw ou bi"><span id="4810" class="lx ly it or b gy ov ow l ox oy">epoch_nr: 0,  train_loss: 1.169, test_loss: 1.020<br/>epoch_nr: 10, train_loss: 0.936, test_loss: 0.959<br/>epoch_nr: 20, train_loss: 0.889, test_loss: 0.931<br/>epoch_nr: 30, train_loss: 0.873, test_loss: 0.923<br/>epoch_nr: 40, train_loss: 0.859, test_loss: 0.925<br/>epoch_nr: 50, train_loss: 0.844, test_loss: 0.929</span></pre></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h2 id="309e" class="lx ly it bd lz ma mb dn mc md me dp mf kr mg mh mi kv mj mk ml kz mm mn mo mp bi translated">如果你喜欢这篇文章，想分享你的想法，问问题或保持联系，请随时通过LinkedIn与我联系。</h2></div><div class="ab cl lq lr hx ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="im in io ip iq"><h2 id="fec1" class="lx ly it bd lz ma mb dn mc md me dp mf kr mg mh mi kv mj mk ml kz mm mn mo mp bi translated">参考</h2><div class="pd pe gp gr pf pg"><a href="https://github.com/artem-oppermann/Deep-Autoencoders-For-Collaborative-Filtering" rel="noopener  ugc nofollow" target="_blank"><div class="ph ab fo"><div class="pi ab pj cl cj pk"><h2 class="bd iu gy z fp pl fr fs pm fu fw is bi translated">artem-opper Mann/Deep-auto encoders-For-Collaborative-Filtering</h2><div class="pn l"><h3 class="bd b gy z fp pl fr fs pm fu fw dk translated">深度自动编码器-用于协同过滤-使用深度自动编码器预测电影分级。</h3></div><div class="po l"><p class="bd b dl z fp pl fr fs pm fu fw dk translated">github.com</p></div></div><div class="pp l"><div class="pq l pr ps pt pp pu lo pg"/></div></div></a></div><p id="7d1e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae mq" href="http://proceedings.mlr.press/v27/baldi12a/baldi12a.pdf" rel="noopener ugc nofollow" target="_blank">http://proceedings.mlr.press/v27/baldi12a/baldi12a.pdf</a></p><p id="48d5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">http://deeplearning.net/tutorial/SdA.html<a class="ae mq" href="http://deeplearning.net/tutorial/SdA.html" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>