<html>
<head>
<title>Introduction to Natural Language Processing for Text</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本自然语言处理导论</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-natural-language-processing-for-text-df845750fb63?source=collection_archive---------0-----------------------#2018-11-17">https://towardsdatascience.com/introduction-to-natural-language-processing-for-text-df845750fb63?source=collection_archive---------0-----------------------#2018-11-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/bbaa359609bc0d8eaeebeefbf4e8f514.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CuPIUoh1nvh_r1Ssqmy8SA.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Icons source: <a class="ae kc" href="https://iconfinder.com" rel="noopener ugc nofollow" target="_blank">https://iconfinder.com</a></figcaption></figure><p id="f027" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">看完这篇博文，你会知道一些从一些<strong class="kf ir">文本</strong>中<strong class="kf ir">提取特征的基本技术，所以你可以把这些特征作为<strong class="kf ir">机器学习模型</strong>的<strong class="kf ir">输入</strong>。</strong></p><h1 id="107b" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">什么是 NLP(自然语言处理)？</h1><p id="2584" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">NLP 是计算机科学和人工智能的一个子领域，涉及计算机和人类(自然)语言之间的交互。用于将<strong class="kf ir">机器学习</strong>算法应用于<strong class="kf ir">文本</strong>和<strong class="kf ir">语音</strong>。</p><p id="4b9f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，我们可以使用 NLP 创建类似于<strong class="kf ir">语音识别</strong>、<strong class="kf ir">文档摘要</strong>、<strong class="kf ir">机器翻译</strong>、<strong class="kf ir">垃圾邮件检测</strong>、<strong class="kf ir">命名实体识别</strong>、<strong class="kf ir">问题回答、自动完成、预测打字</strong>等系统。</p><p id="cdbc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如今，我们大多数人的智能手机都有语音识别功能。这些智能手机使用 NLP 来理解所说的内容。此外，许多人使用操作系统内置语音识别的笔记本电脑。</p><h2 id="c54d" class="me lc iq bd ld mf mg dn lh mh mi dp ll ko mj mk lp ks ml mm lt kw mn mo lx mp bi translated">一些例子</h2><p id="b58d" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated"><strong class="kf ir"> Cortana </strong></p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mq"><img src="../Images/5d791dbb42e8fc14ddb6ac67d3324c22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TXj0kr4jVrtLtmvxZFu8Lw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Source: <a class="ae kc" href="https://blogs.technet.microsoft.com/microsoft_presse/auf-diesen-4-saeulen-basiert-cortanas-persoenlichkeit/" rel="noopener ugc nofollow" target="_blank">https://blogs.technet.microsoft.com/microsoft_presse/auf-diesen-4-saeulen-basiert-cortanas-persoenlichkeit/</a></figcaption></figure><p id="60dd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">微软 OS 有一个名为<a class="ae kc" href="https://support.microsoft.com/en-us/help/17214/windows-10-what-is" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir"> Cortana </strong> </a>的虚拟助手，可以识别一个<strong class="kf ir">自然语音</strong>。你可以用它来设置提醒、打开应用程序、发送电子邮件、玩游戏、跟踪航班和包裹、查看天气等等。</p><p id="0c62" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以从<a class="ae kc" href="https://www.howtogeek.com/225458/15-things-you-can-do-with-cortana-on-windows-10/" rel="noopener ugc nofollow" target="_blank">这里</a>阅读更多关于 Cortana 命令的内容。</p><p id="cd7f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> Siri </strong></p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mv"><img src="../Images/addc34a1c616b3512141fd232cedd79a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-AuKCZbXIVOhI-AgX4J8PQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Source: <a class="ae kc" href="https://www.analyticsindiamag.com/behind-hello-siri-how-apples-ai-powered-personal-assistant-uses-dnn/" rel="noopener ugc nofollow" target="_blank">https://www.analyticsindiamag.com/behind-hello-siri-how-apples-ai-powered-personal-assistant-uses-dnn/</a></figcaption></figure><p id="dcd6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Siri 是苹果公司 iOS、watchOS、macOS、HomePod 和 tvOS 操作系统的虚拟助手。同样，你可以用<strong class="kf ir">语音</strong> <strong class="kf ir">命令</strong>做很多事情:开始通话、给某人发短信、发送电子邮件、设置定时器、拍照、打开应用程序、设置闹钟、使用导航等等。</p><p id="95e8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://www.cnet.com/how-to/the-complete-list-of-siri-commands/" rel="noopener ugc nofollow" target="_blank">这里的</a>是所有 Siri 命令的完整列表。</p><p id="45f3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> Gmail </strong></p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mw"><img src="../Images/e8f58f7d25dbef1f55da805db6e7b75b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*fTPhu7PqgIbnngbWG5zFWA.gif"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Source: <a class="ae kc" href="https://i.gifer.com/Ou1t.gif" rel="noopener ugc nofollow" target="_blank">https://i.gifer.com/Ou1t.gif</a></figcaption></figure><p id="0391" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">谷歌开发的著名电子邮件服务<strong class="kf ir"> Gmail </strong>正在使用<strong class="kf ir">垃圾邮件检测</strong>过滤掉一些垃圾邮件。</p><h1 id="da92" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">Python 的 NLTK 库简介</h1><p id="5a49" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">NLTK ( <strong class="kf ir">自然语言工具包</strong>)是一个<strong class="kf ir">领先的平台</strong>，用于构建 Python 程序来处理<strong class="kf ir">人类语言数据</strong>。它为众多的 <a class="ae kc" href="https://en.wikipedia.org/wiki/Text_corpus" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir">语料库</strong> </a>和<strong class="kf ir">词汇资源</strong>提供了易用的接口。此外，它还包含一套<strong class="kf ir">文本处理库</strong>，用于分类、标记化、词干化、标记、解析和语义推理。最棒的是，NLTK 是一个免费、开源、社区驱动的项目。</p><p id="024d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用这个工具包来展示自然语言处理领域的一些基础知识。对于下面的例子，我假设我们已经导入了 NLTK 工具包。我们可以这样做:<code class="fe mx my mz na b">import nltk</code>。</p><h1 id="4164" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">文本的自然语言处理基础</h1><p id="4e0d" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">在本文中，我们将讨论以下主题:</p><ol class=""><li id="5bae" class="nb nc iq kf b kg kh kk kl ko nd ks ne kw nf la ng nh ni nj bi translated">句子标记化</li><li id="8a7f" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la ng nh ni nj bi translated">单词标记化</li><li id="6c69" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la ng nh ni nj bi translated">文本词汇化和词干化</li><li id="4146" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la ng nh ni nj bi translated">停止言语</li><li id="69c2" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la ng nh ni nj bi translated">正则表达式</li><li id="9269" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la ng nh ni nj bi translated">词汇袋</li><li id="85ee" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la ng nh ni nj bi translated">TF-IDF</li></ol><h2 id="9773" class="me lc iq bd ld mf mg dn lh mh mi dp ll ko mj mk lp ks ml mm lt kw mn mo lx mp bi translated">1.句子标记化</h2><p id="416a" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">句子标记化(也叫<strong class="kf ir">句子切分</strong>就是<strong class="kf ir">把书面语<strong class="kf ir">的一串</strong>分割成</strong>其成分<strong class="kf ir">句子</strong>的问题。这里的想法看起来很简单。在英语和其他一些语言中，每当我们看到标点符号时，我们就可以把句子分开。</p><p id="99b8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，即使在英语中，由于缩写使用句号字符，这个问题也不是微不足道的。当处理纯文本时，包含句点的缩写表可以帮助我们防止错误分配<strong class="kf ir">句子边界</strong>。在很多情况下，我们使用库来完成这项工作，所以现在不要太担心细节。</p><p id="55a5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">例子</strong>:</p><p id="9f51" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们来看一段关于一个著名的棋盘游戏叫做双陆棋的课文。</p><blockquote class="np nq nr"><p id="4012" class="kd ke ns kf b kg kh ki kj kk kl km kn nt kp kq kr nu kt ku kv nv kx ky kz la ij bi translated">双陆棋是已知最古老的棋盘游戏之一。它的历史可以追溯到近 5000 年前中东的考古发现。这是一个两人游戏，每个人有 15 个跳棋，根据两个骰子的滚动在 24 个点之间移动。</p></blockquote><p id="5d1a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要用 NLTK 应用句子标记化，我们可以使用<code class="fe mx my mz na b">nltk.sent_tokenize</code>函数。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="e25f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作为输出，我们分别得到 3 个组成句子。</p><pre class="mr ms mt mu gt ny na nz oa aw ob bi"><span id="e473" class="me lc iq na b gy oc od l oe of">Backgammon is one of the oldest known board games.<br/><br/>Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East.<br/><br/>It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.</span></pre><h2 id="2067" class="me lc iq bd ld mf mg dn lh mh mi dp ll ko mj mk lp ks ml mm lt kw mn mo lx mp bi translated">2.单词标记化</h2><p id="159f" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">分词(也叫<strong class="kf ir">分词</strong>)就是<strong class="kf ir">把书面语<strong class="kf ir">的一串</strong>分割成</strong>它的成分<strong class="kf ir">词</strong>的问题。在英语和许多其他使用某种形式拉丁字母的语言中，空格是单词分隔符的一个很好的近似。</p><p id="44b0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，如果我们仅仅通过空间分割来实现想要的结果，我们仍然会有问题。一些英语复合名词有不同的写法，有时它们包含一个空格。在大多数情况下，我们使用一个库来实现想要的结果，所以不要太担心细节。</p><p id="5af4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">举例</strong>:</p><p id="8a66" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们使用上一步中的句子，看看如何对它们应用单词标记化。我们可以使用<code class="fe mx my mz na b">nltk.word_tokenize</code>函数。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="b155" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">输出:</p><pre class="mr ms mt mu gt ny na nz oa aw ob bi"><span id="0616" class="me lc iq na b gy oc od l oe of">['Backgammon', 'is', 'one', 'of', 'the', 'oldest', 'known', 'board', 'games', '.']<br/><br/>['Its', 'history', 'can', 'be', 'traced', 'back', 'nearly', '5,000', 'years', 'to', 'archeological', 'discoveries', 'in', 'the', 'Middle', 'East', '.']<br/><br/>['It', 'is', 'a', 'two', 'player', 'game', 'where', 'each', 'player', 'has', 'fifteen', 'checkers', 'which', 'move', 'between', 'twenty-four', 'points', 'according', 'to', 'the', 'roll', 'of', 'two', 'dice', '.']</span></pre><h2 id="0c8d" class="me lc iq bd ld mf mg dn lh mh mi dp ll ko mj mk lp ks ml mm lt kw mn mo lx mp bi translated">文本词汇化和词干化</h2><p id="cc28" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">出于语法原因，文档可以包含单词的<strong class="kf ir">不同形式，例如<em class="ns">驱动</em>、<em class="ns">驱动</em>、<em class="ns">驱动</em>。还有，有时候我们会用<strong class="kf ir">相关的词</strong>来表达类似的意思，比如<em class="ns">民族</em>、<em class="ns">国家</em>、<em class="ns">民族</em>。</strong></p><blockquote class="np nq nr"><p id="6e80" class="kd ke ns kf b kg kh ki kj kk kl km kn nt kp kq kr nu kt ku kv nv kx ky kz la ij bi translated"><strong class="kf ir">词干化</strong>和<strong class="kf ir">词汇化</strong>的目的都是为了<strong class="kf ir">将</strong> <a class="ae kc" href="https://en.wikipedia.org/wiki/Inflection" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir">屈折</strong> </a> <strong class="kf ir">形式</strong>以及有时将<strong class="kf ir">单词的衍生相关形式<strong class="kf ir"> </strong>缩减为</strong><strong class="kf ir">公共基础形式</strong>。</p></blockquote><p id="c85e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">来源:<a class="ae kc" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" rel="noopener ugc nofollow" target="_blank">https://NLP . Stanford . edu/IR-book/html/html edition/stemming-and-lemma tization-1 . html</a></p><p id="79aa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">例句</strong>:</p><ul class=""><li id="993f" class="nb nc iq kf b kg kh kk kl ko nd ks ne kw nf la og nh ni nj bi translated">是，是，是<code class="fe mx my mz na b">=&gt;</code>是</li><li id="e377" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated">狗，狗，狗的，狗的<code class="fe mx my mz na b">=&gt;</code>狗</li></ul><p id="9372" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">应用于文本的这种映射的结果将如下所示:</p><ul class=""><li id="377f" class="nb nc iq kf b kg kh kk kl ko nd ks ne kw nf la og nh ni nj bi translated">男孩的狗大小不同</li></ul><p id="49c9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">词干化和词汇化是<strong class="kf ir">规范化</strong>的特例。然而，它们彼此不同。</p><blockquote class="np nq nr"><p id="67df" class="kd ke ns kf b kg kh ki kj kk kl km kn nt kp kq kr nu kt ku kv nv kx ky kz la ij bi translated"><strong class="kf ir">词干</strong>通常指的是一种<strong class="kf ir">粗糙的</strong> <a class="ae kc" href="https://en.wikipedia.org/wiki/Heuristic" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir">启发式</strong> </a> <strong class="kf ir">过程</strong>，它砍掉单词的词尾，希望在大多数时候都能正确实现这一目标，通常还包括去除派生词缀。</p><p id="6723" class="kd ke ns kf b kg kh ki kj kk kl km kn nt kp kq kr nu kt ku kv nv kx ky kz la ij bi translated"><strong class="kf ir">词汇化</strong>通常是指<strong class="kf ir">使用<strong class="kf ir">词汇</strong>和<strong class="kf ir">单词的形态分析</strong>正确地做事情</strong>，通常旨在只去除屈折词尾并返回单词的基本或词典形式，这就是所谓的<strong class="kf ir">引理</strong>。</p></blockquote><p id="741d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">来源:<a class="ae kc" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" rel="noopener ugc nofollow" target="_blank">https://NLP . Stanford . edu/IR-book/html/html edition/stemming-and-lemma tization-1 . html</a></p><p id="fa62" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不同之处在于<strong class="kf ir">词干分析器</strong>在不了解上下文的情况下操作<strong class="kf ir">，因此无法理解根据词性而具有不同含义的单词之间的差异。但是词干分析器也有一些优点，它们更容易实现，通常 T21 运行得更快。此外，降低的“精度”对于某些应用来说可能无关紧要。</strong></p><p id="833e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">例子:</strong></p><ol class=""><li id="6ce8" class="nb nc iq kf b kg kh kk kl ko nd ks ne kw nf la ng nh ni nj bi translated">“更好”这个词的引理是“好”。这一环节被词干遗漏了，因为它需要查字典。</li><li id="a8ff" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la ng nh ni nj bi translated">单词“play”是单词“playing”的基本形式，因此它在词干和词汇化上都是匹配的。</li><li id="a7fc" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la ng nh ni nj bi translated">单词“meeting”可以是名词的基本形式，也可以是动词的形式(“to meet”)，这取决于上下文；例如，“在我们最后一次见面时”或“我们明天还会见面”。与词干提取不同，词汇化试图根据上下文选择正确的词汇。</li></ol><p id="c803" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们知道区别之后，让我们看一些使用 NLTK 工具的例子。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="0e67" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">输出:</p><pre class="mr ms mt mu gt ny na nz oa aw ob bi"><span id="80c5" class="me lc iq na b gy oc od l oe of">Stemmer: seen<br/>Lemmatizer: see<br/><br/>Stemmer: drove<br/>Lemmatizer: drive</span></pre><h2 id="0b95" class="me lc iq bd ld mf mg dn lh mh mi dp ll ko mj mk lp ks ml mm lt kw mn mo lx mp bi translated">停止言语</h2><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/1a74b5a411e88dbbc5ff9fb07e0e0a27.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*kMf7dZW4jTyaq1hxjA0pgg.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Source: <a class="ae kc" href="http://www.nepalinlp.com/detail/stop-words-removal_nepali/" rel="noopener ugc nofollow" target="_blank">http://www.nepalinlp.com/detail/stop-words-removal_nepali/</a></figcaption></figure><p id="37bf" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">停用词是在文本处理之前或之后从中过滤掉的词。在对文本应用机器学习时，这些词可以添加很多<strong class="kf ir">噪音</strong>。这就是为什么我们要去掉这些<strong class="kf ir">无关词</strong>。</p><p id="1fc5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">停用词<strong class="kf ir">通常是指<strong class="kf ir">中最常见的词</strong>如“<strong class="kf ir">、</strong>”、<strong class="kf ir">、</strong>、<strong class="kf ir">、</strong>”，但在一种语言中没有<strong class="kf ir">没有单一的停用词通用列表</strong>。停用字词的列表可以根据您的应用而改变。</strong></p><p id="7da9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">NLTK 工具有一个预定义的停用词列表，它引用最常用的词。如果是第一次使用，需要使用这个代码下载停用词:<code class="fe mx my mz na b">nltk.download(“stopwords”)</code>。一旦我们完成了下载，我们就可以从<code class="fe mx my mz na b">nltk.corpus</code>加载<code class="fe mx my mz na b">stopwords</code>包，并用它来加载停用词。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="9912" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">输出:</p><pre class="mr ms mt mu gt ny na nz oa aw ob bi"><span id="067d" class="me lc iq na b gy oc od l oe of">['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're", "you've", "you'll", "you'd", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', "she's", 'her', 'hers', 'herself', 'it', "it's", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', "that'll", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', "don't", 'should', "should've", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', "aren't", 'couldn', "couldn't", 'didn', "didn't", 'doesn', "doesn't", 'hadn', "hadn't", 'hasn', "hasn't", 'haven', "haven't", 'isn', "isn't", 'ma', 'mightn', "mightn't", 'mustn', "mustn't", 'needn', "needn't", 'shan', "shan't", 'shouldn', "shouldn't", 'wasn', "wasn't", 'weren', "weren't", 'won', "won't", 'wouldn', "wouldn't"]</span></pre><p id="f34b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看看如何从句子中去掉停用词。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="dac0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">输出:</p><pre class="mr ms mt mu gt ny na nz oa aw ob bi"><span id="8ec9" class="me lc iq na b gy oc od l oe of">['Backgammon', 'one', 'oldest', 'known', 'board', 'games', '.']</span></pre><p id="66ae" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你不熟悉 Python 中的<a class="ae kc" rel="noopener" target="_blank" href="/python-basics-list-comprehensions-631278f22c40"> <strong class="kf ir">列表理解</strong>。这里有另一种方法可以达到同样的效果。</a></p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="06a9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，请记住<strong class="kf ir">列表理解</strong>比<strong class="kf ir">更快</strong>，因为它们已经过<strong class="kf ir">优化</strong>，以便 Python 解释器在循环过程中发现可预测的模式。</p><p id="5463" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可能想知道为什么我们把我们的列表转换成一个<a class="ae kc" href="https://docs.python.org/3/tutorial/datastructures.html#sets" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir">集合</strong> </a>。Set 是一种抽象数据类型，可以存储唯一的值，没有任何特定的顺序。集合中的<strong class="kf ir">搜索操作</strong> <strong class="kf ir">比列表</strong>中的搜索操作<strong class="kf ir">快得多<strong class="kf ir"/><strong class="kf ir">。对于少量的单词，没有太大的区别，但是如果你有大量的单词，强烈建议使用 set 类型。</strong></strong></p><p id="74fb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你想了解更多关于不同数据结构的不同操作之间的时间消耗，你可以看看这个很棒的<a class="ae kc" href="http://bigocheatsheet.com/" rel="noopener ugc nofollow" target="_blank">备忘单</a>。</p><h2 id="7371" class="me lc iq bd ld mf mg dn lh mh mi dp ll ko mj mk lp ks ml mm lt kw mn mo lx mp bi translated">正则表达式</h2><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/4f1713a3294dad901a59fc992321614b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*l_EB11yQfbZsKLFr8ZckuQ.jpeg"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Source: <a class="ae kc" href="https://digitalfortress.tech/tricks/top-15-commonly-used-regex/" rel="noopener ugc nofollow" target="_blank">https://digitalfortress.tech/tricks/top-15-commonly-used-regex/</a></figcaption></figure><p id="c323" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">正则表达式</strong>、<strong class="kf ir"> regex </strong>或<strong class="kf ir"> regexp </strong>是定义<strong class="kf ir">搜索模式</strong>的字符序列。让我们看看一些基本的。</p><ul class=""><li id="da70" class="nb nc iq kf b kg kh kk kl ko nd ks ne kw nf la og nh ni nj bi translated"><code class="fe mx my mz na b">.</code> -匹配除换行符之外的任意字符<strong class="kf ir"/></li><li id="72dc" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><code class="fe mx my mz na b">\w</code> -匹配<strong class="kf ir">字</strong></li><li id="5207" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><code class="fe mx my mz na b">\d</code> -匹配<strong class="kf ir">数字</strong></li><li id="6735" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><code class="fe mx my mz na b">\s</code> -匹配<strong class="kf ir">空格</strong></li><li id="d972" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><code class="fe mx my mz na b">\W</code>——配<strong class="kf ir">不字</strong></li><li id="543c" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><code class="fe mx my mz na b">\D</code> -匹配<strong class="kf ir">而非数字</strong></li><li id="2122" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><code class="fe mx my mz na b">\S</code> -匹配<strong class="kf ir">而不是空白</strong></li><li id="e917" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><code class="fe mx my mz na b">[abc]</code> -匹配 a、b 或 c 中的任意一个</li><li id="14cf" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><code class="fe mx my mz na b">[<strong class="kf ir">^</strong>abc]</code> - <strong class="kf ir">不</strong>匹配 a、b 或 c</li><li id="7cc6" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><code class="fe mx my mz na b">[a<strong class="kf ir">-</strong>g]</code> -在和&amp; g 之间匹配一个字符<strong class="kf ir"/></li></ul><blockquote class="np nq nr"><p id="3909" class="kd ke ns kf b kg kh ki kj kk kl km kn nt kp kq kr nu kt ku kv nv kx ky kz la ij bi translated">正则表达式使用<strong class="kf ir">反斜杠字符</strong> ( <code class="fe mx my mz na b">'\'</code>)来表示特殊形式，或者允许使用特殊字符而不调用它们的特殊含义。这个<strong class="kf ir">与 Python 在字符串文字中出于相同目的使用相同字符的用法</strong>相冲突；例如，要匹配一个文字反斜杠，可能必须将<code class="fe mx my mz na b">'\\\\'</code>写成模式字符串，因为正则表达式必须是<code class="fe mx my mz na b">\\</code>，并且每个反斜杠必须在一个常规 Python 字符串文字中表示为<code class="fe mx my mz na b">\\</code>。</p><p id="86c7" class="kd ke ns kf b kg kh ki kj kk kl km kn nt kp kq kr nu kt ku kv nv kx ky kz la ij bi translated">解决方案是将 Python 的<strong class="kf ir">原始字符串符号</strong>用于正则表达式模式；以 <code class="fe mx my mz na b"><strong class="kf ir">'r'</strong></code>为前缀的字符串文字<strong class="kf ir">中的反斜杠没有任何特殊的处理方式。所以<code class="fe mx my mz na b">r"\n"</code>是包含<code class="fe mx my mz na b">'\'</code>和<code class="fe mx my mz na b">'n'</code>的双字符字符串，而<code class="fe mx my mz na b">"\n"</code>是包含换行符的单字符字符串。通常，模式将使用这种原始字符串符号在 Python 代码中表示。</strong></p></blockquote><p id="ba7d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">来源:<a class="ae kc" href="https://docs.python.org/3/library/re.html?highlight=regex" rel="noopener ugc nofollow" target="_blank">https://docs.python.org/3/library/re.html?highlight=regex</a></p><p id="adfa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以使用正则表达式将<strong class="kf ir">附加过滤</strong>应用到我们的文本中。例如，我们可以删除所有非单词字符。在许多情况下，我们不需要标点符号，用正则表达式很容易删除它们。</p><p id="1194" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在 Python 中，<code class="fe mx my mz na b"><strong class="kf ir">re</strong></code>模块提供了类似于 Perl 中的正则表达式匹配操作。我们可以使用<code class="fe mx my mz na b"><strong class="kf ir">re.sub</strong></code>函数用替换字符串替换模式的匹配。让我们看一个用空格字符替换所有非单词的例子。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="8942" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">输出:</p><pre class="mr ms mt mu gt ny na nz oa aw ob bi"><span id="9fe6" class="me lc iq na b gy oc od l oe of">'The development of snowboarding was inspired by skateboarding  sledding  surfing and skiing '</span></pre><p id="e383" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正则表达式是一个强大的工具，我们可以创建更复杂的模式。如果你想了解更多关于 regex 的知识，我可以推荐你试试这两个 web 应用:<a class="ae kc" href="https://regexr.com/" rel="noopener ugc nofollow" target="_blank"> regex </a> r，<a class="ae kc" href="https://regex101.com/" rel="noopener ugc nofollow" target="_blank"> regex101 </a>。</p><h2 id="01b2" class="me lc iq bd ld mf mg dn lh mh mi dp ll ko mj mk lp ks ml mm lt kw mn mo lx mp bi translated">词汇袋</h2><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/17b54aecfc1b8c06f91601277bdd18c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*RPezKXGUUwla-JP52OnZxA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Source: <a class="ae kc" href="https://www.iconfinder.com/icons/299088/bag_icon" rel="noopener ugc nofollow" target="_blank">https://www.iconfinder.com/icons/299088/bag_icon</a></figcaption></figure><p id="134b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">机器学习算法不能直接处理原始文本，我们需要将文本转换成数字向量。这叫做<a class="ae kc" href="https://en.wikipedia.org/wiki/Feature_extraction" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir">特征提取</strong> </a>。</p><p id="1f64" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">词袋</strong>模型是一种<strong class="kf ir">流行的</strong>和<strong class="kf ir">简单的</strong> <strong class="kf ir">特征提取技术</strong>在我们处理文本时使用。它描述了文档中每个单词的出现。</p><p id="fffd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要使用该模型，我们需要:</p><ol class=""><li id="d244" class="nb nc iq kf b kg kh kk kl ko nd ks ne kw nf la ng nh ni nj bi translated">设计一个已知单词的<strong class="kf ir">词汇表</strong>(也叫<strong class="kf ir">记号</strong>)</li><li id="25aa" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la ng nh ni nj bi translated">选择已知单词存在的<strong class="kf ir">度量</strong></li></ol><p id="6447" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">任何关于单词<strong class="kf ir">的顺序</strong>或<strong class="kf ir">结构</strong>的信息都被丢弃。这就是为什么它被称为单词的<strong class="kf ir">袋</strong>。该模型试图理解一个已知单词是否出现在文档中，但不知道该单词在文档中的位置。</p><p id="83a6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">直觉是<strong class="kf ir">相似文档</strong>有<strong class="kf ir">相似内容</strong>。同样，从一个内容中，我们可以了解一些关于文档的含义。</p><h2 id="8ceb" class="me lc iq bd ld mf mg dn lh mh mi dp ll ko mj mk lp ks ml mm lt kw mn mo lx mp bi translated"><strong class="ak">例子</strong></h2><p id="5920" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">我们来看看创建词袋模型有哪些步骤。在这个例子中，我们将用四个句子来看看这个模型是如何工作的。在现实世界的问题中，您将处理大量的数据。</p><p id="59d9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 1。加载数据</strong></p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/a7d5eecaac3a5f13d9186d165978455c.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*JTi6Bnodv2sui50F96v7-Q.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Source: <a class="ae kc" href="https://www.iconfinder.com/icons/315166/note_text_icon" rel="noopener ugc nofollow" target="_blank">https://www.iconfinder.com/icons/315166/note_text_icon</a></figcaption></figure><p id="465e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设这是我们的数据，我们想把它作为一个数组加载。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="1cfc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要做到这一点，我们可以简单地读取文件，并按行分割。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="4009" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">输出:</p><pre class="mr ms mt mu gt ny na nz oa aw ob bi"><span id="72f4" class="me lc iq na b gy oc od l oe of">["I like this movie, it's funny.", 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.']</span></pre><p id="b74c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 2。</strong> <strong class="kf ir">设计词汇</strong></p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/a17f097260a54c5e550d769f6e5278f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*AFUcM9S6FwX7RNTW4zqtLQ.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Source: <a class="ae kc" href="https://www.iconfinder.com/icons/2109153/book_contact_dairy_google_service_icon" rel="noopener ugc nofollow" target="_blank">https://www.iconfinder.com/icons/2109153/book_contact_dairy_google_service_icon</a></figcaption></figure><p id="d008" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们从四个加载的句子中获取所有独特的单词，忽略大小写、标点和单字符标记。这些单词将成为我们的词汇(已知单词)。</p><p id="dc4a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们可以使用 sklearn 库中的<a class="ae kc" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir">计数矢量器</strong> </a>类来设计我们的词汇表。我们也将在阅读下一步后看看如何使用它。</p><p id="d817" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 3。创建文档向量</strong></p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/ae2a38c3377e526895c10b2c56bb4603.png" data-original-src="https://miro.medium.com/v2/resize:fit:256/format:webp/1*90Wv4B73KktRNU9NcYdpjg.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Source: <a class="ae kc" href="https://www.iconfinder.com/icons/1574/binary_icon" rel="noopener ugc nofollow" target="_blank">https://www.iconfinder.com/icons/1574/binary_icon</a></figcaption></figure><p id="2a55" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们需要对每个文档中的单词进行评分。这里的任务是将每个原始文本转换成一个数字向量。之后，我们可以使用这些向量作为机器学习模型的输入。最简单的评分方法是用 1 代表存在，0 代表不存在来标记单词的存在。</p><p id="02b3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，让我们看看如何使用上面提到的 CountVectorizer 类创建一个单词袋模型。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="c31b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">输出</strong>:</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/03a60d75ba011dafb66b2f321cb8f861.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*f5e9vn4EZB8zNSLWO0dn-A.png"/></div></figure><p id="513d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是我们的句子。现在我们可以看到单词袋模型是如何工作的。</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi om"><img src="../Images/daf8f4bc8854e7811fe9c0817c56cb72.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*LtMJ1qSiIuEzZDqB-RQbjw.png"/></div></figure><h2 id="efe2" class="me lc iq bd ld mf mg dn lh mh mi dp ll ko mj mk lp ks ml mm lt kw mn mo lx mp bi translated">关于单词袋模型的补充说明</h2><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/65a8741a342988b2134d88d70097b026.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*JvmcnIYVAzxHYdrxtmMa3Q.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Source: <a class="ae kc" href="https://www.iconfinder.com/icons/1118207/clipboard_notes_pen_pencil_icon" rel="noopener ugc nofollow" target="_blank">https://www.iconfinder.com/icons/1118207/clipboard_notes_pen_pencil_icon</a></figcaption></figure><p id="d6dc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">单词袋模型的<strong class="kf ir">复杂性</strong>来自于决定如何<strong class="kf ir">设计已知单词(记号)的词汇表</strong>以及如何<strong class="kf ir">对已知单词的存在</strong>进行评分。</p><p id="92aa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">设计词汇</strong> <br/>当词汇<strong class="kf ir">大小增加</strong>时，文档的向量表示也增加。在上面的例子中，文档向量的长度等于已知单词的数量。</p><p id="c0e9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在某些情况下，我们可能有<strong class="kf ir">大量的数据</strong>，在这种情况下，表示文档的向量的长度可能是<strong class="kf ir">数千或数百万个</strong>元素。此外，每个文档可能只包含词汇表中的几个已知单词。</p><p id="5365" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，矢量表示将有<strong class="kf ir">个零</strong>。这些有很多零的向量被称为<strong class="kf ir">稀疏向量</strong>。它们需要更多的内存和计算资源。</p><p id="ece1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当使用单词袋模型来减少所需的内存和计算资源时，我们可以减少已知单词的数量。在创建我们的单词袋模型之前，我们可以使用我们已经在本文中看到的<strong class="kf ir">文本清理技术</strong>:</p><ul class=""><li id="8007" class="nb nc iq kf b kg kh kk kl ko nd ks ne kw nf la og nh ni nj bi translated"><strong class="kf ir">忽略大小写</strong>的字样</li><li id="498b" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><strong class="kf ir">忽略标点符号</strong></li><li id="cda7" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><strong class="kf ir">从我们的文档中删除</strong>和<strong class="kf ir">停用词</strong></li><li id="2db7" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated">将单词简化为基本形式(<strong class="kf ir">文本词条化和词干化</strong>)</li><li id="6ae2" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><strong class="kf ir">修复拼错的单词</strong></li></ul><p id="a398" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一种更复杂的创建词汇表的方法是使用<strong class="kf ir">分组单词</strong>。这改变了词汇表的<strong class="kf ir">范围</strong>，并允许单词袋模型获得关于文档的更多细节。这种方法被称为<strong class="kf ir"> n-grams </strong>。</p><p id="864e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个 n-gram 是一个由若干<strong class="kf ir">项</strong>(单词、字母、数字、数位等)组成的<strong class="kf ir">序列。).在<a class="ae kc" href="https://en.wikipedia.org/wiki/Text_corpus" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir">文本语料库</strong> </a>的上下文中，n-grams 一般是指一个单词序列。一个<strong class="kf ir">一元词</strong>是一个词，一个<strong class="kf ir">二元词</strong>是两个词的序列，一个<strong class="kf ir">三元词</strong>是三个词的序列，等等。“n-gram”中的“n”是指分组单词的数量。仅对语料库中出现的 n 元文法进行建模，而不是所有可能的 n 元文法。</strong></p><p id="c32b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">例句</strong> <br/>让我们看看下面这个句子的所有二元模型:<br/> <code class="fe mx my mz na b">The office building is open today</code></p><p id="42a9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所有的二元模型是:</p><ul class=""><li id="bac0" class="nb nc iq kf b kg kh kk kl ko nd ks ne kw nf la og nh ni nj bi translated">办公室</li><li id="18eb" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated">办公楼</li><li id="5afd" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated">建筑是</li><li id="4e89" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated">已打开</li><li id="bc2b" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated">今天开门</li></ul><p id="96f5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">二元模型袋</strong>比词汇袋方法更强大。</p><p id="ab9f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">给单词打分<br/> </strong>一旦我们创建了已知单词的词汇表，我们就需要给这些单词在我们的数据中的出现次数打分。我们看到了一种非常简单的方法——二元方法(1 代表存在，0 代表不存在)。</p><p id="0843" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一些额外的评分方法是:</p><ul class=""><li id="cbb6" class="nb nc iq kf b kg kh kk kl ko nd ks ne kw nf la og nh ni nj bi translated"><strong class="kf ir">伯爵</strong>。计算每个单词在文档中出现的次数。</li><li id="c226" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><strong class="kf ir">频率</strong>。计算文档中所有单词中每个单词出现的频率。</li></ul><h2 id="cec9" class="me lc iq bd ld mf mg dn lh mh mi dp ll ko mj mk lp ks ml mm lt kw mn mo lx mp bi translated">TF-IDF</h2><p id="a8ae" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated"><strong class="kf ir">评分词频</strong>的一个问题是，文档中最频繁出现的词开始有最高的分数。与一些更罕见和特定领域的单词相比，这些频繁出现的单词可能不包含太多的"<strong class="kf ir">信息增益</strong>"。解决这个问题的一个方法是<strong class="kf ir">惩罚在所有文档</strong>中<strong class="kf ir">频繁出现的</strong>单词。这种方法被称为 TF-IDF。</p><p id="75ba" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">TF-IDF，简称<strong class="kf ir">词频-逆文档频数</strong>是一种<strong class="kf ir">统计量</strong>，用于评估一个词在集合或<a class="ae kc" href="https://en.wikipedia.org/wiki/Text_corpus" rel="noopener ugc nofollow" target="_blank">语料库</a>中对一个文档的重要性。</p><p id="be4a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">TF-IDF 得分值与单词在文档中出现的次数成比例地增加，但是它被语料库中包含该单词的文档的数量所抵消。</p><p id="f64d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看看用于计算文档<strong class="kf ir"> y </strong>中给定术语<strong class="kf ir"> x </strong>的 TF-IDF 得分的公式。</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi on"><img src="../Images/d99d3ace4b16642964112d5fcee52d16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V9ac4hLVyms79jl65Ym_Bw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">TF-IDF Formula. Source: <a class="ae kc" href="http://filotechnologia.blogspot.com/2014/01/a-simple-java-class-for-tfidf-scoring.html" rel="noopener ugc nofollow" target="_blank">http://filotechnologia.blogspot.com/2014/01/a-simple-java-class-for-tfidf-scoring.html</a></figcaption></figure><p id="6ba7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，让我们把这个公式拆分一下，看看公式的不同部分是如何工作的。</p><ul class=""><li id="9a39" class="nb nc iq kf b kg kh kk kl ko nd ks ne kw nf la og nh ni nj bi translated"><strong class="kf ir">词频(TF) </strong>:该词在当前文档中出现频率的得分。</li></ul><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/2db726656b5342f30bdb30965f1acc01.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*V3qfsHl0t-bV5kA0mlnsjQ.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Term Frequency Formula</figcaption></figure><ul class=""><li id="9c81" class="nb nc iq kf b kg kh kk kl ko nd ks ne kw nf la og nh ni nj bi translated"><strong class="kf ir">逆词频(ITF) </strong>:对单词在文档中的稀有程度进行评分。</li></ul><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi op"><img src="../Images/843abf9c03050f2989d93e64f5430a6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*wvPGL02y36QL7-tdG1BT1A.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Inverse Document Frequency Formula</figcaption></figure><ul class=""><li id="2d0d" class="nb nc iq kf b kg kh kk kl ko nd ks ne kw nf la og nh ni nj bi translated">最后，我们可以使用前面的公式来计算给定术语的<strong class="kf ir"> TF-IDF 得分</strong>，如下所示:</li></ul><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/4564cb4982d784af624a042c2149bd6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*D2UA6xj9KqcH6amzVj5Y5g.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">TF-IDF Formula</figcaption></figure><p id="86f5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">示例<br/> </strong>在 Python 中，我们可以使用 sklearn 库中的<strong class="kf ir">tfidf 矢量器</strong>类来计算给定文档的 TF-IDF 分数。让我们使用和单词袋例子中相同的句子。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="03fb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">输出:</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi or"><img src="../Images/96f6f3a71f8d4b4c35f580c5f389a83f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dPXb0hL5GluQCf9jMY1YDQ.png"/></div></div></figure><p id="3896" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">同样，我将在这里添加句子，以便于比较和更好地理解这种方法是如何工作的。</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi om"><img src="../Images/daf8f4bc8854e7811fe9c0817c56cb72.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*LtMJ1qSiIuEzZDqB-RQbjw.png"/></div></figure><h1 id="8a9b" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">摘要</h1><p id="511f" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">在这篇博文中，您将学习文本的 NLP 基础知识。更具体地说，您已经学习了以下概念以及其他详细信息:</p><ul class=""><li id="e20b" class="nb nc iq kf b kg kh kk kl ko nd ks ne kw nf la og nh ni nj bi translated"><strong class="kf ir"> NLP </strong>用于将<strong class="kf ir">机器学习算法</strong>应用于<strong class="kf ir">文本</strong>和<strong class="kf ir">语音</strong>。</li><li id="71a4" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated">NLTK ( <strong class="kf ir">自然语言工具包</strong>)是一个<strong class="kf ir">领先的平台</strong>，用于构建 Python 程序来处理<strong class="kf ir">人类语言数据</strong></li><li id="973b" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><strong class="kf ir">句子标记化</strong>就是<strong class="kf ir">把书面语<strong class="kf ir">的一串</strong>分割成</strong>它的成分<strong class="kf ir">句子</strong>的问题</li><li id="b29c" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><strong class="kf ir">分词</strong>就是<strong class="kf ir">将书面语<strong class="kf ir">中的一串</strong>拆分成</strong>其成分<strong class="kf ir">单词</strong>的问题</li><li id="fcd0" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><strong class="kf ir">词干化</strong>和<strong class="kf ir">词汇化</strong>的目的都是为了<strong class="kf ir">将</strong> <a class="ae kc" href="https://en.wikipedia.org/wiki/Inflection" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir">屈折</strong> </a> <strong class="kf ir">形式</strong>以及有时将<strong class="kf ir">单词的衍生相关形式<strong class="kf ir"> </strong>缩减为</strong><strong class="kf ir">公共基础形式</strong>。</li><li id="ed1b" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><strong class="kf ir">停用词</strong>是在文本处理之前或之后过滤掉的词。他们<strong class="kf ir">通常</strong>指的是<strong class="kf ir">语言中最常见的单词</strong>。</li><li id="8a86" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><strong class="kf ir">正则表达式是</strong>定义<strong class="kf ir">搜索模式</strong>的一系列字符。</li><li id="c00c" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><strong class="kf ir">词袋</strong>模型是一种<strong class="kf ir">流行的</strong>和<strong class="kf ir">简单的</strong> <strong class="kf ir">特征提取技术</strong>在我们处理文本时使用。它描述了文档中每个单词的出现。</li><li id="cb8d" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><strong class="kf ir"> TF-IDF </strong>是一个<strong class="kf ir">统计量</strong>，用于<strong class="kf ir">评估</strong>一个<strong class="kf ir">单词</strong>对集合中的一个文档或者<a class="ae kc" href="https://en.wikipedia.org/wiki/Text_corpus" rel="noopener ugc nofollow" target="_blank">语料库</a>的重要性。</li></ul><p id="a9f9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">厉害！现在我们知道了如何从文本中提取特征的基本知识。然后，我们可以使用这些特征作为机器学习算法的输入。</p><p id="d2cc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要不要看<strong class="kf ir">所有</strong>用在<strong class="kf ir">的概念再来一个大例子</strong>？<br/> - <a class="ae kc" href="https://github.com/Ventsislav-Yordanov/Blog-Examples/blob/master/Intro%20to%20NLP%20-%20Cleaning%20Review%20Texts%20Example/Cleaning%20Review%20Texts%20Example.ipynb" rel="noopener ugc nofollow" target="_blank">给您</a>！如果你在手机上阅读，请向下滚动到最后，点击“<em class="ns">桌面版</em>”链接。</p><h1 id="df57" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">资源</h1><ul class=""><li id="b3ac" class="nb nc iq kf b kg lz kk ma ko os ks ot kw ou la og nh ni nj bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Natural_language_processing" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Natural_language_processing</a></li><li id="ee7b" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated">http://www.nltk.org/<a class="ae kc" href="http://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"/></li><li id="e4ae" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated">【https://en.wikipedia.org/wiki/Text_segmentation T4】</li><li id="4dce" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Lemmatisation" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Lemmatisation</a></li><li id="daa6" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Stemming" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Stemming</a></li><li id="3f7a" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><a class="ae kc" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html" rel="noopener ugc nofollow" target="_blank">https://NLP . Stanford . edu/IR-book/html/html edition/stemming-and-lemma tization-1 . html</a></li><li id="b6ad" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Stop_words" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Stop_words</a></li><li id="6c2e" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Regular_expression" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Regular_expression</a></li><li id="081e" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><a class="ae kc" href="https://docs.python.org/3/library/re.html?highlight=regex" rel="noopener ugc nofollow" target="_blank">https://docs.python.org/3/library/re.html?highlight=regex</a></li><li id="16ad" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><a class="ae kc" href="https://machinelearningmastery.com/gentle-introduction-bag-words-model/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/gentle-introduction-bag-words-model/</a></li><li id="4e58" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><a class="ae kc" href="https://chrisalbon.com/machine_learning/preprocessing_text/bag_of_words/" rel="noopener ugc nofollow" target="_blank">https://chrisalbon . com/machine _ learning/preprocessing _ text/bag _ of _ words/</a></li><li id="8eeb" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><a class="ae kc" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Tf%E2%80%93idf</a></li></ul><h1 id="fbbc" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">互动版</h1><p id="c7b5" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated"><a class="ae kc" href="https://beta.deepnote.com/launch?template=deepnote&amp;url=https%3A%2F%2Fstorage.googleapis.com%2Fdeepnote-public-templates%2Fvyordanov%2Fintro2nlp.tar.gz&amp;name=Introduction%20to%20Natural%20Language%20Processing%20for%20Text" rel="noopener ugc nofollow" target="_blank">这里的</a>是在<a class="ae kc" href="https://deepnote.com/" rel="noopener ugc nofollow" target="_blank"> Deepnote </a>(云托管 Jupyter 笔记本平台)上传的这篇文章的<strong class="kf ir">交互版本</strong>。请随意查看并使用示例。</p><h1 id="e582" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">我的其他博客文章</h1><p id="9803" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">你也可以看看我以前的博文。</p><ul class=""><li id="0b50" class="nb nc iq kf b kg kh kk kl ko nd ks ne kw nf la og nh ni nj bi translated"><a class="ae kc" href="https://medium.com/@ventsislav94/jypyter-notebook-shortcuts-bf0101a98330" rel="noopener"> Jupyter 笔记本快捷键</a></li><li id="4c37" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><a class="ae kc" rel="noopener" target="_blank" href="/python-basics-for-data-science-6a6c987f2755">数据科学的 Python 基础知识</a></li><li id="9664" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><a class="ae kc" rel="noopener" target="_blank" href="/data-science-with-python-intro-to-data-visualization-and-matplotlib-5f799b7c6d82">Python 数据科学:Matplotlib 数据可视化简介</a></li><li id="1ad2" class="nb nc iq kf b kg nk kk nl ko nm ks nn kw no la og nh ni nj bi translated"><a class="ae kc" rel="noopener" target="_blank" href="/data-science-with-python-intro-to-loading-and-subsetting-data-with-pandas-9f26895ddd7f">Python 数据科学:pandas 加载、子集化和过滤数据简介</a></li></ul><h1 id="5bf5" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">时事通讯</h1><p id="eb95" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">如果你想在我发表新的博客文章时得到通知，你可以订阅<a class="ae kc" href="https://buttondown.email/Ventsislav" rel="noopener ugc nofollow" target="_blank">我的最新时事通讯</a>。</p><h1 id="6d42" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">商务化人际关系网</h1><p id="517f" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">这是我在 LinkedIn 上的简介，如果你想和我联系的话。我将很高兴与你联系在一起。</p><h1 id="f04d" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">最后的话</h1><p id="a0da" class="pw-post-body-paragraph kd ke iq kf b kg lz ki kj kk ma km kn ko mb kq kr ks mc ku kv kw md ky kz la ij bi translated">谢谢你的阅读。我希望你喜欢这篇文章。如果你喜欢，请按住拍手键，分享给你的朋友。我很高兴听到你的反馈。如果你有什么问题，尽管问。😉</p></div></div>    
</body>
</html>