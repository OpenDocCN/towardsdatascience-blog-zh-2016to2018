<html>
<head>
<title>[ Paper Summary ] What is the Role of Recurrent Neural Networks (RNNs) in an Image Caption Generator?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">【论文摘要】递归神经网络(RNNs)在图像字幕生成器中的作用是什么？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/paper-summary-what-is-the-role-of-recurrent-neural-networks-rnns-in-an-image-caption-e9475056e3cd?source=collection_archive---------6-----------------------#2018-07-07">https://towardsdatascience.com/paper-summary-what-is-the-role-of-recurrent-neural-networks-rnns-in-an-image-caption-e9475056e3cd?source=collection_archive---------6-----------------------#2018-07-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/eaf9babc8857a0aa1b1ce10a4bd705ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*ZK1m3pYHROUYumwfqw83dA.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">GIF from this <a class="ae jy" href="https://giphy.com/gifs/black-and-white-flux-machine-cFbmj5Kd4eylO" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="1b4f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我发现了一篇关于图像标题生成任务的有趣论文。</p><blockquote class="kx ky kz"><p id="671c" class="jz ka la kb b kc kd ke kf kg kh ki kj lb kl km kn lc kp kq kr ld kt ku kv kw ij bi translated"><strong class="kb ir">请注意，这篇帖子是给未来的自己看的，回顾这篇论文上的材料，而不是从头再看一遍。</strong></p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="lp lq l"/></div></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="19b3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">摘要</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi lr"><img src="../Images/1085e17f092c629a89d2c6c9ebb7ea49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*uEVOAGqPYKkPWwngdfimgg.png"/></div></figure><p id="eda7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在大多数图像字幕生成的文献中，许多研究者将 RNN 视为系统的生成器部分。然而，在整个系统中使用 RNN 还有其他方法。一种方法是使用 RNN 作为先前生成的单词的编码器，并在模型的最后阶段将编码的表示与图像合并。这篇论文的作者发现，使用 RNN 作为编码器实际上会给出更好的结果。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="30ff" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">简介</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ls"><img src="../Images/93c61081c3a32b4f18178226074e1d2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q7tk3SpPIzurl6mrOH6V8A.png"/></div></div></figure><p id="b8a0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">大多数字幕生成任务集中于具体的概念描述生成，即严格描述图像中内容的字幕。(然而，目前正在进行一些研究以超越这一点，例如叙事生成和视觉问答。).自然语言生成主要有三种方法。</p><ol class=""><li id="9ddd" class="lx ly iq kb b kc kd kg kh kk lz ko ma ks mb kw mc md me mf bi translated">首先依赖计算机视觉任务的系统，例如物体检测或图像分类。以及使用编码的图像特征作为 NLG 阶段的输入。</li><li id="4ec6" class="lx ly iq kb b kc mg kg mh kk mi ko mj ks mk kw mc md me mf bi translated">将字幕生成任务视为检索问题的系统，其中许多系统依赖于神经模型来处理图像数据和文本数据。</li><li id="33da" class="lx ly iq kb b kc mg kg mh kk mi ko mj ks mk kw mc md me mf bi translated">系统，由神经网络组成，(我猜这个系统和第一个系统的主要区别是使用了多少神经网络。)，并且这些系统通常具有 CNN 来编码图像和 RNN 来生成与该图像相关的字幕。</li></ol><p id="67bb" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">本文主要讨论第三种方法，大多数研究人员将 RNN 视为生成部分，但事实并非总是如此。如上所述，在 a)中，RNN 看到图像和单词，因此它充当生成器，然而在 b)中，RNN 只看到单词而不是图像，因此仅充当语言特征的编码器。本文调查了这两种体系结构之间的性能，看看哪一种更好，通过作者的实验，他们发现体系结构 b)提供了更好的性能。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="1199" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">背景:神经字幕生成架构</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi ml"><img src="../Images/5932400261151f7ff12d023020078b17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MncQ2Tmj8uygDaKhxIdNFw.png"/></div></div></figure><p id="fa50" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，典型地，RNN 接收开始符号，并将语言特征传递给 FNN，该开始一个字一个字地生成，直到遇到结束符号。实现这一点的一种方法是给 RNN 提供图像和语言数据，本文作者称之为注入法。另一种方法是仅将 RNN 视为语言模型，如图 1 中的 b)所示。这两种架构都在研究社区中使用。(另一件要注意的事情是，这两个模型都与注意机制兼容。)</p><p id="f355" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">注入模型和合并模型之间区别在于，在注入模型中，RNN 负责图像条件语言生成，而在合并模型中，负责编码语言表示。这两种型号在 RNN 还有一些额外的差异，例如重量的数量。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="b83b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">实验</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi mm"><img src="../Images/56a3390caf921765a5366d0934b5c0fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CVL28Q3FEAUQq1z06pvhZw.png"/></div></div></figure><p id="6f80" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于数据集，作者选择使用<a class="ae jy" href="http://nlp.cs.illinois.edu/HockenmaierGroup/8k-pictures.html" rel="noopener ugc nofollow" target="_blank">闪烁数据集</a>，并且在这个实验中测试了如上所示的两种不同的网络架构。为了保持公平和简单，作者只对两个网络使用了基本架构。Adam 用作优化器，他们使用 50 的小批量、Xavier 初始化，同时使用交叉熵和作为成本函数。最后他们用 BLEU，METEOR，CIDEr 和 ROUGE-L 来衡量网络的性能。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="ba3d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi mn"><img src="../Images/34e81fa6b4d3f86a1898389c4ce13e31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HnNSL9ZYRbPUZTrNi0hVDQ.png"/></div></div></figure><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi mo"><img src="../Images/385d5d1440516f2db71337e937f92827.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UvfnzYUA_9CvpS7iot5CoQ.png"/></div></div></figure><p id="d94c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所示，作者对每个模型进行了三次训练，并记录了平均分数。除了 ROUGEL 和 BLEU 分数，我们可以观察到合并架构通常比注入架构表现更好的事实。作者在这次实验后发现了一个有趣的事实，即该模型对 Flicker8K 数据集给出了非常好的结果，这可能意味着数据集本身包含更少的变化，使任务变得更容易。还发现合并模型具有更高的性能与模型大小的比率，并且更有效地利用有限的资源。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="3097" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">讨论</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi mp"><img src="../Images/3db74349fc3bc25cccbcb97fdb6d62b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uJcqCF-ZJo0X73YyooETug.png"/></div></div></figure><p id="284b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">当 RNN 的作用是为给定的图像生成标题时，很自然地认为将图像作为输入是非常有益的，然而，实验结果显示了其他方式。这可能发生的一个原因是由于注入架构的任务的复杂性增加。在该体系结构中，单词和图像都被提供给网络，使得编码任务更加复杂，而在合并体系结构中，RNN 只需要对先前给定的单词进行编码。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="55c6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结论</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi mq"><img src="../Images/c79130c4dfd8e14e7998fc31081ee795.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C-PgIjLXGGvQQ9_vsxUlfQ.png"/></div></div></figure><p id="f6bc" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">总之，本文提出了两种不同的网络架构来执行图像字幕任务。在那两个不同的网络中，RNN 扮演着不同的角色，在第一个网络中，RNN 被赋予了既有先前生成的词又有完整的形象。而在第二种情况下，RNN 充当语言特征编码器，只能访问前面的单词。令人惊讶的是，一般来说，对于图像字幕任务，最好有一个只执行单词编码的 RNN。简而言之，生成任务，涉及序列它是一个更好的想法，有一个单独的网络来编码每个输入数据，而不是把一切交给 RNN。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="0ea4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">未来工作</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="gh gi mr"><img src="../Images/4e54ba06e3374641132d7d2739c3b12e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FK_Z9za10qC2aAQXhsWVFg.png"/></div></div></figure><p id="d295" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">尽管很明显，合并模型的性能比注入模型好得多，但结果并不完全一致。作者正在将这个实验扩展到更大的 MSCOCO 数据集。要问的其他问题是，这种方法对机器翻译任务是否也有类似的影响。合并模式的另一个优点是迁移学习更容易。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="46d8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">最后的话</strong></p><p id="2312" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这是一个有趣领域的非常有趣的工作。</p><p id="abd8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 给我，如果你希望看到我所有写作的列表，请<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">在这里查看我的网站</a>。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的 twitter <a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，并访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。我也实现了<a class="ae jy" href="https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec" rel="noopener">广残网，请点击这里查看博文 pos </a> t。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="2235" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="905c" class="lx ly iq kb b kc kd kg kh kk lz ko ma ks mb kw mc md me mf bi translated">(2018).Aclweb.org。检索于 2018 年 7 月 7 日，来自<a class="ae jy" href="http://www.aclweb.org/anthology/W17-3506" rel="noopener ugc nofollow" target="_blank">http://www.aclweb.org/anthology/W17-3506</a></li><li id="ff2b" class="lx ly iq kb b kc mg kg mh kk mi ko mj ks mk kw mc md me mf bi translated">(2018).Nlp.cs.illinois.edu。检索于 2018 年 7 月 7 日，来自<a class="ae jy" href="http://nlp.cs.illinois.edu/HockenmaierGroup/8k-pictures.html" rel="noopener ugc nofollow" target="_blank">http://NLP . cs . Illinois . edu/HockenmaierGroup/8k-pictures . html</a></li></ol></div></div>    
</body>
</html>