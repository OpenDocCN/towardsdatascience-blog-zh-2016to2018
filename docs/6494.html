<html>
<head>
<title>Getting Started with TensorFlow in Google Colaboratory</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Google 联合实验室 TensorFlow 入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-started-with-tensorflow-in-google-colaboratory-9a97458e1014?source=collection_archive---------5-----------------------#2018-12-16">https://towardsdatascience.com/getting-started-with-tensorflow-in-google-colaboratory-9a97458e1014?source=collection_archive---------5-----------------------#2018-12-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4442" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">10 分钟学会两项激动人心的技术！</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b9d0925cdf50491f58a77118f42d2e8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ciM5lWT1dDwKioIQ"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@franckinjapan?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Franck V.</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="826b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">TensorFlow 是数据科学家的主导深度学习框架，Jupyter Notebook 是数据科学家的首选工具。如果您可以在任何地方使用 TensorFlow，而无需设置环境，那会怎么样？更好的是，如果你可以免费使用 GPU 来训练你的深度学习模型呢？</p><p id="e529" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">谷歌合作实验室(Colab)就是答案！这是一项非常令人兴奋的技术，它允许数据科学家专注于建立机器学习模型，而不是物流！</p><p id="e2fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本文中，我们不仅将介绍使用 Colab 的基础知识，还将通过易于理解的示例帮助您开始使用 TensorFlow。</p><p id="97f5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">开始了。</p></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><h1 id="adfb" class="lz ma iq bd mb mc md me mf mg mh mi mj jw mk jx ml jz mm ka mn kc mo kd mp mq bi translated">打开 Colab 笔记本</h1><p id="20d7" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">首次使用 Colab 时，您可以在此处启动新笔记本:</p><div class="mw mx gp gr my mz"><a href="https://colab.research.google.com/" rel="noopener  ugc nofollow" target="_blank"><div class="na ab fo"><div class="nb ab nc cl cj nd"><h2 class="bd ir gy z fp ne fr fs nf fu fw ip bi translated">谷歌联合实验室</h2><div class="ng l"><h3 class="bd b gy z fp ne fr fs nf fu fw dk translated">编辑描述</h3></div><div class="nh l"><p class="bd b dl z fp ne fr fs nf fu fw dk translated">colab.research.google.com</p></div></div><div class="ni l"><div class="nj l nk nl nm ni nn kp mz"/></div></div></a></div><p id="63d0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">创建笔记本后，它将保存在您的 Google Drive (Colab 笔记本文件夹)中。您可以通过访问您的 Google Drive 页面来访问它，然后双击文件名，或者右键单击，然后选择“用 Colab 打开”。</p><h1 id="71e1" class="lz ma iq bd mb mc no me mf mg np mi mj jw nq jx ml jz nr ka mn kc ns kd mp mq bi translated">与 GitHub 连接</h1><p id="d550" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">Colab 的构建者考虑得非常周到，他们甚至在 Github 中加入了承诺的功能。</p><p id="6bf7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要连接 GitHub，首先需要在 GitHub 上创建一个带有主分支的 repo。然后，从下拉菜单中选择“文件—在 GitHub 中保存副本”。您将仅在第一次被要求授权。方便的是，它甚至允许你在笔记本中包含一个“在 Colab 中打开”按钮，就像这样:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/09bd2b32b313187b1464f1158fab611d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M8ctWU_dqFpLXsB1Zg7CRQ.png"/></div></div></figure><h1 id="868e" class="lz ma iq bd mb mc no me mf mg np mi mj jw nq jx ml jz nr ka mn kc ns kd mp mq bi translated">启用 GPU 支持</h1><p id="eb1f" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">要为深度学习项目打开 GPU，只需进入下拉菜单，选择“运行时—更改运行时类型—硬件加速器”，然后选择 GPU:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nu"><img src="../Images/474839908d64ad6983db80ecdcd3dbc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F100D1CkOsZOMqqhhhtGKQ.png"/></div></div></figure><h1 id="c6a7" class="lz ma iq bd mb mc no me mf mg np mi mj jw nq jx ml jz nr ka mn kc ns kd mp mq bi translated">使用单元格</h1><p id="a8b3" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">在大多数情况下，这与本地 Jupyter 笔记本完全相同。例如，要运行代码单元格，只需按“Shift + Enter”即可。查看以下常用键盘快捷键(在使用 Chrome 的 Windows 上):</p><ul class=""><li id="a3d4" class="nv nw iq ky b kz la lc ld lf nx lj ny ln nz lr oa ob oc od bi translated">运行单元格:“Shift + Enter”</li><li id="94ae" class="nv nw iq ky b kz oe lc of lf og lj oh ln oi lr oa ob oc od bi translated">删除单元格:“Ctrl + M，然后 D”</li><li id="9683" class="nv nw iq ky b kz oe lc of lf og lj oh ln oi lr oa ob oc od bi translated">撤消:“Ctrl + Shift + Z”</li><li id="f96d" class="nv nw iq ky b kz oe lc of lf og lj oh ln oi lr oa ob oc od bi translated">转换为代码单元格:“Ctrl + M，然后 Y”</li><li id="4520" class="nv nw iq ky b kz oe lc of lf og lj oh ln oi lr oa ob oc od bi translated">转换为 markdown 单元格:“Ctrl + M，然后 M”</li><li id="1a6b" class="nv nw iq ky b kz oe lc of lf og lj oh ln oi lr oa ob oc od bi translated">保存笔记本:“Ctrl + S”</li><li id="b0f7" class="nv nw iq ky b kz oe lc of lf og lj oh ln oi lr oa ob oc od bi translated">打开快捷方式屏幕:“Ctrl + M，然后 H”</li></ul><h1 id="e737" class="lz ma iq bd mb mc no me mf mg np mi mj jw nq jx ml jz nr ka mn kc ns kd mp mq bi translated">使用文件</h1><p id="5a48" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">您也可以将数据上传到您的 Colab 文件夹。见下图:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oj"><img src="../Images/7153e9b87610f1c3d8ffb700bf4c1412.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*5J8PzeFOT0AHsxxF-v-M-A.gif"/></div></div></figure><h1 id="dae9" class="lz ma iq bd mb mc no me mf mg np mi mj jw nq jx ml jz nr ka mn kc ns kd mp mq bi translated">张量</h1><p id="b3f6" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">TensorFlow 的名字基于“张量”一词。张量到底是什么？简而言之，多维数组。让我们看看这意味着什么！</p><ul class=""><li id="e6ee" class="nv nw iq ky b kz la lc ld lf nx lj ny ln nz lr oa ob oc od bi translated">我们有一个单一的数字，例如 6，我们称之为“<strong class="ky ir">标量</strong>”；</li><li id="3ba5" class="nv nw iq ky b kz oe lc of lf og lj oh ln oi lr oa ob oc od bi translated">我们有三个数字，例如[ 6，8，9]，我们称之为“<strong class="ky ir">向量</strong>”；</li><li id="d0e9" class="nv nw iq ky b kz oe lc of lf og lj oh ln oi lr oa ob oc od bi translated">我们有一个数字表，例如[[6，8，9]，[2，5，7]]，我们称之为“<strong class="ky ir">矩阵</strong>”(有两行三列)；</li><li id="2414" class="nv nw iq ky b kz oe lc of lf og lj oh ln oi lr oa ob oc od bi translated">我们有<strong class="ky ir">一个数表</strong>的表格，例如[[[6，8，9]，[2，5，7]]，[[6，8，9]，[2，5，7]]]，还有……我们这里用词不多了:(朋友，那是一个<strong class="ky ir">张量</strong>！<em class="ok">张量是数组的广义形式，可以有任意维数</em>。</li></ul><p id="1872" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在张量流术语中，标量是秩为 0 的张量，向量是秩为 1 的，矩阵是秩为 2 的，等等。有三种常用的张量类型:常量、变量和占位符，解释如下。</p><h1 id="86bb" class="lz ma iq bd mb mc no me mf mg np mi mj jw nq jx ml jz nr ka mn kc ns kd mp mq bi translated">张量的类型</h1><p id="f9bc" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated"><strong class="ky ir">常量</strong>顾名思义。它们是你等式中的固定数字。要定义一个常数，我们可以这样做:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="aa4a" class="oq ma iq om b gy or os l ot ou">a = tf.constant(1, name='a_var')<br/>b = tf.constant(2, name='b_bar')</span></pre><p id="8aaa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除了值 1，我们还可以为张量提供一个名称，比如“a_var ”,它独立于 Python 变量名“a”。这是可选的，但将有助于以后的操作和故障排除。</p><p id="5ff5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">定义之后，如果我们打印变量 a，我们会得到:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="bd8b" class="oq ma iq om b gy or os l ot ou">&lt;tf.Tensor 'a_var:0' shape=() dtype=int32&gt;</span></pre><p id="7c0c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">变量</strong>是要优化的模型参数，例如，神经网络中的权重和偏差。同样，我们也可以定义一个变量，并像这样显示它的内容:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="556e" class="oq ma iq om b gy or os l ot ou">c = tf.Variable(a + b)<br/>c</span></pre><p id="9cba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">并且有这样的输出:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="9d25" class="oq ma iq om b gy or os l ot ou">&lt;tf.Variable 'Variable:0' shape=() dtype=int32_ref&gt;</span></pre><p id="0f8a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">但是需要注意的是，所有变量在使用前都需要初始化，如下所示:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="b244" class="oq ma iq om b gy or os l ot ou">init = tf.global_variables_initializer()</span></pre><p id="21ae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你可能已经注意到 a 和 b 的值，也就是整数 1 和 2，没有出现在任何地方，为什么？</p><p id="d6fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是 TensorFlow 的一个重要特征——“惰性执行”，意思是首先定义事物，但不运行。它只有在我们告诉它去做的时候才会被执行，这是通过运行一个会话来完成的！(注意 TensorFlow 也有急切执行。查看此处的<a class="ae kv" href="https://www.tensorflow.org/guide/eager" rel="noopener ugc nofollow" target="_blank">了解更多信息)</a></p><h1 id="f856" class="lz ma iq bd mb mc no me mf mg np mi mj jw nq jx ml jz nr ka mn kc ns kd mp mq bi translated">会话和计算图</h1><p id="807a" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">现在让我们定义一个会话并运行它:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="db10" class="oq ma iq om b gy or os l ot ou">with tf.Session() as session:                    <br/>    session.run(init)                            <br/>    print(session.run(c))</span></pre><p id="0a90" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意，在会话中，我们运行变量的初始化和 c 的计算。我们将 c 定义为 a 和 b 的和:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="74be" class="oq ma iq om b gy or os l ot ou">c = tf.Variable(a + b)</span></pre><p id="7cfc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">用 TensorFlow 和深度学习的话说，这就是“计算图”。听起来很复杂，对吧？但它实际上只是我们想要进行的计算的一种表达方式！</p><h1 id="fe01" class="lz ma iq bd mb mc no me mf mg np mi mj jw nq jx ml jz nr ka mn kc ns kd mp mq bi translated">占位符</h1><p id="9e13" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">另一个重要的张量类型是<strong class="ky ir">占位符</strong>。它的用例是保存要提供的数据的位置。例如，我们定义了一个计算图，我们有大量的训练数据，然后我们可以使用占位符来表示我们将在以后输入这些数据。</p><p id="7a27" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们看一个例子。假设我们有这样一个等式:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/3dd9f8438dd9f7d576403dd925109f16.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*Rgppa4XdNPphQ1KahrrySQ.png"/></div></figure><p id="e830" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们有一个 x 的向量，而不是一个单一的 x 输入。所以我们可以用一个占位符来定义 x:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="9f02" class="oq ma iq om b gy or os l ot ou">x = tf.placeholder(dtype=tf.float32)</span></pre><p id="c9fa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们还需要系数。让我们使用常数:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="ab85" class="oq ma iq om b gy or os l ot ou">a = tf.constant(1, dtype=tf.float32)<br/>b = tf.constant(-20, dtype=tf.float32)<br/>c = tf.constant(-100, dtype=tf.float32)</span></pre><p id="82a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在让我们制作计算图，并提供 x 的输入值:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="31d9" class="oq ma iq om b gy or os l ot ou">y = a * (x ** 2) + b * x + c<br/>x_feed = np.linspace(-10, 30, num=10)</span></pre><p id="00b7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们可以运行它:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="bd11" class="oq ma iq om b gy or os l ot ou">with tf.Session() as sess:<br/>  results = sess.run(y, feed_dict={x: x_feed})<br/>print(results)</span></pre><p id="31d8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这给了我们:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="c99c" class="oq ma iq om b gy or os l ot ou">[ 200.         41.975304  -76.54321  -155.55554  -195.06174  -195.06174  -155.55554   -76.54324    41.97534   200.      ]</span></pre><h1 id="a85b" class="lz ma iq bd mb mc no me mf mg np mi mj jw nq jx ml jz nr ka mn kc ns kd mp mq bi translated"><strong class="ak">综合考虑</strong></h1><p id="184d" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">现在我们有了 TensorFlow 的基础知识，让我们做一个迷你项目来构建一个线性回归模型，也就是神经网络:)(代码改编自 TensorFlow 指南中的示例<a class="ae kv" href="https://www.tensorflow.org/guide/low_level_intro" rel="noopener ugc nofollow" target="_blank">这里</a></p><p id="51b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">假设我们有一堆 x，y 值对，我们需要找到最佳拟合线。首先，由于 x 和 y 都有值要输入到模型中，我们将它们定义为占位符:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="4d7a" class="oq ma iq om b gy or os l ot ou">x = tf.placeholder(dtype=tf.float32, shape=(None, 1))<br/>y_true = tf.placeholder(dtype=tf.float32, shape=(None, 1))</span></pre><p id="37ba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">行数被定义为 None，以便灵活地输入我们想要的任意行数。</p><p id="e73c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我们需要定义一个模型。在这种情况下，我们的模型只有一个层，只有一个权重和一个偏差。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ow"><img src="../Images/4851d8098c7e269b5265dbd0a67de84c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ez8gNQ8F5d6oxyxH7EIN8w.png"/></div></div></figure><p id="85a4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">TensorFlow 允许我们非常容易地定义神经网络层:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="3a4e" class="oq ma iq om b gy or os l ot ou">linear_model = tf.layers.Dense(<br/>                   units=1, <br/>                   bias_initializer=tf.constant_initializer(1))<br/>y_pred = linear_model(x)</span></pre><p id="ee1d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">单元的数量被设置为 1，因为我们在隐藏层中只有一个节点。</p><p id="957c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，我们需要有一个损失函数，并建立优化方法。损失函数基本上是一种使用训练数据来衡量我们的模型有多差的方法，所以当然，我们希望它最小化。我们将使用梯度下降算法来优化这个损失函数(我将在以后的文章中解释梯度下降)。</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="6163" class="oq ma iq om b gy or os l ot ou">optimizer = tf.train.GradientDescentOptimizer(0.01)<br/>train = optimizer.minimize(loss)</span></pre><p id="466c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后我们可以初始化所有的变量。在这种情况下，我们所有的变量包括权重和偏差都是我们上面定义的层的一部分。</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="df67" class="oq ma iq om b gy or os l ot ou">init = tf.global_variables_initializer()</span></pre><p id="186a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，我们可以为占位符提供培训数据并开始培训:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="5600" class="oq ma iq om b gy or os l ot ou">x_values = np.array([[1], [2], [3], [4]])<br/>y_values = np.array([[0], [-1], [-2], [-3]])</span><span id="47a7" class="oq ma iq om b gy ox os l ot ou">with tf.Session() as sess:<br/>  sess.run(init)<br/>  for i in range(1000):<br/>    _, loss_value = sess.run((train, loss),<br/>                             feed_dict={x: x_values, y_true: y_values})</span></pre><p id="b928" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以得到权重，并做出这样的预测:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="223a" class="oq ma iq om b gy or os l ot ou">weights = sess.run(linear_model.weights)<br/>bias = sess.run(linear_model.bias)<br/>preds = sess.run(y_pred, <br/>                 feed_dict={x: x_values})</span></pre><p id="ba5a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由此产生了这些预测:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="9e64" class="oq ma iq om b gy or os l ot ou">[[-0.00847495]  [-1.0041066 ]  [-1.9997383 ]  [-2.99537   ]]</span></pre><p id="0c42" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你像我一样好奇，你可以通过以下方式验证模型是否使用其训练的权重和偏差进行预测:</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="1bd5" class="oq ma iq om b gy or os l ot ou">w = weights[0].tolist()[0][0]<br/>b = weights[1].tolist()[0]<br/>x_values * w + b</span></pre><p id="ad19" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这给了我们完全相同的结果！</p><pre class="kg kh ki kj gt ol om on oo aw op bi"><span id="c3bd" class="oq ma iq om b gy or os l ot ou">array([[-0.00847495],        [-1.00410664],        [-1.99973834],        [-2.99537003]])</span></pre></div><div class="ab cl ls lt hu lu" role="separator"><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx ly"/><span class="lv bw bk lw lx"/></div><div class="ij ik il im in"><p id="e31c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">瞧啊。Google Colab 中使用 TensorFlow 搭建的一个简单的神经网络！希望你觉得这个教程有趣和丰富。</p><p id="9686" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">包含所有代码的笔记本可以在<a class="ae kv" href="https://github.com/georgeliu1998/tf_and_colab/blob/master/tf_and_colab.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。一定要试一试！</p><h2 id="6406" class="oq ma iq bd mb oy oz dn mf pa pb dp mj lf pc pd ml lj pe pf mn ln pg ph mp pi bi translated">最后的想法</h2><p id="228f" class="pw-post-body-paragraph kw kx iq ky b kz mr jr lb lc ms ju le lf mt lh li lj mu ll lm ln mv lp lq lr ij bi translated">云计算绝对是深度学习计算的未来。谷歌 Colab 显然是一款面向未来的产品。当我们可以在云上启动笔记本电脑并开始构建模型时，很难想象人们还想花时间建立深度学习环境！</p></div></div>    
</body>
</html>