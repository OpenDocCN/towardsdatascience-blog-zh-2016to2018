<html>
<head>
<title>Can A Machine Be Racist?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器会有种族歧视吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/can-a-machine-be-racist-5809b18e5a91?source=collection_archive---------10-----------------------#2018-02-01">https://towardsdatascience.com/can-a-machine-be-racist-5809b18e5a91?source=collection_archive---------10-----------------------#2018-02-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/952fbb3b7c09d25ee3a35dc0551de798.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m3vlxneAo50hBQYOZbT_ug.jpeg"/></div></div></figure><div class=""/><p id="1a36" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">人工智能已经成为一个家喻户晓的词。它也成了所有家庭的操纵者。人工智能在所有业务和商业模式中的无节制爆炸一直是增长的惊人动力，但它也提出了需要回答的问题。</p><p id="b629" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">数据科学家和人工智能研究人员将越来越多地驱动人类行为，影响企业的决策方式，甚至引导政府。此外，这些模型将越来越多地从传统的人类可理解的设计转向复杂的深度学习模型，其中涉及的复杂性令人难以置信。在实践中，这种情况很少或根本没有围绕这种系统的伦理进行讨论。</p><p id="8c4f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">人体扩增</strong></p><p id="a6ac" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当我们使用ML来增强或执行通常由人类执行的任务时，我们有机会消除影响判断并导致糟糕决策的偏见。我们人类会变得疲惫或懒惰，会变得种族主义或性别歧视，会变得傲慢或过于自信，这样的例子不胜枚举。所有这些特征使人类成为糟糕的决策者——不管这些决定是不是有意的。</p><p id="8409" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">人工智能有能力消除决策过程中的人为因素。也许最重要的是，它可以根据原始客观数据做出纯粹客观的决策。当我们将伦理应用到这些系统的设计中时，每个人最终都会过得更好。伦理提供了一个客观的框架来判断什么是对的，什么是错的。在这篇文章中，我希望让你相信人工智能带来的危险和好处，并为企业和数据科学家提供一个简要的框架。</p><p id="ed7e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在你继续之前，请记住这不是一篇危言耸听的文章。目前人工智能的好处远远大于后果。我正在关注人工智能中的一个具体问题，我希望通过尽早认识到这个问题，我们可以在这个讨论的基础上从这个强大的工具中获得最大的好处。</p><p id="d364" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">为什么道德很重要</strong></p><p id="55f6" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在成为数据科学家之前，我是一名机械工程师。我的学位让我选修了多门伦理学课程，而我的职业生涯要求我全程选修伦理学课程。</p><p id="75e1" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我研究了许多工程事故，这些事故导致了数百人不必要的死亡和伤害，以及数不清的环境破坏。安全设计的规模和重要性，极度关注细节的重要性，以及导致失败的罕见事件。在我学习期间，职业道德不断地灌输给我。相比之下，人工智能经常停留在道德黑洞中。人工智能的现实是，一些模型做出的决策对企业和社会都不利。</p><p id="9f54" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">目前，机器学习中的伦理困境无法与工程界的伦理困境相提并论。很难想象一个机器学习系统会因为错误的设计而杀死数百人，但它们仍然会造成伤害。我们经常将身体伤害提升到金融、政治或操纵痛苦之上，但人工智能系统将在较小范围内影响数十亿人的事实最终使它们变得更加重要。</p><p id="9f29" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">根据真实故事改编</strong></p><p id="087b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">假设您在一家银行工作，想要创建一个模型来预测客户的违约概率。然后，您希望将此预测用于贷款利率。对于这个例子，让我们假设我正在以最大化我的算法为目标来处理这个任务，而没有任何关于道德的想法。我的方法是机器人式的，我会消耗任何增加我的模型预测能力的数据。</p><p id="fe58" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您会使用哪些功能来训练您的模型？</p><ul class=""><li id="4310" class="kw kx jb ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated">客户居住的街道</li><li id="d695" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">性别</li><li id="b513" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">人种</li><li id="3411" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">语言</li><li id="c2eb" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">婚姻状况</li><li id="2212" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">脸书上的朋友，朋友数量</li><li id="3005" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">LinkedIn上的关系</li><li id="02dd" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">年龄</li><li id="dfa8" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">教育</li><li id="d48a" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">医院就诊次数</li></ul><p id="ea7f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这样的例子不胜枚举。几乎任何东西都可以做成模型。一些公司需要脸书数据作为其贷款申请流程的一部分。他们可以解析你的朋友，你的帖子，你朋友的帖子…你明白了。</p><p id="8a0a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">那么什么时候可以呢？这种模式有完全有效的积极的社会论据。它可以让原本无法获得信贷的人获得信贷。事实证明，它可以减少对被传统金融体系拒之门外的人的掠夺性贷款。我还敢打赌，许多(或所有)经济学家都会同意，更广泛的信贷渠道对经济更有利。</p><p id="947c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然而，你可以很容易地看到我们如何开始更深地隔离我们的社区。这些算法将输出越来越准确的违约率，但收取的高利率将成为一个强化循环。随着农行普通客户继续获得更高的贷款利率，他们违约的概率将会上升。算法的下一次更新将考虑到这一点。情况并非总是如此，但在实践中可能会发生。正是设计糟糕的算法成为了其预测的牺牲品。</p><p id="ebce" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">我认为那家伙应该升职</strong></p><p id="530b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们想象同样的过程应用于其他问题——预测组织中的高绩效员工。你输入员工的所有数据(年龄、性别、绩效分数、能力测试),结果就出来了。如果您使用的是基于回归的算法，您可以确定该算法使用哪些数据来做出决策。由于该算法着眼于人类行为(过去的绩效评估和以前的晋升非常主观)，它仅仅是现有做法的反映。此外，如果你在没有任何道德标准的情况下使用它，它会加重任何已经存在的人类偏见。它很快变得比组织本身更有偏见！</p><p id="544f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果性别是一个强有力的预测因素，会发生什么？如果种族是一个强有力的预测因素会发生什么？如果一个领域是由一种性别主导的，比如教学是由女性主导的，或者工程是由男性主导的，那么算法就有可能抓住这一点，并相应地对人们进行细分。</p><p id="03d1" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">数据中存在这些偏差可能有完全有效的原因，但这并不能阻止算法找到它们并加以利用。也许你的组织中外国人的比例很低——你的算法可以利用这一事实来提高其准确性。或者，我们可以想象这样一个场景，A公司有一个种族主义的招聘经理，这个经理的行为会影响模型的预测。毕竟模型没有感觉，也没有情绪；它只是试图预测你让它做什么。如果你打算预测人类行为，而人类行为是有偏差的，那么它<strong class="ka jc">就是</strong>将被嵌入算法中。</p><p id="4f49" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果我用这个算法来告知你的决策精度，它会开始鼓励它首先发现的偏差。这是完全可能的，事实上也很有可能，你更有可能提升来自业务所在国的员工，而不是外籍员工。同样，可能有完全合理的理由——本地员工更有可能在该公司工作更长时间，或者更有可能在工作中掌握更好的语言。话又说回来，它们可能只是不公平的做法。</p><p id="031c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">事实是你不知道。</p><p id="26b6" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这个事实导致了一种算法，它以一种你永远不会允许自己去做的方式运行。它变得类似于一个分数系统，人们根据他们的肤色或性别来打分。这也是你永远不会作为公司政策写下来的东西，但你却允许你的算法这样做。是不是因为电脑做到了就变得OK了？号码</p><p id="1e2b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">发生这种情况的例子有很多，但总体来说，在这个领域很少有这方面的培训或讨论。只是在最近，人工智能中的伦理话题才变得更加普遍。</p><p id="637c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">让人工智能去思考</strong></p><p id="5a15" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我最近在为一个朋友搜索疫苗信息，我不得不进入我的搜索引擎的第二页去寻找来自CDC，NHS和加拿大政府的信息。最可信的来源不应该是第一位的吗？</p><p id="34cc" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为什么会这样？</p><p id="e39b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">根据过去的搜索历史提供搜索结果可能是危险的</strong> —当你进入搜索引擎并键入“疫苗安全吗”时，你是在问一个有倾向性的问题。一般来说，认为疫苗安全的人懒得问这个问题，搜索引擎算法说你有点像这些问类似问题的人，这给了你怀疑的博客。它甚至会扭曲你对这场争论是否存在的看法。</p><p id="709a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">事实是，绝大多数医生和科学家都有结论和数据支持疫苗是安全的这一共识。我甚至无法开始描述疫苗给人类带来的好处。</p><p id="d052" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你向人们展示基于他们对替代事实偏好的搜索结果，你对他们有好处吗？或者你只是在夸大他们的偏见，认为权威的地位是不可信的？在人工智能的发展过程中，许多这类问题都没有被问过。</p><p id="384d" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">分析会扼杀客观性吗？</strong></p><p id="01e5" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在一个充斥着异常善于分析的人的领域，伦理学已经被抛在了一边。事实上，缺乏伦理关怀和对预测能力的追求导致了善于分析的人使用主观数据。在任何模型中使用主观数据时都应该非常谨慎，应该避免使用个人数据来预测人类行为。具有讽刺意味的是，一个本应客观的领域，却往往是主观建造的。</p><p id="1754" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，主观算法通常对它们的创造者没有好处。机器可以通过绕过使我们的行为偏离客观性的认知偏见来做伟大的事情。众所周知，人类会错误地感知一系列反应和结果。他们会犯错，会疲劳——机器可以检查这些固有的缺陷。</p><p id="802b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">伦理道德在哪里？</strong></p><p id="3bd3" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">也许这是因为在数学等许多量化领域并不真正需要进行伦理讨论，而这些正是越来越多地进入AI领域的人。为了优化他们的算法，获得更多的数据，并提高准确性，许多从业者正在开发影响行为和决策的算法。数据科学领域应该关注工程师和医生已经安装的系统，以确保他们的领域为人类造福。道德设计需要成为任何课程的要求，像我这样自学成才的设计师需要熟悉这些想法。</p><p id="1a5e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">业务影响</strong></p><p id="2b5d" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">经历这个过程有点困难。最终，这将落到领先的数据科学家和雇佣数据科学家的公司的肩上。</p><p id="e88f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">关于伦理设计的讨论应该成为现状。否则，目前的方法将开始损害公司的声誉，或者导致公众对人工智能的强烈反对。你永远不应该把数据输入到一个你不会在公司政策中用来做决定(或者实际上是自己做决定)的算法中。就像你永远不会明确地使用性别、种族和语言来提升他人一样(不考虑隐含的偏见)，除非你明白后果，否则你永远也不应该把它们输入算法。</p><p id="1f8b" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">外卖——保持认知和警觉，但避免敲响警钟</strong></p><p id="8838" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">可以肯定的是，在有些地方使用这种主观数据是合乎道德的，甚至是一种要求(例如，医疗保健)，但关键是这种讨论对于大多数数据科学领域来说尚不存在。</p><p id="2f08" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">任何时候你在算法中使用人类行为，你都需要小心。人类是有缺陷的；人类可以因为任何原因产生任何数量的偏见。基于它们的算法将不可避免地成为这种行为的延伸。一个设计不当的算法预测出最佳表现者，不太可能是一个数学专家，而更可能只是模仿你当前流程的行为(尽管是以一种更具成本效益的方式)。</p><p id="64ba" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这从两个方面伤害了公司:</p><ul class=""><li id="c13b" class="kw kx jb ka b kb kc kf kg kj ky kn kz kr la kv lb lc ld le bi translated">第一，它未能完成设计它的目标任务。</li><li id="18dd" class="kw kx jb ka b kb lf kf lg kj lh kn li kr lj kv lb lc ld le bi translated">第二，如果算法偏差被人知道或公开，这可能会成为一场噩梦</li></ul><p id="703a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">所以回到题目；机器会有种族歧视吗？我说不。机器只做它被设计做的事。如果你设计了一台糟糕的机器，它会做出种族歧视的决定，但那是设计者的错，而不是机器的错。就像工程师把一座桥的失败归咎于设计者一样，我们是否应该把一个人工智能系统的失败归咎于它的程序员。</p><p id="f28e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">通过使用正确的特征，坚持分析数据而不是主观数据，算法可以极大地改善你的决策。仅仅有客观的输入是不够的，但是你需要优化一个客观的结果。对很多人来说，这是数据科学中最难、最麻烦的部分；问正确的问题。</p></div></div>    
</body>
</html>