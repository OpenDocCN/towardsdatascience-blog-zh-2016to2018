<html>
<head>
<title>The 4 Deep Learning Breakthroughs You Should Know About</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你应该知道的 4 个深度学习突破</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-5-deep-learning-breakthroughs-you-should-know-about-df27674ccdf2?source=collection_archive---------4-----------------------#2017-12-04">https://towardsdatascience.com/the-5-deep-learning-breakthroughs-you-should-know-about-df27674ccdf2?source=collection_archive---------4-----------------------#2017-12-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="024b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">非专家深度学习系列的第一篇</h2></div><h2 id="6f09" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">为什么要看这个？</h2><p id="dccd" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">无论是作为个体从业者还是作为组织，要开始应用深度学习，你需要两件事情:</p><ol class=""><li id="4723" class="lu lv iq ld b le lw lh lx ko ly ks lz kw ma lt mb mc md me bi translated"><strong class="ld ir">“什么”</strong>:深度学习的最新发展能够做什么的想法。</li><li id="4ffa" class="lu lv iq ld b le mf lh mg ko mh ks mi kw mj lt mb mc md me bi translated"><strong class="ld ir">“如何做”</strong>:培训新模型或使用现有模型并使其投入生产的技术能力。</li></ol><p id="78e8" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">由于开源社区的强大，第二部分变得越来越容易。关于如何使用 TensorFlow 等库来训练和使用深度学习模型的具体细节，有许多很好的教程，其中许多出版物如《走向数据科学》每周出版一次。</p><p id="e1d1" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">这意味着，一旦你有了如何使用深度学习的想法，实现你的想法虽然不容易，但涉及到标准的“开发”工作:遵循本文中链接的教程，根据你的特定目的和/或数据修改它们，通过阅读 StackOverflow 上的帖子进行故障排除，等等。例如，他们不要求(或雇佣)一个拥有博士学位的独角兽，他可以从零开始编写原始的神经网络架构<em class="mn">和</em>是一个有经验的软件工程师。</p><p id="6abb" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">这一系列文章将试图填补第一部分的空白:在高层次上覆盖深度学习的能力，同时为那些想要了解更多和/或深入代码并解决第二部分的人提供资源。更具体地说，我将介绍:</p><ol class=""><li id="72c2" class="lu lv iq ld b le lw lh lx ko ly ks lz kw ma lt mb mc md me bi translated">使用开源架构和数据集的最新成就是什么。</li><li id="0ded" class="lu lv iq ld b le mf lh mg ko mh ks mi kw mj lt mb mc md me bi translated">导致这些成就的关键架构或其他见解是什么</li><li id="845a" class="lu lv iq ld b le mf lh mg ko mh ks mi kw mj lt mb mc md me bi translated">在自己的项目中开始使用类似技术的最佳资源是什么。</li></ol><h2 id="d806" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">这些突破有什么共同点</strong></h2><p id="fcc8" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">这些突破虽然涉及许多新的架构和想法，但都是使用机器学习中常见的“监督学习”过程实现的。具体步骤如下:</p><ol class=""><li id="2bfc" class="lu lv iq ld b le lw lh lx ko ly ks lz kw ma lt mb mc md me bi translated">收集大量适当的训练数据</li><li id="a569" class="lu lv iq ld b le mf lh mg ko mh ks mi kw mj lt mb mc md me bi translated">建立一个神经网络架构——即一个复杂的方程系统，松散地模仿大脑——它通常有数百万个称为“权重”的参数。</li><li id="340b" class="lu lv iq ld b le mf lh mg ko mh ks mi kw mj lt mb mc md me bi translated">通过神经网络重复输入数据；在每次迭代中，将神经网络的预测结果与正确结果进行比较，并根据神经网络的偏差程度和偏差方向来调整每个神经网络的权重。</li></ol><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi mo"><img src="../Images/564359866d4b21003637f9723603630f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fbMYoMRFR_Mr8tNoFI0_Jw.jpeg"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">This is how neural nets are trained: this process is repeated <em class="ne">many, many times. </em><a class="ae nf" href="https://www.embedded-vision.com/platinum-members/cadence/embedded-vision-training/documents/pages/neuralnetworksimagerecognition" rel="noopener ugc nofollow" target="_blank"><em class="ne">Source</em></a><em class="ne">.</em></figcaption></figure><p id="b066" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">这个过程已经被应用到许多不同的领域，并且已经产生了看起来已经“学习”的神经网络。在每个领域，我们将涵盖:</p><ol class=""><li id="df8b" class="lu lv iq ld b le lw lh lx ko ly ks lz kw ma lt mb mc md me bi translated">训练这些模型所需的数据</li><li id="d452" class="lu lv iq ld b le mf lh mg ko mh ks mi kw mj lt mb mc md me bi translated">使用的模型架构</li><li id="3bef" class="lu lv iq ld b le mf lh mg ko mh ks mi kw mj lt mb mc md me bi translated">结果呢</li></ol><h1 id="380b" class="ng kg iq bd kh nh ni nj kk nk nl nm kn jw nn jx kr jz no ka kv kc np kd kz nq bi translated"><strong class="ak"> 1。图像分类</strong></h1><p id="65ba" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated"><em class="mn">神经网络可以被训练来计算出图像包含什么对象。</em></p><h2 id="37ca" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">所需数据</strong></h2><p id="07a9" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">为了训练图像分类器，你需要带标签的图像，其中每个图像属于多个有限类中的一个。例如，用于训练图像分类器的标准数据集之一是<a class="ae nf" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR 10 </a>数据，其正确标记了 10 类图像:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nr"><img src="../Images/0a1cf7f99c691411a0bbf2cb4ae62afc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6WOxNUE8N4M9sWZX67djPA.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Illustration of images of CIFAR-10 data. <a class="ae nf" href="https://becominghuman.ai/training-mxnet-part-2-cifar-10-c7b0b729c33c'" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><h2 id="9878" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">深度学习架构</strong></h2><p id="3ebf" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">我们将涉及的所有神经网络架构都是由思考<em class="mn">人</em>实际上必须如何学习解决问题而激发的。对于图像检测，我们如何做到这一点？当人类确定图像中的内容时，我们首先会寻找高级视觉特征，如树枝、鼻子或车轮。然而，为了检测这些，我们下意识地需要确定较低层次的特征，如颜色、线条和其他形状。事实上，从原始像素到人类可以识别的复杂特征，比如眼睛，我们需要检测像素的特征，然后是像素的特征，等等。</p><p id="4ed8" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">在深度学习之前，研究人员会手动尝试提取这些特征，并将其用于预测。就在深度学习出现之前，研究人员开始使用技术(主要是<a class="ae nf" href="https://crypto.stanford.edu/~pgolle/papers/dogcat.pdf" rel="noopener ugc nofollow" target="_blank">支持向量机</a>)试图找到这些手动提取的特征与图像是猫还是狗之间的复杂非线性关系。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi ns"><img src="../Images/eead39f777df596500de0be856c25dce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2SWb6CmxzbPZijmevFbe-g.jpeg"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Convolutional Neural Network extracting features at each layer. <a class="ae nf" href="https://www.strong.io/blog/deep-neural-networks-go-to-the-movies" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="b52f" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">现在，研究人员开发了神经网络架构，可以学习原始像素本身的这些特征；具体来说，深度卷积神经网络架构。这些网络提取像素的特征，然后提取像素的特征等，然后最终通过常规神经网络层(类似于逻辑回归)进行最终预测。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nt"><img src="../Images/9a7454113a4c725b1998f7815798fb34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u7s9w6R0mS2skp49AW7xJw.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Samples of the predictions a leading CNN architecture made on images from the ImageNet dataset.</figcaption></figure><p id="5507" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">在以后的文章中，我们将深入探讨卷积神经网络是如何用于图像分类的。</p><h2 id="bd38" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">突破</h2><p id="5ebd" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">其结果是，在这些架构旨在解决的中心任务——图像分类——上，算法现在可以获得比人更好的结果。在著名的<a class="ae nf" href="http://www.image-net.org/challenges/LSVRC/" rel="noopener ugc nofollow" target="_blank"> ImageNet 数据集</a>上，这是卷积架构最常用的基准，经过训练的神经网络现在在图像分类上实现了优于人类的性能:</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/283d791a67d62f4a51490185c34aa6b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*Zz0iyMI4Ph1QRr2q8tFJzA.png"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">As of 2015, computers can be trained to classify objects in images better than humans. <a class="ae nf" href="https://devblogs.nvidia.com/parallelforall/mocha-jl-deep-learning-julia/" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="36df" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">此外，研究人员已经找到了如何获取不立即用于图像分类的图像，分割出最有可能代表特定类别对象的图像矩形，<em class="mn">通过 CNN 架构</em>馈送这些矩形中的每一个，并最终得到图像中单个对象的分类以及界定其位置的框(这些被称为“边界框”):</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/2af5caf3779d1a4046189b6f56df4c19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*ReTTDms6THKbK7WrrxK7rQ.png"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Object detection using “Mask R-CNN”. <a class="ae nf" href="https://arxiv.org/pdf/1703.06870.pdf" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="4757" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">这整个多步骤过程在技术上被称为“<a class="ae nf" href="https://en.wikipedia.org/wiki/Object_detection" rel="noopener ugc nofollow" target="_blank">物体检测</a>，尽管它使用“图像分类”来完成最具挑战性的步骤。</p><h2 id="bd07" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">资源</h2><p id="f132" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated"><strong class="ld ir">理论</strong>:要深入了解<em class="mn">为什么</em>CNN 会工作的理论，请阅读 Andrej Karpathy 的斯坦福课程<a class="ae nf" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">中的教程。对于一个稍微更数学的版本，查看克里斯·奥拉关于卷积的帖子</a><a class="ae nf" href="http://colah.github.io/posts/2014-07-Conv-Nets-Modular/" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="fcef" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated"><strong class="ld ir">代码</strong>:要快速开始构建图像分类器，请查看 TensorFlow 文档中的<a class="ae nf" href="https://www.tensorflow.org/tutorials/layers" rel="noopener ugc nofollow" target="_blank">这个介绍性示例</a>。</p><h1 id="cb64" class="ng kg iq bd kh nh ni nj kk nk nl nm kn jw nn jx kr jz no ka kv kc np kd kz nq bi translated"><strong class="ak"> 2。文本生成</strong></h1><p id="8511" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated"><em class="mn">可以训练神经网络来生成模仿给定类型文本的文本。</em></p><h2 id="22e5" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">所需数据</strong></h2><p id="1dab" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">给定类的简单文本。例如，这可能是莎士比亚的所有作品。</p><h2 id="0c69" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">深度学习架构</strong></h2><p id="e4c1" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">神经网络可以对元素序列中的下一个元素进行建模。它可以查看过去的字符序列，并针对给定的一组过去的序列，确定下一个最有可能出现的字符。</p><p id="db0a" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">用于该问题的架构不同于用于图像分类的架构。对于不同的架构，我们要求网络学习不同的东西。之前，我们要求它学习图像的哪些特征是重要的。在这里，我们要求它注意一个字符序列，以预测序列中的下一个字符。要做到这一点，与图像分类不同，网络需要一种跟踪其“状态”的方法。例如，如果之前看到的字符是“c-h-a-r-a-c-t-e”，网络应该“存储”该信息，并预测下一个字符应该是“r”。</p><p id="ec70" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">递归神经网络架构能够做到这一点:在下一次迭代中，它将每个神经元的状态反馈到网络中，允许它学习序列(还有更多内容，但我们将在稍后讨论)。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nw"><img src="../Images/158cbee44eb21e87afdbab420361aa48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*psFYwcDGhtuEB7arpeXPbg.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Image of a Recurrent Neural Net architecture. <a class="ae nf" href="https://medium.com/@erikhallstrm/hello-world-rnn-83cd7105b767" rel="noopener">Source</a>.</figcaption></figure><p id="e2d3" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">然而，要想真正擅长文本生成，网络还必须决定在序列中回溯多远。有时，就像在单词中间，网络只需查看最后几个字符来确定下一个字符，而其他时候它可能需要查看许多字符来确定，例如，我们是否在一个句子的末尾。</p><p id="f0ee" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">有一种叫做“LSTM”(长短期记忆)的特殊细胞在这方面做得特别好。每个细胞根据细胞内部的权重决定是“记住”还是“忘记”，权重随着网络看到的每个新字符而更新。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/2963754eff601e732b89272a273ea94a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*EgQzN0yoqFZVLMIodlaR7A.png"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">The inner workings of an LSTM cell. <a class="ae nf" href="http://harinisuresh.com/2016/10/09/lstms/" rel="noopener ugc nofollow" target="_blank">Source</a>.</figcaption></figure><h2 id="3cc9" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">突破</h2><p id="5547" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">简而言之:我们可以生成看起来有点像我们试图生成的文本的特征的文本，减去一些拼写错误的单词和错误，使其不是正确的英语。这个 Andrej Karpathy 的帖子有一些有趣的例子，从生成莎士比亚的戏剧到生成保罗·格拉厄姆的散文。</p><p id="c3b2" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">相同的架构已经被用于通过顺序生成 x 和 y 坐标来生成手写，就像语言是一个字符一个字符地生成一样。点击这里，查看<a class="ae nf" href="https://www.cs.toronto.edu/~graves/handwriting.cgi" rel="noopener ugc nofollow" target="_blank">的演示。</a></p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/33887bfe956b6cd3b0f3850513d0a3df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*3YlpbzVVXUuTevabf4BxYg.png"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Written by a neural net. Can we still call it *hand*writing? <a class="ae nf" href="https://www.cs.toronto.edu/~graves/handwriting.cgi?text=Handwriting&amp;style=&amp;bias=0.15&amp;samples=3" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="4181" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">在以后的文章中，我们将深入探讨递归神经网络和 LSTMs 是如何工作的。</p><h2 id="379e" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">资源</h2><p id="313c" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated"><strong class="ld ir">理论上:</strong> <a class="ae nf" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank">克里斯·奥拉在 LSTMs </a>上的这篇文章是经典之作，安德烈·卡帕西在 RNNs 上的这篇文章<a class="ae nf" href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" rel="noopener ugc nofollow" target="_blank">也是经典之作，它们能完成什么，以及它们是如何工作的。</a></p><p id="132e" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated"><strong class="ld ir">代码:</strong> <a class="ae nf" href="https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/" rel="noopener ugc nofollow" target="_blank">这个</a>是关于如何开始构建端到端文本生成模型的一个很好的演练，包括数据的预处理。<a class="ae nf" href="https://github.com/snowkylin/rnn-handwriting-generation" rel="noopener ugc nofollow" target="_blank">这个 GitHub repo </a>使得使用预先训练的 RNN-LSTM 模型生成手写变得容易。</p><h1 id="0a68" class="ng kg iq bd kh nh ni nj kk nk nl nm kn jw nn jx kr jz no ka kv kc np kd kz nq bi translated"><strong class="ak"> 3。语言翻译</strong></h1><p id="8a27" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">机器翻译——翻译语言的能力——一直是人工智能研究人员的梦想。深度学习让这个梦想更加接近现实。</p><h2 id="08c5" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">所需数据</strong></h2><p id="eb6b" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">不同语言之间的成对句子。例如，对“我是学生”和“我是学生”将是训练神经网络在英语和法语之间进行翻译的数据集中的一对句子。</p><h2 id="b2bc" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">深度学习架构</strong></h2><p id="b057" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">与其他深度学习架构一样，研究人员已经“假设”了计算机可能如何理想地学习翻译语言，并建立了一个试图模仿这一点的架构。就语言翻译而言，从根本上来说，一个句子(编码为一系列单词)应该被翻译成其潜在的“意义”。这个意思应该被翻译成新语言中的一系列单词。</p><p id="55a7" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">句子从单词“转化”成意义的方式，应该是一种擅长处理序列的架构——这原来就是上面所说的“递归神经网络”架构。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi nz"><img src="../Images/84e2743bc3900284b6e862f2daa99043.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NrCYnkPg2WjLTFA08w_0Ig.jpeg"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Encoder-decoder architecture diagram. <a class="ae nf" href="https://github.com/tensorflow/nmt/tree/tf-1.2" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="91dc" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">这种架构在 2014 年<a class="ae nf" href="https://arxiv.org/pdf/1406.1078.pdf" rel="noopener ugc nofollow" target="_blank">的</a>中首次被发现可以很好地用于语言翻译，此后在许多方向上得到了扩展，特别是“注意力”这一概念，我们将在未来的博客文章中探讨。</p><h2 id="7ddf" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">突破</h2><p id="fe81" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated"><a class="ae nf" href="https://research.googleblog.com/2016/09/a-neural-network-for-machine.html" rel="noopener ugc nofollow" target="_blank">这篇谷歌博客文章</a>表明这个架构确实完成了它设定的目标，将其他语言翻译技术打得落花流水。当然，谷歌能为这项任务获取如此棒的训练数据也无妨！</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/2248cac94d0f5ff668fbfa960e7ea815.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*-h9O3JbSIDxjfkico07_1w.png"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Google Sequence-to-Sequence based model performance. <a class="ae nf" href="https://research.googleblog.com/2016/09/a-neural-network-for-machine.html" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><h2 id="a1b7" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">资源</h2><p id="8e7f" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated"><strong class="ld ir">代码&amp;理论:</strong>谷歌，值得称赞的是，在这里发表了一篇关于序列到序列架构的精彩教程<a class="ae nf" href="https://github.com/tensorflow/nmt/tree/tf-1.2" rel="noopener ugc nofollow" target="_blank">。本教程概述了序列到序列模型的目标和理论，并指导您如何在 TensorFlow 中对它们进行编码。它还包括“注意”，这是对基本序列到序列架构的扩展，我将在详细讨论序列到序列时讨论它。</a></p><h1 id="7d95" class="ng kg iq bd kh nh ni nj kk nk nl nm kn jw nn jx kr jz no ka kv kc np kd kz nq bi translated"><strong class="ak"> 4。生成对抗网络</strong></h1><p id="fa2c" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated"><em class="mn">神经网络可以被训练来生成看起来像给定类别的图像的图像——例如，不是实际人脸的人脸图像。</em></p><h2 id="7e16" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">所需数据</strong></h2><p id="267c" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">特定类别的图像—例如，一组人脸图像。</p><h2 id="60dc" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">深度学习架构</strong></h2><p id="ebf1" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">gan 是一个令人惊讶的重要成果——世界上领先的人工智能研究人员之一 Yann LeCun 说，在我看来，它们是“<a class="ae nf" href="https://www.quora.com/session/Yann-LeCun/1" rel="noopener ugc nofollow" target="_blank">过去 10 年中最有趣的想法。</a>“事实证明，我们可以生成看起来像一组训练图像的图像，但实际上不是来自训练集的图像:例如，看起来像人脸但<em class="mn">实际上不是真实人脸的图像</em>。这是通过同时训练两个神经网络来实现的:一个试图生成看起来真实的假图像，另一个试图检测图像是否真实。如果你训练这两个网络，使它们以“相同的速度”学习——这是构建 GANs 的困难部分——试图生成假图像的网络实际上可以生成看起来非常真实的图像。</p><p id="868a" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">说得更详细一点:我们想用 GANs 训练的主要网络叫做生成器:它将学习接收随机噪声向量，并将其转换成逼真的图像。这个网络具有来自卷积神经网络的“逆”结构，被恰当地命名为“去卷积”架构。另一个试图区分真实和虚假图像的网络是一个卷积网络，就像那些用于图像分类的网络一样，被称为“鉴别器”。</p><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/bf22d565c1706b5de61d152ebdbb1c46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*NTU9LT7Ts3VksTEhVOQaoQ.png"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Deconvolutional architecture of a “generator”. <a class="ae nf" href="https://medium.com/@awjuliani/generative-adversarial-networks-explained-with-a-classic-spongebob-squarepants-episode-54deab2fce39" rel="noopener">Source</a></figcaption></figure><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/506667a7c575133e63f1e586ff23d790.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*AerzoE54SBGPvF-8IhbCzQ.png"/></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Convolutional architecture of the “discriminator”. <a class="ae nf" href="https://medium.com/@awjuliani/generative-adversarial-networks-explained-with-a-classic-spongebob-squarepants-episode-54deab2fce39" rel="noopener">Source</a></figcaption></figure><p id="3fe1" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">在 GANs 的情况下，两个神经网络都是卷积神经网络，因为这些神经网络特别擅长从图像中提取特征。</p><h2 id="74a7" class="kf kg iq bd kh ki kj dn kk kl km dp kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">突破和资源</h2><figure class="mp mq mr ms gt mt gh gi paragraph-image"><div role="button" tabindex="0" class="mu mv di mw bf mx"><div class="gh gi od"><img src="../Images/4c48a9075e221813596aa2795aed51ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*45KebpoOu-mJTPnhmyMB5A.png"/></div></div><figcaption class="na nb gj gh gi nc nd bd b be z dk">Images generated by a GAN from a dataset of faces of celebrities. <a class="ae nf" href="https://github.com/carpedm20/DCGAN-tensorflow" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="b61a" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated"><strong class="ld ir"> Code </strong> : <a class="ae nf" href="https://github.com/carpedm20/DCGAN-tensorflow" rel="noopener ugc nofollow" target="_blank">这个</a> GitHub repo 既是一个关于使用 TensorFlow 训练 GANs 的很棒的教程，也包含了一些由 GANs 生成的引人注目的图像，比如上图。</p><p id="dda2" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated"><strong class="ld ir">理论</strong>:<a class="ae nf" href="https://www.youtube.com/watch?v=BzRgipHRzOE" rel="noopener ugc nofollow" target="_blank">Irmak Sirer 的这个演讲</a>是对 GANs 的有趣介绍，也涵盖了许多有监督的学习概念，这也将帮助你理解上面的发现。</p><p id="4eff" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">最后，优秀的 Arthur Juliani 在这里有另一个有趣的 GANs 的可视化解释，以及在 TensorFlow 中实现它的代码。</p><h1 id="50c7" class="ng kg iq bd kh nh ni nj kk nk nl nm kn jw nn jx kr jz no ka kv kc np kd kz nq bi translated">摘要</h1><p id="3185" class="pw-post-body-paragraph lb lc iq ld b le lf jr lg lh li ju lj ko lk ll lm ks ln lo lp kw lq lr ls lt ij bi translated">这是对深度学习在过去五年中产生最大突破的领域的高度概述。我们讨论的这些模型都有许多开源实现。这意味着您几乎总是可以下载一个“预训练”模型并将其应用于您的数据，例如，您可以下载预训练的图像分类器，您可以通过这些图像分类器输入数据，以便对新图像进行分类或在图像中的对象周围绘制方框。因为这项工作的大部分已经为你完成了，所以使用这些前沿技术所必需的工作不是“进行深度学习”本身——研究人员已经在很大程度上为你解决了这一部分——而是进行“开发”工作，以获得其他人为解决你的问题而开发的模型。</p><p id="716c" class="pw-post-body-paragraph lb lc iq ld b le lw jr lg lh lx ju lj ko mk ll lm ks ml lo lp kw mm lr ls lt ij bi translated">希望现在你对深度学习模型的能力有了一点更好的理解，并且更接近实际使用它们了！</p></div></div>    
</body>
</html>