<html>
<head>
<title>Complete Guide to Build ConvNet HTTP-Based Application using TensorFlow and Flask RESTful Python API</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 TensorFlow 和 Flask RESTful Python API 构建基于 ConvNet HTTP 的应用程序的完整指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/complete-guide-to-build-convnet-http-based-application-using-tensorflow-and-flask-restful-python-c6326b13878b?source=collection_archive---------10-----------------------#2018-05-01">https://towardsdatascience.com/complete-guide-to-build-convnet-http-based-application-using-tensorflow-and-flask-restful-python-c6326b13878b?source=collection_archive---------10-----------------------#2018-05-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="c22c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本教程将带您了解使用 TensorFlow 创建卷积神经网络(CNN/ConvNet)所需的步骤，并通过允许使用 Flask RESTful API 通过基于 HTTP 的应用程序进行远程访问，将其投入生产。</p><p id="74b2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该教程在 2018 年 5 月 15 日至 20 日期间在 KDnuggets.com 最常分享的帖子中排名第二。它获得了银质徽章。</p><p id="e46c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在本教程中，CNN 将使用 TensorFlow NN (tf.nn)模块构建。CNN 模型架构是针对 CIFAR10 数据集创建、训练和测试的。为了使模型可以远程访问，使用 Python 创建了一个 Flask Web 应用程序来接收上传的图像，并使用 HTTP 返回其分类标签。在有 CPU 支持的 Windows 上，除了 TensorFlow 之外，还使用 Anaconda3。本教程假设你对 CNN 有一个基本的了解，比如层、步幅和填充。还需要关于 Python 的知识。</p><p id="6177" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本教程总结为以下步骤:</p><p id="ee71" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">1.通过安装 Python、TensorFlow、PyCharm 和 Flask API 来准备环境。</p><p id="a7ec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2.下载和准备 CIFAR-10 数据集。</p><p id="b9dd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">3.用张量流建立 CNN 计算图。</p><p id="9ab5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">4.训练 CNN。</p><p id="362a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">5.保存训练好的 CNN 模型。</p><p id="b869" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">6.准备测试数据并恢复训练好的 CNN 模型。</p><p id="e0f3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">7.测试训练好的 CNN 模型。</p><p id="1ac1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">8.构建 Flask Web 应用程序。</p><p id="2a41" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">9.使用 HTML 表单上传图像。</p><p id="9ade" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">10.创建辅助 HTML、JavaScript 和 CSS 文件。</p><p id="d584" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">11.基于 HTTP 远程访问训练好的模型进行预测。</p><h1 id="e1dc" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated"><strong class="ak"> 1。安装 Python、TensorFlow、PyCharm 和 Flask API </strong></h1><p id="e22e" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">在开始构建项目之前，需要准备它的环境。Python 是第一个开始安装的工具，因为环境完全依赖于它。如果您已经准备好了环境，可以跳过第一步。</p><h2 id="55e3" class="lr kp it bd kq ls lt dn ku lu lv dp ky kb lw lx lc kf ly lz lg kj ma mb lk mc bi translated"><strong class="ak"> 1.1 Anaconda/Python 安装</strong></h2><p id="162d" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">可以安装原生 Python 发行版，但是建议使用一体化包，比如 Anaconda，因为它会为您做一些事情。在这个项目中，使用了 Anaconda 3。对于 Windows，可执行文件可以从 https://www.anaconda.com/download/#windows 的<a class="ae md" href="https://www.anaconda.com/download/#windows" rel="noopener ugc nofollow" target="_blank">下载。它很容易安装。</a></p><p id="238d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了确保 Anaconda3 安装正确，可以发出 CMD 命令(<em class="me">，其中 python </em>)，如图 1 所示。如果 Anaconda3 安装正确，它的安装路径将出现在命令输出中。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/46a4cdac6a13571e893ba65fff53af1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*AP9HcafdwZr9tI5RujSfpQ.png"/></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">Figure 1</figcaption></figure><h2 id="c3eb" class="lr kp it bd kq ls lt dn ku lu lv dp ky kb lw lx lc kf ly lz lg kj ma mb lk mc bi translated"><strong class="ak"> 1.2 张量流安装</strong></h2><p id="0eec" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">使用 Anaconda3 安装 Python 后，接下来就是安装 TensorFlow (TF)。本教程在有 CPU 支持的 Windows 上使用 TF。安装说明见本页<a class="ae md" href="https://www.tensorflow.org/install/install_windows" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/install/install_windows</a>。这段 YouTube 视频可能会有所帮助(【https://youtu.be/MsONo20MRVU】T2)。</p><p id="a16a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">TF 安装步骤如下:</p><p id="82ad" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 1)通过调用该命令为 TF 创建一个 conda 环境:</strong></p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="5ac2" class="lr kp it ms b gy mw mx l my mz">C:&gt; conda create -n tensorflow pip python=3.5</span></pre><p id="8179" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这将创建一个空文件夹来存放 TF 安装的虚拟环境(venv)。venv 位于此位置的 Anaconda3 安装目录下(\Anaconda3\envs\tensorflow)。</p><p id="1ca1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用此命令激活 TensorFlow 安装的 venv:</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="9f9c" class="lr kp it ms b gy mw mx l my mz">C:&gt; activate tensorflow</span></pre><p id="fea9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">上面的命令告诉我们，我们在 venv 内部，任何库安装都将在其中。在此命令之后，命令提示符应更改为(tensorflow)C:&gt;。进入目录后，我们准备安装库。</p><p id="5b3f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu"> 3)激活 venv 后，可以通过发出以下命令安装 Windows TensorFlow 的纯 CPU 版本:</strong></p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="cc92" class="lr kp it ms b gy mw mx l my mz"><strong class="ms iu">(tensorflow)C:&gt; pip install --ignore-installed --upgrade tensorflow</strong></span></pre><p id="0d59" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了测试 TF 是否安装正确，我们可以尝试如图 2 所示导入它。但是记住在导入 TF 之前，必须激活它的 venv。从 CMD 测试它，我们需要发出<strong class="js iu"> python </strong>命令，以便能够与 python 交互。因为导入行中没有出现错误，所以 TF 安装成功。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi na"><img src="../Images/fbcb151bc9665fd4fe43f1bd50ee45bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jl6_P8b-pbfW8_ErA-rbFA.png"/></div></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">Figure 2</figcaption></figure><h2 id="424e" class="lr kp it bd kq ls lt dn ku lu lv dp ky kb lw lx lc kf ly lz lg kj ma mb lk mc bi translated"><strong class="ak"> 1.3 PyCharm Python IDE 安装</strong></h2><p id="4abc" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">对于这个项目，建议使用 Python IDE，而不是在 CMD 中输入命令。本教程中使用的 IDE 是 PyCharm。它的 Windows 可执行文件可以从这个页面下载<a class="ae md" href="https://www.jetbrains.com/pycharm/download/#section=windows" rel="noopener ugc nofollow" target="_blank">https://www.jetbrains.com/pycharm/download/#section=windows</a>。它的安装说明非常简单。</p><p id="85a6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下载安装 PyCharm Python IDE 后，接下来就是和 TF 链接了。这是通过将其 Python 解释器设置为 TF venv 下安装的 Python 来实现的，如图 3 所示。这是通过打开 IDE 的设置并选择安装在 TF venv 中的<strong class="js iu">python.exe</strong>文件的项目解释器来完成的。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi nf"><img src="../Images/01602aa8b0f87c8b54a896848c6df9bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XgUB3A5w6Dyw8n4wmqOnKA.png"/></div></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">Figure 3</figcaption></figure><h2 id="63e6" class="lr kp it bd kq ls lt dn ku lu lv dp ky kb lw lx lc kf ly lz lg kj ma mb lk mc bi translated"><strong class="ak"> 1.4 烧瓶安装</strong></h2><p id="fe14" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">最后要安装的工具是 Flask RESTful API。它是一个要使用 pip/conda 安装程序在 TF venv 下使用以下 CMD 命令安装的库:</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="e648" class="lr kp it ms b gy mw mx l my mz">C:&gt; pip install Flask-API</span></pre><p id="2dd1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果 NumPy 和 SciPy 尚未安装，应该安装在 venv 中，以便能够读取和操作图像。</p><p id="ca44" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过安装 Anaconda (Python)、TensorFlow、PyCharm 和 Flask，我们已经准备好开始构建项目了。</p><h1 id="3210" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated"><strong class="ak"> 2。下载和准备 CIFAR-10 数据集</strong></h1><p id="f5fa" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">10 类 CIFAR 数据集(CIFAR-10)的 Python 版本可以从 https://www.cs.toronto.edu/~kriz/cifar.html<a class="ae md" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank">的这个页面下载。该数据集包含 60，000 幅图像，分为训练和测试数据。有五个保存训练数据的文件，其中每个文件有 10，000 个图像。这些图像是大小为 32x32x3 的 RGB。训练文件被命名为<strong class="js iu"> data_batch_1 </strong>、<strong class="js iu"> data_batch_2 </strong>等等。有一个保存测试数据的文件，名为<strong class="js iu"> test_batch </strong>，包含 10，000 个图像。有一个名为<strong class="js iu"> batches.meta </strong>的元数据文件，保存着数据集类标签，分别是<strong class="js iu">飞机</strong>、<strong class="js iu">汽车</strong>、<strong class="js iu">鸟</strong>、<strong class="js iu">猫</strong>、<strong class="js iu">鹿</strong>、<strong class="js iu">狗</strong>、<strong class="js iu">青蛙</strong>、<strong class="js iu">马</strong>、<strong class="js iu">船</strong>和<strong class="js iu">卡车</strong>。</a></p><p id="44ae" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因为数据集中的每个文件都是二进制文件，所以应该对其进行解码，以便检索实际的图像数据。为此，创建了一个名为 unpickle_patch 的函数来完成此类工作，定义如下:</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="dee5" class="lr kp it ms b gy mw mx l my mz">def unpickle_patch(file):<br/>"""<br/>Decoding the binary file.<br/>:param file:File to decode it data.<br/>:return: Dictionary of the file holding details including input data and output labels.<br/>"""<br/>patch_bin_file = open(file, 'rb')#Reading the binary file.<br/>patch_dict = pickle.load(patch_bin_file, encoding='bytes')#Loading the details of the binary file into a dictionary.<br/>return patch_dict#Returning the dictionary.</span></pre><p id="4902" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该方法接受二进制文件名，并返回一个包含该文件详细信息的字典。除了标签之外，字典还保存文件中所有 10，000 个样本的数据。</p><p id="3dfb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为了解码整个训练数据，创建了一个名为 get_dataset_images 的新函数。该函数接受数据集路径，并且只对定型数据起作用。因此，它会过滤该路径下的文件，并仅返回以<strong class="js iu"> data_batch_ </strong>开头的文件。测试数据是在构建和训练 CNN 之后准备的。</p><p id="1cce" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于每个训练文件，通过调用 unpickle_patch 函数对其进行解码。基于此类函数返回的字典，get_dataset_images 函数返回图像数据及其类标签。从<strong class="js iu">‘数据’</strong>键检索图像数据，从<strong class="js iu">‘标签’</strong>键检索图像的类别标签。</p><p id="aa3a" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因为图像数据保存为 1D 矢量，它应该被整形为三维。这是因为张量流接受这种形状的图像。因此，get_dataset_images 函数除了接受每个图像中的通道数之外，还接受行数/列数作为参数。</p><p id="d388" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">该功能的实现如下:</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="b914" class="lr kp it ms b gy mw mx l my mz">def get_dataset_images(dataset_path, im_dim=32, num_channels=3):<br/>    """<br/>    This function accepts the dataset path, reads the data, and returns it after being reshaped to match the requierments of the CNN.<br/>    :param dataset_path:Path of the CIFAR10 dataset binary files.<br/>    :param im_dim:Number of rows and columns in each image. The image is expected to be rectangular.<br/>    :param num_channels:Number of color channels in the image.<br/>    :return:Returns the input data after being reshaped and output labels.<br/>    """<br/>    num_files = 5#Number of training binary files in the CIFAR10 dataset.<br/>    images_per_file = 10000#Number of samples withing each binary file.<br/>    files_names = os.listdir(patches_dir)#Listing the binary files in the dataset path.<br/>    """<br/>    Creating an empty array to hold the entire training data after being reshaped.<br/>    The dataset has 5 binary files holding the data. Each binary file has 10,000 samples. Total number of samples in the dataset is 5*10,000=50,000.<br/>    Each sample has a total of 3,072 pixels. These pixels are reshaped to form a RGB image of shape 32x32x3.<br/>    Finally, the entire dataset has 50,000 samples and each sample of shape 32x32x3 (50,000x32x32x3).<br/>    """<br/>    dataset_array = numpy.zeros(shape=(num_files * images_per_file, im_dim, im_dim, num_channels))<br/>    #Creating an empty array to hold the labels of each input sample. Its size is 50,000 to hold the label of each sample in the dataset.<br/>    dataset_labels = numpy.zeros(shape=(num_files * images_per_file), dtype=numpy.uint8)<br/>    index = 0#Index variable to count number of training binary files being processed.<br/>    for file_name in files_names:<br/>        """<br/>        Because the CIFAR10 directory does not only contain the desired training files and has some  other files, it is required to filter the required files.<br/>        Training files start by 'data_batch_' which is used to test whether the file is for training or not.<br/>        """<br/>        if file_name[0:len(file_name) - 1] == "data_batch_":<br/>            print("Working on : ", file_name)<br/>            """<br/>            Appending the path of the binary files to the name of the current file.<br/>            Then the complete path of the binary file is used to decoded the file and return the actual pixels values.<br/>            """<br/>            data_dict = unpickle_patch(dataset_path+file_name)<br/>            """<br/>            Returning the data using its key 'data' in the dictionary.<br/>            Character b is used before the key to tell it is binary string.<br/>            """<br/>            images_data = data_dict[b"data"]<br/>            #Reshaping all samples in the current binary file to be of 32x32x3 shape.<br/>            images_data_reshaped = numpy.reshape(images_data, newshape=(len(images_data), im_dim, im_dim, num_channels))<br/>            #Appending the data of the current file after being reshaped.<br/>            dataset_array[index * images_per_file:(index + 1) * images_per_file, :, :, :] = images_data_reshaped<br/>            #Appening the labels of the current file.<br/>            dataset_labels[index * images_per_file:(index + 1) * images_per_file] = data_dict[b"labels"]<br/>            index = index + 1#Incrementing the counter of the processed training files by 1 to accept new file.<br/>    return dataset_array, dataset_labels#Returning the training input data and output labels.</span></pre><p id="dd8b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通过准备训练数据，我们可以使用 TF 建立和训练 CNN 模型。</p><h1 id="a986" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated"><strong class="ak"> 3。使用 TensorFlow </strong>构建 CNN 计算图</h1><p id="a3e8" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">CNN 的计算图是在一个名为 create_CNN 的函数中创建的。它创建卷积(conv)、ReLU、最大池化、下降和完全连接(FC)图层的堆栈，并返回最后一个完全连接图层的结果。每一层的输出都是下一层的输入。这要求相邻层的输出和输入的大小一致。请注意，对于每个 conv、ReLU 和 max 池层，有一些参数需要指定，如每个维度的跨度和填充。</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="9371" class="lr kp it ms b gy mw mx l my mz">def create_CNN(input_data, num_classes, keep_prop):<br/>"""<br/>Builds the CNN architecture by stacking conv, relu, pool, dropout, and fully connected layers.<br/>:param input_data:patch data to be processed.<br/>:param num_classes:Number of classes in the dataset. It helps determining the number of outputs in the last fully connected layer.<br/>:param keep_prop:probability of dropping neurons in the dropout layer.<br/>:return: last fully connected layer.<br/>"""<br/>#Preparing the first convolution layer.<br/>filters1, conv_layer1 = create_conv_layer(input_data=input_data, filter_size=5, num_filters=4)<br/>"""<br/>Applying ReLU activation function over the conv layer output.<br/>It returns a new array of the same shape as the input array.<br/>"""<br/>relu_layer1 = tensorflow.nn.relu(conv_layer1)<br/>print("Size of relu1 result : ", relu_layer1.shape)<br/>"""<br/>Max pooling is applied to the ReLU layer result to achieve translation invariance.<br/>It returns a new array of a different shape from the the input array relative to the strides and kernel size used.<br/>"""<br/>max_pooling_layer1 = tensorflow.nn.max_pool(value=relu_layer1, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding="VALID")<br/>print("Size of maxpool1 result : ", max_pooling_layer1.shape)</span><span id="b3da" class="lr kp it ms b gy ng mx l my mz">#Similar to the previous conv-relu-pool layers, new layers are just stacked to complete the CNN architecture.<br/>#Conv layer with 3 filters and each filter is of sisze of 5x5.<br/>filters2, conv_layer2 = create_conv_layer(input_data=max_pooling_layer1, filter_size=7, num_filters=3)<br/>relu_layer2 = tensorflow.nn.relu(conv_layer2)<br/>print("Size of relu2 result : ", relu_layer2.shape)<br/>max_pooling_layer2 = tensorflow.nn.max_pool(value=relu_layer2, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding="VALID")<br/>print("Size of maxpool2 result : ", max_pooling_layer2.shape)</span><span id="73dd" class="lr kp it ms b gy ng mx l my mz">#Conv layer with 2 filters and a filter sisze of 5x5.<br/>filters3, conv_layer3 = create_conv_layer(input_data=max_pooling_layer2, filter_size=5, num_filters=2)<br/>relu_layer3 = tensorflow.nn.relu(conv_layer3)<br/>print("Size of relu3 result : ", relu_layer3.shape)<br/>max_pooling_layer3 = tensorflow.nn.max_pool(value=relu_layer3, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding="VALID")<br/>print("Size of maxpool3 result : ", max_pooling_layer3.shape)</span><span id="7e1d" class="lr kp it ms b gy ng mx l my mz">#Adding dropout layer before the fully connected layers to avoid overfitting.<br/>flattened_layer = dropout_flatten_layer(previous_layer=max_pooling_layer3, keep_prop=keep_prop)</span><span id="3a8a" class="lr kp it ms b gy ng mx l my mz">#First fully connected (FC) layer. It accepts the result of the dropout layer after being flattened (1D).<br/>fc_resultl = fc_layer(flattened_layer=flattened_layer, num_inputs=flattened_layer.get_shape()[1:].num_elements(),<br/>num_outputs=200)<br/>#Second fully connected layer accepting the output of the previous fully connected layer. Number of outputs is equal to the number of dataset classes.<br/>fc_result2 = fc_layer(flattened_layer=fc_resultl, num_inputs=fc_resultl.get_shape()[1:].num_elements(), num_outputs=num_classes)<br/>print("Fully connected layer results : ", fc_result2)<br/>return fc_result2#Returning the result of the last FC layer.</span></pre><p id="b573" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因为卷积层在输入数据和所用的一组过滤器之间应用卷积运算，所以 create_CNN 函数接受输入数据作为输入参数。get_dataset_images 函数返回的就是这样的数据。卷积图层是使用创建 conv 图层函数创建的。create_conv_layer 函数接受输入数据、过滤器大小和过滤器数量，并返回输入数据与过滤器集合的卷积结果。这组滤波器根据输入图像的深度来设置它们的大小。创建 conv 层的定义如下:</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="c6b8" class="lr kp it ms b gy mw mx l my mz">def create_conv_layer(input_data, filter_size, num_filters):</span><span id="1478" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="fca1" class="lr kp it ms b gy ng mx l my mz">Builds the CNN convolution (conv) layer.</span><span id="d126" class="lr kp it ms b gy ng mx l my mz">:param input_data:patch data to be processed.</span><span id="cec9" class="lr kp it ms b gy ng mx l my mz">:param filter_size:#Number of rows and columns of each filter. It is expected to have a rectangular filter.</span><span id="dd34" class="lr kp it ms b gy ng mx l my mz">:param num_filters:Number of filters.</span><span id="ec77" class="lr kp it ms b gy ng mx l my mz">:return:The last fully connected layer of the network.</span><span id="7675" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="a9c0" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="adc8" class="lr kp it ms b gy ng mx l my mz">Preparing the filters of the conv layer by specifiying its shape.</span><span id="6926" class="lr kp it ms b gy ng mx l my mz">Number of channels in both input image and each filter must match.</span><span id="a15f" class="lr kp it ms b gy ng mx l my mz">Because number of channels is specified in the shape of the input image as the last value, index of -1 works fine.</span><span id="0ace" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="552c" class="lr kp it ms b gy ng mx l my mz">filters = tensorflow.Variable(tensorflow.truncated_normal(shape=(filter_size, filter_size, tensorflow.cast(input_data.shape[-1], dtype=tensorflow.int32), num_filters),</span><span id="8c02" class="lr kp it ms b gy ng mx l my mz">stddev=0.05))</span><span id="90cf" class="lr kp it ms b gy ng mx l my mz">print("Size of conv filters bank : ", filters.shape)</span><span id="42d6" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="474a" class="lr kp it ms b gy ng mx l my mz">Building the convolution layer by specifying the input data, filters, strides along each of the 4 dimensions, and the padding.</span><span id="e57a" class="lr kp it ms b gy ng mx l my mz">Padding value of 'VALID' means the some borders of the input image will be lost in the result based on the filter size.</span><span id="1fd9" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="4e23" class="lr kp it ms b gy ng mx l my mz">conv_layer = tensorflow.nn.conv2d(input=input_data,</span><span id="8f21" class="lr kp it ms b gy ng mx l my mz">filter=filters,</span><span id="01d7" class="lr kp it ms b gy ng mx l my mz">strides=[1, 1, 1, 1],</span><span id="c947" class="lr kp it ms b gy ng mx l my mz">padding="VALID")</span><span id="aa0a" class="lr kp it ms b gy ng mx l my mz">print("Size of conv result : ", conv_layer.shape)</span><span id="9fc2" class="lr kp it ms b gy ng mx l my mz">return filters, conv_layer#Returing the filters and the convolution layer result.</span></pre><p id="2d9d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">另一个论点是神经元留在脱落层的概率。它指定有多少神经元被丢弃层丢弃。dropout 层是使用 dropout_flatten_layer 函数实现的，如下所示。该函数返回一个展平的数组，该数组将作为完全连接的层的输入。</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="deb1" class="lr kp it ms b gy mw mx l my mz">def dropout_flatten_layer(previous_layer, keep_prop):</span><span id="3b79" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="35f6" class="lr kp it ms b gy ng mx l my mz">Applying the dropout layer.</span><span id="4e19" class="lr kp it ms b gy ng mx l my mz">:param previous_layer: Result of the previous layer to the dropout layer.</span><span id="4e35" class="lr kp it ms b gy ng mx l my mz">:param keep_prop: Probability of keeping neurons.</span><span id="6cb1" class="lr kp it ms b gy ng mx l my mz">:return: flattened array.</span><span id="9aa6" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="1fdc" class="lr kp it ms b gy ng mx l my mz">dropout = tensorflow.nn.dropout(x=previous_layer, keep_prob=keep_prop)</span><span id="f5ae" class="lr kp it ms b gy ng mx l my mz">num_features = dropout.get_shape()[1:].num_elements()</span><span id="b391" class="lr kp it ms b gy ng mx l my mz">layer = tensorflow.reshape(previous_layer, shape=(-1, num_features))#Flattening the results.</span><span id="0b9f" class="lr kp it ms b gy ng mx l my mz">return layer</span></pre><p id="2276" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因为最后一个 FC 层的输出神经元的数量应该等于数据集类的数量，所以数据集类的数量被用作 create_CNN 函数的另一个输入参数。使用 fc_layer 函数创建完全连接的层。该函数接受丢弃层的展平结果、展平结果中的特征数量以及 FC 层的输出神经元数量。根据输入和输出的数量，创建一个权重张量，然后乘以展平层，以获得 FC 层的返回结果。</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="4137" class="lr kp it ms b gy mw mx l my mz">def fc_layer(flattened_layer, num_inputs, num_outputs):</span><span id="8f16" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="fb0c" class="lr kp it ms b gy ng mx l my mz">uilds a fully connected (FC) layer.</span><span id="46d2" class="lr kp it ms b gy ng mx l my mz">:param flattened_layer: Previous layer after being flattened.</span><span id="fb7e" class="lr kp it ms b gy ng mx l my mz">:param num_inputs: Number of inputs in the previous layer.</span><span id="bc36" class="lr kp it ms b gy ng mx l my mz">:param num_outputs: Number of outputs to be returned in such FC layer.</span><span id="ff2a" class="lr kp it ms b gy ng mx l my mz">:return:</span><span id="7b31" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="eff6" class="lr kp it ms b gy ng mx l my mz">#Preparing the set of weights for the FC layer. It depends on the number of inputs and number of outputs.</span><span id="02a5" class="lr kp it ms b gy ng mx l my mz">fc_weights = tensorflow.Variable(tensorflow.truncated_normal(shape=(num_inputs, num_outputs),</span><span id="c0a1" class="lr kp it ms b gy ng mx l my mz">stddev=0.05))</span><span id="6337" class="lr kp it ms b gy ng mx l my mz">#Matrix multiplication between the flattened array and the set of weights.</span><span id="f6a5" class="lr kp it ms b gy ng mx l my mz">fc_resultl = tensorflow.matmul(flattened_layer, fc_weights)</span><span id="c918" class="lr kp it ms b gy ng mx l my mz">return fc_resultl#Output of the FC layer (result of matrix multiplication).</span></pre><p id="39b0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用 TensorBoard 可视化后的计算图如图 4 所示。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi nh"><img src="../Images/64599068b8ece7d787e86f907825d63d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XmcQt2yIDmUY6o0AhRS1ew.png"/></div></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">Figure 4</figcaption></figure><h1 id="7e06" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated"><strong class="ak"> 4。训练 CNN </strong></h1><p id="889a" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">在构建了 CNN 的计算图之后，接下来是针对先前准备的训练数据来训练它。训练是根据下面的代码完成的。代码首先准备数据集的路径，并将其准备到一个占位符中。请注意，路径应该更改为适合您的系统。然后它调用前面讨论过的函数。被训练的 CNN 的预测被用于测量网络的成本，该成本将使用梯度下降优化器被最小化。注意:一些张量有一个名字，这有助于以后测试 CNN 时检索这些张量。</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="5919" class="lr kp it ms b gy mw mx l my mz">#Nnumber of classes in the dataset. Used to specify number of outputs in the last fully connected layer.</span><span id="8217" class="lr kp it ms b gy ng mx l my mz">num_datatset_classes = 10</span><span id="4e3f" class="lr kp it ms b gy ng mx l my mz">#Number of rows &amp; columns in each input image. The image is expected to be rectangular Used to reshape the images and specify the input tensor shape.</span><span id="0762" class="lr kp it ms b gy ng mx l my mz">im_dim = 32</span><span id="80bf" class="lr kp it ms b gy ng mx l my mz">#Number of channels in rach input image. Used to reshape the images and specify the input tensor shape.</span><span id="6f58" class="lr kp it ms b gy ng mx l my mz">num_channels = 3</span><span id="051c" class="lr kp it ms b gy ng mx l my mz">#Directory at which the training binary files of the CIFAR10 dataset are saved.</span><span id="6e2a" class="lr kp it ms b gy ng mx l my mz">patches_dir = "C:\\Users\\Dell\\Downloads\\Compressed\\cifar-10-python\\cifar-10-batches-py\\"</span><span id="beff" class="lr kp it ms b gy ng mx l my mz">#Reading the CIFAR10 training binary files and returning the input data and output labels. Output labels are used to test the CNN prediction accuracy.</span><span id="8e8b" class="lr kp it ms b gy ng mx l my mz">dataset_array, dataset_labels = get_dataset_images(dataset_path=patches_dir, im_dim=im_dim, num_channels=num_channels)</span><span id="832e" class="lr kp it ms b gy ng mx l my mz">print("Size of data : ", dataset_array.shape)</span><span id="bab5" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="39f2" class="lr kp it ms b gy ng mx l my mz">Input tensor to hold the data read above. It is the entry point of the computational graph.</span><span id="cdff" class="lr kp it ms b gy ng mx l my mz">The given name of 'data_tensor' is useful for retreiving it when restoring the trained model graph for testing.</span><span id="85fa" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="b9be" class="lr kp it ms b gy ng mx l my mz">data_tensor = tensorflow.placeholder(tensorflow.float32, shape=[None, im_dim, im_dim, num_channels], name='data_tensor')</span><span id="5170" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="ec53" class="lr kp it ms b gy ng mx l my mz">Tensor to hold the outputs label.</span><span id="32ab" class="lr kp it ms b gy ng mx l my mz">The name "label_tensor" is used for accessing the tensor when tesing the saved trained model after being restored.</span><span id="4ef7" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="82d5" class="lr kp it ms b gy ng mx l my mz">label_tensor = tensorflow.placeholder(tensorflow.float32, shape=[None], name='label_tensor')</span><span id="fc34" class="lr kp it ms b gy ng mx l my mz">#The probability of dropping neurons in the dropout layer. It is given a name for accessing it later.</span><span id="d464" class="lr kp it ms b gy ng mx l my mz">keep_prop = tensorflow.Variable(initial_value=0.5, name="keep_prop")</span><span id="9848" class="lr kp it ms b gy ng mx l my mz">#Building the CNN architecure and returning the last layer which is the fully connected layer.</span><span id="8327" class="lr kp it ms b gy ng mx l my mz">fc_result2 = create_CNN(input_data=data_tensor, num_classes=num_datatset_classes, keep_prop=keep_prop)</span><span id="9903" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="8458" class="lr kp it ms b gy ng mx l my mz">Predicitions probabilities of the CNN for each training sample.</span><span id="2114" class="lr kp it ms b gy ng mx l my mz">Each sample has a probability for each of the 10 classes in the dataset.</span><span id="dd5a" class="lr kp it ms b gy ng mx l my mz">Such tensor is given a name for accessing it later.</span><span id="00b4" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="a01d" class="lr kp it ms b gy ng mx l my mz">softmax_propabilities = tensorflow.nn.softmax(fc_result2, name="softmax_probs")</span><span id="8e7a" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="29b0" class="lr kp it ms b gy ng mx l my mz">Predicitions labels of the CNN for each training sample.</span><span id="7bd6" class="lr kp it ms b gy ng mx l my mz">The input sample is classified as the class of the highest probability.</span><span id="4ce8" class="lr kp it ms b gy ng mx l my mz">axis=1 indicates that maximum of values in the second axis is to be returned. This returns that maximum class probability fo each sample.</span><span id="c5bd" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="9df0" class="lr kp it ms b gy ng mx l my mz">softmax_predictions = tensorflow.argmax(softmax_propabilities, axis=1)</span><span id="c421" class="lr kp it ms b gy ng mx l my mz">#Cross entropy of the CNN based on its calculated probabilities.</span><span id="a1d4" class="lr kp it ms b gy ng mx l my mz">cross_entropy = tensorflow.nn.softmax_cross_entropy_with_logits(logits=tensorflow.reduce_max(input_tensor=softmax_propabilities, reduction_indices=[1]),</span><span id="f59f" class="lr kp it ms b gy ng mx l my mz">labels=label_tensor)</span><span id="b4f0" class="lr kp it ms b gy ng mx l my mz">#Summarizing the cross entropy into a single value (cost) to be minimized by the learning algorithm.</span><span id="e373" class="lr kp it ms b gy ng mx l my mz">cost = tensorflow.reduce_mean(cross_entropy)</span><span id="a82b" class="lr kp it ms b gy ng mx l my mz">#Minimizng the network cost using the Gradient Descent optimizer with a learning rate is 0.01.</span><span id="a8ae" class="lr kp it ms b gy ng mx l my mz">error = tensorflow.train.GradientDescentOptimizer(learning_rate=.01).minimize(cost)</span><span id="8f53" class="lr kp it ms b gy ng mx l my mz">#Creating a new TensorFlow Session to process the computational graph.</span><span id="9680" class="lr kp it ms b gy ng mx l my mz">sess = tensorflow.Session()</span><span id="4122" class="lr kp it ms b gy ng mx l my mz">#Wiriting summary of the graph to visualize it using TensorBoard.</span><span id="2882" class="lr kp it ms b gy ng mx l my mz">tensorflow.summary.FileWriter(logdir="./log/", graph=sess.graph)</span><span id="2352" class="lr kp it ms b gy ng mx l my mz">#Initializing the variables of the graph.</span><span id="2cce" class="lr kp it ms b gy ng mx l my mz">sess.run(tensorflow.global_variables_initializer())</span><span id="3010" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="c2a7" class="lr kp it ms b gy ng mx l my mz">Because it may be impossible to feed the complete data to the CNN on normal machines, it is recommended to split the data into a number of patches.</span><span id="928d" class="lr kp it ms b gy ng mx l my mz">A percent of traning samples is used to create each path. Samples for each path can be randomly selected.</span><span id="f9f4" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="c908" class="lr kp it ms b gy ng mx l my mz">num_patches = 5#Number of patches</span><span id="01d3" class="lr kp it ms b gy ng mx l my mz">for patch_num in numpy.arange(num_patches):</span><span id="2bce" class="lr kp it ms b gy ng mx l my mz">print("Patch : ", str(patch_num))</span><span id="e451" class="lr kp it ms b gy ng mx l my mz">percent = 80 #percent of samples to be included in each path.</span><span id="cec1" class="lr kp it ms b gy ng mx l my mz">#Getting the input-output data of the current path.</span><span id="6b07" class="lr kp it ms b gy ng mx l my mz">shuffled_data, shuffled_labels = get_patch(data=dataset_array, labels=dataset_labels, percent=percent)</span><span id="a168" class="lr kp it ms b gy ng mx l my mz">#Data required for cnn operation. 1)Input Images, 2)Output Labels, and 3)Dropout probability</span><span id="823a" class="lr kp it ms b gy ng mx l my mz">cnn_feed_dict = {data_tensor: shuffled_data,</span><span id="198d" class="lr kp it ms b gy ng mx l my mz">label_tensor: shuffled_labels,</span><span id="46c3" class="lr kp it ms b gy ng mx l my mz">keep_prop: 0.5}</span><span id="e92f" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="7143" class="lr kp it ms b gy ng mx l my mz">Training the CNN based on the current patch.</span><span id="4072" class="lr kp it ms b gy ng mx l my mz">CNN error is used as input in the run to minimize it.</span><span id="9e16" class="lr kp it ms b gy ng mx l my mz">SoftMax predictions are returned to compute the classification accuracy.</span><span id="de4e" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="afba" class="lr kp it ms b gy ng mx l my mz">softmax_predictions_, _ = sess.run([softmax_predictions, error], feed_dict=cnn_feed_dict)</span><span id="f3a1" class="lr kp it ms b gy ng mx l my mz">#Calculating number of correctly classified samples.</span><span id="7af2" class="lr kp it ms b gy ng mx l my mz">correct = numpy.array(numpy.where(softmax_predictions_ == shuffled_labels))</span><span id="cc42" class="lr kp it ms b gy ng mx l my mz">correct = correct.size</span><span id="da4e" class="lr kp it ms b gy ng mx l my mz">print("Correct predictions/", str(percent * 50000/100), ' : ', correct)</span></pre><p id="3fa5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">不是将整个训练数据提供给 CNN，而是将数据分成一组小块，然后一个小块一个小块地通过环路提供给网络。每个补丁包含训练数据的子集。使用 get_patch 函数返回补丁。该函数接受输入数据、标签以及从这些数据中返回的样本百分比。然后，它根据输入的百分比返回数据的子集。</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="4948" class="lr kp it ms b gy mw mx l my mz">def get_patch(data, labels, percent=70):</span><span id="d249" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="7c6a" class="lr kp it ms b gy ng mx l my mz">Returning patch to train the CNN.</span><span id="2b4e" class="lr kp it ms b gy ng mx l my mz">:param data: Complete input data after being encoded and reshaped.</span><span id="7cd5" class="lr kp it ms b gy ng mx l my mz">:param labels: Labels of the entire dataset.</span><span id="235c" class="lr kp it ms b gy ng mx l my mz">:param percent: Percent of samples to get returned in each patch.</span><span id="a253" class="lr kp it ms b gy ng mx l my mz">:return: Subset of the data (patch) to train the CNN model.</span><span id="165d" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="6858" class="lr kp it ms b gy ng mx l my mz">#Using the percent of samples per patch to return the actual number of samples to get returned.</span><span id="75e7" class="lr kp it ms b gy ng mx l my mz">num_elements = numpy.uint32(percent*data.shape[0]/100)</span><span id="74fd" class="lr kp it ms b gy ng mx l my mz">shuffled_labels = labels#Temporary variable to hold the data after being shuffled.</span><span id="b8d8" class="lr kp it ms b gy ng mx l my mz">numpy.random.shuffle(shuffled_labels)#Randomly reordering the labels.</span><span id="f976" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="80cd" class="lr kp it ms b gy ng mx l my mz">The previously specified percent of the data is returned starting from the beginning until meeting the required number of samples.</span><span id="57d8" class="lr kp it ms b gy ng mx l my mz">The labels indices are also used to return their corresponding input images samples.</span><span id="1eeb" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="4c14" class="lr kp it ms b gy ng mx l my mz">return data[shuffled_labels[:num_elements], :, :, :], shuffled_labels[:num_elements]</span></pre><h1 id="7507" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated"><strong class="ak"> 5。保存训练好的 CNN 模型</strong></h1><p id="27f0" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">在对 CNN 进行训练之后，模型被保存起来，供以后在另一个 Python 脚本中测试时重用。您还应该更改保存模型的路径，以适合您的系统。</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="01cd" class="lr kp it ms b gy mw mx l my mz">#Saving the model after being trained.<br/>saver = tensorflow.train.Saver()<br/>save_model_path = "C:\\model\\"<br/>save_path = saver.save(sess=sess, save_path=save_model_path+"model.ckpt")<br/>print("Model saved in : ", save_path)</span></pre><h1 id="0cc7" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated"><strong class="ak"> 6。准备测试数据，恢复训练好的 CNN 模型</strong></h1><p id="2492" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">在测试训练好的模型之前，需要准备测试数据并恢复之前训练好的模型。测试数据准备与训练数据类似，只是只有一个二进制文件需要解码。根据修改的 get_dataset_images 函数对测试文件进行解码。这个函数调用 unpickle_patch 函数，就像之前对训练数据所做的一样。</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="4c49" class="lr kp it ms b gy mw mx l my mz">def get_dataset_images(test_path_path, im_dim=32, num_channels=3):</span><span id="631a" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="0f84" class="lr kp it ms b gy ng mx l my mz">Similar to the one used in training except that there is just a single testing binary file for testing the CIFAR10 trained models.</span><span id="bcfd" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="4006" class="lr kp it ms b gy ng mx l my mz">print("Working on testing patch")</span><span id="9274" class="lr kp it ms b gy ng mx l my mz">data_dict = unpickle_patch(test_path_path)</span><span id="6d7d" class="lr kp it ms b gy ng mx l my mz">images_data = data_dict[b"data"]</span><span id="5c16" class="lr kp it ms b gy ng mx l my mz">dataset_array = numpy.reshape(images_data, newshape=(len(images_data), im_dim, im_dim, num_channels))</span><span id="41df" class="lr kp it ms b gy ng mx l my mz">return dataset_array, data_dict[b"labels"]</span></pre><h1 id="7639" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated"><strong class="ak"> 7。测试训练好的 CNN 模型。</strong></h1><p id="e795" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">准备好测试数据，恢复训练好的模型后，我们就可以按照下面的代码开始测试模型了。值得一提的是，我们的目标只是返回输入样本的网络预测。这就是为什么 TF 会话只返回预测。当训练 CNN 时，会话运行以最小化成本。在测试中，我们不再对最小化成本感兴趣。另一个有趣的地方是，dropout 层的保持概率现在被设置为 1。这意味着不要删除任何节点。这是因为我们只是在确定了要删除的节点后才使用预训练模型。现在，我们只是使用模型之前所做的，并不关心通过删除其他节点来修改它。</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="63c0" class="lr kp it ms b gy mw mx l my mz">#Dataset path containing the testing binary file to be decoded.</span><span id="e163" class="lr kp it ms b gy ng mx l my mz">patches_dir = "C:\\Users\\Dell\\Downloads\\Compressed\\cifar-10-python\\cifar-10-batches-py\\"</span><span id="9b5f" class="lr kp it ms b gy ng mx l my mz">dataset_array, dataset_labels = get_dataset_images(test_path_path=patches_dir + "test_batch", im_dim=32, num_channels=3)</span><span id="190d" class="lr kp it ms b gy ng mx l my mz">print("Size of data : ", dataset_array.shape)</span><span id="86c3" class="lr kp it ms b gy ng mx l my mz">sess = tensorflow.Session()</span><span id="0ce2" class="lr kp it ms b gy ng mx l my mz">#Restoring the previously saved trained model.</span><span id="9cd1" class="lr kp it ms b gy ng mx l my mz">saved_model_path = 'C:\\Users\\Dell\\Desktop\\model\\'</span><span id="7ba4" class="lr kp it ms b gy ng mx l my mz">saver = tensorflow.train.import_meta_graph(saved_model_path+'model.ckpt.meta')</span><span id="1836" class="lr kp it ms b gy ng mx l my mz">saver.restore(sess=sess, save_path=saved_model_path+'model.ckpt')</span><span id="3bc2" class="lr kp it ms b gy ng mx l my mz">#Initalizing the varaibales.</span><span id="1921" class="lr kp it ms b gy ng mx l my mz">sess.run(tensorflow.global_variables_initializer())</span><span id="5508" class="lr kp it ms b gy ng mx l my mz">graph = tensorflow.get_default_graph()</span><span id="d93d" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="2e93" class="lr kp it ms b gy ng mx l my mz">Restoring previous created tensors in the training phase based on their given tensor names in the training phase.</span><span id="9942" class="lr kp it ms b gy ng mx l my mz">Some of such tensors will be assigned the testing input data and their outcomes (data_tensor, label_tensor, and keep_prop).</span><span id="026d" class="lr kp it ms b gy ng mx l my mz">Others are helpful in assessing the model prediction accuracy (softmax_propabilities and softmax_predictions).</span><span id="90aa" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="1971" class="lr kp it ms b gy ng mx l my mz">softmax_propabilities = graph.get_tensor_by_name(name="softmax_probs:0")</span><span id="e3ae" class="lr kp it ms b gy ng mx l my mz">softmax_predictions = tensorflow.argmax(softmax_propabilities, axis=1)</span><span id="3a25" class="lr kp it ms b gy ng mx l my mz">data_tensor = graph.get_tensor_by_name(name="data_tensor:0")</span><span id="76a0" class="lr kp it ms b gy ng mx l my mz">label_tensor = graph.get_tensor_by_name(name="label_tensor:0")</span><span id="2507" class="lr kp it ms b gy ng mx l my mz">keep_prop = graph.get_tensor_by_name(name="keep_prop:0")</span><span id="5126" class="lr kp it ms b gy ng mx l my mz">#keep_prop is equal to 1 because there is no more interest to remove neurons in the testing phase.</span><span id="e4a3" class="lr kp it ms b gy ng mx l my mz">feed_dict_testing = {data_tensor: dataset_array,</span><span id="8c47" class="lr kp it ms b gy ng mx l my mz">label_tensor: dataset_labels,</span><span id="3e23" class="lr kp it ms b gy ng mx l my mz">keep_prop: 1.0}</span><span id="c782" class="lr kp it ms b gy ng mx l my mz">#Running the session to predict the outcomes of the testing samples.</span><span id="c1ce" class="lr kp it ms b gy ng mx l my mz">softmax_propabilities_, softmax_predictions_ = sess.run([softmax_propabilities, softmax_predictions],</span><span id="dfce" class="lr kp it ms b gy ng mx l my mz">feed_dict=feed_dict_testing)</span><span id="1bfb" class="lr kp it ms b gy ng mx l my mz">#Assessing the model accuracy by counting number of correctly classified samples.</span><span id="e622" class="lr kp it ms b gy ng mx l my mz">correct = numpy.array(numpy.where(softmax_predictions_ == dataset_labels))</span><span id="11f9" class="lr kp it ms b gy ng mx l my mz">correct = correct.size</span><span id="547b" class="lr kp it ms b gy ng mx l my mz">print("Correct predictions/10,000 : ", correct)</span></pre><h1 id="00d8" class="ko kp it bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated"><strong class="ak"> 8。构建 Flask Web 应用程序</strong></h1><p id="f5e8" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">在训练 CNN 模型之后，我们可以将它添加到 HTTP 服务器上，并允许用户在线使用它。用户将使用 HTTP 客户端上传图像。上传的图像将由 HTTP 服务器接收，或者更具体地说，由 Flask Web 应用程序接收。这种应用将基于训练的模型预测图像的类别标签，并最终将类别标签返回给 HTTP 客户端。图 5 总结了这种讨论。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi ni"><img src="../Images/5790170ad62ff84c1e5b1ae3265cec73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OH34_ZyPJmA_f1BzNRvXaQ.png"/></div></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">Figure 5</figcaption></figure><p id="c2ab" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">要开始构建 flask 应用程序，需要创建 Flask 库，并使用 Flask 类创建一个新的应用程序。最后，这样的应用程序将运行以从 Web 访问。此类应用程序有一些属性，如访问它的主机、端口号和返回调试信息的调试标志。运行应用程序后，可以使用指定的主机和端口号来访问它。</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="17b8" class="lr kp it ms b gy mw mx l my mz">import flask</span><span id="58c3" class="lr kp it ms b gy ng mx l my mz">#Creating a new Flask Web application. It accepts the package name.</span><span id="6e24" class="lr kp it ms b gy ng mx l my mz">app = flask.Flask("CIFAR10_Flask_Web_App")</span><span id="0cbb" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="8e69" class="lr kp it ms b gy ng mx l my mz">To activate the Web server to receive requests, the application must run.</span><span id="1284" class="lr kp it ms b gy ng mx l my mz">A good practice is to check whether the file is whether the file called from an external Python file or not.</span><span id="2d04" class="lr kp it ms b gy ng mx l my mz">If not, then it will run.</span><span id="5bf4" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="583a" class="lr kp it ms b gy ng mx l my mz">if __name__ == "__main__":</span><span id="c2c6" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="c489" class="lr kp it ms b gy ng mx l my mz">In this example, the app will run based on the following properties:</span><span id="692a" class="lr kp it ms b gy ng mx l my mz">host: localhost</span><span id="af84" class="lr kp it ms b gy ng mx l my mz">port: 7777</span><span id="5642" class="lr kp it ms b gy ng mx l my mz">debug: flag set to True to return debugging information.</span><span id="8fb2" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="7d7f" class="lr kp it ms b gy ng mx l my mz">app.run(host="localhost", port=7777, debug=True)</span></pre><p id="4926" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">目前，服务器没有提供任何功能。服务器应该做的第一件事是允许用户上传图像。当用户访问应用程序的根 URL 时，应用程序什么也不做。应用程序可以将用户重定向到一个 HTML 页面，用户可以在该页面上传图像。为此，该应用程序有一个名为 redirect_upload 的函数，将用户重定向到上传图像的页面。让这个函数在用户访问应用程序的根目录后执行的是使用以下代码行创建的路由:</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="614f" class="lr kp it ms b gy mw mx l my mz">app.add_url_rule(rule="/", endpoint="homepage", view_func=redirect_upload)</span></pre><p id="482f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这一行说的是如果用户访问 app 的根目录(标记为<strong class="js iu">"/</strong>)，那么就会调用查看器函数(redirect_upload)。此类函数除了呈现一个名为<strong class="js iu"> upload_image.html </strong>的 HTML 页面之外什么也不做。该页面位于服务器的专用<strong class="js iu">模板</strong>目录下。模板目录中的页面通过调用 render_template 函数来呈现。请注意，有一个名为 endpoint 的属性，它使多次重用相同的路由变得容易，而无需对其进行硬编码。</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="4957" class="lr kp it ms b gy mw mx l my mz">def redirect_upload():</span><span id="d4ba" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="4769" class="lr kp it ms b gy ng mx l my mz">A viewer function that redirects the Web application from the root to a HTML page for uploading an image to get classified.</span><span id="fb27" class="lr kp it ms b gy ng mx l my mz">The HTML page is located under the /templates directory of the application.</span><span id="a21a" class="lr kp it ms b gy ng mx l my mz">:return: HTML page used for uploading an image. It is 'upload_image.html' in this exmaple.</span><span id="d1a2" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="8131" class="lr kp it ms b gy ng mx l my mz">return flask.render_template(template_name_or_list="upload_image.html")</span><span id="d45e" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="0826" class="lr kp it ms b gy ng mx l my mz">Creating a route between the homepage URL (http://localhost:7777) to a viewer function that is called after getting to such URL.</span><span id="0b0a" class="lr kp it ms b gy ng mx l my mz">Endpoint 'homepage' is used to make the route reusable without hard-coding it later.</span><span id="71da" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="a0fc" class="lr kp it ms b gy ng mx l my mz">app.add_url_rule(rule="/", endpoint="homepage", view_func=redirect_upload)</span></pre><p id="4808" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">呈现的 HTML 页面的屏幕如图 6 所示。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/681b30fabdd04483bcadfad6510470e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*jTWZaW8bERAkmLRwuEKerQ.png"/></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">Figure 6</figcaption></figure><p id="006d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面是这个页面的 HTML 代码。这是一个简单的表单，允许用户上传图像文件。提交该表单时，将向 URL<a class="ae md" href="http://localhost:7777/upload/" rel="noopener ugc nofollow" target="_blank"><strong class="js iu">HTTP://localhost:7777/upload/</strong></a>返回一条 POST HTTP 消息。</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="4fb2" class="lr kp it ms b gy mw mx l my mz">&lt;!DOCTYPE html&gt;</span><span id="e501" class="lr kp it ms b gy ng mx l my mz">&lt;html lang="en"&gt;</span><span id="af32" class="lr kp it ms b gy ng mx l my mz">&lt;head&gt;</span><span id="f92a" class="lr kp it ms b gy ng mx l my mz">&lt;link rel="stylesheet" type="text/css" href="{{url_for(endpoint='static', filename='project_styles.css')}}"&gt;</span><span id="6595" class="lr kp it ms b gy ng mx l my mz">&lt;meta charset="UTF-8"&gt;</span><span id="0ee8" class="lr kp it ms b gy ng mx l my mz">&lt;title&gt;Upload Image&lt;/title&gt;</span><span id="7abd" class="lr kp it ms b gy ng mx l my mz">&lt;/head&gt;</span><span id="d962" class="lr kp it ms b gy ng mx l my mz">&lt;body&gt;</span><span id="9e2f" class="lr kp it ms b gy ng mx l my mz">&lt;form enctype="multipart/form-data" method="post" action="http://localhost:7777/upload/"&gt;</span><span id="bdd9" class="lr kp it ms b gy ng mx l my mz">&lt;center&gt;</span><span id="f462" class="lr kp it ms b gy ng mx l my mz">&lt;h3&gt;Select CIFAR10 image to predict its label.&lt;/h3&gt;</span><span id="bdad" class="lr kp it ms b gy ng mx l my mz">&lt;input type="file" name="image_file" accept="image/*"&gt;&lt;br&gt;</span><span id="9926" class="lr kp it ms b gy ng mx l my mz">&lt;input type="submit" value="Upload"&gt;</span><span id="3229" class="lr kp it ms b gy ng mx l my mz">&lt;/center&gt;</span><span id="8591" class="lr kp it ms b gy ng mx l my mz">&lt;/form&gt;</span><span id="9290" class="lr kp it ms b gy ng mx l my mz">&lt;/body&gt;</span><span id="f267" class="lr kp it ms b gy ng mx l my mz">&lt;/html&gt;</span></pre><p id="36b4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">从 HTML 表单返回到服务器后，将调用与在<strong class="js iu">表单动作</strong>属性中指定的 URL 相关联的查看器函数，即 upload_image 函数。该函数获取用户选择的图像，并将其保存到服务器。</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="9dfc" class="lr kp it ms b gy mw mx l my mz">def upload_image():</span><span id="1df8" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="d61e" class="lr kp it ms b gy ng mx l my mz">Viewer function that is called in response to getting to the 'http://localhost:7777/upload' URL.</span><span id="ffcd" class="lr kp it ms b gy ng mx l my mz">It uploads the selected image to the server.</span><span id="689a" class="lr kp it ms b gy ng mx l my mz">:return: redirects the application to a new page for predicting the class of the image.</span><span id="9cbc" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="a1fd" class="lr kp it ms b gy ng mx l my mz">#Global variable to hold the name of the image file for reuse later in prediction by the 'CNN_predict' viewer functions.</span><span id="3262" class="lr kp it ms b gy ng mx l my mz">global secure_filename</span><span id="a76f" class="lr kp it ms b gy ng mx l my mz">if flask.request.method == "POST":#Checking of the HTTP method initiating the request is POST.</span><span id="9b3f" class="lr kp it ms b gy ng mx l my mz">img_file = flask.request.files["image_file"]#Getting the file name to get uploaded.</span><span id="b225" class="lr kp it ms b gy ng mx l my mz">secure_filename = werkzeug.secure_filename(img_file.filename)#Getting a secure file name. It is a good practice to use it.</span><span id="bee3" class="lr kp it ms b gy ng mx l my mz">img_path = os.path.join(app.root_path, secure_filename)#Preparing the full path under which the image will get saved.</span><span id="3fdd" class="lr kp it ms b gy ng mx l my mz">img_file.save(img_path)#Saving the image in the specified path.</span><span id="4d57" class="lr kp it ms b gy ng mx l my mz">print("Image uploaded successfully.")</span><span id="6a27" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="76a1" class="lr kp it ms b gy ng mx l my mz">After uploading the image file successfully, next is to predict the class label of it.</span><span id="ecca" class="lr kp it ms b gy ng mx l my mz">The application will fetch the URL that is tied to the HTML page responsible for prediction and redirects the browser to it.</span><span id="203a" class="lr kp it ms b gy ng mx l my mz">The URL is fetched using the endpoint 'predict'.</span><span id="fe94" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="728c" class="lr kp it ms b gy ng mx l my mz">return flask.redirect(flask.url_for(endpoint="predict"))</span><span id="d555" class="lr kp it ms b gy ng mx l my mz">return "Image upload failed."</span><span id="49c6" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="93b7" class="lr kp it ms b gy ng mx l my mz">Creating a route between the URL (http://localhost:7777/upload) to a viewer function that is called after navigating to such URL.</span><span id="1862" class="lr kp it ms b gy ng mx l my mz">Endpoint 'upload' is used to make the route reusable without hard-coding it later.</span><span id="9d61" class="lr kp it ms b gy ng mx l my mz">The set of HTTP method the viewer function is to respond to is added using the 'methods' argument.</span><span id="350f" class="lr kp it ms b gy ng mx l my mz">In this case, the function will just respond to requests of method of type POST.</span><span id="b169" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="0120" class="lr kp it ms b gy ng mx l my mz">app.add_url_rule(rule="/upload/", endpoint="upload", view_func=upload_image, methods=["POST"])</span></pre><p id="39c3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">将图像成功上传到服务器后，我们就可以读取图像，并使用之前训练的 CNN 模型预测其类别标签。因此，upload_image 函数将应用程序重定向到负责预测图像类别标签的查看器函数。这种查看器功能是通过其在该行中指定的端点来实现的:</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="62a9" class="lr kp it ms b gy mw mx l my mz">return flask.redirect(flask.url_for(endpoint="predict"))</span></pre><p id="edff" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">将调用与 endpoint =<strong class="js iu">“predict”</strong>关联的方法，这是 CNN_predict 函数。</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="5468" class="lr kp it ms b gy mw mx l my mz">def CNN_predict():</span><span id="fa4c" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="8cd9" class="lr kp it ms b gy ng mx l my mz">Reads the uploaded image file and predicts its label using the saved pre-trained CNN model.</span><span id="be3e" class="lr kp it ms b gy ng mx l my mz">:return: Either an error if the image is not for CIFAR10 dataset or redirects the browser to a new page to show the prediction result if no error occurred.</span><span id="a0b6" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="c0b0" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="0c8e" class="lr kp it ms b gy ng mx l my mz">Setting the previously created 'secure_filename' to global.</span><span id="e150" class="lr kp it ms b gy ng mx l my mz">This is because to be able invoke a global variable created in another function, it must be defined global in the caller function.</span><span id="048f" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="516d" class="lr kp it ms b gy ng mx l my mz">global secure_filename</span><span id="b176" class="lr kp it ms b gy ng mx l my mz">#Reading the image file from the path it was saved in previously.</span><span id="5ef3" class="lr kp it ms b gy ng mx l my mz">img = scipy.misc.imread(os.path.join(app.root_path, secure_filename))</span><span id="0d75" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="fe79" class="lr kp it ms b gy ng mx l my mz">Checking whether the image dimensions match the CIFAR10 specifications.</span><span id="c4fc" class="lr kp it ms b gy ng mx l my mz">CIFAR10 images are RGB (i.e. they have 3 dimensions). It number of dimenions was not equal to 3, then a message will be returned.</span><span id="3d3c" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="d0f0" class="lr kp it ms b gy ng mx l my mz">if(img.ndim) == 3:</span><span id="ca08" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="2e6f" class="lr kp it ms b gy ng mx l my mz">Checking if the number of rows and columns of the read image matched CIFAR10 (32 rows and 32 columns).</span><span id="cabd" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="d672" class="lr kp it ms b gy ng mx l my mz">if img.shape[0] == img.shape[1] and img.shape[0] == 32:</span><span id="9e7a" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="893c" class="lr kp it ms b gy ng mx l my mz">Checking whether the last dimension of the image has just 3 channels (Red, Green, and Blue).</span><span id="7636" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="446f" class="lr kp it ms b gy ng mx l my mz">if img.shape[-1] == 3:</span><span id="ab4e" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="8f4c" class="lr kp it ms b gy ng mx l my mz">Passing all conditions above, the image is proved to be of CIFAR10.</span><span id="755e" class="lr kp it ms b gy ng mx l my mz">This is why it is passed to the predictor.</span><span id="6214" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="bc3f" class="lr kp it ms b gy ng mx l my mz">predicted_class = CIFAR10_CNN_Predict_Image.main(img)</span><span id="8162" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="b6ca" class="lr kp it ms b gy ng mx l my mz">After predicting the class label of the input image, the prediction label is rendered on an HTML page.</span><span id="34da" class="lr kp it ms b gy ng mx l my mz">The HTML page is fetched from the /templates directory. The HTML page accepts an input which is the predicted class.</span><span id="cf0b" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="b84e" class="lr kp it ms b gy ng mx l my mz">return flask.render_template(template_name_or_list="prediction_result.html", predicted_class=predicted_class)</span><span id="21d5" class="lr kp it ms b gy ng mx l my mz">else:</span><span id="8eea" class="lr kp it ms b gy ng mx l my mz"># If the image dimensions do not match the CIFAR10 specifications, then an HTML page is rendered to show the problem.</span><span id="97b6" class="lr kp it ms b gy ng mx l my mz">return flask.render_template(template_name_or_list="error.html", img_shape=img.shape)</span><span id="46f1" class="lr kp it ms b gy ng mx l my mz">else:</span><span id="a73a" class="lr kp it ms b gy ng mx l my mz"># If the image dimensions do not match the CIFAR10 specifications, then an HTML page is rendered to show the problem.</span><span id="45b3" class="lr kp it ms b gy ng mx l my mz">return flask.render_template(template_name_or_list="error.html", img_shape=img.shape)</span><span id="c8c2" class="lr kp it ms b gy ng mx l my mz">return "An error occurred."#Returned if there is a different error other than wrong image dimensions.</span><span id="6b27" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="a23f" class="lr kp it ms b gy ng mx l my mz">Creating a route between the URL (http://localhost:7777/predict) to a viewer function that is called after navigating to such URL.</span><span id="7548" class="lr kp it ms b gy ng mx l my mz">Endpoint 'predict' is used to make the route reusable without hard-coding it later.</span><span id="360a" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="ee70" class="lr kp it ms b gy ng mx l my mz">app.add_url_rule(rule="/predict/", endpoint="predict", view_func=CNN_predict)</span></pre><p id="87d1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这种方法读取图像并检查它是否与 32×32×3 的 CIFAR-10 数据集的尺寸相匹配。如果图像符合 CIFAR-10 数据集的规格，则它将被传递给负责进行预测的函数，如下所示:</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="8dc5" class="lr kp it ms b gy mw mx l my mz">predicted_class = CIFAR10_CNN_Predict_Image.main(img)</span></pre><p id="7a43" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">负责预测图像类别标签的主函数定义如下。它会恢复训练好的模型，并运行一个会话来返回图像的预测类。预测的类被返回给 Flask Web 应用程序。</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="b7b6" class="lr kp it ms b gy mw mx l my mz">def main(img):</span><span id="8550" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="1997" class="lr kp it ms b gy ng mx l my mz">The 'main' method accepts an input image array of size 32x32x3 and returns its class label.</span><span id="dcdf" class="lr kp it ms b gy ng mx l my mz">:param img:RGB image of size 32x32x3.</span><span id="e921" class="lr kp it ms b gy ng mx l my mz">:return:Predicted class label.</span><span id="5e0d" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="6112" class="lr kp it ms b gy ng mx l my mz">#Dataset path containing a binary file with the labels of classes. Useful to decode the prediction code into a significant textual label.</span><span id="f025" class="lr kp it ms b gy ng mx l my mz">patches_dir = "C:\\cifar-10-python\\cifar-10-batches-py\\"</span><span id="e6b0" class="lr kp it ms b gy ng mx l my mz">dataset_array = numpy.random.rand(1, 32, 32, 3)</span><span id="1779" class="lr kp it ms b gy ng mx l my mz">dataset_array[0, :, :, :] = img</span><span id="b149" class="lr kp it ms b gy ng mx l my mz">sess = tensorflow.Session()</span><span id="4c4b" class="lr kp it ms b gy ng mx l my mz">#Restoring the previously saved trained model.</span><span id="3741" class="lr kp it ms b gy ng mx l my mz">saved_model_path = 'C:\\model\\'</span><span id="a7d1" class="lr kp it ms b gy ng mx l my mz">saver = tensorflow.train.import_meta_graph(saved_model_path+'model.ckpt.meta')</span><span id="8748" class="lr kp it ms b gy ng mx l my mz">saver.restore(sess=sess, save_path=saved_model_path+'model.ckpt')</span><span id="7263" class="lr kp it ms b gy ng mx l my mz">#Initalizing the varaibales.</span><span id="281f" class="lr kp it ms b gy ng mx l my mz">sess.run(tensorflow.global_variables_initializer())</span><span id="1344" class="lr kp it ms b gy ng mx l my mz">graph = tensorflow.get_default_graph()</span><span id="a631" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="a348" class="lr kp it ms b gy ng mx l my mz">Restoring previous created tensors in the training phase based on their given tensor names in the training phase.</span><span id="79ee" class="lr kp it ms b gy ng mx l my mz">Some of such tensors will be assigned the testing input data and their outcomes (data_tensor, label_tensor, and keep_prop).</span><span id="b2de" class="lr kp it ms b gy ng mx l my mz">Others are helpful in assessing the model prediction accuracy (softmax_propabilities and softmax_predictions).</span><span id="52f3" class="lr kp it ms b gy ng mx l my mz">"""</span><span id="9591" class="lr kp it ms b gy ng mx l my mz">softmax_propabilities = graph.get_tensor_by_name(name="softmax_probs:0")</span><span id="fcd9" class="lr kp it ms b gy ng mx l my mz">softmax_predictions = tensorflow.argmax(softmax_propabilities, axis=1)</span><span id="f23c" class="lr kp it ms b gy ng mx l my mz">data_tensor = graph.get_tensor_by_name(name="data_tensor:0")</span><span id="8f60" class="lr kp it ms b gy ng mx l my mz">label_tensor = graph.get_tensor_by_name(name="label_tensor:0")</span><span id="add7" class="lr kp it ms b gy ng mx l my mz">keep_prop = graph.get_tensor_by_name(name="keep_prop:0")</span><span id="c828" class="lr kp it ms b gy ng mx l my mz">#keep_prop is equal to 1 because there is no more interest to remove neurons in the testing phase.</span><span id="50c3" class="lr kp it ms b gy ng mx l my mz">feed_dict_testing = {data_tensor: dataset_array,</span><span id="7c03" class="lr kp it ms b gy ng mx l my mz">keep_prop: 1.0}</span><span id="ee16" class="lr kp it ms b gy ng mx l my mz">#Running the session to predict the outcomes of the testing samples.</span><span id="cfe0" class="lr kp it ms b gy ng mx l my mz">softmax_propabilities_, softmax_predictions_ = sess.run([softmax_propabilities, softmax_predictions],</span><span id="7349" class="lr kp it ms b gy ng mx l my mz">feed_dict=feed_dict_testing)</span><span id="c6d7" class="lr kp it ms b gy ng mx l my mz">label_names_dict = unpickle_patch(patches_dir + "batches.meta")</span><span id="29de" class="lr kp it ms b gy ng mx l my mz">dataset_label_names = label_names_dict[b"label_names"]</span><span id="153c" class="lr kp it ms b gy ng mx l my mz">return dataset_label_names[softmax_predictions_[0]].decode('utf-8')</span></pre><p id="4e85" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">返回的图像的类标签将呈现在一个名为<strong class="js iu"> prediction_result.html </strong>的新 HTML 页面上，由 CNN_predict 函数在这一行中指示，如图 7 所示。</p><figure class="mg mh mi mj gt mk gh gi paragraph-image"><div role="button" tabindex="0" class="nb nc di nd bf ne"><div class="gh gi nj"><img src="../Images/e50e048be0a429cbb405974b405d9837.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*ylDiU6iNJgiEehGSUczvZQ.png"/></div></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">Figure 7</figcaption></figure><p id="72b5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">注意，Flask 应用程序使用 Jinja2 模板引擎，该引擎允许 HTML 页面接受输入参数。在这种情况下传递的输入参数是 predicted _ class = predicted _ class。</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="3dd8" class="lr kp it ms b gy mw mx l my mz">return flask.render_template(template_name_or_list="prediction_result.html", predicted_class=predicted_class)</span></pre><p id="914e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这个页面的 HTML 代码如下。</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="f3f2" class="lr kp it ms b gy mw mx l my mz">&lt;!DOCTYPE html&gt;</span><span id="a8c4" class="lr kp it ms b gy ng mx l my mz">&lt;html lang="en"&gt;</span><span id="4c89" class="lr kp it ms b gy ng mx l my mz">&lt;head&gt;</span><span id="beb6" class="lr kp it ms b gy ng mx l my mz">&lt;link rel="stylesheet" type="text/css" href="{{url_for(endpoint='static', filename='project_styles.css')}}"&gt;</span><span id="4d8e" class="lr kp it ms b gy ng mx l my mz">&lt;script type="text/javascript" src="{{url_for(endpoint='static', filename='result.js')}}"&gt;&lt;/script&gt;</span><span id="e5c7" class="lr kp it ms b gy ng mx l my mz">&lt;meta charset="UTF-8"&gt;</span><span id="32a6" class="lr kp it ms b gy ng mx l my mz">&lt;title&gt;Prediction Result&lt;/title&gt;</span><span id="0467" class="lr kp it ms b gy ng mx l my mz">&lt;/head&gt;</span><span id="ebd4" class="lr kp it ms b gy ng mx l my mz">&lt;body onload="show_alert('{{predicted_class}}')"&gt;</span><span id="2f33" class="lr kp it ms b gy ng mx l my mz">&lt;center&gt;&lt;h1&gt;Predicted Class Label : &lt;span&gt;{{predicted_class}}&lt;/span&gt;&lt;/h1&gt;</span><span id="fb83" class="lr kp it ms b gy ng mx l my mz">&lt;br&gt;</span><span id="5abc" class="lr kp it ms b gy ng mx l my mz">&lt;a href="{{url_for(endpoint='homepage')}}"&gt;&lt;span&gt;Return to homepage&lt;/span&gt;.&lt;/a&gt;</span><span id="b44c" class="lr kp it ms b gy ng mx l my mz">&lt;/center&gt;</span><span id="a9ab" class="lr kp it ms b gy ng mx l my mz">&lt;/body&gt;</span><span id="4976" class="lr kp it ms b gy ng mx l my mz">&lt;/html&gt;</span></pre><p id="a704" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">它是一个模板，由图像的预测类填充，作为参数传递给 HTML 页面，如代码的这一部分所示:</p><pre class="mg mh mi mj gt mr ms mt mu aw mv bi"><span id="0c7d" class="lr kp it ms b gy mw mx l my mz">&lt;<strong class="ms iu">span</strong>&gt;{{predicted_class}}&lt;/<strong class="ms iu">span</strong>&gt;</span></pre></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><p id="2a73" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">想了解更多关于 Flask RESTful API 的信息，你可以访问这样的教程【https://www.tutorialspoint.com/flask/index.htm<a class="ae md" href="https://www.tutorialspoint.com/flask/index.htm" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="8237" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">完整的项目可以在 Github 的这个链接中找到:【https://github.com/ahmedfgad/CIFAR10CNNFlask T4】</p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><p id="e817" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="me">原载于 2018 年 5 月 1 日</em><a class="ae md" href="https://www.linkedin.com/pulse/complete-guide-build-convnet-http-based-application-using-ahmed-gad" rel="noopener ugc nofollow" target="_blank"><em class="me">https://www.linkedin.com</em></a><em class="me">。</em></p><p id="3113" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">原文可在 LinkedIn 的以下链接中找到:</p><p id="a66b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><a class="ae md" href="https://www.linkedin.com/pulse/complete-guide-build-convnet-http-based-application-using-ahmed-gad/?published=t" rel="noopener ugc nofollow" target="_blank">https://www . LinkedIn . com/pulse/complete-guide-build-conv net-http-based-application-using-Ahmed-gad</a></p></div><div class="ab cl nk nl hx nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="im in io ip iq"><h1 id="c787" class="ko kp it bd kq kr nr kt ku kv ns kx ky kz nt lb lc ld nu lf lg lh nv lj lk ll bi translated">联系作者</h1><p id="3e01" class="pw-post-body-paragraph jq jr it js b jt lm jv jw jx ln jz ka kb lo kd ke kf lp kh ki kj lq kl km kn im bi translated">艾哈迈德·法齐·加德</p><p id="42a7" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">领英:<a class="ae md" href="https://linkedin.com/in/ahmedfgad" rel="noopener ugc nofollow" target="_blank">https://linkedin.com/in/ahmedfgad</a></p><p id="eead" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">电子邮件:ahmed.f.gad@gmail.com</p></div></div>    
</body>
</html>