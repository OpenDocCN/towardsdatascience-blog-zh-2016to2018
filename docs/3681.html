<html>
<head>
<title>50 TensorFlow.js API Explained in 5 Minutes | TensorFlow.js Cheetsheet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">50 tensor flow . js API 5 分钟讲解| TensorFlow.js Cheetsheet</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/50-tensorflow-js-api-explained-in-5-minutes-tensorflow-js-cheetsheet-4f8c7f9cc8b2?source=collection_archive---------4-----------------------#2018-06-07">https://towardsdatascience.com/50-tensorflow-js-api-explained-in-5-minutes-tensorflow-js-cheetsheet-4f8c7f9cc8b2?source=collection_archive---------4-----------------------#2018-06-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b9ce" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">TensorFlow API Cheetsheet</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/357c3770e5a5e6d7792c106b39073603.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*krqfc0x1UtXBuv2IThIWjw.png"/></div></div></figure><p id="9c16" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在这篇文章中，我真的想看看张量流<strong class="kt ir">。js</strong>API，从整体上理解这个库，并理解它为机器学习社区提供了哪些令人惊叹的东西。</p><p id="b357" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我知道这篇文章应该有 5 分钟长，但不要担心，理解这些显而易见的 API 不会超过 5 分钟，即使它们中的许多从名字上看非常明显，对我来说保持初学者友好是很重要的。</p><p id="d22d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我在文章的其余部分尽可能用例子来说明问题。但是如果你们有任何疑问，让我们在评论中讨论吧。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ln"><img src="../Images/4a11c87fa04e0be9f81cacbf4499cf80.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*P3TnhdZN7U65kw28YTonOw.png"/></div></figure><p id="e11f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">它将帮助你为任何新的未来项目编写更好的通用机器学习代码。</p><h1 id="3a34" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated"><strong class="ak">创造🚀</strong></h1><p id="eed3" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">API 有助于创建张量、克隆体等东西。</p><blockquote class="ml"><p id="8bee" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated"><strong class="ak"> 1 </strong> - <strong class="ak"> tf.tensor ( <em class="mv">数值，</em> </strong> <em class="mv">形状？</em> <strong class="ak"> <em class="mv">，</em> </strong> <em class="mv"> dtype？</em> <strong class="ak"> <em class="mv"> </em> ) </strong></p></blockquote><blockquote class="mw mx my"><p id="1e95" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">创建具有指定数据类型形状的张量。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="dce6" class="nn lp iq nj b gy no np l nq nr"><em class="mz">// Pass an array of values to create a vector.</em> <br/>tf.tensor([1, 2, 3, 4]).print();</span><span id="cdfd" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------</strong><br/><strong class="nj ir">Tensor     [1, 2, 3, 4]</strong></span><span id="99b9" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// Pass a flat array and specify a shape yourself.</em> <br/>tf.tensor([1, 2, 3, 4], [2, 2]).print();</span><span id="2a2a" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------</strong><br/><strong class="nj ir">Tensor     [[1, 2],      <br/>            [3, 4]]</strong></span></pre><p id="c1fe" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Returns → <strong class="kt ir"> tf。张量</strong></p><blockquote class="mw mx my"><p id="41a0" class="kr ks mz kt b ku kv jr kw kx ky ju kz nc lb lc ld ne lf lg lh ng lj lk ll lm ij bi translated"><strong class="kt ir">注</strong>:他们也有形状指定的 API，比如<em class="iq"> tf.tensor1d，tf.tensor2d，</em>T30】TF . tensor 3d 和<em class="iq"> tf.tensor4d </em>。</p></blockquote><blockquote class="ml"><p id="7158" class="mm mn iq bd mo mp nt nu nv nw nx lm dk translated"><strong class="ak">2</strong>-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#buffer" rel="noopener ugc nofollow" target="_blank">-<strong class="ak">TF . buffer</strong></a><strong class="ak">(shape，dtype？，价值观？)</strong></p></blockquote><blockquote class="mw mx my"><p id="fdea" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">创建一个缓冲张量。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="eb60" class="nn lp iq nj b gy no np l nq nr"><em class="mz">// Create a buffer and set values at particular indices.</em> <br/><strong class="nj ir">const</strong> buffer = tf.buffer([2, 2]); <br/>buffer.set(3, 0, 0); <br/>buffer.set(5, 1, 0);  <em class="mz">// Convert the buffer back to a tensor.</em> buffer.toTensor().print();</span><span id="2a26" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">-------RESULT------</strong><br/><strong class="nj ir">Tensor     [[3, 0],<br/>            [5, 0]]</strong></span></pre><p id="eb5f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量缓冲器</strong></p><blockquote class="ml"><p id="9d48" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated"><strong class="ak">3</strong>-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#fromPixels" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . from pixels</strong></a><strong class="ak">(<em class="mv"/></strong><em class="mv">num channels？</em> <strong class="ak"> ) </strong></p></blockquote><blockquote class="mw mx my"><p id="e0a8" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated">从图像中创建一个张量。</p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="2893" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> image = new ImageData(1, 1); <br/>image.data[0] = 100; <br/>image.data[1] = 150; <br/>image.data[2] = 200; <br/>image.data[3] = 255;  <br/>tf.fromPixels(image).print();</span><span id="c7f7" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------</strong><br/><strong class="nj ir">Tensor      [ [[100, 150, 200],]]</strong></span></pre><p id="03cf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。Tensor3D </strong></p><blockquote class="ml"><p id="9937" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated"><strong class="ak">4</strong>-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#linspace" rel="noopener ugc nofollow" target="_blank">-<strong class="ak">TF . linspace</strong></a><strong class="ak">(<em class="mv">start，stop，num </em> ) </strong></p></blockquote><blockquote class="mw mx my"><p id="2b01" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">创建一个具有均匀间隔数字的张量。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="b756" class="nn lp iq nj b gy no np l nq nr">tf.linspace(0, 9, 10).print();</span><span id="5363" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------</strong><br/><strong class="nj ir">Tensor     [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</strong></span></pre><p id="6d0d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量 1D </strong></p><blockquote class="ml"><p id="2ee3" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated"><strong class="ak">5</strong>-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#oneHot" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . onehot</strong></a><strong class="ak">(<em class="mv">indexes，depth，</em> </strong> <em class="mv"> onValue？</em> <strong class="ak"> <em class="mv">，</em> </strong> <em class="mv"> offValue？</em> <strong class="ak"> ) </strong></p></blockquote><blockquote class="mw mx my"><p id="8b29" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">将一组稀疏的标签转换成密集的独热表示。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="a208" class="nn lp iq nj b gy no np l nq nr">tf.oneHot<strong class="nj ir">(</strong>tf.tensor1d([0, 1], 'int32'), 3<strong class="nj ir">)</strong>.print();</span><span id="1d5d" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>Tensor     [[1, 0, 0],<br/>            [0, 1, 0]]</strong></span></pre><p id="dc27" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量 2D </strong></p><blockquote class="ml"><p id="f156" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated"><strong class="ak">6</strong>-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#print" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . print</strong></a><strong class="ak">(<em class="mv"/></strong><em class="mv">啰嗦？</em> <strong class="ak"> <em class="mv"> </em> ) </strong></p></blockquote><blockquote class="mw mx my"><p id="6159" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">打印信息。关于任何张量。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="4b5a" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> verbose = true; <br/>tf.tensor2d([1, 2, 3, 4], [2, 2]).print(verbose);</span><span id="b576" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>Tensor   dtype: float32  <br/>         rank: 2  <br/>         shape: [2,2]  <br/>         values:     [[1, 2], <br/>                      [3, 4]]</strong></span></pre><p id="4b8a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货→ <strong class="kt ir">作废</strong></p><blockquote class="ml"><p id="a40e" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated"><strong class="ak">7</strong>-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#variable" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . variable</strong></a><strong class="ak">(<em class="mv">initial value，</em> </strong> <em class="mv">可训练？，名字？，dtype？</em> <strong class="ak"> ) </strong></p></blockquote><blockquote class="mw mx my"><p id="4bfb" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">用提供的初始值创建一个张量变量。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="5594" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> x = tf.variable(tf.tensor([1, 2, 3]));<br/>x.assign(tf.tensor([4, 5, 6]));<br/>x.print();</span><span id="23d4" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/></strong><strong class="nj ir">Tensor     [4, 5, 6]</strong></span></pre><p id="a1c1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Returns → <strong class="kt ir"> tf。变量</strong></p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><h1 id="9261" class="lo lp iq bd lq lr og lt lu lv oh lx ly jw oi jx ma jz oj ka mc kc ok kd me mf bi translated">tf 的方法。张量</h1><blockquote class="ml"><p id="a1c9" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">8 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Tensor.flatten" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">展平</strong> </a>()</p></blockquote><blockquote class="mw mx my"><p id="a1d4" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">将张量展平为 1D 数组</strong></p></blockquote><p id="38df" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量 1D </strong></p><blockquote class="ml"><p id="d927" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">9-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Tensor.asScalar" rel="noopener ugc nofollow" target="_blank"><strong class="ak"/></a>()</p></blockquote><blockquote class="mw mx my"><p id="9eb3" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">转换一个 size-1 的 tf。张量到一个 tf.Scalar. </strong></p></blockquote><p id="c12e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。标量</strong></p><blockquote class="ml"><p id="5668" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">10.1-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Tensor.as1D" rel="noopener ugc nofollow" target="_blank"><strong class="ak">as1D</strong></a><strong class="ak">()</strong></p></blockquote><blockquote class="mw mx my"><p id="1721" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">转换一个 tf。张量到一个 tf.Tensor1D. </strong></p></blockquote><p id="aa52" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量 1D </strong></p><blockquote class="ml"><p id="3566" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">10.2-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Tensor.as2D" rel="noopener ugc nofollow" target="_blank"><strong class="ak">as2D</strong></a><strong class="ak">(行、列)</strong></p></blockquote><blockquote class="mw mx my"><p id="c275" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">转换一个 tf。张量到一个 tf.Tensor2D. </strong></p></blockquote><p id="23bb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量 2D </strong></p><blockquote class="ml"><p id="039f" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">10.3-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Tensor.as3D" rel="noopener ugc nofollow" target="_blank"><strong class="ak">as3D</strong></a>(<strong class="ak">行、列、深度</strong>)</p></blockquote><blockquote class="mw mx my"><p id="ab4c" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">转换一个 tf。张量到一个 tf.Tensor3D. </strong></p></blockquote><p id="a949" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Returns→ <strong class="kt ir"> tf。张量 3D </strong></p><blockquote class="ml"><p id="c428" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">10.4 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Tensor.as4D" rel="noopener ugc nofollow" target="_blank"> <strong class="ak"> as4D </strong> </a> ( <strong class="ak">行，列，深度，depth2 </strong>)</p></blockquote><blockquote class="mw mx my"><p id="c0b2" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">转换一个 tf。张量到一个 tf.Tensor4D. </strong></p></blockquote><p id="9e66" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Returns→ <strong class="kt ir"> tf。张量 4D </strong></p><blockquote class="ml"><p id="3d57" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">11-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Tensor.asType" rel="noopener ugc nofollow" target="_blank"><strong class="ak">as type</strong></a><strong class="ak">【dtype】</strong></p></blockquote><blockquote class="mw mx my"><p id="a366" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">施放一个 tf。指定数据类型的张量。</strong></p></blockquote><p id="0a08" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir">本</strong></p><blockquote class="ml"><p id="c4d4" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">12 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Tensor.buffer" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">缓冲</strong> </a> <strong class="ak"> ( ) </strong></p></blockquote><blockquote class="mw mx my"><p id="ef55" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated">返回一个 tf。保存底层数据的 TensorBuffer。</p></blockquote><p id="8294" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量缓冲器</strong></p><blockquote class="ml"><p id="96ff" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">13 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Tensor.data" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">数据</strong> </a> <strong class="ak"> </strong>()</p></blockquote><blockquote class="mw mx my"><p id="a9f3" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated">tf.data API 有助于构建灵活高效的输入管道。</p></blockquote><p id="567a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货→ <strong class="kt ir">承诺</strong></p><blockquote class="ml"><p id="f590" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">14 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Tensor.dispose" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">处分</strong> </a> <strong class="ak"> ( ) </strong></p></blockquote><blockquote class="mw mx my"><p id="ed18" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">处置 tf。来自记忆的张量。</strong></p></blockquote><p id="3952" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货→ <strong class="kt ir">作废</strong></p><blockquote class="ml"><p id="fde0" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">15.1 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Tensor.toFloat" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">浮动</strong> </a> <strong class="ak"> ( ) </strong></p></blockquote><blockquote class="mw mx my"><p id="e01b" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">将数组转换为 float32 类型。</strong></p></blockquote><p id="a909" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir">这个</strong></p><blockquote class="ml"><p id="4e31" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">15.2-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Tensor.toInt" rel="noopener ugc nofollow" target="_blank"><strong class="ak">toInt</strong></a><strong class="ak">()</strong></p></blockquote><blockquote class="mw mx my"><p id="b059" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated">将数组转换为 int32 类型。</p></blockquote><p id="fe2b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir">这个</strong></p><blockquote class="ml"><p id="56d3" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">15.3 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Tensor.toBool" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">托布尔</strong> </a> <strong class="ak"> ( ) </strong></p></blockquote><blockquote class="mw mx my"><p id="2bac" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated">将数组转换为 bool 类型。</p></blockquote><p id="8400" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir">这个</strong></p><blockquote class="ml"><p id="a329" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">16-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Tensor.reshapeAs" rel="noopener ugc nofollow" target="_blank"><strong class="ak"/></a><strong class="ak">(x)</strong></p></blockquote><blockquote class="mw mx my"><p id="c887" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">将张量整形为所提供的张量的形状。</strong></p></blockquote><p id="2e9d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量</strong></p><blockquote class="ml"><p id="60df" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">17 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Tensor.toString" rel="noopener ugc nofollow" target="_blank"> <strong class="ak"> toString </strong> </a> <strong class="ak">(啰嗦？)</strong></p></blockquote><blockquote class="mw mx my"><p id="b857" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">返回张量的可读描述。对日志记录有用。</strong></p></blockquote><p id="900b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir">字符串</strong></p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><h1 id="5ebd" class="lo lp iq bd lq lr og lt lu lv oh lx ly jw oi jx ma jz oj ka mc kc ok kd me mf bi translated">tf 的方法。变量扩展到 tf。张量</h1><blockquote class="ml"><p id="5c60" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">18 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Variable.assign" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">赋值</strong> </a> <strong class="ak">(新值)</strong></p></blockquote><blockquote class="mw mx my"><p id="42f4" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated">分配一个新的任务组。这个变量的张量。</p></blockquote><p id="a509" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货→ <strong class="kt ir">作废</strong></p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><h1 id="6cba" class="lo lp iq bd lq lr og lt lu lv oh lx ly jw oi jx ma jz oj ka mc kc ok kd me mf bi translated"><strong class="ak">TF 的方法。张量缓冲</strong></h1><p id="3faf" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated"><strong class="kt ir"> tf。TensorBuffer 允许在声明一个 tf 之前设置一个值。不可改变的张量。</strong></p><blockquote class="ml"><p id="6a82" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated"><a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.TensorBuffer.set" rel="noopener ugc nofollow" target="_blank">19-<strong class="ak">设置</strong> </a> <strong class="ak"> ( value，locs ) </strong></p></blockquote><blockquote class="mw mx my"><p id="7c28" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">在缓冲区的给定位置设置一个值。</strong></p></blockquote><p id="e9f2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货→ <strong class="kt ir">作废</strong></p><blockquote class="ml"><p id="2cff" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">20 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.TensorBuffer.get" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">获取</strong> </a> <strong class="ak"> ( locs ) </strong></p></blockquote><blockquote class="mw mx my"><p id="1e2e" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">返回缓冲区中指定位置的值。</strong></p></blockquote><p id="3bd2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货单→ <strong class="kt ir">编号</strong></p><blockquote class="ml"><p id="2d8c" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">21-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.TensorBuffer.toTensor" rel="noopener ugc nofollow" target="_blank"><strong class="ak"/></a><strong class="ak">()</strong></p></blockquote><blockquote class="mw mx my"><p id="a2ac" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated">创建一个不可变的 tf。缓冲区中的张量对象。</p></blockquote><p id="714e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量</strong></p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><h1 id="a8ff" class="lo lp iq bd lq lr og lt lu lv oh lx ly jw oi jx ma jz oj ka mc kc ok kd me mf bi translated">变形</h1><blockquote class="ml"><p id="5869" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">22-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#expandDims" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . expanddims</strong></a><strong class="ak">(x，轴？)</strong></p></blockquote><blockquote class="mw mx my"><p id="d2f0" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">返回一个 tf。通过在张量的形状中插入一个维度来扩展秩的张量。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="de5b" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> x = tf.tensor1d([1, 2, 3, 4]); <br/><strong class="nj ir">const</strong> axis = 1; <br/>x.expandDims(axis).print();</span><span id="5ad8" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>Tensor     [[1],      [2],      [3],      [4]]</strong></span></pre><p id="983d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量</strong></p><blockquote class="ml"><p id="fd6f" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">23-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#cast" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . cast</strong></a><strong class="ak">(x，dtype ) </strong></p></blockquote><blockquote class="mw mx my"><p id="6272" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">施放一个 tf。张量到一种新的数据类型。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="1252" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> x = tf.tensor1d([1.5, 2.5, 3]);<br/>tf.cast(x, 'int32').print();</span><span id="0dbe" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>Tensor     [1, 2, 3]</strong></span></pre><p id="11f3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量</strong></p><blockquote class="ml"><p id="5bd4" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">24-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#pad" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . pad</strong></a><strong class="ak">(x，paddings，constantValue？)</strong></p></blockquote><blockquote class="mw mx my"><p id="e69b" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">垫一个 tf。具有给定值和填充的张量。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="1bb0" class="nn lp iq nj b gy no np l nq nr">const x = tf.tensor1d([1, 2, 3, 4]);<br/>x.pad([[1, 2]]).print();</span><span id="e0f6" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>Tensor     [0, 1, 2, 3, 4, 0, 0]</strong></span></pre><p id="4a39" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量</strong></p><blockquote class="ml"><p id="4205" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">25-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#reshape" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . shape</strong></a><strong class="ak">(x，shape) </strong></p></blockquote><blockquote class="mw mx my"><p id="7ff9" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">重塑一个 tf。给定形状的张量。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="918e" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> x = tf.tensor1d([1, 2, 3, 4]); <br/>x.reshape([2, 2]).print();</span><span id="d83c" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>Tensor     [[1, 2],      <br/>            [3, 4]]</strong></span></pre><p id="fe46" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Returns→ <strong class="kt ir"> tf。张量</strong></p><blockquote class="ml"><p id="acb1" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">26 - tf.squeeze ( x，轴？)</p></blockquote><blockquote class="mw mx my"><p id="ef2c" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">从 tf 的形状中删除尺寸为 1 的尺寸。张量</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="ec50" class="nn lp iq nj b gy no np l nq nr">const x = tf.tensor([1, 2, 3, 4], [1, 1, 4]);<br/>x.squeeze().print();</span><span id="b3cd" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>Tensor     [1, 2, 3, 4]</strong></span></pre><p id="7d03" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Returns→ <strong class="kt ir"> tf。张量</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/31e201a70203836cb98df7e8408f9617.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-eVfVO9rzOUWEb4h4IWx4g.jpeg"/></div></div></figure><h1 id="c06d" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">模型</h1><p id="9a14" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">模型是层的集合，有关层如何连接的详细信息，请参见模型创建。</p><blockquote class="ml"><p id="9436" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">27 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#sequential" rel="noopener ugc nofollow" target="_blank"> tf。</a> <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#model" rel="noopener ugc nofollow" target="_blank">型号</a>()延伸至集装箱</p></blockquote><blockquote class="mw mx my"><p id="bdae" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">模型是由层组成的数据结构，其节点被定义为输入和输出。</strong></p></blockquote><p id="779a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">用 tf.model 制作的模型比<strong class="kt ir"> tf.sequential </strong>模型更普通。</p><blockquote class="mw mx my"><p id="b46d" class="kr ks mz kt b ku kv jr kw kx ky ju kz nc lb lc ld ne lf lg lh ng lj lk ll lm ij bi translated">下面的代码片段定义了一个由<strong class="kt ir">两个密集层(全连接)</strong>组成的模型，<strong class="kt ir"> 10 和 4 个单元。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="329a" class="nn lp iq nj b gy no np l nq nr"><em class="mz">//Define input, which has a size of 5(not including batch dimension)</em><br/><strong class="nj ir">const input = tf.input({shape: [5]});  </strong><br/><em class="mz">// First dense layer uses relu activation.</em> <br/><strong class="nj ir">const denseLayer1 = tf.layers.dense({units: 10, activation: 'relu'});</strong> <br/><em class="mz">// Second dense layer uses softmax activation.</em> <br/><strong class="nj ir">const denseLayer2 = tf.layers.dense({units: 2, activation: 'softmax'})</strong>;  <br/><em class="mz">// Obtain the output symbolic tensor by applying the layers on the input.</em> <br/><strong class="nj ir">const output = denseLayer2.apply(denseLayer1.apply(input));  <br/></strong><em class="mz">// Create the model based on the inputs.</em> <br/><strong class="nj ir">const model = tf.model({inputs: input, outputs: output});  <br/></strong><em class="mz">// The model can be used for training, evaluation and prediction.</em> <br/><em class="mz">// For example, the following line runs prediction with the model on</em> <em class="mz">// some fake data.</em> <br/><strong class="nj ir">model.predict(tf.ones([2, 5])).print();</strong></span><span id="5d9b" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>Tensor     [[0.3465916, 0.6534085],      [0.3465916, 0.6534085]]</strong></span></pre><blockquote class="ml"><p id="89bf" class="mm mn iq bd mo mp nt nu nv nw nx lm dk translated">27.1 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Model.compile" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">编译</strong> </a> <strong class="ak"> ( config ) </strong></p></blockquote><blockquote class="mw mx my"><p id="c3f5" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">为训练和评估配置和准备模型。编译用配置(优化器、损失和/或度量)装备模型。在未编译的</strong> <strong class="kt ir">模型上调用 fit 或 evaluate 会抛出错误。</strong></p></blockquote><p id="5c0c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货→ <strong class="kt ir">作废</strong></p><blockquote class="ml"><p id="8d5b" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">27.2 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Model.evaluate" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">评估</strong> </a> <strong class="ak"> ( x，y，config？)</strong></p></blockquote><blockquote class="mw mx my"><p id="a5fb" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated">返回测试模式下模型的损失值和度量值，这些值是在 compile()期间指定的，需要在调用 evaluate()之前发生。</p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="87d4" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> model = tf.sequential({    <br/>layers: [tf.layers.dense({units: 1, inputShape: [10]})] }); model.compile({optimizer: 'sgd', loss: 'meanSquaredError'}); <br/><strong class="nj ir">const</strong> result = <strong class="nj ir">model.evaluate(tf.ones([8, 10]), tf.ones([8, 1]),               { batchSize: 4})</strong>; <br/>result.print();<br/><strong class="nj ir">------RESULT------<br/>Tensor     0.00010169133020099252</strong></span></pre><p id="b815" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。标量</strong>或<strong class="kt ir"> tf。标量[] </strong></p><blockquote class="ml"><p id="57e0" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">27.3 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Model.predict" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">预测</strong> </a> <strong class="ak"> ( x，config？)</strong></p></blockquote><blockquote class="mw mx my"><p id="1514" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">为输入样本生成输出预测，计算分批完成。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="4c78" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> model = tf.sequential({<br/>   layers: [tf.layers.dense({units: 1, inputShape: [10]})]<br/>});<br/>model.predict(tf.ones([8, 10]), {batchSize: 4}).print();<br/><strong class="nj ir">------RESULT------<br/>Tensor    <br/>[[1.8470926],      <br/>[1.8470926],      <br/>[1.8470926],      <br/>[1.8470926],      <br/>[1.8470926],      <br/>[1.8470926],      <br/>[1.8470926],      <br/>[1.8470926]]</strong></span></pre><p id="5bd1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量</strong>或<strong class="kt ir"> tf。张量[] </strong></p><blockquote class="ml"><p id="df46" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">27.4 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Model.predictOnBatch" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">预测批次</strong> </a> <strong class="ak"> ( x ) </strong></p></blockquote><blockquote class="mw mx my"><p id="2875" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">返回一批样本的预测值，其中 x 是张量。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="a04b" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> model = tf.sequential({<br/>   layers: [tf.layers.dense({units: 1, inputShape: [10]})]<br/>});<br/>model.predictOnBatch(tf.ones([8, 10])).print();<br/><strong class="nj ir">------RESULT------<br/></strong><strong class="nj ir">Tensor     <br/>[[-1.1825931],      <br/>[-1.1825931],      <br/>[-1.1825931],      <br/>[-1.1825931],      <br/>[-1.1825931],      <br/>[-1.1825931],      <br/>[-1.1825931],      <br/>[-1.1825931]]</strong></span></pre><p id="7c7b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量</strong>或<strong class="kt ir"> tf。张量[ ] </strong></p><blockquote class="ml"><p id="6ee9" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">27.5 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Model.fit" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">拟合</strong> </a> <strong class="ak"> ( x，y，config？)</strong></p></blockquote><blockquote class="mw mx my"><p id="05de" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">为固定数量的历元(数据集上的迭代)训练模型。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="8dba" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> model = tf.sequential({      <br/>layers: [tf.layers.dense({units: 1, inputShape: [10]})] }); model.compile({optimizer: 'sgd', loss: 'meanSquaredError'}); <br/>for (let i = 1; i &lt; 5 ; ++i) {    <br/><strong class="nj ir">const</strong> h = await model.fit(tf.ones([8, 10]), tf.ones([8, 1]), <br/>                          { batchSize: 4, epochs: 3    });    <br/>console.log("Loss after Epoch " + i + " : " + h.history.loss[0]); <br/>}<br/><strong class="nj ir">------RESULT------<br/></strong><strong class="nj ir">Loss after Epoch 1 : 0.32676371932029724 <br/>Loss after Epoch 2 : 0.016571789979934692 <br/>Loss after Epoch 3 : 0.0008404387044720352 <br/>Loss after Epoch 4 : 0.00004262066795490682</strong></span></pre><p id="dd85" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货→ <strong class="kt ir">承诺</strong></p><blockquote class="ml"><p id="8d51" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">28 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#model" rel="noopener ugc nofollow" target="_blank"> <strong class="ak"> tf。</strong></a><a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#sequential" rel="noopener ugc nofollow" target="_blank"/><strong class="ak">()延伸到 tf。型号</strong></p></blockquote><blockquote class="mw mx my"><p id="4eab" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">一个有一堆层的模型，从一层到下一层线性进给。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="3679" class="nn lp iq nj b gy no np l nq nr"><em class="mz">// Define a model for linear regression.</em>   <br/><strong class="nj ir">const</strong> model = tf.sequential();   <br/>model.add(tf.layers.dense({units: 1, inputShape: [1]}));    <br/><em class="mz">//Prepare model for training: Specify the loss and the optimizer.</em>   <br/>model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});    <br/><em class="mz">// Generate some synthetic data for training.</em>   <br/><strong class="nj ir">const</strong> xs = tf.tensor2d([1, 2, 3, 4], [4, 1]);   <br/><strong class="nj ir">const</strong> ys = tf.tensor2d([1, 3, 5, 7], [4, 1]);    <br/><em class="mz">// Train the model using the data then do inference on a data point //the</em> <em class="mz">model hasn't seen:</em>   <br/>await model.fit(xs, ys);   model.predict(tf.tensor2d([5], [1, 1])).print();</span><span id="04a9" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/></strong><strong class="nj ir">Tensor      [[3.1389987],]</strong></span></pre><blockquote class="ml"><p id="4dec" class="mm mn iq bd mo mp nt nu nv nw nx lm dk translated">28.1 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Sequential.add" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">添加</strong> </a> <strong class="ak">(图层)</strong></p></blockquote><blockquote class="mw mx my"><p id="7d28" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">在层堆栈上添加一个层实例。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="898d" class="nn lp iq nj b gy no np l nq nr">const model = tf.sequential();<br/>model.add(tf.layers.dense({units: 8, inputShape: [1]})); model.add(tf.layers.dense({units: 4, activation: 'relu6'})); model.add(tf.layers.dense({units: 1, activation: 'relu6'}));<br/>  <br/><em class="mz">// Note that the untrained model is random at this point.</em><br/> model.predict(tf.randomNormal([10, 1])).print();</span><span id="daf6" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/></strong><strong class="nj ir">Tensor     [[0.0679427],      <br/>[0.3440365],      <br/>[0.4146437],      <br/>[0        ],      <br/>[0.0855753],      <br/>[0.0688378],      <br/>[0.1540508],      <br/>[0        ],      <br/>[0        ],      <br/>[0        ]]</strong></span></pre><p id="c601" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货→ <strong class="kt ir">作废</strong></p><blockquote class="ml"><p id="d184" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">28.2 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Sequential.evaluate" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">评估</strong> </a> <strong class="ak"> ( x，y，config？)</strong></p></blockquote><blockquote class="mw mx my"><p id="50b4" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">返回测试模式下模型的损失值&amp;度量值，计算是成批完成的。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="e9ef" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> model = tf.sequential({<br/>   layers: [tf.layers.dense({units: 1, inputShape: [10]})]<br/>});<br/>model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});<br/><strong class="nj ir">const</strong> result = model.evaluate(tf.ones([8, 10]), tf.ones([8, 1]), {<br/>   batchSize: 4,<br/>});<br/>result.print();</span><span id="2906" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/></strong><strong class="nj ir">Tensor     5.569275379180908</strong></span></pre><p id="554d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。标量</strong>或<strong class="kt ir"> tf。标量[] </strong></p><blockquote class="ml"><p id="a241" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">28.3 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Sequential.predict" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">预测</strong> </a> <strong class="ak"> ( x，config？)</strong></p></blockquote><blockquote class="mw mx my"><p id="f403" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">为输入样本生成输出预测，计算分批完成。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="b6f0" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> model = tf.sequential({<br/>   layers: [tf.layers.dense({units: 1, inputShape: [10]})]<br/>});<br/>model.predict(tf.ones([2, 10])).print();</span><span id="614a" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/></strong><strong class="nj ir">Tensor     [[-0.6576568],      [-0.6576568]]</strong></span></pre><p id="9c0f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量</strong>或<strong class="kt ir"> tf。张量[] </strong></p><blockquote class="ml"><p id="ad31" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">28.4 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tf.Sequential.fit" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">拟合</strong> </a> <strong class="ak"> ( x，y，config？)</strong></p></blockquote><blockquote class="mw mx my"><p id="bd7c" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">为固定数量的历元(数据集上的迭代)训练模型。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="2891" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> model = tf.sequential({<br/>   layers: [tf.layers.dense({units: 1, inputShape: [10]})]<br/>});<br/>model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});<br/><strong class="nj ir">const</strong> history = await model.fit(tf.ones([8, 10]), tf.ones([8, 1]), {<br/>   batchSize: 4,<br/>   epochs: 3<br/>});<br/>console.log(history.history.loss[0]);</span><span id="52d6" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/></strong><strong class="nj ir">0.486328125</strong></span></pre><p id="c1bc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货→ <strong class="kt ir">承诺</strong></p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><blockquote class="ml"><p id="092f" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">29-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#loadModel" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . load model</strong></a><strong class="ak">(path 或 IOHandler ) </strong></p></blockquote><blockquote class="mw mx my"><p id="63c9" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">加载一个模型，包括它的拓扑和可选的权重。</strong></p></blockquote><p id="e643" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">例 1 </strong>:将 tf.model()的拓扑和权重保存到浏览器本地存储；然后装回去。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="a7d0" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> model = tf.sequential(<br/>     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});<br/>console.log('Prediction from original model:');<br/>model.predict(tf.ones([1, 3])).print();<br/><br/><strong class="nj ir">const</strong> saveResults = await model.save('localstorage://my-model-1');<br/><br/><strong class="nj ir">const</strong> loadedModel = await tf.loadModel('localstorage://my-model-1');<br/>console.log('Prediction from loaded model:');<br/>loadedModel.predict(tf.ones([1, 3])).print();</span><span id="57e2" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>Prediction from original model: Tensor      [[0.7820088],] Prediction from loaded model: Tensor      [[0.7820088],]</strong></span></pre><p id="aad3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">示例 2: </strong>从 HTML 文件输入元素中从用户选择的文件中加载模型。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="b73a" class="nn lp iq nj b gy no np l nq nr"><em class="mz">// Note: this code snippet will not work without the HTML elements in the page</em><br/><strong class="nj ir">const</strong> jsonUpload = document.getElementById('json-upload');<br/><strong class="nj ir">const</strong> weightsUpload = document.getElementById('weights-upload');</span><span id="9a85" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">const</strong> model = await tf.loadModel<strong class="nj ir">(</strong><br/>tf.io.browserFiles([jsonUpload.files[0],     weightsUpload.files[0]])<strong class="nj ir">)</strong>;</span></pre><p id="a4ce" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">示例 3: </strong>从 HTTP 服务器加载一个模型。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="6407" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> model = await<br/>     tf.loadModel('https://storage.googleapis.com/tfjs-models/tfjs/iris_v1/model.json')</span></pre><h1 id="28c9" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">模型管理</h1><blockquote class="ml"><p id="fda3" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">30.1-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#copyModel" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . copy model</strong></a><strong class="ak">(sourceURL，destURL ) </strong></p></blockquote><blockquote class="mw mx my"><p id="72b2" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">将模型从一个 URL 复制到另一个 URL。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="7f17" class="nn lp iq nj b gy no np l nq nr"><em class="mz">// First create and save a model.</em> <br/><strong class="nj ir">const</strong> model = tf.sequential(); <br/>model.add(tf.layers.dense<strong class="nj ir">(</strong>      {units: 1, inputShape: [10], activation: 'sigmoid'})<strong class="nj ir">)</strong>; <br/>await model.save('localstorage://demo/management/model1'); <br/> <br/><em class="mz">// Then list existing models.</em> <br/>console.log(await tf.io.listModels());  </span><span id="f307" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// Copy the model, from Local Storage to IndexedDB.</em> <br/>await tf.io.copyModel('localstorage://demo/management/model1',      'indexeddb://demo/management/model1');  </span><span id="f5d0" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// List models again.</em> <br/>console.log(await tf.io.listModels()); <br/> <br/><em class="mz">// Remove both models.</em> <br/>await tf.io.removeModel('localstorage://demo/management/model1'); await tf.io.removeModel('indexeddb://demo/management/model1');</span><span id="7971" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>[object Object] [object Object]</strong></span></pre><p id="41e8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货→ <strong class="kt ir">承诺</strong></p><blockquote class="ml"><p id="a19a" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">30.2-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#listModels" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . list models</strong></a><strong class="ak">()</strong></p></blockquote><blockquote class="mw mx my"><p id="214a" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">列出存储在注册存储介质中的所有型号。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="c707" class="nn lp iq nj b gy no np l nq nr"><em class="mz">// First create and save a model.</em> <br/>const model = tf.sequential(); <br/>model.add<strong class="nj ir">(</strong>tf.layers.dense(  {units: 1, inputShape: [10], activation:   'sigmoid'})<strong class="nj ir">)</strong>; <br/>await model.save('localstorage://demo/management/model1');<br/> <br/><em class="mz">// Then list existing models.</em> <br/>console.log(await tf.io.listModels());  </span><span id="d479" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// Delete the model.</em> <br/>await tf.io.removeModel('localstorage://demo/management/model1'); <br/> <br/><em class="mz">// List models again.</em> <br/>console.log(await tf.io.listModels());</span><span id="3000" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>[object Object] [object Object]</strong></span></pre><p id="96c5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货:→ <strong class="kt ir">承诺</strong></p><blockquote class="ml"><p id="b266" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">30.3-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#moveModel" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . move model</strong></a><strong class="ak">(sourceURL，destURL ) </strong></p></blockquote><blockquote class="mw mx my"><p id="e855" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">将模型从一个 URL 移动到另一个 URL。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="749a" class="nn lp iq nj b gy no np l nq nr"><em class="mz">// First create and save a model.</em> <br/><strong class="nj ir">const</strong> model = tf.sequential(); <br/>model.add(tf.layers.dense({units: 1, inputShape: [10], activation: 'sigmoid'})); <br/>await model.save('localstorage://demo/management/model1');  </span><span id="f09b" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// Then list existing models.</em> <br/>console.log(await tf.io.listModels()); </span><span id="7ed0" class="nn lp iq nj b gy ns np l nq nr"> <em class="mz">// Move the model, from Local Storage to IndexedDB.</em> <br/>await tf.io.moveModel('localstorage://demo/management/model1',      'indexeddb://demo/management/model1');  </span><span id="3c4a" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// List models again.</em> <br/>console.log(await tf.io.listModels());  </span><span id="6fc1" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// Remove the moved model.</em> <br/>await tf.io.removeModel('indexeddb://demo/management/model1');</span><span id="e78b" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>[object Object] [object Object]</strong></span></pre><p id="c86e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货→ <strong class="kt ir">承诺</strong></p><blockquote class="ml"><p id="7f25" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">30.4-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#removeModel" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . remove model</strong></a><strong class="ak">(网址)</strong></p></blockquote><blockquote class="mw mx my"><p id="428d" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">从注册的存储介质中删除由 URL 指定的型号。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="d6d7" class="nn lp iq nj b gy no np l nq nr"><em class="mz">// First create and save a model.</em> <br/><strong class="nj ir">const</strong> model = tf.sequential(); <br/>model.add(tf.layers.dense(      {units: 1, inputShape: [10], activation: 'sigmoid'})); <br/>await model.save('localstorage://demo/management/model1');  </span><span id="b72a" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// Then list existing models.<br/></em> console.log(await tf.io.listModels());  </span><span id="6063" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// Delete the model.</em> <br/>await tf.io.removeModel('localstorage://demo/management/model1');  </span><span id="daab" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// List models again.</em> <br/>console.log(await tf.io.listModels());<br/><strong class="nj ir">------RESULT------<br/>[object Object] [object Object]</strong></span></pre><p id="5646" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货→ <strong class="kt ir">承诺</strong></p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><h1 id="e9b8" class="lo lp iq bd lq lr og lt lu lv oh lx ly jw oi jx ma jz oj ka mc kc ok kd me mf bi translated">层(高级激活)</h1><blockquote class="ml"><p id="a254" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">31.1-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.leakyReLU" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . layers . leaky relu</strong></a><strong class="ak">(config？)</strong></p></blockquote><blockquote class="mw mx my"><p id="55d1" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">输入形状:任意。将该层用作模型中的第一层时，使用配置</strong> <code class="fe om on oo nj b"><strong class="kt ir">inputShape</strong></code> <strong class="kt ir">。</strong></p><p id="f63e" class="kr ks mz kt b ku kv jr kw kx ky ju kz nc lb lc ld ne lf lg lh ng lj lk ll lm ij bi translated"><code class="fe om on oo nj b">(x) = alpha * x for x &lt; 0.</code> <code class="fe om on oo nj b">f(x) = x for x &gt;= 0.</code></p><p id="e471" class="kr ks mz kt b ku kv jr kw kx ky ju kz nc lb lc ld ne lf lg lh ng lj lk ll lm ij bi translated">输出形状→与输入形状相同。</p></blockquote><p id="f5b6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">returns→<strong class="kt ir">TF . layers . layer</strong></p><blockquote class="ml"><p id="0e44" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">31.2-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.softmax" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . layers . soft max</strong></a><strong class="ak">(config？)</strong></p></blockquote><blockquote class="mw mx my"><p id="6a07" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">输入形状</strong> →任意。将该层用作模型中的第一层时，使用配置<code class="fe om on oo nj b">inputShape</code>。</p><p id="5414" class="kr ks mz kt b ku kv jr kw kx ky ju kz nc lb lc ld ne lf lg lh ng lj lk ll lm ij bi translated"><strong class="kt ir">输出形状</strong> →与输入形状相同。</p></blockquote><p id="14fb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">returns→<strong class="kt ir">TF . layers . layer</strong></p><h1 id="af73" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">层(基本功能)</h1><blockquote class="ml"><p id="6be5" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">32.1-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.dense" rel="noopener ugc nofollow" target="_blank"><strong class="ak"/></a><strong class="ak">(单位，激活好玩。，配置？)</strong></p></blockquote><blockquote class="mw mx my"><p id="c40b" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">创建一个密集的(完全连接的)层。</strong></p><p id="103c" class="kr ks mz kt b ku kv jr kw kx ky ju kz nc lb lc ld ne lf lg lh ng lj lk ll lm ij bi translated"><strong class="kt ir">输出=激活(点(输入，内核(又名权重))+偏差)</strong></p></blockquote><p id="b1fc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">单位</strong>(数字)正整数，输出空间的维数。</p><p id="ed37" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">returns→<strong class="kt ir">TF . layers . layer</strong></p><blockquote class="ml"><p id="973a" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">32.2-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.dropout" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . layers . dropout</strong></a><strong class="ak">(rate，config？)</strong></p></blockquote><blockquote class="mw mx my"><p id="b618" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">将漏失应用于输入。</strong></p></blockquote><p id="9578" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">速率</strong>(数字)在 0 和 1 之间浮动。要丢弃的输入单位的分数。</p><p id="c2c8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">returns→<strong class="kt ir">TF . layers . layer</strong></p><blockquote class="ml"><p id="abde" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">32.3-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.flatten" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . layers . flatten</strong></a><strong class="ak">(config？)</strong></p></blockquote><blockquote class="mw mx my"><p id="02b3" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">拉平输入，不影响批量大小。</strong></p><p id="05a2" class="kr ks mz kt b ku kv jr kw kx ky ju kz nc lb lc ld ne lf lg lh ng lj lk ll lm ij bi translated"><strong class="kt ir">它将输入到 1D 的每一批变平(使输出为 2D)。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="9cfe" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> input = tf.input({shape: [4, 3]});<br/><strong class="nj ir">const</strong> flattenLayer = tf.layers.flatten();</span><span id="c575" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// Inspect the inferred output shape of flatten layer, which</em><br/><em class="mz">// equals `[null, 12]`. The 2nd dimension is 4 * 3, i.e., the result // of the flattening.(The 1st dimension is undermined batch size.)</em></span><span id="0f33" class="nn lp iq nj b gy ns np l nq nr">console.log(JSON.stringify(flattenLayer.apply(input).shape));</span><span id="7872" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>[null,12]</strong></span></pre><p id="1c13" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">returns→<strong class="kt ir">TF . layers . layer</strong></p><h1 id="3e68" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">层(卷积)</h1><blockquote class="ml"><p id="7c8b" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">33-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.conv2d" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . layers . conv2d</strong></a><strong class="ak">(滤镜)</strong></p></blockquote><blockquote class="mw mx my"><p id="6b98" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">该层创建一个卷积核，该卷积核与层输入进行卷积，以产生输出张量。</strong></p></blockquote><p id="4199" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">滤波器</strong>(数字)输出空间的维数(即卷积中滤波器的数量)。</p><p id="5e8a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">returns→<strong class="kt ir">TF . layers . layer</strong></p><blockquote class="ml"><p id="e979" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">34-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.cropping2D" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . layers . cropping 2d</strong></a><strong class="ak">(裁剪，配置？)</strong></p></blockquote><blockquote class="mw mx my"><p id="da84" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">该层可以在图像张量的顶部、底部、左侧和右侧裁剪输入。</strong></p></blockquote><p id="930d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">裁剪</strong> (number|[number，number]|[[number，number]，[number，number]])裁剪沿宽度和高度的尺寸。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="5008" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> model = tf.sequential(); model.add(tf.layers.cropping2D({cropping:[[2, 2], [2, 2]],                                 inputShape: [128, 128, 3]})); </span><span id="a50c" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">//now output shape is [batch, 124, 124, 3]</em></span></pre><p id="c5b3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">returns→<strong class="kt ir">TF . layers . layer</strong></p><h1 id="bfc6" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">图层(标准化)</h1><blockquote class="ml"><p id="edc0" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">35-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.batchNormalization" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . layers . batch 规格化</strong> </a> <strong class="ak"> ( axis，config？)</strong></p></blockquote><blockquote class="mw mx my"><p id="0a90" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">标准化每批前一层的激活，即应用一个保持平均激活接近 0 和激活标准偏差接近 1 的变换。</strong></p></blockquote><p id="00c6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">轴</strong>(数字)应该归一化的整数轴(通常是特征轴)。默认值为-1。</p><p id="1efa" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf.layers.Layer </strong></p><h1 id="bc11" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">层(池化)</h1><blockquote class="ml"><p id="2dd0" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">36-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.averagePooling1d" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . layers . averagepool2d</strong></a><strong class="ak">(poolSize，config ) </strong></p></blockquote><blockquote class="mw mx my"><p id="e141" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">空间数据的平均池化操作。</strong></p></blockquote><p id="3dc3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> poolSize </strong> (number 或[number，number])在每个维度[垂直，水平]中缩减的因子。需要一个整数或 2 个整数的数组。</p><p id="4ad7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">returns→<strong class="kt ir">TF . layers . layer</strong></p><blockquote class="mw mx my"><p id="0167" class="kr ks mz kt b ku kv jr kw kx ky ju kz nc lb lc ld ne lf lg lh ng lj lk ll lm ij bi translated">注:他们还有<strong class="kt ir">平均池 1d </strong>和<strong class="kt ir">全局平均池</strong>等。</p></blockquote><blockquote class="ml"><p id="d89f" class="mm mn iq bd mo mp nt nu nv nw nx lm dk translated">37-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.maxPooling2d" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . layers . maxpool2d</strong></a><strong class="ak">(</strong>poolSize，<strong class="ak"> config ) </strong></p></blockquote><blockquote class="mw mx my"><p id="e521" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">空间数据的最大池化操作。</strong></p></blockquote><p id="9e9e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">pool size</strong>(number |[number，number])在每个维度[垂直，水平]中缩减的因子。需要一个整数或 2 个整数的数组。</p><p id="0c77" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">returns→<strong class="kt ir">TF . layers . layer</strong></p><blockquote class="mw mx my"><p id="f238" class="kr ks mz kt b ku kv jr kw kx ky ju kz nc lb lc ld ne lf lg lh ng lj lk ll lm ij bi translated">注:它们还有<strong class="kt ir"> maxPooling1d </strong>和<strong class="kt ir"> globalMaxPooling </strong>等。</p></blockquote></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><h1 id="18d0" class="lo lp iq bd lq lr og lt lu lv oh lx ly jw oi jx ma jz oj ka mc kc ok kd me mf bi translated">层(包装)</h1><blockquote class="ml"><p id="01f4" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">38-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.bidirectional" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . layers . bidirectional</strong></a><strong class="ak">(layer，config ) </strong></p></blockquote><blockquote class="mw mx my"><p id="dbaa" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">它包括复制网络中的第一个循环层，从而现在有两个并排的层，然后将输入序列原样作为输入提供给第一层，并将输入序列的反向副本提供给第二层。这项技术有助于 LSTMs。</strong></p></blockquote><p id="4741" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">图层</strong> (RNN)一个要被包裹的 RNN 图层的实例。</p><p id="31f7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货→ <strong class="kt ir">包装</strong></p><blockquote class="ml"><p id="f012" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">39-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.timeDistributed" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . layers . time distributed</strong></a><strong class="ak">(图层)</strong></p></blockquote><blockquote class="mw mx my"><p id="c7ce" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">输入应该至少是 3D 的，索引 1 的维度将被认为是时间维度。</strong></p></blockquote><p id="68e4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">returns→<strong class="kt ir">TF . layers . layer</strong></p><h1 id="a69b" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">图层(当前)</h1><blockquote class="ml"><p id="03a2" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">40-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.rnn" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . layers . rnn</strong></a><strong class="ak">(cell</strong>(TF。RNNCell 或 tf。RNNCell[ ] <strong class="ak"> ) ) </strong></p></blockquote><blockquote class="mw mx my"><p id="44de" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">输入形状:带形状的 3D 张量。</strong></p></blockquote><p id="054a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">returns→<strong class="kt ir">TF . layers . layer</strong></p><blockquote class="ml"><p id="c550" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">41 - <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.simpleRNN" rel="noopener ugc nofollow" target="_blank"> <strong class="ak"> tf。</strong></a><a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#multiRNNCell" rel="noopener ugc nofollow" target="_blank"><strong class="ak">multi rnncell</strong></a><strong class="ak">(lstmCells，data，c，h) </strong></p></blockquote><blockquote class="mw mx my"><p id="74a8" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">计算 LSTMCells 堆栈的下一个状态和输出。</strong></p><p id="2a47" class="kr ks mz kt b ku kv jr kw kx ky ju kz nc lb lc ld ne lf lg lh ng lj lk ll lm ij bi translated"><strong class="kt ir">每个单元格的输出用作下一个单元格的输入</strong></p></blockquote><p id="13c8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">lstmCells</strong>T28】LSTMCell 函数的数组。</p><p id="2f6b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">数据</strong> <em class="mz">输入到单元格中。</em></p><p id="361d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">c</strong>T36】前一个单元格状态的数组。</p><p id="f9ea" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> h </strong> <em class="mz">前一个单元输出的数组。</em></p><p id="e213" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→<strong class="kt ir">【TF。Tensor2D[]，tf。Tensor2D[]] </strong></p><blockquote class="mw mx my"><p id="f939" class="kr ks mz kt b ku kv jr kw kx ky ju kz nc lb lc ld ne lf lg lh ng lj lk ll lm ij bi translated">注意:它们还有<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.simpleRNNCell" rel="noopener ugc nofollow" target="_blank"><strong class="kt ir">TF . layers . simplernncell</strong></a><strong class="kt ir">，</strong></p><p id="23dc" class="kr ks mz kt b ku kv jr kw kx ky ju kz nc lb lc ld ne lf lg lh ng lj lk ll lm ij bi translated"><a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.stackedRNNCells" rel="noopener ugc nofollow" target="_blank"><strong class="kt ir">TF . layers . stackednncells</strong></a><strong class="kt ir">(配置)，</strong></p><p id="d2c5" class="kr ks mz kt b ku kv jr kw kx ky ju kz nc lb lc ld ne lf lg lh ng lj lk ll lm ij bi translated"><a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.simpleRNN" rel="noopener ugc nofollow" target="_blank"><strong class="kt ir">layers . simplernn</strong></a><strong class="kt ir">(配置)</strong></p></blockquote><blockquote class="ml"><p id="0f75" class="mm mn iq bd mo mp nt nu nv nw nx lm dk translated">42-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.lstm" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . layers . lstm</strong></a><strong class="ak">【配置】</strong></p></blockquote><blockquote class="mw mx my"><p id="9def" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">长短期记忆层</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="7294" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> lstm = tf.layers.lstm({units: 8, returnSequences: true});  </span><span id="0aa6" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// Create an input with 10 time steps.</em> <br/><strong class="nj ir">const</strong> input = tf.input({shape: [10, 20]}); <br/><strong class="nj ir">const</strong> output = lstm.apply(input);  </span><span id="43f1" class="nn lp iq nj b gy ns np l nq nr">console.log(JSON.stringify(output.shape)); </span><span id="ed77" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// [null, 10, 8]: 1st dimension is unknown batch size; <br/>// 2nd dimension is the same as the sequence length of [tf.input()]//(#input), due to `returnSequences`: `true`;</em> <br/><em class="mz">// 3rd dimension is the `LSTMCell`'s number of units.</em></span><span id="6e82" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>[null,10,8]</strong></span></pre><p id="8867" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">returns→<strong class="kt ir">TF . layers . layer</strong></p><blockquote class="ml"><p id="322c" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">43-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#layers.lstmCell" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . layers . lstmcell</strong></a><strong class="ak">(配置)</strong></p></blockquote><blockquote class="mw mx my"><p id="3ce8" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir"> LSTM 单元与 RNN 子类 LSTM 的不同之处在于，其应用方法仅获取单个时间步长的输入数据，并在该时间步长返回单元的输出，而 LSTM 获取多个时间步长的输入数据。</strong></p></blockquote><p id="a4fd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">例如:</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="416b" class="nn lp iq nj b gy no np l nq nr">const cell = tf.layers.lstmCell({units: 2}); <br/>const input = tf.input({shape: [10]}); <br/>const output = cell.apply(input);  console.log(JSON.stringify(output.shape)); <br/><em class="mz">// [null, 10]: This is cell's output at a single time step. The 1st</em> <em class="mz">// dimension is the unknown batch size.</em></span><span id="d02b" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>[null,10]</strong></span></pre><p id="cd7d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">LSTMCell 工作流最典型的用途是将多个像元组合成一个堆叠的 RNN 像元。例如</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="a677" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> cells = [tf.layers.lstmCell({units: 4}),          tf.layers.lstmCell({units: 8}), ]; <br/>const rnn = tf.layers.rnn({cell: cells, returnSequences: true});  </span><span id="5045" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">//Create input with 10 time steps and length-20 vector at each step.</em> <br/>const input = tf.input({shape: [10, 20]}); <br/>const output = rnn.apply(input);</span><span id="0102" class="nn lp iq nj b gy ns np l nq nr">console.log(JSON.stringify(output.shape)); </span><span id="9596" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// [null, 10, 8]: 1st dimension is unknown batch size; 2nd dimension //is the</em> <em class="mz">same as the sequence length of [tf.input()](#input), due to //`returnSequences`: `true`;</em> <em class="mz">3rd dimension is the last `lstmCell`'s //number of units.</em></span><span id="6b28" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>[null,10,8]</strong></span></pre><p id="c21f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。RNNCell </strong></p><blockquote class="ml"><p id="83e7" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">44-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#basicLSTMCell" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . basiclstmcell</strong></a><strong class="ak">(健忘偏差，lstmKernel，lstmBias，数据，c，h ) </strong></p></blockquote><blockquote class="mw mx my"><p id="0283" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">计算 BasicLSTMCell 的下一个状态和输出。</strong></p></blockquote><p id="07ef" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> c </strong>前一个单元格状态。</p><p id="7523" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> h </strong>前一个单元输出。</p><p id="4b03" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">returns→<strong class="kt ir">【TF。Tensor2D，tf。Tensor2D] </strong></p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><h1 id="da6d" class="lo lp iq bd lq lr og lt lu lv oh lx ly jw oi jx ma jz oj ka mc kc ok kd me mf bi translated">训练(梯度)</h1><blockquote class="ml"><p id="7eba" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">45-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#grad" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . grad</strong></a><strong class="ak">(f)</strong></p></blockquote><blockquote class="mw mx my"><p id="5b84" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir"> f </strong>代表数学函数。</p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="e052" class="nn lp iq nj b gy no np l nq nr"><em class="mz">// f(x) = x ^ 2</em> <br/><strong class="nj ir">const</strong> f = x =&gt; x.square(); </span><span id="dfd0" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// f'(x) = 2x</em> <br/><strong class="nj ir">const</strong> g = tf.grad(f); <br/> <br/><strong class="nj ir">const</strong> x = tf.tensor1d([2, 3]); <br/>g(x).print();</span><span id="fd8a" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>Tensor     [4, 6]</strong></span></pre><p id="b70e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">另一个例子</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="ee60" class="nn lp iq nj b gy no np l nq nr"><em class="mz">// f(x) = x ^ 3</em> <br/><strong class="nj ir">const</strong> f = x =&gt; x.pow(tf.scalar(3, 'int32')); </span><span id="6467" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// f'(x) = 3x ^ 2</em> <br/><strong class="nj ir">const</strong> g = tf.grad(f); </span><span id="ba19" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// f''(x) = 6x</em> <br/><strong class="nj ir">const</strong> gg = tf.grad(g);  <br/><strong class="nj ir">const</strong> x = tf.tensor1d([2, 3]); <br/>gg(x).print();</span><span id="3574" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>Tensor     [12, 18.0000038]</strong></span></pre><p id="c07b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">returns→<strong class="kt ir">(x:</strong><a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#class:Tensor" rel="noopener ugc nofollow" target="_blank"><strong class="kt ir">TF。张量</strong> </a> <strong class="kt ir">，dy？:</strong>T30<strong class="kt ir">TF。张量</strong><strong class="kt ir">)=&gt;</strong><a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#class:Tensor" rel="noopener ugc nofollow" target="_blank"><strong class="kt ir">TF。张量</strong> </a></p><blockquote class="ml"><p id="8a22" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">46-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#customGrad" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . custom grad</strong></a><strong class="ak">【f】</strong></p></blockquote><pre class="op oq or os ot ni nj nk nl aw nm bi"><span id="acda" class="nn lp iq nj b gy no np l nq nr"><em class="mz">// Override gradient of our custom x ^ 2 op to be dy * abs(x);</em><br/><strong class="nj ir">const</strong> customOp = tf.customGrad<strong class="nj ir">(</strong>x =&gt; {    <br/>    return {value: x.square(), gradFunc: dy =&gt; [dy.mul(x.abs())]}; <br/>}<strong class="nj ir">)</strong>;</span><span id="ad62" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">const</strong> x = tf.tensor1d([-1, -2, 3]); <br/><strong class="nj ir">const</strong> dx = tf.grad(x =&gt; customOp(x));  <br/>console.log(`f(x):`); <br/>customOp(x).print(); <br/>console.log(`f'(x):`); <br/>dx(x).print();</span><span id="2c9c" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>f(x): Tensor     [1, 4, 9] f'(x): Tensor     [1, 2, 3]</strong></span></pre><p id="9cb1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">returns→<strong class="kt ir">(…args:</strong><a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#class:Tensor" rel="noopener ugc nofollow" target="_blank"><strong class="kt ir">TF。张量</strong></a><strong class="kt ir">[])=&gt;</strong><a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#class:Tensor" rel="noopener ugc nofollow" target="_blank"><strong class="kt ir">TF。张量</strong> </a></p><h1 id="7190" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">培训(优化人员)</h1><blockquote class="ml"><p id="6315" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">47-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#train.adam" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . train . Adam</strong></a><strong class="ak">(learning rate？，beta1？，beta2？，ε？)</strong></p></blockquote><blockquote class="mw mx my"><p id="02ea" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">构建一个使用 Adam 算法的 AdamOptimizer。<em class="iq">见</em></strong><a class="ae ny" href="https://arxiv.org/abs/1412.6980" rel="noopener ugc nofollow" target="_blank"><em class="iq">https://arxiv.org/abs/1412.6980</em></a></p></blockquote><h2 id="7f4b" class="nn lp iq bd lq ou ov dn lu ow ox dp ly la oy oz ma le pa pb mc li pc pd me pe bi translated">参数:</h2><p id="0593" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated"><strong class="kt ir"> learningRate </strong>(数字)用于 Adam 梯度下降算法。可选择的</p><p id="16f2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">(数字)一阶矩估计值的指数衰减率。可选择的</p><p id="43f8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">(数字)二阶矩估计值的指数衰减率。可选择的</p><p id="249f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">ε</strong>(数字)用于数值稳定的小常数。可选择的</p><p id="b131" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Returns→ <strong class="kt ir"> AdamOptimizer </strong></p><blockquote class="ml"><p id="a27f" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">48-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#train.rmsprop" rel="noopener ugc nofollow" target="_blank">T3】TF . train . rms prop</a><strong class="ak">(learning rate，decay？，气势？，ε？，居中？)</strong></p></blockquote><blockquote class="mw mx my"><p id="3262" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">构造一个 tf。使用 RMSProp 梯度下降的 RMSPropOptimizer。</strong></p></blockquote><h2 id="05fa" class="nn lp iq bd lq ou ov dn lu ow ox dp ly la oy oz ma le pa pb mc li pc pd me pe bi translated">参数:</h2><p id="24fb" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated"><strong class="kt ir">学习率</strong>(数字)用于 RMSProp 梯度下降算法的学习率。</p><p id="3c9f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">衰减</strong>(数字)历史/未来梯度的贴现因子。可选择的</p><p id="db31" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">动量</strong>(数字)用于 RMSProp 梯度下降算法的动量。可选择的</p><p id="7600" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">ε</strong>(数字)小值避免分母为零。可选择的</p><p id="fd6e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">居中</strong>(布尔型)如果为真，则通过梯度的估计方差对梯度进行归一化。可选择的</p><p id="62fb" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Returns→ <strong class="kt ir"> tf。RMSPropOptimizer </strong></p><h1 id="a40b" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">培训(损失)</h1><blockquote class="ml"><p id="2e64" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">49-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#losses.meanSquaredError" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . losses . meansquadererror</strong></a><strong class="ak">(标签，预测，权重？，还原？)</strong></p></blockquote><blockquote class="mw mx my"><p id="f6ca" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">计算两个张量之间的均方误差。</strong></p></blockquote><p id="c859" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量</strong></p><blockquote class="ml"><p id="c47f" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">50-<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#losses.softmaxCrossEntropy" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . losses . softmaxcrossentropy</strong></a><strong class="ak">(labels，logits，dim？)</strong></p></blockquote><blockquote class="mw mx my"><p id="8cba" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">计算逻辑和标签之间的 softmax 交叉熵。它测量类别互斥的离散分类任务中的概率误差。</strong></p></blockquote><p id="0f3d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">例如，每个 CIFAR-10 图像都有且只有一个标签:图像可以是狗或卡车，但不能同时是狗和卡车。</p><p id="d0f4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">返回→ <strong class="kt ir"> tf。张量</strong></p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><h1 id="5dca" class="lo lp iq bd lq lr og lt lu lv oh lx ly jw oi jx ma jz oj ka mc kc ok kd me mf bi translated">自我提醒:不要列很长的清单</h1><h1 id="c96b" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">— — — — — —奖金— — — — —</h1><h1 id="b18a" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">表演</h1><blockquote class="ml"><p id="3487" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated"><a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tidy" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . tidy</strong></a><strong class="ak">(nameOrFn，Fn？，gradMode？)</strong></p></blockquote><blockquote class="mw mx my"><p id="00bb" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">执行 f 提供的函数，执行后清除 f 分配的所有中间张量，f 返回的除外</strong></p></blockquote><p id="30dc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">使用这种方法有助于避免内存泄漏。一般来说，将对操作的调用包装在<a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#tidy" rel="noopener ugc nofollow" target="_blank"> tf.tidy() </a>中进行自动内存清理。</p><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="a2c9" class="nn lp iq nj b gy no np l nq nr"><em class="mz">// y = 2 ^ 2 + 1</em> <br/><strong class="nj ir">const</strong> y = tf.tidy(() =&gt; {    <em class="mz">/<br/>/ a, b, and one will be cleaned up when the tidy ends.</em>    <br/><strong class="nj ir">const</strong> one = tf.scalar(1);    <br/><strong class="nj ir">const</strong> a = tf.scalar(2);    <br/><strong class="nj ir">const</strong> b = a.square();     <br/>console.log('numTensors (in tidy): ' + tf.memory().numTensors);     <em class="mz">// The value returned inside the tidy function will return</em>    <br/><em class="mz">// through the tidy, in this case to the variable y.</em>    <br/>return b.add(one); });  <br/>console.log('numTensors (outside tidy): ' + tf.memory().numTensors); <strong class="nj ir">y.print();</strong></span><span id="524f" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>numTensors (in tidy): 16 <br/>numTensors (outside tidy): 14 <br/>Tensor     5</strong></span></pre><p id="850a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">returns→<strong class="kt ir">void | number | string | TF。张量|tf。张量[]|{[key: string]:tf。张量|数字|字符串} </strong></p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><blockquote class="ml"><p id="31f4" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated"><a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#keep" rel="noopener ugc nofollow" target="_blank"><strong class="ak"/></a><strong class="ak">(结果)</strong></p></blockquote><blockquote class="mw mx my"><p id="4973" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">保持一个 tf。tf.tidy()内部生成的张量不会被自动释放。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="594c" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">let</strong> b; <br/><strong class="nj ir">const</strong> y = tf.tidy<strong class="nj ir">(</strong>() =&gt; <strong class="nj ir">{</strong>    <br/>      const one = tf.scalar(1);    <br/>      const a = tf.scalar(2);     </span><span id="c364" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// b will not be cleaned up by the tidy. a and one will be cleaned //up when the tidy ends.</em>    <br/>b = tf.keep(a.square());     <br/>console.log('numTensors (in tidy): ' + tf.memory().numTensors);     </span><span id="d03e" class="nn lp iq nj b gy ns np l nq nr"><em class="mz">// The value returned inside the tidy function will return</em>    <br/><em class="mz">// through the tidy, in this case to the variable y.</em>    <br/>return b.add(one); <br/><strong class="nj ir">})</strong>;  </span><span id="30c5" class="nn lp iq nj b gy ns np l nq nr">console.log('numTensors (outside tidy): ' + tf.memory().numTensors); console.log('y:'); </span><span id="81d7" class="nn lp iq nj b gy ns np l nq nr">y.print(); <br/>console.log('b:'); <br/>b.print();</span><span id="78c0" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>numTensors (in tidy): 16 <br/>numTensors (outside tidy): 15 <br/>y: Tensor     5 <br/>b: Tensor     4</strong></span></pre><p id="25c5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Returns→ <strong class="kt ir"> tf。张量</strong></p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><blockquote class="ml"><p id="4c0c" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated"><a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#memory" rel="noopener ugc nofollow" target="_blank"><strong class="ak"/></a><strong class="ak">()</strong></p></blockquote><blockquote class="mw mx my"><p id="75e7" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">返回程序当前时间的内存信息。</strong></p></blockquote><p id="08ed" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">Returns→ <strong class="kt ir"> MemoryInfo </strong></p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><blockquote class="ml"><p id="aa96" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated"><a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#time" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . time</strong></a><strong class="ak">(f)</strong></p></blockquote><blockquote class="mw mx my"><p id="d568" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">执行</strong> f( ) <strong class="kt ir">并返回一个带有计时信息的承诺。</strong></p></blockquote><pre class="kg kh ki kj gt ni nj nk nl aw nm bi"><span id="70bb" class="nn lp iq nj b gy no np l nq nr"><strong class="nj ir">const</strong> x = tf.randomNormal([20, 20]); <br/><strong class="nj ir">const</strong> time = await tf.time(() =&gt; x.matMul(x));  </span><span id="b471" class="nn lp iq nj b gy ns np l nq nr">console.log<strong class="nj ir">(</strong>`kernelMs: ${time.kernelMs},                       wallTimeMs:   ${time.wallMs}`<strong class="nj ir">)</strong>;</span><span id="aa53" class="nn lp iq nj b gy ns np l nq nr"><strong class="nj ir">------RESULT------<br/>kernelMs: 0.10000000149011612, wallTimeMs: 33.40000000037253</strong></span></pre><p id="15f7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货→ <strong class="kt ir">承诺</strong></p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><blockquote class="ml"><p id="1b14" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated"><a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#setBackend" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . set back end</strong></a><strong class="ak">(backen dtype，safeMode？)</strong></p></blockquote><blockquote class="mw mx my"><p id="e19f" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">设置后端(cpu、webgl 等)负责创建张量并在这些张量上执行操作。</strong></p></blockquote><p id="2676" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货→ <strong class="kt ir">作废</strong></p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><blockquote class="ml"><p id="19b3" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated"><a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#toPixels" rel="noopener ugc nofollow" target="_blank"><strong class="ak">TF . topixels</strong></a><strong class="ak">(img，canvas？)</strong></p></blockquote><blockquote class="mw mx my"><p id="e240" class="kr ks mz kt b ku na jr kw kx nb ju kz nc nd lc ld ne nf lg lh ng nh lk ll lm ij bi translated"><strong class="kt ir">画出一个</strong> <a class="ae ny" href="https://js.tensorflow.org/api/0.11.2/#class:Tensor" rel="noopener ugc nofollow" target="_blank"> <strong class="kt ir"> tf。像素值的张量</strong> </a> <strong class="kt ir">到一个字节数组或可选的画布。</strong></p></blockquote><p id="6ba6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">此外，当输入的 dtype 为“float32”时，我们假定值在范围[0–1]内。否则，当输入为“int32”时，我们假定值在范围[0–255]内。</p><p id="4780" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">要绘制到的画布。可选择的</p><p id="37cc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> img </strong> (tf。Tensor2D 或 tf。Tensor3D)秩 2 或秩 3 张量。如果等级为-2，则绘制灰度。如果秩为 3，则深度必须为 1、3 或 4。当深度为 1 时，绘制灰度。</p><p id="f107" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">退货→ <strong class="kt ir">承诺</strong></p></div><div class="ab cl nz oa hu ob" role="separator"><span class="oc bw bk od oe of"/><span class="oc bw bk od oe of"/><span class="oc bw bk od oe"/></div><div class="ij ik il im in"><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/d5dcb638e4c91a2393a9b70e627de1db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/1*plqfUZ6F48nsC0v1zM2a0Q.gif"/></div></figure><p id="4586" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在…我很确定我已经错过了你最喜欢的 API，所以不要忘记在评论或任何问题中提到它。</p><blockquote class="ml"><p id="8bdc" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">感谢您阅读帖子。</p><p id="7193" class="mm mn iq bd mo mp mq mr ms mt mu lm dk translated">我希望这篇文章对你有所帮助。</p></blockquote><p id="2514" class="pw-post-body-paragraph kr ks iq kt b ku na jr kw kx nb ju kz la nd lc ld le nf lg lh li nh lk ll lm ij bi translated">关注我<a class="ae ny" href="https://medium.com/@sagarsharma4244" rel="noopener"> <strong class="kt ir">中</strong> </a>获取更多惊艳教程。</p><p id="c78c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">鼓掌吧！分享一下！跟我来。</strong></p><p id="5390" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">乐意帮忙。荣誉……..</p><h1 id="3609" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">你会喜欢的以前的故事:</h1><div class="pg ph gp gr pi pj"><a rel="noopener follow" target="_blank" href="/tensorflow-on-mobile-tensorflow-lite-a5303eef77eb"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd ir gy z fp po fr fs pp fu fw ip bi translated">手机上的 tensor flow:tensor flow Lite</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">我们得到了什么？</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">towardsdatascience.com</p></div></div><div class="ps l"><div class="pt l pu pv pw ps px kp pj"/></div></div></a></div><div class="pg ph gp gr pi pj"><a rel="noopener follow" target="_blank" href="/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd ir gy z fp po fr fs pp fu fw ip bi translated">纪元与批量大小与迭代次数</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">了解您的代码…</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">towardsdatascience.com</p></div></div><div class="ps l"><div class="py l pu pv pw ps px kp pj"/></div></div></a></div><div class="pg ph gp gr pi pj"><a rel="noopener follow" target="_blank" href="/tensorflow-on-mobile-tutorial-1-744703297267"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd ir gy z fp po fr fs pp fu fw ip bi translated">手机上的 TensorFlow:教程</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">在 Android 和 iOS 上</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">towardsdatascience.com</p></div></div><div class="ps l"><div class="pz l pu pv pw ps px kp pj"/></div></div></a></div><div class="pg ph gp gr pi pj"><a rel="noopener follow" target="_blank" href="/activation-functions-neural-networks-1cbd9f8d91d6"><div class="pk ab fo"><div class="pl ab pm cl cj pn"><h2 class="bd ir gy z fp po fr fs pp fu fw ip bi translated">激活函数:神经网络</h2><div class="pq l"><h3 class="bd b gy z fp po fr fs pp fu fw dk translated">Sigmoid，tanh，Softmax，ReLU，Leaky ReLU 解释！！！</h3></div><div class="pr l"><p class="bd b dl z fp po fr fs pp fu fw dk translated">towardsdatascience.com</p></div></div><div class="ps l"><div class="qa l pu pv pw ps px kp pj"/></div></div></a></div></div></div>    
</body>
</html>