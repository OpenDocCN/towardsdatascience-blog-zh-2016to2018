<html>
<head>
<title>Image Stitching Using OpenCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 OpenCV 进行图像拼接</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-stitching-using-opencv-817779c86a83?source=collection_archive---------2-----------------------#2018-10-11">https://towardsdatascience.com/image-stitching-using-opencv-817779c86a83?source=collection_archive---------2-----------------------#2018-10-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="d1c6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如你所知，Google photos 应用程序具有令人惊叹的自动功能，如视频制作、全景拼接、拼贴制作、根据照片中人的存在整理照片等等。我一直想知道为什么这些都是可能的。但是有一天，我觉得自己做全景拼接非常酷。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/b5561a6c6e2b8676a5a8268fcb4ed0f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GHulYZ91NWfYNA2cC-QtYA.jpeg"/></div></div></figure><p id="7845" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当我要做一个图像拼接的项目时，我感到非常兴奋。当我终于成功地建立了我自己的图像拼接器时，那是一个灵光一现的时刻:)。我在<strong class="jp ir"><em class="kx">Python</em></strong>——我一直最喜欢的语言和使用<strong class="jp ir"> <em class="kx"> OpenCV 3.1.0 </em> </strong>中做的。</p><p id="50d6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">尽管互联网上有很多这方面的资源，但今天我想和代码<a class="ae ky" href="https://github.com/vagdevik/Computer-Vision/blob/master/Assignment-3/3_image_stitch.py" rel="noopener ugc nofollow" target="_blank">一起展示我的工作。下面的代码和解释都是为了把两张图片拼接在一起。</a></p><p id="24cb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，让我们导入必要的模块。</p><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="0069" class="le lf iq la b gy lg lh l li lj">import cv2<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from random import randrange</span></pre><p id="bbd7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如我们所知，我们正在拼接 2 幅图像，让我们来阅读它们。</p><div class="km kn ko kp gt ab cb"><figure class="lk kq ll lm ln lo lp paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><img src="../Images/7a90392c1bfa84eeed5ef47968bf21e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*XAiD2UEaF-pQmkQZ1V--wg.jpeg"/></div></figure><figure class="lk kq ll lm ln lo lp paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><img src="../Images/4e488f5783cff8c26cb27fdcba3b79bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*VR6nUTu_rwlJJd3DBX22UQ.jpeg"/></div><figcaption class="lq lr gj gh gi ls lt bd b be z dk lu di lv lw">left.jpg and right.jpg</figcaption></figure></div><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="b55d" class="le lf iq la b gy lg lh l li lj">img_ = cv2.imread(‘right.JPG’)<br/>img1 = cv2.cvtColor(img_,cv2.COLOR_BGR2GRAY)</span><span id="9c82" class="le lf iq la b gy lx lh l li lj">img = cv2.imread(‘left.JPG’)<br/>img2 = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)</span></pre><p id="c4c6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae ky" href="https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#cvtcolor" rel="noopener ugc nofollow" target="_blank"> cv2.cvtColor </a>将输入的 RGB 图像转换成灰度形式。</p><p id="2bcb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于图像拼接，我们遵循以下主要步骤:</p><ol class=""><li id="3179" class="ly lz iq jp b jq jr ju jv jy ma kc mb kg mc kk md me mf mg bi translated">计算两幅图像的 sift 关键点和描述符。</li><li id="0ddb" class="ly lz iq jp b jq mh ju mi jy mj kc mk kg ml kk md me mf mg bi translated">计算一幅图像中的每个描述符和另一幅图像中的每个描述符之间的距离。</li><li id="96bd" class="ly lz iq jp b jq mh ju mi jy mj kc mk kg ml kk md me mf mg bi translated">为图像的每个描述符选择前“m”个匹配项。</li><li id="4806" class="ly lz iq jp b jq mh ju mi jy mj kc mk kg ml kk md me mf mg bi translated">运行<a class="ae ky" href="https://www.learnopencv.com/image-alignment-feature-based-using-opencv-c-python/" rel="noopener ugc nofollow" target="_blank"> RANSAC </a>来估计单应性</li><li id="8741" class="ly lz iq jp b jq mh ju mi jy mj kc mk kg ml kk md me mf mg bi translated">缝合时要对齐的经线</li><li id="3515" class="ly lz iq jp b jq mh ju mi jy mj kc mk kg ml kk md me mf mg bi translated">现在把它们缝在一起</li></ol><p id="a09e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">非常感谢…，</p><p id="3501" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我们必须找出两幅图像中匹配的特征。这些最匹配的特征充当缝合的基础。我们提取两幅图像的关键点和 sift 描述符，如下所示:</p><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="d003" class="le lf iq la b gy lg lh l li lj">sift = cv2.xfeatures2d.SIFT_create()<br/># find the keypoints and descriptors with SIFT<br/>kp1, des1 = sift.detectAndCompute(img1,None)<br/>kp2, des2 = sift.detectAndCompute(img2,None)</span></pre><p id="b088" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">kp1 和 kp2 是关键点，des1 和 des2 是相应图像的描述符。</p><p id="397e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，在一幅图像中获得的描述符也将在该图像中被识别。我们的做法如下:</p><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="49d6" class="le lf iq la b gy lg lh l li lj">bf = cv2.BFMatcher()<br/>matches = bf.knnMatch(des1,des2, k=2)</span></pre><p id="dffb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae ky" href="https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_matcher/py_matcher.html" rel="noopener ugc nofollow" target="_blank"> BFMatcher() </a>匹配更相似的特征。当我们设置参数 k=2 时，我们要求 knnMatcher 为每个描述符给出 2 个最佳匹配。</p><p id="bd91" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">“匹配”是一个列表列表，其中每个子列表由“k”个对象组成。为了理解这一点，并更好地跟踪接下来的部分，请通过<a class="ae ky" href="https://docs.opencv.org/3.1.0/dc/dc3/tutorial_py_matcher.html" rel="noopener ugc nofollow" target="_blank">这个</a>。</p><p id="583a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通常在图像中，这些特征很有可能存在于图像的许多地方。这可能会误导我们在实验中使用琐碎的特征。因此，我们从所有匹配中筛选出最佳匹配。因此，我们使用上面获得的前 2 个匹配来应用比率测试。如果下面定义的比率明显大于规定的比率，我们认为匹配。</p><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="c593" class="le lf iq la b gy lg lh l li lj"># Apply ratio test<br/>good = []<br/>for m in matches:<br/>if m[0].distance &lt; 0.5*m[1].distance:<br/>good.append(m)<br/>matches = np.asarray(good)</span></pre><p id="063d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在是对齐图像的时候了。如您所知，执行转换需要单应矩阵，并且单应矩阵需要至少 4 个匹配，我们执行以下操作。点击了解更多<a class="ae ky" href="https://www.learnopencv.com/image-alignment-feature-based-using-opencv-c-python/" rel="noopener ugc nofollow" target="_blank">。</a></p><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="9bff" class="le lf iq la b gy lg lh l li lj">if len(matches[:,0]) &gt;= 4:<br/>src = np.float32([ kp1[m.queryIdx].pt for m in matches[:,0] ]).reshape(-1,1,2)<br/>dst = np.float32([ kp2[m.trainIdx].pt for m in matches[:,0] ]).reshape(-1,1,2)</span><span id="8032" class="le lf iq la b gy lx lh l li lj">H, masked = cv2.findHomography(src, dst, cv2.RANSAC, 5.0)<br/>#print H<br/>else:<br/>raise AssertionError(“Can’t find enough keypoints.”)</span></pre><p id="e3ca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后是最后一部分，图像的拼接。既然我们已经找到了变换的单应性，现在我们可以继续将它们扭曲并缝合在一起:</p><pre class="km kn ko kp gt kz la lb lc aw ld bi"><span id="9deb" class="le lf iq la b gy lg lh l li lj">dst = cv2.warpPerspective(img_,H,(img.shape[1] + img_.shape[1], img.shape[0]))<br/>plt.subplot(122),plt.imshow(dst),plt.title(‘Warped Image’)<br/>plt.show()<br/>plt.figure()<br/>dst[0:img.shape[0], 0:img.shape[1]] = img<br/>cv2.imwrite(‘output.jpg’,dst)<br/>plt.imshow(dst)<br/>plt.show()</span></pre><p id="5410" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们使用 matplotlib 绘制扭曲的图像，以便很好地可视化扭曲。</p><p id="b46e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">结果如下:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mm"><img src="../Images/fa99fd53d2661022eb36fc13b3b3adf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n8bBqnQMlc7mzRIdkinh2g.jpeg"/></div></div></figure></div></div>    
</body>
</html>