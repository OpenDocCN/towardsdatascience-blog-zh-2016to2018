<html>
<head>
<title>Vehicle Detection and Tracking</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">车辆检测和跟踪</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/vehicle-detection-and-tracking-6665d6e1089b?source=collection_archive---------0-----------------------#2017-02-24">https://towardsdatascience.com/vehicle-detection-and-tracking-6665d6e1089b?source=collection_archive---------0-----------------------#2017-02-24</a></blockquote><div><div class="fc if ig ih ii ij"/><div class="ik il im in io"><div class=""/><p id="c9cb" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">在这个车辆检测和跟踪项目中，我们通过滑动窗口在视频管道中检测可能包含车辆的潜在盒子，使用支持向量机分类器进行预测以创建热图。然后，热图历史被用于在识别车辆之前过滤掉误报，方法是在它周围画一个边界框。</p><figure class="kn ko kp kq gu kr gi gj paragraph-image"><div class="gi gj km"><img src="../Images/3cbfa4cd555dff6feb4f7fca9a94b5b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*D00EZ6px0y-ss4dd.png"/></div><figcaption class="ku kv gk gi gj kw kx bd b be z dk">Vehicle Detection Sample</figcaption></figure><p id="a11e" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated"><strong class="jq is">车辆检测项目</strong></p><p id="8e48" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">该项目的目标/步骤如下:</p><ul class=""><li id="ff43" class="ky kz ir jq b jr js jv jw jz la kd lb kh lc kl ld le lf lg bi translated">对图像的标记训练集执行定向梯度直方图(HOG)特征提取，并训练分类器线性SVM分类器</li><li id="27ee" class="ky kz ir jq b jr lh jv li jz lj kd lk kh ll kl ld le lf lg bi translated">或者，您还可以应用颜色变换，并将入库的颜色特征以及颜色直方图添加到HOG特征向量中。</li><li id="827e" class="ky kz ir jq b jr lh jv li jz lj kd lk kh ll kl ld le lf lg bi translated">注意:对于前两步，不要忘记规格化你的特征和随机选择用于训练和测试。</li><li id="9120" class="ky kz ir jq b jr lh jv li jz lj kd lk kh ll kl ld le lf lg bi translated">实施滑动窗口技术，并使用您训练的分类器在图像中搜索车辆。</li><li id="3fa7" class="ky kz ir jq b jr lh jv li jz lj kd lk kh ll kl ld le lf lg bi translated">在视频流上运行管道(从test_video.mp4开始，然后在完整的project_video.mp4上实施),并逐帧创建重复检测的热图，以剔除异常值并跟踪检测到的车辆。</li><li id="e541" class="ky kz ir jq b jr lh jv li jz lj kd lk kh ll kl ld le lf lg bi translated">估计检测到的车辆的边界框。</li></ul><p id="5970" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">使用了jupyter/iPython数据科学笔记本，可在github <a class="ae lm" href="https://github.com/hortovanyi/udacity-vehicle-detection-project" rel="noopener ugc nofollow" target="_blank">完整项目报告</a> — <a class="ae lm" href="https://github.com/hortovanyi/udacity-vehicle-detection-project/blob/master/Vehicle%20Detection%20Project.ipynb" rel="noopener ugc nofollow" target="_blank">车辆检测项目笔记本</a>上找到(注意交互式ipywidgets在github上不起作用)。由于笔记本变得相当大，我将一些代码提取到python文件utils.py(提取函数，加载助手)，features.py(特征提取和类)，images.py(图像和窗口切片处理)，search.py(保存搜索参数类)，boxes.py(窗口和框类)和detection.py(协调图像处理的主车辆检测类)。该项目是用python编写的，使用了<a class="ae lm" href="http://www.numpy.org/" rel="noopener ugc nofollow" target="_blank"> numpy </a>、<a class="ae lm" href="http://opencv.org/" rel="noopener ugc nofollow" target="_blank"> OpenCV </a>、<a class="ae lm" href="http://scikit-learn.org/" rel="noopener ugc nofollow" target="_blank"> scikit learn </a>和<a class="ae lm" href="http://zulko.github.io/moviepy/" rel="noopener ugc nofollow" target="_blank"> MoviePy </a>。</p><h2 id="4d32" class="ln lo ir bd lp lq lr dn ls lt lu dp lv jz lw lx ly kd lz ma mb kh mc md me mf bi translated">方向梯度直方图(HOG)</h2><p id="f016" class="pw-post-body-paragraph jo jp ir jq b jr mg jt ju jv mh jx jy jz mi kb kc kd mj kf kg kh mk kj kk kl ik bi translated">通过一点试错，我找到了一组<a class="ae lm" href="https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients" rel="noopener ugc nofollow" target="_blank">猪</a>参数。</p><h2 id="891e" class="ln lo ir bd lp lq lr dn ls lt lu dp lv jz lw lx ly kd lz ma mb kh mc md me mf bi translated">HOG特征提取和参数</h2><p id="60f1" class="pw-post-body-paragraph jo jp ir jq b jr mg jt ju jv mh jx jy jz mi kb kc kd mj kf kg kh mk kj kk kl ik bi translated">创建了一个函数<a class="ae lm" href="https://github.com/hortovanyi/udacity-vehicle-detection-project/blob/master/utils.py#L151" rel="noopener ugc nofollow" target="_blank"> extract_hog_features </a>,它采用64x64x3的图像数组并返回一组特征。这些是并行提取的，它依次使用<a class="ae lm" href="https://github.com/hortovanyi/udacity-vehicle-detection-project/blob/master/features.py#L49" rel="noopener ugc nofollow" target="_blank"> HogImageFeatures </a>类。</p><p id="b347" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">由于hog算法主要集中在灰度图像上，我最初使用Y通道的YCrCB颜色空间(用于表示灰度图像)。然而，我发现它在检测阶段的选择性不够。因此，我使用了所有3个颜色通道。为了减少特征的数量，我增加了每个单元格的HOG像素的数量。我在我的笔记本中使用了一个交互功能，找到了一个32的方向设置，它显示了车辆的独特特征。样本如下。</p><figure class="kn ko kp kq gu kr gi gj paragraph-image"><div class="gi gj ml"><img src="../Images/83d71ea49d901115b650b894a2772748.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/0*Es9_QpaN8QQN7IGZ."/></div><figcaption class="ku kv gk gi gj kw kx bd b be z dk">Training Vehicle HOG Sample</figcaption></figure><p id="28a9" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">最终的参数设置使用了<code class="fe mm mn mo mp b">color_space = 'YCrCb'</code>、<code class="fe mm mn mo mp b">orient = 32</code>、<code class="fe mm mn mo mp b">pix_per_cell = 16</code>和<code class="fe mm mn mo mp b">hog_channel = 'ALL'</code>。使用颜色直方图特征进行了实验，但是它减慢了特征提取，并且后来增加了检测到的假阳性的数量。根据下面的可视化图形，您可以看到Cr和Cb色彩空间具有可检测的hog特征</p><figure class="kn ko kp kq gu kr gi gj paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gi gj mq"><img src="../Images/fff5a5b3dddf9051206012d7dec859bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xVIdVRDLZi75DWJG."/></div></div><figcaption class="ku kv gk gi gj kw kx bd b be z dk">Sample HOG Channel Output form a video window slice</figcaption></figure><h2 id="6a31" class="ln lo ir bd lp lq lr dn ls lt lu dp lv jz lw lx ly kd lz ma mb kh mc md me mf bi translated">分类器训练</h2><p id="2e67" class="pw-post-body-paragraph jo jp ir jq b jr mg jt ju jv mh jx jy jz mi kb kc kd mj kf kg kh mk kj kk kl ik bi translated">一旦从car ( <a class="ae lm" href="http://www.gti.ssr.upm.es/data/Vehicle_database.html" rel="noopener ugc nofollow" target="_blank"> GTI车辆图像数据库</a>和Udacity Extras)和not _ car(<a class="ae lm" href="http://www.cvlibs.net/datasets/kitti/" rel="noopener ugc nofollow" target="_blank">GTI</a>)图像集中提取出HOG特征(无彩色Hist或Bin空间)。然后，它们被堆叠并转换为浮动在车辆检测笔记本中。</p><p id="377a" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">然后使用Sklearn鲁棒定标器对特征进行定标，结果如下。</p><figure class="kn ko kp kq gu kr gi gj paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gi gj mv"><img src="../Images/e4cac37696f2e138da416ac463adc7fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wlO7XrutoqBLk7qA."/></div></div></figure><p id="fe9d" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">实验发生在<a class="ae lm" href="https://github.com/hortovanyi/udacity-vehicle-detection-project/blob/master/Classifier%20Experimentation.ipynb" rel="noopener ugc nofollow" target="_blank">分类器实验笔记本</a>中的LinearSVC ( <a class="ae lm" href="http://scikit-learn.org/stable/modules/svm.html" rel="noopener ugc nofollow" target="_blank">支持向量机分类器</a>)、RandomForest和ExtraTrees分类器之间。选择LinearSVC是因为10个标签的预测时间为0.00228秒，而其他两个标签的预测时间约为0.10秒。</p><h2 id="e052" class="ln lo ir bd lp lq lr dn ls lt lu dp lv jz lw lx ly kd lz ma mb kh mc md me mf bi translated">滑动窗口搜索</h2><h2 id="5bb6" class="ln lo ir bd lp lq lr dn ls lt lu dp lv jz lw lx ly kd lz ma mb kh mc md me mf bi translated">构建推拉窗</h2><p id="69ec" class="pw-post-body-paragraph jo jp ir jq b jr mg jt ju jv mh jx jy jz mi kb kc kd mj kf kg kh mk kj kk kl ik bi translated">在这个项目中，选择了四种尺寸的窗户——32x 32、48x48、64x64和128x128，并以不同的深度透视放置在图像的右下方，以覆盖道路。较大的窗户靠近驾驶员，较小的窗户靠近地平线。x，y的重叠设置在0.5和0.8之间，以平衡更好的覆盖需求和生成的盒子数量——目前为937个。滑动窗口的方框越多，每个视频图像的计算就越多。</p><figure class="kn ko kp kq gu kr gi gj paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gi gj mw"><img src="../Images/63e929170a21f3958e7926cfbbd3965f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0LyMJaRQXV0rQDvG."/></div></div></figure><h2 id="15ea" class="ln lo ir bd lp lq lr dn ls lt lu dp lv jz lw lx ly kd lz ma mb kh mc md me mf bi translated">分类器示例和优化</h2><p id="5d41" class="pw-post-body-paragraph jo jp ir jq b jr mg jt ju jv mh jx jy jz mi kb kc kd mj kf kg kh mk kj kk kl ik bi translated">使用Python异步方法和VehicleDetection类中的asyncio.gather在搜索的并行化上花费了一些时间。在对每个窗口进行特征提取和预测之前，该搜索提取每个大小的搜索窗口的有界框图像并将其缩放到64×64。</p><figure class="kn ko kp kq gu kr gi gj paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gi gj mx"><img src="../Images/42a652882908c2c4b01eafac01a6f822.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ksx_3BhBp24st9JO."/></div></div></figure><p id="1fa9" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">搜索<code class="fe mm mn mo mp b">hot_box_search</code>返回分类器预测包含车辆的热盒阵列。</p><p id="fa4d" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">这些方框重叠在一起，用于创建一个255的二维热点图。为了消除初始误报，保持计数&gt; 4。在应用另一个阈值之前，热图被标准化</p><pre class="kn ko kp kq gu my mp mz na aw nb bi"><span id="ea39" class="ln lo ir mp b gz nc nd l ne nf">heatmap = apply_threshold(heatmap, 4)<br/>heatmap_std = heatmap.std(ddof=1)<br/>if heatmap_std != 0.0:<br/>    heatmap = (heatmap-heatmap.mean())/heatmap_std<br/>heatmap = apply_threshold(heatmap, np.max([heatmap.std(), 1]))</span></pre><p id="7f5a" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">将这个阶段重新绘制到图像上</p><figure class="kn ko kp kq gu kr gi gj paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gi gj mw"><img src="../Images/65e2f5415c96107854a946ebf28179a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*D5jeEuI82DODFSM0."/></div></div></figure><p id="dd11" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">热图有一个历史记录</p><figure class="kn ko kp kq gu kr gi gj paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gi gj ng"><img src="../Images/7b99b444addcbfc4e3764e4c27cdc34d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0iADTsWNc-eAk__q."/></div></div></figure><p id="ba7b" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">然后作为输入输入到<a class="ae lm" href="https://docs.scipy.org/doc/scipy-0.13.0/reference/generated/scipy.ndimage.measurements.label.html" rel="noopener ugc nofollow" target="_blank"> Scipy标签</a>中，该标签具有链接维度的模糊二进制结构，给出</p><figure class="kn ko kp kq gu kr gi gj paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gi gj nh"><img src="../Images/529e5bd2cdbbe7795f9de5f3ec66f145.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ouer4L9iYvwXd4_u."/></div></div></figure><p id="742d" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">最后，在每个框上应用方差过滤器，如果对于一个检测到的标签框，方差&lt; 0.1 (its just a few close points0 or if multiple with a variance &lt; 1.5 (more noise).</p><h2 id="7e68" class="ln lo ir bd lp lq lr dn ls lt lu dp lv jz lw lx ly kd lz ma mb kh mc md me mf bi translated">Video Implementation</h2><h2 id="e0a5" class="ln lo ir bd lp lq lr dn ls lt lu dp lv jz lw lx ly kd lz ma mb kh mc md me mf bi translated">Vehicle Detection Video</h2><p id="0e1b" class="pw-post-body-paragraph jo jp ir jq b jr mg jt ju jv mh jx jy jz mi kb kc kd mj kf kg kh mk kj kk kl ik bi translated">The <a class="ae lm" href="https://github.com/hortovanyi/udacity-vehicle-detection-project/blob/master/project_video_detection.mp4?raw=true" rel="noopener ugc nofollow" target="_blank">忽略GitHub </a>上的项目VehicleDetection mp4，包含结果(<a class="ae lm" href="https://www.youtube.com/watch?v=xO0UJk0V7xk" rel="noopener ugc nofollow" target="_blank"> YouTube Copy </a>)</p><figure class="kn ko kp kq gu kr gi gj paragraph-image"><div class="gi gj ni"><img src="../Images/6d0ec981fd687f651ca14fcdd029d678.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/0*vbpN0KdVPlksaaeU.jpg"/></div></figure><h2 id="7b4d" class="ln lo ir bd lp lq lr dn ls lt lu dp lv jz lw lx ly kd lz ma mb kh mc md me mf bi translated">跟踪车辆检测</h2><p id="25f7" class="pw-post-body-paragraph jo jp ir jq b jr mg jt ju jv mh jx jy jz mi kb kc kd mj kf kg kh mk kj kk kl ik bi translated"><a class="ae lm" href="https://docs.scipy.org/doc/scipy-0.13.0/reference/generated/scipy.ndimage.measurements.label.html" rel="noopener ugc nofollow" target="_blank">scipy . ndimage . measurements . label</a>函数的一个很好的特性是，它可以处理3d数组，给出x，y，z空间中的标签。因此，当使用热图历史的数组作为输入时，它在x、y、z中标记连接。如果返回的标记框没有在至少3个(热图历史最大值-2)z平面中表示，则它被拒绝为假阳性。结果是，车辆在保存的热图历史中被跟踪。</p><h2 id="fc0d" class="ln lo ir bd lp lq lr dn ls lt lu dp lv jz lw lx ly kd lz ma mb kh mc md me mf bi translated">讨论</h2><p id="2c76" class="pw-post-body-paragraph jo jp ir jq b jr mg jt ju jv mh jx jy jz mi kb kc kd mj kf kg kh mk kj kk kl ik bi translated">当构建这个管道的时候，我花了一些时间来并行化窗口搜索。我发现这样做很可能不会提高整体性能。图像必须连续处理，在生成视频时，我的cpu没有得到充分利用。</p><p id="5d9e" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">事后看来，我应该用一个大范围的搜索来探测车辆，然后用一个更小范围的搜索来探测最后已知的位置。可以以更大的间隔或者当车辆检测丢失时运行大重量搜索。</p><p id="7a1f" class="pw-post-body-paragraph jo jp ir jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl ik bi translated">如果车辆在汽车的左侧或中间，我的管道将立即失效。我怀疑卡车、摩托车、骑自行车的人和行人不会被检测到(因为他们不在训练数据中)。</p></div></div>    
</body>
</html>