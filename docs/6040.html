<html>
<head>
<title>[ Paper Summary ] Matrix Factorization Techniques for Recommender Systems</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">推荐系统的矩阵分解技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/paper-summary-matrix-factorization-techniques-for-recommender-systems-82d1a7ace74?source=collection_archive---------7-----------------------#2018-11-22">https://towardsdatascience.com/paper-summary-matrix-factorization-techniques-for-recommender-systems-82d1a7ace74?source=collection_archive---------7-----------------------#2018-11-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/019c4b1115169ea1989abd5f62e06953.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JjaMwJJzTsQzJzV70KbV3Q.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo by <a class="ae kc" href="https://unsplash.com/photos/TTPMpLl_2lc?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Andrew Neel</a> on <a class="ae kc" href="https://unsplash.com/search/photos/recommend?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="7c52" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">T3】</strong></p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><figure class="lj lk ll lm gt jr"><div class="bz fp l di"><div class="ln lo l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Paper from this <a class="ae kc" href="https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="ac28" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">摘要</strong></p><p id="f734" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些天来，我们不断被各种来源推荐，比如读什么博客，听什么音乐等等…..这些推荐系统变得比以往更加个性化。本文作者利用矩阵分解技术建立了一个复杂的推荐系统，其性能优于最近邻技术。(在电影推荐系统的设置中)。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="37da" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">推荐系统策略</strong></p><p id="18a0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">内容过滤</strong> →为每个用户或产品创建一个档案，以描述其性质(成功案例:<a class="ae kc" href="https://en.wikipedia.org/wiki/Music_Genome_Project" rel="noopener ugc nofollow" target="_blank">音乐基因组项目</a>)</p><p id="d337" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">协作过滤</strong> →分析用户之间的关系和产品之间的相互依赖关系，以识别新的用户-项目关联(成功案例:Tapestry)</p><p id="0115" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">协同过滤通常比内容过滤更准确，但是它存在冷启动问题。(如果新用户存在，且与其他用户之间没有任何相互依赖关系，我们无法推荐任何内容)。通常有两种方法来实现协同过滤。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/f1b1c87a387dad54945e136fe9c9b356.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*gZTEZSbuI5U2pjovr2KFNQ.png"/></div></figure><p id="adfd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">邻近方法</strong> →计算项目之间的关系，或者用户之间的关系(用户群)</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/a1c9e367131901044119bd809f11f3f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AQEx38Wdo5H0WTSjRfAWtA.png"/></div></div></figure><p id="7604" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">潜在因素</strong> →创建一个潜在特征，将一个用户与另一个用户进行比较(特征库)</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="8b63" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">矩阵分解方法</strong></p><p id="c5e0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当用户对他们看过的某部电影进行反馈时(比如他们可以从一到五打分)，这些反馈可以用矩阵的形式来表示。其中每行代表每个用户，而每列代表不同的电影。显然，矩阵将是稀疏的，因为不是每个人都会看每部电影，(当谈到电影时，我们都有不同的品味)。</p><p id="a92b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">矩阵分解的一个优点是它可以包含隐含的反馈信息，这些信息不是直接给出的，而是可以通过分析用户行为得到的。使用这个强度，我们可以估计用户是否会喜欢一部(他/她)从未看过的电影。如果估计的收视率很高，我们可以向用户推荐这部电影。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div class="ab gu cl lr"><img src="../Images/65c3b3b85b4f9b0a29628c2c4760c04d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Zhm1NMlmVywn0G18w3exog.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Image from this <a class="ae kc" href="https://medium.com/@connectwithghosh/simple-matrix-factorization-example-on-the-movielens-dataset-using-pyspark-9b7e3f567536" rel="noopener">website</a></figcaption></figure><p id="8c57" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上图很好地总结了矩阵分解背后的核心思想。设矩阵 A 的维数为(m，n ),这个矩阵可以看作两个矩阵之间的点积，每个矩阵的维数分别为(m，k)和(k，n)。</p><blockquote class="ls lt lu"><p id="7a01" class="kd ke lb kf b kg kh ki kj kk kl km kn lv kp kq kr lw kt ku kv lx kx ky kz la ij bi translated">顺便说一下，上述概念与奇异值分解(SVD)密切相关。SVD 的一个缺点是，当原始矩阵稀疏(不完整)时，左右奇异向量是未定义的。</p></blockquote><p id="cae4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">矩阵分解的概念可以用数学方法写成如下形式。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/4317c211a584f6b6314b8d327fc332c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:316/format:webp/1*M8di8wLkZcqXEDtDKmC2UA.png"/></div></figure><p id="bbf8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后我们可以创建一个关于 q 和 p 的目标函数(我们希望最小化)，这是(m，k)和(k，n)矩阵。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/94a8202f989c5b1a47b80c6bd833fcdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*iBV8FoBkUbSdDL0FZwZQiA.png"/></div></figure><p id="cc1c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">右边的项是正则项，这是添加的，因为我们不希望我们的分解矩阵 q 和 p 过拟合原始矩阵。因为我们的目标是以一种预测未来未知评级的方式来概括以前的评级，所以我们不应该过度拟合我们的模型。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="cea2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">学习方法</strong></p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/2089844d342843870b0569846d1fd28a.png" data-original-src="https://miro.medium.com/v2/resize:fit:464/format:webp/1*nFhAEnnrfojjjysOAgrwLA.png"/></div></figure><p id="ed08" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">求矩阵 q 和 p 的一个明显的方法是梯度下降法。因为我们已经定义了损失函数，所以对 q 和 p 取偏导数来优化这些值。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/aa5562633b60fed69d427bd5f1dee498.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*MdWVINJBDAOofbgQcyRbCw.png"/></div></figure><p id="51fa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过偏导数，更新规则看起来会像上面这样。但是误差表面不是凸的，我们也可以采用另一种方法，其中我们交替地固定 q 和 p，同时优化另一个。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="4cc0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">添加偏置</strong></p><p id="3898" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一些电影有偏见，因为它被广泛认为比其他电影更好(或更差)，一些用户有偏见，因为他们超级咸，从不给电影评分超过 2 分。这些被称为偏差或截距，它们独立于任何相互作用，使用我们的两个分解矩阵 q 和 p 来解释这些偏差项是不明智的，因此我们将偏差项包含在原始方程中。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/adc5b92278073e0643700974524347b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*WWO2sCXvTdQpAtLEJ5h9Zg.png"/></div></figure><p id="1d83" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">新的目标函数如下所示。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div class="gh gi md"><img src="../Images/329bc09f50143b381233a3dd502c3a35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*l1oezj1Ze8JbBZttYYVHmA.png"/></div></figure><p id="ce50" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就像我们如何在原始函数中添加额外的偏置项一样，我们可以添加额外的项来解决冷启动问题。以及结合用户和项目的时间动态。(甚至自信分数)</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div class="gh gi me"><img src="../Images/d88bff07a8cce549698c5391a269ae01.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*TmkPjcCBhP_fYN6PWXWBeA.png"/></div></figure></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="4e7c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">遗言</strong></p><p id="0fcf" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我认为我们可以使用矩阵分解来构建推荐系统是非常酷的。</p></div><div class="ab cl lc ld hu le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ij ik il im in"><p id="e99f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">参考</strong></p><ol class=""><li id="8a19" class="mf mg iq kf b kg kh kk kl ko mh ks mi kw mj la mk ml mm mn bi translated">(2018).Datajobs.com。检索于 2018 年 11 月 22 日，来自<a class="ae kc" href="https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf" rel="noopener ugc nofollow" target="_blank">https://data jobs . com/data-science-repo/Recommender-Systems-[网飞]。pdf </a></li><li id="eb65" class="mf mg iq kf b kg mo kk mp ko mq ks mr kw ms la mk ml mm mn bi translated">音乐基因组计划。(2018).En.wikipedia.org。检索于 2018 年 11 月 22 日，来自<a class="ae kc" href="https://en.wikipedia.org/wiki/Music_Genome_Project" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Music_Genome_Project</a></li><li id="ef06" class="mf mg iq kf b kg mo kk mp ko mq ks mr kw ms la mk ml mm mn bi translated">使用 Pyspark 对 Movielens 数据集进行简单的矩阵分解示例。(2018).中等。检索于 2018 年 11 月 22 日，来自<a class="ae kc" href="https://medium.com/@connectwithghosh/simple-matrix-factorization-example-on-the-movielens-dataset-using-pyspark-9b7e3f567536" rel="noopener">https://medium . com/@ connectwithgosh/simple-matrix-factorization-example-on-the-movie lens-dataset-using-py spark-9b 7 E3 f 567536</a></li></ol></div></div>    
</body>
</html>