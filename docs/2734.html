<html>
<head>
<title>Components of convolutional neural networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络的组件</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/components-of-convolutional-neural-networks-6ff66296b456?source=collection_archive---------11-----------------------#2018-02-26">https://towardsdatascience.com/components-of-convolutional-neural-networks-6ff66296b456?source=collection_archive---------11-----------------------#2018-02-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/9be7f1c83a15740f1785efb867ca65b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tV_6-fK-G3wDs2DrybRgpw.jpeg"/></div></div></figure><p id="bc1a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最近最先进的体系结构采用了许多附加组件来补充卷积运算。在这篇文章中，我将解释一些提高了现代卷积神经网络的速度和精度的最重要的组件。我将从解释每个组件的理论开始，并以keras中的实际实现结束。</p><h1 id="1408" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">联营</h1><p id="3233" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">让CNN非常有效的第一个秘方是联营。池化是一种向量到标量的变换，它对图像的每个局部区域进行操作，就像卷积一样，但是，与卷积不同，它们没有过滤器，也不计算局部区域的点积，而是计算区域中像素的平均值(平均池化)或简单地挑选具有最高强度的像素并丢弃其余的像素(最大池化)。</p><p id="0d08" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">以上是一个2 x 2的池，它将有效地减少了2的要素地图的大小。</p><p id="da8a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">汇集的想法看起来可能是反作用的，因为它会导致信息的丢失，然而它在实践中被证明是非常有效的，因为它使得covnets对于图像呈现的变化是不变的，并且它还减少了背景噪声的影响。最大池近年来工作得最好，它基于一个区域中的最大像素代表该区域中最重要的特征的思想。通常，我们希望分类的对象图像可能包含许多其他对象，例如，出现在汽车图片中某处的猫可能会误导分类器。池有助于减轻这种影响，并使covnets更好地泛化。</p><p id="9025" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">它还大大降低了covnet的计算成本。通常，网络中每层的图像大小与每层的计算成本(flops)成正比。随着层越来越深，池化减少了图像的维度，因此，它有助于防止网络所需的flops数量激增。交错卷积有时被用作池化的替代方法。</p><h1 id="67cf" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">辍学者</h1><p id="4383" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">过度拟合是一种网络在训练集上工作良好，但在测试集上表现不佳的现象。这通常是由于过度依赖训练集中特定特征的存在。辍学是一种应对过度适应的技术。它的工作原理是随机设置一些激活为0，本质上杀死他们。通过这样做，网络被迫探索更多分类图像的方法，而不是过度依赖某些特征。这是AlexNet的关键要素之一。</p><h1 id="fda4" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">批量标准化</h1><p id="d736" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">神经网络的一个主要问题是梯度消失。这是一种梯度变得太小的情况，因此，训练冲浪运动员非常糟糕。来自Google Brain的Ioffe和Szegedy发现，这主要是由于内部协变量的变化，这种情况是由于信息在网络中流动时数据分布的变化而引起的。他们所做的是发明一种被称为批量标准化的技术。其工作原理是将每批图像归一化，使平均值和单位方差为零。</p><p id="0f9c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在CNN中，它通常位于非线性(relu)之前。它极大地提高了准确性，同时令人难以置信地加快了训练过程。</p><h1 id="d3f7" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">数据扩充</h1><p id="efe9" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">现代covnets需要的最后一个要素是数据扩充。人类视觉系统在适应图像平移、旋转和其他形式的失真方面表现出色。拍个图像随便翻一翻反正大部分人还是能认出来的。然而，covnets并不擅长处理这种扭曲，它们可能会因为微小的翻译而严重失败。解决这个问题的关键是随机扭曲训练图像，使用水平翻转、垂直翻转、旋转、白化、移位和其他扭曲。这将使covnets能够学习如何处理这种失真，因此，它们将能够在现实世界中很好地工作。</p><p id="4873" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">另一种常见的技术是从每幅图像中减去平均图像，然后除以标准偏差。</p><p id="2e83" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">解释了这些组件是什么以及它们为什么工作良好之后，我现在将解释如何在keras中实现它们。</p><p id="f845" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在本文中，所有实验都将在CIFAR10上进行，这是一个由60，000张32 x 32 RGB图像组成的数据集。它被分成50，000幅训练图像和10，000幅测试图像</p><p id="5c6e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了使事情更加模块化，让我们为每一层创建一个简单的函数</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="663a" class="mi kx iq me b gy mj mk l ml mm"><strong class="me ir">def </strong>Unit(x,filters):<br/>    out = BatchNormalization()(x)<br/>    out = Activation(<strong class="me ir">"relu"</strong>)(out)<br/>    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=<strong class="me ir">"same"</strong>)(out)<br/><br/>    <strong class="me ir">return </strong>out</span></pre><p id="6f9c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是我们代码中最重要的部分，单位函数定义了一个简单的层，包含三层，首先是我之前解释过的批处理规范化，然后我们添加了RELU激活，最后，我们添加了卷积，注意我是如何将RELU放在conv之前的，这是最近的一个实践，叫做“预激活”</p><p id="711e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们将这个单元层合并成一个单一的模型</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="02a3" class="mi kx iq me b gy mj mk l ml mm"><strong class="me ir">def </strong>MiniModel(input_shape):<br/>    images = Input(input_shape)<br/><br/><br/>    net = Unit(images,64)<br/>    net = Unit(net,64)<br/>    net = Unit(net,64)<br/>    net = MaxPooling2D(pool_size=(2,2))(net)<br/><br/>    net = Unit(net,128)<br/>    net = Unit(net,128)<br/>    net = Unit(net,128)<br/>    net = MaxPooling2D(pool_size=(2, 2))(net)<br/><br/>    net = Unit(net,256)<br/>    net = Unit(net,256)<br/>    net = Unit(net,256)<br/><br/>    net = Dropout(0.5)(net)<br/>    net = AveragePooling2D(pool_size=(8,8))(net)<br/>    net = Flatten()(net)<br/>    net = Dense(units=10,activation=<strong class="me ir">"softmax"</strong>)(net)<br/><br/>    model = Model(inputs=images,outputs=net)<br/><br/>    <strong class="me ir">return </strong>model</span></pre><p id="a98e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这里，我们使用函数式API来定义我们的模型，我们从三个单元开始，每个单元有64个过滤器，然后是最大池层，将我们的32 x 32图像减少到16 x 16。接下来是3，128个过滤器单元，然后是池，在这一点上，我们的图像变成8×8，最后，我们有另外3个单元，256个通道。请注意，每次我们将图像尺寸缩小2倍，通道数量就会增加一倍。</p><p id="50f3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们以0.5的比率添加辍学，这将随机地停用我们的参数的50%，正如我先前解释的，它对抗过度拟合。</p><p id="64b0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，我们需要加载cifar10数据集并执行一些数据扩充</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="47fd" class="mi kx iq me b gy mj mk l ml mm"><em class="mn">#load the cifar10 dataset<br/></em>(train_x, train_y) , (test_x, test_y) = cifar10.load_data()<br/><br/><em class="mn">#normalize the data<br/></em>train_x = train_x.astype(<strong class="me ir">'float32'</strong>) / 255<br/>test_x = test_x.astype(<strong class="me ir">'float32'</strong>) / 255<br/><br/><em class="mn">#Subtract the mean image from both train and test set<br/></em>train_x = train_x - train_x.mean()<br/>test_x = test_x - test_x.mean()<br/><br/><em class="mn">#Divide by the standard deviation<br/></em>train_x = train_x / train_x.std(axis=0)<br/>test_x = test_x / test_x.std(axis=0)</span></pre><p id="ba29" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在上面的代码中，在加载训练和测试数据后，我们从每个图像中减去均值图像，然后除以标准差，这是一种基本的数据扩充技术，有时，我们可能只减去均值，而跳过标准差部分，应该使用效果最好的部分。</p><p id="f2ab" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于更先进的数据增强，我们的图像加载过程会略有变化，keras有一个非常有用的数据增强工具，简化了整个过程。</p><p id="dd68" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下面的代码可以解决这个问题</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="3d4c" class="mi kx iq me b gy mj mk l ml mm">datagen = ImageDataGenerator(rotation_range=10,<br/>                             width_shift_range=5. / 32,<br/>                             height_shift_range=5. / 32,<br/>                             horizontal_flip=<strong class="me ir">True</strong>)<br/><br/><em class="mn"># Compute quantities required for featurewise normalization<br/># (std, mean, and principal components if ZCA whitening is applied).<br/></em>datagen.fit(train_x)</span></pre><p id="35ad" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在上面，首先，我们指定10度的旋转角度，高度和宽度都移动5/32，最后水平翻转，所有这些变换将随机应用于训练集中的图像。请注意，还存在更多的转换，您可以查看一下可以为该类指定的所有参数。请记住，过度使用数据增强可能是有害的。</p><p id="0d69" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，我们必须将标签转换为一键编码</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="7608" class="mi kx iq me b gy mj mk l ml mm"><em class="mn">#Encode the labels to vectors<br/></em>train_y = keras.utils.to_categorical(train_y,10)<br/>test_y = keras.utils.to_categorical(test_y,10)</span></pre><p id="e2b7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我已经在之前的教程中解释过了，所以我不会再在这里解释了。事实上，几乎所有组成训练过程的东西都和我以前的教程一样，因此，这里是完整的代码</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="bd8b" class="mi kx iq me b gy mj mk l ml mm"><em class="mn">#import needed classes<br/></em><strong class="me ir">import </strong>keras<br/><strong class="me ir">from </strong>keras.datasets <strong class="me ir">import </strong>cifar10<br/><strong class="me ir">from </strong>keras.layers <strong class="me ir">import </strong>Dense,Conv2D,MaxPooling2D,Flatten,AveragePooling2D,Dropout,BatchNormalization,Activation<br/><strong class="me ir">from </strong>keras.models <strong class="me ir">import </strong>Model,Input<br/><strong class="me ir">from </strong>keras.optimizers <strong class="me ir">import </strong>Adam<br/><strong class="me ir">from </strong>keras.callbacks <strong class="me ir">import </strong>LearningRateScheduler<br/><strong class="me ir">from </strong>keras.callbacks <strong class="me ir">import </strong>ModelCheckpoint<br/><strong class="me ir">from </strong>math <strong class="me ir">import </strong>ceil<br/><strong class="me ir">import </strong>os<br/><strong class="me ir">from </strong>keras.preprocessing.image <strong class="me ir">import </strong>ImageDataGenerator<br/><br/><br/><strong class="me ir">def </strong>Unit(x,filters):<br/>    out = BatchNormalization()(x)<br/>    out = Activation(<strong class="me ir">"relu"</strong>)(out)<br/>    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=<strong class="me ir">"same"</strong>)(out)<br/><br/>    <strong class="me ir">return </strong>out<br/><br/><em class="mn">#Define the model<br/><br/><br/></em><strong class="me ir">def </strong>MiniModel(input_shape):<br/>    images = Input(input_shape)<br/><br/>    net = Unit(images,64)<br/>    net = Unit(net,64)<br/>    net = Unit(net,64)<br/>    net = MaxPooling2D(pool_size=(2,2))(net)<br/><br/>    net = Unit(net,128)<br/>    net = Unit(net,128)<br/>    net = Unit(net,128)<br/>    net = MaxPooling2D(pool_size=(2, 2))(net)<br/><br/>    net = Unit(net,256)<br/>    net = Unit(net,256)<br/>    net = Unit(net,256)<br/><br/>    net = Dropout(0.25)(net)<br/>    net = AveragePooling2D(pool_size=(8,8))(net)<br/>    net = Flatten()(net)<br/>    net = Dense(units=10,activation=<strong class="me ir">"softmax"</strong>)(net)<br/><br/>    model = Model(inputs=images,outputs=net)<br/><br/>    <strong class="me ir">return </strong>model<br/><br/><em class="mn">#load the cifar10 dataset<br/></em>(train_x, train_y) , (test_x, test_y) = cifar10.load_data()<br/><br/><em class="mn">#normalize the data<br/></em>train_x = train_x.astype(<strong class="me ir">'float32'</strong>) / 255<br/>test_x = test_x.astype(<strong class="me ir">'float32'</strong>) / 255<br/><br/><em class="mn">#Subtract the mean image from both train and test set<br/></em>train_x = train_x - train_x.mean()<br/>test_x = test_x - test_x.mean()<br/><br/><em class="mn">#Divide by the standard deviation<br/></em>train_x = train_x / train_x.std(axis=0)<br/>test_x = test_x / test_x.std(axis=0)<br/><br/><br/>datagen = ImageDataGenerator(rotation_range=10,<br/>                             width_shift_range=5. / 32,<br/>                             height_shift_range=5. / 32,<br/>                             horizontal_flip=<strong class="me ir">True</strong>)<br/><br/><em class="mn"># Compute quantities required for featurewise normalization<br/># (std, mean, and principal components if ZCA whitening is applied).<br/></em>datagen.fit(train_x)<br/><br/><br/><br/><em class="mn">#Encode the labels to vectors<br/></em>train_y = keras.utils.to_categorical(train_y,10)<br/>test_y = keras.utils.to_categorical(test_y,10)<br/><br/><em class="mn">#define a common unit<br/><br/><br/></em>input_shape = (32,32,3)<br/>model = MiniModel(input_shape)<br/><br/><em class="mn">#Print a Summary of the model<br/><br/></em>model.summary()<br/><em class="mn">#Specify the training components<br/></em>model.compile(optimizer=Adam(0.001),loss=<strong class="me ir">"categorical_crossentropy"</strong>,metrics=[<strong class="me ir">"accuracy"</strong>])<br/><br/><br/><br/>epochs = 20<br/>steps_per_epoch = ceil(50000/128)<br/><br/><em class="mn"># Fit the model on the batches generated by datagen.flow().<br/></em>model.fit_generator(datagen.flow(train_x, train_y, batch_size=128),<br/>                    validation_data=[test_x,test_y],<br/>                    epochs=epochs,steps_per_epoch=steps_per_epoch, verbose=1, workers=4)<br/><br/><br/><em class="mn">#Evaluate the accuracy of the test dataset<br/></em>accuracy = model.evaluate(x=test_x,y=test_y,batch_size=128)<br/>model.save(<strong class="me ir">"cifar10model.h5"</strong>)</span></pre><p id="1eaf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">首先，这里有些事情是不同的</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="aea7" class="mi kx iq me b gy mj mk l ml mm">input_shape = (32,32,3)<br/>model = MiniModel(input_shape)<br/><br/><em class="mn">#Print a Summary of the model<br/><br/></em>model.summary()</span></pre><p id="514f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">正如我之前解释的，cifar 10由32 x 32 RGB图像组成，因此，输入形状有3个通道。这是不言自明的。</p><p id="5938" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下一行创建了我们定义的模型的实例，并传入了输入形状</p><p id="582e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后，最后一行将打印出我们网络的完整摘要，包括参数的数量。</p><p id="33e7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后需要解释的是</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="41e9" class="mi kx iq me b gy mj mk l ml mm">epochs = 20<br/>steps_per_epoch = ceil(50000/128)<br/><br/><em class="mn"># Fit the model on the batches generated by datagen.flow().<br/></em>model.fit_generator(datagen.flow(train_x, train_y, batch_size=128),<br/>                    validation_data=[test_x,test_y],<br/>                    epochs=epochs,steps_per_epoch=steps_per_epoch, verbose=1, workers=4)<br/><br/><br/><em class="mn">#Evaluate the accuracy of the test dataset<br/></em>accuracy = model.evaluate(x=test_x,y=test_y,batch_size=128)<br/>model.save(<strong class="me ir">"cifar10model.h5"</strong>)</span></pre><p id="3bd9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">首先，我们定义要运行的周期数，以及每个周期的步数，不要与数字混淆</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="01d8" class="mi kx iq me b gy mj mk l ml mm">steps_per_epoch = ceil(50000/128)</span></pre><p id="65f8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这里的50000是训练图像的总数，这里我们使用128的批量大小，这意味着，对于20个时期中的每一个，网络必须处理50000/128批图像。</p><p id="9d1b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来是fit函数，这显然不同于我在之前的教程中解释的fit函数。</p><p id="bfb0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">再看看下面会有帮助</p><pre class="lz ma mb mc gt md me mf mg aw mh bi"><span id="417c" class="mi kx iq me b gy mj mk l ml mm"><em class="mn">Fit the model on the batches generated by datagen.flow().<br/></em>model.fit_generator(datagen.flow(train_x, train_y, batch_size=128),<br/>                    validation_data=[test_x,test_y],<br/>                    epochs=epochs,steps_per_epoch=steps_per_epoch, verbose=1, workers=4)</span></pre><p id="6776" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于我们将数据生成器类用于数据扩充目的，我们必须使用fit_generator函数，我们也不直接传入train_x和train_y，而是通过来自数据生成器的flow函数传入它们，我们还指定批量大小，接下来我们陈述验证数据，在这种情况下是测试数据。所有其他事情保持不变。</p><p id="c665" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该设置在20个周期后产生82%。</p><p id="2074" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你可以尝试调整参数和网络，看看你能提高多少精度。在下一篇教程中，我将解释一些真正构建高效cnn架构所需的技巧和技术。本教程的目的是向您介绍基本组件。</p><p id="c12d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你想深入研究计算机视觉。从<a class="ae mo" href="https://john.specpal.science/deepvision" rel="noopener ugc nofollow" target="_blank">https://John . specpal . science</a>下载我的免费电子书《深度计算机视觉入门》</p><p id="2474" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你有任何问题，请在下面评论或者通过<a class="ae mo" href="https://twitter.com/johnolafenwa" rel="noopener ugc nofollow" target="_blank"> @johnolafenwa </a>在twitter上联系我</p></div></div>    
</body>
</html>