<html>
<head>
<title>Playing ATARI with 6 Neurons | Open Source Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 6 个神经元玩雅达利|开源代码</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/playing-atari-with-6-neurons-open-source-code-b94c764452ac?source=collection_archive---------12-----------------------#2018-06-29">https://towardsdatascience.com/playing-atari-with-6-neurons-open-source-code-b94c764452ac?source=collection_archive---------12-----------------------#2018-06-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="d5c9" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">#2 <a class="ae kf" href="https://arxiv.org/abs/1806.01363" rel="noopener ugc nofollow" target="_blank">研究论文</a>讲解</h2></div><p id="3e78" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这篇论文为机器学习社区打开的大门是惊人的。这个微小的网络实际上玩的是 Atari 游戏，只有 6 个神经元相当，偶尔还会更胜一筹，让以前的网络看起来像笑话。最棒的是，代码在<a class="ae kf" href="https://github.com/giuse/DNE" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上是开源的，每个人都可以玩。所以，让我们开始吧…</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/e6f994f9e073da8d96bf16bc4cef67e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*aKb_0Ohsz5fXwlKeIOfQfQ.gif"/></div><figcaption class="lk ll gj gh gi lm ln bd b be z dk"><a class="ae kf" href="http://www.reddit.com/r/oddlysatisfying/comments/39t04m/cube/" rel="noopener ugc nofollow" target="_blank">SOURCE</a></figcaption></figure></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><h1 id="912b" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">怎么可能！！！</h1><p id="834b" class="pw-post-body-paragraph kg kh iq ki b kj mn jr kl km mo ju ko kp mp kr ks kt mq kv kw kx mr kz la lb ij bi translated">我们已经知道，玩 atari 游戏的深度强化学习网络基本上是一个<em class="ms">密集的深度神经网络</em>既有又有<em class="ms"> </em>的职责，通过将像素映射到中间表示(<strong class="ki ir">也称为特征提取)</strong>内部学习从图像中提取特征，允许最后(少数)层将这些表示映射到动作和<strong class="ki ir">策略或决策。</strong></p><p id="14bf" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">因此，两者是同时学习的，这使得分开研究政策几乎是不可能的。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/2a62f456777ad726e7871771a93f0e2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*OiZ2Nk73JwrLuLGcB2G1hg.jpeg"/></div><figcaption class="lk ll gj gh gi lm ln bd b be z dk"><a class="ae kf" href="https://www.google.com/url?sa=i&amp;rct=j&amp;q=&amp;esrc=s&amp;source=images&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=&amp;url=https%3A%2F%2Fwww.nature.com%2Farticles%2Fnature14236&amp;psig=AOvVaw0q5seT4_pWHGGBf2NONfwC&amp;ust=1530192629980612" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="9a83" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">因此，仅仅通过将表示学习部分从策略学习部分中分离出来，就可以使网络免于构建中间表示，从而使其能够专注于策略逼近，该策略逼近是根据通过交互获得的观察结果在线训练的。</p><p id="484e" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">本文有助于在复杂 RL 设置中同时学习<em class="ms">功能</em>而分别学习<em class="ms">功能</em>。</p><p id="7f80" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这使得一个较小的政策网络更具竞争力，并以更复杂的方式解决问题。</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><p id="563b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">我们可以通过将它们分成两个不同的网络来更好地控制学习。</p><h2 id="db93" class="mu lw iq bd lx mv mw dn mb mx my dp mf kp mz na mh kt nb nc mj kx nd ne ml nf bi translated">学习特征提取</h2><p id="6742" class="pw-post-body-paragraph kg kh iq ki b kj mn jr kl km mo ju ko kp mp kr ks kt mq kv kw kx mr kz la lb ij bi translated">本文采用了两种新的方法来训练网络:基于<em class="ms">矢量量化</em>的方法称为<strong class="ki ir">增加字典(VQ) </strong>和基于<em class="ms">稀疏编码</em>的方法称为<strong class="ki ir">直接残差 SC </strong>。</p><p id="bfab" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">让我们看一些命令行程序来快速理解基本概念，然后我会在文章的后面解释新的东西。</p><blockquote class="ng"><p id="337c" class="nh ni iq bd nj nk nl nm nn no np lb dk translated">矢量量化是一种神经网络算法，用于通过使用称为字典的矢量列表来学习二元或多元分类。</p></blockquote><p id="537e" class="pw-post-body-paragraph kg kh iq ki b kj nq jr kl km nr ju ko kp ns kr ks kt nt kv kw kx nu kz la lb ij bi translated"><strong class="ki ir">注:</strong>我鼓励你进一步学习<a class="ae kf" href="https://www.techopedia.com/definition/32067/learning-vector-quantization-lvq" rel="noopener ugc nofollow" target="_blank"> <strong class="ki ir">矢量量化</strong> </a>和<a class="ae kf" href="http://ufldl.stanford.edu/tutorial/unsupervised/SparseCoding/" rel="noopener ugc nofollow" target="_blank"> <strong class="ki ir">稀疏编码</strong> </a>以便更好的理解。</p><h2 id="9dde" class="mu lw iq bd lx mv mw dn mb mx my dp mf kp mz na mh kt nb nc mj kx nd ne ml nf bi translated">学习决策政策</h2><p id="f177" class="pw-post-body-paragraph kg kh iq ki b kj mn jr kl km mo ju ko kp mp kr ks kt mq kv kw kx mr kz la lb ij bi translated">使用能够应对维度增长的专门版本的<strong class="ki ir">指数自然进化策略</strong>来训练策略。</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><h1 id="9c7f" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">让我们建立系统💻</h1><p id="7d2c" class="pw-post-body-paragraph kg kh iq ki b kj mn jr kl km mo ju ko kp mp kr ks kt mq kv kw kx mr kz la lb ij bi translated">现在让我们了解一下他们是如何实现这篇论文的。我们的系统可以编码成<strong class="ki ir"> 4 </strong>的简单步骤:</p><h1 id="f74f" class="lv lw iq bd lx ly nv ma mb mc nw me mf jw nx jx mh jz ny ka mj kc nz kd ml mm bi translated">1.环境👾</h1><p id="81b5" class="pw-post-body-paragraph kg kh iq ki b kj mn jr kl km mo ju ko kp mp kr ks kt mq kv kw kx mr kz la lb ij bi translated">该系统建立在 Atari 2600 的 OpenAI 框架上，具有原始控制台的所有限制。观测值由一个[210×180×3]张量组成，代表屏幕输入的 RBG 像素。</p><p id="c97b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">网络的输出被解释为 18 个离散动作中的一个，代表来自操纵杆的潜在输入。跳帧次数固定为 5。</p><h1 id="f5d1" class="lv lw iq bd lx ly nv ma mb mc nw me mf jw nx jx mh jz ny ka mj kc nz kd ml mm bi translated">2.压缩机💼</h1><p id="6118" class="pw-post-body-paragraph kg kh iq ki b kj mn jr kl km mo ju ko kp mp kr ks kt mq kv kw kx mr kz la lb ij bi translated">你也可以称之为预处理器。</p><p id="e674" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">压缩器是一个神经网络，当与环境交互时，它以一种<em class="ms">在线方式从观察中提取低维代码。</em></p><p id="47d4" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">为了获得在线学习的最佳性能，本文采用了两种新的方法，并将它们结合在一起。</p><h2 id="b67b" class="mu lw iq bd lx mv mw dn mb mx my dp mf kp mz na mh kt nb nc mj kx nd ne ml nf bi translated">增加字典矢量量化</h2><p id="7b95" class="pw-post-body-paragraph kg kh iq ki b kj mn jr kl km mo ju ko kp mp kr ks kt mq kv kw kx mr kz la lb ij bi translated">这个版本的 VQ 增加了字典的大小，不像矢量量化有固定的字典大小。</p><p id="e88b" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">字典大小的增长由阈值δ调节，指示被认为是有意义的增加的最小聚集残差。</p><h2 id="b81a" class="mu lw iq bd lx mv mw dn mb mx my dp mf kp mz na mh kt nb nc mj kx nd ne ml nf bi translated">直接残差稀疏编码</h2><p id="984e" class="pw-post-body-paragraph kg kh iq ki b kj mn jr kl km mo ju ko kp mp kr ks kt mq kv kw kx mr kz la lb ij bi translated">基于字典的算法的性能更多地取决于编码而不是字典训练。因此，为了提高 IDVQ 的性能，使用了直接剩余 SC。详细解释<a class="ae kf" href="https://arxiv.org/abs/1806.01363" rel="noopener ugc nofollow" target="_blank">请点击此处</a>。</p><h1 id="6132" class="lv lw iq bd lx ly nv ma mb mc nw me mf jw nx jx mh jz ny ka mj kc nz kd ml mm bi translated">3.控制器🎮</h1><p id="f6c0" class="pw-post-body-paragraph kg kh iq ki b kj mn jr kl km mo ju ko kp mp kr ks kt mq kv kw kx mr kz la lb ij bi translated">所有实验的控制器都是单层全连接递归神经网络(RNN)。</p><p id="505a" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">每个神经元通过加权连接接收以下输入:网络的输入、来自先前激活的所有神经元的输出(最初为零)和恒定偏置(总是设置为 1)。</p><p id="6be7" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">输入<strong class="ki ir">的数量</strong>在任何给定的时间点都等于来自压缩机<em class="ms">变化</em>输出的代码的大小。</p><p id="3f26" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">在<strong class="ki ir">输出层</strong>中的神经元数量保持等于每个游戏的动作，如 ALE 模拟器所定义的。这在一些游戏中低至 6，最多 18。</p><h1 id="c01f" class="lv lw iq bd lx ly nv ma mb mc nw me mf jw nx jx mh jz ny ka mj kc nz kd ml mm bi translated">4.【计算机】优化程序🚀</h1><p id="b8b8" class="pw-post-body-paragraph kg kh iq ki b kj mn jr kl km mo ju ko kp mp kr ks kt mq kv kw kx mr kz la lb ij bi translated">优化器是我们的学习算法，随着时间的推移提高网络的性能，在这种情况下，一种称为...</p><h2 id="359c" class="mu lw iq bd lx mv mw dn mb mx my dp mf kp mz na mh kt nb nc mj kx nd ne ml nf bi translated">指数自然进化策略💁<a class="ae kf" href="http://people.idsia.ch/~juergen/xNES2010gecco.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></h2><p id="0838" class="pw-post-body-paragraph kg kh iq ki b kj mn jr kl km mo ju ko kp mp kr ks kt mq kv kw kx mr kz la lb ij bi translated">自然进化策略是一个进化算法家族，它控制着个体的显式种群参数。</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><h1 id="7641" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">结果</h1><p id="a73e" class="pw-post-body-paragraph kg kh iq ki b kj mn jr kl km mo ju ko kp mp kr ks kt mq kv kw kx mr kz la lb ij bi translated">下面给出了在 OpenAI 的 ALE 框架上，从数百个可用游戏中选出的 10 个 Atari 游戏的比较结果。</p><p id="c588" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">他们将他们的工作与最近的两篇论文进行了比较，这两篇论文提供了 Atari 游戏的广泛结果。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oa"><img src="../Images/99a58c44f9d2e9ece498d8cd7ad21562.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T5r7h2aeqcQ9NOkyCwKsjA.jpeg"/></div></div><figcaption class="lk ll gj gh gi lm ln bd b be z dk"><strong class="bd of">RESULTS</strong></figcaption></figure></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><h1 id="49eb" class="lv lw iq bd lx ly lz ma mb mc md me mf jw mg jx mh jz mi ka mj kc mk kd ml mm bi translated">结论</h1><p id="793d" class="pw-post-body-paragraph kg kh iq ki b kj mn jr kl km mo ju ko kp mp kr ks kt mq kv kw kx mr kz la lb ij bi translated">我们提出了一种在强化学习任务(如 Atari 游戏)中学习视觉控制有效策略的方法，该方法使用比通常用于这些问题的深度神经网络小两个数量级的微小神经网络。</p><p id="207f" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">这是通过将策略学习与特征构建分离来实现的。</p><p id="b1df" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">特征构造是在网络外部通过一种被称为递增字典矢量量化的新颖且有效的矢量量化算法来执行的，该算法是根据网络与环境的交互所获得的观测值来在线(即沿着网络)训练的。</p></div><div class="ab cl lo lp hu lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="ij ik il im in"><p id="e252" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">如果你喜欢<strong class="ki ir">拍拍</strong>和<strong class="ki ir">与社区分享</strong>这个的解释。关注我的<strong class="ki ir"> Medium </strong>和<strong class="ki ir"> Twitter </strong>以获取更多# <strong class="ki ir">研究论文解释</strong>通知…</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><a href="https://medium.com/@sagarsharma4244"><div class="gh gi lc"><img src="../Images/45303d02b0c43f98f0ac2c3cd1446db6.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*d318hSQDEA-NP2sgKkTINw.png"/></div></a></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><a href="https://twitter.com/SagarSharma4244"><div class="gh gi lc"><img src="../Images/ce2f13e1aad357cb162c5550d2fd4868.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*YnbtD8IipCsqVjNwkjtY8w.png"/></div></a></figure><p id="3aee" class="pw-post-body-paragraph kg kh iq ki b kj kk jr kl km kn ju ko kp kq kr ks kt ku kv kw kx ky kz la lb ij bi translated">如果你对这篇论文有任何疑问，或者想让我解释你最喜欢的论文，请在下面评论。</p><h1 id="ed52" class="lv lw iq bd lx ly nv ma mb mc nw me mf jw nx jx mh jz ny ka mj kc nz kd ml mm bi translated">你会喜欢的以前的故事:</h1><div class="og oh gp gr oi oj"><a href="https://hackernoon.com/deepminds-amazing-mix-match-rl-techique-a6f8ce6ac0b4" rel="noopener  ugc nofollow" target="_blank"><div class="ok ab fo"><div class="ol ab om cl cj on"><h2 class="bd ir gy z fp oo fr fs op fu fw ip bi translated">DeepMind 惊人的混搭 RL 技术</h2><div class="oq l"><h3 class="bd b gy z fp oo fr fs op fu fw dk translated">2018 年 6 月发布的研究论文解释</h3></div><div class="or l"><p class="bd b dl z fp oo fr fs op fu fw dk translated">hackernoon.com</p></div></div><div class="os l"><div class="ot l ou ov ow os ox li oj"/></div></div></a></div><div class="og oh gp gr oi oj"><a rel="noopener follow" target="_blank" href="/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9"><div class="ok ab fo"><div class="ol ab om cl cj on"><h2 class="bd ir gy z fp oo fr fs op fu fw ip bi translated">纪元与批量大小与迭代次数</h2><div class="oq l"><h3 class="bd b gy z fp oo fr fs op fu fw dk translated">了解您的代码…</h3></div><div class="or l"><p class="bd b dl z fp oo fr fs op fu fw dk translated">towardsdatascience.com</p></div></div><div class="os l"><div class="oy l ou ov ow os ox li oj"/></div></div></a></div><div class="og oh gp gr oi oj"><a rel="noopener follow" target="_blank" href="/50-tensorflow-js-api-explained-in-5-minutes-tensorflow-js-cheetsheet-4f8c7f9cc8b2"><div class="ok ab fo"><div class="ol ab om cl cj on"><h2 class="bd ir gy z fp oo fr fs op fu fw ip bi translated">50 tensor flow . js API 5 分钟讲解| TensorFlow.js Cheetsheet</h2><div class="oq l"><h3 class="bd b gy z fp oo fr fs op fu fw dk translated">TensorFlow API Cheetsheet</h3></div><div class="or l"><p class="bd b dl z fp oo fr fs op fu fw dk translated">towardsdatascience.com</p></div></div><div class="os l"><div class="oz l ou ov ow os ox li oj"/></div></div></a></div><div class="og oh gp gr oi oj"><a rel="noopener follow" target="_blank" href="/activation-functions-neural-networks-1cbd9f8d91d6"><div class="ok ab fo"><div class="ol ab om cl cj on"><h2 class="bd ir gy z fp oo fr fs op fu fw ip bi translated">激活函数:神经网络</h2><div class="oq l"><h3 class="bd b gy z fp oo fr fs op fu fw dk translated">Sigmoid，tanh，Softmax，ReLU，Leaky ReLU 解释！！！</h3></div><div class="or l"><p class="bd b dl z fp oo fr fs op fu fw dk translated">towardsdatascience.com</p></div></div><div class="os l"><div class="pa l ou ov ow os ox li oj"/></div></div></a></div><div class="og oh gp gr oi oj"><a rel="noopener follow" target="_blank" href="/tensorflow-on-mobile-tutorial-1-744703297267"><div class="ok ab fo"><div class="ol ab om cl cj on"><h2 class="bd ir gy z fp oo fr fs op fu fw ip bi translated">手机上的 TensorFlow:教程</h2><div class="oq l"><h3 class="bd b gy z fp oo fr fs op fu fw dk translated">在 Android 和 iOS 上</h3></div><div class="or l"><p class="bd b dl z fp oo fr fs op fu fw dk translated">towardsdatascience.com</p></div></div><div class="os l"><div class="pb l ou ov ow os ox li oj"/></div></div></a></div></div></div>    
</body>
</html>