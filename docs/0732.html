<html>
<head>
<title>Summary of PixelRNN by Google Deepmind</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Google Deepmind对PixelRNN的总结</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/summary-of-pixelrnn-by-google-deepmind-7-min-read-938d9871d6d9?source=collection_archive---------4-----------------------#2017-06-14">https://towardsdatascience.com/summary-of-pixelrnn-by-google-deepmind-7-min-read-938d9871d6d9?source=collection_archive---------4-----------------------#2017-06-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/d853dc2d05aa9bf49c70bb9648b185e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VmOpsw00gDfkTYvFTNUNjg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 1: Completion of masked image</figcaption></figure><h1 id="65d4" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">简介:</h1><p id="3bad" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">自然图像的分布建模是无监督学习中的一个核心问题，它在图像去模糊、图像压缩、文本到图像的转换等方面都有应用。图1显示了如何使用pixelRNN模型来完成图像。</p><p id="a138" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">变分自动编码器、GANs和自回归模型是三种可用的图像生成方法。这篇文章关注自回归，特别是pixelRNN。</p><h1 id="487a" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">为什么是RNN？</h1><p id="024c" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">在图像中，通常一个像素依赖于所有先前预测的像素，这导致像素之间产生长程相关性。因为RNNs已被证明在具有长范围相关性的时间序列预测中是有效的。因此，RNN用于生成图像中的像素。</p><p id="6279" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">在本文中，像素生成的顺序是由作者确定的——从上到下和从左到右(图2)。(注意:可以有许多可以预测像素的序列，但是需要预先选择其中的一个。)</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi md"><img src="../Images/050d400a5d043d5fdd7cc26e43cc9568.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*64Z0o9mYzj30ScxaYUVtdw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Equation 1: Probability of predicting an image</figcaption></figure><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/f808d613f3279c004f56b04a5a01b193.png" data-original-src="https://miro.medium.com/v2/resize:fit:438/format:webp/1*DZoKHexAxLH3-SjBw4yOHw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 2</figcaption></figure><p id="c4be" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">在等式1中，p( <strong class="lc ir"> x </strong>)表示预测图像的概率(<strong class="lc ir"> x </strong>)，其等于给定所有先前预测的像素的条件概率x <em class="mj"> i </em>的乘积。</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/cabac7d571edd72a58bee2b7105e501d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*0nR6t2tyLlO75HpWhkPq9g.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Equation 2</figcaption></figure><p id="4894" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">等式2表示在给定先前生成的像素的情况下预测像素x <em class="mj"> i </em>的R、G、B值的概率。在像素x <em class="mj"> i </em>的预测中，包括先前预测像素的R、G、B值。在x <em class="mj"> i，G </em>的预测中，预测值x <em class="mj"> i，R </em>也与先前生成的像素的R，G，B值一起被包括。</p><h1 id="8f34" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated"><strong class="ak">图像生成中的LSTM图层:</strong></h1><p id="bb5f" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">LSTM层以前已经用于图像生成。他们逐个像素地训练图像。考虑到图像数据集中的像素数量，训练LSTM需要大量的时间。</p><p id="4ec4" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">隐藏状态(I，j)=隐藏状态(i-1，j)，隐藏状态(I，j-1)，p(i，j)</p><p id="1146" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">像素(I，j)的隐藏状态取决于像素(I，j-1)和像素(i-1，j)的隐藏状态。因此，除非计算出先前像素的隐藏状态，否则无法计算像素(I，j)的隐藏状态。因此，在计算隐藏状态时不可能有并行化，因此也不会节省训练时间。</p><p id="975d" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">作者引入了两种类型的LSTM层来克服上述问题:行LSTM和对角LSTM</p><h1 id="0332" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated"><strong class="ak">排LSTM: </strong></h1><p id="dae6" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">隐藏状态(I，j) =隐藏状态(i-1，j-1)，隐藏状态(i-1，j+1)，隐藏状态(i-1，j)，p(i，j)</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/a22716546ea9377458abc76b28a28c12.png" data-original-src="https://miro.medium.com/v2/resize:fit:420/format:webp/1*yCd_Qln-emZN0dHXSxJcJQ.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 3: Computing hidden state of red pixel; blue pixels are part of the triangular context</figcaption></figure><p id="c484" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">如图3所示，一个像素的隐藏状态直接取决于它上面3个像素的隐藏状态。这3个像素又分别直接依赖于其他3个像素。因此，像素的隐藏状态具有三角形上下文(图3)。这个三角形上下文可以被视为用于预测像素值的“历史”。</p><p id="14be" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">如图3所示，在红色像素之前预测的几个像素不包括在三角形上下文中。因此，用于计算红色像素值的“历史”不包括所有先前生成的像素。这可以被称为“上下文丢失”。像素的隐藏状态取决于它上面的3个像素，而不取决于它所在行中的任何像素。因此，可以并行计算同一行中所有像素的隐藏状态。</p><p id="8dc2" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">因此，行LSTM解决了如在LSTM中的高训练时间的问题，但是产生了用于计算像素的隐藏状态的不完整“上下文”的问题。</p><h1 id="d79b" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">对角线BLSTM:</h1><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/227a5ac1bccabaac5a2245a17d2569b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*Oa5BAtFGxd602opYb_R6sA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 4: Computing hidden state of red pixel; blue pixels are part of the context</figcaption></figure><p id="fe08" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">对角BLSTM的引入是为了解决行LSTM中“上下文”不完整的问题。在对角线BLSTM中，像素(I，j)的隐藏状态取决于像素(I，j-1)和像素(i-1，j)。由于双向LSTM覆盖了前向和后向相关性，所有先前生成的像素都包括在用于预测像素值的“上下文”/“历史”中。</p><h1 id="ee53" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">像素CNN:</h1><p id="f69c" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">行和对角线LSTM层覆盖图像中的长程相关性。由于LSTM层的复杂性质，学习长程相关性需要计算成本。标准卷积层可以捕捉一个有界感受域，并同时计算所有像素位置的特征。保持图像的空间信息很重要；PixelCNN中不使用池层。为了避免在像素预测中使用未来上下文(未来像素)，在PixelCNN中使用了遮罩。</p><h1 id="eb97" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">掩蔽卷积:</h1><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/f808d613f3279c004f56b04a5a01b193.png" data-original-src="https://miro.medium.com/v2/resize:fit:438/format:webp/1*DZoKHexAxLH3-SjBw4yOHw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 5: Value of pixel xi depend on values of previous pixels</figcaption></figure><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/70d4cf9daadfec4cc8c84265f8a63dde.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*MNPHKAbAk29V_pZuDOnZ-g.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 6: Mask to zero out the future pixel values.</figcaption></figure><p id="a128" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">将所有不可用于模型的像素值清零。<br/>像素x <em class="mj"> i </em>只取决于像素x <em class="mj"> 1…</em>x<em class="mj">I 1，</em>因此我们必须确保它不会访问后续像素:x <em class="mj"> i+1。</em>。x <em class="mj"> n^2 </em></p><p id="a95a" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">作者在论文中使用了两种类型的掩码，即掩码A和掩码b。</p><h1 id="ff6a" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">面具B:</h1><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/86ac7fa094339186817ea6189eb3f30e.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*UCY0tiQr9jX9S9u8B6_wFA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 7: Mask B</figcaption></figure><p id="d17e" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">如前所述，保留空间信息对于精确预测像素值非常重要，因此PixelCNN中不使用池层。因此，在网络中不会发生图像的上采样或下采样。因此，在整个网络中，图像必须具有R、G、B值，在本文中，掩码B用于此目的。</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mp"><img src="../Images/f6f5688915a36fcd6833323eccc9eccf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6_SJf2XQVo8UJxU39hkSyw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 8: Convolution without using mask B</figcaption></figure><p id="f8d6" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">如图所示，如果在卷积期间不使用掩码B，则输出特征图中的通道数与输入不同。</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mq"><img src="../Images/da2be4d88d3e2fcc0c9c6c623eb8d1a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pLYZUoLcyJG47ZXMoTquAQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 9: Convolution with using mask B</figcaption></figure><p id="d594" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">使用屏蔽B(图7)，卷积的输出也将R、G、B通道作为输入。</p><h1 id="2215" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">盲点问题:</h1><p id="f31e" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">PixelCNN减少了行LSTM和对角线BLSTM中所需的计算成本，但是存在盲点问题。盲点问题基本上不包括用于计算像素隐藏状态的上下文/历史中的所有先前像素。我们稍后将深入探讨盲点问题。</p><h1 id="e39b" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">使用PixelRNN的图像完成:</h1><figure class="me mf mg mh gt jr gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/33bd7d77bc95d45170b9632d3e800d13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*04LlLZRea6mxiFNjLJdflw.png"/></div></figure></div></div>    
</body>
</html>