# 可解释性:最后一英里

> 原文：<https://towardsdatascience.com/explainability-the-last-mile-c2604bbbf9ff?source=collection_archive---------11----------------------->

![](img/5e9e1a2eba3662314c7abdaffc7fa259.png)

为了让你的用户理解你的模型，仅仅“可解释”是不够的——你需要提供最终的解释

可解释或可解释的模型已经从近乎空想变成了日益普遍的业务需求。然而，尽管有越来越多的方法可用于解释模型，但这些仍然是技术工具，针对的是需要理解他们创建的模型的统计和数据科学实践者。对于创建最终用户可以理解的模型来说，它们是必要的，但还不够。

创建一个最终用户可以理解的模型，一方面意味着确保他们基本理解模型中的输入和输出变量是什么，另一方面意味着他们理解这些变量在模型中如何操作。

在每一种情况下，最终的演示对于确保实现无缝用户体验的最终目标至关重要。虽然相对明显的是，输入变量本身是复杂模型的输出，或者变量具有不透明的名称，如“Var1 ”,会增加用户的困惑，而不是帮助他们理解，但有时不清楚需要多少解释。

部分问题在于，从建模者的角度来看，重要的是变量中包含了什么——模型的比率输入的名称很可能指的是构成比率的变量。显然，这对变量的用户来说意义不大。想想会计比率的名称——“速动比率”、“酸性测试”，或者物理和工程中的无量纲常数，如雷诺数(在简单的水平上，它表示流体中的湍流程度)。

雷诺数虽然没有一个完美的交流名称(从这个角度来看,“湍流数”可能是一个改进),但它确实说明了以不同的方式将模型输入的计算与其在模型中的意义分离的概念——在不同的背景下，不同的工程模型中使用多个雷诺数，但基本上以相同的方式使用雷诺数——来量化流体的湍流。对于管道和通道中的流动，对于穿过流体下落的颗粒，对于搅拌槽中的叶轮以及对于填充床中流动的流体，都有一个雷诺数——所有这些都有不同的计算，都至少在基本层面上表达了相同的概念。

在数据科学模型中，这有两种方式。一个是，如果你想在尽可能多的地方重用你的模型，为了可移植性，用一种独立于它们的成分的方式来标记你的变量是很方便的。例如，在信贷风险模型中，由于当地税收或其他监管原因，收入或资产可能有不同的计算方法。

第二点更为重要——如果其他人要使用模型，您的界面将需要标记，而在模型中引用变量含义的标记比解释其成分的标记更能向用户解释输入。在雷诺数的情况下，解释“表示湍流趋势的常数，其中较高的数更倾向于湍流”更有用，并且比“直径、速度和流体密度与流体粘度之比”更能解释其在模型中的用途。

当然，这个变量定义必须易于用户访问。如果它足够短，悬停或工具提示是一个很好的方法。否则，一个易于访问的定义屏幕将确保您的用户理解您的模型的输入。

很明显，解释变量是什么是不够的——你需要确保你的用户理解他们如何一起工作以确保最终的结果。最大的障碍可以说是机器学习算法通过考虑非线性关系和相互作用来实现准确性，而这些特别难以可视化。

现有的模型解释器(如 LIME)通过假设在靠近模型表面上任意点的区域中，相互作用效应和非线性效应可以忽略不计来简化这些方面。如果你的模型需要理解的重要方面是你的模型如何对单个案例进行评级，那么这就是正确的方法。

如果对你的用户来说，理解整个模型的趋势更重要，创建可视化，可能基于附加模型，梳理出非线性的方面，可能是更用户友好的方法。

*罗伯特·德格拉夫是《进行中的书’*[*【懒惰的数据科学家】*](https://leanpub.com/thelazydatascientist) *的作者，可通过 LeanPub 获得。他最近为 Medium 撰写的文章是* [*保持用户的信任。*](/keeping-your-customers-faith-7ebbf2bb2610)