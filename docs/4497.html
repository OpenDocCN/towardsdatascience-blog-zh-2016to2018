<html>
<head>
<title>[ CVPR 2018 / Paper Summary ] Decorrelated Batch Normalization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">【CVPR 2018 /论文摘要】去相关批量归一化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cvpr-2018-paper-summary-decorrelated-batch-normalization-6917d2a8fcf6?source=collection_archive---------19-----------------------#2018-08-19">https://towardsdatascience.com/cvpr-2018-paper-summary-decorrelated-batch-normalization-6917d2a8fcf6?source=collection_archive---------19-----------------------#2018-08-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/e0df807f8f0708b36a99165066755bf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/1*SRn5dQo5udsusuGUeW2mOg.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">GIF from this <a class="ae jy" href="https://giphy.com/gifs/data-Si60783lTJw5y" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="9eb2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">标准化有多种不同版本，如实例标准化或组标准化。这是一种新的方法，其中该层对给定数据执行统计白化。</p><blockquote class="kx ky kz"><p id="5f44" class="jz ka la kb b kc kd ke kf kg kh ki kj lb kl km kn lc kp kq kr ld kt ku kv kw ij bi translated"><strong class="kb ir">请注意，这篇帖子是为了我未来的自己复习这篇论文上的材料，而不是从头再看一遍。</strong></p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="lp lq l"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Paper from this <a class="ae jy" href="https://arxiv.org/pdf/1804.08450.pdf" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="989b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">摘要</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lr"><img src="../Images/e21d741dfc1f972ae5494f44d4efd1fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IIYLlmVg-sGSaozICdd65g.png"/></div></div></figure><p id="1812" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">批量标准化是一种标准化给定小批量的技术，在这项工作中，作者将这一概念扩展到去相关批量标准化，其中执行 ZCA 白化。并且 ZCA 白化是为了白化数据而使用的白化技术。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="7950" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">简介</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/3aac7f4bd500f7f7033c9bd4e8983824.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/1*kogt2pl5CLSuXB39jLkYZw.png"/></div></figure><p id="7c6e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">批量规范化用于加速深度网络的训练，从它的出现开始，就被广泛应用于深度学习的各个领域。(而且方程式如上图。)需要注意的一点是，在训练期间，我们使用数据均值和方差，但在测试期间，我们使用移动平均均值和方差。众所周知的事实是，如果我们白化输入，训练变得更有效，因为协方差矩阵的更好条件导致在更新权重时更好地调节 Hessian，使得梯度下降更新更接近牛顿更新。然而，典型的批处理规范执行标准化，然后白化数据。因此，本文的作者开发了一个新的层，在其中执行给定数据的白化。(作者解决了反向传播的问题，用于执行数据白化的技术的选择，以及在执行白化操作时如何决定批量大小。)</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="d02b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">相关工作</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lx"><img src="../Images/11c3c04d837efe77c4aa7a9bb6e70215.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vtILJa8f9HeCewluI5OFgA.png"/></div></div></figure><p id="07d9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">众所周知，归一化数据有助于深度神经网络的收敛。BN 的一个问题是，我们需要一个合理的批量大小来估计平均值和方差，为了解决这个问题，开发了层归一化。还有其他尝试，如批量重新规范化和流规范化。作者的工作与自然神经网络密切相关，然而作者指出了他们的方法更稳定的事实。获得去相关数据的另一种方法是添加额外的正则化项。然而，这些方法并不是为了加速训练。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="4060" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">去相关批量标准化</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ly"><img src="../Images/f6987a9f33753f49ba3a88fe10b8b791.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pJH9OjURB1ifQemFHP58fA.png"/></div></div></figure><p id="6e69" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，数学上我们可以定义去相关操作(其中输入维度和输出维度是相同的。).然而，上述白化操作并不是唯一的，因为 sigma 协方差矩阵仅定义到旋转(单击此处的<a class="ae jy" href="https://stats.stackexchange.com/questions/117427/what-is-the-difference-between-zca-whitening-and-pca-whitening" rel="noopener ugc nofollow" target="_blank">以获得更多解释)，并且由于这种现象，作者称之为随机轴交换，这是不可取的。随机轴交换会导致输入维度的随机排列，这会混淆学习算法并损害性能。</a></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lz"><img src="../Images/5dbcb3bb76c99fefd7a8a3a195fb070e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PHElTduNy4kAqZLmcyXn4w.png"/></div></div></figure><p id="8b0d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，我们可以看到，如果发生随机轴交换，网络将无法很好地运行。(甚至根本没有。)为了克服这个问题，作者使用了 ZCA 美白。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/dca1f051ff8129d86134ef89d8213d61.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*IIQzVwDc592vFk1PKPHpWg.png"/></div></figure><p id="7381" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">ZCA 白化将 L2 距离下的白化引入的失真最小化。并且相对于西格玛值的反向传播可以在下面看到。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mb"><img src="../Images/c045b9311baca97bf4d8b3cae877a6c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*txQpFSOZhCYXr5mvtzCwbg.png"/></div></div></figure><p id="19e4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">当我们对输入值 x 求导时，它可以是下面这样的。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mc"><img src="../Images/89b35610cd1e581a52382547f81da7f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*velORxEGTSxd6BwqN3VCpA.png"/></div></div></figure><p id="0d7a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">与批量标准化类似，作者使用了 sigma 和平均值的运行平均值以及可学习参数 alpha 和 beta 的概念。DBN 的完整算法如下所示。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi md"><img src="../Images/b25397dd5f156915d373a9982ab5afc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*AbSdHpALEGiN_Zks7bENdQ.png"/></div></figure><p id="428f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最后，如引言部分所讨论的，作者将特征分成组并对每个组执行白化，而不是一起白化整批。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="b3e1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">实验</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi me"><img src="../Images/a7e5e6e98aa21bddc9f8375a313c8ed6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*om19OK0i9VMB1FnRDUaEKA.png"/></div></div></figure><p id="3a24" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">正如上面看到的所有实验，如条件分析以及不同数据集上训练损失的比较，我们可以看到 DBN 表现出最好的性能。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mf"><img src="../Images/f9a87c56d318f60e0b747f7cf3a8c092.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RWC9HWeCTij4dOdmLyYGiw.png"/></div></div></figure><p id="17f7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">当作者将 VGG-A 架构与 BN 或 DBN 进行比较时，我们可以看到 DBN 在一般化方面表现更好。(最右边的结果是在非线性之后应用 BN/DBN 时的结果。)</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mg"><img src="../Images/5d97ee57560d793c61fb0cc32cd020b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Xo8AjS9V2R3mMk8GLCMDg.png"/></div></div></figure><p id="8c90" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，当网络使用 DBN 而不是 BN 时，训练更加稳定。(更容易优化)。我们也可以更积极地设定学习率。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/c3023590e4bce7ba37aec497cc99f619.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*IyGZ7QTeQ3WqIR4uLFNPBg.png"/></div></figure><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mi"><img src="../Images/36ec5e139a777380ad18e4ca66c32dff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VPAQHhVBkCWryrmCbml3Nw.png"/></div></div></figure><p id="8fb5" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">跳过所有需要的贪婪的细节，作者能够通过使用 DBN 的网络超越基线性能。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="1e81" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结论</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/6246b8b25881c3fa8e648a8dc8509509.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*oUzipcNdO00GV451bJV7rQ.png"/></div></figure><p id="4ad8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">总之，作者介绍了去相关批处理标准化，其中给定数据的性能白化。(而不是标准化)。此外，他们能够超越基线表现。最后，他们发现使用 PCA 美白并不是一个好的选择。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="70ee" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">最后的话</strong></p><p id="f6aa" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最后，如果有人感兴趣的话，我已经链接了斯坦福讲座的 pdf，其中也包含了这个主题。</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="lp lq l"/></div></figure><p id="6103" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 给我，如果你想看我所有写作的列表，请点击这里查看我的网站。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的推特<a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或者我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。我还实现了<a class="ae jy" href="https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec" rel="noopener">广残网，请点击这里查看博文 pos </a> t。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="b1f5" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="026b" class="mk ml iq kb b kc kd kg kh kk mm ko mn ks mo kw mp mq mr ms bi translated">(2018).Cs231n.stanford.edu。检索于 2018 年 8 月 19 日，来自<a class="ae jy" href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture07.pdf" rel="noopener ugc nofollow" target="_blank">http://cs 231n . Stanford . edu/slides/2018/cs 231n _ 2018 _ lecture 07 . pdf</a></li><li id="9761" class="mk ml iq kb b kc mt kg mu kk mv ko mw ks mx kw mp mq mr ms bi translated">(2018).Arxiv.org。检索于 2018 年 8 月 19 日，来自<a class="ae jy" href="https://arxiv.org/pdf/1804.08450.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1804.08450.pdf</a></li><li id="40b1" class="mk ml iq kb b kc mt kg mu kk mv ko mw ks mx kw mp mq mr ms bi translated">美白？，W. (2018)。ZCA 美白和 PCA 美白有什么区别？。交叉验证。检索于 2018 年 8 月 19 日，来自<a class="ae jy" href="https://stats.stackexchange.com/questions/117427/what-is-the-difference-between-zca-whitening-and-pca-whitening" rel="noopener ugc nofollow" target="_blank">https://stats . stack exchange . com/questions/117427/zca-whiting-and-PCA-whiting 的区别是什么</a></li></ol></div></div>    
</body>
</html>