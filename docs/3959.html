<html>
<head>
<title>Wine vs Sparkling Wine: A Neural Network image classification explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">葡萄酒与起泡酒:一个神经网络图像分类解释</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/wine-vs-sparkling-wine-a-neural-network-image-classification-explained-99a6ac477bfa?source=collection_archive---------7-----------------------#2018-07-04">https://towardsdatascience.com/wine-vs-sparkling-wine-a-neural-network-image-classification-explained-99a6ac477bfa?source=collection_archive---------7-----------------------#2018-07-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/16134fbbc0235147540bcf94c2762fb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pMC9C98xxPwZVXYlYZKbkQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><a class="ae kc" href="https://pixabay.com/fr/photos/champagne-cierges-magiques-li%c3%a8ge-4734176/" rel="noopener ugc nofollow" target="_blank">pixabay.com</a></figcaption></figure><p id="1d04" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你看了我<a class="ae kc" rel="noopener" target="_blank" href="/wine-ratings-prediction-using-machine-learning-ce259832b321">之前的帖子</a>，你就知道我喜欢酒。嗯，事实是，我不是特别喜欢汽酒！(☉_☉)</p><p id="ed71" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于我第二次深入机器学习，我想看看卷积神经网络(CNN)对图像分类的可能性。顺便说一下，CNN 并不代表新闻频道(◠‿◠)</p><p id="66cb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最近，一个朋友建议我去查看 Keras，这是一个神经网络库，超级容易使用，由谷歌的<a class="lb lc ep" href="https://medium.com/u/7462d2319de7?source=post_page-----99a6ac477bfa--------------------------------" rel="noopener" target="_blank">弗朗索瓦·乔莱</a>开发。让我们马上进入正题，这个库太棒了:超级容易使用，超级高性能，文档写得很完美。你还能要求什么？</p><p id="5c8f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个实验的目的是了解葡萄酒和起泡酒的图像的识别程度，或者简单地说，这种模型的精确度。</p><h1 id="7785" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">什么是 CNN？</h1><p id="0025" class="pw-post-body-paragraph kd ke iq kf b kg mb ki kj kk mc km kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">我鼓励你阅读这篇写得很好的<a class="ae kc" href="https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050" rel="noopener ugc nofollow" target="_blank">文章</a>，它详细解释了什么是 CNN。</p><p id="4b2f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">简言之，CNN 在两个主要方面不同于常规的机器学习算法:</p><ul class=""><li id="f8bb" class="mg mh iq kf b kg kh kk kl ko mi ks mj kw mk la ml mm mn mo bi translated">它由不同的过滤器(内核)和分类器组成。每个部分都是独立的，就像我们大脑的一部分，如果需要，CNN 可以删除、更新和调整这些部分。</li></ul><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mp"><img src="../Images/55a98386a709f58a9413e96afdbeca55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kkyW7BR5FZJq4_oBTx3OPQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Architecture of a CNN. — Source: <a class="ae kc" href="https://www.mathworks.com/videos/introduction-to-deep-learning-what-are-convolutional-neural-networks--1489512765771.html" rel="noopener ugc nofollow" target="_blank">https://www.mathworks.com/videos/introduction-to-deep-learning-what-are-convolutional-neural-networks--1489512765771.html</a></figcaption></figure><ul class=""><li id="6c3c" class="mg mh iq kf b kg kh kk kl ko mi ks mj kw mk la ml mm mn mo bi translated">CNN 将从经验中学习。它有能力回到数据集并从以前的训练中学习，例如，对效果最好的过滤器或分类器进行更多的加权。对数据集的一次迭代称为一个时期。</li></ul><h1 id="21f6" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">数据集</h1><p id="5118" class="pw-post-body-paragraph kd ke iq kf b kg mb ki kj kk mc km kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">我为了这个不偷懒，就刮了一个不怎么出名的酒类网站。</p><p id="f560" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">结果是一个由 700 幅训练图像和 200 幅测试图像组成的数据集，足够用了。下一步就是简单地将 Keras 的博客例子调整到这个数据集。</p><h1 id="29a6" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">训练和测试模型</h1><p id="da3c" class="pw-post-body-paragraph kd ke iq kf b kg mb ki kj kk mc km kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">为了你自己，我不会把这个项目的所有代码都粘贴在这里，但是 Github 的链接在本文的最后。</p><p id="10f2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那么 Keras 是如何进行图像分类的呢？我认为有几个重要的部分:</p><ul class=""><li id="e087" class="mg mh iq kf b kg kh kk kl ko mi ks mj kw mk la ml mm mn mo bi translated">构建您的神经网络模型:遵循文档</li></ul><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="ceb8" class="mz le iq mv b gy na nb l nc nd">model = Sequential()<br/>model.add(Conv2D(32, (3, 3), input_shape=input_shape))<br/>model.add(Activation('relu'))<br/>model.add(MaxPooling2D(pool_size=(2, 2)))</span><span id="73b9" class="mz le iq mv b gy ne nb l nc nd">[...More CNN layers...]</span><span id="4a29" class="mz le iq mv b gy ne nb l nc nd">model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])</span></pre><ul class=""><li id="ff0a" class="mg mh iq kf b kg kh kk kl ko mi ks mj kw mk la ml mm mn mo bi translated">使用 ImageDataGenerator 为模型提供更广泛、更多样的生成图像集</li></ul><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="0688" class="mz le iq mv b gy na nb l nc nd">train_datagen = ImageDataGenerator(rescale=1. / 255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)</span></pre><ul class=""><li id="0d39" class="mg mh iq kf b kg kh kk kl ko mi ks mj kw mk la ml mm mn mo bi translated">训练和测试您的模型</li></ul><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="43d7" class="mz le iq mv b gy na nb l nc nd">model.fit_generator(train_generator, steps_per_epoch=nb_train_samples, epochs=epochs, validation_data=validation_generator, validation_steps=nb_validation_samples)</span></pre><ul class=""><li id="46fd" class="mg mh iq kf b kg kh kk kl ko mi ks mj kw mk la ml mm mn mo bi translated">最后拯救你的体重和模型</li></ul><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="f7a0" class="mz le iq mv b gy na nb l nc nd">model.save_weights('wines_sparklings_weights.h5')<br/>model.save('wines_sparklings_model.h5')</span></pre><p id="eaef" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">运行 python 文件将输出类似这样的内容(10 个历元后精度约为 99%):</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nf"><img src="../Images/89fd0f58168e6d5ea8ac7f5b8ab771d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5LeFgjfIbRsB8u-J2C2iOw.png"/></div></div></figure><h1 id="1f48" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">解释模型</h1><p id="56bd" class="pw-post-body-paragraph kd ke iq kf b kg mb ki kj kk mc km kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">可解释的人工智能今天被大肆宣传，所以我想给它一个机会。训练一个模型并信任它不是一件容易的事情。验证您的模型实际上不是纯粹偶然地神奇地对图像进行分类是一件好事，特别是如果它是一个真实的项目，并且将被推向生产环境。</p><p id="d473" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我很幸运，不久前，Lime 库在 Github 上发布了，它最近获得了对 Keras 图像分类的支持。我想试一试！</p><p id="64a3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在<a class="ae kc" href="https://github.com/olivierg13/WinesSparklingsKeras/blob/master/keras_wines_sparklings_explanations.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>上，我首先展示了一幅葡萄酒的图像，并使用我们之前训练过的 Keras 模型进行了预测:</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="305b" class="mz le iq mv b gy na nb l nc nd">show_img(wine_image[0])<br/>print(model.predict(wine_image))</span></pre><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/7dc2d1eab9d620b9021e7b00e4bfd219.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*jX-CDNxXP6VQHMWm3ykiAw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Using pyplot to show the image and printing the prediction</figcaption></figure><p id="29aa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">酷，预测是对的，用 pyplot 显示图像。下一步是使用石灰显示图像的哪些部分影响了分类决策:</p><pre class="mq mr ms mt gt mu mv mw mx aw my bi"><span id="02ba" class="mz le iq mv b gy na nb l nc nd"># Explain<br/>explanation = explainer.explain_instance(wine_image[0], model.predict, top_labels=2, hide_color=0, num_samples=1000)</span><span id="fdeb" class="mz le iq mv b gy ne nb l nc nd"># Show image with explanation's masks<br/>temp, mask = explanation.get_image_and_mask(0, positive_only=False, num_features=10, hide_rest=False)<br/>show_img(mark_boundaries(temp / 2 + 0.5, mask))</span></pre><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nh"><img src="../Images/5a784b25ec17e6908f5f390f34237f1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*3RaJgHKW3yVN8Du0oN4eiQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Positive influence in Green, Negative in Red</figcaption></figure><p id="9c8b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">很好。正如所料，葡萄酒的软木塞不同于气泡瓶(影响葡萄酒决策的绿色部分)。起泡的瓶子上的标签通常也较低，瓶子的形状较薄(红色部分影响非起泡的决定)。我用一瓶起泡葡萄酒继续分析:</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/bfcaca8ea5c423cc9b3e9e00270cbaf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*Fe7hKT6byenSp7tvmg6BaA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Positive influence in Green, Negative in Red</figcaption></figure><p id="ae98" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，正如所料，瓶子的顶部和软木塞的形状积极地影响了对起泡葡萄酒的决定，以及瓶子本身的形状影响了对非葡萄酒的决定。</p><h1 id="686e" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">结论</h1><p id="053f" class="pw-post-body-paragraph kd ke iq kf b kg mb ki kj kk mc km kn ko md kq kr ks me ku kv kw mf ky kz la ij bi translated">总之，我们有一个超级有效的 CNN 模型，用大约 100 行代码训练和保存。我们知道这不仅仅是魔法在发生，因为我们解释了图像中识别的模式。</p><p id="2b90" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有哪些可以改进的地方？</p><ul class=""><li id="ab56" class="mg mh iq kf b kg kh kk kl ko mi ks mj kw mk la ml mm mn mo bi translated">拥有更加多样化的图像数据集。老实说，这个场景很容易操作，因为背景是白色的。</li><li id="4bd0" class="mg mh iq kf b kg ni kk nj ko nk ks nl kw nm la ml mm mn mo bi translated">多解释几个图像。为解释而挑选的两张图片相当标准。解释模型做出错误预测的情况也很有趣。</li><li id="d580" class="mg mh iq kf b kg ni kk nj ko nk ks nl kw nm la ml mm mn mo bi translated">将这个模型发布为 Flask/Django API，并编写一个移动应用程序，让人们用他们手机的图片来训练它</li></ul><h1 id="1357" class="ld le iq bd lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma bi translated">链接</h1><ul class=""><li id="bc26" class="mg mh iq kf b kg mb kk mc ko nn ks no kw np la ml mm mn mo bi translated">美国有线电视新闻网(CNN):https://github.com/keras-team/keras<a class="ae kc" href="https://github.com/keras-team/keras" rel="noopener ugc nofollow" target="_blank"/></li><li id="0f0f" class="mg mh iq kf b kg ni kk nj ko nk ks nl kw nm la ml mm mn mo bi translated">Keras 博客:<a class="ae kc" href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html" rel="noopener ugc nofollow" target="_blank">https://Blog . keras . io/building-powerful-image-class ification-models-using-very-little-data . html</a></li><li id="3210" class="mg mh iq kf b kg ni kk nj ko nk ks nl kw nm la ml mm mn mo bi translated">石灰库(型号说明):<a class="ae kc" href="https://github.com/marcotcr/lime" rel="noopener ugc nofollow" target="_blank">https://github.com/marcotcr/lime</a></li><li id="ef22" class="mg mh iq kf b kg ni kk nj ko nk ks nl kw nm la ml mm mn mo bi translated">本文的代号:<a class="ae kc" href="https://github.com/olivierg13/WinesSparklingsKeras" rel="noopener ugc nofollow" target="_blank">https://github.com/olivierg13/WinesSparklingsKeras</a></li></ul></div></div>    
</body>
</html>