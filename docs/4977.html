<html>
<head>
<title>Introduction to Natural Language Processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自然语言处理导论</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-natural-language-processing-part-1-777f972cc7b3?source=collection_archive---------6-----------------------#2018-09-19">https://towardsdatascience.com/introduction-to-natural-language-processing-part-1-777f972cc7b3?source=collection_archive---------6-----------------------#2018-09-19</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="8054" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用数学破译语言</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/10fd0f35f005fb612e1236fbad3905da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ctSQ_pkWUAvXzfaL83foAw.jpeg"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Photo by <a class="ae ky" href="https://unsplash.com/@franki?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Franki Chamaki</a> on <a class="ae ky" href="https://unsplash.com/s/photos/data-has-a-better-idea?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="cf22" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">自然语言处理(NLP)是人工智能领域，涉及人类语言的处理和理解。自 20 世纪 50 年代问世以来，机器对语言的理解已经在翻译、主题建模、文档索引、信息检索和实体抽取中发挥了关键作用。</p><p id="418a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如今，它被用来驱动搜索引擎，过滤垃圾邮件，并以快速和可扩展的方式获得分析。随着计算效率和机器学习的新发展，这些系统的性能呈指数增长。今天的几个 NLP 系统甚至可以夸耀接近人类水平的对等性。</p><p id="db73" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">有了专门用于 NLP 的剩余工具和技术，现在是<em class="lv">所以</em>很容易开始。我的目标是涵盖自然语言处理的基本理论，并向您展示如何构建简单的工具来展示它们的<em class="lv">魔力</em>。查看这些后续文章，获取更多 NLP 阅读资料。</p><ul class=""><li id="c459" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/spam-or-ham-introduction-to-natural-language-processing-part-2-a0093185aebd"> <em class="lv">垃圾邮件还是火腿——一个简单的文本分类问题</em> </a></li><li id="36ce" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><a class="ae ky" href="https://medium.com/analytics-vidhya/neural-networks-for-word-embeddings-4b49e0e9c955" rel="noopener"> <em class="lv">探索单词嵌入的神经网络</em> </a></li></ul><p id="a9f5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">顺便提一下:<em class="lv">这篇文章以及后续的文章主要关注文本处理环境中的 NLP。</em></p></div><div class="ab cl mk ml hx mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="im in io ip iq"><h1 id="c3e7" class="mr ms it bd mt mu mv mw mx my mz na nb jz nc ka nd kc ne kd nf kf ng kg nh ni bi translated">我们到底是如何对语言建模的？</h1><p id="2662" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">语言是流动的。语言充满了抽象和歧义。成年后学习第二语言很难，那么机器到底是怎么做到的呢？</p><p id="1ad5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">事实是，大多数自然语言理解系统都是非常结构化的。他们将文本数据转换成数字表示，并使用复杂的数学模型来学习每个单词、短语和文档之间的依赖关系。最终用户所看到的对语言的智能理解实际上是一个大型语料库中的数百万个参数。</p><p id="d6c1" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">把文字变成数字的过程俗称<em class="lv">矢量化</em>或者<em class="lv">嵌入</em>。这些技术是将单词映射到实数向量的函数。向量形成了向量空间，这是一个代数模型，其中应用了向量加法的所有规则和相似性度量。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/3cb7d094e76adb7bc5ce6396b964a3d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3Yet-ZFumtimMuj4.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Using the word embedding technique word2vec, researchers at Google are able to quantify word relationships in an algebraic model</figcaption></figure><p id="d868" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">向量空间中两个单词之间的距离度量了它们之间的某种相似性。还可以使用向量加法来量化单词关系。上图展示了国王和王后的关系就像男人和女人的关系一样。理论上，这将意味着<code class="fe np nq nr ns b">King Vector — Queen Vector = Man Vector - Woman Vector</code></p><h2 id="1f35" class="nt ms it bd mt nu nv dn mx nw nx dp nb li ny nz nd lm oa ob nf lq oc od nh oe bi translated">每个向量的粒度不限于单词，我们也可以将字符、短语或文档映射到向量</h2><p id="b30d" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">“文档”是指与问题相关的完整的文本实体。例如，垃圾邮件分类系统会将每封邮件视为一个文档。</p><p id="4594" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文档可以映射到向量的向量，其中每个向量对应一个单词。在这种情况下，向量的向量被算法摄取，其中单词关系和单个向量的连接被用于导出含义。或者，可以将整个文档映射到一个向量。这创建了对语言的更简化的理解，但是更少依赖于数据量和计算资源。</p><p id="5a7c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文档级嵌入通常通过检查每个单词的频率来创建。这些嵌入技术依赖于<strong class="lb iu">分布假设</strong>，假设:</p><blockquote class="of"><p id="4a6e" class="og oh it bd oi oj ok ol om on oo lu dk translated">分布假设:在相同语境中使用和出现的词倾向于表达相似的意思</p></blockquote><p id="06d8" class="pw-post-body-paragraph kz la it lb b lc op ju le lf oq jx lh li or lk ll lm os lo lp lq ot ls lt lu im bi translated">让我们来看看最简单的嵌入技术之一——单词包，它用于将每个文档映射到它自己的向量上。</p><h1 id="03ae" class="mr ms it bd mt mu ou mw mx my ov na nb jz ow ka nd kc ox kd nf kf oy kg nh ni bi translated">一袋单词</h1><p id="42d1" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">由于语言过于简单，这种技术在实践中并不常用。它的使用案例主要是作为一种教育工具，旨在使 NLP 的学生轻松地进入该主题。</p><p id="6550" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们考虑以下文件。如果有帮助的话，你可以想象它们是朋友之间分享的荒谬简单的短信。</p><p id="4c8d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">文件一:击掌</strong></p><p id="6a0d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">文件二:我老了。</strong></p><p id="da08" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文件 3:她五岁了。</p><p id="2918" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们从这组文档中获得的词汇是(高，五，我，我，老，她，是)。我们现在将忽略标点符号，尽管根据我们的使用情况，将它们纳入我们的词汇表也很有意义。</p><p id="14c3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以创建一个矩阵来表示词汇表中的每个术语和文档之间的关系。矩阵中的每个元素表示该术语在特定文档中出现的次数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/8f164aee10fbe980c685f2179d4d3873.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GH9QCuPGRPWvV5Xbj6npOA.png"/></div></div></figure><p id="851b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用这个矩阵，我们可以获得每个单词以及文档的向量。我们可以将“五”矢量化为[1，0，1]，将“文档 2”矢量化为[0，0，1，1，1，0，0]。</p><p id="eed9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">单词袋并不能很好地代表语言，尤其是当你的词汇量很小的时候。它忽略了词序和词的关系，产生了稀疏向量，其中大部分是零。从这个小例子中我们还可以看到，单词“我”、“am”、“old”被映射到同一个向量。这暗示这几个字差不多，其实没什么意义。</p><p id="9c88" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里有一些关于 NLP 阅读的文章。<em class="lv"> Spam 或 Ham </em>引入了一种新的文档嵌入类型，它考虑了每个术语的相对重要性。<em class="lv">探索单词嵌入的神经网络</em>介绍了使用神经网络创建的嵌入，这两种方法都是单词袋的更实用的替代方法。</p><ul class=""><li id="b4ed" class="lw lx it lb b lc ld lf lg li ly lm lz lq ma lu mb mc md me bi translated"><a class="ae ky" rel="noopener" target="_blank" href="/spam-or-ham-introduction-to-natural-language-processing-part-2-a0093185aebd"> <em class="lv">垃圾邮件还是火腿—一个简单的文本分类问题</em> </a></li><li id="a33a" class="lw lx it lb b lc mf lf mg li mh lm mi lq mj lu mb mc md me bi translated"><a class="ae ky" href="https://medium.com/analytics-vidhya/neural-networks-for-word-embeddings-4b49e0e9c955" rel="noopener"> <em class="lv">探索单词嵌入的神经网络</em> </a></li></ul><h1 id="90a6" class="mr ms it bd mt mu ou mw mx my ov na nb jz ow ka nd kc ox kd nf kf oy kg nh ni bi translated">在我矢量化/嵌入我的文本后，现在该怎么办？</h1><p id="f744" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">数字表示允许我们使用数学模型来分析我们的文本。下一步是将这些嵌入作为分类问题中的特征。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/ca40822ca9d5bec796f57c5c22efe010.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EhJtMwKBdj_TBOItfLG2Jg.png"/></div></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">By one hot encoding the classes, we can plug this data into any type of classifier</figcaption></figure><p id="a930" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">文本数据丰富且维数高，这使得更复杂的分类器(如神经网络)成为 NLP 的理想选择。</p><h1 id="bf1d" class="mr ms it bd mt mu ou mw mx my ov na nb jz ow ka nd kc ox kd nf kf oy kg nh ni bi translated">感谢您的阅读！</h1><p id="3246" class="pw-post-body-paragraph kz la it lb b lc nj ju le lf nk jx lh li nl lk ll lm nm lo lp lq nn ls lt lu im bi translated">如果你喜欢这篇文章，可以看看我关于数据科学、数学和编程的其他文章。<a class="ae ky" href="https://medium.com/@mandygu" rel="noopener">通过 Medium </a>关注我的最新更新。😃</p><p id="c4c4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">作为一个业余爱好项目，我还在<a class="ae ky" href="http://www.dscrashcourse.com/" rel="noopener ugc nofollow" target="_blank">www.dscrashcourse.com</a>建立了一套全面的<strong class="lb iu">免费</strong>数据科学课程和练习题。</p><p id="fb9b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想支持我的写作，下次你报名参加 Coursera 课程时，可以考虑使用我的会员链接。完全公开—我从每一次注册中获得佣金，但不会对您产生额外费用。</p><p id="99bf" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">再次感谢您的阅读！📕</p></div></div>    
</body>
</html>