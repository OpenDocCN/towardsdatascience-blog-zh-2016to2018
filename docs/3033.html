<html>
<head>
<title>[ Experimental Model ] Implementing Tree Style Deep Neural Network for CIFAR 10 Classification [ Manual Back Prop with TF ]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">[实验模型]实现用于CIFAR 10分类的树形深度神经网络[带有TF的手动后撑]</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/experimental-model-implementing-tree-style-deep-neural-network-for-cifar-10-classification-1896cff85cce?source=collection_archive---------8-----------------------#2018-04-01">https://towardsdatascience.com/experimental-model-implementing-tree-style-deep-neural-network-for-cifar-10-classification-1896cff85cce?source=collection_archive---------8-----------------------#2018-04-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/d150a2db81df2a51f67e8aa1fc865e18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/1*hrsoQdyfphyss3nuwCs3rw.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Gif from <a class="ae jy" href="https://giphy.com/gifs/party-fun-christmas-3o6ZtjqdcQfuno2WPK/download" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="4461" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">所以今天，我想做一个实验模型，昨天晚上我想到了这个网络架构。一种类似树的形状的架构，但是如果你知道任何支持这种创新或网络架构的知名学术论文，请在下面评论，以便我可以提供适当的参考。</p><blockquote class="kx ky kz"><p id="ee2b" class="jz ka la kb b kc kd ke kf kg kh ki kj lb kl km kn lc kp kq kr ld kt ku kv kw ij bi translated">**更新** <a class="ae jy" href="https://medium.com/@pbaylies?source=post_header_lockup" rel="noopener"> Peter Baylies </a>向我提供了一篇论文，该论文的网络架构与本文中的相似，<a class="ae jy" href="https://arxiv.org/pdf/1802.05800.pdf" rel="noopener ugc nofollow" target="_blank">请点击</a>此处查看该论文。</p></blockquote><p id="3eb7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> <em class="la">请注意，这是一个实验模型，因此性能不是我的目标。</em> </strong></p><p id="b291" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">再一次，像往常一样让我们比较。手动反向传播方法与传统自动微分模型的比较。如果你不知道自动微分，请点击<a class="ae jy" href="https://en.wikipedia.org/wiki/Automatic_differentiation" rel="noopener ugc nofollow" target="_blank">这里</a>。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="c188" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">网络架构(基本构建模块/完整架构)</strong></p><div class="ll lm ln lo gt ab cb"><figure class="lp jr lq lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/60cf26bd68d2b7422d99ade7a96f64d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*nxmgH10MiYjOgjA-nvX7BQ.png"/></div></figure><figure class="lp jr lz lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/63118c0d75577da287d26d2bbadeadc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*FZDUIMAUsTeJB-v5mEX1LQ.png"/></div></figure></div><p id="6436" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">黑色矩形</strong> →输入图像<br/>→绿色/红色矩形 →卷积层(内核大小3)→批量归一化<br/>→T18】黄色矩形 →瓶颈卷积层(内核大小1)→批量归一化<br/> <strong class="kb ir">蓝色圆圈</strong> →加法运算(残差连接)</p><p id="2336" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">所以上面的剩余块是我们完整网络的基本块。现在，如果你看到完整的架构，你就会明白为什么我称这个网络为树状网络。(最主要是因为网络的形状像一棵树。)</p><div class="ll lm ln lo gt ab cb"><figure class="lp jr ma lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/94098451ef38fb5c0c5e7628bf9dde54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*GuGe77Is3K1RooFJ644BzA.png"/></div></figure><figure class="lp jr mb lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/009648877fbf975d88f31156933529a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*mu_tXCFC8dryz92wjNhewQ.png"/></div></figure></div><p id="e585" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">圆圈</strong> →我们上面覆盖的每个卷积残差块<br/> <strong class="kb ir">浅棕色矩形</strong> →全连通网络<br/> <strong class="kb ir">橙色矩形</strong> →软Max层</p><p id="23fb" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">所以如果我们把我们的模型旋转90度，它看起来就像一棵树！(嗯有点……)</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mc"><img src="../Images/8329d44857027238f54eb44fc472f8e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ugl6nC7VjrsPBhRT67O7fQ.png"/></div></div></figure><p id="5fc2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">另外，请注意紫色箭头，我们也将做一些不同的事情。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi md"><img src="../Images/10bbf32849739a0add74120333a5bd3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X5c5gbJWCbLqDKyEFEgJMA.png"/></div></div></figure><p id="25b9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> Layer3_a </strong> →仅将红框圈和蓝框圈的结果相加。<br/> <strong class="kb ir"> Layer3_b </strong> →仅将蓝色方框和黄色方框的结果相加。<br/> <strong class="kb ir"> Layer3_c </strong> →只将红框圈和黄框圈的结果相加。</p><p id="8d18" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">紫色箭头不同于粉红色箭头，因为我们没有把所有的变量加起来。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="2f08" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果(自动微分)</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi me"><img src="../Images/083f2effb93a4f70d3f87a8d0a921a35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*pzLGPJj2hH8mzhaURGDPng.png"/></div></figure><p id="0389" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在100 epoch上，我们可以看到模型明显过拟合，这可能是由于多种原因造成的。但众所周知，在深度学习模型中，Adam optimzers并没有那么好地概括。如果您不知道Adam optimizer，请单击此处的<a class="ae jy" href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/" rel="noopener ugc nofollow" target="_blank"/>。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="f2e2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果(破碎的散瞳反向传播)</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi me"><img src="../Images/0bd4b9faf1c1064bab0aa1bfcb7ef110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*V68ipjsXaJeEkKVEyL93Tg.png"/></div></figure><p id="08e8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于这种情况，手动反向传播是可怕的。这个模型甚至不能达到40%的准确率。</p><p id="68e7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">请注意，我们在前馈操作期间执行了批量标准化，但是，我没有在整个过程中反向传播，因此出现了中断的扩张反向传播。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="45da" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">透明度</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mf"><img src="../Images/873841c2317fd11b2156314618c71204.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TyAxnqt5Tfrj1LUb44Oz3Q.png"/></div></div></figure><p id="7dda" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">为了让这个实验更加透明，我把所有的命令日志从我的窗口提示符上传到我的Github。查看<a class="ae jy" href="https://github.com/JaeDukSeo/Only_Numpy_Basic/blob/master/treenet/auto.txt" rel="noopener ugc nofollow" target="_blank">自动微分产生的输出请点击她的</a> e，对于<a class="ae jy" href="https://github.com/JaeDukSeo/Only_Numpy_Basic/blob/master/treenet/man1.txt" rel="noopener ugc nofollow" target="_blank">手动反向传播请点击此处</a>。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="eb9f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">交互代码</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mg"><img src="../Images/6408a470ff3947c777b2a46bfaa6d2cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M7wZIYf5ePzzwv0Hn2PakQ.png"/></div></div></figure><p id="7fa5" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><em class="la">对于Google Colab，您需要一个Google帐户来查看代码，而且您不能在Google Colab中运行只读脚本，因此请在您的操场上创建一个副本。最后，我永远不会请求允许访问你在Google Drive上的文件，仅供参考。编码快乐！</em></p><p id="c69c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">要访问自动<a class="ae jy" href="https://colab.research.google.com/drive/1vIhA9ziT3-1bSLxC1xO-49VdgJLlyyDO" rel="noopener ugc nofollow" target="_blank">区分代码，请点击此处。</a> <br/>要访问手动ba <a class="ae jy" href="https://colab.research.google.com/drive/1VrhHXgFqktTdGLRqye_p22HWG8Ts7AWW" rel="noopener ugc nofollow" target="_blank"> ck繁殖模型，请点击此处。</a></p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="2e4e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">最后的话</strong></p><p id="72d4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我真的很喜欢做实验模型，它们可能不能保证性能，但它们激发了我的创造力。</p><p id="c65c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到jae.duk.seo@gmail.com给我，如果你希望看到我所有写作的列表，请<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">在这里查看我的网站</a>。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的twitter上关注我<a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>，访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或者我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>了解更多内容。如果你感兴趣的话，我还做了解耦神经网络<a class="ae jy" href="https://becominghuman.ai/only-numpy-implementing-and-comparing-combination-of-google-brains-decoupled-neural-interfaces-6712e758c1af" rel="noopener ugc nofollow" target="_blank">的比较。</a></p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="d9a2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="c401" class="mh mi iq kb b kc kd kg kh kk mj ko mk ks ml kw mm mn mo mp bi translated">文件？，W. (2018)。解压一个. tar.gz文件需要什么命令？。Askubuntu.com。检索于2018年3月30日，来自<a class="ae jy" href="https://askubuntu.com/questions/25347/what-command-do-i-need-to-unzip-extract-a-tar-gz-file" rel="noopener ugc nofollow" target="_blank">https://askubuntu . com/questions/25347/what-command-do-I-need-to-unzip-extract-a-tar-gz-file</a></li><li id="9189" class="mh mi iq kb b kc mq kg mr kk ms ko mt ks mu kw mm mn mo mp bi translated">CIFAR-10和CIFAR-100数据集。(2018).Cs.toronto.edu。检索于2018年3月30日，来自<a class="ae jy" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank">https://www.cs.toronto.edu/~kriz/cifar.html</a></li><li id="6976" class="mh mi iq kb b kc mq kg mr kk ms ko mt ks mu kw mm mn mo mp bi translated">j . brown lee(2017年)。深度学习的Adam优化算法的温和介绍-机器学习掌握。机器学习精通。检索于2018年4月1日，来自<a class="ae jy" href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/Adam-optimization-algorithm-for-deep-learning/</a></li><li id="562e" class="mh mi iq kb b kc mq kg mr kk ms ko mt ks mu kw mm mn mo mp bi translated">JaeDukSeo/Only_Numpy_Basic。(2018).GitHub。2018年4月1日检索，来自<a class="ae jy" href="https://github.com/JaeDukSeo/Only_Numpy_Basic/blob/master/treenet/man1.txt" rel="noopener ugc nofollow" target="_blank">https://github . com/JaeDukSeo/Only _ Numpy _ Basic/blob/master/treenet/man 1 . txt</a></li><li id="d22c" class="mh mi iq kb b kc mq kg mr kk ms ko mt ks mu kw mm mn mo mp bi translated">自动微分。(2018).En.wikipedia.org。于2018年4月1日检索，来自<a class="ae jy" href="https://en.wikipedia.org/wiki/Automatic_differentiation" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Automatic_differentiation</a></li></ol></div></div>    
</body>
</html>