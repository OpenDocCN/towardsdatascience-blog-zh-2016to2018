<html>
<head>
<title>Logistic Regression classifier on Census Income Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人口普查收入数据的逻辑回归分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/logistic-regression-classifier-on-census-income-data-e1dbef0b5738?source=collection_archive---------5-----------------------#2018-10-22">https://towardsdatascience.com/logistic-regression-classifier-on-census-income-data-e1dbef0b5738?source=collection_archive---------5-----------------------#2018-10-22</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/7338949c47ccb313ea051b466b1466ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wTWeAaUQv-lms51JmSTWDA.jpeg"/></div></div></figure><p id="16e2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这篇博客中，我们将分析来自 UCI 机器学习知识库的<a class="ae kz" href="https://archive.ics.uci.edu/ml/datasets/census+income" rel="noopener ugc nofollow" target="_blank">人口普查数据集</a>。</p><p id="c237" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">数据集包含三个文件:</p><ul class=""><li id="cacf" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky lf lg lh li bi translated"><a class="ae kz" href="https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data" rel="noopener ugc nofollow" target="_blank">成人数据</a>:训练数据集</li><li id="a7dc" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated"><a class="ae kz" href="https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names" rel="noopener ugc nofollow" target="_blank">成人姓名</a>:数据集描述</li><li id="79cc" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated"><a class="ae kz" href="https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test" rel="noopener ugc nofollow" target="_blank">成人测试</a>:测试数据集</li></ul><p id="1e90" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将使用<strong class="kd iu">逻辑回归</strong>来构建分类器。如果你不知道逻辑回归，你可以看看我之前的博客。</p><p id="ecf4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将看到如何建立一个实用的机器学习项目。一般来说，任何机器学习项目都需要以下步骤:</p><ul class=""><li id="a57b" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky lf lg lh li bi translated">定义问题陈述</li><li id="537d" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">探索性数据分析</li><li id="6e2d" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">训练模型</li><li id="61ac" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">微调模型</li><li id="c846" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">保存模型</li></ul><p id="96ad" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">所以让我们开始吧。</p><h1 id="d9c8" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated"><strong class="ak">定义问题陈述</strong></h1><p id="166d" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">数据包含匿名信息，如年龄、职业、教育、工人阶级等。<em class="mr">目标是训练一个二元分类器来预测收入，它有两个可能的值'&gt; 50K '和'&lt; 50K '。</em>数据集中有 48842 个实例和 14 个属性。数据很好地融合了分类值、数值值和缺失值。</p><p id="4f04" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">首先，我们将导入所需的库</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="598f" class="nb lp it mx b gy nc nd l ne nf">import numpy as np<br/>import pandas as pd<br/>import io<br/>import requests<br/>import seaborn as sns<br/>from matplotlib import pyplot as plt<br/>import pickle<br/>import os<br/>from pandas.api.types import CategoricalDtype</span><span id="3c89" class="nb lp it mx b gy ng nd l ne nf">from sklearn.base import BaseEstimator, TransformerMixin<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.model_selection import GridSearchCV<br/>from sklearn.metrics import classification_report<br/>from sklearn.metrics import confusion_matrix<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.pipeline import FeatureUnion<br/>from sklearn.model_selection import cross_val_score</span><span id="6d37" class="nb lp it mx b gy ng nd l ne nf">%matplotlib inline</span></pre><p id="9962" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">下载数据</strong></p><p id="0c87" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将编写一个小脚本来下载 URL 列表的内容，并将它们保存在一个文件夹中，而不是手动下载数据集。以后我们可以直接使用下载的数据，而不是每次都打网络。您也可以将此代码用于任何机器学习项目。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="8190" class="nb lp it mx b gy nc nd l ne nf">def load_dataset(path, urls):<br/>    if not os.path.exists(path):<br/>        os.mkdir(path)<br/><br/>    for url in urls:<br/>        data = requests.get(url).content<br/>        filename = os.path.join(path, os.path.basename(url))<br/>        with open(filename, "wb") as file:<br/>            file.write(data)</span></pre><p id="ab1a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将在当前工作目录中创建一个<code class="fe nh ni nj mx b">data</code>文件夹，并存储 URL 的内容。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="34cf" class="nb lp it mx b gy nc nd l ne nf">urls = ["http://archive.ics.uci.edu/ml/machine-learning-  databases/adult/adult.data",<br/>        "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names",<br/>        "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test"]</span><span id="799c" class="nb lp it mx b gy ng nd l ne nf">load_dataset('data', urls)</span></pre><p id="e91d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来，我们使用<code class="fe nh ni nj mx b">read_csv</code>函数将数据加载到一个<code class="fe nh ni nj mx b">pandas</code>数据帧中。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="226b" class="nb lp it mx b gy nc nd l ne nf">columns = ["age", "workClass", "fnlwgt", "education", "education-<br/>           num","marital-status", "occupation", "relationship",<br/>          "race", "sex", "capital-gain", "capital-loss", "hours-per-<br/>           week", "native-country", "income"]</span><span id="a1f6" class="nb lp it mx b gy ng nd l ne nf">train_data = pd.read_csv('data/adult.data', names=columns, <br/>             sep=' *, *', na_values='?')<br/>test_data  = pd.read_csv('data/adult.test', names=columns, <br/>             sep=' *, *', skiprows=1, na_values='?')</span></pre><p id="cf7f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">数据值前后有一些空格。为了修剪所有的空白，我们使用分隔符<code class="fe nh ni nj mx b">‘ *, *’</code>。测试数据集有一个奇怪的第一行，因此我们使用<code class="fe nh ni nj mx b">skiprows=1</code>跳过这一行。数据集中缺失的值用<code class="fe nh ni nj mx b">?</code>表示</p><p id="8c52" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来，我们将探索数据。这是构建模型之前的重要一步。</p><h1 id="f3bf" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">探索性数据分析</h1><p id="ef33" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">让我们使用<code class="fe nh ni nj mx b">train_data.info()</code>获得更多关于训练数据的信息</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="9442" class="nb lp it mx b gy nc nd l ne nf">RangeIndex: 32561 entries, 0 to 32560 <br/>Data columns (total 15 columns): <br/>age               32561 non-null int64 <br/>workClass         30725 non-null object <br/>fnlwgt            32561 non-null int64 <br/>education         32561 non-null object <br/>education-num     32561 non-null int64 <br/>marital-status    32561 non-null object <br/>occupation        30718 non-null object <br/>relationship      32561 non-null object <br/>race              32561 non-null object <br/>sex               32561 non-null object <br/>capital-gain      32561 non-null int64 <br/>capital-loss      32561 non-null int64 <br/>hours-per-week    32561 non-null int64 <br/>native-country    31978 non-null object <br/>income            32561 non-null object</span></pre><p id="b573" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">观察结果</strong></p><ul class=""><li id="9d60" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky lf lg lh li bi translated">训练数据集中有<strong class="kd iu"> 32561 </strong>个样本</li><li id="6cb2" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">数据集中既有分类列也有数值列</li><li id="e15a" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">列<strong class="kd iu">工作类别</strong>、<strong class="kd iu">职业</strong>、<strong class="kd iu">本国</strong>有缺失值</li></ul><p id="bb99" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">类似地，对于测试数据集</p><ul class=""><li id="0a86" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky lf lg lh li bi translated">有<strong class="kd iu"> 16281 </strong>个样品</li><li id="4ba0" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">没有<strong class="kd iu">没有</strong>丢失的值</li></ul><p id="204a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们借助一些可视化工具来看看数字和分类数据。</p><h2 id="b79c" class="nb lp it bd lq nk nl dn lu nm nn dp ly km no np mc kq nq nr mg ku ns nt mk nu bi translated"><strong class="ak">处理数值列</strong></h2><p id="e07a" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">我们使用<code class="fe nh ni nj mx b">select_dtypes</code>函数选择数字列。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="fffa" class="nb lp it mx b gy nc nd l ne nf">num_attributes = train_data.select_dtypes(include=['int'])<br/>print(num_attributes.columns)</span><span id="c7a2" class="nb lp it mx b gy ng nd l ne nf">['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',        'hours-per-week']</span></pre><p id="1723" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">变量<strong class="kd iu">年龄</strong>、<strong class="kd iu">每周工作时间</strong>不言自明。</p><ul class=""><li id="bbbe" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky lf lg lh li bi translated"><strong class="kd iu"> fnlwgt </strong>:取样重量</li><li id="c359" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated"><strong class="kd iu"> education-num </strong>:受教育的总年限</li><li id="76c2" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated"><strong class="kd iu">资本收益/资本损失</strong>:工资以外的投资收入</li></ul><p id="ecb0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> fnlwgt </strong>与目标变量<strong class="kd iu">收入</strong>无关，在建立模型之前将被移除</p><p id="e32a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">数据可视化</strong></p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="176d" class="nb lp it mx b gy nc nd l ne nf">num_attributes.hist(figsize=(10,10))</span></pre><figure class="ms mt mu mv gt ju gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/e91b7df93107786f10323e8b0e8483c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*3emuIPUm3cGqHXCFVYZetw.png"/></div></figure><p id="8f91" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">使用<code class="fe nh ni nj mx b">train_data.describe()</code>可以收集更多关于数据的信息</p><figure class="ms mt mu mv gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nw"><img src="../Images/bf37b5d3f9297d322fe32d3e8aaa9a85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VPEN27xJiPmsG9uDv7VZeQ.png"/></div></div></figure><p id="ba96" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">观察结果</strong></p><ul class=""><li id="cc14" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky lf lg lh li bi translated">数字属性都没有缺失值</li><li id="4a91" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">这些值在不同的范围内。许多机器学习模型要求值在相同的范围内。我们将使用 sklearn 库中的<a class="ae kz" href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank"> StandardScaler </a>来缩放特性。</li></ul><h2 id="cb99" class="nb lp it bd lq nk nl dn lu nm nn dp ly km no np mc kq nq nr mg ku ns nt mk nu bi translated">处理分类列</h2><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="7cac" class="nb lp it mx b gy nc nd l ne nf">cat_attributes = train_data.select_dtypes(include=['object'])<br/>print(cat_attributes.columns)</span><span id="c09a" class="nb lp it mx b gy ng nd l ne nf">['workClass', 'education', 'marital-status', 'occupation',        'relationship', 'race', 'sex', 'native-country', 'income']</span></pre><p id="4beb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">数据可视化</strong></p><p id="e201" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将使用 seaborn 包中的<code class="fe nh ni nj mx b">countplot</code>。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="2bae" class="nb lp it mx b gy nc nd l ne nf">sns.countplot(y='workClass', hue='income', data = cat_attributes)</span></pre><figure class="ms mt mu mv gt ju gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/3a2e8cd055fef46bbcc3e875c86710b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*fviGkONFBANGLXqpC5hIRQ.png"/></div></figure><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="a5d1" class="nb lp it mx b gy nc nd l ne nf">sns.countplot(y='occupation', hue='income', data = cat_attributes)</span></pre><figure class="ms mt mu mv gt ju gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/abc8cd8209ec00f55aa6c639c456a65e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*E5XyiAQLaodICDsZBplZ3A.png"/></div></figure><p id="c94f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">观察结果</strong></p><ul class=""><li id="4d8c" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky lf lg lh li bi translated">列<strong class="kd iu"> education </strong>只是列<strong class="kd iu"> education-num </strong>的字符串表示。我们将删除<strong class="kd iu">教育</strong>栏目。</li><li id="496e" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated">变量<strong class="kd iu">工作类别</strong>、<strong class="kd iu">职业</strong>、<strong class="kd iu">母国</strong>有缺失值。我们将用该列中<strong class="kd iu">出现频率最高的</strong>值替换每列中缺失的值。</li></ul><p id="0394" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们需要不同地处理数字和分类属性。数字属性需要缩放，而对于分类列，我们需要填充缺失的值，然后将分类值编码成数字值。为了应用这些转换序列，我们将使用 sklearn 的<a class="ae kz" href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html" rel="noopener ugc nofollow" target="_blank">管道</a>类。我们还将构建可直接用于管道的定制变压器。</p><h1 id="fb57" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">创建管道</h1><p id="3351" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">sklearn 内置了很多变形金刚。然而，如果内置的转换器不能为您完成工作，您可以构建一个定制的转换器。你需要做的就是继承<a class="ae kz" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html" rel="noopener ugc nofollow" target="_blank"> BaseEstimator </a>和<a class="ae kz" href="http://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html" rel="noopener ugc nofollow" target="_blank"> TransformerMixin </a>类。您还需要实现<strong class="kd iu"> fit </strong>和<strong class="kd iu"> transform </strong>方法。</p><ul class=""><li id="6935" class="la lb it kd b ke kf ki kj km lc kq ld ku le ky lf lg lh li bi translated"><strong class="kd iu"> fit: </strong>应该返回 self 的一个实例</li><li id="9e49" class="la lb it kd b ke lj ki lk km ll kq lm ku ln ky lf lg lh li bi translated"><strong class="kd iu">转换:</strong>转换逻辑可在此添加</li></ul><p id="6efc" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">列选择器管道</strong></p><p id="537a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">sklearn 没有提供库来直接操作 pandas 数据帧。我们将编写自己的自定义转换器，它将选择相应的属性(数字或分类)</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="d3cd" class="nb lp it mx b gy nc nd l ne nf">class ColumnsSelector(BaseEstimator, TransformerMixin):<br/>  <br/>  def __init__(self, type):<br/>    self.type = type<br/>  <br/>  def fit(self, X, y=None):<br/>    return self<br/>  <br/>  def transform(self,X):<br/>    return X.select_dtypes(include=[self.type])</span></pre><p id="0ac2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">数字数据管道</strong></p><p id="d352" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们使用上面定义的<strong class="kd iu">列选择器</strong>转换器选择数字属性，然后使用标准缩放器缩放数值。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="0b8f" class="nb lp it mx b gy nc nd l ne nf">num_pipeline = Pipeline(steps=[<br/>    ("num_attr_selector", ColumnsSelector(type='int')),<br/>    ("scaler", StandardScaler())<br/>])</span></pre><p id="dabe" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果我们调用<code class="fe nh ni nj mx b">num_pipeline</code>的<code class="fe nh ni nj mx b">fit</code>和<code class="fe nh ni nj mx b">transform</code>方法，它会在内部调用管道中定义的所有转换器的<code class="fe nh ni nj mx b">fit</code>和<code class="fe nh ni nj mx b">transform</code>方法。在这种情况下，列选择器和标准缩放器转换器。</p><p id="dfd4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">分类数据管道</strong></p><p id="c50a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们需要替换分类列中缺失的值。我们将用每列中出现频率最高的值替换缺失的值。sklearn 带有<a class="ae kz" href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html#" rel="noopener ugc nofollow" target="_blank">估算器</a>来处理缺失值。然而，<strong class="kd iu">输入器</strong>仅适用于数值。我们将编写一个定制的转换器，它将接受我们需要替换缺失值的列的列表，以及用于填充缺失值的策略</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="817f" class="nb lp it mx b gy nc nd l ne nf">class CategoricalImputer(BaseEstimator, TransformerMixin):<br/>  <br/>  def __init__(self, columns = None, strategy='most_frequent'):<br/>    self.columns = columns<br/>    self.strategy = strategy<br/>    <br/>    <br/>  def fit(self,X, y=None):<br/>    if self.columns is None:<br/>      self.columns = X.columns<br/>    <br/>    if self.strategy is 'most_frequent':<br/>      self.fill = {column: X[column].value_counts().index[0] for <br/>        column in self.columns}<br/>    else:<br/>      self.fill ={column: '0' for column in self.columns}<br/>      <br/>    return self<br/>      <br/>  def transform(self,X):<br/>    X_copy = X.copy()<br/>    for column in self.columns:<br/>      X_copy[column] = X_copy[column].fillna(self.fill[column])<br/>    return X_copy</span></pre><p id="f911" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">所有的机器学习模型都需要数值。我们将使用<a class="ae kz" href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html" rel="noopener ugc nofollow" target="_blank"> pd.get_dummies </a>将分类值转换成数值。这类似于使用<a class="ae kz" href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html" rel="noopener ugc nofollow" target="_blank"> OneHotEncoder </a>，只是 OneHotEncoder 需要数字列。</p><p id="5072" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们需要在使用 pd.get_dummies 之前合并训练和测试数据集，因为测试数据集中可能存在训练数据集中不存在的类。为此，在<code class="fe nh ni nj mx b">fit</code>方法中，我们将连接训练和测试数据集，并找出一列的所有可能值。在<code class="fe nh ni nj mx b">transform</code>方法中，我们将把每一列转换成<a class="ae kz" href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.api.types.CategoricalDtype.html" rel="noopener ugc nofollow" target="_blank">分类</a>类型，并指定该列可以接受的类别列表。get_dummies 将为该列的类别列表中不存在的类别创建一个全零的列。</p><p id="485c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">转换器还接受一个参数<code class="fe nh ni nj mx b">dropFirst</code>,它指示我们是否应该在使用 pd.get_dummies 创建虚拟列之后删除第一列。我们应该删除第一列以避免多重共线性。默认情况下，该值设置为<code class="fe nh ni nj mx b">True</code></p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="b64c" class="nb lp it mx b gy nc nd l ne nf">class CategoricalEncoder(BaseEstimator, TransformerMixin):<br/>  <br/>  def __init__(self, dropFirst=True):<br/>    self.categories=dict()<br/>    self.dropFirst=dropFirst<br/>    <br/>  def fit(self, X, y=None):<br/>    join_df = pd.concat([train_data, test_data])<br/>    join_df = join_df.select_dtypes(include=['object'])<br/>    for column in join_df.columns:<br/>      self.categories[column] = <br/>          join_df[column].value_counts().index.tolist()<br/>    return self<br/>    <br/>  def transform(self, X):<br/>    X_copy = X.copy()<br/>    X_copy = X_copy.select_dtypes(include=['object'])<br/>    for column in X_copy.columns:<br/>      X_copy[column] = X_copy[column].astype({column:<br/>                CategoricalDtype(self.categories[column])})<br/>    return pd.get_dummies(X_copy, drop_first=self.dropFirst)</span></pre><p id="fce6" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">完整的分类管道</strong></p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="a835" class="nb lp it mx b gy nc nd l ne nf">cat_pipeline = Pipeline(steps=[<br/>    ("cat_attr_selector", ColumnsSelector(type='object')),<br/>    ("cat_imputer", CategoricalImputer(columns=<br/>          ['workClass','occupation', 'native-country'])),<br/>    ("encoder", CategoricalEncoder(dropFirst=True))<br/>])</span></pre><p id="43e1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">完成管道</strong></p><p id="be5e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们有两条变压器管道，即<strong class="kd iu"> num_pipeline </strong>和<strong class="kd iu"> cat_pipeline </strong>。我们可以使用<a class="ae kz" href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html" rel="noopener ugc nofollow" target="_blank">功能联合</a>来合并它们</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="c400" class="nb lp it mx b gy nc nd l ne nf">full_pipeline = FeatureUnion([("num_pipe", num_pipeline), <br/>                ("cat_pipeline", cat_pipeline)])</span></pre><p id="431e" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在我们有了构建模型的所有管道，让我们为模型准备数据并构建它。</p><p id="5698" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将删除不需要的列</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="4745" class="nb lp it mx b gy nc nd l ne nf">train_data.drop(['fnlwgt', 'education'], axis=1, inplace=True)<br/>test_data.drop(['fnlwgt', 'education'], axis=1, inplace=True)</span></pre><h1 id="5d4c" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">训练模型</h1><p id="c967" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">我们将创建训练数据集的副本，并分离特征向量和目标值。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="4276" class="nb lp it mx b gy nc nd l ne nf">train_copy = train_data.copy()<br/>train_copy["income"] = train_copy["income"].apply(lambda x:0 if <br/>                        x=='&lt;=50K' else 1)</span><span id="3bf7" class="nb lp it mx b gy ng nd l ne nf">X_train = train_copy.drop('income', axis =1)<br/>Y_train = train_copy['income']</span></pre><p id="0852" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">接下来，我们将<code class="fe nh ni nj mx b">X_train</code>传递给我们构建的<code class="fe nh ni nj mx b">full_pipeline</code>。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="5940" class="nb lp it mx b gy nc nd l ne nf">X_train_processed=full_pipeline.fit_transform(X_train)</span><span id="5540" class="nb lp it mx b gy ng nd l ne nf">model = LogisticRegression(random_state=0)<br/>model.fit(X_train_processed, Y_train)</span></pre><h2 id="2d95" class="nb lp it bd lq nk nl dn lu nm nn dp ly km no np mc kq nq nr mg ku ns nt mk nu bi translated">测试模型</h2><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="187a" class="nb lp it mx b gy nc nd l ne nf">test_copy = test_data.copy()<br/>test_copy["income"] = test_copy["income"].apply(lambda x:0 if <br/>                      x=='&lt;=50K.' else 1)</span><span id="d35d" class="nb lp it mx b gy ng nd l ne nf">X_test = test_copy.drop('income', axis =1)<br/>Y_test = test_copy['income']</span></pre><p id="acd7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将应用于训练数据集的相同变换应用于测试数据集。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="1ed9" class="nb lp it mx b gy nc nd l ne nf">X_test_processed = full_pipeline.fit_transform(X_test)</span><span id="9259" class="nb lp it mx b gy ng nd l ne nf">predicted_classes = model.predict(X_test_processed)</span></pre><h1 id="ba9d" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">模型评估</h1><p id="6a46" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">我们将使用来自 sklearn 的<a class="ae kz" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html" rel="noopener ugc nofollow" target="_blank"> accuracy_score </a>来确定模型的准确性</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="9927" class="nb lp it mx b gy nc nd l ne nf">accuracy_score(predicted_classes, Y_test.values)</span></pre><p id="fe3c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">准确率为 85.2%</p><p id="2d70" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">让我们画出<a class="ae kz" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html" rel="noopener ugc nofollow" target="_blank">混淆矩阵</a>。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="407c" class="nb lp it mx b gy nc nd l ne nf">cfm = confusion_matrix(predicted_classes, Y_test.values)<br/>sns.heatmap(cfm, annot=True)<br/>plt.xlabel('Predicted classes')<br/>plt.ylabel('Actual classes')</span></pre><figure class="ms mt mu mv gt ju gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/921810e79168349e42ce32074dd6c710.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*QpVRhl4ohUk6V2ZPvxVOVQ.png"/></div></figure><p id="0d0a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">X 轴代表预测类，Y 轴代表实际类。我们如何解读混淆矩阵？<code class="fe nh ni nj mx b">1.2e+04</code>当实际类别为 0 时，模型正确预测类别为 0 的次数。同样，对于其余的情况也可以得出结论。</p><h1 id="c600" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">交叉验证</h1><p id="f9a3" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">我们将使用<a class="ae kz" href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html" rel="noopener ugc nofollow" target="_blank">stratified fold</a>将我们的数据集分成 k 个文件夹。在每次迭代中，<code class="fe nh ni nj mx b">k-1</code>个折叠被用作训练集，剩余的折叠被用作验证。我们使用 StratifiedKFold，因为它保留了每个类中样本的百分比。</p><p id="0763" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果我们使用<a class="ae kz" href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html" rel="noopener ugc nofollow" target="_blank"> KFold </a>，我们可能会面临引入采样偏差的风险，即训练集可能包含大量收入大于 50K 的样本，而测试集包含更多收入小于 50K 的样本。在这种情况下，从训练数据构建的模型将不能很好地适用于测试数据集。而 StratifiedKFold 将确保在训练和测试数据集中每个类都有足够的样本。</p><p id="a812" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将使用<a class="ae kz" href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html" rel="noopener ugc nofollow" target="_blank"> cross_val_score </a>进行交叉验证。参数<code class="fe nh ni nj mx b">cv</code>决定交叉验证策略。如果整数值被传递给<code class="fe nh ni nj mx b">cv</code>，则使用 StatifiedKFold</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="2813" class="nb lp it mx b gy nc nd l ne nf">cross_val_model = LogisticRegression(random_state=0)<br/>scores = cross_val_score(cross_val_model, X_train_processed, <br/>         Y_train, cv=5)<br/>print(np.mean(scores))</span></pre><p id="fed2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们将每次迭代中获得的所有得分的平均值作为我们模型的最终得分。</p><p id="f0d3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">交叉验证的准确率为 85.0%。</p><h1 id="5b92" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">微调模型</h1><p id="2b25" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">我们可以通过调整参数来微调我们的模型。sklearn 附带了<a class="ae kz" href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" rel="noopener ugc nofollow" target="_blank"> GridSearchCV </a>来对估计器的指定参数值进行彻底搜索。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="d1dd" class="nb lp it mx b gy nc nd l ne nf"># penalty specifies the norm in the penalization<br/>penalty = ['l1', 'l2']</span><span id="dabf" class="nb lp it mx b gy ng nd l ne nf"># C is the inverese of regularization parameter<br/>C = np.logspace(0, 4, 10)</span><span id="a205" class="nb lp it mx b gy ng nd l ne nf">random_state=[0]</span><span id="f733" class="nb lp it mx b gy ng nd l ne nf"># creating a dictionary of hyperparameters<br/>hyperparameters = dict(C=C, penalty=penalty, <br/>                  random_state=random_state)</span></pre><p id="6bbe" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">使用 GridSearchCV 寻找最佳参数</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="df0a" class="nb lp it mx b gy nc nd l ne nf">clf = GridSearchCV(estimator = model, param_grid = hyperparameters, <br/>                   cv=5)<br/>best_model = clf.fit(X_train_processed, Y_train)<br/>print('Best Penalty:', best_model.best_estimator_.get_params() ['penalty'])<br/>print('Best C:', best_model.best_estimator_.get_params()['C'])</span></pre><p id="9cfe" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最佳参数是</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="4963" class="nb lp it mx b gy nc nd l ne nf">Best Penalty: l1 <br/>Best C: 1.0</span></pre><p id="ff9c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">使用最佳模型进行预测</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="026e" class="nb lp it mx b gy nc nd l ne nf">best_predicted_values = best_model.predict(X_test_processed)<br/>accuracy_score(best_predicted_values, Y_test.values)</span></pre><p id="d2ff" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">最佳参数模型的准确率为 85.2%</p><h1 id="0feb" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">保存模型</h1><p id="4eda" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">我们已经完成了创建和测试模型的所有艰苦工作。如果我们可以保存模型以备将来使用，而不是重新训练它，那就太好了。我们将把我们的模型保存在<a class="ae kz" href="https://docs.python.org/2/library/pickle.html" rel="noopener ugc nofollow" target="_blank"> pickle </a>中。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="0f04" class="nb lp it mx b gy nc nd l ne nf">filename = 'final_model.sav'<br/>pickle.dump(model, open(filename, 'wb'))</span></pre><p id="1fc7" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">从 pickle 加载模型</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="c150" class="nb lp it mx b gy nc nd l ne nf">saved_model = pickle.load(open(filename, 'rb')) </span></pre><p id="7134" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在我们可以使用该模型进行预测。</p><p id="a030" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这个博客到此为止。完整的 Jupyter 笔记本可以在这里找到。</p><h1 id="d526" class="lo lp it bd lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml bi translated">结束语</h1><p id="2915" class="pw-post-body-paragraph kb kc it kd b ke mm kg kh ki mn kk kl km mo ko kp kq mp ks kt ku mq kw kx ky im bi translated">我们已经学会了建立一个完整的机器学习项目。在这个过程中，我们构建了可以与 sklearn 的管道类一起使用的自定义转换器。我们还学会了微调我们的模型，并保存它以备将来使用。</p><p id="0577" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">如果有什么地方我可以做得更好，请告诉我。</p><p id="56ff" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">感谢阅读！！</p></div></div>    
</body>
</html>