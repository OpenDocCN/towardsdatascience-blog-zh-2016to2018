# 为什么 AdamW 如此重要

> 原文：<https://towardsdatascience.com/why-adamw-matters-736223f31b5d?source=collection_archive---------1----------------------->

![](img/317fb997be23919f7acc45682ad5d655.png)

When you find yourself in a rocky terrain, take small steps ;) [Mount Sinai, Egypt]

## 像 Adam 这样的自适应优化器已经成为训练神经网络的默认选择。然而，当以最先进的结果为目标时，研究人员通常更喜欢带动量的随机梯度下降(SGD ),因为已经观察到用 Adam 训练的模型也不会泛化。

来自德国弗赖堡大学的 Ilya Loshchilov 和 Frank Hutter 最近发表了他们的[文章](https://arxiv.org/abs/1711.05101)“在 Adam 中固定权重衰减正则化”，其中他们证明了 L2 正则化对于自适应算法的效果明显不如 SGD。他们提出了 Adam 的一个改进版本，称为 AdamW，它产生的模型概括得更好，因此能够与 SGD 竞争，同时训练得更快。

**读完这篇文章的摘要，你会理解 1) Adam 是如何工作的，2)什么是 L2 正则化，为什么使用它，以及 3)为什么改进版 AdamW 比标准 Adam 产生更好的概化模型。**

# ①亚当

试着想象最小化一个神经网络的成本函数 *f* 就像在山上走下山坡:你随机初始化你的网络的权重，这意味着从山上的一个随机点开始。你的目标是尽可能快地达到成本函数的最小值(谷值)。在每一步之前，你计算梯度 *∇ f* (确定山坡最向哪个方向倾斜)并向相反方向走一步:新的权重 *x(t)* (按照文章的注释)等于旧的权重 *x(t-1)* 减去梯度乘以学习速率α:

> x(t)= x(t-1) — α ∇ f

按照这个步骤，你最终会到达山谷(或至少是当地的最小值)，然而，当你走在坡度变化不大的草地上时，你可能想迈出更大、更大胆的步伐，或者当你爬下坡度不断变化的岩石时，迈出更小的步伐。Adams 为您做到了这一点:当梯度变化不大时大步前进，当梯度变化很快时小步前进(单独调整每种重量的步长)。

让我们了解亚当是如何工作的(暂时忽略彩色部分):

![](img/a7ef3bedecf398572a9d16f608d27519.png)

Taken from “Fixing Weight Decay Regularization in Adam” by Ilya Loshchilov, Frank Hutter.

Adam 跟踪梯度的(指数移动)平均值(称为一阶矩，从现在开始表示为 *m* )和梯度的平方(称为原始二阶矩，从现在开始表示为 *v* ) *。*

在每个时间步中，计算梯度*g=∇f*【x(t-1)】,然后计算移动平均值:

> m(t) = β1 m(t-1) + (1-β1) g(t)
> 
> v(t) = β2 v(t-1) + (1-β2) g(t)

参数β1(即 0.9)和β2(即 0.999)控制平均值衰减的速度，即“过去多长时间内对梯度(平方)进行平均”。按以下方式阅读方程式:“新平均值等于旧平均值的 0.9 倍(或梯度平方的 0.999 倍)加上当前梯度的 0.1 倍”。对于每一个时间步长，旧的梯度再乘以 0.9，这意味着它们对移动平均值的贡献越来越小。

请注意，在第 9 行和第 10 行中，平均值由 *(1-β^t)* 重新调整，其中 *t* 是时间步长。为了理解为什么这是必要的，考虑第一个时间步长并记住 *m(0)* 和 *v(0)* 被初始化为 0。这意味着第一个时间步长后的平均值为*m(1)*= 0.9 0+0.1*g(1)*= 0.1*g(1)*。但是，第一个时间步长之后的平均值应该正好是 g(1)，这是将 *m(1)* 除以(1–0.9)= 0.1 得到的结果。

为简单起见，我们设置 *η=1* (学习率计划乘数)，并将所有内容放在第 12 行:

当向下“下山”一步时，步长通过将学习速率α乘以 *m(t)* 并除以 *v(t)* 的根来调整(此时我们忽略帽子^)。

> x(t)= x(t-1)-αm(t)/[sqrt(v(t))+ϵ]

记住一个随机变量 *x* 的方差定义为*Var(x)=<x>-<x>*其中 *< >* 为期望值。梯度平方的指数移动平均值被称为无中心方差，因为我们没有减去梯度平均值的平方。

方差量化了梯度围绕其平均值变化的程度。如果梯度保持近似恒定，因为我们“走在草地上”，梯度的方差近似为 0，无中心方差 *v(t)* 近似等于 *m(t)* 。这就意味着 *m(t) / sqrt(v(t))* 在 1 左右，步长“下山”的顺序是 *α* 。

另一方面，如果梯度快速变化， *sqrt(v(t))* 比 *m(t)* 大得多，因此“下山”的步长比 *α* 小得多。

总之，这意味着 Adam 能够通过估计梯度的一阶和二阶矩来为每个个体权重调整步长。当梯度变化不大且“我们在下山时不必小心”时，步长为 *α、*的数量级，如果它们发生变化且“我们需要小心不要走错方向”，则步长要小得多。

在下一节中，我将解释什么是 L2 正则化，在最后一节中，我将总结作者的研究结果，即为什么使用 L2 正则化的 Adam 产生的模型比使用 SGD 训练的模型更差，以及他们如何解决这个问题。

# 2) L2 正则化和权重衰减

L2 正则化或权重衰减背后的思想是，观察到具有较小权重的网络(所有其他条件相同)过拟合较少且泛化能力较好。如果你不熟悉这个概念，我建议你读一读迈克尔·尼尔森的伟大的电子书。

当然，大重量仍然是可能的，但前提是它们能显著减少损失。每步的权重衰减率 *w* 定义了最小化原始损失函数(如果选择小的 *w* 则更重要)和找到小权重(如果选择大的 *w* 则更重要)的相对重要性。如果如前所述比较权重的更新(新权重等于旧权重减去学习率乘以梯度)

> x(t) = x(t-1) — α ∇ f[x(t-1)]

重量衰减的版本

> x(t) = (1-w) x(t-1) — α ∇ f[x(t-1)]

您会注意到附加项 *-w x(t-1)* ，它指数衰减权重 *x* ，从而迫使网络学习更小的权重。

通常，不是执行*权重衰减，而是定义*正则化损失函数( *L2 正则化*):

> f _ reg[x(t-1)]= f[x(t-1)]+w '/2x(t-1)

如果你计算这个正则化损失函数的梯度

> ∇f _ reg[x(t-1)]=∇f[x(t-1)]+w ' x(t-1)

并更新权重

> x(t) = x(t-1) — α ∇ f_reg[x(t-1)]
> 
> x(t)= x(t-1)—α∇f[x(t-1)]—αw ' x(t-1)

如果定义 *w' = w/α，你会发现这相当于重量衰减。*

**常见的深度学习库通常实现后者的 L2 正则化。然而，** [**文章**](https://arxiv.org/abs/1711.05101) **显示，这种等价只适用于 SGD，不适用于 Adam 这样的自适应优化器！**

在这篇文章的最后一部分，我将解释为什么 L2 正则化不等同于 Adam 的权重衰减，Adam 和 AdamW 之间的区别是什么，以及为什么使用 AdamW 可以给出更好的概化模型。

# 3)阿达姆

让我们再来看看亚当算法。

![](img/a7ef3bedecf398572a9d16f608d27519.png)

Taken from “Fixing Weight Decay Regularization in Adam” by Ilya Loshchilov, Frank Hutter.

第 6 行中的紫色项显示了 Adam(不是 AdamW)中的 L2 正则化，因为它通常在深度学习库中实现。正则化项被添加到成本函数中，然后该成本函数被导出以计算梯度 *g* 。然而，如果在这一点上添加权重衰减项，梯度及其平方的移动平均值( *m* 和 *v* )不仅跟踪损失函数*的梯度，还跟踪正则化项*！

如果我们将第 6、7 和 8 行插入第 12 行(现在忽略帽子^，因为 *t* 被假定为大，因此 *β^t=0* )，权重的更新如下所示:

![](img/7d3efeb9e512b6db5f40e84506f96e04.png)

**如您所见，重量衰减也通过 *sqrt(v)* 进行归一化。如果某个重量的梯度很大(或变化很大)，则相应的 *v* 也很大，并且重量比梯度小且变化缓慢的重量调整得少！这意味着 L2 正则化不能像预期的那样工作，也不如 SGD 有效，这就是为什么 SGD 产生的模型概括得更好，并且已经用于大多数最新的结果。**

因此，作者提出了 Adam 的改进版本，称为 AdamW，其中权重衰减仅在控制参数式步长之后执行(参见第 12 行中的绿色项)。权重衰减或正则化项不会在移动平均值中结束，因此仅与权重本身成比例。作者通过实验表明，AdamW 产生更好的训练损失，并且模型比用 Adam 训练的模型概括得更好，从而允许新版本与具有动量的随机梯度下降竞争。这意味着在未来，研究人员和工程师可能不必经常在 SGD 和 Adam 之间切换。请记住这一点，下次您训练模型时:)