<html>
<head>
<title>Using Markov Chain Monte Carlo method for project estimation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用马尔可夫链蒙特卡罗方法进行项目估算</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/using-markov-chain-monte-carlo-method-for-project-estimation-cd641f8038ce?source=collection_archive---------14-----------------------#2018-12-16">https://towardsdatascience.com/using-markov-chain-monte-carlo-method-for-project-estimation-cd641f8038ce?source=collection_archive---------14-----------------------#2018-12-16</a></blockquote><div><div class="fc if ig ih ii ij"/><div class="ik il im in io"><div class=""/><div class=""><h2 id="84c7" class="pw-subtitle-paragraph jo iq ir bd b jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf dk translated">用张量流概率进行哈密顿取样</h2></div><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj kg"><img src="../Images/5dac3be914063f7debcd2acb59a04ea9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kUcXujZzeuHD0uHVCBGDng.jpeg"/></div></div><figcaption class="ks kt gk gi gj ku kv bd b be z dk">Free photo from <a class="ae kw" href="https://pixabay.com" rel="noopener ugc nofollow" target="_blank">https://pixabay.com</a></figcaption></figure><p id="9944" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">我收到的对<a class="ae kw" rel="noopener" target="_blank" href="/agile-estimation-part-ii-80bba09b9fc1">之前项目评估</a>工作的一种批评是对数正态分布有短尾巴。这是真的，尽管对数正态分布有很多好处。原因很简单:当将数据拟合到分布形状时，我们选择最可能的参数μμ和σσ。这种方法，无论多么简单，总是导致短尾巴，特别是对于我们拥有的少量数据。事实上，对数正态分布的参数可能不同于我们基于五个数据点得到的最可能的参数。合适的方法是获得预测和参数的联合分布，然后根据参数进行边缘化。在正态分布的情况下，我们将得到具有漂亮长尾的学生 t 分布。对于对数正态分布，我们会得到一个更复杂的分布，但也有长尾。</p><p id="4533" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">为了提醒您我们正在处理的问题，我们的任务是根据历史数据来估计一个敏捷迭代/sprint 中可以容纳的故事点的数量。特别是，我们感兴趣的是找到我们可以在一次迭代中完成的故事点的数量，并且有 95%的置信度。</p><p id="2cc0" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">我们将从定义大小为 1 的样本的似然函数开始:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj lt"><img src="../Images/90f9dcc51521b4ecbc7174a55a65a89c.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*ty_MeJlTESNKBYiMQOJyCQ.png"/></div></figure><p id="ab61" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">让我们选择μ和σ的先验。</p><p id="28dc" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">对于σ，我们选择非信息先验:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj lu"><img src="../Images/be04192636a344d61927cf8d6e8794d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:378/format:webp/1*uBgrTWRXD5u0P6XdqigqiA.png"/></div></figure><p id="f229" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">对于μ，我们选择共轭先验，它是具有 L2 正则化超参数λ的正态分布:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj lv"><img src="../Images/95e33117031661f8f1eb75346512f812.png" data-original-src="https://miro.medium.com/v2/resize:fit:492/format:webp/1*Z6pzx4gV4d-SAm7M8arI9A.png"/></div></figure><p id="e7be" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">这种情况下的后验概率正比于:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div class="gi gj lw"><img src="../Images/5f103a2beb1ed4bda671ad53e324b8fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*rIvwWh91Wt46_csqZlQvdQ.png"/></div></figure><p id="3040" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">因此，让我们计算百分位数的联合概率分布是:</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj lx"><img src="../Images/6aa97a8806e62bff22232e831c77bbb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GNMKu7SnzWob-xcDTIS0Jg.png"/></div></div></figure><p id="3934" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">因此，我们可以通过忽略参数μ和σ来计算所有百分点。答案可以通过分析得出，但在我们的情况下，我想用 MCMC 哈密顿取样法数值求解。</p><p id="1c83" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">这种方法的思想是得到一个联合分布 p(x，μ，σ2|x(i))的样本。之后，我们可以计算 x 的百分位数。这相当于通过后验分布的参数边缘化。</p><p id="40f4" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">正如我前面说过的，答案可以通过分析得出，但是我们将使用一种可以用于分布的方法，对于这种分布，很难或者不可能获得样本。这种方法叫做<a class="ae kw" href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo" rel="noopener ugc nofollow" target="_blank">马尔可夫链蒙特卡罗</a>。该方法的思想是在变量空间中进行随机行走，但是尝试更频繁地访问更可能的区域，以便在结果样本中直方图遵循概率分布。在这种情况下，一些不太可能的值必须被拒绝。</p><p id="149a" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">MCMC 的一个特殊风格是哈密尔顿采样方法。它有点类似于梯度下降算法，除了 MCMC 中的步长足够大，而不是试图收敛到成本函数的最小值，因此它也探索变量空间中可能性较小的区域，但是倾向于更频繁地访问高可能性区域。</p><p id="818d" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">为此，我们需要取联合分布函数的对数(忽略常数):</p><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj ly"><img src="../Images/3bed0095df025df4c098ecaca8b82f23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pcwvJqQVzu1wQtWa2L5b6w.png"/></div></div></figure><p id="7969" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">有很多库做哈密顿取样。甚至还有为此优化的概率编程语言，比如<a class="ae kw" href="https://en.wikipedia.org/wiki/Stan_(software)" rel="noopener ugc nofollow" target="_blank"> Stan </a>。但是这里我们将使用 TensorFlow Probability，这是一个由 Google 创建的概率库</p><pre class="kh ki kj kk gu lz ma mb mc aw md bi"><span id="89fa" class="me mf ir ma b gz mg mh l mi mj"><strong class="ma is">import</strong> <strong class="ma is">numpy</strong> <strong class="ma is">as</strong> <strong class="ma is">np</strong><br/><strong class="ma is">import</strong> <strong class="ma is">pandas</strong> <strong class="ma is">as</strong> <strong class="ma is">pd</strong><br/><strong class="ma is">import</strong> <strong class="ma is">tensorflow</strong> <strong class="ma is">as</strong> <strong class="ma is">tf</strong><br/><strong class="ma is">import</strong> <strong class="ma is">tensorflow_probability</strong> <strong class="ma is">as</strong> <strong class="ma is">tfp</strong></span><span id="3c13" class="me mf ir ma b gz mk mh l mi mj">lamb = 2e-1<br/><strong class="ma is">def</strong> log_likelihood(x, mu, sigma2):<br/>    'The (negative) log likelihood function for one sample'<br/>    <strong class="ma is">return</strong> (tf.log(x)-mu)**2/2.0/sigma2</span><span id="5b39" class="me mf ir ma b gz mk mh l mi mj"><strong class="ma is">def</strong> get_unnormalized_log_probability(data):<br/>    <strong class="ma is">def</strong> joined_probability(x, mu, sigma2):<br/>        result = -(2.0+len(data))/2*tf.log(sigma2) - lamb * mu**2/2.0 -log_likelihood(x, mu, sigma2) <em class="ml">#sigma2</em><br/>        <strong class="ma is">for</strong> datum <strong class="ma is">in</strong> data:<br/>            result -= log_likelihood(float(datum), mu, sigma2)<br/>        <strong class="ma is">return</strong> result<br/>    <strong class="ma is">return</strong> joined_probability</span></pre><p id="2451" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">我们希望确保我们的功能正常工作，最好的方法是编写一个单元测试</p><pre class="kh ki kj kk gu lz ma mb mc aw md bi"><span id="75d6" class="me mf ir ma b gz mg mh l mi mj"><strong class="ma is">import</strong> <strong class="ma is">unittest</strong><br/><strong class="ma is">import</strong> <strong class="ma is">math</strong></span><span id="8c3a" class="me mf ir ma b gz mk mh l mi mj"><strong class="ma is">class</strong> <strong class="ma is">TestUnnormalizedLogProbability</strong>(unittest.TestCase):</span><span id="b10b" class="me mf ir ma b gz mk mh l mi mj">    <strong class="ma is">def</strong> test_get(self):<br/>        tf.reset_default_graph()<br/>        data=np.array([1.0,1.0])<br/>        x = tf.constant(value=1.0)<br/>        mu = tf.constant(value=0.0)<br/>        sigma2 = tf.exp(1.0)<br/>        probability_function = get_unnormalized_log_probability(data)<br/>        probability = probability_function(x, mu, sigma2)<br/>        <br/>        init = tf.global_variables_initializer()</span><span id="2a50" class="me mf ir ma b gz mk mh l mi mj">        <strong class="ma is">with</strong> tf.Session() <strong class="ma is">as</strong> sess:<br/>            sess.run(init)<br/>            self.assertTrue(abs(-2-probability.eval())&lt;1e-5)<br/>        <br/>unittest.main(argv=[''], verbosity=0, exit=<strong class="ma is">False</strong>);</span><span id="2f7b" class="me mf ir ma b gz mk mh l mi mj"><em class="ml">----------------------------------------------------------------------<br/>Ran 1 test in 0.088s</em></span><span id="c948" class="me mf ir ma b gz mk mh l mi mj"><em class="ml">OK</em></span></pre><p id="0d5e" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">我们将使用与之前相同的数据</p><pre class="kh ki kj kk gu lz ma mb mc aw md bi"><span id="4daa" class="me mf ir ma b gz mg mh l mi mj">data=np.array([14, 12,  7, 14, 13])<br/><em class="ml"># Create state to hold updated `step_size`.</em><br/>step_size = tf.get_variable(<br/>    name='step_size',<br/>    initializer=1e-1,<br/>    use_resource=<strong class="ma is">True</strong>,  <em class="ml"># For TFE compatibility.</em><br/>    trainable=<strong class="ma is">False</strong>)</span><span id="1adf" class="me mf ir ma b gz mk mh l mi mj"><em class="ml"># Initialize the HMC transition kernel.</em><br/>hmc = tfp.mcmc.HamiltonianMonteCarlo(<br/>    target_log_prob_fn=get_unnormalized_log_probability(data),<br/>    num_leapfrog_steps=3,<br/>    step_size=step_size,<br/>    step_size_update_fn=tfp.mcmc.make_simple_step_size_update_policy(),<br/>    seed=1398)</span><span id="64fc" class="me mf ir ma b gz mk mh l mi mj"><em class="ml"># Run the chain (with burn-in).</em><br/>samples, kernel_results = tfp.mcmc.sample_chain(<br/>    num_results=int(1e5),<br/>    <em class="ml">#num_burnin_steps=int(1e1),</em><br/>    current_state=[10.0,2.0,0.2],<br/>    kernel=hmc)</span><span id="8edc" class="me mf ir ma b gz mk mh l mi mj"><em class="ml"># Initialize all constructed variables.</em><br/>init_op = tf.global_variables_initializer()</span><span id="fc28" class="me mf ir ma b gz mk mh l mi mj"><strong class="ma is">with</strong> tf.Session() <strong class="ma is">as</strong> sess:<br/>    init_op.run()<br/>    samples_, kernel_results_ = sess.run([samples, kernel_results])</span><span id="08fc" class="me mf ir ma b gz mk mh l mi mj">all_samples = np.array(samples_)<br/>all_samples.shape</span><span id="7ceb" class="me mf ir ma b gz mk mh l mi mj"><em class="ml">(3, 100000)</em></span></pre><p id="ec79" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">我们的结果有三行，分别是 x，μ和σ。我们可以利用这三个变量</p><pre class="kh ki kj kk gu lz ma mb mc aw md bi"><span id="0c40" class="me mf ir ma b gz mg mh l mi mj">all_samples.mean(axis=1)</span><span id="676e" class="me mf ir ma b gz mk mh l mi mj"><em class="ml">array([14.040146  ,  2.4572225 ,  0.21323058], dtype=float32)</em></span></pre><p id="088c" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">出乎意料的是，<code class="fe mm mn mo ma b">x</code>的均值比我们想象的要高(12)。让我们绘制直方图来查看概率分布:</p><pre class="kh ki kj kk gu lz ma mb mc aw md bi"><span id="676d" class="me mf ir ma b gz mg mh l mi mj">%<strong class="ma is">matplotlib</strong> inline<br/><strong class="ma is">import</strong> <strong class="ma is">matplotlib.pyplot</strong> <strong class="ma is">as</strong> <strong class="ma is">plt</strong><br/><strong class="ma is">import</strong> <strong class="ma is">seaborn</strong> <strong class="ma is">as</strong> <strong class="ma is">sns</strong><br/>fig, ax = plt.subplots(figsize=(11.7, 8.27))<br/>sns.distplot(all_samples[0,:], hist=<strong class="ma is">False</strong>);</span></pre><figure class="kh ki kj kk gu kl gi gj paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="gi gj mp"><img src="../Images/6e5cd2cee501e4eeec1c4ca1a96771ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*roTrqSf1z6snLFTBUoWd9g.png"/></div></div></figure><p id="b7ed" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">我们看到最大值约为 12，因为我们将使用最大后验分布。</p><p id="e216" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">该曲线具有不规则的形状，但对于多变量 MCMC 结果来说，这在某种程度上是意料之中的。还要注意，对数正态分布的尾部更长。这是忽略后验分布参数的结果。让我们看看我们 95%的信心会落在哪里:</p><pre class="kh ki kj kk gu lz ma mb mc aw md bi"><span id="7d68" class="me mf ir ma b gz mg mh l mi mj">np.percentile(all_samples[0,:], q=5)</span><span id="21c5" class="me mf ir ma b gz mk mh l mi mj"><em class="ml">7.160015678405762</em></span></pre><p id="a868" class="pw-post-body-paragraph kx ky ir kz b la lb js lc ld le jv lf lg lh li lj lk ll lm ln lo lp lq lr ls ik bi translated">95%的置信度也非常接近我们用更简单的方法得到的结果。然而，用 MCMC I 进行的实验发现，该方法不稳定，并且强烈依赖于播种、初始值和超参数的选择。随着维度的增加，这个问题变得更加严重。</p><h1 id="961c" class="mq mf ir bd mr ms mt mu mv mw mx my mz jx na jy nb ka nc kb nd kd ne ke nf ng bi translated">结论</h1><p id="ad39" class="pw-post-body-paragraph kx ky ir kz b la nh js lc ld ni jv lf lg nj li lj lk nk lm ln lo nl lq lr ls ik bi translated">在这个故事中，我们试图在敏捷项目评估中使用贝叶斯方法，而不是分析性地计算百分位数，我们展示了如何使用马尔可夫链蒙特卡罗和哈密尔顿抽样来实现这个结果。我们还演示了如何在 TensorFlow 概率包中实现它。</p></div></div>    
</body>
</html>