<html>
<head>
<title>Diving into K-Means…</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">潜入 K-Means…</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/k-means-clustering-implementation-2018-ac5cd1e51d0a?source=collection_archive---------7-----------------------#2018-09-10">https://towardsdatascience.com/k-means-clustering-implementation-2018-ac5cd1e51d0a?source=collection_archive---------7-----------------------#2018-09-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="00be" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi kl translated"><span class="l km kn ko bm kp kq kr ks kt di">我们</span>已经在上一篇<a class="ae ku" href="https://medium.com/@diti.modi/linear-regression-model-899558ba0fc4" rel="noopener"> <strong class="jp ir"> <em class="kv">这里</em> </strong> </a>完成了我们的第一个基本监督学习模型，即线性回归模型。因此，在这篇文章中，我们从最基本的无监督学习算法开始- <strong class="jp ir"> K 均值聚类</strong>。事不宜迟，我们开始吧！</p><h2 id="941c" class="kw kx iq bd ky kz la dn lb lc ld dp le jy lf lg lh kc li lj lk kg ll lm ln lo bi translated"><strong class="ak">背景:</strong></h2><p id="0f5a" class="pw-post-body-paragraph jn jo iq jp b jq lp js jt ju lq jw jx jy lr ka kb kc ls ke kf kg lt ki kj kk ij bi translated">顾名思义，K-means 聚类是一种聚类算法，没有预先确定的标签，就像我们对线性回归模型一样，因此被称为无监督学习算法。</p><h2 id="4aca" class="kw kx iq bd ky kz la dn lb lc ld dp le jy lf lg lh kc li lj lk kg ll lm ln lo bi translated"><strong class="ak">逻辑与工作:</strong></h2><blockquote class="lu"><p id="257e" class="lv lw iq bd lx ly lz ma mb mc md kk dk translated"><em class="me"> K-means 简单地将给定数据集划分成具有不同特征的各种聚类(组)。</em></p></blockquote><p id="1b5a" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated"><strong class="jp ir">到底如何？</strong></p><p id="f37a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">k 是指在整个数据集中定义的聚类总数。有一个为给定聚类类型选择的质心，用于计算给定数据点的距离。距离本质上表示数据点的特征与聚类类型的相似性。</p><blockquote class="mk ml mm"><p id="5dca" class="jn jo kv jp b jq jr js jt ju jv jw jx mn jz ka kb mo kd ke kf mp kh ki kj kk ij bi translated">我们可以以校车为例来说明这一点。如果我们有来自特定区域(集群)的许多学生(数据点)通过校车前往学校，学校声明一个中心汽车站(质心),来自附近地区的所有学生可以在此集合登上校车(集群过程)。</p></blockquote><p id="a21b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">约束:</strong></p><p id="b067" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">只能使用<strong class="jp ir">数值数据</strong>。一般来说，k-means 最适合二维数值数据。在 2d 或 3d 数据中可视化是可能的。但实际上，一次总有多个特征需要考虑。</p><p id="a948" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，可以使用多维数据，但是在将数据用于 k-均值之前，必须对数据进行降维。</p><p id="9abb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kv">选择 K: </em></p><p id="73c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">没有确切的方法来确定 K(用于划分的总聚类数)的理想值。我们必须对给定的数据集尝试不同的 K 值，并比较由此获得的结果。</p><h2 id="6ef0" class="kw kx iq bd ky kz la dn lb lc ld dp le jy lf lg lh kc li lj lk kg ll lm ln lo bi translated">为什么要用 K-means？</h2><blockquote class="mk ml mm"><p id="2c82" class="jn jo kv jp b jq jr js jt ju jv jw jx mn jz ka kb mo kd ke kf mp kh ki kj kk ij bi translated">使用 k-means，在分析数据之后对数据进行聚类，而不是基于预定义的标签将其原始地定义在一个组下。每个质心都是本质上代表其所属聚类类型的特征的集合。因此，质心可以用来解释所形成的集群的类型。</p></blockquote><h2 id="3226" class="kw kx iq bd ky kz la dn lb lc ld dp le jy lf lg lh kc li lj lk kg ll lm ln lo bi translated">现实生活应用:</h2><ol class=""><li id="d4fa" class="mq mr iq jp b jq lp ju lq jy ms kc mt kg mu kk mv mw mx my bi translated">客户零售细分分为不同数据分析应用的聚类，例如了解忠诚客户、分析客户的消费行为或特定类型客户的需求。</li><li id="311f" class="mq mr iq jp b jq mz ju na jy nb kc nc kg nd kk mv mw mx my bi translated">网络犯罪欺诈的欺诈检测。</li><li id="a52d" class="mq mr iq jp b jq mz ju na jy nb kc nc kg nd kk mv mw mx my bi translated">MP3 文件、手机是使用这种技术的一般领域。英语中大约有 40 种不同的声音。</li></ol><h1 id="f50e" class="ne kx iq bd ky nf ng nh lb ni nj nk le nl nm nn lh no np nq lk nr ns nt ln nu bi translated">TL；速度三角形定位法(dead reckoning)</h1><p id="748d" class="pw-post-body-paragraph jn jo iq jp b jq lp js jt ju lq jw jx jy lr ka kb kc ls ke kf kg lt ki kj kk ij bi translated">在这里，我们执行整个机器学习过程，而不仅仅是算法实现。</p><blockquote class="mk ml mm"><p id="a7ea" class="jn jo kv jp b jq jr js jt ju jv jw jx mn jz ka kb mo kd ke kf mp kh ki kj kk ij bi translated">注意:我们在这里从头开始实现 K-means。“scikit-learn”库，Python 中的机器学习库内置了 K-means 方法，可以直接使用。</p></blockquote><h2 id="debe" class="kw kx iq bd ky kz la dn lb lc ld dp le jy lf lg lh kc li lj lk kg ll lm ln lo bi translated">为机器学习方法执行的步骤是:</h2><ol class=""><li id="764c" class="mq mr iq jp b jq lp ju lq jy ms kc mt kg mu kk mv mw mx my bi translated">数据预处理</li><li id="ecd6" class="mq mr iq jp b jq mz ju na jy nb kc nc kg nd kk mv mw mx my bi translated">数据分析</li><li id="b88f" class="mq mr iq jp b jq mz ju na jy nb kc nc kg nd kk mv mw mx my bi translated">模型实现</li></ol><h2 id="1cb4" class="kw kx iq bd ky kz la dn lb lc ld dp le jy lf lg lh kc li lj lk kg ll lm ln lo bi translated">k-means 算法的基本步骤:</h2><p id="0de8" class="pw-post-body-paragraph jn jo iq jp b jq lp js jt ju lq jw jx jy lr ka kb kc ls ke kf kg lt ki kj kk ij bi translated">步骤 1:从数据集中的值中选择 k 个质心的随机值(这里 k=2)</p><p id="f1f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">步骤 2:计算每个质心的每个点的欧几里德距离</p><p id="3d4a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">步骤 3:比较距离并分配聚类</p><p id="d335" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第四步:取平均值，重复直到误差为零</p><p id="f2a6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">4.结果可视化</p><h2 id="fd64" class="kw kx iq bd ky kz la dn lb lc ld dp le jy lf lg lh kc li lj lk kg ll lm ln lo bi translated"><strong class="ak">实施:</strong></h2><blockquote class="lu"><p id="d38c" class="lv lw iq bd lx ly lz ma mb mc md kk dk translated">1.数据预处理</p></blockquote><p id="31a1" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">在使用现有数据之前，我们必须对其进行预处理，以获得准确的结果。预处理包括数据清洗、数据争论、特征提取、数据归约等。这些根据数据和要求而变化。</p><p id="de03" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里我们导入 numpy、pandas、matplotlib 库，分别用于数组处理、数据帧使用和数据可视化。数据被读取并存储在名为“data”的数据帧中。这里的编码被指定为“ISO-8859–1 ”,因为我们的 csv 文件是“utf-8”格式的，以便于阅读。data.head()显示整个数据集的前 5 行。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi nv"><img src="../Images/168ab0419819a59cdd5b414a3ab8f51e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yOf0fY-1vVsygKWw-CEuzA.png"/></div></div></figure><p id="c14f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们通过(total_rows，total_columns)格式的 data.shape 找到数据帧的大小。数据清理是为了清除空值或缺失值。为此，我们需要使用 data.isnull()知道数据中空值的数量。sum()。它在每个属性列中提供总的空值。我们可以使用“data.drop.na()”删除所有空值条目。</p><p id="47da" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为我们在这里只想使用数字数据来表示 K-means，而且属性中没有空值，所以我们可以让数据保持原样。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oh"><img src="../Images/f1b9c3e5c2086e98d88593fcc9083348.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CjARYEHoDkZQiGF2EARkQw.png"/></div></div></figure><p id="cbcd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">特征提取在数据分析部分进一步完成。</p><blockquote class="lu"><p id="ecf9" class="lv lw iq bd lx ly lz ma mb mc md kk dk translated">2.数据分析</p></blockquote><p id="4b33" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">我们用 data.describe()存储在“summary”变量中获得数据的摘要。我们转置它来交换行和列。summary.head()显示摘要。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oi"><img src="../Images/6947c65d8d44f25052ba11503be21aa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_9nsPtk57w4yg4YSXsTMjA.png"/></div></div></figure><p id="1195" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">可以进行数据可视化，以可视化该列中的分布，无论它是否倾斜，绘制直方图、箱线图、散点图。这里绘制了“销售额”、“订购数量”和“价格”的直方图。我们可以使用“SALES”和“QUANTITYORDERED”来根据产品的销售额和订购数量形成集群。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi oj"><img src="../Images/3726c8409912c170fc38c4313c6e10ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YTsJoLUVj9qKSmfM_QsKXQ.png"/></div></div></figure><p id="8fb6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们绘制一个散点图。“x”仅用于保存我们需要的“数据”中的 2 列，以及所有行条目。接下来，我们绘制散点图，将图形大小设置为 16x9，样式设置为 ggplot，这样就形成了一个网格。plt.scatter()用黑色圆点绘制 x 数据帧的第 0 列和第 1 列，大小为 7。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/e8e3602b2979f005e28e84a7b1edb858.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*ucPf3qLkDbL0W1DXewA9lg.png"/></div></figure><p id="80a7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的初始数据看起来像这样，没有分组:</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi ol"><img src="../Images/fbde4a70429b8d31fccb71b6d821f64a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M29OMasy2ZDeXRv-FGciew.png"/></div></div></figure><p id="1a6e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的数据中有异常值。离群值只是远离其他数据点的值，它们不适合我们的数据，可能会妨碍我们的准确性。</p><p id="0f14" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如我们看到的，在我们的数据中有许多异常值，我们通过计算 z-score 来删除这些异常值。zscore()是 python 的 scipy 库中的内置函数。</p><p id="c2c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Z score 使我们的数据正常化。在这里，我们得到的 z 得分的绝对值在-3 到 3 的范围内，所有点都存储回 x 中，所有其他行都被删除。</p><p id="2622" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如我们注意到的，x 的形状从最初的行数变化到更少的行数，因为删除的行数更少。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div class="gh gi om"><img src="../Images/7acf61ff123616a53e06c4a2169ec325.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*Z1uzKo6z7dUj8_eq_moD8g.png"/></div></figure><blockquote class="lu"><p id="a8ed" class="lv lw iq bd lx ly on oo op oq or kk dk translated">3.k-均值实现</p></blockquote><p id="95fd" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">因此，现在我们终于在获得最终数据后开始实际的算法实现。我们只是在这里导入复制库和其他基本库。deepcopy 用于将一个数组复制到另一个数组中。我们用它来存储质心的历史，可以用来提前计算误差。</p><p id="66ac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们定义一个函数“欧几里得”来计算两点“a”和“b”之间的距离。np.linalg.norm()是 numpy 库中的内置函数，它在这里计算 a 和 b 的欧氏距离。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div class="gh gi os"><img src="../Images/24da9b106211f01a038ba4695f5398f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*qC1PnYx-V0k0iQbWb4gbtQ.png"/></div></figure><p id="2924" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来我们定义 main()函数。这里我们应用所有的 k 均值算法步骤。</p><p id="4da0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">K-Means 的第一步:选择随机质心</p><p id="6b70" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，第一步是从数据集本身选择随机质心。Numpy 具有内置函数 np.random.choice()，其参数为 x.shape[0],给出了总行数和 2 列数，即聚类数，replace 设置为 false，即 x 不被这些值替换。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi ot"><img src="../Images/84b06eaf5c241f15ee34d252e99dadb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S6mrIj60kB10Fqq5zRP4Lg.png"/></div></div></figure><p id="93d5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以打印出质心的随机值，然后我们定义所有的变量以备将来使用。我们将“total”变量定义为 x 的形状值。“ditance_1”和“distance_2”分别定义为从数据中的每个点到质心 1 和质心 2 的距离，我们用大小为 total[0]的零对其进行初始化。因此，这些是 x 中总行数的 1D 数组</p><p id="74e6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">“belongs_to”用于存储数据点所属的簇的值。它通过索引对应于 x 中的每个数据点。它还被初始化为零和 total[0]的大小，以便存储每个数据点的逐行的簇号(这里是-0，1 编号的簇)。“c_old”存储质心的旧值。这里它被初始化为零，并且是“形心”的形状。</p><p id="09c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">“误差”用于存储当前质心和旧质心的欧几里德距离，即如果两个质心值相同，误差变为零。“mean”用于存储新的质心。因此，它是“质心”的大小，并被初始化为零。“np.zeros()”是 Numpy 中的内置函数，它通过将大小作为参数传递来将给定数组初始化为零。最后“iterator”计算执行的迭代总数。目前为零。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/b6163648ae2098946b244aba84f632d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*nhjB6y9hOJqIWvKqwAE-Xw.png"/></div></figure><p id="f63f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">K-Means 的第二步:计算欧氏距离</strong></p><p id="ec81" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们执行步骤 2，计算每个质心的每个数据点的欧几里德距离。循环条件是误差不等于零，如果误差变为零，那么计算的质心与前一个相同，所以循环将在那里停止。我们打印出迭代次数，并开始 for 循环来计算欧几里得距离。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/f4af9a00944c377daf27d078e46e63e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*zrG1X273WiCXI9I2hPj8lA.png"/></div></figure><p id="7d42" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">K-Means 的步骤 3:比较距离</strong></p><p id="ee63" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，步骤 3 将这些距离相互比较，并相应地分配聚类。因此,“if”条件为第一组分配 0，为第二组分配 1。“属于”值根据每个数据点与第一个和第二个质心的距离而变化。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/52f71ecb373f4e1a3e6c8d0120510bc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*QODAE4WXPvHd4DfGoGoO7w.png"/></div></figure><p id="3676" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">K 均值第 4 步:取均值，重复</strong></p><p id="0fd7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后一步现在通过分别对聚类 1 数据点和聚类 2 数据点取平均值来计算新的质心。我们使用“deepcopy”复制 c_old 中旧质心的值。for 循环一直进行到 belongs_to 的范围，为第一个聚类分配每列的平均值。“np.mean()”是用于计算平均值的内置 Numpy 函数。现在我们知道为什么我们在 Python 中如此广泛地使用 Numpy 了！:P</p><p id="83aa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了清楚起见，我在这里使用了单独的“均值”变量。我们可以替换“质心”变量并在这里重新使用它。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div class="gh gi ox"><img src="../Images/cb27589eba297e6d264f97dccc567445.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*ZeW3IA8P5KY77YHBn0MmCg.png"/></div></figure><p id="7917" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们对聚类 2 的平均值进行相同的循环，其中 belongs_to()值为 1，而聚类 1 的平均值为 0。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/df2a06055b30e265d397fc7f5e927493.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*QvJajWcqlPr_ehVpsCuysg.png"/></div></figure><p id="ab1e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我们将平均值分配给质心，并计算旧质心和新质心的误差。迭代器加 1，条件错误检查在这里完成。如果误差为 0，则传送相同质心值的消息，然后循环停止。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/abd7d67f70455f6af5a517815272f16f.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*LLbQRzk76-JPG58yXAg2dw.png"/></div></figure><blockquote class="lu"><p id="5c36" class="lv lw iq bd lx ly on oo op oq or kk dk translated">4.结果可视化</p></blockquote><p id="5eb2" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">最后，我们执行机器学习过程的最后一步，可视化我们的聚类点。我们使用和以前一样的情节。唯一改变的是每个簇的颜色。我们用红色‘r’和绿色‘g’来代表每个聚类。我们将“点”指定为 x 的数组，该数组位于其所属行的范围内，其中“所属行”的值为 0 或 1。我们只是将红色点(颜色[0])分散到聚类 1(属于 _ 属于[]=0)，将绿色点(颜色[1])分散到聚类 2(属于 _ 属于[]=1)。我们指定星号(*)标记，用黑色标出最终质心。</p><p id="e03b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们调用主函数来执行模型。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pa"><img src="../Images/2fef44b0d77f85c831a0acbcde81aec7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4oXHkCrCe9AUJzaeWICvXQ.png"/></div></div></figure><p id="c744" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">完整的代码和数据集可在<a class="ae ku" href="https://github.com/ditsme/Machine-Learning/tree/master/100-Days-Of-ML-Code/Day-06-07-k-means" rel="noopener ugc nofollow" target="_blank">这里</a>获得。我还添加了运动员数据的另一个实现，这可以使数据清理部分变得清晰，因为我们删除了那里的重复值和空值。</p><h2 id="5f57" class="kw kx iq bd ky kz la dn lb lc ld dp le jy lf lg lh kc li lj lk kg ll lm ln lo bi translated"><strong class="ak">输出:</strong></h2><p id="1aae" class="pw-post-body-paragraph jn jo iq jp b jq lp js jt ju lq jw jx jy lr ka kb kc ls ke kf kg lt ki kj kk ij bi translated">我得到的输出如下:</p><blockquote class="mk ml mm"><p id="96d3" class="jn jo kv jp b jq jr js jt ju jv jw jx mn jz ka kb mo kd ke kf mp kh ki kj kk ij bi translated">注意:这里的输出可能会有所不同，因为我们最初是随机选择质心的。这里仅执行 2 次迭代，直到误差变为零。</p></blockquote><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/654b95bc09c7bd20e6b3eff77d52385e.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*Emq2P9-j28FSz1IK-6PJfA.png"/></div></figure><p id="5b59" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">聚类:</p><p id="c7ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">绘制散点图时考虑最终迭代质心和聚类。</p><figure class="nw nx ny nz gt oa gh gi paragraph-image"><div role="button" tabindex="0" class="ob oc di od bf oe"><div class="gh gi pc"><img src="../Images/e92ec7cd607694b68e4dfc86c6d38411.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nuzFplyzvIO5V9J9wsaV1g.png"/></div></div></figure><p id="ce45" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于任何疑问或评论，请在下面评论，让我知道你是否喜欢这个博客！；)</p></div></div>    
</body>
</html>