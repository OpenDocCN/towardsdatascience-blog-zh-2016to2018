<html>
<head>
<title>Automatic GPUs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动图形处理器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automatic-gpus-46aa08f01886?source=collection_archive---------9-----------------------#2018-03-22">https://towardsdatascience.com/automatic-gpus-46aa08f01886?source=collection_archive---------9-----------------------#2018-03-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9b56" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用Tensorflow中的GPU在GCloud上快速启动和运行的可再现R / Python方法</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/b48bd9141d9ff0f7e086c88cdb9ad77a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fCJgjtSFFLBlV7O6."/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">“A high view of a sea of clouds covering a mountain valley in the Dolomites” by <a class="ae kv" href="https://unsplash.com/@oldskool2016?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">paul morris</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="5d7b" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">背景</h2><p id="2521" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">最近在<em class="ml"> Coursera </em>上完成了谷歌优秀的<a class="ae kv" href="https://www.coursera.org/specializations/gcp-data-machine-learning" rel="noopener ugc nofollow" target="_blank"> <em class="ml">数据工程认证专业</em></a>(*我强烈推荐)，我认为在一个单一的GCE虚拟上获得自己的<em class="ml">谷歌计算引擎(" GCE "或</em><a class="ae kv" href="https://twitter.com/hashtag/gcloud?lang=en" rel="noopener ugc nofollow" target="_blank"><em class="ml"># g cloud</em></a><em class="ml">)</em>实例既实用又有用——在<em class="ml"> Tensorflow中使用GPU，</em>使用<em class="ml"> R和Python </em>像许多其他数据科学家一样，我经常使用两种语言，并且喜欢与谷歌计算平台(“GCP”)一起工作。希望您喜欢我方法的简单性，并从这次演练中获得一些收获！</p><h2 id="a6c8" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">带R / Python的GPU和Tensorflow】</strong></h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mm"><img src="../Images/70e3f2d0602f44a7fb8dd9dfc4540978.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gDQY-1btNVxNQp_A."/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">“A computer without the case showing the motherboard, cooling fans, graphics cards, and power supply mounted on a red-lit wall labeled ASUS in a gaming convention” by <a class="ae kv" href="https://unsplash.com/@maxoor?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Maxime Rossignol</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="5ed1" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">这些<em class="ml"> GCE机器</em>是高度动态的，就像<em class="ml"> AWS实例</em>一样，并且与<em class="ml">张量处理单元</em>(<em class="ml">“TPUs”</em>是最近在GCP测试版上可用的ASIC卡)和<em class="ml">图形处理单元(“GPU”</em>或用于“alt coin”挖掘、游戏和深度学习的“显卡”)一起工作。这篇文章将不包括自动TPU安装(也许这将是另一个有用的，当价格下降)。我们将运行一个简单的安装程序<em class="ml"> Tensorflow，</em>来检查GPU是否在工作，在运行一个bash脚本后，它首先完成所有繁重的工作。</p><p id="0fa0" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">最初，我尝试了许多与GCloud和GPU相关的不同演练，最终在Medium上找到了两个精彩的帖子，分别是这里的<a class="ae kv" href="https://medium.com/google-cloud/containerized-jupyter-notebooks-on-gpu-on-google-cloud-8e86ef7f31e9" rel="noopener"/>(<a class="ms mt ep" href="https://medium.com/u/3630dfb701f5?source=post_page-----46aa08f01886--------------------------------" rel="noopener" target="_blank">Durgesh manke kar</a>)和这里的<a class="ae kv" href="https://medium.com/google-cloud/using-a-gpu-tensorflow-on-google-cloud-platform-1a2458f42b0" rel="noopener"/>(<a class="ms mt ep" href="https://medium.com/u/c85c6404c0f9?source=post_page-----46aa08f01886--------------------------------" rel="noopener" target="_blank">Luuk Derksen</a>)。我的自动化脚本的一部分是基于上面的两篇文章，还有这个<a class="ae kv" href="https://gist.github.com/mjdietzx/0ff77af5ae60622ce6ed8c4d9b419f45" rel="noopener ugc nofollow" target="_blank">有用的要点</a>(作者<a class="ae kv" href="https://github.com/mjdietzx" rel="noopener ugc nofollow" target="_blank">迈克尔·迪茨</a>)以及无数其他来源。然而，其他帖子要么更适合Jupyter笔记本设置，要么在CuDNN驱动程序之前手动设置NVIDIA Cuda，并且只测试Python。坦率地说，考虑到最近的许多变化，我很难从其他演练中获得环境设置。</p><p id="66ad" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">因此，我决定采取完全自动化的方法，不需要注册英伟达，登录，并下载特定操作系统的特定驱动程序。它假设用户可以用一个bash脚本再现下面的输出，给定一个GCE虚拟机的设置，该虚拟机具有任何当前可用的g cloud GPU(NVIDIA:Tesla K80或P100)，在Ubuntu 16.04上至少25Gb的HD，以及2个以上的内核，最少7.5Gb的RAM，我们也将在下面逐步介绍。</p><h2 id="f214" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">预期方向</strong></h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mu"><img src="../Images/2584533bf5b7ac9e89b4b759497776c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*dYafgaCgjR9xeOH9."/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@eberhardgross?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">eberhard grossgasteiger</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="a4d4" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">如果使用共享GPU正确设置，下面的内容将有望允许多用户Jupyter笔记本配置，我希望继续关注另一个博客，该博客将使用<em class="ml"> RStudio服务器(易于在GCloud中设置密码登录)</em>或<em class="ml"> JupyterLab(不那么容易)</em>。此外，它使用Anaconda安装两个R / Python，在同一个<a class="ae kv" href="https://conda.io/docs/user-guide/tasks/manage-environments.html" rel="noopener ugc nofollow" target="_blank"> <em class="ml"> conda环境</em> </a>，应该支持多用户共享GPU。</p><h2 id="63c8" class="kw kx iq bd ky kz la dn lb lc ld dp le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated"><strong class="ak">我们来看一下设置</strong></h2><p id="baf2" class="pw-post-body-paragraph ls lt iq lu b lv lw jr lx ly lz ju ma lf mb mc md lj me mf mg ln mh mi mj mk ij bi translated">我们将保持这一部分非常简单，没有太多的截屏(‘咳！嗯嗯……’)。谷歌赠送了为期12个月的300美元信用(T7)，让你开始在GCP工作。您将使用该配额为特定区域申请GPU配额，并在配额被允许后申请配额。</p><p id="fd8b" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">您首先需要创建一个项目；在这里，我从照片中突出显示的链接创建了<code class="fe mv mw mx my b">ML-Test</code>。使用<code class="fe mv mw mx my b">+</code>符号建立一个项目。您将在突出显示的左上方下拉列表中看到项目。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/0eace074322637a5034afd091c4787a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NASFr6L0MmLVe2YvKA71rA.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi na"><img src="../Images/d3e39dbdf87a86addbf2d9b598f891cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*YT3B5xUq1CnUq3tbo7yVIg.png"/></div></figure><p id="a626" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">在您设置好项目之后，您会立即想要为GPU申请一个配额。事实上，谷歌很可能会要求你提供第二个参考项目，所以你只需建立另一个名为<code class="fe mv mw mx my b">Project-Placeholder</code>的项目，当谷歌发邮件给你时，你就可以用它来参考。</p><p id="99a0" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">收到一封电子邮件大约需要24小时，您可以通过下拉左上方的“汉堡菜单”来参考<code class="fe mv mw mx my b">Project-Placeholder</code>的可用点数，以结算剩余的&gt; &gt;金额(对您来说大约是300.00美元)。顺便说一句，帮我设置的谷歌人员非常友好。礼貌地说，如果有人从谷歌上看到这个，我认为这一步可以自动化。</p><p id="f422" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">要访问配额页面，您需要首先进入<code class="fe mv mw mx my b">ML-Test</code>项目，然后下拉至IAM &gt; &gt;配额，并编辑您的GCE以请求GCE的配额更新。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nb"><img src="../Images/ea8eaa6139ee78b7df3d43bcbab26ac8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XOviG6TiRp2nHG-usELnww.png"/></div></div></figure><p id="731e" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">在您的用户信息(即，姓名、电子邮件和电话[确保使用您的帐户电子邮件[[我有过惨痛的教训]]])通过验证后，您将单击下一步(如上所示)。现在键入类似下面的内容。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/81beab6e2e668ac56142a5de3e7898ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*QBQvjI_TwiSM9e9ljhIImQ.png"/></div></figure><p id="c162" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">提交。然后等待。谷歌友好的员工会在24-48小时内给你发邮件，希望<code class="fe mv mw mx my b">ML-Test</code>能准备好使用GPU！</p><p id="bd04" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated"><strong class="lu ir">设置您的GPU实例</strong></p><p id="f332" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">如果您想在没有GPU的情况下快速入门，同时使用Python和R在GCE上使用Anaconda，您可以查看我最近在Pepperdine 的一次演讲中创建的这些<a class="ae kv" href="https://gist.github.com/ZeccaLehn/de42e70660e54f34628249fae7d26ce5#file-condarandpython-txt" rel="noopener ugc nofollow" target="_blank">笔记。然而，如果您只对GPU感兴趣，并且您的配额得到批准，那么是时候启动VM了。</a></p><p id="6c46" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">登录<code class="fe mv mw mx my b">ML-Test</code>后，点击汉堡栏计算&gt; &gt;计算引擎&gt; &gt;虚拟机实例。在那里，我们将单击“Create”。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/320bfc19af99d0aaa64d9a610ef092c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*AR78NL8L5rtA03i43MtscQ.png"/></div></figure><p id="64f8" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">现在创建实例…</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/c3cad584808b4461bd9e1e0ac9d685b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EUeCnsY2EKYbnL1Nou1mbQ.png"/></div></div></figure><p id="ceaf" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">在转到磁盘空间和操作系统之前，您需要配置前几个步骤来满足我们的最低要求。您将把虚拟机命名为<code class="fe mv mw mx my b">gpu-vm</code>，并匹配下面突出显示的最小设置。请注意，您的配额可能包括<code class="fe mv mw mx my b">us-west1-b</code>，但也可能包括特定GPU类型的其他区域。如果您使用一个不支持您的配额的区域，机器将会出错—这让我暂停了一段时间。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/6e2097ed030384820f3a67bc523090f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*AiJabprAqfvBV2CXUBr97Q.png"/></div></figure><p id="f4cc" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">最后，在发布之前，为了进行复制，您需要通过点击“更改”来安装<code class="fe mv mw mx my b">Ubuntu16.04</code>和一个最低25Gb的硬盘(注意:您可以降低硬盘容量以避免存储费用，但发现这可能会改变conda环境中安装R时的环境最大存储容量)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/cf7363ff146039383115787d884bc843.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*LYBgum0_fVBslu5PNkGCPw.png"/></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/fd21351c5605551f5ee281744ea74dd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*-Q6G7KH04WbAKRACx72ZBQ.png"/></div></figure><p id="dba4" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">选择操作系统和存储设备后，您将使用<code class="fe mv mw mx my b">Create</code>按钮启动虚拟机。可选地，一旦您测试了这个模拟安装，您可能想要考虑这个虚拟机上的<code class="fe mv mw mx my b">Pre-Emptible</code>选项。这些可以节省高达75%的每小时费用。然而，根据其他需求，它们可以在使用一个小时后关闭，我还没有在抢先模式下测试过这个安装。我认为在削减成本方面，这类似于AWS的保留实例机会。在创建菜单下的“管理、磁盘、网络、SSH密钥”下，可以看到下面的可优先选项，红色，但是再次声明，现在让它保持“关闭”。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/b1e06df91f210763d55c557dec7b6cee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*O0buEPL0DSES3HT-C7zhlQ.png"/></div></figure><p id="98d1" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">您的机器现在正在启动，一旦准备就绪(30秒后)，您将看到带有绿色复选标记的<code class="fe mv mw mx my b">gpu-vm</code>。</p><blockquote class="nj nk nl"><p id="6a65" class="ls lt ml lu b lv mn jr lx ly mo ju ma nm mp mc md nn mq mf mg no mr mi mj mk ij bi translated"><strong class="lu ir">注意:您现在正在接受计费，您将始终希望选中标记该机器，并在不使用时单击停止。当绿色的复选标记变成灰色的停止信号时，我通常只是确认机器已经关闭。</strong></p></blockquote><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/8c875b4459fd15bcc781129ae7af29a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w3WGMee8beG3JoGX8_Cz-A.png"/></div></div></figure><p id="4f94" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">现在您将点击上面的SSH按钮。这将启动您到<code class="fe mv mw mx my b">gpu-vm</code>的SSH连接，并为您的虚拟机打开一个单独的选项卡。您还可以通过点击SSH按钮的左箭头来运行您的SSH shell，并通过如下所示的<code class="fe mv mw mx my b">View Gcloud Command</code>进行访问。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/8492c3f29ca18b0466036b8fcc71d1ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*Q_b79ruV9h2feHcUO2P88w.png"/></div></figure><p id="96eb" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">点击<code class="fe mv mw mx my b">RUN IN CLOUD SHELL</code>，一个内嵌的云Shell将插入上面的命令，点击回车键，你将通过SSH进入你的虚拟机。在Windows上，这通常更好，因为SSH按钮会弹出一个浮动外壳，而在Mac上，它会打开一个新标签。</p><blockquote class="nj nk nl"><p id="602c" class="ls lt ml lu b lv mn jr lx ly mo ju ma nm mp mc md nn mq mf mg no mr mi mj mk ij bi translated">注意:在屏幕右上方的“激活谷歌云外壳”按钮下有一个免费的云外壳可供使用。GCloud的另一个优点是在其环境中完全SSH安全，这意味着没有本地防火墙和Putty。</p></blockquote><p id="ab9e" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated"><strong class="lu ir">让我们用自动脚本安装GPU</strong></p><p id="8592" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">您应该会看到类似这样的内容，但是在VM名称之前有您自己的用户名。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/8556c9b6660b19cfdf9e79f057182eb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3t0K-1HSTw2SlaB1i_YcWw.png"/></div></div></figure><p id="0b3c" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">你已经准备好了，可以参加普通教育证书考试了。现在，您需要将下面的完整脚本复制到命令行中。它将执行，因为NVIDIA的Cuda还没有安装在if语句中。如果你对这里的任何一行有任何特殊的问题，不要犹豫，留下评论并提出来。我宁愿不去研究Cuda——这么说吧，这使得这个过程更容易实现。该脚本已经过全面测试，可以保留路径、文件夹、删除下载的zip文件，并管理正确安装的环境，能够关闭该机器，并再次启动它，而不会破坏任何东西！</p><blockquote class="nj nk nl"><p id="995c" class="ls lt ml lu b lv mn jr lx ly mo ju ma nm mp mc md nn mq mf mg no mr mi mj mk ij bi translated">注意:这个bash脚本大约需要10分钟，并且一举安装Cuda/cud nn/tensor flow-GPU/Python/R！</p></blockquote><pre class="kg kh ki kj gt ns my nt nu aw nv bi"><span id="3cba" class="kw kx iq my b gy nw nx l ny nz"># Check for CUDA and try to install.<br/>if ! dpkg-query -W cuda; then</span><span id="6b88" class="kw kx iq my b gy oa nx l ny nz"># Start Timer here<br/> START=$(date +%s) # Time script</span><span id="5f35" class="kw kx iq my b gy oa nx l ny nz"># Install Cuda from NVIDIA<br/> curl -O <a class="ae kv" href="http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb" rel="noopener ugc nofollow" target="_blank">http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.61-1_amd64.deb</a><br/> # Login as root<br/> sudo dpkg -i ./cuda-repo-ubuntu1604_8.0.61-1_amd64.deb<br/> rm -r cuda-repo-ubuntu1604_8.0.61-1_amd64.deb<br/> sudo apt-get update<br/> sudo apt-get -y install cuda-8.0</span><span id="304a" class="kw kx iq my b gy oa nx l ny nz"># Install cuDNN v6.0<br/> CUDNN_TAR_FILE="cudnn-8.0-linux-x64-v6.0.tgz"<br/> wget <a class="ae kv" href="http://developer.download.nvidia.com/compute/redist/cudnn/v6.0/${CUDNN_TAR_FILE" rel="noopener ugc nofollow" target="_blank">http://developer.download.nvidia.com/compute/redist/cudnn/v6.0/${CUDNN_TAR_FILE</a>}<br/> tar -xzvf ${CUDNN_TAR_FILE}<br/> rm -r cudnn-8.0-linux-x64-v6.0.tgz<br/> sudo cp -P cuda/include/cudnn.h /usr/local/cuda/include<br/> sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda/lib64/<br/> sudo chmod a+r /usr/local/cuda/lib64/libcudnn*</span><span id="cbf0" class="kw kx iq my b gy oa nx l ny nz"># Export Paths<br/> echo 'export CUDA_HOME=/usr/local/cuda' &gt;&gt; ~/.bashrc<br/> echo 'export PATH=$PATH:$CUDA_HOME/bin' &gt;&gt; ~/.bashrc<br/> echo 'export LD_LIBRARY_PATH=$CUDA_HOME/lib64' &gt;&gt; ~/.bashrc<br/> echo 'export PATH=$PATH:$HOME/anaconda3/bin' &gt;&gt; ~/.bashrc<br/> source ~/.bashrc</span><span id="fcd2" class="kw kx iq my b gy oa nx l ny nz"># Install Anaconda<br/> mkdir Downloads<br/> cd Downloads<br/> wget "<a class="ae kv" href="https://repo.continuum.io/archive/Anaconda3-5.0.1-Linux-x86_64.sh" rel="noopener ugc nofollow" target="_blank">https://repo.continuum.io/archive/Anaconda3-5.0.1-Linux-x86_64.sh</a>" -O "Anaconda3-5.0.1-Linux-x86_64.sh"<br/> chmod +x Anaconda3-5.0.1-Linux-x86_64.sh<br/> sudo sh "Anaconda3-5.0.1-Linux-x86_64.sh" -b<br/> cd $HOME<br/> rm -r Downloads</span><span id="7613" class="kw kx iq my b gy oa nx l ny nz"># Create conda environment to work with Python/R<br/> # conda search python # Current Python packages hosted by Anaconda<br/> # conda search r  # Current R packages hosted by Anaconda<br/> mkdir prog_env<br/> source activate prog_env<br/> sudo apt-get update<br/> conda install -c anaconda --prefix=$HOME/prog_env python=3.6 -y<br/> conda install -c anaconda tensorflow-gpu --prefix=$HOME/prog_env -y<br/> conda install -c anaconda --prefix=$HOME/prog_env r=3.4 -y<br/> source deactivate prog_env</span><span id="7bf4" class="kw kx iq my b gy oa nx l ny nz"># Shows Cuda Info<br/> nvidia-smi</span><span id="26f1" class="kw kx iq my b gy oa nx l ny nz"># End of timer<br/> END=$(date +%s)<br/> DIFF=$(( $END - $START ))<br/> echo "It took $DIFF seconds"</span><span id="4aea" class="kw kx iq my b gy oa nx l ny nz">fi</span></pre><p id="7061" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">等待…如果你看到这个，那么事情看起来很好！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ob"><img src="../Images/1127dd34cb9f0943efd99b6e46ffdaff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AiBbRDC5hTqhOlKbvLorKA.png"/></div></div></figure><p id="273e" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">在我们运行一次之后，在我们停止虚拟机之后，就不需要再运行一次了。事实上，如果我们尝试的话，for循环会阻止我们再次运行它，因为CUDA已经安装在进程中了。如果我们幸运的话，您将会看到CUDA和GPU被认可的初步迹象，以及完成的时间(如下所述)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/f6bfd1c5c8ab891f4d350346320f37f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oZ8cLippyuDy24lut6qUGg.png"/></div></div></figure><p id="b5bb" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated"><strong class="lu ir">现在让我们在R和Python上测试我们的tensorflow-gpu安装</strong></p><p id="1989" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">首先，我们想熟悉一下新创建的conda环境，它安装了<code class="fe mv mw mx my b">tensorflow-gpu</code> Python模块，以及安装在主目录<code class="fe mv mw mx my b">prog_env</code>(“程序环境”)中的最新版本的R和Python语言。</p><p id="2887" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">为了在R和Python中测试Tensorflow上的GPU，我们将运行下面的代码，应该会得到与下面用<code class="fe mv mw mx my b">#</code>标记注释掉的结果完全相同的结果。</p><p id="a1d8" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">关于在conda环境中使用<a class="ae kv" href="https://conda.io/docs/_downloads/conda-cheatsheet.pdf" rel="noopener ugc nofollow" target="_blank"> Anaconda的详细信息</a>。</p><p id="4d71" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">测试Python:</p><pre class="kg kh ki kj gt ns my nt nu aw nv bi"><span id="70e8" class="kw kx iq my b gy nw nx l ny nz">## Source environment from home directory in linux<br/>source activate prog_env</span><span id="ad88" class="kw kx iq my b gy oa nx l ny nz">## Now in program environment<br/>(prog_env)$ python</span><span id="a817" class="kw kx iq my b gy oa nx l ny nz">## Test GPU is working from Python<br/>from tensorflow.python.client import device_lib<br/>device_lib.list_local_devices()</span><span id="3a5b" class="kw kx iq my b gy oa nx l ny nz">   # Output should look like this<br/>   # name: "/device:CPU:0"<br/>   # device_type: "CPU"<br/>   # memory_limit: 268435456</span><span id="57bc" class="kw kx iq my b gy oa nx l ny nz">   # name: "/device:GPU:0" (Note: Confirmed GPU!)<br/>   # device_type: "GPU"<br/>   # memory_limit: 11326131405<br/>  <br/>quit("yes") # CTRL(or CMD) + Z</span></pre><p id="2343" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">测试R:</p><pre class="kg kh ki kj gt ns my nt nu aw nv bi"><span id="e4c5" class="kw kx iq my b gy nw nx l ny nz">## While in program environment<br/>(prog_env)$ R</span><span id="8e5f" class="kw kx iq my b gy oa nx l ny nz">## From R command line<br/>install.packages("tensorflow") # Run first time only<br/>library(tensorflow)<br/>install_tensorflow(version = "gpu") # To use GPUs<br/>use_condaenv("r-tensorflow") # For running from conda env<br/>sess = tf$Session() # Creates Tensorflow session</span><span id="4596" class="kw kx iq my b gy oa nx l ny nz">   # Confirms TeslaK80 GPU being used<br/>   # 2018-03-21 19:32:33.987396:<br/>   # tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] <br/>   # Creating TensorFlow device (/device:GPU:0) -&gt; <br/>   # (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, <br/>   # compute capability: 3.7) (Note: Confirmed GPU!)<br/>  <br/>GPUtest &lt;- tf$constant('GPU is running!')<br/>sess$run(GPUtest)<br/>   # "GPU is running!"<br/> <br/>quit("yes") # CTRL(or CMD) + Z</span></pre><p id="967e" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated"><strong class="lu ir">给所有R和Python爱好者的总结</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/44a726c77d251756c8285d7d485b5358.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*RanIdioHlUzhQ2fo."/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@chiro?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">photo-nic.co.uk nic</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="cb31" class="pw-post-body-paragraph ls lt iq lu b lv mn jr lx ly mo ju ma lf mp mc md lj mq mf mg ln mr mi mj mk ij bi translated">就这样，我们做到了！你现在已经有了一台完整的机器，你可以用R和Python来进行GPU深度学习。期待听到这篇文章是否有帮助，以及你可以如何扩展它。期待一个多用户环境，登录，链接到GPU，使用GCloud按分钟付费的可抢占性。</p><blockquote class="nj nk nl"><p id="3b12" class="ls lt ml lu b lv mn jr lx ly mo ju ma nm mp mc md nn mq mf mg no mr mi mj mk ij bi">Note on <em class="iq">DataLab Notebooks</em>: With GCP’s newer product <em class="iq">DataLab</em>, a single user GCE, using a <a class="ae kv" href="https://github.com/googledatalab/datalab" rel="noopener ugc nofollow" target="_blank">custom <em class="iq">Jupyter Notebook</em> interface</a>, setup with GPUs, is as easy to get up and running with a single line of code. Unfortunately, aside from only being single-user, it also does not ship with an R kernel for connecting to GPUs and Tensorflow through the Jupyter interface; it also requires all interaction be ran through the notebook and not the command line, given it’s Docker configuration. For an excellent walkthrough of setting up a GPU enabled DataLab GCE notebook quickly, <a class="ae kv" href="https://qiita.com/kazunori279/items/b17d16a2bfbec5e72984" rel="noopener ugc nofollow" target="_blank">see this article</a> posted <a class="ae kv" href="https://github.com/kazunori279" rel="noopener ugc nofollow" target="_blank">by Kaz Sato</a> (you can right click translate from Japanese to English in Chrome, if needed [for the most part 次に変更 ]).</p></blockquote></div></div>    
</body>
</html>