<html>
<head>
<title>InfoGAN — Generative Adversarial Networks Part III</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">信息根——生成性对抗网络第三部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/infogan-generative-adversarial-networks-part-iii-380c0c6712cd?source=collection_archive---------1-----------------------#2017-11-15">https://towardsdatascience.com/infogan-generative-adversarial-networks-part-iii-380c0c6712cd?source=collection_archive---------1-----------------------#2017-11-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="12dc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">结账我的</em> <a class="ae km" href="https://www.youtube.com/watch?v=3z8VSpBL6Vg&amp;list=PLSgGvve8UweFoMyAEFlFiE--JtWect5-T" rel="noopener ugc nofollow" target="_blank"> <em class="kl"> YouTube上甘斯的视频</em> </a> <em class="kl">。本文原载于</em><a class="ae km" href="https://blog.zakjost.com/post/gans_overview_3/" rel="noopener ugc nofollow" target="_blank"><em class="kl"/></a></p><p id="ce11" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<a class="ae km" href="https://medium.com/@zjost85/overview-of-gans-generative-adversarial-networks-part-i-ac78ec775e31" rel="noopener">第一部分</a>中，提交了原始GAN文件。<a class="ae km" rel="noopener" target="_blank" href="/generative-adversarial-networks-part-ii-6212f7755c1f">第二部分</a>对DCGAN进行了概述，它极大地提高了GANs的性能和稳定性。在这最后一部分，将探讨<a class="ae km" href="https://arxiv.org/abs/1606.03657" rel="noopener ugc nofollow" target="_blank"> InfoGAN </a>的贡献，它应用信息论中的概念将一些噪声项转换成对结果有系统、可预测影响的潜在代码。</p><h1 id="4287" class="kn ko iq bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">动机</h1><p id="a308" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">正如在第二部分的例子中所看到的，当对发生器的噪声矢量进行算术运算时，可以做一些有趣且令人印象深刻的事情。在下面来自DCGAN论文的例子中，戴眼镜的男人的输入噪声向量被操纵以给出导致戴太阳镜的女人一旦被馈送到生成器中的向量。这表明在噪声向量中有<em class="kl">结构</em>对发电机输出具有有意义且一致的影响。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lq"><img src="../Images/416b9f0674bb74686669841c6249cb3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U35fSJ9aMBQQNSYVVhDguQ.png"/></div></div></figure><p id="47fd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，没有系统的方法找到这些结构。这个过程是非常手动的:1)生成一堆图像，2)找到具有你想要的特征的图像，3)将它们的噪声向量平均在一起，并希望它捕捉到感兴趣的结构。</p><p id="d225" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">改变发电机输出的唯一“旋钮”是噪声输入。因为它是噪音，所以没有关于如何修改它以获得想要的效果的直觉。问题是:“如果你想要一个戴眼镜的男人的图像——你如何改变噪声？”这是一个问题，因为你的表象是<em class="kl">纠缠</em>。InfoGAN试图解决这个问题，并提供了一个<em class="kl">清晰的表示</em>。</p><p id="a257" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个想法是提供一个<em class="kl">潜在代码</em>，它对输出有意义和一致的影响。例如，假设您正在处理MNIST手写数字数据集。你知道有10个数字，所以如果你能通过把部分输入赋给一个10态离散变量来使用这个结构就好了。希望是，如果你保持代码不变，随机改变噪声，你会得到<em class="kl">相同数字</em>的变体。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi mc"><img src="../Images/f1c2ca9728b91306e7bab56b131f0f97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rn0gZXRDHmG7PnBRAq70VQ.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Entangled vs Disentangled</figcaption></figure><h1 id="757e" class="kn ko iq bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">InfoGAN</h1><p id="123e" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">InfoGAN解决这个问题的方法是将生成器输入分成两部分:传统的噪声向量和新的“潜在代码”向量。然后，通过最大化代码和发电机输出之间的<a class="ae km" href="https://en.wikipedia.org/wiki/Mutual_information" rel="noopener ugc nofollow" target="_blank">互信息</a>，使代码变得有意义。</p><h2 id="48a1" class="mh ko iq bd kp mi mj dn kt mk ml dp kx jy mm mn lb kc mo mp lf kg mq mr lj ms bi translated">理论</h2><p id="2828" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">该框架仅通过将正则化项(红框)添加到原始GAN的目标函数来实现。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/d8bc782ec8b0185b6da401e3ff8952c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*rSZXfx4_xcC-5z4LirNDRQ.png"/></div></figure><p id="9236" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">λ是正则化常数，通常设置为1。<em class="kl">我(c；G(z，c)) </em>项是潜在码<em class="kl"> c </em>和发电机输出<em class="kl"> G(z，c) </em>之间的互信息。</p><p id="0f21" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">显式计算互信息是不实际的，因此使用标准的变分论点来近似下限。这包括引入一个“辅助”分布<em class="kl"> Q(c|x) </em>，该分布由一个参数化的神经网络建模，并且旨在逼近真实的<em class="kl"> P(c|x) </em>。<em class="kl"> P(c|x) </em>表示在给定生成的输入<em class="kl"> x </em>的情况下，码<em class="kl"> c </em>的可能性。然后，他们使用一种重新参数化的技巧，使您可以只从用户指定的先验(即均匀分布)中采样，而不是未知的后验。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/65e63a36ba1b4e4cf5e0783d10c4193f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*NTYmbgNBT9RzhdLl71-koA.png"/></div></figure><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/4d7e6fd31a44c5174dab9ac1c0d47de0.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*92L-ml_k7iQcPIWcvT7TIw.png"/></div></figure><p id="b0b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面的正则项转化为以下过程:从你选择的先验中为潜在代码<em class="kl"> c </em>采样一个值；从您选择的先验中采样噪声值<em class="kl">z</em>；生成<em class="kl"> x = G(c，z)</em>；计算<em class="kl"> Q(c|x=G(c，z)) </em>。</p><p id="4cd5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，目标函数的最终形式由互信息的下限近似给出:</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/d0c7fe201d2b30cfa5a4b91f7cbfd76a.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*W2G0DFBQUa52Piy1snYVjQ.png"/></div></figure><h2 id="b9cd" class="mh ko iq bd kp mi mj dn kt mk ml dp kx jy mm mn lb kc mo mp lf kg mq mr lj ms bi translated">体系结构</h2><p id="b52e" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">如上所述，现在有了生成器的第二个输入:潜在代码。理论部分介绍的辅助分布由另一个神经网络模拟，它实际上只是一个完全连接的层，附加在鉴别器的最后一个表示层上。Q网络本质上是试图预测代码是什么(见下面的细微差别)。这只在输入假输入时使用，因为这是唯一知道代码的时候。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi mx"><img src="../Images/cc9c4348d9e8352559128c11e12a949d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dXLgTV8lNiTInvxomgZSAg.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">InfoGAN architecture. New components outlined in red.</figcaption></figure><p id="c1b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里有一个很难理解的细微差别。为了计算正则项，您不需要估计代码本身，而是需要估计对于给定的生成输入，看到该代码的<em class="kl">可能性</em>。因此，<em class="kl"> Q </em>的输出不是代码值本身，而是您选择用来对代码建模的分布的统计数据。一旦知道了概率分布的充分统计量，就可以计算可能性了。</p><p id="6f84" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如，如果您使用连续值代码(即在-1和+1之间)，您可以将<em class="kl"> Q(c|x) </em>建模为正态/高斯分布。在这种情况下，<em class="kl"> Q </em>将为这部分代码输出两个值:平均值和标准差。一旦你知道了平均值和标准差，你就可以计算出可能性<em class="kl"> Q(c|x)，</em>，这就是你需要的正则项。</p><h1 id="38e7" class="kn ko iq bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">结果</h1><p id="d71d" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">在MNIST手写数字数据集上的训练报告了初步结果。作者指定了一个10态离散码(希望它能映射到手写的数字值)，以及两个介于-1到+1之间的连续码。为了进行比较，他们训练了一个具有相同结构的常规GAN，但没有使用最大化互信息的正则化项。</p><p id="821e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下图显示了一个过程，其中特定的噪声矢量保持不变(每行)，但潜在代码发生了变化(每列)。在部分<em class="kl"> a </em>中，您可以看到离散代码不断改变数字。部分<em class="kl"> b </em>显示常规GAN基本上没有显著或一致的变化。</p><p id="a4a6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">零件<em class="kl"> c </em>和<em class="kl"> d </em>显示了InfoGAN的连续代码变化。这显然会影响手指的倾斜度和宽度。有趣的是，它们实际上从-2变化到+2，即使训练只使用从-1到+1的值，这表明这些代码有意义地推断。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi my"><img src="../Images/337ecb5ceecdc001835162f3e3738b0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*kyyjNnuNaOscjucBpql2AA.png"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Comparing InfoGAN to regular GAN when changing code values. From InfoGAN paper.</figcaption></figure><p id="3ab7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一些面部图像的结果。请参见<a class="ae km" href="https://arxiv.org/pdf/1606.03657.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>了解更多结果和解释。</p><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi my"><img src="../Images/1bcb73e84160b06a4d8ca390e8638656.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*Qa5zeA2_TgngrVh38oclaw.png"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Results on 3D face model dataset</figcaption></figure><figure class="lr ls lt lu gt lv gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/f20895cb943944c003e0aad2fe542f97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*wOUkeLmh_6sHJ6ykAcQCiQ.png"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Results on CelebA dataset</figcaption></figure><h1 id="cdfe" class="kn ko iq bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">结论</h1><p id="3b4b" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">值得强调的是，从来没有预先指定倾斜或手指粗细将有助于分离为代码。InfoGAN训练程序自己发现了这些属性，即在无人监督的情况下。这项研究做的唯一事情就是确定潜在代码的结构。</p><p id="2ced" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们已经看到，通过简单地添加一个项，最大化部分生成器输入与其输出之间的互信息，学习过程将数据中有意义的属性解开，并将它们分配给这个强加的潜在代码结构。</p><h1 id="6752" class="kn ko iq bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">你做吧</h1><p id="e577" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">我发现<a class="ae km" href="https://github.com/openai/InfoGAN" rel="noopener ugc nofollow" target="_blank">原始回购</a>很难运行，因为它的依赖关系非常陈旧。我已经<a class="ae km" href="https://github.com/zjost/InfoGAN" rel="noopener ugc nofollow" target="_blank">更新了代码</a>，这样你就可以用现代Tensorflow APIs(版本1.3.0)运行了。</p><h1 id="0bea" class="kn ko iq bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">继续挖</h1><p id="b315" class="pw-post-body-paragraph jn jo iq jp b jq ll js jt ju lm jw jx jy ln ka kb kc lo ke kf kg lp ki kj kk ij bi translated">在这个由3部分组成的系列中，我们已经介绍了一些主要的贡献，并看到了GANs所做的惊人的事情。尽管如此，这仅仅触及了表面。有多个github repos，其中包含大量且不断增长的研究论文。这里有<a class="ae km" href="https://github.com/zhangqianhui/AdversarialNetsPapers" rel="noopener ugc nofollow" target="_blank">一个</a>，这里有<a class="ae km" href="https://github.com/nightrome/really-awesome-gan" rel="noopener ugc nofollow" target="_blank">另一个</a>。这是一个令人兴奋的研究领域，其成熟度和有效性都在不断提高。如果你在这里发现了你想评论的某篇论文，请在评论中留言。</p></div></div>    
</body>
</html>