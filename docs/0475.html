<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://towardsdatascience.com/gradient-descent-is-a-first-order-iterative-optimization-algorithm-wikipedia-4d2174528bfa?source=collection_archive---------4-----------------------#2017-05-08">https://towardsdatascience.com/gradient-descent-is-a-first-order-iterative-optimization-algorithm-wikipedia-4d2174528bfa?source=collection_archive---------4-----------------------#2017-05-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/0df8850414ab5759e86c489e46619378.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UbJy1_1TGVKNQbMCsIaHEQ.png"/></div></div><figcaption class="jc jd gj gh gi je jf bd b be z dk">Image: Pixabay</figcaption></figure><p id="6349" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">梯度下降:当你骑自行车的时候建造它。</p><p id="07b8" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">"<strong class="jj kf">梯度下降</strong>是一种<a class="ae kg" href="https://en.wikipedia.org/wiki/Category:First_order_methods" rel="noopener ugc nofollow" target="_blank">一阶</a> <a class="ae kg" href="https://en.wikipedia.org/wiki/Iterative_algorithm" rel="noopener ugc nofollow" target="_blank">迭代</a> <a class="ae kg" href="https://en.wikipedia.org/wiki/Mathematical_optimization" rel="noopener ugc nofollow" target="_blank">优化</a> <a class="ae kg" href="https://en.wikipedia.org/wiki/Algorithm" rel="noopener ugc nofollow" target="_blank">算法</a>"-维基百科</p><p id="f952" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">我认为“优化”这个词让所有人都迷惑了。词典将“优化”定义为动词:“使尽可能完美、有效或实用。”</p><p id="0adf" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">我假设已经创建了一个次优对象— <em class="kh">然后</em>我通过添加东西来优化它！想到的是自行车。<a class="ae kg" href="http://earlyretirementextreme.com/a-few-things-you-can-do-to-optimize-your-bicycle.html" rel="noopener ugc nofollow" target="_blank">一辆新自行车通常不适合骑车人，但骑车人会将自行车“调”到最佳状态。</a>这里，调谐过程与制造过程是分开的。</p><p id="5d5c" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">然而，梯度下降包含两个部分<em class="kh">；</em>“造自行车”本身的过程<em class="kh">就是</em>优化它的过程。想象一个外星人——姑且称他为<a class="ae kg" href="https://en.wikipedia.org/wiki/Ford_Prefect_(character)" rel="noopener ugc nofollow" target="_blank">福特长官</a>——在没有说明书的情况下建造一辆宜家设计的自行车。</p><p id="d6c1" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">我们的自行车制造外星人得到了一些轮子，并将它们连接到一个框架上(没有踏板，没有把手，没有座位)。显然，自行车很糟糕，但这是一个开始。</p><p id="dbf2" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">现在，想象一下福特·普瑞福瑞必须试驾这辆自行车(不知何故)。自行车无法工作的数量是安装自行车的“误差”(在这种情况下，是<em class="kh">很多)。</em></p><p id="46d3" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">接下来，他只是增加了齿轮，再试一次，仍然失败，但比上一次少一点。然后他增加了踏板，失败的次数更少了。最终，每次优化他的自行车时，福特长官都会稍微调整一下他的自行车——因为每次需要改进的地方越来越少。当然，他的自行车每次骑行失败的数量——他的“错误”——在他的自行车制造的每次迭代中变得越来越小。</p><p id="c656" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">现在，假设我们将误差绘制在图表上:</p><figure class="kj kk kl km gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ki"><img src="../Images/63750b93d4ccb832a58fd92dfecb04c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Id_hYRmnVQpqr--_xhxCg.png"/></div></div></figure><p id="9eaf" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">请注意，在制造更好的自行车的每一步，都没有“踩下”已经存在的曲线，而是过程的每一次迭代实际上<em class="kh">在进行中创建</em>曲线。</p><p id="6f5d" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">在梯度下降中，我们正在建立一个模型，而不是一辆自行车，但梯度下降的每次迭代同时<em class="kh">和</em>会创建一个更好的拟合模型(希望如此)，该模型的误差会创建一个损失函数，由一条曲线(或碗，或一些小山——取决于我们正在建立的模型)表示。曲线向局部最优(即“底部”)的每次“下降”运动都与我们模型的“更好拟合”迭代相关。</p><blockquote class="kn"><p id="87f6" class="ko kp ji bd kq kr ks kt ku kv kw ke dk translated"><em class="kx">每当我们的模型更好地实现我们的目标(回归或分类)时，我们就减少错误。每次我们减少误差，损失函数的斜率就会降低。</em></p></blockquote><p id="a713" class="pw-post-body-paragraph jg jh ji jj b jk ky jm jn jo kz jq jr js la ju jv jw lb jy jz ka lc kc kd ke im bi translated"><strong class="jj kf">迭代</strong>是我们告诉算法运行数据以适应模型的次数。这意味着我们不能保证达到最优。想象一下，福特·普里菲斯特在他的自行车第二次迭代后停下来了！</p><p id="2fa6" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">最后，我们可以根据<strong class="jj kf">“学习率”</strong>对此进行调快或调慢。这是我们告诉模型每次调整的量。当我们将学习率放入梯度下降算法时，它会告诉算法在哪里取[部分]导数，并使斜率趋向最小值。选择小的和大的“台阶”是有权衡的。</p><p id="389c" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">如果我们告诉它以小的间隔求导，算法将需要很长时间才能达到最小值，这是非常直观的。例如，想象一下福特·普里菲蒂特必须一次增加一个轮辐。</p><p id="9ddd" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">如果我们告诉算法以更宽的间隔检查点，我们也可以超越最佳模型。如果福特Prefect跳过了加档位这一步会怎么样？</p><p id="73ef" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">当我学习梯度下降时，我们的老师使用微积分，通过[偏导数]找到一条沿着损失函数向下倾斜的切线，从而找到局部(但理想情况下是全局)最优值。吴恩达在他的在线机器学习课程中解释了线性回归的梯度下降背后的数学原理。</p><p id="f824" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">在互联网上，我发现了许多优秀的博客，向您展示如何用Python创建一个梯度体面算法，在三维空间中可视化损失函数，当然，还提供了无处不在的山/碗类比:</p><blockquote class="kn"><p id="bd92" class="ko kp ji bd kq kr ks kt ku kv kw ke dk translated"><em class="kx">“想象一个人想要到达一座山的底部。他们一步步走向底部，直到到达那里。”</em></p></blockquote><blockquote class="ld le lf"><p id="97f5" class="jg jh kh jj b jk ky jm jn jo kz jq jr lg la ju jv lh lb jy jz li lc kc kd ke im bi translated">我挑战自己，试图向我4岁的儿子解释这个概念，他问:“他为什么不乘雪橇到底部呢？”他的直觉是，一个人“只知道”如何下去，重力会把他带到那里。</p></blockquote><blockquote class="kn"><p id="8b26" class="ko kp ji bd kq kr lj lk ll lm ln ke dk translated">这让我想到，我们必须考虑梯度下降，就像在每次迭代中故意一点一点地创建模型一样，同时减少损失。本质上，它们是一回事。</p></blockquote><p id="4953" class="pw-post-body-paragraph jg jh ji jj b jk ky jm jn jo kz jq jr js la ju jv jw lb jy jz ka lc kc kd ke im bi translated"><strong class="jj kf">资源:</strong></p><p id="ae84" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated">这里有一些惊人的资源，可以帮助您使用梯度下降可视化构建线性回归和逻辑回归。</p><p id="e0cb" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated"><a class="ae kg" href="https://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/" rel="noopener ugc nofollow" target="_blank">https://spin . atomic object . com/2014/06/24/gradient-descent-linear-regression/</a></p><p id="d3c9" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated"><a class="ae kg" href="http://www.pyimagesearch.com/2016/10/10/gradient-descent-with-python/http://www.pyimagesearch.com/2016/10/10/gradient-descent-with-python/http://www.pyimagesearch.com/2016/10/10/gradient-descent-with-python/http://www.pyimagesearch.com/2016/10/10/gradient-descent-with-python/http://www.pyimagesearch.com/2016/10/10/gradient-descent-with-python/" rel="noopener ugc nofollow" target="_blank">http://www . pyimagesearch . com/2016/10/10/gradient-descent-with-python/</a></p><p id="08d5" class="pw-post-body-paragraph jg jh ji jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke im bi translated"><a class="ae kg" href="https://github.com/mattnedrich/GradientDescentExample/blob/master/readme.mdhttps://github.com/mattnedrich/GradientDescentExample/blob/master/readme.md" rel="noopener ugc nofollow" target="_blank">https://github . com/mattnedrich/GradientDescentExample/blob/master/readme . MD https://github . com/mattnedrich/GradientDescentExample/blob/master/readme . MD</a></p></div></div>    
</body>
</html>