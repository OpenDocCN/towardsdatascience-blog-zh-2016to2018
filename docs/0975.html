<html>
<head>
<title>Deep Learning #4: Why You Need to Start Using Embedding Layers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习#4:为什么你需要开始使用嵌入层</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-4-embedding-layers-f9a02d55ac12?source=collection_archive---------0-----------------------#2017-07-17">https://towardsdatascience.com/deep-learning-4-embedding-layers-f9a02d55ac12?source=collection_archive---------0-----------------------#2017-07-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="dc60" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">以及它不仅仅是单词嵌入。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/70acedde766255842350113467c63b64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sXNXYfAqfLUeiDXPCo130w.png"/></div></div></figure><p id="eaff" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这篇文章是深度学习系列文章的一部分。在这里检查其他部分:</p><ol class=""><li id="2e44" class="lo lp iq kt b ku kv kx ky la lq le lr li ls lm lt lu lv lw bi translated"><a class="ae lx" href="https://medium.com/towards-data-science/deep-learning-1-1a7e7d9e3c07" rel="noopener">设置AWS &amp;图像识别</a></li><li id="637d" class="lo lp iq kt b ku ly kx lz la ma le mb li mc lm lt lu lv lw bi translated"><a class="ae lx" href="https://medium.com/towards-data-science/deep-learning-2-f81ebe632d5c" rel="noopener">卷积神经网络</a></li><li id="1298" class="lo lp iq kt b ku ly kx lz la ma le mb li mc lm lt lu lv lw bi translated"><a class="ae lx" href="https://medium.com/towards-data-science/deep-learning-3-more-on-cnns-handling-overfitting-2bd5d99abe5d" rel="noopener">更多关于CNN&amp;处理过度拟合的信息</a></li></ol></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><p id="2ed3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">欢迎来到深度学习系列的第4部分。你可能已经注意到，前三篇文章和这篇文章之间有一点延迟。这个系列最初的目标是与深度学习的fast.ai课程一起写作。然而，后面讲座的概念经常重叠，所以我决定先完成课程。通过这种方式，我可以更详细地概述这些主题。在这篇博客中，我想介绍一个概念，它跨越了课程(4-6)的多个讲座，并且在实践中证明对我非常有用:<strong class="kt ir"> </strong>嵌入层。</p><p id="eb85" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在介绍时，嵌入层的概念可能是非常陌生的。例如，Keras文档除了“将正整数(索引)转化为固定大小的密集向量”之外，没有提供任何解释。快速的谷歌搜索可能也不会让你走得更远，因为这些类型的文档是首先弹出的东西。然而，在某种意义上，Keras的文档描述了所有发生的事情。那么，为什么要使用嵌入层呢？这里有两个主要原因:</p><ol class=""><li id="710e" class="lo lp iq kt b ku kv kx ky la lq le lr li ls lm lt lu lv lw bi translated">独热编码矢量是高维稀疏的。假设我们在做自然语言处理(NLP)，有一个2000字的字典。这意味着，当使用一键编码时，每个单词将由一个包含2000个整数的向量来表示。并且这些整数中的1999个是零。在大型数据集中，这种方法计算效率不高。</li><li id="4b3d" class="lo lp iq kt b ku ly kx lz la ma le mb li mc lm lt lu lv lw bi translated">每次嵌入的向量在训练神经网络时得到更新。如果你看过这篇文章顶部的图片，你就会明白如何在多维空间中找到单词之间的相似之处。这使我们可以可视化单词之间的关系，也可以通过嵌入层将一切转化为矢量。</li></ol><p id="3bf2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这个概念可能还是有点模糊。让我们用一个单词的例子来看看嵌入层是做什么的。然而，嵌入的起源来自于词的嵌入。有兴趣了解更多可以查一下<a class="ae lx" href="https://arxiv.org/pdf/1301.3781.pdf" rel="noopener ugc nofollow" target="_blank"> word2vec </a>。让我们以这句话为例(不要当真):</p><blockquote class="mk ml mm"><p id="85fe" class="kr ks ln kt b ku kv jr kw kx ky ju kz mn lb lc ld mo lf lg lh mp lj lk ll lm ij bi translated">“深度学习很深”</p></blockquote><p id="fb71" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">使用嵌入层的第一步是通过索引对这个句子进行编码。在这种情况下，我们为每个唯一的单词分配一个索引。句子看起来是这样的:</p><blockquote class="mk ml mm"><p id="e78a" class="kr ks ln kt b ku kv jr kw kx ky ju kz mn lb lc ld mo lf lg lh mp lj lk ll lm ij bi">1 2 3 4 1</p></blockquote><p id="db8c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来创建嵌入矩阵。我们决定给每个指数分配多少“潜在因素”。基本上这意味着我们希望向量有多长。一般的用例是32和50这样的长度。让我们在这篇文章中为每个指数分配6个潜在因素，以保持可读性。嵌入矩阵看起来像这样:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/45cd335aeaa95393a8b806ef5587d233.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*Di85w_0UTc6C3ilk5_LEgg.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">Embedding Matrix</figcaption></figure><p id="786b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，我们可以使用嵌入矩阵来保持每个向量的大小更小，而不是以巨大的独热编码向量结束。简而言之，所有发生的事情就是单词“deep”由一个向量[.32、. 02、. 48、. 21、. 56、. 15]表示。然而，并不是每个单词都被向量所取代。相反，它被用于在嵌入矩阵中查找向量的索引所取代。同样，当使用非常大的数据集时，这在计算上是高效的。因为嵌入的向量也在深度神经网络的训练过程中得到更新，所以我们可以在多维空间中探索哪些单词是彼此相似的。通过使用像t-SNE这样的降维技术，这些相似性可以被可视化。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mv"><img src="../Images/a7b38c6fc3573afe4508becd0c2f0332.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m8Ahpl-lpVgm16CC-INGuw.png"/></div></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">t-SNE visualization of word embeddings</figcaption></figure></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="ae7c" class="mw mx iq bd my mz na nb nc nd ne nf ng jw nh jx ni jz nj ka nk kc nl kd nm nn bi translated">不仅仅是单词嵌入</h1><p id="ca1d" class="pw-post-body-paragraph kr ks iq kt b ku no jr kw kx np ju kz la nq lc ld le nr lg lh li ns lk ll lm ij bi translated">这些前面的例子表明，单词嵌入在自然语言处理领域非常重要。它们让我们能够捕捉语言中的关系，否则很难捕捉。然而，嵌入层可以用来嵌入更多的东西，而不仅仅是文字。在我目前的研究项目中，我使用嵌入层来嵌入在线用户行为。在这种情况下，我为用户行为分配指数，如“门户Y上页面类型X的页面视图”或“滚动X像素”。这些指数然后被用于构建用户行为序列。</p><p id="74af" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在“传统”机器学习模型(SVM、随机森林、梯度增强树)与深度学习模型(深度神经网络、递归神经网络)的比较中，我发现这种嵌入方法对深度神经网络非常有效。</p><p id="661b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">“传统的”机器学习模型依赖于特征工程的表格输入。这意味着，作为研究人员，我们决定什么会变成一个特征。在这些情况下，特征可以是:访问的主页数量，完成的搜索数量，滚动的像素总量。然而，在进行特征工程时，很难捕捉空间(时间)维度。通过使用深度学习和嵌入层，我们可以通过提供一系列用户行为(作为索引)作为模型的输入来有效地捕捉这个空间维度。</p><p id="195c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在我的研究中，具有门控循环单元/长短期记忆的循环神经网络表现最好。结果非常接近。从“传统”特征工程模型来看，梯度增强树表现最好。以后我会写一篇关于这项研究的更详细的博文。我想我的下一篇博文将更详细地探索递归神经网络。</p><p id="adbd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">其他研究探索了使用嵌入层来编码MOOCs中的学生行为(皮赫等人，2016年)和用户通过在线时装商店的路径(塔姆哈尼等人，2017年)。</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h2 id="2576" class="nt mx iq bd my nu nv dn nc nw nx dp ng la ny nz ni le oa ob nk li oc od nm oe bi translated">推荐系统</h2><p id="0cda" class="pw-post-body-paragraph kr ks iq kt b ku no jr kw kx np ju kz la nq lc ld le nr lg lh li ns lk ll lm ij bi translated">嵌入层甚至可以用来处理推荐系统中的稀疏矩阵问题。由于深度学习课程(fast.ai)使用推荐系统来引入嵌入层，所以我也想在这里探索它们。</p><p id="d945" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">推荐系统到处都在使用，你可能每天都受到它们的影响。最常见的例子是亚马逊的产品推荐和网飞的节目推荐系统。实际上，网飞举办了一场100万美元的挑战赛，为他们的推荐系统寻找最佳的协同过滤算法。你可以在这里看到这些模型中的一个<a class="ae lx" href="http://abeautifulwww.com/wp-content/uploads/2007/04/netflixAllMovies-blackBack3[5].jpg" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="922a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">有两种主要类型的推荐系统，区分这两种是很重要的。</p><ol class=""><li id="db2a" class="lo lp iq kt b ku kv kx ky la lq le lr li ls lm lt lu lv lw bi translated">基于内容的过滤。这种类型的过滤基于关于项目/产品的数据。例如，我们让用户填写一份关于他们喜欢什么电影的调查。如果他们说他们喜欢科幻电影，我们会向他们推荐科幻电影。在这种情况下，所有项目都必须有大量的元信息。</li><li id="1d25" class="lo lp iq kt b ku ly kx lz la ma le mb li mc lm lt lu lv lw bi translated">协同过滤:让我们找到和你一样的人，看看他们喜欢什么，然后假设你也喜欢同样的东西。像你这样的人=对你看过的电影评价相似的人。在大型数据集中，这已被证明比元数据方法好得多。从本质上讲，询问人们的行为不如观察他们的实际行为好。进一步讨论这个问题是我们当中的心理学家的事情。</li></ol><p id="183e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了解决这个问题，我们可以创建一个所有用户对所有电影的评级的巨大矩阵。然而，在许多情况下，这将创建一个极其稀疏的矩阵。想想你在网飞的账户。你看过的连续剧和电影占他们总供应量的百分比是多少？这可能是一个很小的百分比。然后，通过梯度下降，我们可以训练一个神经网络来预测每个用户对每部电影的评价有多高。如果你想知道更多关于深度学习在推荐系统中的使用，请告诉我，我们可以一起进一步探索。总之，嵌入层是惊人的，不应该被忽视。</p><p id="eeb0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你喜欢这篇文章，一定要推荐给别人看。你也可以按照这个简介来跟上我在快速人工智能课程中的进程。那里见！</p><h2 id="984d" class="nt mx iq bd my nu nv dn nc nw nx dp ng la ny nz ni le oa ob nk li oc od nm oe bi translated">参考</h2><p id="1c97" class="pw-post-body-paragraph kr ks iq kt b ku no jr kw kx np ju kz la nq lc ld le nr lg lh li ns lk ll lm ij bi translated">c .、Bassen、j .、Huang、j .、Ganguli、s .、Sahami、m .、Guibas、L. J .、&amp; Sohl-Dickstein，J. (2015年)。<em class="ln">深度知识溯源。神经信息处理系统进展</em>(第505-513页)。</p><p id="17b1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">塔哈内，a .，阿罗拉，s .，&amp;瓦里耶，D. (2017年5月)。<em class="ln">对时尚电子商务中用户行为的情境变化进行建模</em>。亚太知识发现和数据挖掘会议(第539-550页)。斯普林格，查姆。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi of"><img src="../Images/338e91424f021d6b703d7808e936e534.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*DCO2zagLK2ukqojzv9jV8g.gif"/></div></div></figure></div></div>    
</body>
</html>