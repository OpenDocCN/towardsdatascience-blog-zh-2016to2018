<html>
<head>
<title>Getting started with AutoML Vision alpha</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AutoML Vision alpha 入门</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-started-with-automl-vision-alpha-ba769121235c?source=collection_archive---------5-----------------------#2018-07-11">https://towardsdatascience.com/getting-started-with-automl-vision-alpha-ba769121235c?source=collection_archive---------5-----------------------#2018-07-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/9b60859acc589d62a556f7bff1df0491.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MgJKWZLoRP9E9-iwnjmlQg.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">May your path to machine learning be less twisted</figcaption></figure><div class=""/><p id="dca7" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我演讲时被问到的最多的事情之一是<a class="ae la" href="https://cloud.google.com/automl/" rel="noopener ugc nofollow" target="_blank">谷歌云自动化</a>。让我们使用 AutoML Vision alpha 来构建和部署一个机器学习模型，该模型可以识别不同类型的椅子，以及一些其他项目。我们正在做所有的事情，从原始数据收集一直到为模型服务，以及中间的所有事情！</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lb"><img src="../Images/0634e52fc9cff95afe2a56b05d1b54c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Y80_Id_zEAMyf3ggWTuMQ.jpeg"/></div></div></figure><p id="1ef3" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">许多人一直嚷嚷着要访问 AutoML Vision alpha，我想对工作流程做一个简单的介绍，向您展示使用它的感觉，即使您还没有离开等待名单。在<a class="ae la" href="https://www.youtube.com/watch?v=kgxfdTh9lz0" rel="noopener ugc nofollow" target="_blank">第一个视频</a>中，我们将把数据转换成 AutoML Vision 的正确格式。然后在第二部分的<a class="ae la" href="https://youtu.be/aUfIFoMEIgg" rel="noopener ugc nofollow" target="_blank">中，我们将使用它建立一个模型来检测图片中的椅子是什么风格。让我们开始吧。</a></p><figure class="lc ld le lf gt is"><div class="bz fp l di"><div class="lg lh l"/></div></figure><h1 id="7aaf" class="li lj jf bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">那么……什么是 AutoML？</h1><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mg"><img src="../Images/7f27c1359d707883e2749a20f28d3183.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HGItCh2JJgDx_iSgYKqgaQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Cloud Vision API can identify a chair, but it’s generic</figcaption></figure><p id="4e6e" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">AutoML 如此引人注目的原因之一是定制模型。像<a class="ae la" href="https://cloud.google.com/vision/" rel="noopener ugc nofollow" target="_blank"> Cloud Vision API </a>这样的现有模型和服务可以毫无问题地识别出一张给定的图片中可能有一把椅子，但是如果您设计并制造了椅子，并且需要一种方法来对库存中的各种品牌的椅子进行分类，该怎么办呢？可以说，如果能够使用一个“定制”视觉 API 来识别您的<strong class="ke jg"> <em class="mh">特定椅子</em></strong>不是很好吗？这就是 AutoML Vision 的目标。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mi"><img src="../Images/336f56cf71cce98fda90e56706e25587.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tDE7kOgBKhHkXpt5"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">This is a yellow chair</figcaption></figure><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mi"><img src="../Images/71112855e5dcb497c2334fe1951257a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*glJTNtkUylkDVyAS"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Here are some more chairs :)</figcaption></figure><p id="b28d" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke jg"> AutoML Vision 将大量带标签的照片作为输入</strong>。你问多少张照片？理想情况下，每个对象数百个就不错了。所以走出去，开始拍照吧。如果你厌倦了点击快门按钮，你可以试试我一直在用的另一种方法。</p><h1 id="426c" class="li lj jf bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">用视频拍照！</h1><p id="e5ed" class="pw-post-body-paragraph kc kd jf ke b kf mj kh ki kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz ij bi translated">为了更容易地为 AutoML Vision 捕获数据，我通过捕获我感兴趣的椅子的<em class="mh">视频</em>来收集我的训练数据，然后使用<code class="fe mo mp mq mr b">ffmpeg</code>来提取帧。</p><p id="6736" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我去了谷歌桑尼维尔园区，拍了一些各种不同户外椅子的视频。我还拍了一些他们周围桌子的视频，还有一辆自行车，只是为了让事情更有趣一点。</p><p id="6fdc" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">让我们来看一个例子。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ms"><img src="../Images/e98178009fc84240207578cfbe6914f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*XmnMzsuNaTkYQ8Pejc3xCg.gif"/></div></div></figure><p id="287a" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">有不同形状、风格和颜色的椅子。没有视频长度超过 30 秒。我们有一张桌子的短片，还有一张自行车的短片。这就是我们将要处理的数据。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ms"><img src="../Images/e73fa3bbffdee626da854ef66a9bd249.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*PiXjrvMd8KM23H2kxn0i1A.gif"/></div></div></figure><h1 id="5606" class="li lj jf bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">分割您的视频</h1><p id="daa6" class="pw-post-body-paragraph kc kd jf ke b kf mj kh ki kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz ij bi translated">我们想要的最终状态是一个 CSV 文件，每个图像有一行，两列，第一列是图像在 Google 云存储中的位置，第二列是标签，如“红椅子”、“桌子”或“蓝椅子”。</p><p id="0ba9" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为了便于组织，我将每个视频放在了各自的文件夹中。然后我们可以依次对每个视频文件运行<code class="fe mo mp mq mr b">ffmpeg</code>。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/0cd8674ec3996771c24fee12e42a9d57.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*KaSyac4WZBBlkH5VuxFqbA.png"/></div></figure><p id="2043" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">提取帧后，每个标签都有一个文件夹，里面装满了该标签的图像。这是一种组织图片的便捷方式，比用一个巨大的文件夹存放所有图片要简单得多。</p><p id="8d17" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><code class="fe mo mp mq mr b">ffmpeg -i chair.mp4 chair%03d.jpg</code> <br/>(文件名中的<code class="fe mo mp mq mr b">%03d</code>会给我们 3 位数的填充编号，如<code class="fe mo mp mq mr b">chair003.jpg</code>、<code class="fe mo mp mq mr b">chair073.jpg</code>等。如果您有超过 999 张图像，您应该使用<code class="fe mo mp mq mr b">%04d</code>或其他合适的值)</p><p id="96c3" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">接下来，我们可以使用<code class="fe mo mp mq mr b">gsutil</code>将图像上传到 Google 云存储，复制每个标签一个文件夹的文件夹结构:</p><p id="e202" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><code class="fe mo mp mq mr b">gsutil -m cp -r all_data gs://cloudml-demo-vcm/dataset</code> <br/>(该命令递归复制/上传<code class="fe mo mp mq mr b">all_data</code>中的整个文件夹结构，并使用<code class="fe mo mp mq mr b">-m</code>对多个流进行复制/上传)</p><h1 id="d9b5" class="li lj jf bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">结构化您的数据</h1><p id="d9f0" class="pw-post-body-paragraph kc kd jf ke b kf mj kh ki kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz ij bi translated">AutoML 需要一种方法来知道在哪里可以找到你所有的照片，以及每张照片中的对象。我们需要创建一个 CSV 文件，为我想要包含在数据集中的每张图像列出<em class="mh">路径</em>和<em class="mh">标签</em>。有许多方法可以实现这一点，但我选择了旋转本地 Jupyter 笔记本并创建一个熊猫数据帧以导出为 CSV 文件。让我们在下面的视频中浏览一下。</p><figure class="lc ld le lf gt is"><div class="bz fp l di"><div class="lg lh l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Looking for the code/notebook shown above? It’s <a class="ae la" href="https://gist.github.com/yufengg/984ed8c02d95ce7e95e1c39da906ee04" rel="noopener ugc nofollow" target="_blank">here</a>!</figcaption></figure><p id="760f" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">好了，现在我们有了一个 CSV 文件，它描述了数据集中所有图像的位置和标签。我们准备好训练我们的模型了！</p><p id="a6c5" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这是你将图像加载到 AutoML Vision 后的样子。CSV 文件已经通知平台每个图像的正确标签是什么。如果您的图像还没有被标记，那也没关系——UI 中内置的工具可以帮助您完成标记过程，并显示哪些图像仍未被标记。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mu"><img src="../Images/59d0323e3cef035c9300ed8c108088aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YfXEaecJZkqEcEDcaylZRA.png"/></div></div></figure><h1 id="ee88" class="li lj jf bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">第 2 部分:培训和部署 AutoML Vision</h1><figure class="lc ld le lf gt is"><div class="bz fp l di"><div class="lg lh l"/></div></figure><h1 id="e687" class="li lj jf bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">训练模型</h1><p id="66f2" class="pw-post-body-paragraph kc kd jf ke b kf mj kh ki kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz ij bi translated">训练模型就像点击训练一样简单！这是我们一直在做的所有设置的要点。它使 AutoML Vision 能够获取数据，并在先进的图像模型上训练您的数据，并自动计算出适当的超参数，如网络结构。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mi"><img src="../Images/acc63750901bce064f3e8f25ca348e23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2xYfpHhLE0NKYyLq"/></div></div></figure><p id="513e" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">但是在您尝试更高级的模型之前，我建议您先从简单的模型开始，看看它的性能如何。这将为您提供一个基线，您可以用它来比较其他模型的相对性能。</p><p id="418b" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">训练开始后，去散散步，或者抓一把 coffee☕.鉴于我们已经提供了这么多数据，这需要一点时间。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/0cdea383b44dc99cd09b545d4fafd50d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cEi5KOgg8i-cZg-DBSSV0w.png"/></div></div></figure><h1 id="8249" class="li lj jf bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">评估您的模型</h1><p id="ab80" class="pw-post-body-paragraph kc kd jf ke b kf mj kh ki kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz ij bi translated">一旦训练完成，您将获得关于您的模型的各种统计数据，您可以使用这些数据来查看它的表现，以及是否有一些图像被错误标记，或者其他方面值得纠正，然后再进行重新训练。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mw"><img src="../Images/4e4692b69deaf88008bc5777b3f2c001.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N-J-pb1zdKRz8z3vIMMEfg.png"/></div></div></figure><p id="50fd" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在我们的例子中，由于我们通过设计收集了非常具体、干净的数据，我们得到了一些非常高的指标。然而，真正重要的是它在新的、看不见的数据上的表现。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ms"><img src="../Images/0d51cb54db06dce6de493cec65aaddae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7kDsr8cj2kjHom8J"/></div></div></figure><h1 id="3620" class="li lj jf bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">预测时间！</h1><p id="b35c" class="pw-post-body-paragraph kc kd jf ke b kf mj kh ki kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz ij bi translated">我拍了一些照片，试图挑战这个模型，看看它会返回什么。</p><p id="3f00" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">让我们试试这张图片，它包含了自行车，以及黄色和蓝色的椅子。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mx"><img src="../Images/1fc83fd3fde1cb834a9d963a597542ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H5R8HiG8sDjQ98rgmXZDfw.png"/></div></div></figure><p id="bf0f" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">好的，这张图片主要是自行车，但也有一点黄色和蓝色的椅子。它们在背景中，在这张照片中远没有那么突出。</p><p id="054d" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">让我们试试另一个。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi my"><img src="../Images/ce6fea6c51f2a026854e58481948273e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dD151lr7kyL4hjQ71FHT9Q.png"/></div></div></figure><p id="fc96" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这张图片大部分是黄色的椅子，但是也有一些蓝色的椅子。模特决定它主要看到黄色的椅子，和一点蓝色的椅子。</p><p id="4b52" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这张大部分是蓝色椅子的照片怎么样？</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mz"><img src="../Images/12ac0e49445f4a3e48c7a726a6c72ade.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yTcpEFJiWWjhpArcqmOhMg.png"/></div></div></figure><p id="f1ca" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">是的，这显示出大部分是蓝色的椅子，有一点桌子，有趣的是，有一点黄色的椅子，这不是预期的。不是所有的事情都是完美的，但是到目前为止，第一个选择已经被证明是相当好的。</p><p id="1b11" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">最后，这张图片怎么样，和上一张非常相似，但是前面的椅子是黄色的？模特会怎么想？</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi na"><img src="../Images/69acd0bf4d7c73b585eb634dabe5888f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KNqMSg0NRLPRoeCHs_kA6g.png"/></div></div></figure><p id="c714" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">哇，前景中的黄色椅子赢得了大奖！试图找出模型和数据集中的差距，以便更好地理解如何根据您的用例收集更可靠、更有代表性的数据，这可能是一件非常有趣的事情。</p><h1 id="3342" class="li lj jf bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated">包扎</h1><p id="1168" class="pw-post-body-paragraph kc kd jf ke b kf mj kh ki kj mk kl km kn ml kp kq kr mm kt ku kv mn kx ky kz ij bi translated">值得指出的是，在这一点上，模型可以通过它的 REST API 来调用。该服务利用 Cloud ML Engine 的在线预测功能来提供一个定制的、自动缩放的预测服务，<strong class="ke jg">，并在我们的数据集</strong>上进行训练。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nb"><img src="../Images/2cc9521bcc078bb53f958eb197812581.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h3fzbcLd4RnyEdN-WEpR8w.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">You can call your service via REST API from any server or internet-connected device</figcaption></figure><p id="483b" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">所有这一切的巧妙之处在于，一旦你的数据管道都设计好了，训练和部署机器学习模型的过程就完全不用动手了！这使您可以专注于让您的数据处于良好状态，并摆脱构建合适的计算机视觉机器学习模型的挑战。</p><figure class="lc ld le lf gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nc"><img src="../Images/4bd80fd69dbbd177171f81d5bf7c65e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w5wiye0MlyZlvDJRMzVwkg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Notice the annotation “AutoDeployed” below the model name</figcaption></figure><p id="17bc" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在，如果你不介意的话，我要去拍一些彩色椅子的视频，这样我就可以为我的 AutoML 视觉模型扩展我的数据集了！</p><p id="e037" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">快乐 p̵i̵c̵t̵u̵r̵e̵ <em class="mh">视频</em>-拍摄和汽车视觉模型训练！</p></div><div class="ab cl nd ne hu nf" role="separator"><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni nj"/><span class="ng bw bk nh ni"/></div><div class="ij ik il im in"><p id="f9e8" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">感谢阅读本集<a class="ae la" href="https://goo.gl/UC5usG" rel="noopener ugc nofollow" target="_blank">云 AI 冒险</a>。如果你喜欢这个系列，请为这篇文章鼓掌让我知道。如果你想要更多的机器学习动作，一定要关注媒体上的<a class="ae la" href="https://medium.com/@yufengg" rel="noopener">me</a>或订阅 YouTube 频道的<a class="ae la" href="https://goo.gl/S0AS51" rel="noopener ugc nofollow" target="_blank">来观看未来的剧集。更多剧集即将推出！</a></p><p id="5e7c" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果你还在读这篇文章，我希望收到你的来信！你有什么样的问题？你希望这个系列探索什么主题？有什么推荐的工具、技巧和窍门可以尝试吗？在下面的评论中分享吧！</p></div></div>    
</body>
</html>