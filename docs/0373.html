<html>
<head>
<title>Clustering: Why to Use it</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">集群:为什么要使用它</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/clustering-why-to-use-it-16d8e2fbafe?source=collection_archive---------3-----------------------#2017-04-24">https://towardsdatascience.com/clustering-why-to-use-it-16d8e2fbafe?source=collection_archive---------3-----------------------#2017-04-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="acc4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为一名没有编程背景的数据科学新生，我喜欢用简单的方式解释复杂的主题。好像在我的节目开始前自言自语。好吧，我希望你们都准备好了一些集群。</p><p id="d76d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们从什么是集群开始？事实上，你已经做过很多次了。这是寻找相似之处并将这些相似点放入一个组(或集群)的行为。让我们都回想一下上次出去吃饭的情形。你首先要弄清楚的是你想要什么类型的食物，墨西哥的、中国的、意大利的等等。你正在制造具有这些属性的多个餐馆的集群。</p><p id="b0f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在来看一个更加数据科学的例子，我将观察种子的不同属性，看看对这些属性进行聚类是否有助于预测种子是否属于某个物种。</p><p id="485d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">直接进入代码，我们需要导入库来执行下面几行。我还将在底部读取我的数据集</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="392a" class="ku kv iq kq b gy kw kx l ky kz">%matplotlib inline <br/><br/><strong class="kq ir">import</strong> <strong class="kq ir">pandas</strong> <strong class="kq ir">as</strong> <strong class="kq ir">pd</strong><br/><strong class="kq ir">import</strong> <strong class="kq ir">numpy</strong> <strong class="kq ir">as</strong> <strong class="kq ir">np</strong><br/><strong class="kq ir">from</strong> <strong class="kq ir">sklearn</strong> <strong class="kq ir">import</strong> cluster<br/><strong class="kq ir">from</strong> <strong class="kq ir">sklearn</strong> <strong class="kq ir">import</strong> metrics<br/><strong class="kq ir">from</strong> <strong class="kq ir">sklearn.metrics</strong> <strong class="kq ir">import</strong> pairwise_distances<br/><strong class="kq ir">import</strong> <strong class="kq ir">matplotlib.pyplot</strong> <strong class="kq ir">as</strong> <strong class="kq ir">plt</strong><br/><strong class="kq ir">import</strong> <strong class="kq ir">matplotlib</strong><br/>matplotlib.style.use('ggplot') <br/><br/><strong class="kq ir">import</strong> <strong class="kq ir">seaborn</strong> <strong class="kq ir">as</strong> <strong class="kq ir">sns</strong></span><span id="d935" class="ku kv iq kq b gy la kx l ky kz">seeds = pd.read_csv("../assets/datasets/seeds.csv")</span></pre><p id="958d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">看看我的数据框的前几行，这就是它的样子。使用pandas查看这一点的代码是seeds.head()，它将显示前5行</p><figure class="kl km kn ko gt lc gh gi paragraph-image"><div class="gh gi lb"><img src="../Images/6914124b1c2994c73535873012be0e3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*b__0KegWUwtWTqLJNmpUVg.png"/></div></figure><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="4e8c" class="ku kv iq kq b gy kw kx l ky kz">seeds.species.nunique()</span></pre><p id="d21e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我查看了我的“物种”列中独特值的数量，这是“目标值”列(我们试图预测的东西)。我们的数据集中有三个物种</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="6947" class="ku kv iq kq b gy kw kx l ky kz"><em class="lf"># Plot the Data to see the distributions/relationships</em><br/>cols = seeds.columns[:-1]<br/>sns.pairplot(seeds, x_vars=cols, y_vars= cols, hue='species')</span></pre><figure class="kl km kn ko gt lc gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lg"><img src="../Images/50a32d41519fa7035c0dbbc31cab0884.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RSD1P1oz4iRaz740Jry7mQ.png"/></div></div></figure><p id="a6d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一个散点图，显示了我们不同的变量是如何相互联系的，颜色(或我上面设置的色调)是每个不同的物种。因此，你可以开始看到，一般来说，对于我们的大多数变量(预测)，种子往往与它们自己的物种聚集在一起。</p><p id="f7bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为我们有一个目标值，所以我们可以在这里停止聚类，但是很多时候我们会在没有目标值的时候使用聚类。因此，我将放弃我们的目标，看看我们的聚类是否会发现差异，并很好地预测哪些种子应该聚集在一起。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="5fa5" class="ku kv iq kq b gy kw kx l ky kz">X = seeds.drop("species", axis = 1)</span><span id="4a62" class="ku kv iq kq b gy la kx l ky kz"><strong class="kq ir">from</strong> <strong class="kq ir">sklearn.metrics</strong> <strong class="kq ir">import</strong> pairwise_distances<br/><strong class="kq ir">from</strong> <strong class="kq ir">sklearn</strong> <strong class="kq ir">import</strong> cluster, datasets, preprocessing, metrics<br/>X_scaled = preprocessing.normalize(X,axis=0)</span></pre><p id="487b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我放弃了目标值，我还从sklearn导入了几个库，这样我就可以规范化我的数据。规范化数据是组织数据库的属性和关系以缩放范围[0，1]内的所有数值变量的过程。我们这样做是为了使permiter等值为15的列不会比紧致度等值低于1的列更重要</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="e591" class="ku kv iq kq b gy kw kx l ky kz"><strong class="kq ir">from</strong> <strong class="kq ir">sklearn.cluster</strong> <strong class="kq ir">import</strong> KMeans<br/><br/>k = 3<br/>kmeans = cluster.KMeans(n_clusters=k)<br/>kmeans.fit(X_scaled)</span></pre><p id="b8a4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我使用kmeans集群来解决这个问题。它设置随机质心(每组的中心点),这些质心将不断移动，直到它们位于一组点的中心，以使所有点的平均距离尽可能小。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="3848" class="ku kv iq kq b gy kw kx l ky kz">inertia = kmeans.inertia_<br/><strong class="kq ir">print</strong> 'Silhouette Score:', metrics.silhouette_score(X_scaled, labels, metric='euclidean')</span></pre><p id="d3a1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我在上面所做的是查看两个不同的指标来分析我们的聚类方法做得有多好。惯性是每个聚类的误差平方和。因此，惯性越小，集群越密集(所有点越靠近)</p><p id="756a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">轮廓分数从-1到1，显示了聚类之间的距离以及聚类的密度。你的轮廓分数越接近1，你的聚类就越明显。如果你的分数是1，把你的集群想象成完美的小球，它们彼此远离，没有分类失误。</p><p id="3330" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">聚类可以用在很多问题上，不管你有没有目标值，都有助于寻求洞见，看到关系。</p></div></div>    
</body>
</html>