<html>
<head>
<title>Tweet Like Trump with a One2Seq Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">像特朗普一样用 One2Seq 模型发推特</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tweet-like-trump-with-a-one2seq-model-cb1461f9d54c?source=collection_archive---------0-----------------------#2017-04-27">https://towardsdatascience.com/tweet-like-trump-with-a-one2seq-model-cb1461f9d54c?source=collection_archive---------0-----------------------#2017-04-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="a7b9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我将向您介绍我的项目的大部分内容，我创建了一个一对一的模型，可以生成类似于 Trump 的推文。实际模型与我在我的<a class="ae kl" href="https://medium.com/@Currie32/how-to-build-your-first-chatbot-c84495d4622d" rel="noopener">“如何构建你的第一个聊天机器人”</a>文章中构建的模型非常相似。这个模型的两个关键区别是输入和不包括注意力。注意力被排除在外，因为它没有显著提高生成的推文的质量。创建输入的步骤将是本文的重点。作为预览，我们将遵循以下路径:</p><ul class=""><li id="3372" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">清理特朗普的推文。</li><li id="b084" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">使用预先训练的单词向量创建单词向量(<a class="ae kl" href="https://nlp.stanford.edu/projects/glove/)" rel="noopener ugc nofollow" target="_blank"> GloVe — Twitter 200d </a>)。</li><li id="5a49" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">平均一条推文的词向量的维度。</li><li id="2274" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">使用主成分分析将维数减少到 1。</li><li id="da5e" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">根据主成分分析值对推文进行排序。</li><li id="b992" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">通过文字的质量来限制推文。</li></ul><p id="bdfe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我真正喜欢这个模型的地方是，我希望你也会喜欢，我们如何使用这样一个简单的输入，一个值，来生成一条推文。此外，从我们如何创建输入数据，我们将能够在某种程度上控制我们生成的推文的风格。</p><p id="ac65" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了设定你的期望，这里有几个你可以用这个模型创建的推文的例子:</p><ul class=""><li id="3d8f" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">谢谢你亚利桑那！# makamericagreatagain # trump 2016</li><li id="f1b1" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">必须阻止希拉里</li><li id="0e0a" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">记得出来投票！#杂志#特朗普 2016</li></ul><p id="ff05" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="la">注意:我将从我的代码中删除注释，以帮助保持简短。如果你想看评论和我的完整代码，请访问这个项目的</em> <a class="ae kl" href="https://github.com/Currie32/Tweet-Like-Trump" rel="noopener ugc nofollow" target="_blank"> <em class="la"> GitHub 页面</em> </a> <em class="la">。</em></p><p id="834e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们开始吧！</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="443a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个项目的数据来自 Kaggle 上的数据集，它包含了 7375 条推文。我们需要做的第一件事是清理我们的推文。</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="bf61" class="lr ls iq ln b gy lt lu l lv lw">def clean_tweet(tweet):<br/>    tweet = tweet.lower()<br/>    tweet = re.sub(r'https?:\/\/.*[\r\n]*', '', tweet, flags=re.MULTILINE)<br/>    tweet = re.sub(r'[_"\-;%()|.,+&amp;=*%]', '', tweet)<br/>    tweet = re.sub(r'\.', ' . ', tweet)<br/>    tweet = re.sub(r'\!', ' !', tweet)<br/>    tweet = re.sub(r'\?', ' ?', tweet)<br/>    tweet = re.sub(r'\,', ' ,', tweet)<br/>    tweet = re.sub(r':', ' : ', tweet)<br/>    tweet = re.sub(r'#', ' # ', tweet)<br/>    tweet = re.sub(r'@', ' @ ', tweet)<br/>    tweet = re.sub(r'd .c .', 'd.c.', tweet)<br/>    tweet = re.sub(r'u .s .', 'd.c.', tweet)<br/>    tweet = re.sub(r' amp ', ' and ', tweet)<br/>    tweet = re.sub(r'pm', ' pm ', tweet)<br/>    tweet = re.sub(r'news', ' news ', tweet)<br/>    tweet = re.sub(r' . . . ', ' ', tweet)<br/>    tweet = re.sub(r' .  .  . ', ' ', tweet)<br/>    tweet = re.sub(r' ! ! ', ' ! ', tweet)<br/>    tweet = re.sub(r'&amp;amp', 'and', tweet)<br/>    return tweet</span></pre><p id="f68e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这段代码将删除任何链接和无用的字符，并重新格式化文本，以便我们可以最大限度地利用<a class="ae kl" href="https://nlp.stanford.edu/projects/glove/" rel="noopener ugc nofollow" target="_blank"> GloVe 的预训练单词向量</a>。例如，所有的标签都与文本分开。这是因为 GloVe 没有针对 hashtagged 单词的预训练单词向量，所以如果我们想要利用这些预训练向量，我们需要进行这种分离。</p><p id="b631" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="la">注意:我们将使用 GloVe 的 Twitter 矢量。</em></p><p id="fdab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是一些干净的推文示例:</p><ul class=""><li id="e6ef" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">今天，我们向所有曾在我们的军队中服役的人表达最深切的感谢</li><li id="fe6c" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">rt @ ivankatrump:投票给我父亲竞选美国总统真是一个超现实的时刻！发出你的声音并投票！#选择 2</li><li id="6b25" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">晚上 9 : 45 看投票结果#选举之夜#杂志</li></ul><p id="7234" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了生成单词向量，我们首先需要从 GloVe 的单词向量中创建一个嵌入索引。</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="1b67" class="lr ls iq ln b gy lt lu l lv lw">embeddings_index = {}<br/>with open('/Users/Dave/Desktop/Programming/glove.twitter.27B/<br/>           glove.twitter.27B.200d.txt', encoding='utf-8') as f:<br/>    for line in f:<br/>        values = line.split(' ')<br/>        word = values[0]<br/>        embedding = np.asarray(values[1:], dtype='float32')<br/>        embeddings_index[word] = embedding</span></pre><p id="918f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这个文件中有 1，193，514 个单词嵌入，每个嵌入有 200 个维度。</p><p id="f9ed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将使用这个嵌入指数为每条推文创建一个“平均”嵌入。为此，我们将从“空”嵌入开始(所有 200 个值[对于 200 个维度]将为 0)。如果 tweet 中的一个单词在索引中，它的嵌入将被添加到“空”嵌入中。如果 tweet 中的一个单词不在索引中，那么“空”嵌入中将不会添加任何内容。在考虑了推文中的每个单词后，我们将根据推文中的单词数对每个维度进行平均。这些平均维度将为每条推文创建我们的“平均”嵌入。</p><p id="2416" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是相关的代码:</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="928b" class="lr ls iq ln b gy lt lu l lv lw">embedding_dim = 200 </span><span id="15a6" class="lr ls iq ln b gy lx lu l lv lw">embed_tweets = [] # Contains the 'average' embedding for each tweet</span><span id="a3a0" class="lr ls iq ln b gy lx lu l lv lw">for tweet in clean_tweets:<br/>    avg_embed = np.zeros(embedding_dim) <br/>    for word in tweet.split():<br/>        embed = embeddings_index.get(word)<br/>        if embed is not None:<br/>            avg_embed += embed <br/>    embed_tweets.append(avg_embed/len(tweet.split()))</span></pre><p id="7593" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了创建这些<em class="la"> tweet 嵌入，</em>我们可以使用其他方法，比如 Word2Vec。Word2Vec 的好处是不会有任何空嵌入，但考虑到我们正在处理的数据量，只有 7375 条推文，我认为利用 GloVe 更大的数据集会更好。你很快就会看到，使用手套效果很好。</p><p id="5f59" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的下一步是将数据的维度从 200 减少到 1。我们将 reduction 设置为 1，以简化和组织我们的输入数据，并使其易于生成我们想要的 tweet 类型，例如。如果我们想要一条有更多标签或者只有文字的推文。</p><p id="2980" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如你可能已经预料到的，我们将使用 PCA(主成分分析)来降低数据的维度。</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="67c3" class="lr ls iq ln b gy lt lu l lv lw">pca = PCA(n_components=1, random_state = 2)<br/>pca_tweets = pca.fit_transform(embed_tweets)</span></pre><p id="a402" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们的每条推文都有一个 PCA 值，我们将从最小值到最大值对它们进行排序，这样类似的推文将更加接近。</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="2288" class="lr ls iq ln b gy lt lu l lv lw">pca_tweets_list = [] # Contains the pca values<br/>for tweet in pca_tweets:<br/>    pca_tweets_list.append(tweet[0])</span><span id="3292" class="lr ls iq ln b gy lx lu l lv lw">order = np.array(pca_tweets_list).argsort()<br/>pca_labels = order.argsort()<br/>pca_labels *= 2 </span></pre><p id="71ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将我们的<code class="fe ly lz ma ln b">pca_labels</code>乘以 2，以便更简单地生成新的推文。虽然我们不会使用所有的 tweet 来训练我们的模型，但是所有的训练 tweet 都是偶数。为了确保生成新的 tweet，你需要做的就是使用一个奇数作为输入。这个生成的 tweet 应该类似于训练数据中的 tweet，其值接近您的输入值。</p><p id="24af" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了了解 Trump 发布的推文的类型，我们将使用 KMeans 将推文分组。<code class="fe ly lz ma ln b">pca_tweets</code>将是我们对 KMeans 的输入，在使用 3-10 个聚类检查该函数的结果后，我认为 4 个聚类最好地将 Trump 的推文分成不同的组。</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="1fcb" class="lr ls iq ln b gy lt lu l lv lw">kmeans = KMeans(n_clusters=4, max_iter = 1000, n_init = 20, random_state=2).fit(pca_tweets)<br/>labels = kmeans.labels_</span></pre><p id="2633" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">每组包含以下数量的推文:</p><p id="0f05" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1(红色):315，2(橙色):2600，3(黄色):1674，4(蓝色):2782</p><figure class="li lj lk ll gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mb"><img src="../Images/524d96f801b2341c8be08059fd4c274c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pzxyCtS9saQnraf6HnncGA.png"/></div></div></figure><p id="4bbb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">推文由它们的 KMeans 标签着色，但是输入到 TSNE 的数据是<code class="fe ly lz ma ln b">embed_tweets</code>。这张图表明，你可以将推文分成一些合理的不同类别。它并不完美，如果你愿意，你可以为自己创造一些情节，但我认为这是最好的结果。</p><p id="dc67" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们可以看看 PCA 标签与 tweet 组相比有多好。</p><figure class="li lj lk ll gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mj"><img src="../Images/9b3f7dcd9a623eb6e4357a6babdd20b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r-gBK83uswCPCHgbwVSfOA.png"/></div></div><figcaption class="mk ml gj gh gi mm mn bd b be z dk">I’d make this graph bigger, but Medium won’t let me</figcaption></figure><p id="9520" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如所料，鉴于 tweet 组是使用 PCA 数据创建的，我们可以看到四个明显的组。这也提供了一个很好的可视化来比较不同大小的推文组，并可以帮助您在想要生成推文时选择推文类型。</p><p id="bc4c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我的 iPython 笔记本中，我会更详细地介绍每个组中的单词和推文，但为了给你一个示例，这里是每个组的一些推文:</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="7cc3" class="lr ls iq ln b gy lt lu l lv lw">Group # 1 - short tweets with hashtags<br/>#1: # electionday <br/>#2: rt  @ donaldjtrumpjr :  thanks new hampshire ! !<br/>    # nh  # newhampshire  # maga <br/>#3:  # draintheswamp !<br/><br/>Group # 2 - long tweets that are retweeted<br/>#1: rt  @ ivankatrump :  such a surreal moment to vote for my father <br/>    for president of the united states ! make your voice heard and <br/>    vote !  # election2<br/>#2: rt  @ erictrump :  join my family in this incredible movement to  <br/>    # makeamericagreatagain ! now it is up to you ! please  # vote <br/>    for america ! https : <br/>#3: rt  @ donaldjtrumpjr :  final push ! eric and i doing dozens of <br/>    radio interviews we can win this thing ! get out and vote !  # <br/>    maga  # electionday ht<br/><br/>Group # 3 - typically involve a data/time/location<br/>#1: watching the returns at 9 : 45 pm # electionnight  # maga <br/>#2: monday  11/7/2016 <br/>    scranton pennsylvania at 5 : 30 pm <br/>    grand rapids michigan at 11 pm  <br/>#3: rt  @ ivankatrump :  thank you new hampshire !  <br/><br/>Group # 4 - longer tweet, mostly just text<br/>#1: today we express our deepest gratitude to all those who have  <br/>    served in our armed forces  # thankavet <br/>#2: busy day planned in new york will soon be making some very <br/>    important decisions on the people who will be running our <br/>    government !<br/>#3: love the fact that the small groups of protesters last night <br/>    have passion for our great country we will all come together and <br/>    be proud !</span></pre><p id="1a19" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了帮助模型生成最佳推文，我们将通过一些措施来限制我们的训练数据。我们要做的第一件事是建立一个词汇到整数(vocab_to_int)字典和 int_to_vocab 字典，其中只包括在特朗普的推文中出现 10 次或更多次的单词。为什么是 10？我对此没有任何“硬”的理由，但这将有助于我们生成的推文听起来更像特朗普的典型推文，而且这将有助于模型更好地理解每个单词的意思，因为它会看到至少 10 次。如果阈值只是 2 或 3，模型将很难理解和使用很少出现的单词。</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="89cf" class="lr ls iq ln b gy lt lu l lv lw">threshold = 10</span><span id="7bf9" class="lr ls iq ln b gy lx lu l lv lw">vocab_to_int = {}</span><span id="b89d" class="lr ls iq ln b gy lx lu l lv lw">value = 0<br/>for word, count in word_counts.items():<br/>    if count &gt;= threshold:<br/>        vocab_to_int[word] = value<br/>        value += 1</span><span id="d6e6" class="lr ls iq ln b gy lx lu l lv lw">int_to_vocab = {}<br/>for word, value in vocab_to_int.items():<br/>    int_to_vocab[value] = word</span></pre><p id="2f25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们将限制我们将使用的推文的长度。在训练数据中，我选择了 25 作为 tweet 的最大长度。选择该值是因为它是模型仍能很好学习的最大长度。再长一点，模型就很难学习推文，再短一点，我们就会进一步限制我们的训练数据。</p><p id="a10d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还将设置一个<unk>限制。<unk>是一个标记，用于表示不包括在我们的训练词汇中的单词。如果一条推文中出现多个<unk>令牌，则该推文将不会用于训练模型。我尝试将<unk>限制增加到 2，但这导致<unk>在生成的 tweets 中出现太频繁。</unk></unk></unk></unk></unk></p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="364b" class="lr ls iq ln b gy lt lu l lv lw">max_tweet_length = 25<br/>min_tweet_length = 1<br/>unk_limit = 1</span><span id="4e54" class="lr ls iq ln b gy lx lu l lv lw">short_tweets = []<br/>short_labels = []</span><span id="3caf" class="lr ls iq ln b gy lx lu l lv lw">for i in range(len(int_tweets)):<br/>    unk_count = 0<br/>    if len(int_tweets[i]) &lt;= max_tweet_length and \<br/>       len(int_tweets[i]) &gt;= min_tweet_length:<br/>        if len(int_tweets[i]) == 1:<br/>            if int_tweets[i][0] != vocab_to_int['&lt;UNK&gt;']:<br/>                short_tweets.append(int_tweets[i])<br/>                short_labels.append(pca_labels[i])<br/>        else:<br/>            for word in int_tweets[i]:<br/>                if word == vocab_to_int['&lt;UNK&gt;']:<br/>                    unk_count += 1<br/>            if unk_count &lt;= unk_limit:<br/>                short_tweets.append(int_tweets[i])<br/>                short_labels.append(pca_labels[i])</span></pre><p id="1211" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为为模型准备数据的最后一步，我们将按长度对推文进行排序。这样做将有助于我们的模型训练得更快，因为早期的批次将包含更短的推文。每批中的推文需要具有相同的长度，因此通过对推文进行排序，将避免长推文与短推文一起被批量处理。</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="98cf" class="lr ls iq ln b gy lt lu l lv lw">sorted_tweets = []<br/>sorted_labels = []</span><span id="50cf" class="lr ls iq ln b gy lx lu l lv lw">for length in range(1,max_tweet_length+1):<br/>    for i in range(len(short_tweets)):<br/>        if length == len(short_tweets[i]):<br/>            sorted_tweets.append(short_tweets[i])<br/>            sorted_labels.append([short_labels[i]])</span></pre><p id="017f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就是创建我们的训练数据！这需要做一些工作，但是可以说你的输入数据是模型中最重要的部分。没有好的训练数据，模型将无法生成好的输出。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="af61" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本文的最后一部分是如何生成推文。有两种不同的方法可以使用。</p><h2 id="845e" class="lr ls iq bd mo mp mq dn mr ms mt dp mu jy mv mw mx kc my mz na kg nb nc nd ne bi translated">选项 1:找一条类似的推文</h2><p id="2ea9" class="pw-post-body-paragraph jn jo iq jp b jq nf js jt ju ng jw jx jy nh ka kb kc ni ke kf kg nj ki kj kk ij bi translated">通过这种方法，你可以输入与最相似的推文匹配的单词或短语。</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="6693" class="lr ls iq ln b gy lt lu l lv lw">create_tweet = "I need your help to make america great again! #maga"</span><span id="d030" class="lr ls iq ln b gy lx lu l lv lw">create_tweet = clean_tweet(create_tweet)</span><span id="5695" class="lr ls iq ln b gy lx lu l lv lw">create_tweet_vect = vectorize_tweet(create_tweet)</span><span id="d6ad" class="lr ls iq ln b gy lx lu l lv lw">create_tweet_pca = pca.transform(create_tweet_vect)</span><span id="f900" class="lr ls iq ln b gy lx lu l lv lw">similar_tweet = min(pca_tweets_list, <br/>                    key=lambda x:abs(x-create_tweet_pca))</span><span id="cf81" class="lr ls iq ln b gy lx lu l lv lw">for tweet in enumerate(pca_tweets_list):<br/>    if tweet[1] == similar_tweet:<br/>        print("Most similar tweet:", pca_labels[tweet[0]])<br/>        break</span></pre><ul class=""><li id="ab91" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">在<code class="fe ly lz ma ln b">create_tweet</code>中，输入您想要匹配的任何文本。</li><li id="1f65" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">这条推文将被清理，然后使用与我们进行“平均”嵌入时输入数据相同的方法转换为向量。</li><li id="c2a8" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">推文的“平均”嵌入将被用于找到其 PCA 值。这个值将与最接近的 tweet 匹配。</li><li id="4a82" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">匹配的 tweet 的 PCA 值将用于查找其 PCA 标签。这个标签是模型的输入。</li></ul><p id="624d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你对这条最接近的推文的内容感到好奇，那么下面是给你的代码！</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="58ad" class="lr ls iq ln b gy lt lu l lv lw">tweet_type = 3464</span><span id="3be3" class="lr ls iq ln b gy lx lu l lv lw">closest_type = min(short_labels, key=lambda x:abs(x-tweet_type))<br/>words = []<br/>for tweet in enumerate(short_labels):<br/>    if tweet[1] == closest_type:<br/>        for num in short_tweets[tweet[0]]:<br/>            words.append(int_to_vocab[num])<br/>print(" ".join(words))</span></pre><p id="3859" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe ly lz ma ln b">tweet_type</code>可以认为是 PCA 标签。该值将与用于训练模型的最接近的标签相匹配。将打印出与最近标签相关的文本。</p><p id="e0fc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为这种方法局限性的一个例子，我用了这样一句话“我需要你们的帮助，让美国再次伟大！#maga "作为我的<code class="fe ly lz ma ln b">create_tweet</code>，返回的<code class="fe ly lz ma ln b">tweet_type</code>和文字是:3464，“希拉里是有史以来竞选美国总统最腐败的人# draintheswamp”。</p><p id="fea9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些文本差别很大，但是它们的结构是相似的，多个普通的单词和一个标签。我同意这是第四组风格的推文的模式。</p><h2 id="263a" class="lr ls iq bd mo mp mq dn mr ms mt dp mu jy mv mw mx kc my mz na kg nb nc nd ne bi translated">选项 2:输入一个值</h2><p id="582c" class="pw-post-body-paragraph jn jo iq jp b jq nf js jt ju ng jw jx jy nh ka kb kc ni ke kf kg nj ki kj kk ij bi translated">这是更简单的选择，包含了更多的随机性。你需要做的就是选择一个<code class="fe ly lz ma ln b">tweet_type</code>，我建议你参考推文组的范围来控制推文的风格。您还可以通过设置 sequence_length 的值来控制您想要生成的 tweet 的长度，但我将其设置为随机整数，因为我喜欢危险地生活。</p><pre class="li lj lk ll gt lm ln lo lp aw lq bi"><span id="381e" class="lr ls iq ln b gy lt lu l lv lw">tweet_type = 3464</span><span id="3ba7" class="lr ls iq ln b gy lx lu l lv lw">checkpoint = "./best_model.ckpt"</span><span id="8370" class="lr ls iq ln b gy lx lu l lv lw">loaded_graph = tf.Graph()<br/>with tf.Session(graph=loaded_graph) as sess:<br/>    loader = tf.train.import_meta_graph(checkpoint + '.meta')<br/>    loader.restore(sess, checkpoint)</span><span id="7fd5" class="lr ls iq ln b gy lx lu l lv lw">    input_data = loaded_graph.get_tensor_by_name('input:0')<br/>    logits = loaded_graph.get_tensor_by_name('logits:0')<br/>    sequence_length = <br/>        loaded_graph.get_tensor_by_name('sequence_length:0')<br/>    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')</span><span id="0646" class="lr ls iq ln b gy lx lu l lv lw">tweet_logits = sess.run(logits, <br/>                        {input_data: [[tweet_type]], <br/>                         sequence_length: np.random.randint(3,15),<br/>                         keep_prob: 1.0})[0]</span><span id="69f3" class="lr ls iq ln b gy lx lu l lv lw"># Remove the padding from the tweet<br/>pad = vocab_to_int["&lt;PAD&gt;"]</span><span id="22ba" class="lr ls iq ln b gy lx lu l lv lw">print('Tweet')<br/>print('  Word Ids: {}'.format(<br/>         [i for i in np.argmax(tweet_logits, 1) if i != pad]))<br/>print('  Tweet: {}'.format(" ".join([int_to_vocab[i] for i in <br/>                          np.argmax(tweet_logits, 1) if i != pad])))</span></pre></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="3c3b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个项目到此为止！我希望你喜欢了解它，如果你想看到整个过程，那么就去我的<a class="ae kl" href="https://github.com/Currie32/Tweet-Like-Trump" rel="noopener ugc nofollow" target="_blank"> GitHub </a>吧。如果您有任何问题、意见或建议，请在下面发表。</p><p id="77ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你对扩展这项工作感兴趣，我的一个想法是对生成的推文提供更大的控制。我认为如果我们可以在输入数据中包含一个关键字(或多个单词)会很好。这应该有助于我们控制我们想要生成的推文的风格和上下文。</p><p id="1f82" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">感谢阅读！</p></div></div>    
</body>
</html>