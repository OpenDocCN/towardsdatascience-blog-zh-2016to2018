<html>
<head>
<title>Neural network for satellite image segmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于卫星图像分割的神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/dstl-satellite-imagery-contest-on-kaggle-2f3ef7b8ac40?source=collection_archive---------4-----------------------#2017-08-27">https://towardsdatascience.com/dstl-satellite-imagery-contest-on-kaggle-2f3ef7b8ac40?source=collection_archive---------4-----------------------#2017-08-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="8736" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的卡格尔DSTL卫星图像竞赛项目概述。该项目在公共测试数据集上获得了0.46的分数，在私有测试数据集上获得了0.44的分数，这将在私有领导板上的419个团队中排名第7。代码在我的<a class="ae kl" href="https://github.com/jiangxu87/dstl_unet" rel="noopener ugc nofollow" target="_blank"> github </a>上。</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h2 id="b406" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated"><strong class="ak">数据可视化和特征合成</strong></h2><p id="1f0a" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk ij bi translated">训练数据集包括25个图像，每个图像具有20个通道(3个波段(3个通道，RGB) + A波段(8个通道)+ M波段(8个通道)+ P波段(1个通道))，以及对象的相应标签。用等高线标注的重叠对象有10种(<a class="ae kl" href="https://en.wikipedia.org/wiki/Well-known_text" rel="noopener ugc nofollow" target="_blank"> wkt </a>类数据)，其中0。建筑物，1。杂项，2。路，3。音轨，4。树木，5。农作物，6。水路，7。死水，8。大型车辆，9。小型车辆。</p><p id="880c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的策略是首先将轮廓转换成掩模，然后为每一类对象训练一个逐像素的二元分类器。下图显示了20个通道和标签的示例。值得注意的是，A波段(下面中间一行)的分辨率比其他波段低得多，因此在我们的模型中没有直接使用。M波段相对于3波段显示出轻微的空间偏移，并且被插值到与3波段相同的分辨率，并且进一步配准到3波段。我们还根据给定的3、A、M波段创建了另外4个指数，<a class="ae kl" href="https://www.researchgate.net/publication/259360047_Use_of_the_Canopy_Chlorophyl_Content_Index_CCCI_for_Remote_Estimation_of_Wheat_Nitrogen_Content_in_Rainfed_Environments" rel="noopener ugc nofollow" target="_blank"> CCCI </a>、<a class="ae kl" href="https://en.wikipedia.org/wiki/Normalized_difference_water_index" rel="noopener ugc nofollow" target="_blank"> NDWI </a>、<a class="ae kl" href="https://en.wikipedia.org/wiki/Enhanced_vegetation_index" rel="noopener ugc nofollow" target="_blank"> EVI </a>、<a class="ae kl" href="https://en.wikipedia.org/wiki/Soil-Adjusted_Vegetation_Index" rel="noopener ugc nofollow" target="_blank"> SAVI </a>。这些指数已被证明与传统GIS中的某些类别的对象有很好的相关性，并且可能使特征学习更容易。因此，我们总共有16个通道(3个波段(3个通道)+ M波段(8个通道)+ P波段(1个通道)+ 4个合成通道)输入。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi lr"><img src="../Images/ff4ae07f50bb14b80e93204d23afac92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*suV3S6LeBtzaCIHFGkRIMA.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Examples of all channels of training data and class labels</figcaption></figure><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mh"><img src="../Images/248ad52251d729bc2798843c6653a99b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*3QDCxLym4rDIMtqIpo8Irw.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">An example of the 3-band image with class labels overlay</figcaption></figure></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h2 id="bdde" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">班级统计</h2><p id="f55f" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk ij bi translated">与包含大约100万张训练图像的ImageNet分类挑战相比，这个训练数据集相当小，只有25张图像。然而，本次竞赛中的标签是在像素级别上，因此每个像素都是一个训练示例，该数据集的有效大小为3300 * 3300 * 25 = 2.7亿。</p><p id="5c79" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对所有训练图像的所有类别的百分比面积的统计显示了大多数类别的真标签和假标签之间的高度不平衡，以及真标签在类别之间的严重不平衡分布。因此，我们决定为每个类别训练一个二元分类器，而不是用单一模型来预测所有类别。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mi"><img src="../Images/df1de67e8d27b97eee4e5d6b942c02f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1UcdmU1AGdj-tKYXmH8Yrg.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Statistics of percentage area for all classes of all the training data. (Note: on some images, the sum is over 100% because of overlap between classes.)</figcaption></figure></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h2 id="2eb2" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">U网模型</h2><p id="b5dc" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk ij bi translated">在tensorflow中开发了具有批量归一化的U-net，并用作分类模型。该模型被训练9000批，每批包含60个图像补片。每个图像块都是原始图像的144*144裁剪。类似于最初的<a class="ae kl" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> U-net </a>论文，由于边缘像素仅接收部分信息，因此仅在中心80*80区域上计算损失。</p><p id="9c30" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">损失函数:比较了两种损失函数，包括加权交叉熵和软<a class="ae kl" href="https://en.wikipedia.org/wiki/Jaccard_index" rel="noopener ugc nofollow" target="_blank"> Jaccard指数</a>，这两种损失函数都可以解释真假标签的不平衡。发现加权交叉熵在训练期间对交叉验证数据产生振荡性能。给定评估度量是类的平均Jaccard指数，使用Jaccard指数作为损失函数是理想的。不幸的是，Jaccard指数是不可微的。相反，软Jaccard指数是可微分的，并且在非常有把握的预测中接近Jaccard指数。交叉熵(H)和软<a class="ae kl" href="https://en.wikipedia.org/wiki/Jaccard_index" rel="noopener ugc nofollow" target="_blank"> Jaccard指数</a> (J)的组合，L = H -log(J)，被用作损失函数。</p><p id="095b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">优化器:使用初始学习率为0.0001的Adam优化器。虽然Adam optimizer应该自然地执行步长退火，但我们发现每4000批学习率衰减到0.1确实改善了训练。</p><p id="143e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">批量大小:原来的U-net模型使用每批中的单个图像进行训练，显然不适合这个问题。从职业统计可以看出，职业分布在不同的图像中变化很大。大批量(此处为60)是可取的，以确保每个有效批量的统计数据(考虑动量)与整个训练数据集的统计数据一致。批量大小也必须与有效训练区域妥协，因为边缘像素必须被丢弃。太大的批量将导致用于训练的中心区域非常小。</p><p id="eb59" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在CPU上创建两个独立的线程进行数据预处理，预处理后的数据被推入两个队列，并分别在GPU上进行训练和交叉验证。这减轻了GPU的负担，加快了训练的速度。所有训练数据都被预加载到RAM中，以避免训练期间缓慢的文件I/O。</p><p id="89c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该项目是通过对21幅图像进行训练，使用另外4幅图像进行交叉验证而开发的。最终的模型是用所有25幅图像训练出来的。</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h2 id="902f" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">训练数据扩充</h2><p id="f411" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk ij bi translated">训练数据扩充包括随机水平和垂直反射和平移，以及360度旋转(1度步长)。旋转破坏了CNN的平移对称性。选择1度的步长，因为对于144的裁剪大小，围绕其中心旋转1度会在边缘产生约1.3个像素的偏移，从而为CNN产生不同的输入图像。有趣的是，通过实验确定旋转在多大的步长下停止改善性能。</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h2 id="04a6" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">测试时间增加</h2><p id="59f7" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk ij bi translated">U-net模型的一个优点是它是完全卷积的，因此用于训练和推断的输入数据的空间维度不必相同。如上所述，在训练中，相对较小的图像补片和较大的批量是可取的。然而，对于推断来说，使图像块尽可能大以减少由丢弃边缘上的预测而产生的开销是有益的。受GPU内存的限制，我们每次只能将大约四分之一的图像(~1900*1900)送入U-net进行推理。图像的每四分之一旋转0、90、180和360度，并且水平和垂直翻转，用于放大。并且最终预测掩码是8个掩码的算术平均值，以减少预测中的方差。与最初的U-net论文类似，我们在边界上应用了反射，以改进边缘像素上的预测。</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h2 id="5b49" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">预测和结果</h2><p id="b594" class="pw-post-body-paragraph jn jo iq jp b jq lm js jt ju ln jw jx jy lo ka kb kc lp ke kf kg lq ki kj kk ij bi translated">在线评估在私人排行榜上的得分为0.44113，在419分中排名第七。下图显示了0级建筑物的真实标签和预测标签之间的比较。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mj"><img src="../Images/fd21220afd905103a3ba67d10bb2efcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W_J9lC4lqs8nUJfiTTWwgQ.png"/></div></div></figure><p id="160d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一些有趣的观察:该模型能够从训练数据中纠正一些不精确的标签。如下图所示，3波段图像似乎有一个小的“空”区域，充满了自然光产生的阴影，位于建筑物的中间。虽然“真实”标签将整个区域作为建筑物类包括在内，但预测掩膜能够正确排除阴影区域。我们在预测中发现了几个这样的例子。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mk"><img src="../Images/6594bfb683eee5598c803dbde6115db9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hvaq6kLDe9LmCLOsrZc4WA.png"/></div></div></figure><p id="d6d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">水类:我们已经注意到，对于建筑物类，如果只使用2个图像进行训练，U-net会完全过拟合，但是对于≥21个训练图像，U-net可以很好地推广。了解确切的界限在哪里以及为什么会有意思。这也意味着深度学习在这场比赛中对水类不起作用，因为水类只在很少的图像上有实例。我们已经发现，对于水类，阈值CCCI优于深度学习模型。</p></div><div class="ab cl km kn hu ko" role="separator"><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr ks"/><span class="kp bw bk kq kr"/></div><div class="ij ik il im in"><h2 id="778b" class="kt ku iq bd kv kw kx dn ky kz la dp lb jy lc ld le kc lf lg lh kg li lj lk ll bi translated">一些评论</h2><ol class=""><li id="e046" class="ml mm iq jp b jq lm ju ln jy mn kc mo kg mp kk mq mr ms mt bi translated">该模型主要基于其在0级(即建筑物)上的性能而开发。通过为每个类定制模型参数，结果肯定可以进一步改善。</li><li id="03c3" class="ml mm iq jp b jq mu ju mv jy mw kc mx kg my kk mq mr ms mt bi translated">我们的模型完全无法预测大型和小型车辆类别，可能是由于严重的真假标签不平衡和车辆的空间尺寸太小。诸如对真实标签的过采样和大批量训练等技术可能有助于前者。</li></ol></div></div>    
</body>
</html>