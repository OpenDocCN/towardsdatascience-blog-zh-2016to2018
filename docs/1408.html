<html>
<head>
<title>Applied Text-Classification on Email Spam Filtering [Part 1]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">垃圾邮件过滤中的文本分类应用(上)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/applied-text-classification-on-email-spam-filtering-part-1-1861e1a83246?source=collection_archive---------1-----------------------#2017-09-01">https://towardsdatascience.com/applied-text-classification-on-email-spam-filtering-part-1-1861e1a83246?source=collection_archive---------1-----------------------#2017-09-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/8491e71e30c17547c50df65f54169ab6.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*9vX9GriIxB3yRXYtoEiy8w.jpeg"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Email-Spam Filtering</figcaption></figure><p id="31a4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">原创文章发表在<a class="ae kw" href="http://www.sarahmestiri.com/index.php/2017/09/01/applied-text-classification-on-email-spam-filtering-part-1/" rel="noopener ugc nofollow" target="_blank">我的网站</a>。</p><p id="4b69" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从上个月开始，我开始在华盛顿大学提供的在线<a class="ae kw" href="https://www.coursera.org/specializations/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习专业</a>上工作。第一个课程是关于<em class="kx"> ML 基础</em>，第二个是关于<em class="kx">线性回归</em>，第三个课程是关于<em class="kx">分类</em>。我喜欢这些课程的各个方面，因为它们从头开始教授 ML 算法的实现。当我决定更深入地探索这个领域时，这就是我的目标。但是，老实说，我觉得有一个差距，因为许多问题都没有答案。然后，在阅读了关于如何开始机器学习的内容后，我发现大多数文章都强调了将课程与实践项目相结合的重要性，以便学以致用..而且是那么真实！你只要试着把两者结合起来，你很快就会注意到不同之处！</p><p id="8202" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是我的第一次实习申请！:D 我选择尝试<strong class="ka ir"> <em class="kx">垃圾邮件过滤</em> </strong>，因为这是应用分类中一个非常常见的话题。这很容易理解，因为我们每天都在经历电子邮件中的垃圾邮件过滤。</p><p id="4e11" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我遵循了一个简单的入门教程:<a class="ae kw" href="https://appliedmachinelearning.wordpress.com/2017/01/23/email-spam-filter-python-scikit-learn/" rel="noopener ugc nofollow" target="_blank">电子邮件垃圾邮件过滤:使用 Scikit-learn 的 Python 实现</a>。做完不久，我的大脑开始分析步骤，一堆问题轰炸我的脑袋！</p><p id="1725" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为什么“垃圾邮件和非垃圾邮件数量相等”？什么是词干？除了删除停用词和词条化之外，还有其他清理数据的方法吗？训练集和测试集之间的划分是如何完成的？为什么没有验证集？为什么特别使用朴素贝叶斯分类器和 SVM(支持向量机)？是什么让朴素贝叶斯在文档分类问题上如此受欢迎？等等..</p><blockquote class="ky kz la"><p id="4755" class="jy jz kx ka b kb kc kd ke kf kg kh ki lb kk kl km lc ko kp kq ld ks kt ku kv ij bi translated">扮成威廉。巴勒斯说:“如果你学会放松并等待答案，你的大脑会回答大多数问题。”</p></blockquote><p id="40f2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我吸了口气，开始一个问题一个问题地回答，有时在网上搜索，试验一些代码的变化，并分析输出。我很高兴地分享结果:</p><h1 id="fc85" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">1)我们需要的数据</h1><p id="60b5" class="pw-post-body-paragraph jy jz iq ka b kb mc kd ke kf md kh ki kj me kl km kn mf kp kq kr mg kt ku kv ij bi translated">-我们已经看到了多少封电子邮件(将在训练测试集中使用)<br/> -每个标签中有多少封电子邮件(用于检测是否存在不平衡数据)<br/> -一个单词与每个标签关联的频率(用于计算电子邮件是垃圾邮件或垃圾邮件(0 类或 1 类)的概率)</p><h1 id="bbfe" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">2)清理数据</h1><p id="3a0f" class="pw-post-body-paragraph jy jz iq ka b kb mc kd ke kf md kh ki kj me kl km kn mf kp kq kr mg kt ku kv ij bi translated"><strong class="ka ir">为什么要清洗单词表？</strong>为了减少得到错误结果的可能性，清理数据是必不可少的，因为一些单词对分类没有影响(它们既不能与垃圾邮件类相关联，也不能与垃圾邮件类相关联),并且有一些单词可以被标准化，以便将意思相同的单词分组并减少冗余。通过对训练数据的质量采取行动，我们可以改变分类器的所谓的<a class="ae kw" href="https://en.wikipedia.org/wiki/Accuracy_and_precision" rel="noopener ugc nofollow" target="_blank">准确度</a>。因此，移除<em class="kx">停用词、词干</em>和<em class="kx">词条化</em>有助于改善机器学习算法的结果。</p><h1 id="513d" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">3)朴素贝叶斯</h1><p id="6109" class="pw-post-body-paragraph jy jz iq ka b kb mc kd ke kf md kh ki kj me kl km kn mf kp kq kr mg kt ku kv ij bi translated"><strong class="ka ir">为什么使用朴素贝叶斯？</strong>朴素贝叶斯具有高效的学习和预测能力，它经常被用来与更复杂的方法进行比较，因为它快速且高度可伸缩(适用于高维数据),正如吴恩达建议的那样，在处理 ML 问题时，从尝试简单快速的算法开始，然后从该点扩展。</p><p id="c14e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">朴素贝叶斯如何简单易行？</strong>朴素贝叶斯基于“贝叶斯”定理，之所以称之为“朴素”，是因为它假设在给定类的情况下<em class="kx">要素是相互独立的</em>(要素之间没有/几乎没有相关性)，这是不现实的。因此，朴素贝叶斯可以学习单个特征的重要性，但不能确定特征之间的关系。此外，与其他方法相比，朴素贝叶斯的训练时间要短得多，并且不需要太多的训练数据。</p><p id="806b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">为什么是多项朴素贝叶斯？其他模型比如高斯朴素贝叶斯或者伯努利朴素贝叶斯呢？</strong></p><p id="30dd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">嗯，<strong class="ka ir"> <em class="kx">多项式 NB </em> </strong>考虑的是特征(在我们的例子中是单词)的<strong class="ka ir"> <em class="kx">频率</em> <em class="kx">计数</em> </strong>(出现次数)<em class="kx">而<strong class="ka ir">伯努利 NB </strong>只关心文档中某个特定特征(单词)的<strong class="ka ir">存在与否</strong>。后者适用于<em class="kx">二进制值</em>(伯努利，布尔)的特性。鉴于使用<strong class="ka ir">高斯 NB </strong>，特征是<em class="kx">实值</em>或<em class="kx">连续</em>并且它们的分布是高斯的，Iris Flower 数据集是具有连续特征的例子。</em></p><h1 id="2f5e" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">4)支持向量机(SVM)</h1><p id="9a2b" class="pw-post-body-paragraph jy jz iq ka b kb mc kd ke kf md kh ki kj me kl km kn mf kp kq kr mg kt ku kv ij bi translated">为什么使用 SVM？我没有找到具体的原因，但据我所知，SVM 可以提供高精度的结果，因为它使用了优化程序。SVM 通过搜索最优的分离超平面(<strong class="ka ir">最优超平面</strong>)和<strong class="ka ir">最大化分离类别(在我们的例子中是垃圾邮件和火腿)的间隔</strong>来构建分类器。因此，当维数大于样本数时，SVM 具有一般稳健性和有效性的优点。</p><p id="9938" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">与朴素贝叶斯不同，SVM 是一种非概率算法。</p><p id="5c4a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">【LinearSVC 和 SVC (Scikit-learn)有什么区别？区别在于它们不接受相同的参数。例如，LinearSVC 不接受内核参数，因为它被认为是线性的。SVC 支持更多的参数(C，γ，..)因为它保存了所有可能的<a class="ae kw" href="http://scikit-learn.org/stable/modules/svm.html#svm-kernels" rel="noopener ugc nofollow" target="_blank">核函数</a>(线性、多项式、rbf 或径向基函数、sigmoid)。</p><p id="dd89" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">如何调整 SVM 参数？</strong>调整 SVM 参数提高了算法的性能。其中一些影响更大:</p><p id="22e3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">-内核</strong>:内核就像一个相似度函数。这是一种在可能的高维特征空间中计算两个向量的点积的方法，使用基于一些提供的约束的数据转换到更复杂的空间。核函数有时被称为“广义点积”。</p><p id="36e3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">-Gamma:</strong>“RBF”、“poly”和“sigmoid”的核系数。更高的伽马值将试图按照训练数据集精确拟合，即泛化误差，并导致过拟合问题。</p><p id="a8dc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">-C</strong>:(3.15)中的系数<em class="kx"> C </em>是一个允许在训练误差和模型复杂度之间进行权衡的参数。小的值<em class="kx"> C </em>将增加训练错误的数量，而大的值<em class="kx"> C </em>将导致类似于硬边际 SVM 的行为。”约阿希姆(2002)，第 40 页</p><h1 id="c8d7" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">5)分析不同情况下的输出</h1><p id="381c" class="pw-post-body-paragraph jy jz iq ka b kb mc kd ke kf md kh ki kj me kl km kn mf kp kq kr mg kt ku kv ij bi translated">如果我改变字典的大小会怎样？</p><p id="78e5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">改变字典大小意味着改变特征(单词)的数量。因此，我想探索拥有更多功能的影响，以及基于<a class="ae kw" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html" rel="noopener ugc nofollow" target="_blank">混淆矩阵</a>结果的好结果的限制。</p><p id="31b7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我在 size= {3000，5000，6000，7000}上进行测试，发现在 size = 7000 时，SVM 分类开始略有下降(错误识别),而朴素贝叶斯尽管在大小上有所变化，但仍提供了相同的结果。</p><p id="9e8c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我认为，在这一点上，可能目标类开始重叠或训练数据过度拟合。我还不确定对这个结果的解释。</p><p id="7f84" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果我尝试高斯和伯努利呢？</p><p id="eb1a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">显然，引入伯努利不会有所帮助，因为正如我上面解释的，它在我们的情况下没有提供足够的信息，我们需要的是字数，而不是它的存在/不存在。</p><p id="3abf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">多项式 NB:<br/>[[129 1]<br/>【9 121]]<br/>高斯 NB:<br/>[[129 1]<br/>【11 119]]<br/>伯努利 NB:<br/>[[130 0 0]<br/>【53 77】]</p><p id="fd1f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如我们所见，多项式 NB 优于高斯 NB 和伯努利 NB。</p><p id="57dc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">如果我在 SVM 上尝试</strong><a class="ae kw" href="http://scikit-learn.org/stable/modules/grid_search.html" rel="noopener ugc nofollow" target="_blank"><strong class="ka ir">grid search</strong></a><strong class="ka ir">来调整 SVM 参数会怎么样？</strong><br/>Params grid search:param _ grid = { ' C ':[0.1，1，10，100，1000]，' gamma':[1，0.1，0.01，0.001，0.0001]} <br/>找到最佳参数:Gamma:0.0001；列车员:100 元</p><p id="7b10" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">线性 SVM:<br/>[[126 4]<br/>【5 125】]<br/>多项式 NB:<br/>[[129 1]<br/>【9 121】]<br/>SVM:<br/>[[129 1]<br/>【62 68]]<br/>grid search on SVM:<br/>[[126 4]<br/>【2 128】]</p><p id="8061" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">SVM 使用 GridSearch 调整参数，可以获得更好的结果。</p><h2 id="c58f" class="mh lf iq bd lg mi mj dn lk mk ml dp lo kj mm mn ls kn mo mp lw kr mq mr ma ms bi translated">结论</h2><p id="690b" class="pw-post-body-paragraph jy jz iq ka b kb mc kd ke kf md kh ki kj me kl km kn mf kp kq kr mg kt ku kv ij bi translated">这就是我使用垃圾邮件过滤软件的第一步！如果你正在考虑开始一个文本分类项目，我希望它对你有所帮助！我会继续分享各种思考和实验。下一次，我将探索更多的训练数据和特征的改进/改变。</p><p id="cc81" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这个项目也在 Github 上。</p><p id="02d5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">有用的资源:</strong></p><p id="003d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">[1] <a class="ae kw" href="http://sebastianraschka.com/Articles/2014_naive_bayes_1.html" rel="noopener ugc nofollow" target="_blank">朴素贝叶斯和文本分类</a>。<br/>【2】<a class="ae kw" href="http://dataaspirant.com/2017/02/06/naive-bayes-classifier-machine-learning/" rel="noopener ugc nofollow" target="_blank">朴素贝叶斯举例</a>。<br/>【3】吴恩达解释朴素贝叶斯<a class="ae kw" href="https://www.youtube.com/watch?v=z5UQyCESW64" rel="noopener ugc nofollow" target="_blank">视频 1 </a>和<a class="ae kw" href="https://www.youtube.com/watch?v=NFd0ZQk5bR4" rel="noopener ugc nofollow" target="_blank">视频 2</a><br/>【4】<a class="ae kw" href="https://www.reddit.com/r/MachineLearning/comments/15zrpp/please_explain_support_vector_machines_svm_like_i/" rel="noopener ugc nofollow" target="_blank">请像我 5 岁一样解释 SVM</a>。<br/>【5】<a class="ae kw" href="https://www.analyticsvidhya.com/blog/2015/10/understaing-support-vector-machine-example-code/" rel="noopener ugc nofollow" target="_blank">从实例理解支持向量机</a>。</p><p id="6d74" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">告诉我你在文本分类方面的经验？你用它做什么？你建议用什么方法？有哪些挑战？T3】</p></div></div>    
</body>
</html>