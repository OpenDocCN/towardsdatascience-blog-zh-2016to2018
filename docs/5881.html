<html>
<head>
<title>Getting Your Text Data Ready for Your Natural Language Processing Journey</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为您的自然语言处理之旅准备好文本数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-your-text-data-ready-for-your-natural-language-processing-journey-744d52912867?source=collection_archive---------17-----------------------#2018-11-13">https://towardsdatascience.com/getting-your-text-data-ready-for-your-natural-language-processing-journey-744d52912867?source=collection_archive---------17-----------------------#2018-11-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/a553ffb6bb8068b2de1a8e9027151c4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Z9VgMkehuH_bOZthwjH5g.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo by <a class="ae kc" href="https://unsplash.com/photos/Oaqk7qqNh_c?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Patrick Tomasso</a> on <a class="ae kc" href="https://unsplash.com/search/photos/books?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="29eb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们生活的各个方面，我们都被语言所包围。语言是我们存在的基础，是让我们成为我们自己的东西。语言使我们能够以如此简单的方式做事情，否则这是不可能的，比如交流思想，像指环王一样讲述巨大的故事，甚至深入了解我们的内心。</p><p id="0359" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于语言是我们生活和社会不可或缺的一部分，我们自然会被大量的文本所包围。我们可以从书籍、新闻文章、维基百科文章、推文以及许多其他形式的资源中获取文本。</p><p id="f5da" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些大量的文本可能是我们所能处理的最大数量的数据。从书面文字中可以获得许多真知灼见，由此提取的信息可以产生非常有用的结果，可用于各种应用。但是，所有这些数据都有一个小缺陷，即文本是我们可用的最无结构的数据形式。这是纯粹的语言，没有任何数学含义。可悲的是，我们所有的机器学习和深度学习算法都是针对数字而不是文本的。</p><p id="4ed8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那么，我们该怎么办？</p><p id="0f3d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">简单！我们需要清理这些文本，并将其转换为数学数据(向量)，我们可以将这些数据提供给我们饥饿的算法，这样它们就可以为我们提供一些很好的见解。这被称为<em class="lb">文本预处理。</em></p><p id="f538" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">文本预处理可以大致分为两个主要步骤:</p><ol class=""><li id="3c4f" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la lh li lj lk bi translated"><strong class="kf ir">文字清理</strong></li><li id="6702" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated"><strong class="kf ir">文本到矢量的转换</strong></li></ol><p id="d41a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们深入了解他们的细节…</p><h1 id="73cc" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated"><strong class="ak">文字清理</strong></h1><p id="55bd" class="pw-post-body-paragraph kd ke iq kf b kg mo ki kj kk mp km kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">为了避免占用我们的内存(自然语言处理是一个耗时耗内存的过程)，在我们将文本转换成向量之前，文本必须尽可能的干净。以下是清理数据时可以遵循的几个步骤:</p><p id="5ec6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">移除 HTML 标签:</strong>大多数可用的文本数据都是 web 废弃的，因此几乎总是包含 HTML 标签(例如:&lt; br/ &gt;、&lt; p &gt;、&lt; h1 &gt;等)。如果我们把它们转换成向量，它们只会占用内存空间，增加处理时间，而不会提供任何关于文本的有价值的信息。</p><p id="0504" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">去掉标点:</strong>标点没有用。与 HTML 标签相同。这些也需要清洗，原因和上面提到的一样。</p><figure class="mt mu mv mw gt jr"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="5d2f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">去除停用词:</strong>像‘this’，‘there’，‘that’，‘is’等词。不能提供非常有用的信息，而且会在我们的记忆中制造一些无用的混乱。这种词被称为停用词。可以使用删除此类单词，但建议在这样做时要小心，因为像“not”这样的单词也被视为停用词(这对于情感分析等任务可能是危险的)。</p><p id="bccd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">词干:</strong>像‘有味道的’、‘有品味地’等词都是‘有味道的’这个词的变体。因此，如果我们的文本数据中有所有这些单词，当所有这些暗示(或多或少)相同的事情时，我们将最终为每个单词创建向量。为了避免这种情况，我们可以提取所有这些单词的<em class="lb">词根</em>，并为<em class="lb">词根</em>创建一个向量。提取出<em class="lb">词根</em>词的过程称为<em class="lb">词干化。“雪球斯特梅尔”是最先进的词干分析器之一。</em></p><figure class="mt mu mv mw gt jr"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="272e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该代码片段给出了以下输出:</p><figure class="mt mu mv mw gt jr"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="dd03" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">令人惊讶的是，tasty 的词根竟然是 tasti。</p><p id="39fd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">将所有内容转换为小写:</strong>在我们的数据中同时包含“饼干”和“饼干”是没有意义的，最好将所有内容转换为小写。此外，我们需要确保没有文字是字母数字。</p><p id="f249" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">实现上述所有过程的最终代码如下所示:</p><figure class="mt mu mv mw gt jr"><div class="bz fp l di"><div class="mx my l"/></div></figure><h1 id="295f" class="lq lr iq bd ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn bi translated"><strong class="ak">文本到矢量的转换</strong></h1><p id="94d9" class="pw-post-body-paragraph kd ke iq kf b kg mo ki kj kk mp km kn ko mq kq kr ks mr ku kv kw ms ky kz la ij bi translated">一旦我们完成了对数据的清理，就应该将清理后的文本转换为我们的机器学习/深度学习算法可以理解的向量。</p><p id="fef5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有相当多的技术可供我们使用来实现这种转换。其中最简单的就是<em class="lb">袋字。</em></p><p id="9593" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">文字袋—简短介绍</strong></p><p id="9263" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">单词包基本上创建了一个<em class="lb">‘d’</em>单词的字典(这不是 python 字典)，其中<em class="lb">‘d’</em>是我们的文本语料库中<em class="lb">唯一</em>单词的数量。然后，它为每个文档创建<em class="lb">‘d’</em>维向量(将其视为长度为‘d’的数组)，每个维(单元格)的值等于相应单词在文档中出现的次数。</p><p id="1340" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">类似这样的-</p><figure class="mt mu mv mw gt jr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/bac686d6643e5ec5365c68b30b27f2d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*0OJcy1Z4ndIEiIBPUZXL1w.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><a class="ae kc" href="https://cdn-images-1.medium.com/max/1600/1*j3HUg18QwjDJTJwW9ja5-Q.png" rel="noopener">credits</a></figcaption></figure><p id="9349" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在上面的例子中，字典有八个单词(are，cat，dog，is，on，table，the)。问题中的句子(查询)有六个单词(The，dog，is，on，the，table)。显然，每个单元格都具有相应单词在查询中出现的次数的计数值。</p><p id="875f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在非常高维的向量中，零的数量将大大超过非零值的数量，因为每个向量将具有针对数据语料库中所有唯一单词的维度。这样的向量维数可以是几千、几万甚至更多，但是单个文档不会有这么多独特的单词。这种类型的向量(其中大多数元素为零)被称为稀疏向量。</p><p id="4582" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">它们看起来像这样-</p><figure class="mt mu mv mw gt jr gh gi paragraph-image"><div class="gh gi na"><img src="../Images/e6a7c470a661af862b35101d1bafc954.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*RcvJB5ja-KmOYHkagRxHFw.jpeg"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><a class="ae kc" href="https://image.slidesharecdn.com/vectorland-151126121952-lva1-app6892/95/vectorland-brief-notes-from-using-text-embeddings-for-search-11-638.jpg?cb=1448540745" rel="noopener ugc nofollow" target="_blank">visiting link</a></figcaption></figure><p id="a7e7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当这些稀疏向量相互叠加时，我们得到一个稀疏矩阵。</p><p id="81f2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">类似这样的-</p><figure class="mt mu mv mw gt jr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/c6dcfd8ed10862d5bfd1d41cc82b77b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*96aVT0Zq1d5f79erLNOmxA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><a class="ae kc" href="https://www.researchgate.net/profile/Nidhal_El_abbadi/publication/269410885/figure/fig2/AS:392105793998849@1470496714111/suggested-sparse-matrix.png" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="ff3f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个图中，可以清楚地看到大多数值是零。该稀疏矩阵将我们的整个文本语料库表示为 n*d 矩阵，其中‘n’表示文本语料库中的文档数量，而‘d’表示其中唯一单词的数量(各个向量的维数)。</p><p id="ef2e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是获取单词包的代码片段:</p><figure class="mt mu mv mw gt jr"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="1a8b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">获得的输出是:</p><figure class="mt mu mv mw gt jr"><div class="bz fp l di"><div class="mx my l"/></div></figure><p id="e073" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，对于我们的每个文档(总共 525814 个—‘n’)，我们得到一个 70780(‘d’)维向量！这是巨大的！</p><p id="e9b2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我希望这个数字能说明为什么我们需要在将数据转换成向量之前清理数据，因为如果我们不清理数据，数据的维数会比我们现有的维数大得多。</p><p id="68b9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">文本已经被转换成向量，我们现在已经准备好建立我们的 ML/DL 模型了！</p><p id="aeb3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">更多关于单词袋方法的信息可以在<a class="ae kc" href="https://machinelearningmastery.com/gentle-introduction-bag-words-model/" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="6ad3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其他更复杂的文本到矢量转换技术包括:</p><ol class=""><li id="1473" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la lh li lj lk bi translated"><a class="ae kc" href="https://www.quora.com/How-does-TF-IDF-work" rel="noopener ugc nofollow" target="_blank"> Tfidf </a></li><li id="8ec0" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated"><a class="ae kc" rel="noopener" target="_blank" href="/light-on-math-machine-learning-intuitive-guide-to-understanding-word2vec-e0128a460f0f"> Word2Vec </a></li></ol><p id="f0ea" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个项目的完整 Jupyter 笔记本可以在<a class="ae kc" href="https://github.com/tanmaylata/Text-Cleaning-and-BoW/blob/master/Text%20Cleaning%20and%20BoW.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="6916" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里完成的预处理步骤是在<a class="ae kc" href="https://www.kaggle.com" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上可用的<a class="ae kc" href="https://www.kaggle.com/snap/amazon-fine-food-reviews" rel="noopener ugc nofollow" target="_blank">亚马逊美食评论数据集</a>上执行的。执行所有步骤所依据的<em class="lb">“文本”</em>功能是指不同食品的审查(被视为文件)。</p><p id="2282" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">暂时就这样吧！感谢人们读到这里！</p><figure class="mt mu mv mw gt jr gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/edd5a0abb5ac03a3dcf91a6767310cf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*BYS6KlOuX573eC7vQjtpww.gif"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><a class="ae kc" href="https://media1.tenor.com/images/0584ba2a53ae5f9ef7782eef423b69c3/tenor.gif?itemid=9394190" rel="noopener ugc nofollow" target="_blank">BBYE!!</a></figcaption></figure></div></div>    
</body>
</html>