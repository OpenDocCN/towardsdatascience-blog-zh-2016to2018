<html>
<head>
<title>Fascinating Tales of a Strange Tomorrow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">奇异明天的迷人故事</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fascinating-tales-of-a-strange-tomorrow-72048639e754?source=collection_archive---------4-----------------------#2017-04-05">https://towardsdatascience.com/fascinating-tales-of-a-strange-tomorrow-72048639e754?source=collection_archive---------4-----------------------#2017-04-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="a4da" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">人工智能:科学与小说</h1><p id="0d92" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">我们的旅行始于1956年3月“禁忌星球”电影的上映，这部电影的主角是机器人<strong class="kn ir">罗比</strong>，他是公认的第一个出现在银幕上的科幻机器人。几个月后，由<strong class="kn ir"/><a class="ae lj" href="https://en.wikipedia.org/wiki/John_McCarthy_(computer_scientist)" rel="noopener ugc nofollow" target="_blank">【1】</a>领导的一小组计算机科学家在新罕布什尔州的达特茅斯学院举办了为期6周的研讨会。</p><div class="lk ll lm ln gt ab cb"><figure class="lo lp lq lr ls lt lu paragraph-image"><img src="../Images/0f17938b2fd257df81b7d0e87f15f367.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*BP0H48KcXBO52m912cV_mw.png"/></figure><figure class="lo lp lx lr ls lt lu paragraph-image"><img src="../Images/b422b4e90591764195e4c251e7966063.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*g_mqan44TfqMfks65-MMmw.png"/><figcaption class="ly lz gj gh gi ma mb bd b be z dk mc di md me">John McCarthy (Turing Award 1971) &amp; Robbie the Robot</figcaption></figure></div><p id="a9ab" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">这次研讨会的主题是“<strong class="kn ir">人工智能</strong>”，这是麦卡锡自己创造的一个术语，他是这样定义的:</p><blockquote class="mk ml mm"><p id="d475" class="kl km mn kn b ko mf kq kr ks mg ku kv mo mh ky kz mp mi lc ld mq mj lg lh li ij bi translated"><em class="iq">“学习的每一个方面或智力的任何其他特征，原则上都可以如此精确地描述，以至于可以制造一台机器来模拟它”。</em></p></blockquote><p id="9750" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">如果达特茅斯的工作室实际上是由约翰·麦卡锡看了《禁忌星球》然后回家想:“让我们来建造罗比”而引发的，那不是很棒吗？不过，这可能根本不是真的。哦好吧。</p><p id="34b1" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">不管怎样，这个小组开始工作，为我们所知的人工智能奠定了基础。事实上，大多数参与者将他们的整个职业生涯都奉献给了推动人工智能的发展，在这个过程中获得了不下四个图灵奖:1969年的<strong class="kn ir">马文·明斯基</strong><a class="ae lj" href="https://en.wikipedia.org/wiki/Marvin_Minsky" rel="noopener ugc nofollow" target="_blank">【3】</a>，1971年的约翰·麦卡锡，<strong class="kn ir">希尔伯特·西蒙</strong><a class="ae lj" href="https://en.wikipedia.org/wiki/Herbert_A._Simon" rel="noopener ugc nofollow" target="_blank">【4】</a>&amp;<strong class="kn ir">艾伦·纽厄尔</strong><a class="ae lj" href="https://en.wikipedia.org/wiki/Allen_Newell" rel="noopener ugc nofollow" target="_blank">【5】</a>1975年。</p><div class="lk ll lm ln gt ab cb"><figure class="lo lp mr lr ls lt lu paragraph-image"><img src="../Images/973296b86e69278d6b8e89bab3f9fc68.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*EPw7CI9Pecfhde4FwDq_Mw.png"/></figure><figure class="lo lp ms lr ls lt lu paragraph-image"><img src="../Images/309d010b608e9dbeba966398c53f29ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*LBdjlgihtm_Pu5x2BXZWJg.png"/><figcaption class="ly lz gj gh gi ma mb bd b be z dk mt di mu me">Herbert Simon (Turing Award 1975, Nobel Prize in Economics 1978) ad Allen Newell (Turing Award 1975)</figcaption></figure></div><p id="43a8" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">在人工智能的早期，这些聪明的科学家做出了一些预测，比如:</p><p id="27c1" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">1958年，希尔伯特·西蒙和艾伦·纽厄尔:“<strong class="kn ir"><em class="mn">10年内数字计算机将是世界象棋冠军。</em> </strong></p><p id="1b0c" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">1965年，希尔伯特·西蒙:“<strong class="kn ir"><em class="mn">20年内，机器将能做任何人能做的工作。</em> </strong></p><p id="08df" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">1967年马文·明斯基:<strong class="kn ir"> <em class="mn">在一代人之内，创造‘人工智能’的问题将得到实质性解决</em>。</strong></p><p id="7d37" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">1970年马文·明斯基:“<strong class="kn ir"> <em class="mn">在3到8年的时间里，我们将拥有一台拥有普通人一般智力的机器。</em> </strong></p><p id="6c94" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">哎呀。</p><h1 id="c139" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">人工智能的冬天来了</h1><p id="5cfa" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">预测未来总是有风险的事情，但这仍然提出了一个令人生畏的问题:对于人工智能在合理的时间框架内会(或不会)实现什么，如此聪明的头脑怎么会如此大错特错？不要担心，我们稍后会回答这个问题。</p><blockquote class="mk ml mm"><p id="25d9" class="kl km mn kn b ko mf kq kr ks mg ku kv mo mh ky kz mp mi lc ld mq mj lg lh li ij bi translated">不幸的是，多次未能取得重大进展成为了人工智能的商标。</p></blockquote><p id="68e3" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">期望很高，结果很少或根本没有，资金被削减，项目被放弃。不出所料，这些多重的<strong class="kn ir"> AI winters </strong>让除了最铁杆支持者之外的所有人望而却步。</p><p id="1c86" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">这种幻灭最明显的象征来自马文·明斯基本人。2001年，他做了一个名为“<strong class="kn ir">的报告:现在是2001年:哈尔在哪里？当然指的是斯坦利·库布里克电影《2001:太空漫游》中的哈尔电脑。更重要的是，早在1968年，明斯基就在电影制作期间给库布里克提了建议。在这次演讲中，他明确地提出了“<strong class="kn ir">常识问题</strong>”:<em class="mn">“今天没有任何程序可以区分狗和猫，或者识别典型房间中的物体，或者回答4岁儿童可以回答的问题！”</em></strong></p><div class="lk ll lm ln gt ab cb"><figure class="lo lp mv lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><img src="../Images/9282fe8a7e4a4f793038a16b78a32c22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*l9D6KMIc_WX9kvoxlp5VaQ.png"/></div></figure><figure class="lo lp na lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><img src="../Images/d2e59b7eedd3cda63ffd47a626b31042.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*u2hrDMKr1k__X6fSgmKzqQ.png"/></div><figcaption class="ly lz gj gh gi ma mb bd b be z dk nb di nc me">Marvin Minsky (Turing Award 1969) &amp; HAL 9000</figcaption></figure></div><p id="10c1" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">一句话:在实验室环境中玩人工智能很酷，但在现实世界中它永远不会有所成就。结案了。</p><h1 id="175c" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">与此同时，在美国西海岸…</h1><p id="9ebc" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">当人工智能研究人员在实验室里绝望的时候，一些初创公司正在重塑世界:亚马逊、谷歌、雅虎，后来脸书和其他几家公司加入进来，它们正在以疯狂的速度发展自己的网络平台。在这个过程中，他们获得了数以百万计的用户，积累了大量的数据。很快就清楚了，这些数据是一座金矿，<strong class="kn ir">如果真的可以开采的话</strong>！</p><p id="52d9" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">使用商用硬件，这些公司的工程师开始寻求设计和构建数据处理平台，使他们能够<strong class="kn ir">处理原始数据并提取商业价值，这些价值可以转化为收入</strong> …这始终是快速增长的初创公司的一个关键目标！</p><p id="f747" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">2004年12月达到了一个重要的里程碑，当时Google发布了著名的<strong class="kn ir"> Map Reduce </strong>论文<a class="ae lj" href="https://research.google.com/archive/mapreduce.html" rel="noopener ugc nofollow" target="_blank">【6】</a>，其中他们描述了<em class="mn">一个编程模型和一个用于处理和生成大型数据集的相关实现</em>。不甘示弱的雅虎实现了本文描述的想法，并于2006年4月发布了他们项目的第一个版本:<strong class="kn ir">Hadoop</strong><a class="ae lj" href="https://hadoop.apache.org/" rel="noopener ugc nofollow" target="_blank">【7】</a>诞生了。</p><blockquote class="mk ml mm"><p id="a3d3" class="kl km mn kn b ko mf kq kr ks mg ku kv mo mh ky kz mp mi lc ld mq mj lg lh li ij bi translated">等待火柴的汽油:机器学习爆炸发生了，剩下的，正如他们所说，是历史。</p></blockquote><h1 id="9973" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">快进几年</h1><p id="5f32" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">2010年左右:<strong class="kn ir">机器学习现在是商品</strong>。客户有广泛的选择，从DIY到机器学习即服务。数据世界一切都很棒。但真的是这样吗？是的，机器学习帮助我们让很多应用程序变得“更聪明”，但是<strong class="kn ir">我们在人工智能方面取得重大进展了吗？</strong>换句话说，我们离“建设哈尔”更近了吗？嗯……不。让我们试着理解为什么。</p><p id="a57a" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">构建机器学习应用的第一步被称为“<strong class="kn ir">特征提取</strong>”。简而言之，这是数据科学家探索数据集的一个步骤，以找出哪些变量对预测或分类数据有意义，哪些没有意义。虽然这仍然主要是一个冗长的手动过程，但现在已经很好地理解了它，并且可以很好地处理结构化或半结构化数据，如web日志或销售数据。</p><p id="d23a" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">然而，<strong class="kn ir">对于复杂的人工智能问题</strong>如计算机视觉或计算机语音并不适用，原因很简单，因为要正式定义<strong class="kn ir">的特征</strong>是什么:例如，是什么让猫成为猫？猫和狗有什么不同？还是来自狮子？</p><blockquote class="mk ml mm"><p id="67ca" class="kl km mn kn b ko mf kq kr ks mg ku kv mo mh ky kz mp mi lc ld mq mj lg lh li ij bi translated">简单来说，传统的机器学习并不能解决这类问题，这就是为什么需要新的工具。进入神经网络！</p></blockquote><h1 id="99fb" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">回到未来</h1><p id="6d0c" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">新工具？几乎没有！1957年，Frank Rosenblatt设计了一个机电神经网络，感知器<a class="ae lj" href="https://en.wikipedia.org/wiki/Perceptron" rel="noopener ugc nofollow" target="_blank">【8】</a>，他训练它识别图像(20x20“像素”)。1975年，Paul Werbos发表了一篇描述“反向传播”<a class="ae lj" href="https://en.wikipedia.org/wiki/Backpropagation" rel="noopener ugc nofollow" target="_blank">【9】</a>的文章，这是一种允许更好更快地训练神经网络的算法。</p><p id="488b" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">因此，如果神经网络已经存在了这么长时间，那么它们肯定要对失败的人工智能尝试负部分责任，对吗？他们真的应该复活吗？为什么他们会突然成功？</p><p id="001a" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">确实是非常合理的问题。让我们首先快速了解一下神经网络是如何工作的。一个<strong class="kn ir">神经元</strong>是一个简单的构造，它将多个<strong class="kn ir">加权输入</strong>相加产生一个<strong class="kn ir">输出</strong>。神经元被组织在<strong class="kn ir">层</strong>中，其中层‘n’中每个神经元的输出作为层‘n+1’中每个神经元的输入。第一层称为<strong class="kn ir">输入层</strong>，输入数据，比如图像的像素值。最后一层称为<strong class="kn ir">输出层</strong>并产生结果，比如图像的类别号(“这是一只狗”)。</p><div class="lk ll lm ln gt ab cb"><figure class="lo lp nd lr ls lt lu paragraph-image"><img src="../Images/6fc1bc88610cfb5099f08f697fd14d45.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*s3q_ob5bY1V-xB25zJE4iA.png"/></figure><figure class="lo lp ne lr ls lt lu paragraph-image"><img src="../Images/e4f2d9d4e13da86116e7b0148eab89ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*qloAHmuLvAUbLsDYobaGfQ.png"/><figcaption class="ly lz gj gh gi ma mb bd b be z dk nf di ng me">The basic structure of a neural network (Source: “Deep Learning”, Goodfellow &amp; Bengio, 2016)</figcaption></figure></div><blockquote class="mk ml mm"><p id="2d18" class="kl km mn kn b ko mf kq kr ks mg ku kv mo mh ky kz mp mi lc ld mq mj lg lh li ij bi translated">神经网络的美妙之处在于它们能够<strong class="kn ir">自我组织</strong>:给定足够大的数据集(比如，图像作为输入，类别标签作为输出)，神经网络能够自动学习<strong class="kn ir">如何产生正确的答案</strong></p></blockquote><p id="7b70" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">由于一个迭代训练过程，它能够<strong class="kn ir">发现允许图像被分类的特征</strong>，并反复调整权重以达到最佳结果，即具有最小错误率的结果。</p><p id="f0e5" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">训练阶段及其自动特征发现非常适合解决非正式问题，但这里有一个问题:它们涉及<strong class="kn ir">许多</strong>数学运算，随着<strong class="kn ir">数据大小</strong>的增加(想想高分辨率图片)以及随着<strong class="kn ir">层数</strong>的增加，这些运算往往会呈指数增长。这个问题被称为“<strong class="kn ir">维数灾难</strong>”，这也是神经网络几十年来停滞不前的主要原因之一:根本没有足够的<strong class="kn ir">计算能力</strong>来大规模运行它们。</p><p id="a6ca" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">也没有足够的数据可用。神经网络需要大量数据才能正确学习。数据越多越好！直到最近，收集和存储大量的数字数据还是不可能的。你记得穿孔卡片或软盘吗？</p><p id="f2df" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">一项重大突破发生在1998年，当时Yann Le Cun发明了<strong class="kn ir">卷积神经网络</strong><a class="ae lj" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">【10】</a>，这是一种新型的多层网络(因此被称为“深度学习”)。</p><blockquote class="mk ml mm"><p id="fc4f" class="kl km mn kn b ko mf kq kr ks mg ku kv mo mh ky kz mp mi lc ld mq mj lg lh li ij bi translated">简而言之，CNN能够有效地提取特征，同时减少输入数据的大小:这允许更小的网络用于分类，这大大降低了网络训练的计算成本。</p></blockquote><p id="da83" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">这种方法非常成功，以至于银行采用CNN驱动的系统来实现支票手写识别的自动化。对于神经网络来说，这是一个令人鼓舞的成就…但是最好的还在后面！</p><figure class="lk ll lm ln gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi nh"><img src="../Images/f718aa6fe459289b285ab6b3d30c1a05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qGWVCW3scw3g6EEF8Pscog.png"/></div></div><figcaption class="ly lz gj gh gi ma mb bd b be z dk">Architecture of a Convolutional Neural Network (Source: NVIDIA blog)</figcaption></figure><h1 id="b95c" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">神经帝国反击了</h1><p id="1dd1" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">到2000年代末，三个几乎同时发生的事件使得大规模神经网络成为可能。</p><p id="65da" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">首先，<strong class="kn ir">大型数据集</strong>变得广泛可用。文本、图片、电影、音乐:一切都突然数字化了，可以用来训练神经网络。今天，ImageNet<a class="ae lj" href="http://image-net.org" rel="noopener ugc nofollow" target="_blank">【11】</a>数据库拥有超过1400万张带标签的图像，世界各地的研究人员每年都用它来竞争建立最成功的图像检测和分类网络(稍后将详细介绍)。</p><p id="57d2" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">然后，研究人员能够利用<strong class="kn ir">图形处理单元</strong>(GPU)的<strong class="kn ir">惊人的并行处理能力</strong>来训练大型神经网络。你能相信赢得2015年和2016年ImageNet竞赛的分别有152层和269层吗？</p><p id="704e" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">最后但同样重要的是，<strong class="kn ir">云计算</strong>为开发人员和研究人员带来了<strong class="kn ir">弹性</strong>和<strong class="kn ir">可扩展性</strong>，允许他们根据培训需要使用尽可能多的基础设施……而不必长期构建、运行或支付费用。</p><blockquote class="mk ml mm"><p id="4451" class="kl km mn kn b ko mf kq kr ks mg ku kv mo mh ky kz mp mi lc ld mq mj lg lh li ij bi translated">这三个因素的结合有助于神经网络实现其60年的承诺。</p></blockquote><p id="88c2" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">最先进的网络现在能够比任何人更快<strong class="kn ir"/>和更准确<strong class="kn ir"/>地<strong class="kn ir">分类图像(误差小于3%，而人类为5%)。像亚马逊Echo这样的设备能够理解自然语言并和我们交流。自动驾驶汽车正在成为现实。人工智能应用的列表每天都在增长。</strong></p><p id="942e" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">你不想添加你的吗？</p><figure class="lk ll lm ln gt lp gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi ni"><img src="../Images/d0856ba3681eb7314fdf6001cdb68a22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V_FsNpscIuseTUAB3cy_AA.png"/></div></div><figcaption class="ly lz gj gh gi ma mb bd b be z dk">Number of layers and error rate of ILSVRC winners</figcaption></figure><h1 id="2bcb" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">AWS如何帮助您构建深度学习应用程序</h1><p id="0461" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">AWS提供了您开始构建深度学习应用程序所需的一切:</p><p id="ba63" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">种类繁多的<strong class="kn ir">亚马逊EC2实例</strong>来构建和训练你的模型，随你选择<strong class="kn ir">CPU</strong><a class="ae lj" href="https://aws.amazon.com/about-aws/whats-new/2016/11/coming-soon-amazon-ec2-c5-instances-the-next-generation-of-compute-optimized-instances/" rel="noopener ugc nofollow" target="_blank">【13】</a><strong class="kn ir">GPU</strong><a class="ae lj" href="https://aws.amazon.com/blogs/aws/in-the-work-amazon-ec2-elastic-gpus/" rel="noopener ugc nofollow" target="_blank"/><a class="ae lj" href="https://aws.amazon.com/blogs/aws/new-p2-instance-type-for-amazon-ec2-up-to-16-gpus/" rel="noopener ugc nofollow" target="_blank">【15】</a>甚至<strong class="kn ir">FPGA</strong><a class="ae lj" href="https://aws.amazon.com/blogs/aws/developer-preview-ec2-instances-f1-with-programmable-hardware/" rel="noopener ugc nofollow" target="_blank">【16】</a>。</p><p id="8b7f" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated"><strong class="kn ir">深度学习亚马逊机器映像</strong><a class="ae lj" href="https://aws.amazon.com/marketplace/pp/B01M0AXXQB" rel="noopener ugc nofollow" target="_blank">【17】</a>，预装工具和库集合:mxnet<a class="ae lj" href="http://mxnet.io/" rel="noopener ugc nofollow" target="_blank">【18】</a>(AWS官方支持)，Theano，Caffe，TensorFlow，Torch，Anaconda等等。</p><p id="cfe7" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">高级别的<strong class="kn ir">人工智能服务</strong><a class="ae lj" href="https://aws.amazon.com/amazon-ai/" rel="noopener ugc nofollow" target="_blank">【19】</a>用于图像识别(<strong class="kn ir">亚马逊识别</strong>)、语音转文本(<strong class="kn ir">亚马逊Polly </strong>)和聊天机器人(<strong class="kn ir">亚马逊Lex </strong>)。</p><blockquote class="mk ml mm"><p id="7809" class="kl km mn kn b ko mf kq kr ks mg ku kv mo mh ky kz mp mi lc ld mq mj lg lh li ij bi translated">选择权在你，<strong class="kn ir">开始吧</strong>帮助科学赶上小说！</p></blockquote><h1 id="b112" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">新的希望？</h1><figure class="lk ll lm ln gt lp gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/0b5b63991dcd1016fa3a51149295ee93.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*j206w6dxISxonkrDVhlxIg.png"/></div></figure><p id="d628" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">人工智能每天都在进步。人们只能想知道接下来会发生什么！</p><p id="013a" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">机器会学习如何理解人类——而不是相反吗？</p><p id="b3e3" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">它们会帮助人类相互理解吗？</p><p id="aa85" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">他们最终会统治世界吗？</p><p id="2cc2" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">谁知道呢？</p><p id="3c5a" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated">无论发生什么，这些都将是奇妙明天的迷人故事。</p><p id="ff4c" class="pw-post-body-paragraph kl km iq kn b ko mf kq kr ks mg ku kv kw mh ky kz la mi lc ld le mj lg lh li ij bi translated"><em class="mn">注:这是我最近一次主题演讲的编辑稿。原始幻灯片可用</em> <a class="ae lj" href="https://www.slideshare.net/JulienSIMON5/fascinating-tales-of-a-strange-tomorrow-74449554" rel="noopener ugc nofollow" target="_blank"> <em class="mn">此处</em> </a> <em class="mn">。</em></p></div></div>    
</body>
</html>