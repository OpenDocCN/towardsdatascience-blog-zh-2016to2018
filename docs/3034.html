<html>
<head>
<title>Medical Image Segmentation [Part 1] — UNet: Convolutional Networks with Interactive Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">医学图像分割[第一部分] — UNet:交互式编码卷积网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/medical-image-segmentation-part-1-unet-convolutional-networks-with-interactive-code-70f0f17f46c6?source=collection_archive---------0-----------------------#2018-04-02">https://towardsdatascience.com/medical-image-segmentation-part-1-unet-convolutional-networks-with-interactive-code-70f0f17f46c6?source=collection_archive---------0-----------------------#2018-04-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/3f986b03360137beb10bd28b67e2d39e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*BBYuLIsXxmIF3Hafuvfa8g.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Gif from this <a class="ae jy" href="https://giphy.com/gifs/computer-vision-zs7mLIVB5vNlK/download" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="2acd" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最后，我开始了这个系列，医学图像分割。关于这个主题，我的第一篇文章是实现众所周知的体系结构，UNet。如果你想看原文，请点击<a class="ae jy" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank">这里</a>。(或者我也把它链接到下面)。请注意，今天我觉得有点懒，只想使用自动微分。也许在不久的将来，我可以回来为这个网络做人工反向传播。</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><figure class="le lf lg lh gt jr"><div class="bz fp l di"><div class="li lj l"/></div></figure></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="a7c3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">网络架构(图形/ OOP形式)</strong></p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lk"><img src="../Images/f6751b7fc1dcbb1546e60f33b233d433.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q3vqSaSTgYzpbk1KIBmWsw.png"/></div></div></figure><p id="1e48" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这篇论文在解释网络体系结构方面做得非常出色。我们可以看到网络由卷积运算、最大池、<a class="ae jy" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" rel="noopener ugc nofollow" target="_blank">、ReLU激活</a>、级联和上采样层组成。现在，我知道有些人可能对如何对原始图像进行上采样感到困惑，这可以通过使用转置卷积运算来实现。我不会深入讨论这个材料，但是这篇博文<a class="ae jy" rel="noopener" target="_blank" href="/up-sampling-with-transposed-convolution-9ae4f2df52d0">做了一件令人惊奇的工作，解释了我们如何使用它来上采样图像。还有，这里是我们可以使用的</a><a class="ae jy" href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose" rel="noopener ugc nofollow" target="_blank"> Tensorflow API </a>。</p><div class="le lf lg lh gt ab cb"><figure class="lp jr lq lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/d77ce545e1da525ba3d7ea3af23ecd5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/format:webp/1*WfImvU7tiKI0Ck4QOw3mnQ.png"/></div></figure><figure class="lp jr lv lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/f192edac4fab58f6964c91a260857903.png" data-original-src="https://miro.medium.com/v2/resize:fit:1502/format:webp/1*aRMefObpm7AMVOZYYiQAMQ.png"/></div></figure></div><p id="eab6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">红框</strong> →代表U网左侧<br/> <strong class="kb ir">蓝框</strong> →代表U网右侧<br/> <strong class="kb ir">绿框</strong> →最终瓶颈层。</p><p id="d1d4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">从实现的角度来看，它非常简单，只需要几个卷积层，再加上最大池和ReLu()激活。</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="885f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">实验设置/与论文的差异</strong></p><div class="le lf lg lh gt ab cb"><figure class="lp jr lw lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/610eaf1594517ee4ffa08d4363dfdf51.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Bw_NJLs-SsWxIqYZfyk-jg.png"/></div></figure><figure class="lp jr lw lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/2c904ee075beaa87b8968abfbd3ce8f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*7pSRd0yrNj7fmG0ZHHdrkg.png"/></div></figure><figure class="lp jr lw lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/a8cc81bf7d4f66858e797cc8377aa1ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*zfLwh8rv8ucyYSXlQO-izQ.png"/></div></figure></div><p id="5e62" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">右图</strong> →原图<br/> <strong class="kb ir">中图</strong> →地面真实二值蒙版<br/> <strong class="kb ir">左图</strong> →地面真实蒙版叠加原图</p><p id="d582" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这个网络的实验设置非常简单，我们将使用Kaggle Challenge <a class="ae jy" href="https://www.kaggle.com/c/ultrasound-nerve-segmentation/leaderboard" rel="noopener ugc nofollow" target="_blank"> <em class="lx">超声神经分割</em> </a> <em class="lx">的公开可用数据集。我们将看看我们的模型是否能够从图像中分割出特定的部分。但是，请注意，与原文有三处不同。</em></p><ol class=""><li id="6c32" class="ly lz iq kb b kc kd kg kh kk ma ko mb ks mc kw md me mf mg bi translated"><strong class="kb ir"> <em class="lx">使用了较小的特征图尺寸</em> </strong> →这是由于硬件的限制，我使用的特征图数量是(1、3、6、12、24和48)。</li><li id="0c46" class="ly lz iq kb b kc mh kg mi kk mj ko mk ks ml kw md me mf mg bi translated"><strong class="kb ir"> <em class="lx">使用了不同的代价函数</em> </strong> →如下图所示，原纸已经使用了<a class="ae jy" href="https://deepnotes.io/softmax-crossentropy" rel="noopener ugc nofollow" target="_blank">带交叉熵损失函数的softmax】。</a></li></ol><figure class="le lf lg lh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mm"><img src="../Images/b62bb63739633733019b4a0e0ce21ce0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e2rBzA7ZiJrj-cSzXx_dsA.png"/></div></div></figure><p id="fc15" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">然而，我使用了一个<a class="ae jy" href="https://en.wikipedia.org/wiki/Mean_squared_error" rel="noopener ugc nofollow" target="_blank">均方损失函数</a>，激活了ReLu()。</p><p id="476e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">3 <strong class="kb ir"> <em class="lx">。用了不同的优化器</em> </strong> →如下图所示，原论文用的是<a class="ae jy" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent" rel="noopener ugc nofollow" target="_blank">随机梯度下降优化器</a>，我只是用了一个<a class="ae jy" href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/" rel="noopener ugc nofollow" target="_blank"> Adam优化器</a>。</p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mn"><img src="../Images/d310aed6f02a568cc66e902732ec4493.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XDEUqP66LKlov0L5D6PsPA.png"/></div></div></figure></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="f90f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果</strong></p><div class="le lf lg lh gt ab cb"><figure class="lp jr lw lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/0669c1c8f086ca005f60b9451e002fbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*1z-sSFY7FT7D1ANUt51YSw.png"/></div></figure><figure class="lp jr lw lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/54cc64458cbf10e65de78bc0c181917d.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*27AB1jng_QnaYUF7GG5pqQ.png"/></div></figure><figure class="lp jr lw lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/80e519b912dd9d5aec1a71e8a11f21c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*_dggcdSIUaLz9KhmHH0GzA.png"/></div></figure></div><div class="ab cb"><figure class="lp jr lw lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/d9cf2b83cc3c5569da05a211cfefb27a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*SHbuXQWtHBeOwZHlLtv5Iw.png"/></div></figure><figure class="lp jr lw lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/143c5f0686524398496b45513e396823.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*ppVeQyzPLeu0K-f-bbQRig.png"/></div></figure><figure class="lp jr lw lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/c4540a81d0198be15fdf0d023ba4189a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*iyuPhzBFeUdIaR6-1IhdHA.png"/></div></figure></div><p id="6c19" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">右图</strong> →原图<br/> <strong class="kb ir">中图</strong> →二值掩码<br/> <strong class="kb ir">左图</strong> →从网络生成二值掩码</p><p id="6821" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">总的来说，与地面真实二进制掩码相比，网络做得令人惊讶地好，网络似乎正确地分割了它周围的区域。下面是在原始图像上叠加地面真实蒙版或生成蒙版时的一些图像。</p><div class="le lf lg lh gt ab cb"><figure class="lp jr mo lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/cb421486b15de04c81e560293c246ea7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*GiBWXADxJv4g5x-Hm4y9_g.png"/></div></figure><figure class="lp jr mo lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/cce25217873605ce2cdb14f4e3c98105.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*xX-lbJzJcIbH4gAKtfP9Qw.png"/></div></figure></div><div class="ab cb"><figure class="lp jr mo lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/01237e46a840a11f387a13ee4af2b36c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*78gA0FuQbwsXw-FUvtQSpg.png"/></div></figure><figure class="lp jr mo lr ls lt lu paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><img src="../Images/f50bcfec13b085c2533f235723803bc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*GuGThzkh1A6_DtlrWP5Uuw.png"/></div></figure></div></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="ce6f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">GIF格式的结果</strong></p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/e6d1c2c32efd58be2732c4fdbeebf4e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*S9skg1Cs9MRXe3hbsO9o-A.gif"/></div></figure><p id="a9e3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">显示图像的顺序</strong> → 1。原图→ 2。地面真实二进制掩码→ 3。生成的二进制掩码→ 4。原始图像上的地面真实遮罩叠加→ 5。原始图像上生成的蒙版覆盖。</p><p id="66e3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">以上是我根据分割结果制作的GIF，请注意观看GIF的顺序，以下是网络如何加班的汇编。随着训练的持续(从epoch来看),我们可以看到生成的掩码变得更加精确。</p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/4fa5d826040ebdc95abf42e8fab09152.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*DKIeqS16ctIEhIbfwjav9g.gif"/></div></figure></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="012c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">互动代码/透明度</strong></p><figure class="le lf lg lh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mq"><img src="../Images/e34262c13d9d94e40d988119bb3d1559.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tYKfJKyI2fzM142q2zJXQA.png"/></div></div></figure><p id="ef75" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于Google Colab，你需要一个Google帐户来查看代码，而且你不能在Google Colab中运行只读脚本，所以在你的操场上做一个副本。最后，我永远不会请求允许访问你在Google Drive上的文件，仅供参考。编码快乐！</p><p id="f79d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">要访问Google Colab上的代码，<a class="ae jy" href="https://colab.research.google.com/drive/1BgCDxVdVc0MAe_kC0waMGUV9ShcWW0hM" rel="noopener ugc nofollow" target="_blank">请点击此处</a>。</p><ul class=""><li id="27b9" class="ly lz iq kb b kc kd kg kh kk ma ko mb ks mc kw mr me mf mg bi translated">*注**:我不想在github上托管Kaggles的数据，因为我可能会违反他们的数据使用政策。所以这段代码不能直接在线运行。</li><li id="f32a" class="ly lz iq kb b kc mh kg mi kk mj ko mk ks ml kw mr me mf mg bi translated">为了让这个实验更加透明，我把我所有的命令输出上传到了我的github，如果你想看，请点击<a class="ae jy" href="https://github.com/JaeDukSeo/Only_Numpy_Basic/blob/master/U-net/u-net.txt" rel="noopener ugc nofollow" target="_blank">这里</a>。</li></ul></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="ce5c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">遗言</strong></p><p id="0665" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我真的想将我的技能扩展到细分领域，我很高兴最终我能够做到这一点。</p><p id="8ee7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到jae.duk.seo@gmail.com给我，如果你希望看到我所有写作的列表，请<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">在这里查看我的网站</a>。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的推特<a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，并访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>了解更多内容。如果你感兴趣的话，我还做了解耦神经网络的比较。</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="f682" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="84e6" class="ly lz iq kb b kc kd kg kh kk ma ko mb ks mc kw md me mf mg bi translated">罗尼伯格，o .，菲舍尔，p .，&amp; Brox，T. (2015年10月)。生物医学图像分割的卷积网络。在<em class="lx">医学图像计算和计算机辅助介入国际会议上</em>(第234-241页)。斯普林格，查姆。</li><li id="f15e" class="ly lz iq kb b kc mh kg mi kk mj ko mk ks ml kw md me mf mg bi translated">超声波神经分割| Kaggle。(2018).Kaggle.com。检索于2018年4月2日，来自<a class="ae jy" href="https://www.kaggle.com/c/ultrasound-nerve-segmentation" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/ultrasound-nerve-segmentation</a></li><li id="181a" class="ly lz iq kb b kc mh kg mi kk mj ko mk ks ml kw md me mf mg bi translated">整流器(神经网络)。(2018).En.wikipedia.org。检索于2018年4月2日，来自<a class="ae jy" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Rectifier _(neural _ networks)</a></li><li id="c18d" class="ly lz iq kb b kc mh kg mi kk mj ko mk ks ml kw md me mf mg bi translated">面向数据科学的转置卷积上采样。(2017).走向数据科学。检索于2018年4月2日，来自<a class="ae jy" rel="noopener" target="_blank" href="/up-sampling-with-transposed-convolution-9ae4f2df52d0">https://towards data science . com/up-sampling-with-transposed-convolution-9 AE 4 F2 df 52d 0</a></li><li id="bc9b" class="ly lz iq kb b kc mh kg mi kk mj ko mk ks ml kw md me mf mg bi translated">TF . nn . conv 2d _ transpose | tensor flow。(2018).张量流。检索于2018年4月2日，来自<a class="ae jy" href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/nn/conv2d _ transpose</a></li><li id="f6b3" class="ly lz iq kb b kc mh kg mi kk mj ko mk ks ml kw md me mf mg bi translated">达哈尔，P. (2017年)。分类和损失评估— Softmax和交叉熵损失。深度笔记。2018年4月2日检索，来自<a class="ae jy" href="https://deepnotes.io/softmax-crossentropy" rel="noopener ugc nofollow" target="_blank">https://deepnotes.io/softmax-crossentropy</a></li><li id="1863" class="ly lz iq kb b kc mh kg mi kk mj ko mk ks ml kw md me mf mg bi translated">j . brown lee(2017年)。深度学习的Adam优化算法的温和介绍-机器学习掌握。机器学习精通。检索于2018年4月2日，来自<a class="ae jy" href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/Adam-optimization-algorithm-for-deep-learning/</a></li><li id="458e" class="ly lz iq kb b kc mh kg mi kk mj ko mk ks ml kw md me mf mg bi translated">随机梯度下降。(2018).En.wikipedia.org。检索于2018年4月2日，来自https://en.wikipedia.org/wiki/Stochastic_gradient_descent<a class="ae jy" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent" rel="noopener ugc nofollow" target="_blank"/></li><li id="1736" class="ly lz iq kb b kc mh kg mi kk mj ko mk ks ml kw md me mf mg bi translated">Python中的DICOM:用PyDICOM和VTK将医学图像数据导入NumPy。(2014).PyScience。2018年4月2日检索，来自<a class="ae jy" href="https://pyscience.wordpress.com/2014/09/08/dicom-in-python-importing-medical-image-data-into-numpy-with-pydicom-and-vtk/" rel="noopener ugc nofollow" target="_blank">https://pyscience . WordPress . com/2014/09/08/DICOM-in-python-importing-medical-image-data-into-numpy-with-pydicom-and-VTK/</a></li><li id="42d6" class="ly lz iq kb b kc mh kg mi kk mj ko mk ks ml kw md me mf mg bi translated">JaeDukSeo/Only_Numpy_Basic。(2018).GitHub。2018年4月2日检索，来自<a class="ae jy" href="https://github.com/JaeDukSeo/Only_Numpy_Basic/blob/master/U-net/u-net.txt" rel="noopener ugc nofollow" target="_blank">https://github . com/JaeDukSeo/Only _ Numpy _ Basic/blob/master/U-net/U-net . txt</a></li><li id="dbb7" class="ly lz iq kb b kc mh kg mi kk mj ko mk ks ml kw md me mf mg bi translated">均方差。(2018).En.wikipedia.org。检索于2018年4月2日，来自<a class="ae jy" href="https://en.wikipedia.org/wiki/Mean_squared_error" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Mean_squared_error</a></li></ol></div></div>    
</body>
</html>