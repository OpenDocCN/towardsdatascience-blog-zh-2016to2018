<html>
<head>
<title>Differentiable Rendering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">可区分渲染</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/differentiable-rendering-d00a4b0f14be?source=collection_archive---------9-----------------------#2018-08-19">https://towardsdatascience.com/differentiable-rendering-d00a4b0f14be?source=collection_archive---------9-----------------------#2018-08-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4901" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">听起来很酷，但是…是什么？</h2></div><p id="47a9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">随着我开始更多地关注机器学习，可微分渲染是引起我注意的一个话题，并且以一定的频率出现。我的第一个想法是，“cooooool 这是一个生成像素的新系统，可以利用机器学习吗？”深究题目之后，这立刻是失望，但失望最终被对实际实际应用的现实兴奋所取代。那么，什么是可微分渲染呢？</p><blockquote class="lb lc ld"><p id="f555" class="kf kg le kh b ki kj jr kk kl km ju kn lf kp kq kr lg kt ku kv lh kx ky kz la ij bi translated">反向图形试图获取传感器数据并推断 3D 几何图形、照明、材质和运动，以便图形渲染器可以逼真地再现观察到的场景。然而，渲染器被设计成解决图像合成的正向过程。在另一个方向，我们提出了一种近似可微分渲染器(DR ),它显式地模拟模型参数和图像观察之间的关系。<br/> -OpenDR:一个近似可微分的渲染器(<a class="ae li" href="http://files.is.tue.mpg.de/black/papers/OpenDR.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>，<a class="ae li" href="https://www.youtube.com/watch?v=4B06sKUt5dY" rel="noopener ugc nofollow" target="_blank">技术谈</a>)</p></blockquote><p id="c44d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">OpenDR 可以将颜色和顶点作为输入来产生图像中的像素，并从这些像素中保留导数，以便可以准确地确定哪些输入影响了最终的像素颜色。通过这种方式，它可以将图像“反渲染”回颜色和顶点。</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi lj"><img src="../Images/83fa9b8b4081d8d4ed61f90b83e7b792.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*bS86RMQ36PEdGa-Fu0Bbzw.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">OpenDR: An Approximate Differentiable Renderer</figcaption></figure><p id="b2b4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">OpenDR 是“近似的”,因为光栅化中存在不连续性，例如由于遮挡。这只是一种不同形式的渲染引擎(光栅化引擎)，但也存在其他形式的 DR，包括光线行进，基于点的技术，甚至是单一的着色表面。单一阴影表面的情况(想象一个全屏四边形)可能是最容易理解的，因为它只需要通过照明和 BRDF 传播就可以回到输入端。那么这有什么用呢？</p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/e727a642865f55c26cc7e7fe6c7c190b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*-wudQD-SmtxlhzZC2hDIqA.png"/></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><a class="ae li" href="https://hal.inria.fr/hal-01793826/document" rel="noopener ugc nofollow" target="_blank">Single-Image SVBRDF Capture with a Rendering-Aware Deep Network</a></figcaption></figure><p id="8075" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可区分渲染的一个用例是在训练机器学习模型时计算损失。例如，在 SVBRDF 重建论文的<a class="ae li" href="https://hal.inria.fr/hal-01793826/document" rel="noopener ugc nofollow" target="_blank">中，网络产生四个输出纹理图(漫反射率、镜面反射率、粗糙度、法线)，但是单独计算这四个空间中的损失是不够的。问题是，目标法线(例如)和推断法线之间的比较没有捕捉到当纹理实际渲染为光照表面时可见的感知损失。使用可微分渲染器来计算渲染图像空间中的损失；然后将损失传播回四个纹理输入，并从那里应用反向传播来训练网络。</a></p><figure class="lk ll lm ln gt lo gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi lw"><img src="../Images/fc1a584fdf915119d9d0b4b896c840a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TcH0txJs4hipPTZSzZIvYg.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk"><a class="ae li" href="https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/dyson-robotics-lab/jzienkiewicz_etal_iros2016.pdf" rel="noopener ugc nofollow" target="_blank">Real-Time Height Map Fusion using Differentiable Rendering</a></figcaption></figure><p id="b743" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">DR 在使用微分渲染的实时高度图融合中具有类似的应用。目标是从单个单目摄像机鲁棒地重建高度图。使用三角形网格和 DR，效率和鲁棒性都得到了提高。</p><blockquote class="lb lc ld"><p id="c711" class="kf kg le kh b ki kj jr kk kl km ju kn lf kp kq kr lg kt ku kv lh kx ky kz la ij bi translated">我们的方法的一个重要元素是在标准 OpenGL 计算机图形流水线中实现的可微分渲染器，该元素能够实现高效的操作。给定当前的表面模型和相机姿态，它可以在几乎没有额外计算成本的情况下，为每个像素渲染预测的图像和深度，以及这些量相对于模型参数的导数。</p></blockquote><p id="451f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">初始深度估计被转换成高度图，然后被渲染成具有顶点位移的三角形网格，以产生新的深度图，该深度图然后可用于计算损失。整个过程是可微分的，这意味着可以通过深度图、通过三角形网格、通过高度图、通过原始深度估计以及通过用于训练的网络追溯损失。</p><h2 id="4410" class="mb mc iq bd md me mf dn mg mh mi dp mj ko mk ml mm ks mn mo mp kw mq mr ms mt bi translated">结论和补充阅读</h2><p id="ef57" class="pw-post-body-paragraph kf kg iq kh b ki mu jr kk kl mv ju kn ko mw kq kr ks mx ku kv kw my ky kz la ij bi translated">这是对可区分渲染的快速概述，如果您和我一样，对 DR 的定义和用途感到疑惑，我希望这是有用的。我没有对这些论文的质量做任何声明，这些只是我写这篇文章时发现的相关作品。</p><ul class=""><li id="b7f3" class="mz na iq kh b ki kj kl km ko nb ks nc kw nd la ne nf ng nh bi translated">RenderNet:一个深度卷积网络，用于 3D 形状的可区分渲染</li><li id="896a" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ne nf ng nh bi translated"><a class="ae li" href="https://openreview.net/pdf?id=H13F3Pqll" rel="noopener ugc nofollow" target="_blank">使用对抗性想象先验的计算机视觉中的逆问题</a></li><li id="9444" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ne nf ng nh bi translated"><a class="ae li" href="https://distill.pub/2018/differentiable-parameterizations/" rel="noopener ugc nofollow" target="_blank">可微分图像参数化</a></li><li id="cd52" class="mz na iq kh b ki ni kl nj ko nk ks nl kw nm la ne nf ng nh bi translated"><a class="ae li" href="http://nsd.csail.mit.edu/" rel="noopener ugc nofollow" target="_blank">神经场景去渲染</a></li></ul></div></div>    
</body>
</html>