<html>
<head>
<title>Machine Learning tackles the Fake News problem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习解决假新闻问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-tackles-the-fake-news-problem-c3fa75549e52?source=collection_archive---------14-----------------------#2018-08-21">https://towardsdatascience.com/machine-learning-tackles-the-fake-news-problem-c3fa75549e52?source=collection_archive---------14-----------------------#2018-08-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="73b1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我最近有机会使用机器学习来解决美国媒体最前沿的一个问题，即识别假新闻的困难。具体来说，我的同学 David Masse 和我应用了两种 ML 方法来识别故意误导的新闻文章:逻辑回归和朴素贝叶斯分类器。使用包含 20，000 篇带标签文章的<a class="ae kn" href="https://www.kaggle.com/c/fake-news" rel="noopener ugc nofollow" target="_blank"> kaggle </a>数据集，我们在预测测试集的标签时达到了 93%的准确率。这是练习自然语言处理以及构建强大分类模型的一些有效技术的绝佳机会。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ko"><img src="../Images/bd00ac7f1bdfe9db9a8fc33148232a2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*4_K-1IT2ygIvYZkAIcReIg.jpeg"/></div></figure><p id="3cec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">自然语言处理是计算机科学领域，致力于处理和分析任何形式的自然人类语言(书面、口头或其他)。简单来说，计算机理解 0 和 1，而人类使用广泛的语言进行交流。NLP 旨在弥合这两个世界之间的差距，以便数据科学家和机器学习工程师可以分析大量的人类通信数据。</p><p id="1766" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在假新闻问题的背景下，NLP 允许我们将文章分解成它们的组成部分，并选择重要的特征。然后，我们构建并训练模型来识别不可靠的文档。</p><h1 id="0823" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">清理时间！</h1><p id="c323" class="pw-post-body-paragraph jn jo iq jp b jq lu js jt ju lv jw jx jy lw ka kb kc lx ke kf kg ly ki kj kk ij bi translated">对于许多数据驱动的项目来说，探索之后的首要任务是清理数据。我们正在处理来自各种来源的数千篇文章，有些文章比其他文章干净得多。正则表达式提供了一种限制我们允许包含在分析中的字符串类型的方法。例如，这行代码使用了<a class="ae kn" href="https://docs.python.org/3/howto/regex.html#" rel="noopener ugc nofollow" target="_blank"> re python 模块</a>:</p><blockquote class="lz ma mb"><p id="d66c" class="jn jo mc jp b jq jr js jt ju jv jw jx md jz ka kb me kd ke kf mf kh ki kj kk ij bi translated">clean _ article = re.sub("[^a-za-z0–9']"，' '，文章)</p></blockquote><p id="103c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">用空格替换所有非字母数字字符。^表示我们要替换的是指定集合的补集。一旦我们删除了不需要的字符，我们就可以进行标记化和矢量化了！</p><p id="fa63" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Scikit-learn 是一个令人难以置信的 python 机器学习包，它完成了大量繁重的工作。特别是，<a class="ae kn" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank">计数矢量器</a>创建一个包含所有被分析文本的完整词汇表，并将每个文档转换成一个表示每个单词总计数的矢量。这将以稀疏矩阵的形式返回向量，因为大多数文章不包含大多数单词。矢量器允许集成预处理函数，以及您的首选标记器。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mg"><img src="../Images/c5c0eedef0e70cf1f0b078dce09aae08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MYjj3l1I0dxZA_e6-w5K2g.jpeg"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">An example of vectorized articles, each row contains the occurrences of our initial 1000 feature words</figcaption></figure><p id="80d1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在新闻分析的情况下，单独考虑每个单词过于简单，因此我们的矢量化允许双词或两个单词的短语。我们将特征的数量限制为 1000，因此我们只考虑将文档分类为真实或伪造的最重要的特征。</p><h1 id="5238" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">特征工程</h1><p id="2064" class="pw-post-body-paragraph jn jo iq jp b jq lu js jt ju lv jw jx jy lw ka kb kc lx ke kf kg ly ki kj kk ij bi translated">特征工程与其说是简单的技术，不如说是一种复杂的艺术形式。它包括考虑数据集和属性域、决定最适合您的模型的功能以及最终测试您的功能以优化您的选择的过程。Scikit-learn 的矢量器提取了我们的 1000 个基本 n-gram 特征，我们开始添加元特征来完善我们的分类。我们决定计算每个文档中的平均单词长度和数值数量，这提高了我们的模型的准确性。</p><div class="kp kq kr ks gt ab cb"><figure class="mp kt mq mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><img src="../Images/0173e511afb0eb9fbb513f43e91aee82.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*oL5Bhq6Nz5WJKnmlWA5_2g.jpeg"/></div></figure><figure class="mp kt mv mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><img src="../Images/2056c9d91d71ef21ea06513e3ce7eeb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*ULCHTUQnEAL_pm4rPyGlXQ.jpeg"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk mw di mx my">Left: Aggregate features, Right: Sentiment scores</figcaption></figure></div><p id="ab02" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">情感分析代表了 NLP 的另一种分析工具，为文本主体中表达的一般情感分配数值。我们使用了两个软件包，TextBlob 和自然语言工具包的 Vader。这些都是对文本文档进行开箱即用情感分析的好工具。Vader 产生了衡量极性和中性的各种分数，而 TextBlob 提供了总体主观性以及它自己的极性衡量标准。我们原本希望，当计算误导性和真实的文章时，这些情绪的分布会非常不同，但是我们发现情况并非如此。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mz"><img src="../Images/d99c86be1cd00fdd1bdf1cdfe75db3c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LE4KRAWeI-6w0yOiL_I23Q.jpeg"/></div></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">The distribution of neutral article sentiment via Vader, where 0 is fully neutral</figcaption></figure><div class="kp kq kr ks gt ab cb"><figure class="mp kt na mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><img src="../Images/399aa9c60aa005a0e7b754a111b9a4b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*DV84CnVShhsbip6JXaJC9w.jpeg"/></div></figure><figure class="mp kt nb mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><img src="../Images/29f6e6434dea1461024a4f2af19e595b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*ym5NAkcLM-CR0AB_0HER3g.jpeg"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk nc di nd my"><strong class="bd ne">TextBlob Sentiment Scores</strong> (left: -1 polarity is negative and 1 is positive, right: 0 is very objective and 1 is very subjective)</figcaption></figure></div><p id="d678" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从上面可以看出，仅仅从情感得分上看，很少有洞察力。然而，我们决定将它们保留在我们的模型中，因为当与我们的分类器结合时，它们会增加准确性。</p><h1 id="5bc8" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated"><strong class="ak">逻辑回归</strong></h1><p id="f4dc" class="pw-post-body-paragraph jn jo iq jp b jq lu js jt ju lv jw jx jy lw ka kb kc lx ke kf kg ly ki kj kk ij bi translated">我们在这里考虑的系统是二进制的，其中只有类是真的和假的。考虑到文章的相关特征，我们需要对文章不可靠的概率进行建模。这是多项式逻辑回归的完美候选，我们的模型依赖于 logit 变换和最大似然估计来模拟与预测变量相关的不可靠性概率。</p><p id="ca93" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">换句话说，LR 直接计算后验 p(x|y ),学习将哪些标签分配给哪些特征输入。这是一个判别方法的例子，虽然这在技术上不是一个统计分类，但它给出了我们用来赋值的类成员的条件概率。SciKit-Learn 的<a class="ae kn" href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">逻辑回归</a>模型提供了一种简单的方法来实现这一点。</p><div class="kp kq kr ks gt ab cb"><figure class="mp kt nf mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><img src="../Images/71d33938f85e2a8c5ffb3965cc19e2d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*XS7hUS5hHBBlHMeRNw6xQg.jpeg"/></div></figure><figure class="mp kt ng mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><img src="../Images/8052a49b61bf8765572d6d16728edd05.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*3Eb8RJNeArOFNQPlQl09_w.jpeg"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk nh di ni my">Left: ROC curve for the logistic regression. Right: 20 of the top features for the regression.</figcaption></figure></div><h1 id="3676" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">朴素贝叶斯分类器</h1><p id="ac83" class="pw-post-body-paragraph jn jo iq jp b jq lu js jt ju lv jw jx jy lw ka kb kc lx ke kf kg ly ki kj kk ij bi translated">我们的第二种方法是使用朴素贝叶斯(NB)算法，尽管它很简单，但对于这个应用程序来说效果很好。假设特征之间独立，NB 从每个标记的文章中学习联合概率 p(x，y)的模型。然后使用贝叶斯规则计算条件概率，根据最大概率分配标签，从而进行预测。相比之下，这是一个生成分类器的例子。</p><div class="kp kq kr ks gt ab cb"><figure class="mp kt nj mr ms mt mu paragraph-image"><img src="../Images/9eeb6f643bb2e2181bc3527c4e6758b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*QkiVyQqGuoCd00L1SnUCAw.jpeg"/></figure><figure class="mp kt nk mr ms mt mu paragraph-image"><img src="../Images/80a7cae41f98dfc12cf8876a540242d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*UkK3-rJFJFJyr11p58FVkw.jpeg"/></figure></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/5bca35250c340ba97d02cb72b4b1cc71.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*NqZ0pnXvpGBzOns-BeI8pg.jpeg"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk">Bayes Classifier, using MAP decision rule</figcaption></figure><p id="9b99" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这种情况下，我们考虑一个多项式事件模型，它最准确地代表了我们的特征的分布。正如预期的那样，结果与逻辑拟合获得的结果非常接近。</p><div class="kp kq kr ks gt ab cb"><figure class="mp kt nm mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><img src="../Images/7aab6e532b1d023cf3373e76031bec44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*V1fXLaOifVkiLbO8s_k9Fw.jpeg"/></div></figure><figure class="mp kt nn mr ms mt mu paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><img src="../Images/8d4f123fca594e30a98f2ed4fe441c89.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*PEawoi1_IFxKnAIRZE44Hg.jpeg"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk no di np my">Left: ROC curve for the Multinomial Naïve Bayes. Right: 20 of the top features for the Naïve Bayes Classifier.</figcaption></figure></div><h1 id="01b7" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">最后</h1><p id="6c42" class="pw-post-body-paragraph jn jo iq jp b jq lu js jt ju lv jw jx jy lw ka kb kc lx ke kf kg ly ki kj kk ij bi translated">使用机器学习可以有效地识别假新闻形式的错误信息的存在。即使没有上下文信息，如标题或来源，正文也足以做到这一点。因此，这些策略可以很容易地应用于其他没有附加描述符的文档。虽然情感特征本身不足以用于假新闻分类，但当与其他特征结合时，它们确实提高了我们的分类器性能。未来的工作可以与其他流行的模型进行比较，如支持向量机。</p><p id="6c45" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">关于这两种方法之间关系的进一步阅读要感谢吴恩达和迈克尔·乔丹博士:</p><div class="nq nr gp gr ns nt"><a href="http://papers.nips.cc/paper/2020-on-discriminative-vs-generative-classifiers-a-comparison-of-logistic-regression-and-naive-bayes" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab fo"><div class="nv ab nw cl cj nx"><h2 class="bd ir gy z fp ny fr fs nz fu fw ip bi translated">判别型与生成型量词的比较——逻辑回归和朴素贝叶斯的比较</h2><div class="oa l"><h3 class="bd b gy z fp ny fr fs nz fu fw dk translated">神经信息处理系统电子会议录</h3></div><div class="ob l"><p class="bd b dl z fp ny fr fs nz fu fw dk translated">papers.nips.cc</p></div></div></div></a></div></div></div>    
</body>
</html>