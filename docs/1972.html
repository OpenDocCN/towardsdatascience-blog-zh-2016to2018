<html>
<head>
<title>Serving TensorFlow Models. Serverless</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">服务TensorFlow模型。无服务器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/serving-tensorflow-models-serverless-6a39614094ff?source=collection_archive---------0-----------------------#2017-11-26">https://towardsdatascience.com/serving-tensorflow-models-serverless-6a39614094ff?source=collection_archive---------0-----------------------#2017-11-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/f494a0817a6b50e4b7a5ff97bb41ab6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_7tS__vvpsnJqQXfS4jBQQ.png"/></div></div></figure><p id="1483" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">之前我写过，<a class="ae kw" rel="noopener" target="_blank" href="/how-to-deploy-machine-learning-models-with-tensorflow-part-1-make-your-model-ready-for-serving-776a14ec3198">如何用TensorFlow服务模型</a>或<a class="ae kw" href="https://becominghuman.ai/creating-restful-api-to-tensorflow-models-c5c57b692c10" rel="noopener ugc nofollow" target="_blank">用Flask </a>包装它以提供REST API。也可以用Flask直接托管模型，这在许多用例中也是非常可行的。所有这些技术都有一个共性——你需要将应用程序放在一个容器中，由你的云提供商运行它，维护一个服务器，并负责扩展。我们有Docker和Kubernetes这样的工具让我们的生活变得更轻松，但最终，你会有一个耗费金钱和时间的基础设施。</p><p id="c7d1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">几年前，AWS引入了无服务器应用程序的新概念，你不需要服务器来托管你的应用程序，你只需要编写一个代码，它会被调用来响应一些事件——T4。目前，它支持Node.js、Java、Python和C#作为编程语言。我们也有替代方案，比如<a class="ae kw" href="https://azure.microsoft.com/en-us/services/functions/" rel="noopener ugc nofollow" target="_blank">微软功能</a>和<a class="ae kw" href="https://cloud.google.com/functions/" rel="noopener ugc nofollow" target="_blank">谷歌云功能</a>，但微软只做Python的实验性支持，谷歌功能仍处于测试阶段。</p><h1 id="390d" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">无服务器，是什么？</h1><p id="ab52" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">我强烈推荐马丁·福勒的这篇关于无服务器架构的文章。我不能解释得更好了。简而言之，您完全依赖提供者服务来管理服务器逻辑和状态。当然，您编写一个后端代码，但是，与传统方法不同，您在无状态容器中运行它，并将它们的管理外包出去。</p><p id="4e08" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">拥有无服务器应用程序的想法听起来很棒——您只需创建一个后端逻辑，AWS Lambda将调用它来响应事件。例如，一个事件可以是REST API调用或在S3桶中写一些东西。然后使用提供的Web UI或AWS CLI将代码部署到AWS Lambda，就这样。不用担心容器、扩展和其他基础设施相关的东西；亚马逊负责所有这些。</p><p id="23f1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">不幸的是，它并不适用于所有用例。它非常适合<a class="ae kw" href="https://en.wikipedia.org/wiki/Microservices" rel="noopener ugc nofollow" target="_blank">微服务</a>架构和无状态API。这意味着，如果您需要在REST请求之间保存任何东西，或者拥有某些东西的全局实例(例如，已初始化并准备好进行预测的机器学习模型)，那么无服务器架构可能不是最佳选择。</p><h1 id="b3ab" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">服务TensorFlow模型无服务器？</h1><p id="7207" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">无服务器方法对TensorFlow模型的服务有意义并带来优势吗？在我看来，如果你开发机器学习产品或服务，而不想在Docker、Kubernetes和所有这些东西上浪费时间，这是有意义的。</p><p id="06bf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">另一个要考虑的方面是成本。与AWS EC2实例不同，您是根据请求的数量和代码执行的时间来收费的。此外，如果您的代码利用其他AWS服务或传输数据(例如，从S3桶)，您也将为此付费。详细信息可以在<a class="ae kw" href="https://aws.amazon.com/lambda/pricing/" rel="noopener ugc nofollow" target="_blank">这里</a>找到。我想在很多情况下，AWS Lambda会是一个更便宜的选择。</p><h1 id="b557" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">考虑</h1><p id="61c6" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">如果您决定尝试TensorFlow模型的无服务器服务，请考虑以下因素。</p><h2 id="1232" class="ma ky iq bd kz mb mc dn ld md me dp lh kj mf mg ll kn mh mi lp kr mj mk lt ml bi translated">加载模型</h2><p id="064e" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">通常，您训练模型，保存它，并在web应用程序启动时加载。在无服务器的情况下，您只提供一个处理请求的函数，因此，理论上，您需要在每次函数调用时加载模型。幸运的是，根据<a class="ae kw" href="http://docs.aws.amazon.com/lambda/latest/dg/best-practices.html" rel="noopener ugc nofollow" target="_blank">的最佳实践</a>，你可以解决这个问题，在lambda函数被调用之前全局加载模型。</p><h2 id="5eaa" class="ma ky iq bd kz mb mc dn ld md me dp lh kj mf mg ll kn mh mi lp kr mj mk lt ml bi translated">功能生命周期</h2><p id="0869" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">此外，如果您在第一次函数调用之前加载您的模型，则不能保证同一个函数实例保持活动状态并处理后续调用。这意味着AWS可以实例化您的函数，并在每次事件发生时加载模型。然而，我的测试表明，如果后续调用之间的时间差很小(几秒钟)，实例会被重用，模型会保留在内存中。如果您预计工作量很大，那么重新加载模型将不是问题。否则，每个请求可能需要几秒钟才能得到响应。</p><h2 id="7d5c" class="ma ky iq bd kz mb mc dn ld md me dp lh kj mf mg ll kn mh mi lp kr mj mk lt ml bi translated">限制</h2><p id="cba4" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">AWS Lambda在大小和超时方面有一定的限制。请仔细检查。特别是在TensorFlow的情况下，您必须应用一些技巧来部署函数、加载模型和传输数据。我在下面提供细节。</p><h1 id="1ad0" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">履行</h1><p id="e7c5" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">我创建了一个<a class="ae kw" href="https://github.com/Vetal1977/tf_aws_lambda" rel="noopener ugc nofollow" target="_blank">项目</a>,演示如何使用AWS Lambda为TensorFlow模型提供服务。请随意复制、修改和用于商业和非商业目的，但我不提供任何担保和支持。在这里，我给出了一个简短的概述，并描述了模型部署的步骤和工具。</p><h2 id="d1e2" class="ma ky iq bd kz mb mc dn ld md me dp lh kj mf mg ll kn mh mi lp kr mj mk lt ml bi translated">你需要什么</h2><p id="d296" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">我假设一个知识，什么是AWS和如何使用它的管理控制台。开始之前，请确保您已经:</p><ul class=""><li id="a4eb" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">AWS帐户</li><li id="904d" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated">EC2实例，自由层，Ubuntu 16.04</li><li id="6e6a" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated">S3桶容纳模型和数据。</li></ul><p id="9d82" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我测试了以下配置和库:</p><ul class=""><li id="8b7a" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">Python 2.7</li><li id="07f5" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated">用于机器学习模型的TensorFlow 1.4.0</li><li id="d35c" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated">Boto3 1.4.7，用于从自动气象站S3桶传输数据</li><li id="fe6f" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated"><a class="ae kw" href="https://www.getpostman.com/" rel="noopener ugc nofollow" target="_blank">邮递员</a>进行测试</li><li id="c1a8" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated"><a class="ae kw" href="https://nodejs.org/en/" rel="noopener ugc nofollow" target="_blank"> Node.js </a>框架和<a class="ae kw" href="https://www.npmjs.com/" rel="noopener ugc nofollow" target="_blank"> npm </a></li><li id="56f4" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated"><a class="ae kw" href="https://serverless.com/" rel="noopener ugc nofollow" target="_blank">用于在AWS Lambda中部署的无服务器</a>工具包。</li></ul><h2 id="a9af" class="ma ky iq bd kz mb mc dn ld md me dp lh kj mf mg ll kn mh mi lp kr mj mk lt ml bi translated">准备</h2><p id="f94f" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">为了方便起见，我使用了<a class="ae kw" href="https://www.anaconda.com/download" rel="noopener ugc nofollow" target="_blank"> Anaconda </a>，在这里我为项目创建了Python 2.7环境。</p><ul class=""><li id="5199" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">安装Python库——我为PIP安装提供了<a class="ae kw" href="https://github.com/Vetal1977/tf_aws_lambda/blob/master/requirements.txt" rel="noopener ugc nofollow" target="_blank">需求</a>文件</li><li id="782a" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated">下载并安装Node.js. npm是安装包的一部分，不需要单独安装</li><li id="b6e2" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated">安装无服务器工具包，以便在AWS Lambda中更容易地部署代码</li><li id="1f68" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated">或者，安装Postman来发布REST请求。</li></ul><h2 id="80b5" class="ma ky iq bd kz mb mc dn ld md me dp lh kj mf mg ll kn mh mi lp kr mj mk lt ml bi translated">项目结构</h2><p id="6109" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">在<a class="ae kw" href="https://github.com/Vetal1977/tf_aws_lambda" rel="noopener ugc nofollow" target="_blank">项目存储库</a>中，您可以找到以下文件:</p><ul class=""><li id="8b7f" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated"><em class="na"> gan_model.py </em>:表示gan模型。它恢复保存到Protobuf模型，创建一个会话并初始化计算图。它提供了一种预测的方法</li><li id="dc83" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated"><em class="na"> utils.py </em>:包含帮助函数。最重要的是用于从自动气象站S3存储桶传输数据的那些</li><li id="246b" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated"><em class="na"> handler.py </em>:实现一个被AWS Lambda调用的函数。此外，我们在这里导入预编译的依赖项(见下文)并创建模型实例</li><li id="7732" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated"><em class="na"> serverless.yml </em>:无服务器工具包部署配置</li><li id="2152" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated"><em class="na"> settings.py </em>:包含在项目范围内使用的常量</li><li id="055c" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated">我只在本地测试中使用它来检查数据传输和模型功能</li><li id="a36c" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated"><em class="na">requirements . txt</em>:PIP安装需求文件</li><li id="a530" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated"><em class="na"> env_var.sh </em>:为本地测试导出环境变量的助手脚本</li><li id="a13f" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated"><em class="na">卖主</em>:在这里你可以找到一份自述文件。在本地，我们将额外的项目依赖项放入这个目录中进行部署。</li></ul><h2 id="afb4" class="ma ky iq bd kz mb mc dn ld md me dp lh kj mf mg ll kn mh mi lp kr mj mk lt ml bi translated">准备项目相关性</h2><p id="a96b" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">AWS Lambda为代码执行提供了Python环境。这个环境没有提供你可能需要的所有库。在我们的例子中，我们必须提供TensorFlow、Numpy等。并将它们与我们的代码一起部署。</p><p id="911f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">问题是AWSλ<a class="ae kw" href="http://docs.aws.amazon.com/lambda/latest/dg/limits.html" rel="noopener ugc nofollow" target="_blank">限制</a> —部署包大小不能超过50 MB。但是TensorFlow的重量，也就是ZIP的重量，实在太重了。它包含了许多我们不需要的东西(TensorBoard、预编译的Python脚本等等)。所以我们必须运用一些技巧来克服这个障碍。我建议采取以下步骤:</p><ul class=""><li id="1146" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">创建并启动AWS EC2实例，自由层，Ubuntu 16.04 64位</li><li id="a8c5" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated">从终端连接到实例:</li></ul><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="78dc" class="ma ky iq ng b gy nk nl l nm nn">ssh &lt;your instance name&gt;.compute.amazonaws.com</span></pre><ul class=""><li id="310b" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">将ZIP、虚拟环境和TensorFlow安装到其中:</li></ul><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="df5b" class="ma ky iq ng b gy nk nl l nm nn">sudo apt-get update<br/>sudo apt-get install -y zip python-dev python-pip<br/>export LC_ALL=C<br/>pip install --upgrade pip<br/>sudo pip install virtualenv<br/>virtualenv tf_env<br/>source tf_env/bin/activate<br/>pip install tensorflow</span></pre><ul class=""><li id="d63e" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">摆脱无用的东西和压缩依赖，我们需要:</li></ul><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="7e21" class="ma ky iq ng b gy nk nl l nm nn">touch ~/tf_env/lib/python2.7/site-packages/google/__init__.py</span><span id="1620" class="ma ky iq ng b gy no nl l nm nn">cd ~/tf_env/lib/python2.7/site-packages</span><span id="ea43" class="ma ky iq ng b gy no nl l nm nn">zip -r ~/tf_env.zip . --exclude \*.pyc *.DS_Store /external/* /tensorflow/contrib/* /tensorflow/include/unsupported/* /tensorflow/examples/* /tensorboard/* /tensorflow_tensorboard-0.4.0rc3.dist-info/* /pip/* /pip-9.0.1.dist-info/*</span></pre><ul class=""><li id="407c" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">将依赖项复制到本地计算机:</li></ul><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="8179" class="ma ky iq ng b gy nk nl l nm nn">scp ubuntu@&lt;your instance name&gt;.compute.amazonaws.com:~/tf_env.zip &lt;somewhere at your local machine&gt;/tf_env.zip</span></pre><ul class=""><li id="c21c" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">终止AWS EC2实例。</li></ul><p id="880c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们有了<em class="na"> tf_env.zip </em>和部署到AWS Lambda的依赖项。</p><h2 id="39c4" class="ma ky iq bd kz mb mc dn ld md me dp lh kj mf mg ll kn mh mi lp kr mj mk lt ml bi translated">张量流模型准备</h2><p id="df94" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">我们成功地开发并训练了一个模型，最终将其导出到Protobuf中，现在我们希望使用它进行预测。问题是——我们是将其作为部署包的一部分，还是从外部来源加载？</p><p id="5b5e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">将模型和源代码一起部署的好处是——您将所有的东西都放在一个地方。但是有两个缺点——模型可能太大，无法通过AWS Lambda限制，当您更改模型时，您必须重新部署所有内容。</p><p id="0c5e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我强烈建议在外部保存您的模型，并从那个地方加载它。我在这个项目中做了什么:</p><ul class=""><li id="937d" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">当我在Udacity 学习的时候，我用我的样本模型进行了面部生成，我用生成式对抗网络<a class="ae kw" rel="noopener" target="_blank" href="/my-experience-with-udacity-deep-learning-foundations-nanodegree-a42a010f7b58">进行了训练</a></li><li id="0a36" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated">我将模型训练并导出到Protobuf中(我在这里描述了流程<a class="ae kw" rel="noopener" target="_blank" href="/how-to-deploy-machine-learning-models-with-tensorflow-part-1-make-your-model-ready-for-serving-776a14ec3198"/>)并将模型<em class="na">压缩到protobuf文件</em>和<em class="na">变量</em>目录中</li><li id="eafe" class="mm mn iq ka b kb mv kf mw kj mx kn my kr mz kv mr ms mt mu bi translated">我创建了AWS S3桶，并上传了我的模型ZIP文件。重要说明—我的S3桶和Lambda函数在同一个AWS区域。这允许更快的传输和更容易的权限设置。</li></ul><p id="a196" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然后，我可以将我的模型从S3桶加载到我的Lambda函数中。</p><h2 id="e2c5" class="ma ky iq bd kz mb mc dn ld md me dp lh kj mf mg ll kn mh mi lp kr mj mk lt ml bi translated">准备测试图像</h2><p id="52b1" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">Lambda函数对<a class="ae kw" href="http://ufldl.stanford.edu/housenumbers/" rel="noopener ugc nofollow" target="_blank">街景门牌号</a>进行预测。我决定把我的测试图像也上传到S3桶中，并从那里下载一个特定的图像进行预测。这意味着该函数获取桶名和图像名，下载图像并对其运行预测。</p><h2 id="f450" class="ma ky iq bd kz mb mc dn ld md me dp lh kj mf mg ll kn mh mi lp kr mj mk lt ml bi translated">AWS Lambda函数解释</h2><p id="aa2b" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">主要的挑战是提供被AWS Lambda调用的函数和初始化步骤。让我们来看看<em class="na"> handler.py </em>:</p><ul class=""><li id="3145" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">首先，我们导入标准库:</li></ul><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="277a" class="ma ky iq ng b gy nk nl l nm nn">import os<br/>import sys<br/>import json</span></pre><ul class=""><li id="c54a" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">接下来，我们让Python环境知道，在哪里可以找到额外的项目依赖关系:</li></ul><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="3fac" class="ma ky iq ng b gy nk nl l nm nn">current_location = os.path.dirname(os.path.realpath(__file__))<br/>sys.path.append(os.path.join(current_location, 'vendored'))</span></pre><ul class=""><li id="da30" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">只有现在我们才能导入加载我们的模型。我们从S3桶加载保存的模型——详情请查看<em class="na"> utils.py </em>,非常简单。</li></ul><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="63c1" class="ma ky iq ng b gy nk nl l nm nn">from gan_model import GANModel<br/>import utils</span><span id="2561" class="ma ky iq ng b gy no nl l nm nn">model_dir = utils.create_model_dir()<br/>utils.download_model_from_bucket(model_dir)<br/>gan_model = GANModel(model_dir)</span></pre><ul class=""><li id="ad3c" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">我们提供一个带有特殊签名的Lambda函数。<em class="na">事件</em>包含AWS Lambda提供的数据，我们希望Python <em class="na"> dict </em>在我们的例子中。<em class="na">上下文</em>提供运行时信息，但是我们不在函数中使用它。</li></ul><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="26ce" class="ma ky iq ng b gy nk nl l nm nn">def predict(event, context):</span></pre><ul class=""><li id="5cc4" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">下面是一个对我们函数的REST请求的例子。<em class="na"> {LambdaURL} </em>为无服务器安装返回的URL，<em class="na"> {stage} </em>在部署设置文件<em class="na"> serverless.yml </em>中设置。</li></ul><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="b517" class="ma ky iq ng b gy nk nl l nm nn">{LambdaURL}/{stage}/predict?bucket=&lt;your bucket&gt;&amp;key=&lt;image file in bucket&gt;</span></pre><ul class=""><li id="e175" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">该函数从S3桶下载图像并对其进行预测:</li></ul><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="3b24" class="ma ky iq ng b gy nk nl l nm nn">......</span><span id="3fcf" class="ma ky iq ng b gy no nl l nm nn">image = utils.download_image_from_bucket(bucket_name, key)<br/>results = gan_model.predict(image)</span><span id="b547" class="ma ky iq ng b gy no nl l nm nn">......</span></pre><ul class=""><li id="6ad0" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">最后一件事是响应准备——我们提供3个最可能的数字，它们的概率为JSON:</li></ul><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="de05" class="ma ky iq ng b gy nk nl l nm nn">......</span><span id="e9fb" class="ma ky iq ng b gy no nl l nm nn">def lambda_gateway_response(code, body):<br/>    return {"statusCode": code,<br/>            "headers": {"Content-Type": "application/json"},<br/>            "body": json.dumps(body)}</span><span id="4f1b" class="ma ky iq ng b gy no nl l nm nn">......</span><span id="98de" class="ma ky iq ng b gy no nl l nm nn">results_json = [{'digit': str(res[0]), 'probability': str(res[1])} for res in results]</span><span id="1943" class="ma ky iq ng b gy no nl l nm nn">......</span><span id="e5a3" class="ma ky iq ng b gy no nl l nm nn">return lambda_gateway_response(<br/>            200, <br/>            {'prediction_result': results_json})</span></pre><p id="7bd9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">就是这样。函数本身的创建要简单得多，因为所有的准备步骤都是:-)</p><h2 id="3154" class="ma ky iq bd kz mb mc dn ld md me dp lh kj mf mg ll kn mh mi lp kr mj mk lt ml bi translated">部署</h2><p id="52c5" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">我们可以在AWS Lambda中使用提供的Web UI手动部署我们的功能，但是我强烈建议使用无服务器框架。它独立于云提供商，我鼓励您查看官方文档<a class="ae kw" href="https://serverless.com/framework/docs/" rel="noopener ugc nofollow" target="_blank">以了解详细信息。</a></p><p id="cbdd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">首先，安装无服务器工具包:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="0668" class="ma ky iq ng b gy nk nl l nm nn">sudo npm install serverless -g<br/>serverless --version</span></pre><p id="9005" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您应该会看到工具包的安装版本。配置AWS凭证—我使用了AWS访问密钥。请查看<a class="ae kw" href="http://docs.aws.amazon.com/general/latest/gr/aws-security-credentials.html" rel="noopener ugc nofollow" target="_blank">官方AWS文档</a>中关于管理凭证和访问密钥的内容。生成AWS访问密钥后，保存它们并导出到shell环境中:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="afdc" class="ma ky iq ng b gy nk nl l nm nn">export AWS_ACCESS_KEY_ID=&lt;your-key-here&gt;<br/>export AWS_SECRET_ACCESS_KEY=&lt;your-secret-key-here&gt;</span></pre><p id="0557" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，我们在<em class="na"> serverless.yml. </em>中定义部署配置。</p><ul class=""><li id="251b" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">AWS作为提供者，Python 2.7作为执行环境:</li></ul><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="5a7f" class="ma ky iq ng b gy nk nl l nm nn">provider:<br/>  name: aws<br/>  runtime: python2.7</span></pre><ul class=""><li id="1538" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">环境变量:</li></ul><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="655b" class="ma ky iq ng b gy nk nl l nm nn">environment:<br/>  TF_AWS_MODEL_ZIP_FILE_NAME: gan_model.zip<br/>  TF_AWS_MODEL_PROTOBUF_FILE_NAME: saved_model.pb<br/>  TF_AWS_S3_MODEL_BUCKET_NAME: &lt;bucket name that holds the model&gt;</span></pre><ul class=""><li id="f24e" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">Lambda函数执行角色的AWS IAM(身份和访问管理)策略。它必须被添加以允许函数访问S3桶，在那里我们保存我们的模型和测试图像。以下是我的设置:</li></ul><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="9a94" class="ma ky iq ng b gy nk nl l nm nn">iamRoleStatements:<br/>  - Effect: “Allow”<br/>    Action:<br/>      - "s3:GetObject"<br/>    Resource:<br/>      - "arn:aws:s3:::vb-tf-aws-lambda-model"<br/>      - "arn:aws:s3:::vb-tf-aws-lambda-model/*"<br/>      - "arn:aws:s3:::vb-tf-aws-lambda-images"<br/>      - "arn:aws:s3:::vb-tf-aws-lambda-images/*"</span></pre><ul class=""><li id="95a5" class="mm mn iq ka b kb kc kf kg kj mo kn mp kr mq kv mr ms mt mu bi translated">要响应的处理函数和事件—在我们的例子中是HTTP GET请求。当AWS Lambda收到请求时，它调用我们的函数来获得响应:</li></ul><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="b70b" class="ma ky iq ng b gy nk nl l nm nn">functions:<br/>  predict:<br/>    handler: handler.predict<br/>    events:<br/>      - http:<br/>          path: /predict<br/>          method: get</span></pre><p id="d994" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在只需从终端执行部署命令…</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="277b" class="ma ky iq ng b gy nk nl l nm nn">cd &lt;project root&gt;<br/>serverless deploy</span></pre><p id="5e1f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">…然后等到一切都部署完毕。在终端中，您会看到一个部署日志和关于已部署服务的信息。具体来说，您可以看到端点和函数:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="f0ab" class="ma ky iq ng b gy nk nl l nm nn">endpoints:<br/>  GET — <a class="ae kw" href="https://9cspjk5fg6.execute-api.us-west-1.amazonaws.com/dev/predict" rel="noopener ugc nofollow" target="_blank">https://&lt;address&gt;.amazonaws.com/dev/predict</a><br/>functions:<br/>  predict: tensorflow-lambda-gan-dev-predict</span></pre><p id="11b2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果要从AWS中删除该功能，请执行以下操作:</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="5ec8" class="ma ky iq ng b gy nk nl l nm nn">serverless remove</span></pre><h2 id="d41b" class="ma ky iq bd kz mb mc dn ld md me dp lh kj mf mg ll kn mh mi lp kr mj mk lt ml bi translated">试验</h2><p id="cc7e" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">对于测试，我使用Postman，但是如果你愿意，你也可以使用你的浏览器。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi np"><img src="../Images/b0b2dd3198ff8b1dfa31c57e3b4ca514.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*80lbuttSl2IijjlnywIX2g.png"/></div></div></figure><p id="0f23" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们得到了与这里的<a class="ae kw" rel="noopener" target="_blank" href="/how-to-deploy-machine-learning-models-with-tensorflow-part-3-into-the-cloud-7115ff774bb6"/>和这里的<a class="ae kw" href="https://becominghuman.ai/creating-restful-api-to-tensorflow-models-c5c57b692c10" rel="noopener ugc nofollow" target="_blank"/>相同的结果，但是没有创建Docker容器，使用Kubernetes进行缩放，最终使用Flask进行服务。</p><h1 id="a094" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">结论</h1><p id="84ce" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">一开始，我相当怀疑预测服务的无服务器部署是否可行和有意义。我首先关心的是Lambda函数实例的重用——我们不希望每次收到请求时都重新加载模型。第二个问题是——我们如何克服Lambda限制，并使用TensorFlow这样复杂而庞大的库。</p><p id="93f3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在做了一些研究并阅读了一篇<a class="ae kw" href="https://medium.com/tooso/serving-tensorflow-predictions-with-python-and-aws-lambda-facb4ab87ddd" rel="noopener">非常有帮助的文章</a>之后，我能够解决第二个问题。我的测试表明，在恒定负载下，函数被重用，模型很少被重载。</p><p id="5cb8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我的印象是——AWS Lambda加快了开发周期，因为我们不关心容器化、缩放和应用服务器。一切都由云提供商管理。你可以快速上传一个新版本的模型，如果你使用S3桶来存储它。我没有展示这一点，但是对S3桶中模型的更新做出反应是可能的——这是一个可以由Lambda函数处理的额外事件。</p><p id="318b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">另一方面，当AWS删除一个函数实例时，这是不可预测的。如果您的服务没有被广泛使用，那么每个请求需要几秒钟而不是几毫秒，这是事实。如果你能忍受，那很好，否则，你应该建立一个预热机制来模拟负载。</p><p id="da6c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">另一个方面——目前，将TensorFlow依赖项引入AWS Lambda确实很棘手。我个人不喜欢这样的黑客。</p><p id="d0f4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于TensorFlow对于无服务器架构的不可预测性和未就绪性，我仍然倾向于在生产环境中使用全服务器方法。</p><h1 id="e774" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">更新2018年10月26日</h1><p id="7c86" class="pw-post-body-paragraph jy jz iq ka b kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr lz kt ku kv ij bi translated">最初，我使用TensorFlow 1.4.0作为我的预测函数的依赖项。从那时起，谷歌团队对TensorFlow框架进行了重大更新，我们必须稍微改变项目依赖性，为绕过AWS Lambda限制做准备。在<em class="na"> virtualenv </em>中安装TensorFlow后，我们执行以下命令</p><pre class="nb nc nd ne gt nf ng nh ni aw nj bi"><span id="22be" class="ma ky iq ng b gy nk nl l nm nn">touch ~/tf_env/lib/python2.7/site-packages/google/__init__.py</span><span id="22e7" class="ma ky iq ng b gy no nl l nm nn">cd ~/tf_env/lib/python2.7/site-packages</span><span id="21b9" class="ma ky iq ng b gy no nl l nm nn">find . -name "*.so" | xargs strip</span><span id="4f7c" class="ma ky iq ng b gy no nl l nm nn">zip -r ~/tf_env_l.zip . --exclude \*.pyc *.DS_Store /external/* /tensorflow/contrib/* /tensorflow/include/unsupported/* /tensorflow/examples/* /tensorboard*/* /pip*/* /setuptools*/* /wheel*/* easy_install*</span></pre><p id="dc15" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">创建具有所需依赖项的ZIP文件。最值得注意的动作是对所有目标文件执行<em class="na">剥离</em>。这允许显著减小它们的尺寸。此外，我稍微清理了一下<em class="na"> zip </em>命令的参数。我用TensorFlow 1.11.0测试了一下，效果和预期一样。</p><figure class="nb nc nd ne gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nq"><img src="../Images/622f291b4e194230c443412d9c81d83f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hGCLkyvYr8Rpmg2VlmyBNQ.jpeg"/></div></div><figcaption class="nr ns gj gh gi nt nu bd b be z dk">Source: Google</figcaption></figure></div></div>    
</body>
</html>