<html>
<head>
<title>Image Tagging with Keras in TensorFlow 1.3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow 1.3中使用Keras的图像标记</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/image-tagging-with-keras-in-tensorflow-1-2-bc43c1058019?source=collection_archive---------5-----------------------#2017-08-24">https://towardsdatascience.com/image-tagging-with-keras-in-tensorflow-1-2-bc43c1058019?source=collection_archive---------5-----------------------#2017-08-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="052b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们已经了解了如何通过TensorFlow 使用<a class="ae kl" href="https://medium.com/towards-data-science/from-scikit-learn-to-tensorflow-part-2-66c56985d6c7" rel="noopener"> Scikit-learn，并大致讨论了TensorFlow的高级API。TensorFlow直接支持的另一个流行的高级API是Keras。</a></p><p id="cb4e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://github.com/tensorflow/tensorflow/releases" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a> 1.3的发布让美国用户可以直接在TensorFlow中使用Keras。<a class="ae kl" href="https://keras.io" rel="noopener ugc nofollow" target="_blank"> Keras </a>是一个高级API规范，由<a class="ae kl" href="https://twitter.com/fchollet" rel="noopener ugc nofollow" target="_blank">Fran ois Chollet</a>积极构建，主要是为了降低开发机器学习模型的门槛，并提供一个单一的API来访问许多底层的机器学习工具包。Keras的流行意味着许多模型的框架(代码+预处理)都是现成的，并且由社区很好地维护和改进。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi km"><img src="../Images/9bfd8ced38d255f3696f242f71796fe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*U-YCuqBJ21EnW5cWAOmRIQ.png"/></div><figcaption class="ku kv gj gh gi kw kx bd b be z dk">Keras — supported ML toolkits [TensorFlow, Theano, MXNet and Cognitive Toolkit]</figcaption></figure><h1 id="6374" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">为什么对TensorFlow开发者很重要？</h1><p id="5f6d" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">就提交、开发者和更新的数量而言，TensorFlow是迄今为止开发最活跃的ML工具包。然而，随着<em class="mb">的积极发展，API也发生了变化。另一方面，Keras为底层的ML工具包提供了更高层次的抽象。因此，原型快速ML框架的可行性是不可知的变化酝酿之下。</em></p><p id="5153" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">将Keras放在TensorFlow中还可以避免安装其他库。如果您以前使用过Keras，在您的机器上安装Keras也意味着安装Theano(直到最近才支持两个框架)。当只使用TensorFlow和Keras时，这是一个不必要的Theano安装，当您想要部署使用Keras开发的ML模型时，这也是一个需要关注的原因。</p><p id="d267" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在过去的两篇博客中，我们一直在讨论如何从Scikit-learn迁移到TensorFlow，以及如何将TensorFlow和Scikit-learn库结合起来开发我们的ML模型。将Keras集成到TensorFlow中带来了一个类似的特性，只是除了TensorFlow之外，不需要安装其他库。</p><h1 id="9e20" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">为什么对Keras开发者很重要？</h1><p id="3a57" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">我们不得不承认，TensorFlow正在成为集成新的ML函数和库的领导者。因此，在训练大型深度网络时，Keras开发人员将极大地受益于TensorFlow的分布式训练。</p><p id="5497" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Keras开发者可以使用的另一个有趣的功能是TensorFlow的<a class="ae kl" href="https://www.tensorflow.org/get_started/summaries_and_tensorboard" rel="noopener ugc nofollow" target="_blank"> TensorBoard </a>。TensorBoard不仅提供了培训和评估的可视化，也是<a class="ae kl" href="https://www.tensorflow.org/get_started/embedding_viz" rel="noopener ugc nofollow" target="_blank">可视化嵌入</a>的简洁实现。</p><p id="50b5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Keras开发人员还可以访问<a class="ae kl" href="https://www.tensorflow.org/deploy/tfserve" rel="noopener ugc nofollow" target="_blank"> TensorFlow Serving </a>和<a class="ae kl" href="https://cloud.google.com/ml-engine/" rel="noopener ugc nofollow" target="_blank"> Google Cloud ML </a>，它们允许部署ML模型来对生产环境中的新数据进行推理。</p><h1 id="beb8" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">用5行深CNN标记图像</h1><p id="e454" class="pw-post-body-paragraph jn jo iq jp b jq lw js jt ju lx jw jx jy ly ka kb kc lz ke kf kg ma ki kj kk ij bi translated">深度卷积神经网络已经证明<a class="ae kl" href="http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/" rel="noopener ugc nofollow" target="_blank">在图像分类方面优于人类</a>。虽然训练这种深度模型所需的GPU和CPU资源是昂贵的，但推理在计算上并不昂贵。因此，我们看看如何利用不同的艺术级图像分类模型，在少于<em class="mb">五行</em>代码中对图像进行推理。</p><p id="7aa7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">并且，为了使这样的推论成为可能，我们使用Keras来使这成为可能。以下几行显示了我们如何在TensorFlow 1.2中使用Keras实现这一点:</p><pre class="kn ko kp kq gt mc md me mf aw mg bi"><span id="71d3" class="mh kz iq md b gy mi mj l mk ml">img = image.load_img('niagara.jpeg', target_size=(224, 224))<br/>x = image.img_to_array(img)<br/>x = np.expand_dims(x, axis=0)<br/>x = preprocess_input(x)<br/><br/>preds = model.predict(x)</span></pre><p id="7759" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如所承诺的，我们处理图像并在5行代码中推断其内容(<em class="mb">忽略导入，咄！</em>)。在上面的代码中我们还没有定义的一件事是<em class="mb">模型</em>。有两个非常好的深度CNN模型，其性能优于人类。我们对用于执行分类的<a class="ae kl" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">残差网络</a>和<a class="ae kl" href="https://arxiv.org/abs/1512.00567" rel="noopener ugc nofollow" target="_blank"> Inception v3 </a> CNN模型特别感兴趣。这两个模型都是深度网络，需要数周时间在ImageNet数据上进行训练。然而，我们将简单地<em class="mb">站在巨人</em>的肩膀上，下载这些模型并对我们的图像进行推理。我们如下初始化剩余网络(50层深的CNN ):</p><pre class="kn ko kp kq gt mc md me mf aw mg bi"><span id="a17f" class="mh kz iq md b gy mi mj l mk ml">model = ResNet50(weights='imagenet')</span></pre><p id="4315" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以类似地使用一个Inception v3模型来为我们的预测加载权重。我们如下初始化Inception v3模型:</p><pre class="kn ko kp kq gt mc md me mf aw mg bi"><span id="4ae3" class="mh kz iq md b gy mi mj l mk ml">model = InceptionV3(weights='imagenet')</span></pre><p id="ed5a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们对之前加载的图像进行推断，以获得我们预测的类别和概率，如下所示:</p><pre class="kn ko kp kq gt mc md me mf aw mg bi"><span id="5b9a" class="mh kz iq md b gy mi mj l mk ml">preds = model.predict(x)</span></pre><p id="fba7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以如下解码来自模型的图像预测:</p><pre class="kn ko kp kq gt mc md me mf aw mg bi"><span id="2511" class="mh kz iq md b gy mi mj l mk ml">print('Predicted:', decode_predictions(preds, top=5)[0])</span></pre><p id="63e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从图像加载到执行预测的端到端框架的笔记本可以在我的GitHub存储库中找到。《盗梦空间》v3 T1和《T2》残网T3笔记本上市了。在我的GitHub上的<a class="ae kl" href="https://github.com/karthikmswamy/Keras_In_TensorFlow/" rel="noopener ugc nofollow" target="_blank"> Keras资源库</a>中有一些更有趣的脚本，供那些想使用Keras探索其他TensorFlow应用程序的人使用。</p><p id="23e8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在TensorFlow最近的更新中，使用最先进的深度CNN标记图像变得非常容易。Keras作为高级API，肯定降低了进入ML的门槛。查看我的<a class="ae kl" href="https://github.com/karthikmswamy/Keras_In_TensorFlow/" rel="noopener ugc nofollow" target="_blank"> Keras </a>，了解更多使用Keras和TensorFlow构建的应用程序。</p><p id="772a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我知道你想要建造什么。请在下一篇博文中留下您希望我讨论的内容！干杯！</p></div></div>    
</body>
</html>