<html>
<head>
<title>Collaborative Embeddings for Lipstick Recommendations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">口红推荐的协作嵌入</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/collaborative-embeddings-for-lipstick-recommendations-98eccfa816bd?source=collection_archive---------8-----------------------#2018-10-10">https://towardsdatascience.com/collaborative-embeddings-for-lipstick-recommendations-98eccfa816bd?source=collection_archive---------8-----------------------#2018-10-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c8d3" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Sephora SEA 机器学习案例研究</h2></div><p id="6f4f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于一家电子商务公司来说，花时间和精力去了解客户行为，对客户和公司本身来说都是一种双赢的策略。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi lb"><img src="../Images/f99371675115d1e2246597a5e14f6273.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E4lVdCqmwkLCxCFHPzoCOg.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Embeddings: turning beauty products into vectors</figcaption></figure><p id="7a1c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，执行良好的产品策划是销量<strong class="kh ir">和多样性</strong>的<strong class="kh ir">关键驱动力</strong>，也是客户参与品牌的关键驱动力。它还能让购物者花更少的时间浏览他们真正想要的东西。</p><p id="a8d4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我的公司 Sephora SEA，我们利用客户生成的数据来更好地了解我们的业务，并为我们的客户创造愉快的购物体验。</p><p id="bbae" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这个故事中，</p><ul class=""><li id="e2b0" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated">我演示了如何将来自自然语言处理 (NLP)的<strong class="kh ir">研究思想，更准确地说是来自<em class="lr">手套</em>论文【1】的研究思想，移植到<strong class="kh ir">项目到项目</strong> <strong class="kh ir">产品推荐系统中。</strong></strong></li><li id="d455" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">我展示了如何利用丝芙兰电子平台上的<strong class="kh ir">顾客浏览数据</strong>来<em class="lr">了解美容产品的</em> <strong class="kh ir">密集表示</strong>，也就是<em class="lr">又名。嵌入。</em></li><li id="d871" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">我用嵌入的<strong class="kh ir">可视化</strong>和<strong class="kh ir">基础代数</strong>研究了<em class="lr">通过算法</em>学到了什么。</li><li id="b8ac" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">我介绍了推荐系统离线评估的度量标准，并给出了不同方法的基准。</li></ul></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="4718" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在行业中已经有相当多的嵌入式应用记录[4][5]。本案例研究旨在补充那些特别关注<strong class="kh ir">产品发现</strong>和<strong class="kh ir">嵌入代数</strong>的案例。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><p id="8391" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这篇文章的布局是</p><ul class=""><li id="55f7" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated"><strong class="kh ir"> 0 |单词嵌入入门</strong></li><li id="51b0" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated"><strong class="kh ir"> 1 |构建协同推荐系统</strong></li><li id="b771" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated"><strong class="kh ir"> 2 |离线基准</strong></li><li id="f3e3" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated"><strong class="kh ir"> 3 |产品发现的嵌入代数</strong></li><li id="5f8c" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated"><strong class="kh ir"> 4 |视角</strong></li></ul></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h1 id="33da" class="mn mo iq bd mp mq mr ms mt mu mv mw mx jw my jx mz jz na ka nb kc nc kd nd ne bi translated">0 |单词嵌入入门</h1><p id="2140" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">NLP 中的一个主要挑战在于文本数据的数学表示。</p><p id="764c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个产生有趣结果的简单方法在于单词的<strong class="kh ir">一键编码</strong>:对于给定的词汇集<strong class="kh ir"><em class="lr">【V</em></strong><strong class="kh ir"><em class="lr">| V |</em></strong>，每个单词都用它在<strong class="kh ir"> <em class="lr"> V </em> </strong> <em class="lr">中的位置来表示。</em></p><p id="4e1b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">反过来，一个文档<strong class="kh ir"><em class="lr">【d】</em></strong>由它的字<strong class="kh ir"> <em class="lr"> W </em> </strong>中的<strong class="kh ir"> <em class="lr"> V </em> </strong>中的位置来表示。结果是一个长度为“在<strong class="kh ir"> <em class="lr"> V </em> </strong>中的字数”的<em class="lr">稀疏</em>向量，除了在<strong class="kh ir"> <em class="lr"> W </em> </strong>的位置之外，所有系数都为零。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi nk"><img src="../Images/f85a08444aad740bdb3029860c0cca95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1yWFCBLhybVJlpqOW2qc-w.jpeg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Example of one-hot encoding of a sentence. Semantic and syntactic similarities are omitted.</figcaption></figure><p id="d819" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一键编码的问题是，它认为单词是完全离散的实体，完全由其拼写定义:<strong class="kh ir">它忽略了单词的语义和句法相似性</strong>。</p><p id="1a29" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，在这个模型中，“狗”与“拉布拉多”的不同之处就像它与任何其他单词的不同之处一样，比如“滑板”。</p><p id="a5d1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">提出<em class="lr">密集</em>(≠稀疏)，低维(∼30 到 300)单词表示，具有语义和句法规则，在 2001 年首次成为感兴趣的领域[2]，并在 2013 年开始广泛流行[3]。</p><p id="ac6d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些表示被称为<strong class="kh ir"> <em class="lr">嵌入</em> </strong>。</p><p id="c3a7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个想法在于使用<strong class="kh ir">巨大的文本语料库</strong>来学习那些嵌入，目的是在相同上下文中经常出现的<strong class="kh ir">单词应该具有相似的向量</strong>。</p><p id="bcbd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">特别是，GloVe 算法[1]因其简单性和有效性而脱颖而出:它建议将问题视为矩阵分解问题。</p><p id="3676" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要分解的矩阵是单词到单词共现矩阵:a <strong class="kh ir"> <em class="lr"> |V|×|V| </em> </strong>矩阵，其中每个系数是两个单词在同一<strong class="kh ir">上下文</strong>中出现的次数。</p><blockquote class="nl"><p id="007a" class="nm nn iq bd no np nq nr ns nt nu la dk translated">"词汇和美容产品都是可以放入语境中的独立实体."</p></blockquote><p id="1c8e" class="pw-post-body-paragraph kf kg iq kh b ki nv jr kk kl nw ju kn ko nx kq kr ks ny ku kv kw nz ky kz la ij bi translated">注意:上下文的定义取决于用户。例如，可以使用 3 个单词的滑动窗口。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi oa"><img src="../Images/03b861c5ee67784484ba326928dd621b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9esFBZHBwkbJDeeF4sIEmA.jpeg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Context generation with 3-word-long sliding window</figcaption></figure><p id="8a29" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">词语和美容产品都是可以放入语境中的独立实体。</p><p id="6ef6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于电子商务中的美容产品，上下文可以由以下内容组成:</p><ul class=""><li id="3514" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated">结账篮</li><li id="c8ac" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">意愿列表共现</li><li id="8e18" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">产品浏览会话上的滑动窗口</li><li id="3ef5" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">和许多其他信号</li></ul><p id="0be4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">听起来手套的<strong class="kh ir">原理可以用来衍生产品的密集表示</strong>。让我们看看如何做到这一点。</p><h1 id="3ad1" class="mn mo iq bd mp mq ob ms mt mu oc mw mx jw od jx mz jz oe ka nb kc of kd nd ne bi translated">1 |建立协同推荐系统</h1><p id="8f1c" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">在本案例研究中，我们的输入信号将完全来自客户浏览会话，其中产品上下文由滑动窗口生成。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi og"><img src="../Images/8408a0c6001ce9f43a04fb1e2cb6c528.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cz9desU5V-CIveGeEuOL-A.jpeg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">How contexts can be derived from browsing sessions</figcaption></figure><p id="0788" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从这个上下文生成方案中，我们可以导出一个产品共现矩阵<strong class="kh ir"> <em class="lr"> X </em> </strong>。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi oh"><img src="../Images/0267ab64f59f051163c7230d2aefd7eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WGetVhZH1ia1QAHRnUbCCw.jpeg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">The co-occurrence matrix</figcaption></figure><p id="4c8f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该矩阵是输入数据的汇总，也是我们将使用的唯一信号。</p><p id="a25f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">直觉上，</p><ul class=""><li id="56e9" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated"><strong class="kh ir">强相关产品</strong>应具有<strong class="kh ir">高共现</strong>编号</li><li id="f37e" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated"><strong class="kh ir">强相关产品</strong>出现在<strong class="kh ir">相似语境</strong>中。它们与产品目录中的产品的共现特征应该相似。</li><li id="435c" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated"><strong class="kh ir">非常受欢迎的产品</strong>可能会与目录中的许多产品出现强烈的同现号。但这并不意味着它们与所有产品都相关。这相当于 NLP 中的<a class="ae oi" href="https://en.wikipedia.org/wiki/Stop_words" rel="noopener ugc nofollow" target="_blank"> <em class="lr">停用词</em> </a> <em class="lr"> </em>。</li></ul><h2 id="f7e3" class="oj mo iq bd mp ok ol dn mt om on dp mx ko oo op mz ks oq or nb kw os ot nd ou bi translated">模型</h2><p id="fcfa" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated"><em class="lr"> GloVe </em>建议的是将<strong class="kh ir"> <em class="lr"> log(X) </em> </strong>分解为<strong class="kh ir">具有加性偏差的嵌入矩阵的点积</strong>。关于这个模型的细节和原因的更多信息，我强烈建议你参考最初的<a class="ae oi" href="https://nlp.stanford.edu/pubs/glove.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>。</p><p id="7988" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在本案例研究中，我们选择考虑一个与要学习的参数密切相关的分解模型:</p><ul class=""><li id="b91c" class="ls lt iq kh b ki kj kl km ko lu ks lv kw lw la lx ly lz ma bi translated">嵌入矩阵<strong class="kh ir"> <em class="lr"> E </em> </strong>，大小为|<strong class="kh ir"><em class="lr">V</em></strong>|×<strong class="kh ir"><em class="lr">D</em></strong>。<strong class="kh ir"> <em class="lr"> D </em> </strong>是嵌入物的尺寸。注意，<strong class="kh ir">t39】dt41】≪|<strong class="kh ir">t43】vt45】|。</strong></strong></li><li id="caab" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">偏置向量<strong class="kh ir"> <em class="lr"> b </em> </strong>，大小为| <strong class="kh ir"> <em class="lr"> V </em> </strong> |。我们稍后会看到，这是一种产品<em class="lr">流行偏见</em>，它有助于应对过度流行产品的影响。</li></ul><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ov"><img src="../Images/1292468e47bc46b39a836eda5471227b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kUYFAAaY0-EWdBID0q0GcA.jpeg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">The factorisation model</figcaption></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ow"><img src="../Images/876061c0ffc2c65565fbb5ba3acc4e1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GXTHKnfW3gBuAtS8Lf5YEA.jpeg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Representation as a (very) shallow neural network</figcaption></figure><p id="a9ad" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">相应的目标函数(损失最小化)为:</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ox"><img src="../Images/52c7eca52c6080c851491f0e17bdd544.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jUWjaIDzkAhfJg-nu3d30Q.jpeg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Objective function</figcaption></figure><p id="1fed" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">参数<strong class="kh ir"><em class="lr">【E】</em></strong>和<strong class="kh ir"> <em class="lr"> b </em> </strong>可以通过例如<a class="ae oi" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent" rel="noopener ugc nofollow" target="_blank">小批量随机梯度下降</a>来学习:该算法将迭代地查看小批量的产品对，并相应地利用同现计数来优化它们相应的嵌入和偏差。</p><p id="eb96" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦嵌入被学习，向量相似性的一个<strong class="kh ir">普通度量</strong>是<em class="lr">余弦相似性</em>。</p><p id="a243" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，它可以用于导出完全协作的项目到项目推荐系统。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ox"><img src="../Images/29c918341970b57d491aec39d06753a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PmHaMKrPit_UPp1zyFfzFw.jpeg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Cosine similarity for embeddings</figcaption></figure><h2 id="c852" class="oj mo iq bd mp ok ol dn mt om on dp mx ko oo op mz ks oq or nb kw os ot nd ou bi translated">可视化</h2><p id="6625" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">像<a class="ae oi" href="https://projector.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> Tensorboard 投影仪</a>这样的工具可以帮助可视化 2D 或 3D 投影中的嵌入。</p><blockquote class="oy oz pa"><p id="c9f9" class="kf kg lr kh b ki kj jr kk kl km ju kn pb kp kq kr pc kt ku kv pd kx ky kz la ij bi translated">这里有一些关于你如何自己使用它的提示</p></blockquote><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi pe"><img src="../Images/baf6c583563cc6cadc22046d1e8e8b42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*vMxTTUudbCUL7obTiiLq6g.gif"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Tensorboard projector for 3D embeddings visualisation. Each point is a product. Its colour corresponds to its highest-level category.</figcaption></figure><p id="0b30" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一个我个人喜欢的可视化是在色标上绘制嵌入系数值。以某种方式订购产品有助于展示有趣的图案。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi pf"><img src="../Images/443590e3b741145da2c28be2dfd9c332.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sVXZIPRoARqqia8u9d1HTg.jpeg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">On the top plot, the products are randomly ordered. On the bottom plot, they are ordered according to brand. The latter exhibits horizontal patterns and shows how brand information was implicitly learnt. Note that the bottom ruler indicates brand.</figcaption></figure><p id="ba0b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">偏见<strong class="kh ir"> <em class="lr"> b </em> </strong>怎么样？这些对应什么？</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi pg"><img src="../Images/93955049de891f49ed0a6cbe42b85885.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q44BT0yaWWcqjD48s5dyDw.jpeg"/></div></div></figure><p id="abc4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当绘制学习偏见与产品受欢迎程度(在视图中)的关系时，有一个明显的相关性。手套策略允许将流行性从嵌入中抽象出来，这确实是一个很好的特性。</p><h2 id="7a84" class="oj mo iq bd mp ok ol dn mt om on dp mx ko oo op mz ks oq or nb kw os ot nd ou bi translated">定性示例</h2><p id="99dd" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">一些单品对单品推荐示例:</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ph pi l"/></div></figure><h2 id="90f6" class="oj mo iq bd mp ok ol dn mt om on dp mx ko oo op mz ks oq or nb kw os ot nd ou bi translated">更进一步:加入边信息</h2><p id="c325" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">嵌入成功地学习了一些产品关联。特别是，推断出了产品<strong class="kh ir">元数据</strong>(品牌、类别、范围、属性、益处……)。如果该信息已经可用，则可以将其集成到学习逻辑中。</p><p id="af40" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，在美容产品的情况下，我们可以查看产品的<strong class="kh ir">品牌</strong>及其<strong class="kh ir">类别</strong>。</p><p id="136d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">举个例子，</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ph pi l"/></div></figure><p id="69d9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些元数据的嵌入也可以被学习并用于丰富产品向量表示。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi pj"><img src="../Images/66dc05fd4ffe284cdd258ec5a16c5895.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uyik9am8o80Z-oQfBpF9kw.jpeg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">GloVe for product representation learning, with side-information. The mean layer following the category embedding layer is to manage multi-category products.</figcaption></figure><p id="abb5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意，每种元数据类型的影响都可以通过为它们各自的嵌入选择维度来监控(维度越高，影响越强)。</p><p id="52ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这种架构在非常稀疏的共生矩阵或<em class="lr">冷启动</em> ( <em class="lr"> ie)的情况下非常有用。</em>新引入)项，因为它<strong class="kh ir">弥补了缺乏与产品元数据的协作数据</strong>。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi pk"><img src="../Images/3d82adb2cbc812a633346a421e9a6fde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AERN6sVRpxuVSsK7VkifeA.jpeg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Embeddings learnt with a GloVe-like strategy with side-information. Products are ordered by brand. The bottom ruler represents brand. The concatenated brand and category embeddings are clearly visible.</figcaption></figure><p id="06f7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一种方法[6]是将元数据实体视为产品本身:具有相同品牌的产品更接近于相同的品牌嵌入。优点是预测时的架构类似于没有边信息的网络。</p><h1 id="413b" class="mn mo iq bd mp mq ob ms mt mu oc mw mx jw od jx mz jz oe ka nb kc of kd nd ne bi translated">2 |离线基准测试</h1><p id="f095" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">为了评估推荐的性能，没有什么比现场测试更好的了，无论是通过 A/B 测试(见我的<a class="ae oi" rel="noopener" target="_blank" href="/the-art-of-a-b-testing-5a10c9bb70a4">前一篇</a>)还是强化学习。</p><p id="a2e5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">尽管如此，你仍然可以通过分割你的训练集并尝试预测下一次购买/观看来验证你的算法。</p><p id="5ce8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然这些基准测试的准确性很重要，但一个经常被<strong class="kh ir">忽略的</strong>考虑因素是推荐项目的多样性。</p><h2 id="ef59" class="oj mo iq bd mp ok ol dn mt om on dp mx ko oo op mz ks oq or nb kw os ot nd ou bi translated">关于长尾产品</h2><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi pl"><img src="../Images/8189718ae4fef1321a1c26f78f2cdb07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h2tizJgwGuRAu-xZd0MRAw.jpeg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Illustration of a long tail (from <a class="ae oi" href="https://en.wikipedia.org/wiki/Long_tail" rel="noopener ugc nofollow" target="_blank">wikipedia</a>). In our current context, X-axis: products ordered by descending popularity. Y-axis: popularity</figcaption></figure><p id="8e7a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在绝大多数零售公司中，受欢迎程度(例如以购买数量来衡量)远远不是同质的。</p><p id="671c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">相对较少的产品会占据销售额的大部分。</p><p id="b363" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其余产品不常购买，代表收入机会(长尾产品)。</p><h2 id="4947" class="oj mo iq bd mp ok ol dn mt om on dp mx ko oo op mz ks oq or nb kw os ot nd ou bi translated">可发现性的度量</h2><p id="0f80" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">应对这类产品的一种方法是通过推荐来确保它们的可发现性。因此，我们着眼于系统对每个产品的公平性。</p><p id="94d3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为此，对于给定的推荐系统<strong class="kh ir"> <em class="lr"> R </em> </strong>，我们为每个产品<strong class="kh ir"> <em class="lr"> i </em> </strong>引入一个可发现性评分(<em class="lr"> dscore </em>)。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ox"><img src="../Images/6658074989eaeacf9111654f23a73b11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*230dGK1S4pKfor1u_YqPNw.jpeg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">This dscore measures how well product i is being represented in the other products’ recommendations. The rank function is the rank of product i in recommendations coming from j, under system R.</figcaption></figure><p id="abdc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">人们可以查看目录中所有产品的<em class="lr"> dscore </em>的重新分配，按降序<em class="lr"> dscore </em>排序。再一次，再分配很可能是尾巴形的，但是<strong class="kh ir">尾巴越重，所有产品的代表就越公平</strong>。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi pm"><img src="../Images/268aaddf1d865f283560261f12677373.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TUPL_VoX9bWGC50MJYwrUw.jpeg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Repartition of dscores for all products, ordered in descending dscore, given different recommender systems</figcaption></figure><h2 id="43eb" class="oj mo iq bd mp ok ol dn mt om on dp mx ko oo op mz ks oq or nb kw os ot nd ou bi translated">评论</h2><ul class=""><li id="7e96" class="ls lt iq kh b ki nf kl ng ko pn ks po kw pp la lx ly lz ma bi translated">天真的<em class="lr">一起购买/观看</em>推荐系统简单地包括，对于一个产品，查看在相同的收银台/观看环境中出现最多的产品。</li><li id="634a" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated">包含了一个<strong class="kh ir">随机</strong>推荐系统的基线曲线。毫无意外，它实现了<strong class="kh ir">最佳发现性能</strong>，代价是<strong class="kh ir">大部分不相关的推荐</strong>。它提醒我们不能只考虑这个评估指标。</li><li id="97a6" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated"><em class="lr">一起购买</em>实现最差的发现性能，主要是因为在考虑篮子时，共生矩阵的稀疏性更大。在这种情况下，冷启动产品更有可能出现。</li><li id="8773" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated"><em class="lr">一起看</em>比<em class="lr">一起买</em>获得更好的发现性能，这要归功于更密集的同现矩阵。但是，它受到产品流行偏见的限制。</li><li id="6475" class="ls lt iq kh b ki mb kl mc ko md ks me kw mf la lx ly lz ma bi translated"><em class="lr"> GloVe </em>实现了更好的发现性能，这要归功于在学习算法中集成了流行度偏差(如上所示)。此外，注入产品元数据使冷启动产品更容易被发现。</li></ul><p id="0e9f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在前面的定性例子中，你可能会认为推荐大多来自同一个品牌。</p><p id="37c7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">虽然按品牌购买美容产品并不罕见，但这些建议可能会让顾客保持循环，并影响其他品牌的发现。</p><p id="1fcf" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看看解决这个问题的方法。</p><h1 id="cda1" class="mn mo iq bd mp mq ob ms mt mu oc mw mx jw od jx mz jz oe ka nb kc of kd nd ne bi translated"><strong class="ak"> 3 |产品发现的嵌入代数</strong></h1><p id="5cf7" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">嵌入有一个令人惊讶的特性，基本代数(平均值、和、差)可以用它们来执行，同时使人类理解。</p><p id="4b5e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是令人惊讶的，因为这种考虑没有出现在模型中。</p><p id="1363" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看几个美容产品的例子。</p><h2 id="d6c8" class="oj mo iq bd mp ok ol dn mt om on dp mx ko oo op mz ks oq or nb kw os ot nd ou bi translated">产品超群</h2><p id="7357" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">从学习到的产品嵌入中，你实际上可以通过平均来自同一品牌的产品向量来导出品牌的嵌入。</p><p id="9b35" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">品牌相似性和品牌映射可以从那里计算出来。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi pq"><img src="../Images/fa7418d0d269421e5423c6514df126d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t24dLCXDae1tIBUsM99amg.png"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">Brand embeddings visualised in Tensorboard Projector (2D t-SNE projection)</figcaption></figure><h2 id="ff53" class="oj mo iq bd mp ok ol dn mt om on dp mx ko oo op mz ks oq or nb kw os ot nd ou bi translated">与品牌无关的表述</h2><p id="65b0" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">如果我们只对产品的功能和好处感兴趣，而对品牌不感兴趣，那会怎样？我们能想出<em class="lr">品牌不可知的</em>向量表示<em class="lr"> </em>和<em class="lr">品牌不可知的</em>推荐器吗？</p><p id="bd16" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">实现这一点的一个方法是，对于一个给定的产品，从它的嵌入中提取它的品牌向量表示。</p><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/7d5c5e6357d52ded9160b87cda394e68.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*LFwQWN1aSIt9YN3vzkxXjg.gif"/></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">3D projection of the original embeddings. Each colour corresponds to a product’s highest-level category.</figcaption></figure><figure class="lc ld le lf gt lg gh gi paragraph-image"><div class="gh gi pr"><img src="../Images/e25322deb3feb9edf78f0f3389059a87.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*WeLI5vu5na4UcnyoVR2gVA.gif"/></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">3D projection of brand-agnostic embeddings. Notice how their were shifted to a more spherical catalogue projection.</figcaption></figure><p id="72d9" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看一些定性的例子。</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ph pi l"/></div></figure><h2 id="803b" class="oj mo iq bd mp ok ol dn mt om on dp mx ko oo op mz ks oq or nb kw os ot nd ou bi translated">相同的产品，但来自另一个品牌</h2><p id="323d" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">如果您已经熟悉了嵌入，那么您很可能在 NLP 中遇到过几乎太常用的例子</p><blockquote class="oy oz pa"><p id="3287" class="kf kg lr kh b ki kj jr kk kl km ju kn pb kp kq kr pc kt ku kv pd kx ky kz la ij bi translated">“国王”——“男人”+“女人”=“女王”</p></blockquote><p id="94ac" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">是的，嵌入可以用于某种类型的问题回答。在前面的例子中，<em class="lr">什么是“女人”什么是“国王”什么是“男人”？→《女王》</em></p><p id="f9fa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以丝芙兰 SEA 为例，<strong class="kh ir">是否可以利用嵌入来推荐类似的产品，但在丝芙兰</strong>(丝芙兰系列)的品牌中？</p><p id="c55d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lr">即。</em></p><blockquote class="oy oz pa"><p id="4db0" class="kf kg lr kh b ki kj jr kk kl km ju kn pb kp kq kr pc kt ku kv pd kx ky kz la ij bi translated">“Fenty Beauty Pro Filt ' r Soft Matte Longwear 粉底”——“Fenty Beauty”+“丝芙兰系列”=？</p></blockquote><figure class="lc ld le lf gt lg gh gi paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="gh gi ps"><img src="../Images/5a609cd557c3e1bf76476923975e276f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HAMgOa_YDxMmGxQZmr1zCQ.jpeg"/></div></div><figcaption class="ln lo gj gh gi lp lq bd b be z dk">In practice, it really outputs interpretable results!</figcaption></figure><p id="18f3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">和以前一样，一些定性的例子，</p><figure class="lc ld le lf gt lg"><div class="bz fp l di"><div class="ph pi l"/></div></figure><h1 id="058f" class="mn mo iq bd mp mq ob ms mt mu oc mw mx jw od jx mz jz oe ka nb kc of kd nd ne bi translated">4 |候选人</h1><p id="35da" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">我在这个案例研究中提出的框架实际上对许多情况非常适用。<strong class="kh ir">你所需要的就是为你要嵌入的对象导出同现上下文</strong>。</p><p id="a2e4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最重要的是，上下文的定义可以像您希望的那样灵活。在这里，我只考虑了浏览会话，但也可以混合其他信号。</p><p id="0697" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，我只展示了单品到单品的推荐，但是通过平均嵌入输入产品，来自客户过去购买或当前购物篮的推荐是完全可以实现的。</p></div><div class="ab cl mg mh hu mi" role="separator"><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml mm"/><span class="mj bw bk mk ml"/></div><div class="ij ik il im in"><h2 id="3694" class="oj mo iq bd mp ok ol dn mt om on dp mx ko oo op mz ks oq or nb kw os ot nd ou bi translated">参考</h2><p id="0dc8" class="pw-post-body-paragraph kf kg iq kh b ki nf jr kk kl ng ju kn ko nh kq kr ks ni ku kv kw nj ky kz la ij bi translated">[1] Pennington 等人，<a class="ae oi" href="https://nlp.stanford.edu/pubs/glove.pdf" rel="noopener ugc nofollow" target="_blank">GloVe:Global Vectors for Word Representation</a>，2014<br/>【2】Bengio 等人，<a class="ae oi" href="https://papers.nips.cc/paper/1839-a-neural-probabilistic-language-model.pdf" rel="noopener ugc nofollow" target="_blank">一种神经概率语言模型</a>，2001<br/>【3】miko lov 等人，<a class="ae oi" href="https://arxiv.org/pdf/1301.3781.pdf" rel="noopener ugc nofollow" target="_blank">Vector Space 中单词表示的高效估计</a>，2013<br/>【4】<a class="pt pu ep" href="https://medium.com/u/a655fe1c6831?source=post_page-----98eccfa816bd--------------------------------" rel="noopener" target="_blank">Mihajlo Grbovic</a>，<a class="ae oi" href="https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e" rel="noopener">列出搜索排名中的嵌入</a> (Airbnb  <a class="ae oi" href="https://eng.uber.com/uber-eats-query-understanding/" rel="noopener ugc nofollow" target="_blank">用 Uber Eats 发现食物:构建查询理解引擎</a>，2018 年 6 月<br/>【6】Vasile 等人，<a class="ae oi" href="http://Product Embeddings Using Side-Information for Recommendation" rel="noopener ugc nofollow" target="_blank"> Meta-Prod2Vec -产品嵌入使用边信息进行推荐</a>，2016</p></div></div>    
</body>
</html>