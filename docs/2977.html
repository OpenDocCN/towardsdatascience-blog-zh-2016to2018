<html>
<head>
<title>Convolutional Neural Network to steer a vehicle inside a game</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络在游戏中驾驶车辆</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/convolutional-neural-network-to-steer-a-vehicle-inside-a-game-2aab41a5ef60?source=collection_archive---------11-----------------------#2018-03-26">https://towardsdatascience.com/convolutional-neural-network-to-steer-a-vehicle-inside-a-game-2aab41a5ef60?source=collection_archive---------11-----------------------#2018-03-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/1129e11396c6dd6837fd6febf06f2080.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R1U_Heirup8Gxgi2Yqczlw.jpeg"/></div></div></figure><p id="c2d8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">大约两年前，英伟达发表了<a class="ae kw" href="https://arxiv.org/abs/1604.07316" rel="noopener ugc nofollow" target="_blank"> PilotNet 论文</a>，以端到端的方式展示了自动驾驶汽车的卷积神经网络(CNN)。在这篇文章中，我想展示我是如何在游戏中使用这个架构来预测车辆的方向盘轴线的。我已经将转向角预测公式化为回归问题。</p><p id="e294" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">任何有监督的机器学习问题都是在有标签的数据(X，Y)上工作的。其中<strong class="ka ir"> X </strong>是输入，<strong class="ka ir"> Y </strong>是输出。学习算法学习映射函数 Y = f(X)。在这个问题中，输入 X 是任意给定点的道路图像，输出 Y 是方向盘轴。</p><h2 id="d0ab" class="kx ky iq bd kz la lb dn lc ld le dp lf kj lg lh li kn lj lk ll kr lm ln lo lp bi translated">资料组</h2><p id="d28f" class="pw-post-body-paragraph jy jz iq ka b kb lq kd ke kf lr kh ki kj ls kl km kn lt kp kq kr lu kt ku kv ij bi translated">我从<a class="ae kw" href="https://github.com/marsauto/europilot#sample-training-data" rel="noopener ugc nofollow" target="_blank">这里</a>获得了大约 16 万张图像的数据集。该数据集是通过以 10fps 的速度驾驶大约 5 个小时，通过游戏杆捕捉游戏窗口和方向盘轴的截图而生成的。方向盘轴不是以度为单位，而是以操纵杆的不同刻度为单位，范围从-10k(左转)到 10k(右转)。原始图像大小为 1024 X 768 X 3 像素。这里有一些例子图片—</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/aa8ca5b8dbbccc806084d4fd95bddd24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SDm9i7-2TNnGbd5xDnJhNg.jpeg"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Driving in the daylight</figcaption></figure><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/6ba9309d83d62ffffe525494dd85e7b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lZL9texw53UvnyfIP0LAjA.jpeg"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Driving at the night</figcaption></figure><p id="cb10" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">图像的大部分不是很有用，因此感兴趣区域(ROI)被裁剪并按比例缩小以获得尺寸为 200 x 66 x 3 的图像。</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi md"><img src="../Images/ea9af98c10ca673d80a3e00961bf14ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*0yuKIQGkRRpPoGI92Qzf9g.jpeg"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">ROI(200 x 66 x 3)</figcaption></figure><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi md"><img src="../Images/1c169a071710e486281d2918d9a8b8fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*zTAWvoM2dyakwoOQXCCcBg.jpeg"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">ROI(200 x 66 x 3)</figcaption></figure><p id="4120" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是数据准备的一个重要部分，因为裁剪确保了学习算法只关注 ROI，而不是整个图像，缩小比例确保了网络没有太多的输入参数。</p><p id="5698" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">整个数据被混洗，然后分成训练集(87%)和验证集(13%)。具有超参数调整的模型训练在训练集上完成，而验证集用于检查模型的最终准确性。洗牌确保了训练集和验证集都有来自所有不同驾驶条件的数据，如白天、夜晚、下雨等。</p><p id="1a9a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在来看标签，这是方向盘轴的直方图。正值对应于右转的方向盘旋转量，反之亦然。</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi me"><img src="../Images/5948ab4fcd7438bf847b5c7a977cecc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jlPNvRIqjs0v1v-IuAl3rQ.png"/></div></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Distribution of steering wheel axis (labels) BEFORE Augmentation</figcaption></figure><p id="3fbb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">急转弯的例子很少，大多数数据在-2500 到 2500 之间。此外，由于这种分布是正常的，均方差(MSE)损失(已用于回归)应该工作得很好。</p><p id="8b21" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，<strong class="ka ir">数据通过水平翻转图像并因此翻转转向轴而得到增强</strong>。</p><pre class="lv lw lx ly gt mf mg mh mi aw mj bi"><span id="17ac" class="kx ky iq mg b gy mk ml l mm mn">if(np.random.choice(2, 1)[0] == 1):<br/>    pil_img = pil_img.transpose(Image.FLIP_LEFT_RIGHT)<br/>    label = -1 * label # Changing the direction of wheel axis.</span></pre><p id="b1d9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这几乎使训练数据翻倍。</p><h2 id="67d1" class="kx ky iq bd kz la lb dn lc ld le dp lf kj lg lh li kn lj lk ll kr lm ln lo lp bi translated">网络体系结构</h2><p id="7a94" class="pw-post-body-paragraph jy jz iq ka b kb lq kd ke kf lr kh ki kj ls kl km kn lt kp kq kr lu kt ku kv ij bi translated">我选择了 Nvidia 著名的<a class="ae kw" href="https://arxiv.org/abs/1604.07316" rel="noopener ugc nofollow" target="_blank"> PilotNet 架构，并做了一些修改。这是最初的建筑</a></p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/9493991c13c17befb114a0c13f5834c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*2BK4bSxk-eRBRith3KAeVg.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Source <a class="ae kw" href="https://devblogs.nvidia.com/deep-learning-self-driving-cars/" rel="noopener ugc nofollow" target="_blank">Nvidia blog</a></figcaption></figure><p id="cf47" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了更快的训练，我在每一层之后增加了<strong class="ka ir">【BN】</strong>(在卷积层的信道轴上)。我也尝试使用<strong class="ka ir">辍学</strong>进行正规化，但这似乎并不影响准确性，因此删除了它。关于何时应用 BN 有许多<a class="ae kw" href="https://www.reddit.com/r/MachineLearning/comments/67gonq/d_batch_normalization_before_or_after_relu/" rel="noopener ugc nofollow" target="_blank">争论，BN</a>是在非线性之前还是在非线性之后。因为我在每一层使用了<strong class="ka ir"> Relu 激活</strong>，在 Relu 激活后应用 BN 是<strong class="ka ir">增加了隐藏层激活的平均值并减少了方差</strong>，因为 BN 没有考虑负面激活。因此，我在非线性<strong class="ka ir">、</strong>后应用 BN，结果很好。</p><p id="b9ae" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我将输入图像缩小到 200 x 66(与 PilotNet 相同)，以保持全连接层的参数较低(卷积层的参数不受影响)。这对于避免过度拟合非常重要。具有非常高的参数的模型具有高熵，并且它们倾向于过度拟合(即记忆训练集)。在低熵的情况下，梯度下降算法迫使模型学习数据中的重要模式，而不是记忆训练集。而参数很低也是不好的，因为模型可能什么也学不到。</p><p id="e121" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">可以通过使用最大池来避免参数的增加，但是它通常用于空间不变性，这在这种情况下是不期望的。</p><p id="5f6e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">通过将输入像素除以 255 来归一化模型的输入。使用整个训练集的均值和方差来归一化输入图像有更好的方法，但这也很好。我使用没有任何正则化的均方误差损失。在验证集上测试了这些参数之后，我想出了所有这些设计选择。其余的网络参数保持不变。</p><p id="6b70" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是我和<code class="fe mp mq mr mg b">input_shape = (66, 200, 3)</code>一起使用的最终架构。</p><pre class="lv lw lx ly gt mf mg mh mi aw mj bi"><span id="0aba" class="kx ky iq mg b gy mk ml l mm mn">_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d_1 (Conv2D)            (None, 31, 98, 24)        1824      <br/>_________________________________________________________________<br/>batch_normalization_1 (Batch (None, 31, 98, 24)        96        <br/>_________________________________________________________________<br/>conv2d_2 (Conv2D)            (None, 14, 47, 36)        21636     <br/>_________________________________________________________________<br/>batch_normalization_2 (Batch (None, 14, 47, 36)        144       <br/>_________________________________________________________________<br/>conv2d_3 (Conv2D)            (None, 5, 22, 48)         43248     <br/>_________________________________________________________________<br/>batch_normalization_3 (Batch (None, 5, 22, 48)         192       <br/>_________________________________________________________________<br/>conv2d_4 (Conv2D)            (None, 3, 20, 64)         27712     <br/>_________________________________________________________________<br/>batch_normalization_4 (Batch (None, 3, 20, 64)         256       <br/>_________________________________________________________________<br/>conv2d_5 (Conv2D)            (None, 1, 18, 64)         36928     <br/>_________________________________________________________________<br/>batch_normalization_5 (Batch (None, 1, 18, 64)         256       <br/>_________________________________________________________________<br/>flatten_1 (Flatten)          (None, 1152)              0         <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 100)               115300    <br/>_________________________________________________________________<br/>batch_normalization_6 (Batch (None, 100)               400       <br/>_________________________________________________________________<br/>dense_2 (Dense)              (None, 50)                5050      <br/>_________________________________________________________________<br/>batch_normalization_7 (Batch (None, 50)                200       <br/>_________________________________________________________________<br/>dense_3 (Dense)              (None, 10)                510       <br/>_________________________________________________________________<br/>batch_normalization_8 (Batch (None, 10)                40        <br/>_________________________________________________________________<br/>dense_4 (Dense)              (None, 1)                 11        <br/>=================================================================<br/>Total params: 253,803<br/>Trainable params: 253,011<br/>Non-trainable params: 792</span></pre><p id="07f4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我使用 Keras 和 Tensorflow 后端进行所有的实验和最终训练。</p><h2 id="e9e6" class="kx ky iq bd kz la lb dn lc ld le dp lf kj lg lh li kn lj lk ll kr lm ln lo lp bi translated">培养</h2><p id="ba68" class="pw-post-body-paragraph jy jz iq ka b kb lq kd ke kf lr kh ki kj ls kl km kn lt kp kq kr lu kt ku kv ij bi translated">该数据集在相邻图像之间具有非常高的相关性，因此对训练进行洗牌是很重要的。与此同时，在每个时期之后，数据集被重新洗牌，这样每个批次在多个时期中都是唯一的。</p><pre class="lv lw lx ly gt mf mg mh mi aw mj bi"><span id="d68d" class="kx ky iq mg b gy mk ml l mm mn">total data: 162495, training set: 140800, validation set: 21695<br/>batch_size: 128, train_steps: 1100, val_steps: 170</span></pre><p id="9459" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于 keras <a class="ae kw" href="https://github.com/keras-team/keras/issues/5152" rel="noopener ugc nofollow" target="_blank">没有用于回归</a>任务的 <code class="fe mp mq mr mg b"><a class="ae kw" href="https://github.com/keras-team/keras/issues/5152" rel="noopener ugc nofollow" target="_blank">flow_from_directory</a></code> <a class="ae kw" href="https://github.com/keras-team/keras/issues/5152" rel="noopener ugc nofollow" target="_blank">，我不得不编写自己的带有数据扩充的 data_generator。</a></p><pre class="lv lw lx ly gt mf mg mh mi aw mj bi"><span id="d594" class="kx ky iq mg b gy mk ml l mm mn">INPUT_NORMALIZATION = 255.0<br/>OUTPUT_NORMALIZATION = 655.35 #picked this number to compare results with data source model.<br/>img_shape = (66, 200, 3)<br/>batch_size = 128<br/>def generator(df, batch_size):<br/>    img_list = df['img']<br/>    wheel_axis = df['wheel-axis']    <br/>    <strong class="mg ir"># create an empty batch</strong><br/>    batch_img = np.zeros((batch_size,) + img_shape)<br/>    batch_label = np.zeros((batch_size, 1))<br/>    index = 0</span><span id="612e" class="kx ky iq mg b gy ms ml l mm mn">    while True:<br/>        for i in range(batch_size):<br/>            label = wheel_axis.iloc[index]<br/>            img_name = img_list.iloc[index]<br/>            pil_img = image.load_img(path_to_data+img_name)<br/>            <strong class="mg ir"># Data augmentation </strong>          <br/>            if(np.random.choice(2, 1)[0] == 1):<br/>                pil_img = pil_img.transpose(Image.FLIP_LEFT_RIGHT)<br/>                label = -1 * label            <br/>            batch_img[i] = image.img_to_array(pil_img)<br/>            batch_label[i] = label<br/>            index += 1<br/>            if index == len(img_list):<br/>                <strong class="mg ir">#End of an epoch hence reshuffle</strong><br/>                df = df.sample(frac=1).reset_index(drop=True)<br/>                img_list = df['img']<br/>                wheel_axis = df['wheel-axis']<br/>                index = 0<br/>        yield batch_img / INPUT_NORMALIZATION, (batch_label / OUTPUT_NORMALIZATION)</span></pre><p id="4572" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">决定使用多大的迷你批次也很棘手。如果我们使用非常小的批量，计算的梯度可能会非常不准确，因此训练会有噪声。如果你选择一个非常大的批量，它可能不适合内存。我选择使用 128 作为迷你批次大小。</p><p id="3cbc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我使用具有动量和学习率衰减的随机梯度下降优化器来训练网络。</p><pre class="lv lw lx ly gt mf mg mh mi aw mj bi"><span id="1368" class="kx ky iq mg b gy mk ml l mm mn">sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)</span></pre><p id="b008" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该模型在 CPU 上训练 41 个时期，持续约 30 小时，以实现 0.1166 的验证均方误差和 0.2429 的验证平均绝对误差(在第 36 个时期)，这对应于 20k 标度上 160 (=0.2429 x 输出 _ 归一化)的平均误差。</p><div class="lv lw lx ly gt ab cb"><figure class="mt jr mu mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/8ee155da9de4767a8c862a4ec0140eff.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*EeB3JTaAJt4W0VJgyOk5uQ.png"/></div></figure><figure class="mt jr mz mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/b02459ebc0caf4cba7c752c12b08f44f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*GiI_Jl0QRfTZL9R8ZxTA3Q.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk na di nb nc">Validation MAE and MSE</figcaption></figure></div><div class="ab cb"><figure class="mt jr nd mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/6b5e22157f325ec4b522611da2c23791.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*gof3ihw7nIe9pB-RftiGjw.png"/></div></figure><figure class="mt jr ne mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/777d5e0d1451191b6960b39d328c583b.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*UqbbtTQh1bEtPYD8DxLAxg.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk nf di ng nc">Training MAE and MSE</figcaption></figure></div><p id="3e3d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">而训练批次规范化有助于更快的转换。与 20 个时期内没有批量标准化的架构相比，我能够在仅 9 个时期内通过批量标准化实现相同的 MSE 损失。</p><h2 id="551e" class="kx ky iq bd kz la lb dn lc ld le dp lf kj lg lh li kn lj lk ll kr lm ln lo lp bi translated">结果</h2><p id="a542" class="pw-post-body-paragraph jy jz iq ka b kb lq kd ke kf lr kh ki kj ls kl km kn lt kp kq kr lu kt ku kv ij bi translated">以下是一些结果(提醒—负值表示左转，反之亦然)</p><div class="lv lw lx ly gt ab cb"><figure class="mt jr nh mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/43f59e9c75a5ab954f3afad0a1f19e9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*YBShzqMDPEjnILmPnhN8tQ.png"/></div></figure><figure class="mt jr ni mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/bc6214c3bcb78a77938b94e4c838b967.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*mN77XQEocBRGJwL3NREIXQ.png"/></div></figure></div><div class="ab cb"><figure class="mt jr nj mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/9667447819e473d55bd0675883d2bacd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*8UcvPXwyIW-NBBcMrw3ugg.png"/></div></figure><figure class="mt jr nk mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/da571b1664f41cc2330d01c953517716.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*kFmM4F6k13iMhf3Cv-Oxhg.png"/></div></figure></div><div class="ab cb"><figure class="mt jr nl mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/b09656129034349bbff8795016a9c471.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*IlX33z2YIx_MPFKRP4h_lA.png"/></div></figure><figure class="mt jr nm mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/f4a2268bda620dbe2e6e4813c50a6585.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*WsgQQH9bVMT_7JXEOc2hJw.png"/></div></figure></div><p id="62a4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">尽管急转弯的例子很少，但 model 仍然学会了这些模式。</p><div class="lv lw lx ly gt ab cb"><figure class="mt jr nn mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/8abd91d0a59e099f9fc4a0132febd172.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*mURcHtbKEPylFTyyUc4slg.png"/></div></figure><figure class="mt jr no mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/e44535de64893c29c12b3b635573beee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*fWy023PoG4i0XkeirWDU4w.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk np di nq nc">Sharp Right Turns</figcaption></figure></div><div class="ab cb"><figure class="mt jr nr mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/8d98c561eb35eefe5535c5d389c525f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*Zta-5uNINR1XOYfI8x8vrw.png"/></div></figure><figure class="mt jr ns mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/f4b86072907b8612b0474d05d3517c31.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*0C2GuISyWt04wVRpqavfeA.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk nt di nu nc">Sharp Left Turns</figcaption></figure></div><p id="463d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有些情况下，模型比真实标签表现得更好。</p><div class="lv lw lx ly gt ab cb"><figure class="mt jr nv mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/cef37c30f2f57fcf3152b821fdbf0c21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*9oqPq4mUuST7LsNQXHq9FA.png"/></div></figure><figure class="mt jr nw mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/50cea1d9bbf06fba53e44a1003841504.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*9dJtSjewRNBAXzjoq6f05w.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk nt di nu nc">Model predictions are better than ground truth labels</figcaption></figure></div><p id="32b2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在某些情况下，模型的表现不是很好。</p><div class="lv lw lx ly gt ab cb"><figure class="mt jr nx mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/348b7ac1f9c413dd8a7511553241ffed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*pjBUPK7sbUbVRDt8JCO7EA.png"/></div></figure><figure class="mt jr ny mv mw mx my paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><img src="../Images/b096f0c401766dfa21a3e1036db3d1c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*7s0kba9rUE5UDx22cqcktg.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk nz di oa nc">Model prediction are not very good</figcaption></figure></div><p id="3c52" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这篇文章的重量和代码可以在<a class="ae kw" href="https://github.com/aryarohit07/PilotNetSelfDrivingCar" rel="noopener ugc nofollow" target="_blank"> my Github </a>上找到。</p><h2 id="1bbb" class="kx ky iq bd kz la lb dn lc ld le dp lf kj lg lh li kn lj lk ll kr lm ln lo lp bi translated">结论</h2><p id="a6eb" class="pw-post-body-paragraph jy jz iq ka b kb lq kd ke kf lr kh ki kj ls kl km kn lt kp kq kr lu kt ku kv ij bi translated">对于这个项目，一个基于 CNN 的小型架构似乎工作得很好。我使用了各种技术，如数据处理(裁剪 ROI、缩放输入大小)、数据扩充、批量标准化，仅用大约 5 小时的行驶数据就实现了相当好的验证损失。这可以通过使用不同的架构，如<a class="ae kw" href="http://cs231n.stanford.edu/reports/2017/pdfs/626.pdf" rel="noopener ugc nofollow" target="_blank">CNN-RNN</a>网络来获得更好的结果，并通过使用其他梯度下降优化器，如 Adam、Adadelta 等来进一步改善。</p><p id="4bd0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你喜欢读这篇文章，请鼓掌并与你的同事和朋友分享。谢谢！</p><p id="82ee" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">还有，我们来连线一下<a class="ae kw" href="https://www.facebook.com/aryarohit07" rel="noopener ugc nofollow" target="_blank">脸书</a>、<a class="ae kw" href="https://twitter.com/arya_rohit07" rel="noopener ugc nofollow" target="_blank">推特</a>、<a class="ae kw" href="https://in.linkedin.com/in/aryarohit07" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>和<a class="ae kw" href="https://github.com/aryarohit07/" rel="noopener ugc nofollow" target="_blank"> Github </a>。</p></div></div>    
</body>
</html>