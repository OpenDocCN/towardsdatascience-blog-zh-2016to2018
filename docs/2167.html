<html>
<head>
<title>An Introduction to GPU Optimization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">GPU 优化简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-introduction-to-gpu-optimization-6ea255ef6360?source=collection_archive---------3-----------------------#2017-12-29">https://towardsdatascience.com/an-introduction-to-gpu-optimization-6ea255ef6360?source=collection_archive---------3-----------------------#2017-12-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5104" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">借助 GPU 的强大功能加速简单的计算任务</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/1e682110e19ce65543cfbe9a303873ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*dVo15ilNgnTp862WRmqEGg.jpeg"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Source: <a class="ae kr" href="https://images.techhive.com/images/article/2016/08/speedomter-fast-speed-100678036-primary.idge.jpg" rel="noopener ugc nofollow" target="_blank">Link</a></figcaption></figure><p id="deb1" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">大多数涉及大量计算的任务都需要时间，随着数据集变得越来越大，这将变得更加耗时。解决这个问题的一种方法是使用线程。在本文中，我将介绍 GPU 加速，它是如何完成的，以及一个简单的 GPU 任务 API 和一段代码。首先，让我们考虑矩阵乘法的例子。</p><h1 id="7de8" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">矩阵乘法</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mg"><img src="../Images/769afd853fb258f217a6eda393b26be2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lJ8G9OrAGa5iG8BCloExLQ.jpeg"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">Matrix Multiplication</figcaption></figure><p id="9a40" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">在上面的场景中，有两个矩阵，一个大小为<strong class="ku ir"><em class="ml">3×6</em></strong>，另一个大小为<strong class="ku ir"><em class="ml">6×6</em></strong>。得到的矩阵大小为<strong class="ku ir"><em class="ml">3×6</em></strong>。因此，对于矩阵的每个单元，将有<strong class="ku ir"> <em class="ml"> 6 </em> </strong>个计算。总共会有<strong class="ku ir"><em class="ml">3×6×6</em></strong>多次乘法。因此，我们可以断定，这项任务需要<strong class="ku ir"> <em class="ml"> O(mn ) </em> </strong>的时间量来计算。这意味着，对于一个大小为<strong class="ku ir"> <em class="ml"> 2000 x 2000 </em> </strong>的矩阵，将有<strong class="ku ir"><em class="ml">80 亿</em> </strong>次计算完成。这是大量的 CPU 时间！！！。</p><h1 id="e1a0" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">GPU 简介</h1><p id="6658" class="pw-post-body-paragraph ks kt iq ku b kv mm jr kx ky mn ju la lb mo ld le lf mp lh li lj mq ll lm ln ij bi translated">通常 GPU 包含大量的处理核心。通常从 384 到几千不等。下面简单对比一下<strong class="ku ir">英伟达</strong>的部分最新显卡。(<a class="ae kr" href="https://www.nvidia.com/en-us/geforce/products/10series/compare/" rel="noopener ugc nofollow" target="_blank">来源</a>)</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mr"><img src="../Images/1ec413fc9c783806025e994250082e15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HmGsHOTOm5FQTFlW3SHUYg.png"/></div></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk">CUDA Core Count</figcaption></figure><p id="68f8" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir"> CUDA </strong>代表<strong class="ku ir">计算统一设备架构</strong>。这些处理器运行速度相对较低，但通过使用大量 alu(算术和逻辑单元)提供了更高的并行性。点击阅读更多<a class="ae kr" href="http://www.nvidia.com/object/what-is-gpu-computing.html" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/81c747aa1bb772b5311fc2eef513e69f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*6M1CNuVH_uxdb0ryEdAGew.jpeg"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk"><a class="ae kr" href="https://stackoverflow.com/questions/42526790/cuda-c-programing-guide-how-do-thread-and-block-indexing-calculations-work" rel="noopener ugc nofollow" target="_blank">CUDA Thread Model</a></figcaption></figure><p id="d95e" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">此图展示了 CUDA 中的线程模型(这与市场上的其他架构(如 AMD)非常相似)。为了简单起见，我们可以假设每个 CUDA 内核或 GPU 内核一次可以运行一个线程。如果我们有一个大的数据集，我们可以把它分成几个部分。一个<strong class="ku ir">网格</strong>包含几个<strong class="ku ir">块</strong>，块是另一个矩阵，包含数量与其大小相等的<strong class="ku ir">线程</strong>。无论如何，因为这是介绍，所以让我们把注意力放在用 JAVA 开发的更简单的 API 上。</p><h1 id="c61a" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">想想 GPU</h1><p id="52e3" class="pw-post-body-paragraph ks kt iq ku b kv mm jr kx ky mn ju la lb mo ld le lf mp lh li lj mq ll lm ln ij bi translated">正如我们所讨论的，每个 GPU 核心都能够运行一个单独的线程。开始类比的最简单方法是假设矩阵的每个单元将由单个 GPU 核心来计算。由于所有内核都是并行运行的，因此所有单元都将被并行计算。因此，我们的时间复杂度突然下降到<strong class="ku ir"> <em class="ml"> O(n) </em> </strong>。现在，对于<strong class="ku ir"> <em class="ml"> 2000 x 2000 </em> </strong>矩阵我们只需要<strong class="ku ir"><em class="ml">2000</em></strong>次运行，这对于计算机来说是相当容易计算的。通常我们之前讨论的每个线程都知道它的身份，也就是它所属的<strong class="ku ir"> <em class="ml">块</em> </strong>和<strong class="ku ir"> <em class="ml">网格</em> </strong>。或者更简单地说，矩阵的单元位置。此外，矩阵将被加载到 GPU 的共享内存中，我们可以通过索引直接访问单元数据并进行并行处理。简单对吗？让我们检查一下代码。</p><h1 id="48d9" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">用 APARAPI 进行 GPU 编程</h1><p id="2dc0" class="pw-post-body-paragraph ks kt iq ku b kv mm jr kx ky mn ju la lb mo ld le lf mp lh li lj mq ll lm ln ij bi translated">什么？嗯，<strong class="ku ir"><em class="ml">APAR API(A-PARallel-API)</em></strong>是<strong class="ku ir"> OpenCL </strong>的<strong class="ku ir"> JAVA </strong>包装器，OpenCL 是用于编写 GPU 的<strong class="ku ir">开放计算语言</strong>。这同时支持<strong class="ku ir"> CUDA </strong>架构和<strong class="ku ir"> AMD </strong>设备。此外，API 将更好的面向对象的<strong class="ku ir"> JAVA </strong>带入了画面，如果我们直接用<strong class="ku ir"> <em class="ml"> C++ </em> </strong>跳转到任务，这可能看起来很混乱。开始很容易。有一个 maven 依赖。但是要确保你已经正确设置了<strong class="ku ir"> OpenCL </strong>或者<strong class="ku ir"> CUDA </strong>。简单的谷歌搜索应该可以帮助你。大多数设备都捆绑在一起(<strong class="ku ir"> OSX </strong>和<strong class="ku ir"> Windows </strong>设备)。</p><h2 id="8cc3" class="mt lp iq bd lq mu mv dn lu mw mx dp ly lb my mz ma lf na nb mc lj nc nd me ne bi translated">pom.xml</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nf ng l"/></div></figure><h2 id="b596" class="mt lp iq bd lq mu mv dn lu mw mx dp ly lb my mz ma lf na nb mc lj nc nd me ne bi translated">MatrixMultiplication.java</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nf ng l"/></div></figure><h2 id="c90e" class="mt lp iq bd lq mu mv dn lu mw mx dp ly lb my mz ma lf na nb mc lj nc nd me ne bi translated">上述代码的详细说明</h2><p id="f2cb" class="pw-post-body-paragraph ks kt iq ku b kv mm jr kx ky mn ju la lb mo ld le lf mp lh li lj mq ll lm ln ij bi translated">内核是由 GPU 执行的代码的一部分。内核可见的变量将被复制到 GPU RAM 中。我们以线性阵列而不是 2D 阵列的形式提供数据，因为这是 GPU 支持的方式。这并不是说它们不能处理 2D 数组，而是它们被处理的方式是通过维度的概念(我们现在还不会谈论它)。</p><pre class="kg kh ki kj gt nh ni nj nk aw nl bi"><span id="1c02" class="mt lp iq ni b gy nm nn l no np">Range range = Range.<em class="ml">create</em>(SIZE * SIZE);</span></pre><p id="d030" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">上述代码在 GPU 中分配内存，以便<strong class="ku ir"><em class="ml">SIZE x SIZE</em></strong>GPU 中运行的线程数量或更少(如可用)。</p><pre class="kg kh ki kj gt nh ni nj nk aw nl bi"><span id="2068" class="mt lp iq ni b gy nm nn l no np">int row = getGlobalId() / SIZE;<br/>int col = getGlobalId() % SIZE;</span></pre><p id="415a" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">上面的代码从线程的私有内存中获取线程的<strong class="ku ir"> <em class="ml"> Id </em> </strong>。有了这个特定线程，我们就可以确定线程的单元位置。对于每个单元格，我们将执行以下操作。</p><pre class="kg kh ki kj gt nh ni nj nk aw nl bi"><span id="9206" class="mt lp iq ni b gy nm nn l no np">for (int i = 0; i &lt; SIZE; i++) {<br/>    d[row * SIZE + col] += a[row * SIZE + i] * b[i * SIZE + col];<br/>}</span></pre><p id="913c" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">这是两个矩阵的相应单元的倍数的简单和。我们只是使用线程索引为单个线程定义内核，它将为所有线程并行运行。</p><h1 id="b1c0" class="lo lp iq bd lq lr ls lt lu lv lw lx ly jw lz jx ma jz mb ka mc kc md kd me mf bi translated">结果</h1><p id="01f9" class="pw-post-body-paragraph ks kt iq ku b kv mm jr kx ky mn ju la lb mo ld le lf mp lh li lj mq ll lm ln ij bi translated">它很快。但是有多快呢？。这是上面程序的输出。</p><p id="98b2" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir"> 1200 x 1200 </strong></p><pre class="kg kh ki kj gt nh ni nj nk aw nl bi"><span id="a975" class="mt lp iq ni b gy nm nn l no np">Starting single threaded computation<br/>Task finished in 25269ms <br/>Starting GPU computation<br/>Task finished in 1535ms</span></pre><p id="262b" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">以下仅针对 GPU 组件运行，因为 CPU 的计算时间非常长。</p><p id="b76f" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated"><strong class="ku ir"> 2000 x 2000 </strong>任务用时 3757 毫秒<br/>T5】5000 x 5000 任务用时 5402 毫秒</p><p id="5665" class="pw-post-body-paragraph ks kt iq ku b kv kw jr kx ky kz ju la lb lc ld le lf lg lh li lj lk ll lm ln ij bi translated">希望你喜欢阅读。请一定要试试！！干杯！！</p></div></div>    
</body>
</html>