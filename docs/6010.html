<html>
<head>
<title>A gentle introduction to Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-gentle-introduction-to-neural-networks-14e5c02bafe?source=collection_archive---------16-----------------------#2018-11-20">https://towardsdatascience.com/a-gentle-introduction-to-neural-networks-14e5c02bafe?source=collection_archive---------16-----------------------#2018-11-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="0aad" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/neural-networks-series" rel="noopener" target="_blank">神经网络系列</a></h2><div class=""/><div class=""><h2 id="adb5" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">神经网络系列—第 0 章</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/6bb9d915161831be88d7ab35895dfb3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jj6AsSP9c9hZiuASYic7Eg.jpeg"/></div></div></figure><h2 id="b91e" class="ld le it bd lf lg lh dn li lj lk dp ll lm ln lo lp lq lr ls lt lu lv lw lx iz bi translated">序言注释</h2><p id="b830" class="pw-post-body-paragraph ly lz it ma b mb mc kd md me mf kg mg lm mh mi mj lq mk ml mm lu mn mo mp mq im bi translated">这个故事是我正在创作的关于神经网络的新系列的第一部分。作为一名前研究人员，我喜欢让自己跟上研究领域的最新发展，我也喜欢写作。我最近一直在努力做到这一点，直到我想到了一个主意:如果我强迫自己通过写作来强迫自己阅读和调查更多的东西，会怎么样？所以我想出了这个从零开始的想法，深入研究神经网络领域的历史，从基础直到今天应用的复杂的神经网络架构。这个系列对我个人来说有两个挑战:填补知识上的空白(我很确定我不是什么都知道)，以及确保我可以开始一个想法并坚持到底而不放弃。</p><p id="5d25" class="pw-post-body-paragraph ly lz it ma b mb mr kd md me ms kg mg lm mt mi mj lq mu ml mm lu mv mo mp mq im bi translated">我决定将这一章命名为第 0 章，因为在这篇文章中，我将只解释该领域的最初历史步骤，为什么神经网络存在，它们用于什么，以及神经生物学和计算机科学之间的桥梁是什么。</p><h2 id="0ab3" class="ld le it bd lf lg lh dn li lj lk dp ll lm ln lo lp lq lr ls lt lu lv lw lx iz bi translated">神经网络</h2><p id="5ce2" class="pw-post-body-paragraph ly lz it ma b mb mc kd md me mf kg mg lm mh mi mj lq mk ml mm lu mn mo mp mq im bi translated">神经网络是一种人工智能<a class="ae mw" href="https://en.wikipedia.org/wiki/Connectionism" rel="noopener ugc nofollow" target="_blank">连接主义</a>方法，能够学习如何执行模式识别或过程控制任务，而无需显式编程。神经网络应用的一些例子可以是(1) <a class="ae mw" href="http://www.sysecol2.ethz.ch/OptiControl/LiteratureOC/Ruan_06_EB_inPress.pdf" rel="noopener ugc nofollow" target="_blank">控制房间的温度</a>，(2) <a class="ae mw" href="http://cis.csuohio.edu/~sschung/CIS660/DeepFaceRecognition_parkhi15.pdf" rel="noopener ugc nofollow" target="_blank">识别图片/视频中的人脸</a>，(3) <a class="ae mw" href="https://www.cs.utoronto.ca/~ilya/pubs/2011/LANG-RNN.pdf" rel="noopener ugc nofollow" target="_blank">生成文本序列</a>。它们受到我们大脑工作方式的启发，通过连接和引起多个基本实体之间的交互来实现最终目标。这些实体被称为神经元(根据这些算法和我们大脑工作方式之间的整体相似性)。神经元可以与其他神经元相互作用，这取决于它们相互连接的方式以及它们的连接有多强。</p><h2 id="525b" class="ld le it bd lf lg lh dn li lj lk dp ll lm ln lo lp lq lr ls lt lu lv lw lx iz bi translated">这个过程是如何从生物学转化到计算机科学的？</h2><p id="86c8" class="pw-post-body-paragraph ly lz it ma b mb mc kd md me mf kg mg lm mh mi mj lq mk ml mm lu mn mo mp mq im bi translated">从生物学上讲，神经元由 3 个主要部分组成:树突、核/细胞体和轴突。其完整结构如图 1 所示。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/0425a0a5d84db9f922a7acb5c5a8bfcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*gqV_CYhwg5z_6UsufGWnXA.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk">Figure 1: Structure of a neuron. Image taken from <a class="ae mw" href="https://lifehacker.com/the-science-of-practice-what-happens-when-you-learn-a-510255025" rel="noopener ugc nofollow" target="_blank">this lifehacker article</a></figcaption></figure><p id="59f9" class="pw-post-body-paragraph ly lz it ma b mb mr kd md me ms kg mg lm mt mi mj lq mu ml mm lu mv mo mp mq im bi translated">树突以电脉冲的形式接收来自其他神经元的信息。细胞体是接收和处理来自树突的信息的地方。这种处理的结果然后通过轴突传导，直到它到达末端(突触)。然后，信息通过一个称为突触过程的化学过程传递给另一个树突神经元。在整个人类生活中，许多神经元被创建和死亡，神经元之间的许多连接被创建，而其他连接则不复存在(这是一种过于简化的说法，但它让你了解了我们大脑的动态)。</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><p id="b4f6" class="pw-post-body-paragraph ly lz it ma b mb mr kd md me ms kg mg lm mt mi mj lq mu ml mm lu mv mo mp mq im bi translated">根据<a class="ae mw" href="https://en.wikipedia.org/wiki/Hebbian_theory" rel="noopener ugc nofollow" target="_blank">赫布边理论</a>，当它们之间的突触过程重复发生时，这些连接的强度会更大。换句话说，两个神经元一起放电越多，它们之间的联系就越强。另一方面，如果两个神经元从未一起被激发，它们的连接就会变弱。这条规则被称为<strong class="ma jd">赫布规则</strong>。</p><p id="0440" class="pw-post-body-paragraph ly lz it ma b mb mr kd md me ms kg mg lm mt mi mj lq mu ml mm lu mv mo mp mq im bi translated">一些人认为赫布法则是经典条件作用的一种形式<a class="ae mw" href="https://en.wikipedia.org/wiki/Classical_conditioning" rel="noopener ugc nofollow" target="_blank">(也称为巴甫洛夫学习)。经典条件反射是一种应用于刺激的联想学习形式。这个想法是将两种刺激联系在一起，这样它们就可以共享相同的反应。在巴甫洛夫的实验中，以他的名字命名这个概念的人，他训练他的狗，给它们食物，同时按铃。因为一旦给了狗食物，狗就会开始分泌唾液，在重复这个食物-铃的联系相当多的次数后，他的狗一听到铃响就开始分泌唾液。赫比学习也是如此:如果代表'<em class="nj">获取食物'</em>的最终神经元与流涎反应相关，并且如果'<em class="nj">听觉铃</em>'神经元和'<em class="nj">获取食物</em>'神经元之间的连接受到刺激，从而变得更强，那么在某个点激发'<em class="nj">听觉铃</em>'神经元就足以引起相同的流涎反应。</a></p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><p id="8b90" class="pw-post-body-paragraph ly lz it ma b mb mr kd md me ms kg mg lm mt mi mj lq mu ml mm lu mv mo mp mq im bi translated">1943 年，麦卡洛克和皮茨提出了一个数学模型，能够捕捉神经元的这些生物特征。图 2 描述了神经元的这种数学模型的模式。这个被称为<strong class="ma jd">麦卡洛克-皮茨神经元</strong>。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/2b58a3ae63f9faf200eab3813d8773f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*uXuRKXPSWDtbvZwPvh7S6A.png"/></div><figcaption class="my mz gj gh gi na nb bd b be z dk">Figure 2: Schema of the McCulloch-Pitts neuron</figcaption></figure><p id="f132" class="pw-post-body-paragraph ly lz it ma b mb mr kd md me ms kg mg lm mt mi mj lq mu ml mm lu mv mo mp mq im bi translated">麦卡洛克-皮茨神经元有三个组成部分:</p><ul class=""><li id="ef15" class="nl nm it ma b mb mr me ms lm nn lq no lu np mq nq nr ns nt bi translated"><strong class="ma jd">一组加权输入</strong>(<em class="nj">x</em>和<em class="nj"> w </em>)。它们分别代表输入和连接强度。赫布规则是关于刺激或减弱神经元之间的连接，取决于它对两个神经元一起放电的重要性。<em class="nj"> w </em>的角色就是这个意思:描述关系的优势。它们被称为权重，因为它们量化了连接的权重。<em class="nj"> x </em>映射到从突触中一个神经元的轴突末端传递到其他神经元的树突的输入。</li><li id="b33d" class="nl nm it ma b mb nu me nv lm nw lq nx lu ny mq nq nr ns nt bi translated"><strong class="ma jd">一个加法器</strong>(即<em class="nj"> z </em>)。这代表负责将所有输入信号整理和聚集成统一电脉冲的核/细胞体，该电脉冲稍后将沿着轴突传输。用数学术语来说，麦卡洛克和皮茨将这种聚合转化为输入(<em class="nj"> x </em>)和权重(<em class="nj"> w </em>)之间的点积。但这意味着什么呢？让我们使用图 2 中的例子。向量<em class="nj"> x </em>由<em class="nj"> x₀ </em>、<em class="nj"> x₁ </em>、<em class="nj"> x </em> ₂组成，而向量<em class="nj"> w </em>具有元素<em class="nj"> w₀ </em>、<em class="nj"> w₁ </em>、<em class="nj"> w </em> ₂ <em class="nj">。</em>那么 x 和 w 的点积就是:<em class="nj">x₀×w₀</em>﹢<em class="nj">x₁×w₁</em>﹢<em class="nj">x</em>₂<em class="nj">×w</em>₂.让我们用数学符号将这个逻辑形式化。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/c0d7728897ca464e43b45c61f7c9e931.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*qKwmVu2Sc7zAeXWHAAP18A.png"/></div></figure><ul class=""><li id="5b0c" class="nl nm it ma b mb mr me ms lm nn lq no lu np mq nq nr ns nt bi translated"><strong class="ma jd">一个激活功能</strong>(<em class="nj">f(z)</em>块)。激活功能的作用是决定整理后的信号的输出，并基于整理后的信号检查神经元是否应该触发。神经元的这一部分是一个数学函数，它抓取<em class="nj"> z </em>并基于该函数计算输出<em class="nj"> y </em>。麦卡洛克和皮茨提出的方法是阈值函数。基本上定义一个阈值电平𝜃，如果 z 大于𝜃，输出将是<em class="nj"> 1 </em>，否则输出将是<em class="nj"> 0 </em>。</li></ul><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/61e482517196e31db65a418dee92fb0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*OFdY7Btw8k_GbZGidKFhgg.png"/></div></figure><p id="7415" class="pw-post-body-paragraph ly lz it ma b mb mr kd md me ms kg mg lm mt mi mj lq mu ml mm lu mv mo mp mq im bi translated">让我们尝试一个端到端的例子。想象你有一个神经元，它有输入:<em class="nj"> x₀﹦2 </em>，<em class="nj"> x₁﹦-0.75 </em>，<em class="nj"> x </em> ₂﹦ <em class="nj"> 2 </em>，还有权重<em class="nj"> w₀﹦-1 </em>，<em class="nj"> w₁﹦-1 </em>，<em class="nj"> w </em> ₂﹦ <em class="nj"> 1 </em>。所以，要做的第一件事就是计算 z。根据之前定义的方程，<em class="nj">z</em>﹦<em class="nj">2×(-1)</em>﹢(<em class="nj">-0.75)×(-1)</em>﹢<em class="nj">2×1</em>﹦<em class="nj">0.75</em>。<em class="nj"> </em>最后一步是计算激活函数<em class="nj"> f(z) </em>。例如，让我们假设一个𝜃﹦为 0 的阈值函数。因为<em class="nj"> 0.75 </em> &gt; <em class="nj"> 0 </em>我们的输出会是<em class="nj"> 1 </em>。</p><p id="bf55" class="pw-post-body-paragraph ly lz it ma b mb mr kd md me ms kg mg lm mt mi mj lq mu ml mm lu mv mo mp mq im bi translated">我已经解释了最基本的神经网络是如何工作的。但真的是全部吗？你现在已经理解了网络如何基于外部输入或来自环境的传感器来计算其输出/预测/结果，但是在这个解释中描述的学习过程在哪里呢？答案是:无处！神经网络学习的方式是通过找到向量<em class="nj"> w </em>的正确值，这些值将增加网络根据提供的输入正确猜测答案的次数。向量<em class="nj"> w </em>在很大程度上是神经网络中的“内部”,因此尝试不同的值是我们可以用来训练网络的。那么这些权重<em class="nj"> w </em>如何修改才能提高网络质量呢？我将在我的下一章:感知机网络中谈论这个。敬请期待！</p></div><div class="ab cl nc nd hx ne" role="separator"><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh ni"/><span class="nf bw bk ng nh"/></div><div class="im in io ip iq"><p id="e0cf" class="pw-post-body-paragraph ly lz it ma b mb mr kd md me ms kg mg lm mt mi mj lq mu ml mm lu mv mo mp mq im bi translated">感谢阅读！你喜欢这篇文章吗？非常感谢你的反馈，🗣。你可以随时在<a class="ae mw" href="https://twitter.com/adrianovinhas" rel="noopener ugc nofollow" target="_blank"> <strong class="ma jd"> Twitter </strong> </a>或<a class="ae mw" href="https://www.linkedin.com/in/adrianovinhas/" rel="noopener ugc nofollow" target="_blank"> <strong class="ma jd"> LinkedIn </strong> </a>上联系我，或者如果你对下一章的最新消息感兴趣，就在 Medium 上关注我😀。</p><p id="023b" class="pw-post-body-paragraph ly lz it ma b mb mr kd md me ms kg mg lm mt mi mj lq mu ml mm lu mv mo mp mq im bi translated">一些相关阅读:</p><ul class=""><li id="39fd" class="nl nm it ma b mb mr me ms lm nn lq no lu np mq nq nr ns nt bi translated">【1】<a class="ae mw" rel="noopener" target="_blank" href="/introduction-to-neural-networks-advantages-and-applications-96851bd1a207">神经网络简介、优势及应用</a>作者<a class="ob oc ep" href="https://medium.com/u/17a6dbe78d34?source=post_page-----14e5c02bafe--------------------------------" rel="noopener" target="_blank">Jahnavi Mahanta</a>；</li><li id="ed0b" class="nl nm it ma b mb nu me nv lm nw lq nx lu ny mq nq nr ns nt bi translated">【2】<a class="ae mw" href="https://medium.com/@johnolafenwa/introduction-to-neural-networks-ca7eab1d27d7" rel="noopener">神经网络简介</a>作者<a class="ob oc ep" href="https://medium.com/u/90303d006c1a?source=post_page-----14e5c02bafe--------------------------------" rel="noopener" target="_blank">约翰·奥拉芬瓦</a>；</li><li id="0c09" class="nl nm it ma b mb nu me nv lm nw lq nx lu ny mq nq nr ns nt bi translated">[3] <a class="ae mw" rel="noopener" target="_blank" href="/a-visual-introduction-to-neural-networks-68586b0b733b">对神经网络的可视化介绍</a>作者<a class="ob oc ep" href="https://medium.com/u/9947e090b1d1?source=post_page-----14e5c02bafe--------------------------------" rel="noopener" target="_blank">shik har Sharma</a>；</li><li id="8681" class="nl nm it ma b mb nu me nv lm nw lq nx lu ny mq nq nr ns nt bi translated">[4] <a class="ae mw" href="https://medium.com/@tharanignanasegaram/artificial-neural-network-a-brief-introduction-572d462666f1" rel="noopener">人工神经网络——简介</a>作者<a class="ob oc ep" href="https://medium.com/u/faf652cfc457?source=post_page-----14e5c02bafe--------------------------------" rel="noopener" target="_blank"> Tharani Gnanasegaram </a>。</li><li id="01ab" class="nl nm it ma b mb nu me nv lm nw lq nx lu ny mq nq nr ns nt bi translated">【5】<a class="ae mw" rel="noopener" target="_blank" href="/mcculloch-pitts-model-5fdf65ac5dd1">麦卡洛克-皮茨神经元——人类第一个生物神经元的数学模型</a>作者<a class="ob oc ep" href="https://medium.com/u/202534492f47?source=post_page-----14e5c02bafe--------------------------------" rel="noopener" target="_blank">阿克谢·钱德拉·拉甘杜拉</a></li></ul></div></div>    
</body>
</html>