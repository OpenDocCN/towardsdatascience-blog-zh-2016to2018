<html>
<head>
<title>Fashion MNIST Classification with TensorFlow featuring Deepmind Sonnet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">时尚 MNIST 分类与 TensorFlow 特色 Deepmind 十四行诗</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fashion-mnist-classification-with-tensorflow-featuring-deepmind-sonnet-aeb3987d826e?source=collection_archive---------5-----------------------#2018-08-11">https://towardsdatascience.com/fashion-mnist-classification-with-tensorflow-featuring-deepmind-sonnet-aeb3987d826e?source=collection_archive---------5-----------------------#2018-08-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="5b0a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这篇文章中，我们将看看如何使用 TensorFlow (TF)和 Deepmind 的十四行诗库在时尚 MNIST 数据集上执行一个简单的分类任务。</p><p id="a41c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇文章也可以作为合作笔记本使用。请随意将笔记本复制到您的驱动器上，并修改代码。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/8ee5c35fa1f04b865e715a929c9839e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:64/format:webp/0*o6Q0aRyERP3elscS.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><a class="ae kx" href="https://colab.research.google.com/drive/0BztMifQrkZdTQjh3cWVsSUs4OGs?resourcekey=0-NNX5nsJgR-p-0_e09ZHz3g" rel="noopener ugc nofollow" target="_blank">Run in Colab</a></figcaption></figure><p id="095b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我写这篇文章的目的有两个:</p><ol class=""><li id="8d39" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk ld le lf lg bi translated">展示如何在一个简单的机器学习(ML)任务中使用 TF 提供的附加功能。</li><li id="37b1" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">作为 Deepmind 的<a class="ae kx" href="https://deepmind.github.io/sonnet/" rel="noopener ugc nofollow" target="_blank">十四行诗</a>库的一个简单入门示例。</li></ol><p id="379f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">大部分解释都是以代码中注释的形式出现的，所以可以考虑和文章一起阅读代码。这篇文章是在假设读者对 ML 和 TF 框架有基本了解的情况下撰写的。也就是说，我试图提供外部链接到所使用的技术术语。</p><p id="d1c6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先让我们安装 sonnet。通过命令行进行简单的 pip 安装就可以了，但是要确保安装了 TensorFlow 并且版本&gt; = 1.5</p><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="a96c" class="lr ls iq ln b gy lt lu l lv lw">$ pip install dm-sonnet</span></pre><p id="78fe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">假设安装了其他库，我们将导入所需的 python 库。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="lx ly l"/></div></figure><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="16c7" class="lr ls iq ln b gy lt lu l lv lw"><strong class="ln ir">[Out]</strong><br/>Tensorflow version: 1.10.0-rc1</span></pre><h1 id="d6ae" class="lz ls iq bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">时尚 MNIST 数据集</h1><p id="7038" class="pw-post-body-paragraph jn jo iq jp b jq mw js jt ju mx jw jx jy my ka kb kc mz ke kf kg na ki kj kk ij bi translated">更传统的 MNIST 数据集已经被过度使用到了一定程度(99%以上的准确率)，不再是一个有价值的分类问题。<a class="ae kx" href="https://research.zalando.com/" rel="noopener ugc nofollow" target="_blank"> Zalando Research </a>为机器学习研究提供了一个新起点，在 28x28 的图像中捕捉 10 种不同的服装，而不是 10 个数字。这 10 种服装的各种变化构成了<a class="ae kx" href="https://github.com/zalandoresearch/fashion-mnist" rel="noopener ugc nofollow" target="_blank">时尚 MNIST </a>数据集。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="nc nd di ne bf nf"><div class="gh gi nb"><img src="../Images/f875e8cdff300768b54ee7ddf55bc63f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Besobl3-MJUhXTvg.png"/></div></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><strong class="bd ng">A Sample from the Fashion MNIST dataset (Credit: Zalando, MIT License)</strong></figcaption></figure><p id="eec4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用<a class="ae kx" href="https://www.tensorflow.org/guide/keras" rel="noopener ugc nofollow" target="_blank">Keras</a>(tensor flow 的高级 API)我们可以通过一个函数调用直接下载时尚 MNIST。由于它相对较小(70K 记录)，我们将把它直接加载到内存中。</p><h2 id="0020" class="lr ls iq bd ma nh ni dn me nj nk dp mi jy nl nm mm kc nn no mq kg np nq mu nr bi translated">预处理数据集</h2><p id="0cba" class="pw-post-body-paragraph jn jo iq jp b jq mw js jt ju mx jw jx jy my ka kb kc mz ke kf kg na ki kj kk ij bi translated">由于数据集是为 ML 研究手工制作的，我们不需要进行<a class="ae kx" href="https://en.wikipedia.org/wiki/Data_wrangling" rel="noopener ugc nofollow" target="_blank">数据争论</a>。我们需要的唯一预处理是均值居中和方差归一化。所得的数据分布将具有球形结构，导致梯度下降收敛的步骤数量较少。参考 LeCun，Yann A .等人的<a class="ae kx" href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf" rel="noopener ugc nofollow" target="_blank">第 5.3 节“有效反推”</a>关于为什么我们需要进行居中和归一化以实现梯度下降的更快收敛的精确解释。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="lx ly l"/></div></figure><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="d683" class="lr ls iq ln b gy lt lu l lv lw"><strong class="ln ir">[Out]<br/></strong>Downloading data from <a class="ae kx" href="https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz" rel="noopener ugc nofollow" target="_blank">https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz</a><br/>32768/29515 [=================================] - 0s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz <br/>26427392/26421880 [==============================] - 1s 0us/step Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz <br/>8192/5148 [===============================================] - 0s 0us/step <br/>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz <br/>4423680/4422102 [==============================] - 0s 0us/step Training Data ::: Images Shape: (60000, 28, 28), Labels Shape: (60000,) <br/>Test Data ::: Images Shape: (10000, 28, 28), Labels Shape: (10000,) Random 25 Images from the Training Data:</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/8ca67f2a71301bfd9b0a73c337ece4b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/0*191xAy-k6RuluaDU.png"/></div></figure><h1 id="129f" class="lz ls iq bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">构建模型</h1><p id="dfa6" class="pw-post-body-paragraph jn jo iq jp b jq mw js jt ju mx jw jx jy my ka kb kc mz ke kf kg na ki kj kk ij bi translated">使用 Deepmind 的十四行诗库，我们将建立两个模型，一个是简单的多层感知器(MLP)，另一个是卷积网络。然后，我们将设置训练设备，以便在两个模型之间切换是一个简单的配置参数。</p><p id="2fd5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">顺便说一下，<a class="ae kx" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>是另一个高级 API，从 TF v1.9 开始，它就紧密集成到 TF 中。快速原型对于任何 ML 研究项目都是有用的，Keras 和 Sonnet 在这方面都非常有用。诚然，Keras 是一个更加成熟的项目，并且有 TF 团队的官方支持。此外，互联网上有大量的 Keras 教程和项目，再增加一个没有任何意义。另一方面，十四行诗很少在 Deepmind 之外使用，但对于任何跟踪他们的研究的人来说都是必须知道的。</p><h2 id="ff52" class="lr ls iq bd ma nh ni dn me nj nk dp mi jy nl nm mm kc nn no mq kg np nq mu nr bi translated">深度思维十四行诗</h2><p id="db80" class="pw-post-body-paragraph jn jo iq jp b jq mw js jt ju mx jw jx jy my ka kb kc mz ke kf kg na ki kj kk ij bi translated">Sonnet 是来自 Deepmind 的 TensorFlow 库，它抽象出了建模的过程。sonnet 的宗旨是将模型的组件封装为 python 对象(模块),然后可以在需要时插入到 TF 图中，从而为代码重用提供无缝机制。这样的设计让我们不必担心内部配置，如变量重用、重量共享等。有关详细指南，请参考他们的官方<a class="ae kx" href="https://deepmind.github.io/sonnet/" rel="noopener ugc nofollow" target="_blank">文档</a>。此外，它们的源代码有很好的文档记录，值得一读，尤其是在尝试实现某些东西时。</p><p id="6ab3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们的例子中，我们将创建两个模块:<code class="fe nt nu nv ln b">FMNISTMLPClassifier</code>和<code class="fe nt nu nv ln b">FMNISTConvClassifier</code>。顾名思义<code class="fe nt nu nv ln b">FMNISTMLPClassifier</code>用的是 MLP，<code class="fe nt nu nv ln b">FMNISTConvClassifier</code>用的是卷积神经网络。然后，我们将在 TensorFlow 中设置训练设备，然后插入我们想要训练的模型。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="lx ly l"/></div></figure><h1 id="0126" class="lz ls iq bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">组装训练器材。</h1><p id="008e" class="pw-post-body-paragraph jn jo iq jp b jq mw js jt ju mx jw jx jy my ka kb kc mz ke kf kg na ki kj kk ij bi translated"><em class="nw">训练器械</em>包含以下部件:</p><ol class=""><li id="dce0" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk ld le lf lg bi translated">数据通过输入管道输入到模型中</li><li id="7910" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">执行梯度下降的优化算法。</li><li id="925c" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">将由优化器优化的损失函数。</li><li id="904f" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">正在接受训练的模型。</li></ol><h2 id="2cf8" class="lr ls iq bd ma nh ni dn me nj nk dp mi jy nl nm mm kc nn no mq kg np nq mu nr bi translated">输入管道</h2><p id="2092" class="pw-post-body-paragraph jn jo iq jp b jq mw js jt ju mx jw jx jy my ka kb kc mz ke kf kg na ki kj kk ij bi translated">在 TensorFlow 中，向模型提供数据的首选方式是使用<code class="fe nt nu nv ln b"><a class="ae kx" href="https://www.tensorflow.org/api_docs/python/tf/data" rel="noopener ugc nofollow" target="_blank">tf.data</a></code>模块。它允许我们以简单和可重用的方式对输入数据进行转换。<code class="fe nt nu nv ln b">tf.data</code>模块允许我们设计输入管道，比如聚合来自多个来源的数据，以可插拔的方式添加复杂的数据操作任务等。在这个例子中，我们展示了它的基本功能，鼓励读者浏览官方的<a class="ae kx" href="https://www.tensorflow.org/guide/datasets" rel="noopener ugc nofollow" target="_blank">指南</a>。</p><p id="7f25" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们希望输入管道具有以下三个属性:</p><ol class=""><li id="d770" class="ky kz iq jp b jq jr ju jv jy la kc lb kg lc kk ld le lf lg bi translated">能够在训练和测试数据集之间无缝切换，允许我们在每个<a class="ae kx" rel="noopener" target="_blank" href="/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9">时期</a>后执行评估。</li><li id="733a" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">打乱数据集，以避免从磁盘上的数据排序中了解到意外的关联。</li><li id="4d52" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated">对随机梯度下降的数据集进行批处理。</li></ol><p id="2b37" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在单个时期中，训练循环将包含覆盖整个数据集的多个小批量训练，然后是对测试数据集的准确度评估。</p><h2 id="bf8d" class="lr ls iq bd ma nh ni dn me nj nk dp mi jy nl nm mm kc nn no mq kg np nq mu nr bi translated">【计算机】优化程序</h2><p id="b864" class="pw-post-body-paragraph jn jo iq jp b jq mw js jt ju mx jw jx jy my ka kb kc mz ke kf kg na ki kj kk ij bi translated">Adam(自适应矩估计)优化器是随机梯度下降的变体。在许多其他技术中，Adam 对每个参数使用自适应学习率。这允许与不常见的特征相关联的参数具有积极的学习率，而与常见特征相关联的参数具有低学习率。有关不同 SGD 优化器的详细说明，请阅读这篇精彩的<a class="ae kx" href="http://ruder.io/optimizing-gradient-descent/" rel="noopener ugc nofollow" target="_blank">帖子</a>。</p><h2 id="35dd" class="lr ls iq bd ma nh ni dn me nj nk dp mi jy nl nm mm kc nn no mq kg np nq mu nr bi translated">损失函数</h2><p id="2e0a" class="pw-post-body-paragraph jn jo iq jp b jq mw js jt ju mx jw jx jy my ka kb kc mz ke kf kg na ki kj kk ij bi translated">对模型的输出执行 softmax 后，评估交叉熵损失。更多详情<a class="ae kx" href="http://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><h2 id="8144" class="lr ls iq bd ma nh ni dn me nj nk dp mi jy nl nm mm kc nn no mq kg np nq mu nr bi translated">模型</h2><p id="7961" class="pw-post-body-paragraph jn jo iq jp b jq mw js jt ju mx jw jx jy my ka kb kc mz ke kf kg na ki kj kk ij bi translated">这里我们将使用我们用 Sonnet 构建的模型。我们将设置培训，以便根据配置参数值交换两种型号(MLP 和康文网络)。</p><p id="898f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们把所有的组件放在一起。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="lx ly l"/></div></figure><pre class="km kn ko kp gt lm ln lo lp aw lq bi"><span id="8599" class="lr ls iq ln b gy lt lu l lv lw"><strong class="ln ir">[Out]</strong><br/>Epoch 1 ::: Training Time: 27.48s, Training Loss: 0.35541, Training Accuracy: 0.82533, Test Accuracy: 0.86060 <br/>Epoch 2 ::: Training Time: 26.22s, Training Loss: 0.27885, Training Accuracy: 0.88165, Test Accuracy: 0.88280 <br/>Epoch 3 ::: Training Time: 25.68s, Training Loss: 0.25212, Training Accuracy: 0.89918, Test Accuracy: 0.88710 <br/>Epoch 4 ::: Training Time: 25.82s, Training Loss: 0.21601, Training Accuracy: 0.91033, Test Accuracy: 0.89750 <br/>Epoch 5 ::: Training Time: 26.27s, Training Loss: 0.18370, Training Accuracy: 0.91778, Test Accuracy: 0.90500 <br/>Epoch 6 ::: Training Time: 25.84s, Training Loss: 0.19794, Training Accuracy: 0.92612, Test Accuracy: 0.89190 <br/>Epoch 7 ::: Training Time: 26.45s, Training Loss: 0.15230, Training Accuracy: 0.93163, Test Accuracy: 0.90500 <br/>Epoch 8 ::: Training Time: 25.84s, Training Loss: 0.15200, Training Accuracy: 0.93763, Test Accuracy: 0.90360 <br/>Epoch 9 ::: Training Time: 25.85s, Training Loss: 0.12375, Training Accuracy: 0.94403, Test Accuracy: 0.90550 <br/>Epoch 10 ::: Training Time: 26.06s, Training Loss: 0.11385, Training Accuracy: 0.95010, Test Accuracy: 0.91050</span></pre><p id="6986" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">就是这样，我们训练了一个卷积神经网络模型，对时尚 MNIST 数据集进行分类，测试准确率<strong class="jp ir"> 91.050% </strong>。要训练基于 MLP 的模型，只需在<code class="fe nt nu nv ln b">train</code>函数调用中将<code class="fe nt nu nv ln b">'conv'</code>改为<code class="fe nt nu nv ln b">'mlp'</code>。</p><p id="666e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这篇文章的完整代码可以在 GitHub 上找到:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/41adca11e39668e9cba4019276fe6940.png" data-original-src="https://miro.medium.com/v2/resize:fit:64/format:webp/0*EJhWSVqWx3AzHcwu.png"/></div><figcaption class="kt ku gj gh gi kv kw bd b be z dk"><a class="ae kx" href="https://github.com/surajx/Fashion-MNIST-Sonnet" rel="noopener ugc nofollow" target="_blank">View on GitHub</a></figcaption></figure><h1 id="4c9f" class="lz ls iq bd ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv bi translated">参考</h1><ol class=""><li id="35b9" class="ky kz iq jp b jq mw ju mx jy nx kc ny kg nz kk ld le lf lg bi translated"><a class="ae kx" href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf" rel="noopener ugc nofollow" target="_blank"> LeCun，Yann A .等人《有效的反向投影》</a></li><li id="5081" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated"><a class="ae kx" href="https://deepmind.github.io/sonnet/" rel="noopener ugc nofollow" target="_blank"> Deepmind 十四行诗</a></li><li id="074f" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated"><a class="ae kx" href="https://github.com/zalandoresearch/fashion-mnist" rel="noopener ugc nofollow" target="_blank">时尚 MNIST </a></li><li id="5b8b" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated"><a class="ae kx" href="https://www.tensorflow.org/tutorials/keras/basic_classification" rel="noopener ugc nofollow" target="_blank">来自 TF 指南的基本分类</a></li><li id="d335" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated"><a class="ae kx" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank"> CS231n 斯坦福课程笔记</a></li><li id="ee48" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated"><a class="ae kx" href="http://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html" rel="noopener ugc nofollow" target="_blank"> ML 备忘单损失函数</a></li><li id="9990" class="ky kz iq jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated"><a class="ae kx" href="https://steemit.com/machine-learning/@ronny.rest/avoiding-headaches-with-tf-metrics" rel="noopener ugc nofollow" target="_blank"> TF 指标</a></li></ol></div><div class="ab cl oa ob hu oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="ij ik il im in"><p id="2db1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="nw">最初发布于</em><a class="ae kx" href="https://www.surajx.in/2018/08/fashion-mnist-classification-with-tensorflow-featuring-deepmind-sonnet/" rel="noopener ugc nofollow" target="_blank"><em class="nw">https://www . surajx . in/2018/08/fashion-mnist-class ification-with-tensor flow-featured-deep mind-sonnet/</em></a><em class="nw">。</em></p></div></div>    
</body>
</html>