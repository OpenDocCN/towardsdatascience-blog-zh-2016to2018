<html>
<head>
<title>GAN by Example using Keras on Tensorflow Backend</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Tensorflow 后端使用 Keras 的 GAN 示例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gan-by-example-using-keras-on-tensorflow-backend-1a6d515a60d0?source=collection_archive---------0-----------------------#2017-03-30">https://towardsdatascience.com/gan-by-example-using-keras-on-tensorflow-backend-1a6d515a60d0?source=collection_archive---------0-----------------------#2017-03-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="6a6d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">生成对抗网络(GAN)是深度学习领域最有前途的新发展之一。<a class="ae kl" href="http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf" rel="noopener ugc nofollow" target="_blank"> GAN </a>由 Ian Goodfellow 于 2014 年提出，通过训练两个相互竞争和合作的深度网络(称为生成器和鉴别器)来解决无监督学习的问题。在训练过程中，两个网络最终都学会了如何执行它们的任务。</p><p id="85d2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">甘几乎总是被解释为伪造者(生殖)和警察(鉴别者)。最初，伪造者会向警察出示假币。警察说是假的。警察向造假者反馈为什么钱是假的。伪造者试图根据收到的反馈制造新的假币。警方表示，这些钱仍然是假的，并提供了一套新的反馈。伪造者试图根据最新的反馈制造新的假币。这种循环无限期地继续下去，直到警察被假钱所愚弄，因为它看起来像真的。</p><p id="36f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">尽管 GAN 的想法在理论上很简单，但要建立一个可行的模型却非常困难。在 GAN 中，有两个耦合在一起的深层网络，使得梯度的反向传播具有两倍的挑战性。<a class="ae kl" href="https://arxiv.org/pdf/1511.06434.pdf%C3%AF%C2%BC%E2%80%B0" rel="noopener ugc nofollow" target="_blank">深度卷积 GAN (DCGAN) </a>是演示如何构建实用 GAN 的模型之一，它能够自学如何合成新图像。</p><p id="8f36" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我们将讨论如何在 Tensorflow 1.0 后端上使用 Keras 2.0 用不到 200 行代码构建一个有效的 DCGAN。我们将训练一只 DCGAN 学习如何书写手写数字，用 MNIST 的方式。</p><h1 id="073e" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">鉴别器</strong></h1><p id="61b8" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">辨别图像真实程度的鉴别器基本上是一个深度卷积神经网络(CNN ),如图 1 所示。对于 MNIST 数据集，输入是图像(28 像素 x 28 像素 x 1 通道)。sigmoid 输出是图像真实程度概率的标量值(0.0 肯定是假的，1.0 肯定是真实的，介于两者之间的任何值都是灰色区域)。与典型的 CNN 的区别在于层间没有最大池。相反，步长卷积用于下采样。在每个 CNN 层中使用的激活函数是一个泄漏 ReLU。层间 0.4 和 0.7 之间的压差防止过拟合和记忆。清单 1 展示了 Keras 中的实现。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/71b441ae4e7c8638f20b8a38b9d70f6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QHMGABbwL04x5VGYc_UWSA.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Figure 1. Discriminator of DCGAN tells how real an input image of a digit is. MNIST Dataset is used as ground truth for real images. Strided convolution instead of max-pooling down samples the image.</figcaption></figure><pre class="lq lr ls lt gt mf mg mh mi aw mj bi"><span id="71c5" class="mk kn iq mg b gy ml mm l mn mo">self.D = Sequential()</span><span id="00f3" class="mk kn iq mg b gy mp mm l mn mo">depth = 64</span><span id="b551" class="mk kn iq mg b gy mp mm l mn mo">dropout = 0.4</span><span id="55da" class="mk kn iq mg b gy mp mm l mn mo"># In: 28 x 28 x 1, depth = 1</span><span id="b714" class="mk kn iq mg b gy mp mm l mn mo"># Out: 14 x 14 x 1, depth=64</span><span id="4f98" class="mk kn iq mg b gy mp mm l mn mo">input_shape = (self.img_rows, self.img_cols, self.channel)</span><span id="90c9" class="mk kn iq mg b gy mp mm l mn mo">self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=input_shape,\</span><span id="7f00" class="mk kn iq mg b gy mp mm l mn mo">padding='same', activation=LeakyReLU(alpha=0.2)))</span><span id="0985" class="mk kn iq mg b gy mp mm l mn mo">self.D.add(Dropout(dropout))</span><span id="14bf" class="mk kn iq mg b gy mp mm l mn mo">self.D.add(Conv2D(depth*2, 5, strides=2, padding='same',\</span><span id="2ebe" class="mk kn iq mg b gy mp mm l mn mo">activation=LeakyReLU(alpha=0.2)))</span><span id="928d" class="mk kn iq mg b gy mp mm l mn mo">self.D.add(Dropout(dropout))</span><span id="fb38" class="mk kn iq mg b gy mp mm l mn mo">self.D.add(Conv2D(depth*4, 5, strides=2, padding='same',\</span><span id="349e" class="mk kn iq mg b gy mp mm l mn mo">activation=LeakyReLU(alpha=0.2)))</span><span id="9843" class="mk kn iq mg b gy mp mm l mn mo">self.D.add(Dropout(dropout))</span><span id="db93" class="mk kn iq mg b gy mp mm l mn mo">self.D.add(Conv2D(depth*8, 5, strides=1, padding='same',\</span><span id="104f" class="mk kn iq mg b gy mp mm l mn mo">activation=LeakyReLU(alpha=0.2)))</span><span id="49e7" class="mk kn iq mg b gy mp mm l mn mo">self.D.add(Dropout(dropout))</span><span id="3477" class="mk kn iq mg b gy mp mm l mn mo"># Out: 1-dim probability</span><span id="d9ad" class="mk kn iq mg b gy mp mm l mn mo">self.D.add(Flatten())</span><span id="fa59" class="mk kn iq mg b gy mp mm l mn mo">self.D.add(Dense(1))</span><span id="af5b" class="mk kn iq mg b gy mp mm l mn mo">self.D.add(Activation('sigmoid'))</span><span id="f05f" class="mk kn iq mg b gy mp mm l mn mo">self.D.summary()</span></pre><p id="7a3d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">清单 1。图 1 中鉴别器的 Keras 代码。</p><h1 id="f3d3" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">发电机</h1><p id="b3b6" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">生成器合成假图像。在图 2 中，假图像是使用卷积的逆运算(称为转置卷积)从 100 维噪声(均匀分布在-1.0 到 1.0 之间)生成的。使用前三层之间的上采样，而不是 DCGAN 中建议的分数步长卷积，因为它合成了更真实的手写图像。在各层之间，批量标准化稳定了学习。每一层之后的激活函数是一个 ReLU。最后一层的 sigmoid 的输出产生假图像。第一层 0.3 至 0.5 之间的压差可防止过度拟合。清单 2 展示了 Keras 中的实现。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mq"><img src="../Images/99faaad2058ff2edbd84cb24c0b8bb2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gvBT3h4JD7eUN0GexHwx2w.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Figure 2. Generator model synthesizes fake MNIST images from noise. Upsampling is used instead of fractionally-strided transposed convolution.</figcaption></figure><pre class="lq lr ls lt gt mf mg mh mi aw mj bi"><span id="cf56" class="mk kn iq mg b gy ml mm l mn mo">self.G = Sequential()</span><span id="57eb" class="mk kn iq mg b gy mp mm l mn mo">dropout = 0.4</span><span id="c7be" class="mk kn iq mg b gy mp mm l mn mo">depth = 64+64+64+64</span><span id="b2c3" class="mk kn iq mg b gy mp mm l mn mo">dim = 7</span><span id="5959" class="mk kn iq mg b gy mp mm l mn mo"># In: 100</span><span id="b278" class="mk kn iq mg b gy mp mm l mn mo"># Out: dim x dim x depth</span><span id="32f5" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(Dense(dim*dim*depth, input_dim=100))</span><span id="c503" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(BatchNormalization(momentum=0.9))</span><span id="cb34" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(Activation('relu'))</span><span id="2924" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(Reshape((dim, dim, depth)))</span><span id="44b1" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(Dropout(dropout))</span><span id="f257" class="mk kn iq mg b gy mp mm l mn mo"># In: dim x dim x depth</span><span id="cee5" class="mk kn iq mg b gy mp mm l mn mo"># Out: 2*dim x 2*dim x depth/2</span><span id="b462" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(UpSampling2D())</span><span id="8e59" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(Conv2DTranspose(int(depth/2), 5, padding='same'))</span><span id="530b" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(BatchNormalization(momentum=0.9))</span><span id="efb9" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(Activation('relu'))</span><span id="9388" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(UpSampling2D())</span><span id="c979" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(Conv2DTranspose(int(depth/4), 5, padding='same'))</span><span id="139b" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(BatchNormalization(momentum=0.9))</span><span id="0bb9" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(Activation('relu'))</span><span id="2c8d" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(Conv2DTranspose(int(depth/8), 5, padding='same'))</span><span id="1bce" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(BatchNormalization(momentum=0.9))</span><span id="c4e6" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(Activation('relu'))</span><span id="7843" class="mk kn iq mg b gy mp mm l mn mo"># Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix</span><span id="65a3" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(Conv2DTranspose(1, 5, padding='same'))</span><span id="0a25" class="mk kn iq mg b gy mp mm l mn mo">self.G.add(Activation('sigmoid'))</span><span id="2345" class="mk kn iq mg b gy mp mm l mn mo">self.G.summary()</span><span id="c458" class="mk kn iq mg b gy mp mm l mn mo">return self.G</span></pre><p id="156d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">清单 2。图 2 中生成器的 Keras 代码。</p><h1 id="a0c2" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">GAN 模型</h1><p id="0e78" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">到目前为止，还没有模型。是时候为训练建立模型了。我们需要两个模型:1)鉴别器模型(警察)和 2)对抗模型或生成器-鉴别器(伪造者向警察学习)。</p><h1 id="b2cb" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">鉴别器模型</h1><p id="3945" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">清单 3 展示了鉴别器模型的 Keras 代码。它是上面描述的鉴别器，具有为训练定义的损失函数。由于鉴频器的输出是 sigmoid，我们使用二进制交叉熵来计算损耗。在这种情况下，RMSProp 作为优化器生成了比 Adam 更真实的假图像。学习率 0.0008。权重衰减和剪辑值在训练的后半部分稳定学习。你要调整学习率就要调整衰减。</p><pre class="lq lr ls lt gt mf mg mh mi aw mj bi"><span id="f0f2" class="mk kn iq mg b gy ml mm l mn mo">optimizer = RMSprop(lr=0.0008, clipvalue=1.0, decay=6e-8)</span><span id="9a8f" class="mk kn iq mg b gy mp mm l mn mo">self.DM = Sequential()</span><span id="7fcd" class="mk kn iq mg b gy mp mm l mn mo">self.DM.add(self.discriminator())</span><span id="dce8" class="mk kn iq mg b gy mp mm l mn mo">self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\</span><span id="fc2f" class="mk kn iq mg b gy mp mm l mn mo">metrics=['accuracy'])</span></pre><p id="4e78" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">清单 3。鉴别器模型在 Keras 中实现。</p><h1 id="bf86" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">对抗模式</h1><p id="86a5" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">对抗模型只是如图 3 所示的生成器-鉴别器堆叠在一起。生成器部分试图欺骗鉴别器，同时从它的反馈中学习。清单 4 展示了使用 Keras 代码的实现。训练参数与鉴别器模型中的相同，除了降低的学习速率和相应的权重衰减。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mr"><img src="../Images/6de0c2702e5cd71bfa68b4e952e6dbc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PIpd1jHbPc2QrTOPhvxoaw.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Figure 3. The Adversarial model is simply generator with its output connected to the input of the discriminator. Also shown is the training process wherein the Generator labels its fake image output with 1.0 trying to fool the Discriminator.</figcaption></figure><pre class="lq lr ls lt gt mf mg mh mi aw mj bi"><span id="c9fb" class="mk kn iq mg b gy ml mm l mn mo">optimizer = RMSprop(lr=0.0004, clipvalue=1.0, decay=3e-8)</span><span id="e2b1" class="mk kn iq mg b gy mp mm l mn mo">self.AM = Sequential()</span><span id="e74a" class="mk kn iq mg b gy mp mm l mn mo">self.AM.add(self.generator())</span><span id="c8ff" class="mk kn iq mg b gy mp mm l mn mo">self.AM.add(self.discriminator())</span><span id="c292" class="mk kn iq mg b gy mp mm l mn mo">self.AM.compile(loss='binary_crossentropy', optimizer=optimizer,\</span><span id="45f1" class="mk kn iq mg b gy mp mm l mn mo">metrics=['accuracy'])</span></pre><p id="3410" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">清单 4。在 Keras 中实现的对抗模型如图 3 所示。</p><h1 id="5790" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">训练</strong></h1><p id="4421" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">训练是最难的部分。我们首先通过用真实和虚假图像单独训练鉴别器模型来确定鉴别器模型是否正确。然后，依次训练鉴别模型和对抗模型。图 4 显示了鉴别模型，而图 3 显示了训练期间的对抗模型。清单 5 展示了 Keras 中的训练代码。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ms"><img src="../Images/e157221997fa562d1152dc17d9820fa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N3nT9AXVnsFBta2R1eEMjg.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Figure 4. Discriminator model is trained to distinguish real from fake handwritten images.</figcaption></figure><pre class="lq lr ls lt gt mf mg mh mi aw mj bi"><span id="54dd" class="mk kn iq mg b gy ml mm l mn mo">images_train = self.x_train[np.random.randint(0,</span><span id="7300" class="mk kn iq mg b gy mp mm l mn mo">self.x_train.shape[0], size=batch_size), :, :, :]</span><span id="2da9" class="mk kn iq mg b gy mp mm l mn mo">noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])</span><span id="01e9" class="mk kn iq mg b gy mp mm l mn mo">images_fake = self.generator.predict(noise)</span><span id="d50d" class="mk kn iq mg b gy mp mm l mn mo">x = np.concatenate((images_train, images_fake))</span><span id="1920" class="mk kn iq mg b gy mp mm l mn mo">y = np.ones([2*batch_size, 1])</span><span id="6dae" class="mk kn iq mg b gy mp mm l mn mo">y[batch_size:, :] = 0</span><span id="851f" class="mk kn iq mg b gy mp mm l mn mo">d_loss = self.discriminator.train_on_batch(x, y)</span><span id="2dbd" class="mk kn iq mg b gy mp mm l mn mo">y = np.ones([batch_size, 1])</span><span id="86bd" class="mk kn iq mg b gy mp mm l mn mo">noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])</span><span id="702b" class="mk kn iq mg b gy mp mm l mn mo">a_loss = self.adversarial.train_on_batch(noise, y)</span></pre><p id="c490" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">清单 5。鉴别模型和对抗模型的序贯训练。超过 1000 步的训练会产生可观的输出。</p><p id="87e2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">训练 GAN 模型由于其深度需要很大的耐心。以下是一些提示:</p><ol class=""><li id="e1df" class="mt mu iq jp b jq jr ju jv jy mv kc mw kg mx kk my mz na nb bi translated">问题:生成的图像看起来像噪音。解决方案:在鉴频器和发生器上使用压差。低压差值(0.3 到 0.6)生成更真实的图像。</li><li id="33a5" class="mt mu iq jp b jq nc ju nd jy ne kc nf kg ng kk my mz na nb bi translated">问题:鉴别器损耗迅速收敛到零，从而阻止发电机学习。解决方案:不要预先训练鉴别器。而是使其学习率大于对抗模型的学习率。对生成器使用不同的训练噪声样本。</li><li id="95f7" class="mt mu iq jp b jq nc ju nd jy ne kc nf kg ng kk my mz na nb bi translated">问题:发生器图像看起来仍然像噪声。解决方案:检查激活、批处理规范化和删除是否按正确的顺序应用。</li><li id="e18d" class="mt mu iq jp b jq nc ju nd jy ne kc nf kg ng kk my mz na nb bi translated">问题:计算出正确的训练/模型参数。解决方案:从发表的论文和代码中的一些已知工作值开始，一次调整一个参数。在训练 2000 步或以上之前，观察 500 步或 1000 步左右参数值调整的效果。</li></ol><h1 id="6f68" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">样本输出</h1><p id="3d98" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">图 5 显示了训练期间输出图像的演变。观察图 5 很有趣。GAN 正在学习如何自己书写手写数字！</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nh"><img src="../Images/d37e194e25131dab39362093a9d3ed8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lLoKIf8Ow3ZZPiO91vQyDA.png"/></div></div><figcaption class="mb mc gj gh gi md me bd b be z dk">Figure 5. DCGAN output images during 10,000 steps of training.</figcaption></figure><p id="3993" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Keras 的完整代码可以在这里找到。</p></div></div>    
</body>
</html>