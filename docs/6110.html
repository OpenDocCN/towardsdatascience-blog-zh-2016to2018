<html>
<head>
<title>Confidence intervals: parametric and non-parametric resampling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">置信区间:参数和非参数重采样</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-note-on-parametric-and-non-parametric-bootstrap-resampling-72069b2be228?source=collection_archive---------14-----------------------#2018-11-26">https://towardsdatascience.com/a-note-on-parametric-and-non-parametric-bootstrap-resampling-72069b2be228?source=collection_archive---------14-----------------------#2018-11-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/d296814903ab6cbc363eebc11ee9197c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NefEeBrLIgxzUYItv5JgrQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Image by Author</figcaption></figure><p id="0ed7" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">机器学习工程师一生中很重要的一部分时间都花在制作一个好的模型上。泪水和汗水被投入到这个艰苦的过程中。但是，一旦基于防弹理论(当然)的模型存在，一个狡猾的问题就潜伏在其中:“它能告诉我们什么？”。</p><h1 id="cc48" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">置信区间</h1><p id="461b" class="pw-post-body-paragraph kc kd iq ke b kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv mc kx ky kz ij bi translated">置信区间的概念通常用对称高斯分布来解释。然而，它们不一定是对称的，并且根据具体情况，推导起来可能非常繁琐。总的想法基于下面的公式:</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi md"><img src="../Images/d3ff019438b4dee4bbd171dec41bdfce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v1kHizjoEHOEvG9npIudmw.png"/></div></div></figure><p id="95ba" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">其中<strong class="ke ir"><em class="mi">【⍬】</em></strong>为固定且未知的参数真值，<strong class="ke ir"><em class="mi">【⍬】</em></strong><em class="mi">【hat】</em><strong class="ke ir"><em class="mi"/></strong>为其“最大似然估计(<em class="mi"> MLE) </em>来自数据<strong class="ke ir"><em class="mi"/></strong>(为随机变量)<strong class="ke ir"> <em class="mi"> deltas </em> </strong>为置信区间的界限，其在术语中取决于与常见的误解相反，置信区间并不给出预测的置信度，而是给出参数的真实值属于由边界定义的范围的概率。类似地，它可以被解释为误差概率，即参数的真实值超出界限的概率。</p><h1 id="6664" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">如果再次运行该路径，我会看到什么结果？</h1><p id="8795" class="pw-post-body-paragraph kc kd iq ke b kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv mc kx ky kz ij bi translated">这个问题是频率主义者分析的核心。模型依赖于数据，数据越大、越清晰、越通用，就能获得更好的参数估计。在给定数据的情况下，可以使用参数的置信区间并通过提出以下问题来估计模型的良好性:“如果略有不同，参数和预测将会是什么，但仍然使用看似合理的数据来生成它们。”获取置信区间的步骤如下:</p><ol class=""><li id="6ed5" class="mj mk iq ke b kf kg kj kk kn ml kr mm kv mn kz mo mp mq mr bi translated">写出一个概率模型。</li><li id="142f" class="mj mk iq ke b kf ms kj mt kn mu kr mv kv mw kz mo mp mq mr bi translated">在给定数据的情况下，用最大似然估计替换任何参数。用<em class="mi">重采样版本</em>替换任何随机变量。</li><li id="9e10" class="mj mk iq ke b kf ms kj mt kn mu kr mv kv mw kz mo mp mq mr bi translated">使用蒙特卡罗方法来估计第 2 步中的概率。</li></ol><p id="6394" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">步骤 2 中的<em class="mi">重采样版本</em>可以通过多种方式获得，即参数化和非参数化。</p><h1 id="a8e2" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">非参数重采样</h1><p id="2700" class="pw-post-body-paragraph kc kd iq ke b kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv mc kx ky kz ij bi translated">如果假设我们可能看到的所有数据都来自与手头数据相同的分布是安全的，那么，我们能做的最好的事情就是从数据集本身进行替换采样(以保持概率密度函数)。</p><h1 id="56c6" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">参数重采样</h1><p id="9392" class="pw-post-body-paragraph kc kd iq ke b kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv mc kx ky kz ij bi translated">然而，在某些情况下，从数据集进行采样并不是一个很好的主意，例如当数据稀缺时。然后，我们可以直接从最佳拟合(<em class="mi"> MLE)、</em>中生成新样本，并对噪声进行一些假设。</p><h1 id="4f40" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">把所有的放在一起</h1><p id="06e9" class="pw-post-body-paragraph kc kd iq ke b kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv mc kx ky kz ij bi translated">考虑两种情况:当数据充足时和当数据有限时。在这两种情况下，数据的基本分布都被假定为未知。</p><div class="me mf mg mh gt ab cb"><figure class="mx jr my mz na nb nc paragraph-image"><img src="../Images/ba06feb852e5c5a98b997d701c083292.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*sbCA-7DSraJLa0UuL_33TA.png"/></figure><figure class="mx jr nd mz na nb nc paragraph-image"><img src="../Images/e969bef6e4bd27089fee052039e80cb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*Q13r2Iev80AtV1E417wc4A.png"/><figcaption class="jy jz gj gh gi ka kb bd b be z dk ne di nf ng">Image by Author.</figcaption></figure></div><p id="64ea" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">检查散点图(图 1)后，假设最能描述数据的模型是三次多项式。</p><figure class="me mf mg mh gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nh"><img src="../Images/a654d0897ebe6ae51c3dd279b0f09c98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6CT9Q4vURzfBb5QOnXuSaA.png"/></div></div></figure><p id="0451" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">此外，假设数据中的噪声是具有零均值和未知标准差的高斯噪声是安全的。</p><p id="f390" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这两个过程都遵循上一节中的步骤。对于参数重采样，样本从具有附加高斯噪声的模型中生成，该噪声具有从<em class="mi"> MLE </em>拟合的残差中获得的方差。对于非参数重采样，样本从数据的原始分布中生成。</p><p id="fad9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">要获得响应的置信区间:首先，对于每个预测值，从所有 bootstrap 运行中对模型的预测进行排序，然后找出<em class="mi"> MLE </em>和期望区间的界限之间的差异(在这种情况下为 95%)。上限和下限之间的差异是置信区间的上限和下限的增量。</p><div class="me mf mg mh gt ab cb"><figure class="mx jr ni mz na nb nc paragraph-image"><img src="../Images/8c595e8e2c0db0852060002b7f8f930b.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*YfAaG1vtuv7BvQPg6ujfPg.png"/></figure><figure class="mx jr ni mz na nb nc paragraph-image"><img src="../Images/4088f885591d7c898e28bd731f917e5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*UdMPFjb53uG_K9OuZKt0_g.png"/><figcaption class="jy jz gj gh gi ka kb bd b be z dk nj di nk ng">95% confidence intervals for response, non-parametric (left), parametric (Right), 10 points. Image by Author.</figcaption></figure></div><div class="ab cb"><figure class="mx jr ni mz na nb nc paragraph-image"><img src="../Images/f3e00e7ad6cd327d9d9b2f535f36f263.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*Y7UeGFHyk_Q_150Ms2lKbA.png"/></figure><figure class="mx jr ni mz na nb nc paragraph-image"><img src="../Images/1d6608ef31279563405d4c0a61600adc.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*Dv0mYUuiHb44mdZuYhVMyQ.png"/><figcaption class="jy jz gj gh gi ka kb bd b be z dk nj di nk ng">95% confidence intervals for response, non-parametric (left), parametric (Right), 100 points. Image by Author.</figcaption></figure></div><p id="2b9f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">类似于预测的置信区间，我们保存来自 bootstrap 的所有拟合模型。</p><div class="me mf mg mh gt ab cb"><figure class="mx jr nl mz na nb nc paragraph-image"><img src="../Images/3db289256c7e96030a170ee34b68224f.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*OsaqRi3ygzUFx06pZvLczw.png"/></figure><figure class="mx jr nm mz na nb nc paragraph-image"><img src="../Images/edfcb477cb6258108a6a04383366f80b.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*oNITXTiqrPTjkmZ69-7eJA.png"/><figcaption class="jy jz gj gh gi ka kb bd b be z dk nn di no ng">95% confidence intervals for coefficients, non-parametric (left), parametric (Right), 10 points. Image by Author.</figcaption></figure></div><div class="ab cb"><figure class="mx jr ni mz na nb nc paragraph-image"><img src="../Images/c989c4425b2201a3d7c095e9cd8b245c.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*gBe1K7FqbgEf-VRMk9hxOA.png"/></figure><figure class="mx jr ni mz na nb nc paragraph-image"><img src="../Images/e8c26bec405270aac083a14ff157e0f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*XrbPZQcWq8LAL2ycoKU3Jg.png"/><figcaption class="jy jz gj gh gi ka kb bd b be z dk nj di nk ng">95% confidence intervals for coefficients, non-parametric (left), parametric (Right), 100 points. Image by Author.</figcaption></figure></div><h1 id="a62a" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">何时使用</h1><p id="9004" class="pw-post-body-paragraph kc kd iq ke b kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv mc kx ky kz ij bi translated">何时需要使用参数和非参数重采样？两者都有论据支持。使用非参数重采样，我们无法生成超出经验分布的样本，而使用参数重采样，可以生成超出我们目前所见的数据。但是，如果对模型没有太大的信心，或者数据丰富，那么非参数重采样是更可取的。如果数据不足，那么从参数模型中取样可以使其平滑(从图中可以看出)。</p><h1 id="1bd2" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">进一步阅读和链接</h1><p id="cdd6" class="pw-post-body-paragraph kc kd iq ke b kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv mc kx ky kz ij bi translated">有很多方法可以获得置信区间，例如估计后验分布(贝叶斯主义)，应用中心极限定理(在正态假设下)，使用威尔克斯定理，或者如果使用高斯随机变量，使用海森的<a class="ae np" href="https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470824566.app1" rel="noopener ugc nofollow" target="_blank">逆作为协方差矩阵等。</a></p><p id="959e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我推荐阅读<a class="ae np" href="https://erikbern.com/2018/10/08/the-hackers-guide-to-uncertainty-estimates.html" rel="noopener ugc nofollow" target="_blank">这篇关于置信区间的</a>文章，它从实践的角度给出了一个概述。另外，<a class="ae np" href="https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/1365-2656.12382" rel="noopener ugc nofollow" target="_blank">这篇</a>论文对基于 bootstrap 的置信区间方法进行了很好的概述。</p><p id="edd2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">本文的<strong class="ke ir"> jupyter 笔记本</strong>可从<a class="ae np" href="https://github.com/mikhailiuk/medium/blob/master/Bootstrap-resampling.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>获得。</p><h2 id="3958" class="nq lb iq bd lc nr ns dn lg nt nu dp lk kn nv nw lo kr nx ny ls kv nz oa lw ob bi translated">喜欢作者？保持联系！</h2><p id="a0e3" class="pw-post-body-paragraph kc kd iq ke b kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv mc kx ky kz ij bi translated">我错过了什么吗？请不要犹豫，直接在<a class="ae np" href="https://www.linkedin.com/in/aliakseimikhailiuk/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae np" href="https://twitter.com/mikhailiuka" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上给我留言、评论或发消息吧！</p><div class="oc od gp gr oe of"><a rel="noopener follow" target="_blank" href="/can-you-do-better-sampling-strategies-with-an-emphasis-on-gibbs-sampling-practicals-and-code-c97730d54ebc"><div class="og ab fo"><div class="oh ab oi cl cj oj"><h2 class="bd ir gy z fp ok fr fs ol fu fw ip bi translated">你能做得更好吗？抽样策略，重点是吉布斯抽样，实践和代码</h2><div class="om l"><h3 class="bd b gy z fp ok fr fs ol fu fw dk translated">提供了通用采样策略的概述，重点是 Gibbs 采样、示例和 python 代码。</h3></div><div class="on l"><p class="bd b dl z fp ok fr fs ol fu fw dk translated">towardsdatascience.com</p></div></div><div class="oo l"><div class="op l oq or os oo ot jw of"/></div></div></a></div><div class="oc od gp gr oe of"><a rel="noopener follow" target="_blank" href="/bayesian-optimization-or-how-i-carved-boats-from-wood-examples-and-code-78b9c79b31e5"><div class="og ab fo"><div class="oh ab oi cl cj oj"><h2 class="bd ir gy z fp ok fr fs ol fu fw ip bi translated">贝叶斯优化的超参数调整或者我如何用木头雕刻船</h2><div class="om l"><h3 class="bd b gy z fp ok fr fs ol fu fw dk translated">超参数调整通常是不可避免的。对于一个参数，网格搜索可能就足够了，但如何处理…</h3></div><div class="on l"><p class="bd b dl z fp ok fr fs ol fu fw dk translated">towardsdatascience.com</p></div></div><div class="oo l"><div class="ou l oq or os oo ot jw of"/></div></div></a></div><div class="oc od gp gr oe of"><a rel="noopener follow" target="_blank" href="/active-sampling-for-pairwise-comparisons-476c2dc18231"><div class="og ab fo"><div class="oh ab oi cl cj oj"><h2 class="bd ir gy z fp ok fr fs ol fu fw ip bi translated">成对比较的主动采样</h2><div class="om l"><h3 class="bd b gy z fp ok fr fs ol fu fw dk translated">如何配对玩家，以便在尽可能少的游戏中知道排名，同时游戏体验质量…</h3></div><div class="on l"><p class="bd b dl z fp ok fr fs ol fu fw dk translated">towardsdatascience.com</p></div></div><div class="oo l"><div class="ov l oq or os oo ot jw of"/></div></div></a></div></div></div>    
</body>
</html>