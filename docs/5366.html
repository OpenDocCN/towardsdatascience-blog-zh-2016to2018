<html>
<head>
<title>Review: MobileNetV1 — Depthwise Separable Convolution (Light Weight Model)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">复习:MobileNetV1 —深度方向可分离卷积(轻型模型)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-mobilenetv1-depthwise-separable-convolution-light-weight-model-a382df364b69?source=collection_archive---------1-----------------------#2018-10-14">https://towardsdatascience.com/review-mobilenetv1-depthwise-separable-convolution-light-weight-model-a382df364b69?source=collection_archive---------1-----------------------#2018-10-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="4b1a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi kl translated"><span class="l km kn ko bm kp kq kr ks kt di">在</span>这个故事中，回顾了来自谷歌的<strong class="jp ir"> MobileNetV1 </strong>。<strong class="jp ir">深度方向可分离卷积</strong>用于降低模型大小和复杂度。它对移动和嵌入式视觉应用特别有用。</p><ul class=""><li id="c7b6" class="ku kv iq jp b jq jr ju jv jy kw kc kx kg ky kk kz la lb lc bi translated"><strong class="jp ir">更小的模型尺寸</strong>:参数数量更少</li><li id="c028" class="ku kv iq jp b jq ld ju le jy lf kc lg kg lh kk kz la lb lc bi translated"><strong class="jp ir">更小的复杂度</strong>:更少的乘法和加法(多重加法)</li></ul><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi li"><img src="../Images/b07dd525b26bdfa5dcaff69e88a1182b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aj1Ef3zcJy2Rlct3Z7oPHQ.png"/></div></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">When MobileNets Applied to Real Life</strong></figcaption></figure><p id="5ce4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">引入两个参数使得 MobileNet 可以很容易地调整:<strong class="jp ir">宽度乘数α </strong>和<strong class="jp ir">分辨率乘数ρ </strong>。而这是我写这篇论文的时候发表在<strong class="jp ir">arXiv 2017</strong>【1】的论文，引用<strong class="jp ir">600 多篇</strong>。(<a class="lz ma ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----a382df364b69--------------------------------" rel="noopener" target="_blank">曾植和</a> @中)</p><figure class="lj lk ll lm gt ln"><div class="bz fp l di"><div class="mb mc l"/></div></figure><p id="3025" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面的对象检测示例是 MobileNet，它实际上是令人惊讶的，因为它可以在同时检测到如此大量的对象时达到大约 25 fps。</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="255a" class="mk ml iq bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">涵盖哪些内容</h1><ol class=""><li id="00f1" class="ku kv iq jp b jq ni ju nj jy nk kc nl kg nm kk nn la lb lc bi translated"><strong class="jp ir">深度方向可分离卷积</strong></li><li id="ef80" class="ku kv iq jp b jq ld ju le jy lf kc lg kg lh kk nn la lb lc bi translated"><strong class="jp ir">全网架构</strong></li><li id="9b86" class="ku kv iq jp b jq ld ju le jy lf kc lg kg lh kk nn la lb lc bi translated"><strong class="jp ir">较薄型号的宽度乘数α</strong></li><li id="6948" class="ku kv iq jp b jq ld ju le jy lf kc lg kg lh kk nn la lb lc bi translated"><strong class="jp ir">简化表示的分辨率乘数ρ</strong></li><li id="fb51" class="ku kv iq jp b jq ld ju le jy lf kc lg kg lh kk nn la lb lc bi translated"><strong class="jp ir">与最先进方法的比较</strong></li></ol></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="93ae" class="mk ml iq bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated"><strong class="ak"> 1。深度方向可分离卷积</strong></h1><p id="336f" class="pw-post-body-paragraph jn jo iq jp b jq ni js jt ju nj jw jx jy no ka kb kc np ke kf kg nq ki kj kk ij bi translated">深度方向可分离卷积是<strong class="jp ir">一个深度方向卷积，后面跟着一个点方向卷积</strong>，如下所示:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi nr"><img src="../Images/80d3d92873fea816ed812ceedbf78f6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Voah8cvrs7gnTDf6acRvDw.png"/></div></div></figure><ol class=""><li id="7224" class="ku kv iq jp b jq jr ju jv jy kw kc kx kg ky kk nn la lb lc bi translated"><strong class="jp ir">深度方向卷积</strong>是<strong class="jp ir">通道方向 DK×DK 空间卷积</strong>。假设在上图中，我们有 5 个通道，那么我们将有 5 个 DK×DK 空间卷积。</li><li id="65ea" class="ku kv iq jp b jq ld ju le jy lf kc lg kg lh kk nn la lb lc bi translated"><strong class="jp ir">逐点卷积</strong>实际上是改变尺寸的<strong class="jp ir"> 1×1 卷积</strong>。</li></ol><p id="63e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过以上操作，操作成本为:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/020590bdc4fcadac47fb497482ad17fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*xEl35TofPaFk6e0gih8jYA.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">Depthwise Separable Convolution Cost: Depthwise Convolution Cost (Left), Pointwise Convolution Cost (Right)</strong></figcaption></figure><p id="64ea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中 M:输入通道数，N:输出通道数，DK:内核大小，DF:特征映射大小。</p><p id="f64b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于标准卷积，它是:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/eb082f0ac6dc6bf2ec3764d01c129a34.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*RJWCVT-y2JRrHStgq26g2A.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">Standard Convolution Cost</strong></figcaption></figure><p id="5f77" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，计算量减少为:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi nu"><img src="../Images/69181f8240d6ffb654edba479f15f375.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*tZ7pUgBdG-_-GHT6Az62Ug.png"/></div></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">Depthwise Separable Convolution Cost / Standard Convolution Cost</strong></figcaption></figure><p id="e0a9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">当 DK×DK 为 3×3 时，计算量可减少 8 至 9 倍，但精度仅略有降低。</strong></p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="3d13" class="mk ml iq bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated"><strong class="ak"> 2。全网架构</strong></h1><p id="c948" class="pw-post-body-paragraph jn jo iq jp b jq ni js jt ju nj jw jx jy no ka kb kc np ke kf kg nq ki kj kk ij bi translated">以下是 MobileNet 架构:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/426b1816c7468d3a3d02e663eb547625.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*ylHiMKAXb57bN7uDhzldlg.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">Whole Network Architecture for MobileNet</strong></figcaption></figure><p id="e538" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，批次归一化(BN)和 ReLU 在每次卷积后应用:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi nw"><img src="../Images/f921d421c9d71ad0e5bfe6e5a6584e86.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*XFvQWA4VESeQIcxzXMHCAg.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">Standard Convolution (Left), Depthwise separable convolution (Right) With BN and ReLU</strong></figcaption></figure><p id="2ed8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于 ImageNet 数据集，If 标准卷积与深度方向可分离卷积:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/cbbd88d1a1b57cbe13efb564583e988c.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*IS871KUvOodJ-YB1H3Rkgw.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">Standard Convolution vs Depthwise Separable Convolution (ImageNet dataset)</strong></figcaption></figure><p id="78e1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> MobileNet 只损失了 1%的精度，但乘法和参数却大大减少了。</strong></p><h1 id="96b9" class="mk ml iq bd mm mn ny mp mq mr nz mt mu mv oa mx my mz ob nb nc nd oc nf ng nh bi translated"><strong class="ak"> 3。更薄型号的宽度乘数α</strong></h1><p id="1754" class="pw-post-body-paragraph jn jo iq jp b jq ni js jt ju nj jw jx jy no ka kb kc np ke kf kg nq ki kj kk ij bi translated">引入宽度乘数α<strong class="jp ir">控制通道数或通道深度</strong>，使 M 变为αM，深度方向可分卷积代价变为:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi od"><img src="../Images/db828b640c5c9a408e9f8187323ab998.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*wiYEpn5HOkWs6udGC8ja1w.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">Depthwise Separable Convolution Cost with Width Multiplier α</strong></figcaption></figure><p id="d5bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中α在 0 到 1 之间，典型设置为 1、0.75、0.5 和 0.25。当α=1 时，它是基线 MobileNet。并且计算成本和参数数量可以减少大约α倍。</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/d80058bc5548415d69111b7108fbe7ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*l_t6gTb_BKaxjFkTl7Cp8w.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">Different Values of Width Multiplier α</strong></figcaption></figure><p id="b7eb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">精度从α=1 平滑下降到 0.5，直到α=0.25，这太小。</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="99c0" class="mk ml iq bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated"><strong class="ak"> 4。简化表示的分辨率乘数ρ</strong></h1><p id="649c" class="pw-post-body-paragraph jn jo iq jp b jq ni js jt ju nj jw jx jy no ka kb kc np ke kf kg nq ki kj kk ij bi translated">引入分辨率乘数ρ以<strong class="jp ir">控制网络的输入图像分辨率</strong>，用分辨率乘数ρ，成本变成:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi of"><img src="../Images/2075aa31b7fcf4c826169521b2ae3336.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*o9jr0anTAs0sGEit8PTGZQ.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">Depthwise Separable Convolution Cost with Both Width Multiplier α and Resolution Multiplier ρ</strong></figcaption></figure><p id="d894" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中ρ在 0 到 1 之间。输入分辨率为 224、192、160 和 128。当ρ=1 时，为基线 MobileNet。</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi og"><img src="../Images/f841d3b5e6acc9430c7def595cf882c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*dFaxIA0Z9XH3t_el_ugDvA.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">Different Values of Resolution Multiplier ρ</strong></figcaption></figure><p id="c57c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">分辨率从 224 到 128 时，精确度会平稳下降。</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="64c4" class="mk ml iq bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated"><strong class="ak"> 5。与最先进方法的比较</strong></h1><p id="3d3d" class="pw-post-body-paragraph jn jo iq jp b jq ni js jt ju nj jw jx jy no ka kb kc np ke kf kg nq ki kj kk ij bi translated"><strong class="jp ir">当使用 1.0 MobileNet-224 时，它的性能优于 GoogLeNet(ils vrc 2014 的冠军)和 VGGNet(ils vrc 2014 的亚军)</strong>而 multi-adds 和参数却少得多:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/88d9f1194ca1a71b0b11b3ea754c1ee6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*tmweh8oLPUoiXU6XsvYBlA.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">ImageNet Dataset</strong></figcaption></figure><p id="eac0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">当使用更小的网络(0.50 MobileNet-160)时，它的性能优于 Squeezenet 和 Alex net(2012 年 ILSVRC 的获奖者)</strong>而 multi-adds 和参数则少得多:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/634d3ef7903028eae82f1194c147134f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*A_89hq4HxHpwPosqYX3RMg.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">ImageNet Dataset</strong></figcaption></figure><p id="3443" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它与 Inception-v3(ils vrc 2015 的亚军)也有竞争力，而 multi-adds 和参数要少得多:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/675d7a618ab2c7505a36373f5adbf8d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*7fxzJxg4iA8GV3UgMR3ySg.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">Stanford Dogs Dataset</strong></figcaption></figure></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><p id="6459" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">许多其他数据集也被尝试</strong>来证明 MobileNet 的有效性:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/f76eec3819cf000f134ff9e7ea523085.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*XuhEwpVfv1IgchrmG6JLPA.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">GPS Localization Via Photos</strong></figcaption></figure><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/399c2bca1471e648e41e67f3239e23b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*B_m8bVYK6eGsRdeNlnVTsA.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">Face Attribute Classification</strong></figcaption></figure><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/a1034dfab38787163c396793aad7cecb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/1*E809tflHR8V8fZiP-cidyQ.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">Microsoft COCO Object Detection Dataset</strong></figcaption></figure><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="gh gi om"><img src="../Images/410c23ea14e6e847cf562798ad19ceec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*Sl3ezGZWzZbizy937Qq5tA.png"/></div></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">MobileNet SSD</strong></figcaption></figure><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi on"><img src="../Images/a0e6c98e6e3cda7db67c925645e283e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ZsKu8KKbrGdVNCcmqRhbXg.png"/></div><figcaption class="lu lv gj gh gi lw lx bd b be z dk"><strong class="bd ly">Face Recognition</strong></figcaption></figure><p id="0cd6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">总之，利用深度方向可分离卷积，使用 MobileNet 可以获得与最先进方法类似的性能，但网络要小得多。</p><p id="3a0c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">的确，还有很多我上面没有提到的应用，比如通过照片进行 GPS 定位，人脸属性分类和人脸识别。希望我能在未来的日子里报道它们。:)</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="c6dd" class="mk ml iq bd mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng nh bi translated">参考</h1><ol class=""><li id="bd74" class="ku kv iq jp b jq ni ju nj jy nk kc nl kg nm kk nn la lb lc bi translated">【2017 arXiv】【MobileNetV1】<br/><a class="ae oo" href="https://arxiv.org/abs/1704.04861" rel="noopener ugc nofollow" target="_blank">MobileNets:面向移动视觉应用的高效卷积神经网络</a></li></ol><h1 id="1f75" class="mk ml iq bd mm mn ny mp mq mr nz mt mu mv oa mx my mz ob nb nc nd oc nf ng nh bi translated">我的评论</h1><p id="9f5a" class="pw-post-body-paragraph jn jo iq jp b jq ni js jt ju nj jw jx jy no ka kb kc np ke kf kg nq ki kj kk ij bi translated"><a class="ae oo" href="https://medium.com/@sh.tsang/review-inception-v3-1st-runner-up-image-classification-in-ilsvrc-2015-17915421f77c" rel="noopener"> Inception-v3 </a> <a class="ae oo" href="https://medium.com/@sh.tsang/review-batch-normalization-inception-v2-bn-inception-the-2nd-to-surpass-human-level-18e2d0f56651" rel="noopener"> BatchNorm </a> <a class="ae oo" href="https://medium.com/coinmonks/paper-review-of-googlenet-inception-v1-winner-of-ilsvlc-2014-image-classification-c2b3565a64e7" rel="noopener"> GoogLeNet </a> <a class="ae oo" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener"> VGGNet </a> <a class="ae oo" href="https://medium.com/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160" rel="noopener"> AlexNet </a></p></div></div>    
</body>
</html>