<html>
<head>
<title>Adversarial predictive networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">敌对预测网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/adversarial-predictive-networks-3aa7026d53d2?source=collection_archive---------3-----------------------#2017-10-15">https://towardsdatascience.com/adversarial-predictive-networks-3aa7026d53d2?source=collection_archive---------3-----------------------#2017-10-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="f971" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">作者:Lukasz Burzawa、Abhishek Chaurasia和Eugenio culrciello</em></p><p id="b0a6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们想测试像<a class="ae km" href="https://engineering.purdue.edu/elab/CortexNet/\" rel="noopener ugc nofollow" target="_blank"> CortexNet </a>这样的预测性神经网络将从同时训练中受益的想法:</p><p id="1ab5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1-预测视频中的未来帧</p><p id="351f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2-使用对抗性训练来区分视频中的真实帧和网络生成的帧</p><p id="335e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们称之为<em class="kl">对抗性预测训练</em>。这个想法是改进CortexNet的能力，在更多的未标记数据上进行预训练，然后只使用少量的标记数据。</p><p id="873e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们以这种方式修改了我们的<a class="ae km" href="https://medium.com/towards-data-science/a-new-kind-of-deep-neural-networks-749bcde19108" rel="noopener">新型神经网络</a>:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi kn"><img src="../Images/46856fe22dbdbe4a2f00c0f54d7e8f3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*OR15l3_9y-xuJfWRexednw.png"/></div></figure><p id="fe19" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们添加了一个分类器<em class="kl"> C </em>来预测伪生成帧和真实生成帧。我们的网络鉴别器或编码器D类似于标准的多层神经网络，因此我们将分类器C放置在所有绿色层之后。蓝色生成层或解码器层对于重建未来的图像或表示是有用的。更详细的是<a class="ae km" href="https://medium.com/towards-data-science/a-new-kind-of-deep-neural-networks-749bcde19108" rel="noopener">这里</a>。</p><p id="7567" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了进行培训，我们采用以下步骤:</p><p id="647a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">1-我们训练网络来预测下一帧，就像在常规的<a class="ae km" href="https://engineering.purdue.edu/elab/CortexNet/\" rel="noopener ugc nofollow" target="_blank"> CortexNet </a>中一样</p><p id="aa85" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">2-一旦网络可以生成合适的未来帧，我们训练分类器C来预测输入是真实的下一帧还是生成的下一帧</p><p id="dd60" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们在每个训练步骤中按顺序运行步骤1、2。</p><p id="cf54" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些是G和D模块的详细信息:</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi kv"><img src="../Images/928f348c56fe167fa56e27fe10d7e76f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yo_YHElEgALWNF1QgJeAFg.png"/></div></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">D, G blocks in detail</figcaption></figure><p id="f22b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们在conv和ReLU之间使用批量标准化。</p><p id="0072" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">结果:</strong>使用<a class="ae km" href="http://www.nada.kth.se/cvap/actions/" rel="noopener ugc nofollow" target="_blank"> KTH数据集</a>，我们用上述对抗性预测方法对网络进行预训练，然后通过冻结生成器的网络，使用10%的数据来训练分类器C。</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi le"><img src="../Images/58fa6282ef929a75924e58fa205800d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*Vk5FT8uRNIrktfts."/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">CASE 1</figcaption></figure><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi le"><img src="../Images/db0fbd600ead2fea74e9b0ed561144c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*QRV3vwx7YZ2J2UpE."/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">CASE 2</figcaption></figure><p id="979e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">案例1 :我们用10%的数据训练整个网络。我们得到了60.43%的最高测试准确率</p><p id="1836" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">案例2 </strong>:我们对100%的数据使用了对抗性预测训练(假/真，也预测下一帧)，然后对10%的数据进行了网络微调。我们得到了53.33%的最高测试准确率</p><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div class="gh gi le"><img src="../Images/e6b1ecb141ae85889abd543725e0d275.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*2bfGLi03PcR9v6EO."/></div><figcaption class="la lb gj gh gi lc ld bd b be z dk">CASE 3</figcaption></figure><p id="bf7f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">案例3 </strong>:我们只对100%的数据使用预测训练(预测下一帧，作为原始CortexNet)，然后对10%的数据微调网络。我们得到了最高71.98%的测试准确率</p><p id="7c63" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">结论</strong>:如你所见，我们期望<strong class="jp ir">案例2 </strong>比<strong class="jp ir">案例3 </strong>更好。<em class="kl">但这并没有发生:</em> (53对71% —案例2对3)。我们的结论是，对抗性预测训练在训练关于假/真分类的分类器和整个网络的预测能力之间产生冲突。</p><p id="9c0d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对33%(62%对79% —案例2对3)和50% (71%对81% —案例2对3)的数据进行预训练，而不是只对10%的数据进行预训练，并没有改变这种情况，而且使用更多的数据无论如何都无法达到对未标记数据进行预训练的目的…</p><h1 id="c04f" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">关于作者</h1><p id="7e75" class="pw-post-body-paragraph jn jo iq jp b jq md js jt ju me jw jx jy mf ka kb kc mg ke kf kg mh ki kj kk ij bi translated">我在硬件和软件方面都有将近20年的神经网络经验(一个罕见的组合)。在这里看关于我:<a class="ae km" href="https://medium.com/@culurciello/" rel="noopener">媒介</a>、<a class="ae km" href="https://e-lab.github.io/html/contact-eugenio-culurciello.html" rel="noopener ugc nofollow" target="_blank">网页</a>、<a class="ae km" href="https://scholar.google.com/citations?user=SeGmqkIAAAAJ" rel="noopener ugc nofollow" target="_blank">学者</a>、<a class="ae km" href="https://www.linkedin.com/in/eugenioculurciello/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>等等…</p><h1 id="b80d" class="lf lg iq bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">捐款</h1><figure class="ko kp kq kr gt ks gh gi paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="gh gi mi"><img src="../Images/bb6a9f917e37eb5d49e0181cc20b788c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gCbUDLiPi6SzCmfkhuqrCg.jpeg"/></div></div></figure><p id="57ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你觉得这篇文章有用，请考虑捐赠<a class="ae km" href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=Q3FHE3BWSC72W" rel="noopener ugc nofollow" target="_blank">来支持更多的教程和博客。任何贡献都能有所作为！</a></p></div></div>    
</body>
</html>