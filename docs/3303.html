<html>
<head>
<title>The 4 Recommendation Engines That Can Predict Your Movie Tastes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">4个推荐引擎可以预测你的电影口味</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-4-recommendation-engines-that-can-predict-your-movie-tastes-109dc4e10c52?source=collection_archive---------1-----------------------#2018-05-01">https://towardsdatascience.com/the-4-recommendation-engines-that-can-predict-your-movie-tastes-109dc4e10c52?source=collection_archive---------1-----------------------#2018-05-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/f066afd9a53e74e51b2f04f8f5c6a838.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*5szjas4x6IWc1D_2."/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">“A person holding a clapper board in a desert” by <a class="ae kc" href="https://unsplash.com/@jakobowens1?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jakob Owens</a> on <a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="ac0c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">今晚我应该看什么电影？</p><p id="f9a0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当你下班回家的时候，你曾经不得不回答这个问题至少一次吗？至于我——是的，而且不止一次。从网飞到Hulu，鉴于现代消费者对个性化内容的巨大需求，建立强大的电影推荐系统的需求极其重要。</p><p id="12ae" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">推荐系统的一个例子是这样的:</p><ul class=""><li id="fd5a" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la lh li lj lk bi translated">用户A看<strong class="kf ir">权力的游戏</strong>和<strong class="kf ir">绝命毒师</strong>。</li><li id="13b1" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">用户B在<strong class="kf ir">上搜索《权力的游戏</strong>，然后系统从收集的关于用户a的数据中建议<strong class="kf ir">绝命毒师</strong>。</li></ul><p id="b071" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">推荐系统不仅用于电影，还用于其他多种产品和服务，如亚马逊(书籍、商品)、Pandora/Spotify(音乐)、谷歌(新闻、搜索)、YouTube(视频)等。</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lq"><img src="../Images/ab29aa296a7642cb4728cf141f4511f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dMR3xmufnmKiw4crlisQUA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Netflix Recommendations</figcaption></figure><p id="eb61" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我将向你展示如何实现4种不同的电影推荐方法，并对它们进行评估，看看哪一种具有最好的性能。</p><h1 id="d8a8" class="lv lw iq bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">电影镜头数据集</h1><p id="852c" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">我正在使用的数据集是<a class="ae kc" href="https://grouplens.org/datasets/movielens/" rel="noopener ugc nofollow" target="_blank"> MovieLens </a>，这是互联网上最常见的数据集之一，可用于构建推荐系统。我正在使用的数据集版本(<a class="ae kc" href="https://grouplens.org/datasets/movielens/1m/" rel="noopener ugc nofollow" target="_blank"> 1M </a>)包含了2000年加入MovieLens的6040名MovieLens用户制作的约3900部电影的1000209个匿名评级。</p><p id="cf11" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在处理数据并进行一些探索性分析后，以下是该数据集最有趣的特性:</p><p id="ca51" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是<strong class="kf ir">电影片名</strong>的文字云可视化:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi my"><img src="../Images/1a8929ec7f3b02ce2085b8fc3c7f5951.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qMrcVoRVNmxgHODwyYGE_w.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">MovieLens Titles</figcaption></figure><p id="991d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">很美，不是吗？我可以识别出这个数据集中有很多电影特许经营权，例如<em class="lb"> II </em>和<em class="lb"> III </em> …除此之外，还有<em class="lb">日</em>、<em class="lb">爱</em>、<em class="lb">生</em>、<em class="lb">时</em>、<em class="lb">夜</em>、<em class="lb">男</em>、<em class="lb">死</em>、<em class="lb">美</em>等</p><p id="1e96" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是<strong class="kf ir">用户评分</strong>的分布:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/1a8f9813cc7ad048a446f6e90c7130f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*P_NyzkYXMGipY7Gm9oGl2w.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">MovieLens Ratings</figcaption></figure><p id="ee68" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">看起来用户对他们的评价很慷慨。在5分制中，平均得分为3.58分。一半的电影有4级和5级。我个人认为，5级评级技能不是一个好的指标，因为人们可能有不同的评级风格(即，人A对一般电影总是使用4，而人B对他们最喜欢的电影只给出4)。每个用户至少评价了20部电影，所以我怀疑这种分布可能只是由电影质量的偶然差异造成的。</p><p id="5744" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里还有另外一个词——电影类型的云:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi na"><img src="../Images/7dc1326509c7361085006ec412f5ead2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q9zePC_ggd0GB6r67Uw1Bw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">MovieLens Genres</figcaption></figure><p id="b9a2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">排名前五的类型依次是:戏剧、喜剧、动作片、惊悚片和爱情片。</p><p id="a392" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在让我们继续探索可以使用的4个推荐系统。以下是他们，按照各自的展示顺序:</p><ol class=""><li id="af70" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la nb li lj lk bi translated">基于内容的过滤</li><li id="61e4" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la nb li lj lk bi translated">基于记忆的协同过滤</li><li id="cf08" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la nb li lj lk bi translated">基于模型的协同过滤</li><li id="5754" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la nb li lj lk bi translated">深度学习/神经网络</li></ol><h1 id="9f11" class="lv lw iq bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">1-基于内容</h1><p id="1c00" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">基于内容的推荐器依赖于被推荐项目的相似性。基本思想是，如果你喜欢一个项目，那么你也会喜欢一个“相似”的项目。当很容易确定每个项目的上下文/属性时，它通常工作得很好。</p><p id="fda8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">基于内容的推荐器与用户提供的数据一起工作，该数据或者是针对电影镜头数据集的明确的电影评级。基于该数据，生成用户简档，然后使用该简档向用户提出建议。随着用户提供更多的输入或对推荐采取行动，引擎变得越来越准确。</p><h2 id="b48d" class="nc lw iq bd lx nd ne dn mb nf ng dp mf ko nh ni mj ks nj nk mn kw nl nm mr nn bi translated">数学</h2><p id="19a4" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated"><strong class="kf ir">术语频率(TF) </strong>和<strong class="kf ir">逆文档频率(IDF) </strong>的概念用于信息检索系统以及基于内容的过滤机制(例如基于内容的推荐器)。它们用于确定文档/文章/新闻/电影等的相对重要性。</p><p id="3d1c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">TF就是一个单词在文档中出现的频率。IDF是文档在整个语料库中出现频率的倒数。使用TF-IDF主要有两个原因:假设我们在谷歌上搜索“<strong class="kf ir">最新欧洲足球赛</strong>的结果。可以肯定的是"<strong class="kf ir"/>"将比"<strong class="kf ir">足球比赛</strong>"出现得更频繁，但是<strong class="kf ir">足球比赛</strong>的相对重要性高于搜索查询角度。在这种情况下，TF-IDF加权在确定项目(文档)的重要性时否定了高频词的影响。</p><p id="706d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下面是计算TF-IDF分数的公式:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi no"><img src="../Images/b2ce4cf974735aa18eb1bbc8133f9fae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KZrjbKHcsWt-zzUj2oRk3w.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">TF-IDF Equation</figcaption></figure><p id="c574" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在计算TF-IDF分数之后，我们如何确定哪些项目彼此更接近，而不是更接近用户简档？这是使用<strong class="kf ir">向量空间模型</strong>完成的，该模型根据向量之间的角度计算接近度。在该模型中，每个项目作为其属性的向量(也是向量)存储在一个n维空间<strong class="kf ir">中，并且向量之间的角度被计算以<strong class="kf ir">确定向量之间的相似性</strong>。接下来，也基于用户对项目的先前属性的动作来创建用户简档向量，并且也以类似的方式来确定项目和用户之间的相似性。</strong></p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi np"><img src="../Images/833592dccf4fe410c7a30a3856407157.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b06OA4v3x3yhQiFNNzbzow.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Vector Space Model</figcaption></figure><p id="a326" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">句子2更可能使用术语2，而不是术语1。对于句子1反之亦然。计算这种相对度量的方法是通过取句子和术语之间角度的余弦来计算的。使用余弦的最终原因是余弦的<strong class="kf ir">值将随着角度</strong>值的减小而增加，这意味着更相似。向量被长度归一化，之后它们变成长度为1的向量，然后余弦计算简单地是向量的和积。</p><h2 id="3da6" class="nc lw iq bd lx nd ne dn mb nf ng dp mf ko nh ni mj ks nj nk mn kw nl nm mr nn bi translated">代码</h2><p id="6950" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">有了这些数学知识，我将构建一个基于内容的推荐引擎，根据电影类型计算电影之间的相似性。它会根据电影的类型推荐与特定电影最相似的电影。</p><p id="50b3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我没有一个量化指标来判断机器的性能，所以这将不得不做定性。为了做到这一点，我将使用来自<strong class="kf ir"> scikit-learn </strong>的<strong class="kf ir"> TfidfVectorizer </strong>函数，它将文本转换为可用作估计器输入的特征向量。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="a59a" class="nc lw iq nr b gy nv nw l nx ny"><strong class="nr ir">from</strong> <strong class="nr ir">sklearn.feature_extraction.text</strong> <strong class="nr ir">import</strong> TfidfVectorizer<br/>tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')<br/>tfidf_matrix = tf.fit_transform(movies['genres'])</span></pre><p id="f17e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我将使用<a class="ae kc" href="https://masongallo.github.io/machine/learning,/python/2016/07/29/cosine-similarity.html" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir">余弦相似度</strong> </a>来计算表示两部电影相似度的数值。由于我使用了TF-IDF矢量器，计算点积将直接给出余弦相似性得分。因此，我将使用sklearn的<strong class="kf ir"> linear_kernel </strong>而不是余弦_相似度，因为它要快得多。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="3828" class="nc lw iq nr b gy nv nw l nx ny"><strong class="nr ir">from</strong> <strong class="nr ir">sklearn.metrics.pairwise</strong> <strong class="nr ir">import</strong> linear_kernel<br/>cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)</span></pre><p id="ac8c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我现在有了数据集中所有电影的成对余弦相似矩阵。下一步是编写一个函数，根据余弦相似性得分返回20部最相似的电影。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="6138" class="nc lw iq nr b gy nv nw l nx ny"><em class="lb"># Build a 1-dimensional array with movie titles</em><br/>titles = movies['title']<br/>indices = pd.Series(movies.index, index=movies['title'])<br/><br/><em class="lb"># Function that get movie recommendations based on the cosine similarity score of movie genres</em><br/><strong class="nr ir">def</strong> genre_recommendations(title):<br/>    idx = indices[title]<br/>    sim_scores = list(enumerate(cosine_sim[idx]))<br/>    sim_scores = sorted(sim_scores, key=<strong class="nr ir">lambda</strong> x: x[1], reverse=<strong class="nr ir">True</strong>)<br/>    sim_scores = sim_scores[1:21]<br/>    movie_indices = [i[0] <strong class="nr ir">for</strong> i <strong class="nr ir">in</strong> sim_scores]<br/>    <strong class="nr ir">return</strong> titles.iloc[movie_indices]</span></pre><h2 id="0cab" class="nc lw iq bd lx nd ne dn mb nf ng dp mf ko nh ni mj ks nj nk mn kw nl nm mr nn bi translated">该建议</h2><p id="5084" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">让我们尝试获得几部电影的最佳推荐，看看这些推荐有多好。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="f13d" class="nc lw iq nr b gy nv nw l nx ny">genre_recommendations('Good Will Hunting (1997)').head(20)</span></pre><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nz"><img src="../Images/bb2a735ae04f76a50871876eeeec13fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zRAvGlrgLCZwqTrmlv30Jw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Recommendations Similar to “Good Will Hunting”</figcaption></figure><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="07be" class="nc lw iq nr b gy nv nw l nx ny">genre_recommendations('Toy Story (1995)').head(20)</span></pre><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oa"><img src="../Images/201e1e94a2cceffd14c225a03889436b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E3kOkf1lNUg-mlVKtTRofA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Recommendations Similar to “Toy Story”</figcaption></figure><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="906a" class="nc lw iq nr b gy nv nw l nx ny">genre_recommendations('Saving Private Ryan (1998)').head(20)</span></pre><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/471cdb0a06c3c4a9a0e0905460faa921.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*yUxyA60SFJ3yRaikiM4GBw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Recommendations Similar to “Saving Private Ryan”</figcaption></figure><p id="a650" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如你所见，我有一份相当不错的推荐名单，分别是《心灵捕手》(T12)、《剧情》(T13)、《玩具总动员》(T14)、《动画、儿童、喜剧》(T15)、《拯救大兵瑞恩》(T16)、《动作、惊悚、战争》(T17)。</p><p id="db8a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">总的来说，以下是使用基于内容的推荐的优点:</p><ul class=""><li id="d734" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la lh li lj lk bi translated">不需要关于其他用户的数据，因此没有冷启动或稀疏性问题。</li><li id="02b7" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">可以推荐给口味独特的用户。</li><li id="06b8" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">可以推荐新的和不受欢迎的项目。</li><li id="6ea5" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">可以通过列出导致项目被推荐的内容特征(在本例中是电影类型)来为推荐的项目提供解释</li></ul><p id="94e0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是，使用这种方法有一些缺点:</p><ul class=""><li id="5ef6" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la lh li lj lk bi translated">找到合适的特征很难。</li><li id="17bd" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">不推荐用户内容简档之外的项目。</li><li id="c4b0" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">无法利用其他用户的质量判断。</li></ul><h1 id="9636" class="lv lw iq bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">2 —协同过滤</h1><p id="cac8" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">协同过滤推荐器完全基于过去的行为，而不是基于上下文。更具体地说，它是基于两个用户的偏好、品味和选择的相似性。它分析一个用户与另一个用户的口味有多相似，并在此基础上提出建议。</p><p id="7b38" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">例如，如果用户A喜欢电影1、2、3，而用户B喜欢电影2、3、4，那么他们有相似的兴趣，A应该喜欢电影4，B应该喜欢电影1。这使得它成为最常用的算法之一，因为它不依赖于任何附加信息。</p><p id="a68e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一般来说，协同过滤是推荐引擎的主力。该算法有一个非常有趣的特性，即能够自己进行特征学习，这意味着它可以开始自己学习使用什么特征。</p><h2 id="a1b8" class="nc lw iq bd lx nd ne dn mb nf ng dp mf ko nh ni mj ks nj nk mn kw nl nm mr nn bi translated">数学</h2><p id="cdac" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">有两种主要类型的基于记忆的协同过滤算法:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nz"><img src="../Images/ed4bef341a804531a3bf78f18914f603.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QvhetbRjCr1vryTch_2HZQ.jpeg"/></div></div></figure><ol class=""><li id="caec" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la nb li lj lk bi translated"><strong class="kf ir">用户-用户协同过滤</strong>:在这里，我们根据相似性找到相似的用户，并推荐第一个用户的相似者过去选择的电影。这种算法非常有效，但需要大量的时间和资源。它需要计算每个用户对信息，这需要时间。因此，对于大型基础平台，如果没有非常强大的可并行化系统，该算法很难实现。</li><li id="fe5d" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la nb li lj lk bi translated"><strong class="kf ir">逐项协同过滤</strong>:与之前的算法非常相似，但我们不是寻找用户的相似物，而是尝试寻找电影的相似物。一旦我们有了电影的相似矩阵，我们就可以很容易地向从数据集中给任何电影评分的用户推荐相似的电影。该算法比用户-用户协同过滤消耗的资源少得多。因此，对于一个新用户，该算法比用户-用户协作花费的时间少得多，因为我们不需要用户之间的所有相似性分数。并且对于固定数量的电影，电影-电影相似矩阵随着时间是固定的。</li></ol><p id="5b65" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这两种情况下，我们都会建立一个相似度矩阵。对于用户-用户协同过滤，<strong class="kf ir">用户相似性矩阵</strong>将由一些度量任意两对用户之间相似性的距离度量组成。同样，<strong class="kf ir">项目相似性矩阵</strong>将测量任意两对项目之间的相似性。</p><p id="1d53" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在协同过滤中通常使用3种距离相似性度量:</p><ol class=""><li id="bc0c" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la nb li lj lk bi translated"><strong class="kf ir"> Jaccard相似度</strong>:相似度基于对项目A和B评分的用户数量除以对项目A或B评分的用户数量。它通常用于我们没有数字评分而只有布尔值的情况，如购买的产品或点击的添加。</li><li id="ff2a" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la nb li lj lk bi translated"><strong class="kf ir">余弦相似度</strong>:(和基于内容的系统一样)相似度是A和b的项目向量的2个向量之间的夹角余弦，向量越近，夹角越小，余弦越大。</li><li id="e790" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la nb li lj lk bi translated"><strong class="kf ir">皮尔逊相似度</strong>:相似度是两个向量之间的皮尔逊系数。出于多样性的目的，我将在这个实现中使用<strong class="kf ir">皮尔逊相似度</strong>。</li></ol><h2 id="46ce" class="nc lw iq bd lx nd ne dn mb nf ng dp mf ko nh ni mj ks nj nk mn kw nl nm mr nn bi translated">代码</h2><p id="d389" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">由于我的笔记本电脑的计算能力有限，我将只使用评级的子集来构建推荐系统。特别是，我将从100万个收视率中随机抽取2万个收视率样本(2%)。</p><p id="91b0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我使用<strong class="kf ir"> scikit-learn库</strong>将数据集分成测试和训练。<strong class="kf ir">Cross _ validation . train _ test _ split</strong>根据测试实例的百分比将数据混洗并拆分成两个数据集，这里是0.2。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="bd98" class="nc lw iq nr b gy nv nw l nx ny"><strong class="nr ir">from</strong> <strong class="nr ir">sklearn</strong> <strong class="nr ir">import</strong> cross_validation <strong class="nr ir">as</strong> cv<br/>train_data, test_data = cv.train_test_split(small_data, test_size=0.2)</span></pre><p id="9109" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我需要创建一个用户条目矩阵。因为我已经将数据分为测试和训练，所以我需要创建两个矩阵。培训矩阵包含80%的评级，测试矩阵包含20%的评级。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="80d1" class="nc lw iq nr b gy nv nw l nx ny"><em class="lb"># Create two user-item matrices for training and testing data</em><br/>train_data_matrix = train_data.as_matrix(columns = ['user_id', 'movie_id', 'rating'])<br/>test_data_matrix = test_data.as_matrix(columns = ['user_id', 'movie_id', 'rating'])</span></pre><p id="4b49" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我使用sklearn的<strong class="kf ir"> pairwise_distances </strong>函数来计算<a class="ae kc" href="https://stackoverflow.com/questions/1838806/euclidean-distance-vs-pearson-correlation-vs-cosine-similarity" rel="noopener ugc nofollow" target="_blank">皮尔逊相关系数</a>。该方法提供了一种将距离矩阵作为输入的安全方法，同时保持了与许多其他采用向量数组的算法的兼容性。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="5a56" class="nc lw iq nr b gy nv nw l nx ny"><strong class="nr ir">from</strong> <strong class="nr ir">sklearn.metrics.pairwise</strong> <strong class="nr ir">import</strong> pairwise_distances<br/><br/><em class="lb"># User Similarity Matrix</em><br/>user_correlation = 1 - pairwise_distances(train_data, metric='correlation')<br/>user_correlation[np.isnan(user_correlation)] = 0</span><span id="aab7" class="nc lw iq nr b gy oc nw l nx ny"><em class="lb"># Item Similarity Matrix</em><br/>item_correlation = 1 - pairwise_distances(train_data_matrix.T, metric='correlation')<br/>item_correlation[np.isnan(item_correlation)] = 0</span></pre><p id="b3b7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有了相似性矩阵，我现在可以预测数据中没有包括的评分。使用这些预测，我可以将它们与测试数据进行比较，以尝试验证我们的推荐模型的质量。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="3a69" class="nc lw iq nr b gy nv nw l nx ny"><em class="lb"># Function to predict ratings</em><br/><strong class="nr ir">def</strong> predict(ratings, similarity, type='user'):<br/>    <strong class="nr ir">if</strong> type == 'user':<br/>        mean_user_rating = ratings.mean(axis=1)<br/>        <em class="lb"># Use np.newaxis so that mean_user_rating has same format as ratings</em><br/>        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])<br/>        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T<br/>    <strong class="nr ir">elif</strong> type == 'item':<br/>        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])<br/>    <strong class="nr ir">return</strong> pred</span></pre><h2 id="3f4b" class="nc lw iq bd lx nd ne dn mb nf ng dp mf ko nh ni mj ks nj nk mn kw nl nm mr nn bi translated">评估</h2><p id="5160" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">有许多评估指标，但用于评估预测评级准确性的最常用指标之一是<strong class="kf ir">均方根误差(RMSE) </strong>。我将使用sklearn的<strong class="kf ir"> mean_square_error (MSE) </strong>函数，其中RMSE就是MSE的平方根。我将使用scikit-learn的<strong class="kf ir">均方误差</strong>函数作为我的验证指标。比较基于用户和基于项目的协同过滤，看起来基于用户的协同过滤给出了更好的结果。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="4382" class="nc lw iq nr b gy nv nw l nx ny"><strong class="nr ir">from</strong> <strong class="nr ir">sklearn.metrics</strong> <strong class="nr ir">import</strong> mean_squared_error<br/><strong class="nr ir">from</strong> <strong class="nr ir">math</strong> <strong class="nr ir">import</strong> sqrt<br/><br/><em class="lb"># Function to calculate RMSE</em><br/><strong class="nr ir">def</strong> rmse(pred, actual):<br/>    <em class="lb"># Ignore nonzero terms.</em><br/>    pred = pred[actual.nonzero()].flatten()<br/>    actual = actual[actual.nonzero()].flatten()<br/>    <strong class="nr ir">return</strong> sqrt(mean_squared_error(pred, actual))</span><span id="2e38" class="nc lw iq nr b gy oc nw l nx ny"><em class="lb"># Predict ratings on the training data with both similarity score</em><br/>user_prediction = predict(train_data_matrix, user_correlation, type='user')<br/>item_prediction = predict(train_data_matrix, item_correlation, type='item')</span><span id="6af4" class="nc lw iq nr b gy oc nw l nx ny"><em class="lb"># RMSE on the train data</em><br/>print('User-based CF RMSE: ' + str(rmse(user_prediction, train_data_matrix)))<br/>print('Item-based CF RMSE: ' + str(rmse(item_prediction, train_data_matrix)))</span><span id="7bb5" class="nc lw iq nr b gy oc nw l nx ny">## Output<br/>User-based CF RMSE: 699.9584792778463<br/>Item-based CF RMSE: 114.97271725933925</span></pre><p id="33c9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">模型训练的RMSE是度量信号和噪声被模型解释了多少的度量。我注意到我的RMSE相当大。我想我可能过度拟合了训练数据。</p><p id="9cbc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">总的来说，<strong class="kf ir">基于记忆的协同过滤</strong>易于实现并产生合理的预测质量。然而，这种方法有一些缺点:</p><ul class=""><li id="bcb4" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la lh li lj lk bi translated">它没有解决众所周知的冷启动问题，即当新用户或新项目进入系统时。</li><li id="a4f2" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">它不能处理稀疏数据，这意味着很难找到对相同项目进行评级的用户。</li><li id="4c72" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">当没有任何评级的新用户或项目进入系统时，它会受到影响。</li><li id="ab9a" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">它倾向于推荐热门商品。</li></ul><p id="98dd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">注:</strong>基于内容和基于记忆的协同过滤的完整代码可以在<a class="ae kc" href="https://github.com/khanhnamle1994/movielens/blob/master/Content_Based_and_Collaborative_Filtering_Models.ipynb" rel="noopener ugc nofollow" target="_blank">这个Jupyter笔记本</a>中找到。</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi od"><img src="../Images/cc200521d68949e5407a3b04140187b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PfgYi6hg02TDM0GknVa2nQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Collaborative Filtering vs Content-Based Filtering</figcaption></figure><h1 id="f476" class="lv lw iq bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">3 —矩阵分解</h1><p id="f60d" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">在之前的尝试中，我已经使用了基于记忆的协同过滤来根据用户的评分数据进行电影推荐。我只能在一个非常小的数据样本(20，000个评级)上尝试它们，结果得到了相当高的均方根误差(糟糕的推荐)。计算项目或用户之间的距离关系的基于记忆的协同过滤方法有这两个主要问题:</p><ol class=""><li id="d4f6" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la nb li lj lk bi translated">它不太适合大规模数据集，尤其是基于用户行为相似性的实时推荐——这需要大量计算。</li><li id="4612" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la nb li lj lk bi translated">评级矩阵可能过度适合用户口味和偏好的嘈杂表示。当我们在原始数据上使用基于距离的“邻域”方法时，我们匹配稀疏的低级细节，我们假设这些细节代表用户的偏好向量而不是向量本身。</li></ol><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/ad7dd4c8e21afec4f82cb500183c1579.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*bWAAyciKq580ArTix_O3nw.jpeg"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">3 Reasons to Reduce Data’s Dimensionality</figcaption></figure><p id="35b6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我需要应用<strong class="kf ir">降维</strong>技术来从原始数据中提取口味和偏好，也就是所谓的低秩矩阵分解。为什么要降维？</p><ul class=""><li id="ddae" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la lh li lj lk bi translated">我可以发现原始数据中隐藏的相关性/特征。</li><li id="ac91" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">我可以删除无用的冗余和嘈杂的功能。</li><li id="a858" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">我可以更容易地解释和可视化数据。</li><li id="ccb3" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">我也可以访问更容易的数据存储和处理。</li></ul><h2 id="c27b" class="nc lw iq bd lx nd ne dn mb nf ng dp mf ko nh ni mj ks nj nk mn kw nl nm mr nn bi translated">数学</h2><p id="8b1a" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated"><strong class="kf ir"> <em class="lb">基于模型的协同过滤</em> </strong>是在<strong class="kf ir"> <em class="lb">矩阵分解(MF) </em> </strong>的基础上得到更大的曝光，主要作为潜变量分解和降维的无监督学习方法。矩阵分解被广泛用于推荐系统，与基于记忆的CF相比，它可以更好地处理可伸缩性和稀疏性:</p><ul class=""><li id="791b" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la lh li lj lk bi translated">MF的目标是从已知的评分中学习用户的潜在偏好和项目的潜在属性(学习描述评分特征的特征),然后通过用户和项目的潜在特征的点积来预测未知的评分。</li><li id="42e8" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">当你有一个非常稀疏的矩阵，有很多维度，通过做矩阵分解，你可以把用户项矩阵重新构造成低秩结构，你可以用两个低秩矩阵相乘来表示矩阵，其中的行包含潜在向量。</li><li id="1aaa" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">通过将低秩矩阵相乘，填充原始矩阵中缺少的条目，使该矩阵尽可能接近原始矩阵。</li></ul><p id="20c0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一种众所周知的矩阵分解方法是<strong class="kf ir"> <em class="lb">【奇异值分解】</em> </strong>。在高层次上，SVD是一种将矩阵A分解为原始矩阵A的最佳低秩(即更小/更简单)近似的算法。在数学上，它将A分解为两个酉矩阵和一个对角矩阵:</p><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/1f520a8d9c5b16206dfbdd9d4cf8ce27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W4MnB2hyvgqedLmwJLrpqw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">SVD Equation</figcaption></figure><p id="c9b6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<strong class="kf ir"> A是输入数据矩阵</strong>(用户评分)<strong class="kf ir"> U是左奇异向量</strong>(用户“特征”矩阵)<strong class="kf ir"> Sum是奇异值对角矩阵</strong>(实质上是每个概念的权重/强度)<strong class="kf ir"> V^T是右奇异向量</strong>(电影“特征”矩阵)。u和V^T是列正交的，代表不同的东西:<strong class="kf ir"> U代表用户“喜欢”每个特征的程度</strong>和<strong class="kf ir"> V^T代表每个特征与每个电影的相关程度</strong>。</p><p id="82b5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了得到较低等级的近似，我采用这些矩阵并只保留前k个特征，这可以被认为是潜在的品味和偏好向量。</p><h2 id="513a" class="nc lw iq bd lx nd ne dn mb nf ng dp mf ko nh ni mj ks nj nk mn kw nl nm mr nn bi translated"><strong class="ak">代码</strong></h2><p id="ad23" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">Scipy和Numpy都有进行奇异值分解的函数。我将使用Scipy函数<em class="lb"> svds </em>,因为它让我可以选择要使用多少潜在因素来逼近原始评级矩阵(而不是在此之后将其截断)。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="46a5" class="nc lw iq nr b gy nv nw l nx ny"><strong class="nr ir">from</strong> <strong class="nr ir">scipy.sparse.linalg</strong> <strong class="nr ir">import</strong> svds <br/>U, sigma, Vt = svds(Ratings_demeaned, k = 50)</span></pre><p id="6b09" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因为我要利用矩阵乘法来获得预测，所以我要将Sum(现在是值)转换成对角矩阵形式。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="ef6a" class="nc lw iq nr b gy nv nw l nx ny">sigma = np.diag(sigma)</span></pre><p id="f11a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我现在有了为每个用户预测电影收视率所需的一切。我可以通过数学和矩阵乘法u，Sum，和V^T，得到a的秩k = 50的近似值，一次完成</p><p id="d0fc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">但是首先，我需要将用户均值加回去，以获得实际的星级预测。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="49a3" class="nc lw iq nr b gy nv nw l nx ny">all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + user_ratings_mean.reshape(-1, 1)</span></pre><p id="234a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有了每个用户的预测矩阵，我可以构建一个函数来为任何用户推荐电影。为了便于比较，我返回用户已经评级的电影列表。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="2156" class="nc lw iq nr b gy nv nw l nx ny">preds = pd.DataFrame(all_user_predicted_ratings, columns = Ratings.columns)</span></pre><p id="c945" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，我编写一个函数来返回指定用户尚未评级的预测评级最高的电影。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="df76" class="nc lw iq nr b gy nv nw l nx ny"><strong class="nr ir">def</strong> recommend_movies(predictions, userID, movies, original_ratings, num_recommendations):<br/>    <br/>    <em class="lb"># Get and sort the user's predictions</em><br/>    user_row_number = userID - 1 <em class="lb"># User ID starts at 1, not 0</em><br/>    sorted_user_predictions = preds.iloc[user_row_number].sort_values(ascending=False) <em class="lb"># User ID starts at 1</em><br/>    <br/>    <em class="lb"># Get the user's data and merge in the movie information.</em><br/>    user_data = original_ratings[original_ratings.user_id == (userID)]<br/>    user_full = (user_data.merge(movies, how = 'left', left_on = 'movie_id', right_on = 'movie_id').<br/>                     sort_values(['rating'], ascending=False)<br/>                 )<br/>    <br/>    <em class="lb"># Recommend the highest predicted rating movies that the user hasn't seen yet.</em><br/>    recommendations = (movies[~movies['movie_id'].isin(user_full['movie_id'])].<br/>         merge(pd.DataFrame(sorted_user_predictions).reset_index(), how = 'left',<br/>               left_on = 'movie_id',<br/>               right_on = 'movie_id').<br/>         rename(columns = {user_row_number: 'Predictions'}).<br/>         sort_values('Predictions', ascending = False).<br/>                       iloc[:num_recommendations, :-1]<br/>                      )<br/><br/>    <strong class="nr ir">return</strong> user_full, recommendations</span></pre><h2 id="2fd5" class="nc lw iq bd lx nd ne dn mb nf ng dp mf ko nh ni mj ks nj nk mn kw nl nm mr nn bi translated">评估</h2><p id="046d" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">我将使用<a class="ae kc" href="https://pypi.python.org/pypi/scikit-surprise" rel="noopener ugc nofollow" target="_blank"><em class="lb"/></a><em class="lb"/>库来评估其在MovieLens数据集上的RMSE(均方根误差),而不是像上次那样手动评估。这是Python Scikit-Learn的构建和分析推荐系统。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="1dda" class="nc lw iq nr b gy nv nw l nx ny"><em class="lb"># Import libraries from Surprise package</em><br/><strong class="nr ir">from</strong> <strong class="nr ir">surprise</strong> <strong class="nr ir">import</strong> Reader, Dataset, SVD, evaluate<br/><br/><em class="lb"># Load Reader library</em><br/>reader = Reader()<br/><br/><em class="lb"># Load ratings dataset with Dataset library</em><br/>data = Dataset.load_from_df(ratings[['user_id', 'movie_id', 'rating']], reader)<br/><br/><em class="lb"># Split the dataset for 5-fold evaluation</em><br/>data.split(n_folds=5)</span><span id="b8f6" class="nc lw iq nr b gy oc nw l nx ny"><em class="lb"># Use the SVD algorithm.</em><br/>svd = SVD()<br/><br/><em class="lb"># Compute the RMSE of the SVD algorithm.</em><br/>evaluate(svd, data, measures=['RMSE'])</span></pre><p id="c484" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我得到了一个平均值<em class="lb">均方根误差</em>0.8736，相当不错。</p><h2 id="82e2" class="nc lw iq bd lx nd ne dn mb nf ng dp mf ko nh ni mj ks nj nk mn kw nl nm mr nn bi translated">该建议</h2><p id="33e1" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">让我们试着为ID为1310的用户推荐20部电影。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="9490" class="nc lw iq nr b gy nv nw l nx ny">predictions = recommend_movies(preds, 1310, movies, ratings, 20)</span><span id="15ae" class="nc lw iq nr b gy oc nw l nx ny">predictions</span></pre><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi og"><img src="../Images/2a290f000014da07a394d28ada59f3ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1NNP0ayB8_HbMChzoYv-pw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Recommendations using SVD</figcaption></figure><p id="cea0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些看起来是很好的建议。很高兴看到，虽然我实际上没有使用电影的类型作为特征，但截断矩阵分解的特征“拾取”了用户的潜在品味和偏好。我推荐了一些喜剧、戏剧和爱情电影——这些都是这个用户评价最高的电影类型。</p><p id="87b8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">注:</strong>SVD矩阵分解的完整代码可以在<a class="ae kc" href="https://github.com/khanhnamle1994/movielens/blob/master/SVD_Model.ipynb" rel="noopener ugc nofollow" target="_blank">这本Jupyter笔记本</a>中找到。</p><h1 id="e94e" class="lv lw iq bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">4 —深度学习</h1><h2 id="2fa9" class="nc lw iq bd lx nd ne dn mb nf ng dp mf ko nh ni mj ks nj nk mn kw nl nm mr nn bi translated">数学</h2><p id="a852" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">使用深度学习的思路类似于基于模型的矩阵分解。在矩阵分解中，我们将原始稀疏矩阵分解成2个低秩正交矩阵的乘积。对于深度学习实现，我们不需要它们是正交的，我们希望我们的模型能够学习嵌入矩阵本身的值。对于特定的电影-用户组合，从嵌入矩阵中查找用户潜在特征和电影潜在特征。这些是进一步线性和非线性图层的输入值。我们可以将此输入传递给多个relu、线性或sigmoid层，并通过任何优化算法(Adam、SGD等)学习相应的权重。).</p><h2 id="fd55" class="nc lw iq bd lx nd ne dn mb nf ng dp mf ko nh ni mj ks nj nk mn kw nl nm mr nn bi translated">代码</h2><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oh"><img src="../Images/ec9c3a90fff5d987fc2218b81087dea3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*OK0qufUIpzzJO1Ofqy5cqw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Architecture for Neural Network</figcaption></figure><p id="6656" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是我的神经网络的主要组成部分:</p><ul class=""><li id="991c" class="lc ld iq kf b kg kh kk kl ko le ks lf kw lg la lh li lj lk bi translated">左侧嵌入层，通过潜在因素矩阵创建用户。</li><li id="ca81" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">通过潜在因素矩阵创建电影的右嵌入层。</li><li id="da58" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">当这些图层的输入是(I)用户id和(ii)电影id时，它们将分别返回用户和电影的潜在因素向量。</li><li id="4b9e" class="lc ld iq kf b kg ll kk lm ko ln ks lo kw lp la lh li lj lk bi translated">采用这两个潜在向量的点积来返回预测评级的合并层。</li></ul><p id="3c46" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这段代码基于<a class="ae kc" href="http://www.fenris.org/" rel="noopener ugc nofollow" target="_blank">阿尔凯斯特</a>的博客文章<a class="ae kc" href="http://www.fenris.org/2016/03/07/index-html" rel="noopener ugc nofollow" target="_blank">Keras</a>中概述的方法。</p><p id="0d6f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然后，我使用均方误差(MSE)作为损失函数和AdaMax学习算法来编译模型。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="834e" class="nc lw iq nr b gy nv nw l nx ny"><em class="lb"># Define model</em><br/>model = CFModel(max_userid, max_movieid, K_FACTORS)<br/><em class="lb"># Compile the model using MSE as the loss function and the AdaMax learning algorithm</em><br/>model.compile(loss='mse', optimizer='adamax')</span></pre><p id="3a83" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在我需要训练模型。这一步将是最耗时的一步。在我的特殊情况下，对于我们的数据集，它有近100万个评级，近6，000个用户和4，000部电影，我在我的MacBook笔记本电脑CPU内每个时期大约6分钟(30个时期~ 3小时)训练了模型。我以90/10的比例分割了训练和验证数据。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="d22b" class="nc lw iq nr b gy nv nw l nx ny"><em class="lb"># Callbacks monitor the validation loss</em><br/><em class="lb"># Save the model weights each time the validation loss has improved</em><br/>callbacks = [EarlyStopping('val_loss', patience=2), <br/>             ModelCheckpoint('weights.h5', save_best_only=True)]<br/><br/><em class="lb"># Use 30 epochs, 90% training data, 10% validation data </em><br/>history = model.fit([Users, Movies], Ratings, nb_epoch=30, validation_split=.1, verbose=2, callbacks=callbacks)</span></pre><p id="983e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下一步是实际预测随机用户对随机电影的评价。下面，我对所有用户和所有电影应用新训练的深度学习模型，对每个用户和电影使用100维嵌入。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="89a6" class="nc lw iq nr b gy nv nw l nx ny"><em class="lb"># Use the pre-trained model</em><br/>trained_model = CFModel(max_userid, max_movieid, K_FACTORS)<br/><em class="lb"># Load weights</em><br/>trained_model.load_weights('weights.h5')</span></pre><p id="d83d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里我定义了一个函数来预测用户对未评级项目的评级。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="9bca" class="nc lw iq nr b gy nv nw l nx ny"><em class="lb"># Function to predict the ratings given User ID and Movie ID</em><br/><strong class="nr ir">def</strong> predict_rating(user_id, movie_id):<br/>    <strong class="nr ir">return</strong> trained_model.rate(user_id - 1, movie_id - 1)</span></pre><h2 id="e5ea" class="nc lw iq bd lx nd ne dn mb nf ng dp mf ko nh ni mj ks nj nk mn kw nl nm mr nn bi translated">评估</h2><p id="36c0" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">在上面的训练过程中，每当验证损失有所改善时，我都会保存模型权重。因此，我可以使用该值来计算最佳验证均方根误差。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="7a66" class="nc lw iq nr b gy nv nw l nx ny"><em class="lb"># Show the best validation RMSE</em><br/>min_val_loss, idx = min((val, idx) <strong class="nr ir">for</strong> (idx, val) <strong class="nr ir">in</strong> enumerate(history.history['val_loss']))</span><span id="dc38" class="nc lw iq nr b gy oc nw l nx ny"><strong class="nr ir">print</strong> 'Minimum RMSE at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(math.sqrt(min_val_loss))</span><span id="b848" class="nc lw iq nr b gy oc nw l nx ny">## Output<br/>Minimum RMSE at epoch 17 = 0.8616</span></pre><p id="e1da" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最好的验证损失是在第17个时期的0.7424。取那个数的平方根，得到了<em class="lb"> 0.8616 </em>的RMSE值，比SVD模型得到的RMSE(<em class="lb">0.8736</em>)要好。</p><h2 id="0c63" class="nc lw iq bd lx nd ne dn mb nf ng dp mf ko nh ni mj ks nj nk mn kw nl nm mr nn bi translated">该建议</h2><p id="460e" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">这里我给用户ID 2000做一个未分级的20部电影的推荐列表，按照预测值排序。让我们看看。</p><pre class="lr ls lt lu gt nq nr ns nt aw nu bi"><span id="fa74" class="nc lw iq nr b gy nv nw l nx ny">recommendations = ratings[ratings['movie_id'].isin(user_ratings['movie_id']) == False][['movie_id']].drop_duplicates()</span><span id="9bbf" class="nc lw iq nr b gy oc nw l nx ny">recommendations['prediction'] = recommendations.apply(<strong class="nr ir">lambda</strong> x: predict_rating(TEST_USER, x['movie_id']), axis=1)</span><span id="abc1" class="nc lw iq nr b gy oc nw l nx ny">recommendations.sort_values(by='prediction', ascending=False).merge(movies, on='movie_id', how='inner',<br/>suffixes=['_u', '_m']).head(20)</span></pre><figure class="lr ls lt lu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oi"><img src="../Images/39af0b637709cddac840bdb0c938c5f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TV-g8yLa1JhIr6c9ILUDpA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Recommendations using Deep Learning / Neural Networks</figcaption></figure><p id="28b8" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这个模型比我以前尝试过的所有方法(基于内容的、用户-项目相似性的协同过滤，SVD)都表现得更好。我当然可以通过增加更多的线性和非线性层来提高这个模型的性能。</p><p id="7938" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">注:</strong>深度学习模型的完整代码可以在<a class="ae kc" href="https://github.com/khanhnamle1994/movielens/blob/master/Deep_Learning_Model.ipynb" rel="noopener ugc nofollow" target="_blank">本Jupyter笔记本</a>中找到。</p><h1 id="828b" class="lv lw iq bd lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms bi translated">最后一次外卖</h1><p id="0694" class="pw-post-body-paragraph kd ke iq kf b kg mt ki kj kk mu km kn ko mv kq kr ks mw ku kv kw mx ky kz la ij bi translated">推荐引擎是您的伴侣和顾问，通过为您提供量身定制的选项和创建个性化的体验来帮助您做出正确的选择。毫无疑问，推荐引擎在新时代越来越受欢迎和重要。学会使用它们对企业更有竞争力，对消费者更有效率，这将是对你最有利的。</p><p id="d56b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我希望这篇文章有助于你了解4种不同的方法来建立你自己的电影推荐系统。你可以通过这个链接查看我的GitHub repo中的所有源代码(<a class="ae kc" href="https://github.com/khanhnamle1994/movielens" rel="noopener ugc nofollow" target="_blank">https://github.com/khanhnamle1994/movielens</a>)。如果您有任何问题或改进建议，请告诉我！</p><p id="e5cb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi">— —</p><p id="6a6b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">如果你喜欢这首曲子，我希望你能按下鼓掌按钮</em>👏<em class="lb">这样别人可能会偶然发现它。你可以在</em> <a class="ae kc" href="https://github.com/khanhnamle1994" rel="noopener ugc nofollow" target="_blank"> <em class="lb"> GitHub </em> </a> <em class="lb">上找到我自己的代码，在</em><a class="ae kc" href="https://jameskle.com" rel="noopener ugc nofollow" target="_blank"><em class="lb">【https://jameskle.com/】</em></a><em class="lb">上找到更多我的写作和项目。也可以在</em> <a class="ae kc" href="https://twitter.com/@james_aka_yale" rel="noopener ugc nofollow" target="_blank"> <em class="lb">推特</em> </a> <em class="lb">，</em> <a class="ae kc" href="mailto:khanhle.1013@gmail.com" rel="noopener ugc nofollow" target="_blank"> <em class="lb">上关注我直接发邮件给我</em> </a> <em class="lb">或者</em> <a class="ae kc" href="http://www.linkedin.com/in/khanhnamle94" rel="noopener ugc nofollow" target="_blank"> <em class="lb">在LinkedIn </em> </a> <em class="lb">上找我。</em> <a class="ae kc" href="http://eepurl.com/deWjzb" rel="noopener ugc nofollow" target="_blank"> <em class="lb">注册我的简讯</em> </a> <em class="lb">就在你的收件箱里接收我关于数据科学、机器学习和人工智能的最新想法吧！</em></p></div></div>    
</body>
</html>