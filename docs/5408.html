<html>
<head>
<title>Automated Hyper-Parameter Optimization in SageMaker</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SageMaker 中的自动化超参数优化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automated-hyper-parameter-optimization-in-sagemaker-492f4c5205b4?source=collection_archive---------9-----------------------#2018-10-16">https://towardsdatascience.com/automated-hyper-parameter-optimization-in-sagemaker-492f4c5205b4?source=collection_archive---------9-----------------------#2018-10-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/02f600ed4014f9d331c46ed2168a6cf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0RuFKK3VBOa3xh3UOuBfRw.jpeg"/></div></div></figure><p id="edda" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">注:代码示例在</em> <a class="ae kx" href="https://blog.zakjost.com/post/sagemaker-hpo/" rel="noopener ugc nofollow" target="_blank"> <em class="kw">我的博客</em> </a> <em class="kw">上呈现比在介质上好得多。</em></p><h1 id="ad87" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">什么是超参数优化(HPO)？</h1><p id="7689" class="pw-post-body-paragraph jy jz iq ka b kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv ij bi translated">因此，您已经构建了您的模型，并获得了合理的结果，现在准备尽可能多地挤出性能。一种可能是进行<a class="ae kx" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search" rel="noopener ugc nofollow" target="_blank">网格搜索</a>，在那里你尝试超参数的每一种可能的组合，并选择最好的一个。如果您的选择数量相对较少，这种方法很有效，但是如果您有大量的超参数，并且有些是可能跨越几个数量级的连续值，那该怎么办呢？<a class="ae kx" href="https://en.wikipedia.org/wiki/Random_search" rel="noopener ugc nofollow" target="_blank">随机搜索</a>可以很好地探索参数空间，而无需致力于探索<em class="kw">所有的参数空间</em>，但是在黑暗中随机探索是我们能做的最好的事情吗？</p><p id="fd49" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当然不是。<a class="ae kx" href="https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html" rel="noopener ugc nofollow" target="_blank">贝叶斯优化</a>是一种在进行顺序决策时优化功能的技术。在这种情况下，我们试图通过选择超参数值来最大化性能。这种顺序决策框架意味着，您为下一步选择的超参数将受到所有先前尝试的性能的影响。贝叶斯优化做出关于如何平衡探索参数空间的新区域和利用已知表现良好的区域的原则性决定。这就是说，使用贝叶斯优化通常比网格搜索和随机搜索更有效。</p><h1 id="a7b9" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">怎么做</h1><p id="01e8" class="pw-post-body-paragraph jy jz iq ka b kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv ij bi translated">好消息是 SageMaker 使这变得非常容易，因为该平台负责以下事项:</p><ol class=""><li id="e687" class="mb mc iq ka b kb kc kf kg kj md kn me kr mf kv mg mh mi mj bi translated">实施贝叶斯优化算法来处理分类、整数和浮点超参数</li><li id="4e12" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">在给定一组来自 HPO 服务的超参数的情况下，协调模型的训练和评估</li><li id="3582" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">整合培训作业和 HPO 服务，后者会传达选定的超参数值，并在作业完成后报告绩效</li></ol><h1 id="889e" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">先决条件</h1><p id="0016" class="pw-post-body-paragraph jy jz iq ka b kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv ij bi translated">下面的代码将假设我们正在使用 TensorFlow 估计器模型，但是与 HPO 相关的部分应该扩展到任何<a class="ae kx" href="https://sagemaker.readthedocs.io/en/latest/estimators.html" rel="noopener ugc nofollow" target="_blank"> SageMaker 估计器</a>。要以本示例所示的方式运行代码，您需要以下内容:</p><ul class=""><li id="2d7e" class="mb mc iq ka b kb kc kf kg kj md kn me kr mf kv mp mh mi mj bi translated">对 SageMaker 的工作原理有所了解。如果你想要一些这样的例子，在<a class="ae kx" href="https://github.com/awslabs/amazon-sagemaker-examples" rel="noopener ugc nofollow" target="_blank">这个回购</a>中有几个官方笔记本例子。你可能会发现<a class="ae kx" href="https://github.com/awslabs/amazon-sagemaker-examples/tree/master/hyperparameter_tuning/tensorflow_mnist" rel="noopener ugc nofollow" target="_blank"> TensorFlow HPO 的例子</a>特别相关。</li><li id="c03f" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mp mh mi mj bi translated">有 SageMaker 的 Python <a class="ae kx" href="https://github.com/aws/sagemaker-python-sdk" rel="noopener ugc nofollow" target="_blank"> SDK </a></li><li id="736a" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mp mh mi mj bi translated">已经配置了必要的 API 权限，或者正在 SageMaker 笔记本实例中运行</li></ul><h1 id="6626" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">步骤 1-创建评估者</h1><p id="5934" class="pw-post-body-paragraph jy jz iq ka b kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv ij bi translated">使用 SageMaker 运行 HPO 的一个关键要求是，您的模型需要:</p><ol class=""><li id="d5e2" class="mb mc iq ka b kb kc kf kg kj md kn me kr mf kv mg mh mi mj bi translated">预计超参数将从 SageMaker 传递</li><li id="8468" class="mb mc iq ka b kb mk kf ml kj mm kn mn kr mo kv mg mh mi mj bi translated">将性能指标写入日志</li></ol><p id="1282" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于内置算法，这已经为您完成了。在使用 SageMaker 构建任意张量流模型的情况下，这意味着在<code class="fe mq mr ms mt b">model.py</code>文件中正确配置东西，也称为“入口点”。这是 SageMaker 用来构建 TensorFlow 模型的文件，它希望定义符合特定输入/输出模式的某些函数。(有关您需要指定的功能的更多详细信息，请参见<a class="ae kx" href="https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/README.rst" rel="noopener ugc nofollow" target="_blank"> TensorFlow 自述文件</a>。)</p><h1 id="74cd" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">让您的模型准备好接受 SageMaker 的超参数</h1><p id="602d" class="pw-post-body-paragraph jy jz iq ka b kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv ij bi translated">为了动态地指定参数值，您的模型代码需要接受、解析和利用它们。在 TensorFlow 中，您允许 SageMaker 通过向需要在入口点文件中指定的函数添加<code class="fe mq mr ms mt b">hyperparameters</code>参数来指定超参数。例如，对于<code class="fe mq mr ms mt b">model_fn</code>中需要的超参数:</p><pre class="mu mv mw mx gt my mt mz na aw nb bi"><span id="f4ab" class="nc kz iq mt b gy nd ne l nf ng">DEFAULT_LEARNING_RATE = 1e-3<br/>def model_fn(features, labels, mode, hyperparameters=None):<br/>    if hyperparameters is None:<br/>        hyperparameters = dict()<br/>    # Extract parameters<br/>    learning_rate = hyperparameters.get('learning_rate', DEFAULT_LEARNING_RATE)<br/>    ...</span></pre><p id="6182" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您可能还希望在<code class="fe mq mr ms mt b">train_input_fn</code>中有一个超参数，例如指定训练时期的数量:</p><pre class="mu mv mw mx gt my mt mz na aw nb bi"><span id="59c1" class="nc kz iq mt b gy nd ne l nf ng">def train_input_fn(training_dir, hyperparameters=None):<br/>    # Extract parameters<br/>    if not hyperparameters:<br/>        hyperparameters = dict()</span><span id="a6d5" class="nc kz iq mt b gy nh ne l nf ng">    epochs = hyperparameters.get('epochs', None)<br/>    ...</span></pre><p id="e5b0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果指定了参数，这些示例提取参数，如果没有指定，则使用默认值。</p><h1 id="861c" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">将性能指标写入日志</h1><p id="5976" class="pw-post-body-paragraph jy jz iq ka b kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv ij bi translated">将性能指标写入日志的第二个要求是 SageMaker 的一个实现细节:它通过从训练日志文本中提取模型性能来获得运行的模型性能。这些是发送回 HPO 引擎的值。</p><p id="90d5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于 TensorFlow，默认情况下，<code class="fe mq mr ms mt b">EstimatorSpec</code>中指定的指标会写入日志。例如，这段代码是我的<code class="fe mq mr ms mt b">model_fn</code>的一部分:</p><pre class="mu mv mw mx gt my mt mz na aw nb bi"><span id="5357" class="nc kz iq mt b gy nd ne l nf ng">def model_fn(features, labels, model, hyperparameters=None)<br/>    ...<br/>    if mode == tf.estimator.ModeKeys.EVAL:<br/>        eval_metric_ops = {<br/>            "roc_auc": tf.metrics.auc(<br/>                labels, <br/>                predictions,<br/>                summation_method='careful_interpolation'),<br/>            "pr_auc": tf.metrics.auc(<br/>                labels, <br/>                predictions, <br/>                summation_method='careful_interpolation', <br/>                curve='PR'),<br/>        }<br/>    else:<br/>        # e.g. in "training" mode<br/>        eval_metric_ops = {}</span><span id="bfef" class="nc kz iq mt b gy nh ne l nf ng">    return tf.estimator.EstimatorSpec(<br/>        mode=mode,<br/>        loss=loss,<br/>        train_op=train_op,<br/>        eval_metric_ops=eval_metric_ops,<br/>    )</span></pre><p id="079e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在训练期间，模型将定期停止并评估测试集(这个过程的细节可以由您配置)。这些事件的日志如下所示:</p><pre class="mu mv mw mx gt my mt mz na aw nb bi"><span id="499d" class="nc kz iq mt b gy nd ne l nf ng"><em class="kw">2018–10–02 17:23:40,657 INFO — tensorflow — Saving dict for global step 101: global_step = 101, loss = 0.45420808, pr_auc = 0.36799875, roc_auc = 0.6891242</em></span></pre><p id="5436" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是 SageMaker 将用来衡量任何特定培训工作的表现。</p><h1 id="3eb3" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">构建评估器</h1><p id="4ff6" class="pw-post-body-paragraph jy jz iq ka b kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv ij bi translated">评估员通常用于开始一项培训工作。这使您能够告诉 SageMaker 在哪里存储输出，哪些实例用于训练…等等。既然入口点文件中的函数已经正确配置为接受超参数并将性能指标写入日志，您就可以创建 TensorFlow 估计器了:</p><pre class="mu mv mw mx gt my mt mz na aw nb bi"><span id="9f35" class="nc kz iq mt b gy nd ne l nf ng">from sagemaker.tensorflow import TensorFlow</span><span id="0c29" class="nc kz iq mt b gy nh ne l nf ng"># The parameters that are constant and will not be tuned<br/>shared_hyperparameters = {<br/>    'number_layers': 5,<br/>}</span><span id="950a" class="nc kz iq mt b gy nh ne l nf ng">tf_estimator = TensorFlow(<br/>    entry_point='my/tensorflow/model.py',<br/>    role='&lt;sagemaker_role_arn&gt;',<br/>    train_instance_count=1,<br/>    train_instance_type='ml.p3.2xlarge',<br/>    training_steps=10000,<br/>    hyperparameters=shared_hyperparameters,<br/>)</span></pre><h1 id="4077" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">步骤 2 —定义绩效指标</h1><p id="58f7" class="pw-post-body-paragraph jy jz iq ka b kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv ij bi translated">在这一步，我们需要告诉 SageMaker <em class="kw">如何</em>从日志中提取性能信息。这是通过指定一个<a class="ae kx" href="https://regexr.com/" rel="noopener ugc nofollow" target="_blank">正则表达式</a>并将其分配给一个度量名称来实现的。尽管您可以指定多个表达式(AWS CloudWatch 会自动收集这些表达式以便于绘图/监控)，但需要挑出其中一个作为 HPO 的优化目标。您还需要指定是最大化还是最小化数量。注意，虽然正则表达式可能匹配多个日志条目，但是日志中的最后一个实例作为最终性能值返回。</p><pre class="mu mv mw mx gt my mt mz na aw nb bi"><span id="b0fd" class="nc kz iq mt b gy nd ne l nf ng">objective_metric_name = 'PR-AUC'<br/>objective_type = 'Maximize'<br/>metric_definitions = [<br/>    {'Name': 'ROC-AUC', 'Regex': 'roc_auc = ([0-9\\.]+)'},<br/>    {'Name': 'PR-AUC', 'Regex': 'pr_auc = ([0-9\\.]+)'}<br/>]</span></pre><h1 id="6ad5" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">步骤 3-定义超参数搜索空间</h1><p id="9e69" class="pw-post-body-paragraph jy jz iq ka b kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv ij bi translated">我们现在需要指定我们的超参数被称为什么，它们是什么类型(连续、整数或分类)，以及它们的可能值是什么。下面是一个例子:</p><pre class="mu mv mw mx gt my mt mz na aw nb bi"><span id="371b" class="nc kz iq mt b gy nd ne l nf ng">from sagemaker.tuner import (<br/>    IntegerParameter, CategoricalParameter, <br/>    ContinuousParameter, HyperparameterTuner)</span><span id="d102" class="nc kz iq mt b gy nh ne l nf ng">hyperparameter_ranges = {<br/>    "learning_rate": ContinuousParameter(1e-5, 1e-1),<br/>    "number_nodes": IntegerParameter(32, 512),<br/>    "optimizer": CategoricalParameter(['Adam', 'SGD'])<br/>}</span></pre><h1 id="11f4" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">步骤 4-指定优化迭代的次数</h1><p id="ad02" class="pw-post-body-paragraph jy jz iq ka b kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv ij bi translated">最后，我们需要决定如何运行 HPO 作业。如果您并行运行许多作业，那么您可以同时探索大部分空间。然而，如果您只是并行运行一百万个作业，那么您实际上是在进行随机搜索。贝叶斯优化的<em class="kw">顺序</em>本质允许之前运行的结果通知未来的运行。</p><p id="bdd7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，我们需要决定总共运行多少个作业，以及在任何给定时间并行运行多少个作业。例如，我们可能运行 100 个作业，并行运行 5 个。总共有 20 次连续迭代，每次探索 5 个点。这里的选择将取决于参数空间的大小和预算。</p><p id="81bd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在你有了要求 SageMaker 管理 HPO 所需的一切:</p><pre class="mu mv mw mx gt my mt mz na aw nb bi"><span id="928f" class="nc kz iq mt b gy nd ne l nf ng">tuner = HyperparameterTuner(<br/>    tf_estimator,<br/>    objective_metric_name,<br/>    hyperparameter_ranges,<br/>    metric_definitions,<br/>    max_jobs=100,<br/>    max_parallel_jobs=5,<br/>    objective_type=objective_type<br/>)</span><span id="cbff" class="nc kz iq mt b gy nh ne l nf ng"># The data configuration<br/>channel = {<br/>    'training': 's3://&lt;bucket_name&gt;/my/training_file.csv',<br/>    'test': 's3://&lt;bucket_name&gt;/my/test_file.csv',<br/>}</span><span id="1a9b" class="nc kz iq mt b gy nh ne l nf ng">tuner.fit(inputs=channel)</span></pre><h1 id="6b84" class="ky kz iq bd la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv bi translated">最终性能</h1><p id="7d3e" class="pw-post-body-paragraph jy jz iq ka b kb lw kd ke kf lx kh ki kj ly kl km kn lz kp kq kr ma kt ku kv ij bi translated">您可以使用<a class="ae kx" href="https://sagemaker.readthedocs.io/en/latest/tuner.html" rel="noopener ugc nofollow" target="_blank"> sdk </a>来 pinging SageMaker 以获得状态报告，或者从 HPO 运行中获得最佳作业的统计数据。您还可以从 AWS SageMaker 控制台完成这项工作，它很好地显示了所有作业的性能摘要以及 HPO 作业配置。</p><p id="2983" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如上所述，你可以在控制台中进入 CloudWatch，点击<code class="fe mq mr ms mt b">Browse Metrics</code>，找到你在第二步<code class="fe mq mr ms mt b">metric_definitions</code>的<code class="fe mq mr ms mt b">Name</code>字段中定义的指标。</p><p id="bade" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">完成所有工作后，您只需发出以下命令即可部署最佳模型:</p><pre class="mu mv mw mx gt my mt mz na aw nb bi"><span id="b982" class="nc kz iq mt b gy nd ne l nf ng">tuner.deploy(<br/>    initial_instance_count=1,<br/>    instance_type='ml.p3.2xlarge'<br/>)</span></pre></div><div class="ab cl ni nj hu nk" role="separator"><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn no"/><span class="nl bw bk nm nn"/></div><div class="ij ik il im in"><p id="c596" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">你可以在【blog.zakjost.com】<a class="ae kx" href="http://blog.zakjost.com" rel="noopener ugc nofollow" target="_blank"><em class="kw"/></a>找到我所有的内容并订阅</em></p></div></div>    
</body>
</html>