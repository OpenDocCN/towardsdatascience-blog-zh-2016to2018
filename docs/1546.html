<html>
<head>
<title>How to use a machine learning model on iOS 11 using Core ML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Core ML在iOS 11上使用机器学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-use-a-machine-learning-model-on-ios-11-using-core-ml-24a9d8654df6?source=collection_archive---------2-----------------------#2017-09-18">https://towardsdatascience.com/how-to-use-a-machine-learning-model-on-ios-11-using-core-ml-24a9d8654df6?source=collection_archive---------2-----------------------#2017-09-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/bda701d4c082c11567ccdbfe80710dd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I4a6MOBxYhgQsBRcwbShRw.jpeg"/></div></div></figure><p id="4046" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">iOS 11的发布给开发者带来了很多新功能，比如<a class="ae kw" href="https://developer.apple.com/arkit/" rel="noopener ugc nofollow" target="_blank"> ARKit </a>、<a class="ae kw" href="https://developer.apple.com/documentation/corenfc" rel="noopener ugc nofollow" target="_blank"> Core NFC </a>等等。对我来说真正突出的一点是增加了<a class="ae kw" href="https://developer.apple.com/documentation/coreml" rel="noopener ugc nofollow" target="_blank">核心ML </a>。</p><blockquote class="kx ky kz"><p id="74ed" class="jy jz la ka b kb kc kd ke kf kg kh ki lb kk kl km lc ko kp kq ld ks kt ku kv ij bi translated">Core ML可以让你将任何机器学习模型集成到你的iOS应用中。</p></blockquote><p id="c497" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在本教程中，我将使用一个预先训练好的深度卷积神经网络来确定一张图片是否包含一只猫或一只狗。这是我在学习DL时建立的一个非常简单的模型。</p><h2 id="bd6e" class="le lf iq bd lg lh li dn lj lk ll dp lm kj ln lo lp kn lq lr ls kr lt lu lv lw bi translated"><strong class="ak">先决条件</strong></h2><p id="143c" class="pw-post-body-paragraph jy jz iq ka b kb lx kd ke kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv ij bi translated">要完成本教程，您需要:</p><ol class=""><li id="e1c5" class="mc md iq ka b kb kc kf kg kj me kn mf kr mg kv mh mi mj mk bi translated">运行iOS 11的设备</li><li id="adfb" class="mc md iq ka b kb ml kf mm kj mn kn mo kr mp kv mh mi mj mk bi translated">Xcode 9</li><li id="3d28" class="mc md iq ka b kb ml kf mm kj mn kn mo kr mp kv mh mi mj mk bi translated">受过训练的模特</li></ol><h1 id="fd08" class="mq lf iq bd lg mr ms mt lj mu mv mw lm mx my mz lp na nb nc ls nd ne nf lv ng bi translated">获取核心ML模型</h1><p id="f449" class="pw-post-body-paragraph jy jz iq ka b kb lx kd ke kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv ij bi translated">要将您的模型转换为<a class="ae kw" href="https://developer.apple.com/documentation/coreml" rel="noopener ugc nofollow" target="_blank"> Core ML </a>，您需要安装Apple提供的命令行工具。</p><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="561a" class="le lf iq nm b gy nq nr l ns nt">pip install coremltools</span></pre><p id="ce7f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，在与模型相同的文件夹中创建一个python文件，并添加下面的代码。<em class="la"> image_input_names和is_bgr </em>告诉转换器我们的输入参数将是一个图像。</p><figure class="nh ni nj nk gt jr"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="c7a1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">注意:如果您的模型不是用Keras构建的，或者如果您需要关于可用参数的更多信息，您可以查看Apple文档。</strong><a class="ae kw" href="https://apple.github.io/coremltools/coremltools.converters.html" rel="noopener ugc nofollow" target="_blank">https://apple . github . io/coremltools/coremltools . converters . html</a></p><p id="362b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">创建后，执行python文件来转换您的模型。</p><pre class="nh ni nj nk gt nl nm nn no aw np bi"><span id="0a87" class="le lf iq nm b gy nq nr l ns nt">python your_file_name.py</span></pre><h1 id="af44" class="mq lf iq bd lg mr ms mt lj mu mv mw lm mx my mz lp na nb nc ls nd ne nf lv ng bi translated">将新模型添加到您的应用中</h1><p id="f690" class="pw-post-body-paragraph jy jz iq ka b kb lx kd ke kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv ij bi translated">首先，将模型拖到项目导航器中，将模型添加到Xcode项目中。<strong class="ka ir">将自动生成一个带有模型名称及其属性的新对象。</strong></p><p id="2b89" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您可以通过在Xcode中打开它来查看有关模型的信息。在查看mine时，我们可以看到模型类型和我们在转换模型时配置的输入/输出。</p><figure class="nh ni nj nk gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nw"><img src="../Images/48484473a02728ed5c75db669778a6ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hGfw7j6CkJKfHJrAGvZwCQ.png"/></div></div></figure><h2 id="3890" class="le lf iq bd lg lh li dn lj lk ll dp lm kj ln lo lp kn lq lr ls kr lt lu lv lw bi translated">给你的模型拍照</h2><p id="a348" class="pw-post-body-paragraph jy jz iq ka b kb lx kd ke kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv ij bi translated">首先实现本地相机来拍摄照片，为我们的模型提供素材。</p><p id="d0eb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在UIImagePickerController的委托中，我们将进行预测，并提供一个简单的警告来显示我们模型的输出。预测方法将在稍后实现。</p><figure class="nh ni nj nk gt jr"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h2 id="2c98" class="le lf iq bd lg lh li dn lj lk ll dp lm kj ln lo lp kn lq lr ls kr lt lu lv lw bi translated">调整照片大小</h2><p id="bbfc" class="pw-post-body-paragraph jy jz iq ka b kb lx kd ke kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv ij bi translated">如果你仔细看了我的模型的描述，你会注意到我的输入图像的大小是64x64。由于我的模型是用特定大小的图像训练的，我们需要将相机中的照片调整到与它们相同的大小。</p><figure class="nh ni nj nk gt jr"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h2 id="40df" class="le lf iq bd lg lh li dn lj lk ll dp lm kj ln lo lp kn lq lr ls kr lt lu lv lw bi translated">将UIImage转换为CVPixelBuffer</h2><p id="b372" class="pw-post-body-paragraph jy jz iq ka b kb lx kd ke kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv ij bi translated">遗憾的是<a class="ae kw" href="https://developer.apple.com/documentation/coreml" rel="noopener ugc nofollow" target="_blank"> Core ML </a>不允许我们将UIImage直接输入到模型中。而是需要转换成支持的类型<a class="ae kw" href="https://developer.apple.com/documentation/corevideo/cvpixelbuffer-q2e" rel="noopener ugc nofollow" target="_blank"><em class="la">CVPixelBuffer</em></a><em class="la">。我创建了一个简单的扩展来将UIImage转换成CVPixelBuffer。</em></p><figure class="nh ni nj nk gt jr"><div class="bz fp l di"><div class="nu nv l"/></div></figure><h2 id="a4a8" class="le lf iq bd lg lh li dn lj lk ll dp lm kj ln lo lp kn lq lr ls kr lt lu lv lw bi translated">做预测</h2><p id="31af" class="pw-post-body-paragraph jy jz iq ka b kb lx kd ke kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv ij bi translated">现在是有趣的部分！我们将使用我们之前创建的方法来格式化我们的UIImage，然后将它提供给我们的模型。一旦格式化，我们简单地调用<em class="la">预测</em>方法<em class="la"> </em>来获得我们的预测。</p><figure class="nh ni nj nk gt jr"><div class="bz fp l di"><div class="nu nv l"/></div></figure><p id="c62b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Tada！现在，您应该可以从您的模型中获得预测。</p><p id="cb9c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你可以在Github上找到完整的项目:<a class="ae kw" href="https://github.com/francoismarceau29/CoreMLCNNDemo" rel="noopener ugc nofollow" target="_blank">https://github.com/francoismarceau29/CoreMLCNNDemo</a></p><p id="aca2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你喜欢这篇文章，请一定留下你的关注，你也可以在twitter上联系我。</p></div></div>    
</body>
</html>