<html>
<head>
<title>Deploying Keras Deep Learning Models with Flask</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Flask 部署 Keras 深度学习模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deploying-keras-deep-learning-models-with-flask-5da4181436a2?source=collection_archive---------2-----------------------#2018-07-31">https://towardsdatascience.com/deploying-keras-deep-learning-models-with-flask-5da4181436a2?source=collection_archive---------2-----------------------#2018-07-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/ea37e96bd53cd164917441aa3c396d3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RtEhSUbFk8yNAoln.jpg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Source: Wikimedia Commons</figcaption></figure><div class=""/><p id="3e9d" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这篇文章演示了如何使用用<a class="ae la" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>构建的深度学习模型来设置端点以服务于预测。它首先介绍了一个使用<a class="ae la" href="http://flask.pocoo.org/" rel="noopener ugc nofollow" target="_blank"> Flask </a>来设置 Python 端点的例子，然后展示了在使用 Flask 为预测构建 Keras 端点时需要解决的一些问题。</p><p id="5280" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">将深度学习模型产品化具有挑战性，或者至少在过去对我来说是如此，原因有很多:</p><ul class=""><li id="9fb4" class="lb lc jf ke b kf kg kj kk kn ld kr le kv lf kz lg lh li lj bi translated"><strong class="ke jg">模型序列化:</strong>序列化模型的标准方法，比如 PMML，只有有限的支持。例如<a class="ae la" href="https://github.com/vaclavcadek/keras2pmml" rel="noopener ugc nofollow" target="_blank"> keras2pmml </a>缺少 relu 激活，这意味着我在<a class="ae la" rel="noopener" target="_blank" href="/data-science-for-startups-model-production-b14a29b2f920">模型生产</a>帖子中提出的数据流+ PMML 方法是不可行的。</li><li id="e455" class="lb lc jf ke b kf lk kj ll kn lm kr ln kv lo kz lg lh li lj bi translated"><strong class="ke jg">大型库:</strong>在我过去的<a class="ae la" rel="noopener" target="_blank" href="/data-science-for-startups-model-services-2facf2dde81d">帖子</a>中，我展示了如何使用 AWS lambda 函数来托管<a class="ae la" href="http://scikit-learn.org/" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>模型。这种方法对于 Keras 是有问题的，因为未压缩的 Keras 和 Tensorflow 库超过了 AWS lambda 的 256MB 文件上传限制。</li><li id="5c1d" class="lb lc jf ke b kf lk kj ll kn lm kr ln kv lo kz lg lh li lj bi translated"><strong class="ke jg">运行时间:</strong>批处理和实时预测都很难伸缩，因为我的大部分模型预测经验都是用 Java 编写的。我之前在<a class="ae la" rel="noopener" target="_blank" href="/data-science-for-startups-model-production-b14a29b2f920">的博客</a>中提到使用 Jetty 提供实时评估，使用 Google 的数据流提供批量评估。这篇文章展示了当你需要使用 Python 库进行估算时，如何使用 Flask 来代替 Jetty。</li></ul><p id="5217" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这篇文章的目的是展示如何使用 AWS 在 EC2 实例上设置一个 Keras 模型作为端点。我从探索下面的例子开始:</p><div class="ip iq gp gr ir lp"><a href="https://blog.keras.io/building-a-simple-keras-deep-learning-rest-api.html" rel="noopener  ugc nofollow" target="_blank"><div class="lq ab fo"><div class="lr ab ls cl cj lt"><h2 class="bd jg gy z fp lu fr fs lv fu fw je bi translated">构建一个简单的 Keras +深度学习 REST API</h2><div class="lw l"><h3 class="bd b gy z fp lu fr fs lv fu fw dk translated">这篇文章中的例子将作为构建你自己的深度学习 API 的模板/起点…</h3></div><div class="lx l"><p class="bd b dl z fp lu fr fs lv fu fw dk translated">blog.keras.io</p></div></div><div class="ly l"><div class="lz l ma mb mc ly md ix lp"/></div></div></a></div><p id="0235" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我将讨论的一些问题包括在 Keras 中使用模型持久性时处理自定义指标，在 Keras 与 Flask 结合使用时处理多线程问题，以及让它在 EC2 实例上运行。这篇文章的完整代码清单可以在<a class="ae la" href="https://github.com/bgweber/StartupDataScience/blob/master/DeepLearning/Flask_Keras.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。</p><p id="22dd" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这篇文章介绍了如何设置一个简单的 Flask 应用程序，然后展示了如何使用 Flask 来设置一个带有 Keras 模型的端点。它假设读者熟悉用 jupyter 设置 EC2 实例，这将在<a class="ae la" rel="noopener" target="_blank" href="/data-science-for-startups-r-python-2ca2cd149c5c">这里</a>讨论。</p><h2 id="b660" class="me mf jf bd mg mh mi dn mj mk ml dp mm kn mn mo mp kr mq mr ms kv mt mu mv mw bi translated">带烧瓶的 Hello World</h2><p id="6992" class="pw-post-body-paragraph kc kd jf ke b kf mx kh ki kj my kl km kn mz kp kq kr na kt ku kv nb kx ky kz ij bi translated">Flask 是一个 Python 库，它使得设置可以通过 web 调用的 Python 函数变得很容易。它使用注释来提供关于在哪些端点设置哪些功能的元数据。要使用 Flask，您首先需要安装模块:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="ba09" class="me mf jf nh b gy nl nm l nn no">pip3 install --user Flask</span></pre><p id="7d73" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为了熟悉 Flask，我们将设置一个简单的函数来回显传入的参数。下面的代码片段首先实例化一个 Flask 应用程序，定义函数，然后启动应用程序。使用 Flask，<em class="np"> app.route </em>注释用于指定在 web 上的何处使函数可用，以及允许哪些方法。使用下面的代码，该功能将在<em class="np"> </em> <code class="fe nq nr ns nh b"><em class="np">location:5000/predict</em></code>可用。该函数检查<code class="fe nq nr ns nh b">request.json</code>和<code class="fe nq nr ns nh b">request.args</code>对象的输入参数，这些参数的使用基于函数的调用方式(例如<em class="np">浏览器 get vs curl post </em>)。如果一个<em class="np">消息</em>参数已经被传递给该函数，当它被回显到该函数返回的 JSON 响应时。</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="039b" class="me mf jf nh b gy nl nm l nn no"><strong class="nh jg"># load Flask <br/></strong>import flask<br/>app = flask.Flask(__name__)</span><span id="1dfd" class="me mf jf nh b gy nt nm l nn no"><strong class="nh jg"># define a predict function as an endpoint <br/></strong><a class="ae la" href="http://twitter.com/app" rel="noopener ugc nofollow" target="_blank">@app</a>.route("/predict", methods=["GET","POST"])<br/>def predict():<br/>    data = {"success": False}</span><span id="0af2" class="me mf jf nh b gy nt nm l nn no"><strong class="nh jg">    # get the request parameters<br/></strong>    params = flask.request.json<br/>    if (params == None):<br/>        params = flask.request.args</span><span id="746e" class="me mf jf nh b gy nt nm l nn no"><strong class="nh jg">    # if parameters are found, echo the msg parameter </strong><br/>    if (params != None):<br/>        data["response"] = params.get("msg")<br/>        data["success"] = True</span><span id="b268" class="me mf jf nh b gy nt nm l nn no"><strong class="nh jg">    # return a response in json format <br/></strong>    return flask.jsonify(data)</span><span id="ed84" class="me mf jf nh b gy nt nm l nn no"><strong class="nh jg"># start the flask app<em class="np">, allow remote connections</em><br/></strong>app.run(host='0.0.0.0')</span></pre><p id="d6db" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">当您运行<code class="fe nq nr ns nh b">python3 <a class="ae la" href="https://github.com/bgweber/StartupDataScience/blob/master/DeepLearning/Flask_Echo.py" rel="noopener ugc nofollow" target="_blank">Flask_Echo.py</a></code>时，您将得到以下结果:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="50c4" class="me mf jf nh b gy nl nm l nn no">* Running on <a class="ae la" href="http://127.0.0.1:5000/" rel="noopener ugc nofollow" target="_blank">http://127.0.0.1:5000/</a> (Press CTRL+C to quit)</span></pre><p id="fa08" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们现在可以连接到函数来测试它。为了支持远程连接，我加入了<code class="fe nq nr ns nh b">host='0.0.0.0'</code>，因为 Flask 应用程序运行在 EC2 实例上。如果您使用 EC2，您需要修改安全组以允许在端口 5000 上访问 Flask，类似于在 8888 上允许 Jupyter 访问。</p><figure class="nc nd ne nf gt is gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/c90290f711911e183daa53653c0d4e78.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*sAj6KOhCPiueBjzmRKkZOg.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Inbound rules for the EC2 instance.</figcaption></figure><p id="29ef" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">可以使用 web 浏览器或 curl 调用该函数。我用的是 Windows 环境下的 curl，不然你可以用<code class="fe nq nr ns nh b">-d '{"msg":"Hello World"}'</code>。两种方法的结果是一样的，来自客户端的 JSON 响应重复了传入的<em class="np"> msg </em>参数。</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="77b5" class="me mf jf nh b gy nl nm l nn no"><strong class="nh jg"># Browser </strong><br/><a class="ae la" href="http://localhost:5000/predict?msg=HelloWorld1" rel="noopener ugc nofollow" target="_blank">http://</a><a class="ae la" href="http://54.227.110.43:5000/predict?g1=1&amp;g2=0&amp;g3=0&amp;g4=0&amp;g5=0&amp;g6=0&amp;g7=0&amp;g8=0&amp;g9=0&amp;g10=0" rel="noopener ugc nofollow" target="_blank">54.227.110.43</a><a class="ae la" href="http://localhost:5000/predict?msg=HelloWorld1" rel="noopener ugc nofollow" target="_blank">:5000/predict?msg=HelloWorld</a></span><span id="c025" class="me mf jf nh b gy nt nm l nn no"><strong class="nh jg"># Curl<br/></strong>&gt;curl -X POST -H "Content-Type: application/json" -d "{ \"msg\":<br/>\"Hello World\" }" <a class="ae la" href="http://localhost:5000/predict" rel="noopener ugc nofollow" target="_blank">http://</a><a class="ae la" href="http://54.227.110.43:5000/predict?g1=1&amp;g2=0&amp;g3=0&amp;g4=0&amp;g5=0&amp;g6=0&amp;g7=0&amp;g8=0&amp;g9=0&amp;g10=0" rel="noopener ugc nofollow" target="_blank">54.227.110.43</a><a class="ae la" href="http://localhost:5000/predict" rel="noopener ugc nofollow" target="_blank">:5000/predict</a></span><span id="f988" class="me mf jf nh b gy nt nm l nn no"><strong class="nh jg"># Response <br/></strong>{<br/>  "response": "Hello World",<br/>  "success": true<br/>}</span></pre><p id="a87c" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们现在有能力将 Python 函数设置为 web 端点，下一步是让函数调用一个经过训练的深度网络。</p><h2 id="7d0f" class="me mf jf bd mg mh mi dn mj mk ml dp mm kn mn mo mp kr mq mr ms kv mt mu mv mw bi translated">弗拉斯克&amp;克拉斯</h2><p id="a68b" class="pw-post-body-paragraph kc kd jf ke b kf mx kh ki kj my kl km kn mz kp kq kr na kt ku kv nb kx ky kz ij bi translated">要使用 Keras 进行深度学习，我们需要首先用 Keras 和 Tensorflow 库设置环境，然后训练一个模型，我们将通过 Flask 在 web 上公开该模型。</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="53ac" class="me mf jf nh b gy nl nm l nn no"><strong class="nh jg"># Deep Learning setup <br/></strong>pip3 install --user tensorflow<br/>pip3 install --user keras<br/>pip3 install --user  pandas</span></pre><p id="ef24" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">因为我使用了一个没有附加 GPU 的 EC2 实例，所以在 CPU 模式下运行 Keras 不需要额外的配置。</p><p id="b145" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke jg">模型训练<br/> </strong>我用一个简单的网络结构创建了一个二元分类器。模型的输入是描述用户以前玩过哪些游戏的特征数组，输出是玩家将来玩特定游戏的可能性。关于训练模型的更多细节可以在我过去关于深度学习的<a class="ae la" rel="noopener" target="_blank" href="/data-science-for-startups-deep-learning-40d4d8af8009">帖子</a>中找到。</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="c597" class="me mf jf nh b gy nl nm l nn no"><strong class="nh jg"># import panda, keras and tensorflow<br/></strong>import pandas as pd<br/>import tensorflow as tf<br/>import keras<br/>from keras import models, layers</span><span id="8450" class="me mf jf nh b gy nt nm l nn no"><strong class="nh jg"># Load the sample data set and split into x and y data frames <br/></strong>df = pd.read_csv("https://github.com/bgweber/Twitch/raw/<br/>                      master/Recommendations/games-expand.csv")<br/>x = df.drop(['label'], axis=1)<br/>y = df['label']</span><span id="9a63" class="me mf jf nh b gy nt nm l nn no"><strong class="nh jg"># Define the keras model<br/></strong>model = models.Sequential()<br/>model.add(layers.Dense(64, activation='relu', input_shape=(10,)))<br/>model.add(layers.Dropout(0.1))<br/>model.add(layers.Dense(64, activation='relu'))<br/>model.add(layers.Dropout(0.1))<br/>model.add(layers.Dense(64, activation='relu'))<br/>model.add(layers.Dense(1, activation='sigmoid'))<br/><br/><strong class="nh jg"># Use a custom metricfunction<br/></strong>def auc(y_true, y_pred):<br/>    auc = tf.metrics.auc(y_true, y_pred)[1]<br/>   keras.backend.get_session().run(tf.local_variables_initializer())<br/>    return auc    </span><span id="4239" class="me mf jf nh b gy nt nm l nn no"><strong class="nh jg"># Compile and fit the model<br/></strong>model.compile(optimizer='rmsprop',loss='binary_crossentropy',<br/>              metrics=[auc])<br/>history = model.fit(x, y, epochs=100, batch_size=100,<br/>                    validation_split = .2, verbose=0)<br/></span><span id="ccb3" class="me mf jf nh b gy nt nm l nn no"><strong class="nh jg"># Save the model in h5 format <br/></strong>model.save("games.h5")</span></pre><p id="0dc6" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">代码片段定义了一个自定义指标函数，用于训练模型以优化 ROC AUC 指标。这段代码的主要附加部分是最后一步，它将模型序列化为 h5 格式。我们可以稍后将这个模型加载到 Flask 应用程序中，以服务于模型预测。可以通过运行生成<code class="fe nq nr ns nh b">games.h5</code>的<code class="fe nq nr ns nh b">python3 <a class="ae la" href="https://github.com/bgweber/StartupDataScience/blob/master/DeepLearning/Flask_Train.py" rel="noopener ugc nofollow" target="_blank">Flask_Train.py</a></code>来训练模型。</p><p id="20f3" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke jg">模型部署<br/>用于模型预测的完整代码清单如下所示。代码的整体结构与我们前面的例子相同，但是主要的区别是在定义预测函数之前加载模型，并在预测函数中使用模型。为了重新加载模型，我们需要使用<em class="np"> custom_objects </em>参数将自定义度量函数作为输入参数传递给<em class="np"> load_model </em>。</strong></p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="a47b" class="me mf jf nh b gy nl nm l nn no"><strong class="nh jg"># Load libraries<br/></strong>import flask<br/>import pandas as pd<br/>import tensorflow as tf<br/>import keras<br/>from keras.models import load_model<br/><br/><strong class="nh jg"><em class="np"># instantiate flask </em><br/></strong>app = flask.Flask(__name__)<br/><br/><strong class="nh jg"><em class="np"># we need to redefine our metric function in order <br/># to use it when loading the model </em><br/></strong>def auc(y_true, y_pred):<br/>    auc = tf.metrics.auc(y_true, y_pred)[1]<br/>   keras.backend.get_session().run(tf.local_variables_initializer())<br/>    return auc<br/><br/><strong class="nh jg"><em class="np"># load the model, and pass in the custom metric function</em><br/></strong>global graph<br/>graph = tf.get_default_graph()<br/>model = load_model('games.h5', custom_objects={'auc': auc})<br/><br/><strong class="nh jg"><em class="np"># define a predict function as an endpoint </em><br/></strong>@app.route("/predict", methods=["GET","POST"])<br/>def predict():<br/>    data = {"success": False}<br/><br/>    params = flask.request.json<br/>    if (params == None):<br/>        params = flask.request.args<br/><br/><strong class="nh jg">    <em class="np"># if parameters are found, return a prediction</em><br/></strong>    if (params != None):<br/>        x=pd.DataFrame.from_dict(params, orient='index').transpose()<br/>        with graph.as_default():<br/>            data["prediction"] = str(model.predict(x)[0][0])<br/>            data["success"] = True<br/><br/><strong class="nh jg">    <em class="np"># return a response in json format </em><br/></strong>    return flask.jsonify(data)    <br/><br/><em class="np">#</em><strong class="nh jg"><em class="np"> start the flask app, allow remote connections </em><br/></strong>app.run(host='0.0.0.0')</span></pre><p id="174d" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">使用<code class="fe nq nr ns nh b">tf.get_default_graph()</code>建立对张量流图的引用也是必要的。如果省略此步骤，预测步骤期间可能会发生异常。条件<code class="fe nq nr ns nh b">with graph.as_default()</code>用于在进行预测时获取对图的线程安全引用。在预测函数中，请求参数被转换为数据帧，然后传递给 Keras 模型进行预测。关于使用传入参数的更多细节在我的<a class="ae la" rel="noopener" target="_blank" href="/data-science-for-startups-model-services-2facf2dde81d">模型即服务</a>帖子中有所介绍。</p><p id="cf55" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">可以通过运行<code class="fe nq nr ns nh b">python3 <a class="ae la" href="https://github.com/bgweber/StartupDataScience/blob/master/DeepLearning/Flask_Deploy.py" rel="noopener ugc nofollow" target="_blank">Flask_Deploy.py</a></code>来部署 Flask app。你可以像以前一样连接到应用程序，但是你需要指定属性<em class="np"> G1 </em>到<em class="np"> G10 </em>的值。我使用浏览器测试端点，结果如下:</p><pre class="nc nd ne nf gt ng nh ni nj aw nk bi"><span id="d4df" class="me mf jf nh b gy nl nm l nn no"><strong class="nh jg"># Browser </strong><a class="ae la" href="http://54.227.110.43:5000/predict?g1=1&amp;g2=0&amp;g3=0&amp;g4=0&amp;g5=0&amp;g6=0&amp;g7=0&amp;g8=0&amp;g9=0&amp;g10=0" rel="noopener ugc nofollow" target="_blank"><strong class="nh jg"><br/></strong>http://54.227.110.43:5000/predict?g1=1&amp;g2=0&amp;g3=0&amp;g4=0&amp;g5=0&amp;g6=0&amp;g7=0&amp;g8=0&amp;g9=0&amp;g10=0</a></span><span id="a6c5" class="me mf jf nh b gy nt nm l nn no"><strong class="nh jg"># Response<br/></strong>{<br/> "prediction":"0.04930059",<br/> "success":true}<br/>}</span></pre><p id="ed4d" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">您现在有了一个 EC2 实例，可以在 web 上提供 Keras 预测服务！</p><h1 id="33f6" class="nv mf jf bd mg nw nx ny mj nz oa ob mm oc od oe mp of og oh ms oi oj ok mv ol bi translated">结论</h1><p id="e1ba" class="pw-post-body-paragraph kc kd jf ke b kf mx kh ki kj my kl km kn mz kp kq kr na kt ku kv nb kx ky kz ij bi translated">部署深度学习模型并不简单，因为您需要使用支持 tensorflow 运行时的环境。为了以服务的形式提供 Keras 模型，我展示了如何使用 Flask 来为预先训练好的模型提供预测服务。这种方法不如我在上一种方法中讨论的 AWS lambda 方法可伸缩，但可能更适合您的用例。在原型制作时，Flash 对于设置本地服务也很有用。</p><p id="4aa5" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">理想情况下，我希望能够将 Flask 中的注释与 AWS lambda 的可伸缩性结合起来，而不需要将库安装到目录中并上传结果的中间步骤。AWS SageMaker 有助于实现这一目标，我将在未来几周内更详细地探索这一工具。</p></div><div class="ab cl om on hu oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="ij ik il im in"><p id="5dc9" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">本·韦伯是 Zynga 的首席数据科学家。我们正在<a class="ae la" href="https://www.zynga.com/careers/positions/categories/data-analytics-user-research" rel="noopener ugc nofollow" target="_blank">招聘</a>！</p></div></div>    
</body>
</html>