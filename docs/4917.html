<html>
<head>
<title>Generative Deep Learning : Let’s seek how AI Extending, not Replacing Creative Process</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成性深度学习:让我们探索人工智能如何延伸，而不是取代创造过程</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generative-deep-learning-lets-seek-how-ai-extending-not-replacing-creative-process-fded15b0561b?source=collection_archive---------7-----------------------#2018-09-15">https://towardsdatascience.com/generative-deep-learning-lets-seek-how-ai-extending-not-replacing-creative-process-fded15b0561b?source=collection_archive---------7-----------------------#2018-09-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><blockquote class="jn"><p id="f5e8" class="jo jp iq bd jq jr js jt ju jv jw jx dk translated">"技术不应该旨在取代人类，而是增强人类的能力."</p><p id="fc43" class="jo jp iq bd jq jr jy jz ka kb kc jx dk translated">-道格·恩格尔巴特，电脑鼠标的发明者</p></blockquote><p id="06de" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz jx ij bi translated">在葡萄牙里斯本举行的全球最大的科技大会 Web Summit 2017 上。由人工智能(AI)驱动的人形机器人索菲亚(Sophia)说<strong class="kf ir">“我们会抢走你的工作”</strong>6 万名世界科技领袖的观众只是紧张地笑了笑。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi la"><img src="../Images/1fe8e0929b5e3ef8a2edba591cdfeede.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TgpExCYg6LCTu5yl7dFyug.jpeg"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Web Summit 2017</figcaption></figure><p id="20de" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">到目前为止，你们都一定听说过人工智能的进步是如何破坏工业并对全球数百万工人的工作安全构成威胁的。办公室文员、接待员、客户服务代表、分析师、营销人员、医生和律师的工作可能在未来十年被人工智能取代。正如谷歌首席执行官<a class="lv lw ep" href="https://medium.com/u/d329f4843d82?source=post_page-----fded15b0561b--------------------------------" rel="noopener" target="_blank">桑德尔·皮帅</a>所说，“未来 10 年，我们将转向人工智能优先的世界。”</p><p id="a121" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">但是取代人类总是跑题了:人工智能不是用其他东西取代我们自己的智能，而是给我们的生活和工作带来更多的智能——不同种类的智能。在许多领域，尤其是在创造性领域，人工智能将被人类用作增强自身能力的工具:因此它更像是增强的智能，而不是人工智能。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi lx"><img src="../Images/f302017cd81c3633f3987ddff647dde9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eLycHqhlX0XOBegPSJ-Fzw.jpeg"/></div></div></figure><p id="7f46" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">在这篇文章中，我将提供一个高层次的概述，说明人工智能目前是如何通过生成性深度学习来扩展而不是取代创造性过程的。</p><p id="817d" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">在这篇文章中，我将讨论什么是生成性深度学习，什么是 D <strong class="kf ir">辨别</strong>模型，以及它与 G <strong class="kf ir">生成</strong>模型有何不同。我甚至会提供一些应用生成性深度学习的具体例子，这将进一步帮助任何人和每个人增加他们对这些生成模型为我们所有人提供的奇妙可能性的理解。</p><p id="b437" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">所以，把你的手机调到静音模式，关掉你的电视，让我们开始吧。</p><p id="9f50" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">在我的工程设计期间，我的老师每次都会说要更加关注基础知识，因为它们会让你在你阅读的任何学科中打下坚实的基础，所以在这里我也会首先给你关于监督学习和非监督学习的基本信息，然后我会为你们所有人打开生成模型的知识之门，让你们一头扎进去。</p><p id="8ff4" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated"><strong class="kf ir">监督学习</strong>是目前为止最主要的深度学习形式，具有广泛的行业应用。在监督学习中，您有一个输入变量(x)和一个输出变量(Y ),并使用一种算法来学习从输入到输出的映射函数。</p><p id="a183" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">目标是很好地逼近映射函数，以便当您有新的输入数据(x)时，可以预测该数据的输出变量(Y)。</p><p id="df4d" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">一般来说，目前备受关注的几乎所有深度学习应用都属于这一类别，如光学字符识别、语音识别、图像分类和语言翻译。</p><p id="61ac" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">*信息部分*:如果你想了解如何使用 tensorflow 我做了一个食物分类器，只需点击这个<a class="ae ly" rel="noopener" target="_blank" href="/north-indian-food-or-south-indian-food-deep-learning-knows-it-all-part-1-13e1d20c359c">链接</a>，无论如何，看一下视频更清晰。</p><figure class="lb lc ld le gt lf"><div class="bz fp l di"><div class="lz ma l"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk"><a class="ae ly" href="https://youtu.be/DwQ7wCzbDzY" rel="noopener ugc nofollow" target="_blank">Indian food classifier</a></figcaption></figure><p id="3cc2" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">虽然监督学习主要由分类和回归组成，但也有更多引人注目的变体，包括以下内容:</p><ul class=""><li id="0b64" class="mb mc iq kf b kg lq kk lr ko md ks me kw mf jx mg mh mi mj bi translated">图像分割—给定一张图片，在特定对象上绘制像素级蒙版。</li><li id="a8ad" class="mb mc iq kf b kg mk kk ml ko mm ks mn kw mo jx mg mh mi mj bi translated">对象检测——给定一张图片，围绕图片中的某些对象绘制一个边界框，如果你想了解更多关于对象检测的信息，请阅读这篇<a class="ae ly" rel="noopener" target="_blank" href="/real-time-object-detection-with-tensorflow-detection-model-e7fd20421d5d">文章</a>(当然这也是我写的:)，但不要忘记查看下面的视频。</li></ul><figure class="lb lc ld le gt lf"><div class="bz fp l di"><div class="mp ma l"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk"><a class="ae ly" href="https://youtu.be/Ic2zxAzioNQ" rel="noopener ugc nofollow" target="_blank">Object detection</a></figcaption></figure><p id="1dee" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated"><strong class="kf ir">无监督学习</strong>是深度学习的另一个分支，它包括在没有任何目标的帮助下寻找输入数据的有趣转换，目的是数据可视化、数据压缩或数据去噪，或者更好地理解手头数据中存在的相关性。许多机器学习专家都说，无监督学习是数据分析的面包和黄油，在试图解决监督学习问题之前，这通常是更好地理解数据集的必要步骤。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/778cf64d5575fb2d41f2d0168ad7b446.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*5RDVF1xW0LfXjoxZp6jI1Q.png"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">Image Courtesy :<a class="ae ly" href="https://www.quora.com/What-is-the-difference-between-supervised-and-unsupervised-learning-algorithms" rel="noopener ugc nofollow" target="_blank"> Unsupervised learning</a></figcaption></figure><p id="52ac" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated"><a class="ae ly" href="https://www.analyticsvidhya.com/blog/2015/07/dimension-reduction-methods/" rel="noopener ugc nofollow" target="_blank">降维</a>和<a class="ae ly" href="https://www.analyticsvidhya.com/blog/2016/11/an-introduction-to-clustering-and-different-methods-of-clustering/" rel="noopener ugc nofollow" target="_blank">聚类</a>是非常著名的无监督学习类别，请通过点击链接来阅读它们，以进一步加强您对机器学习这一领域的理解。</p><p id="8566" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">现在，该谈谈本文的主人公了，即“生成模型”。生成模型是一类用于无监督学习的模型，其中给定训练数据，我们的目标是尝试从相同的分布中生成新的样本。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi mr"><img src="../Images/c151a971506d8d24894f807c3acce36b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kgl51QOZIlKunVS47DBF5A.png"/></div></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk">image courtesy: cs231n 2017 lecture notes</figcaption></figure><p id="e27a" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">为了训练生成模型，我们首先收集某个领域的大量数据(例如，想象数百万的图像、句子或声音等。)然后训练一个模型生成类似的数据。</p><p id="7d0b" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">诀窍在于，我们用作生成模型的神经网络的许多参数远小于我们训练它们的数据量，因此模型被迫发现并有效地内在化数据的本质，以便生成数据。</p><p id="f938" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">生成模型有许多短期应用。但从长远来看，它们有可能自动学习数据集的自然特征，无论是类别、维度还是其他完全不同的东西。</p><p id="a06a" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">好了，有很多文献，现在让我们来谈一点形式主义。</p><p id="5be4" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">D <strong class="kf ir">区别型</strong>和 G <strong class="kf ir">生成型</strong>的根本区别在于:</p><p id="cd56" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated"><strong class="kf ir">判别模型</strong>学习类之间的<strong class="kf ir">(硬或软)边界</strong></p><p id="f7a3" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated"><strong class="kf ir">生成模型</strong>对各个类的<strong class="kf ir">分布</strong>进行建模</p><p id="8376" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">生成模型是能够生成数据的<strong class="kf ir">。它对特征和类(即完整的数据)进行建模。</strong></p><p id="3980" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">如果我们对<code class="fe ms mt mu mv b">P(x,y)</code>建模:我可以使用这个概率分布来生成数据点——因此所有对<code class="fe ms mt mu mv b">P(x,y)</code>建模的算法都是可生成的。</p><p id="37d3" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">如生成模型</p><ul class=""><li id="cc77" class="mb mc iq kf b kg lq kk lr ko md ks me kw mf jx mg mh mi mj bi translated">朴素贝叶斯模型<code class="fe ms mt mu mv b">P(c)</code>和<code class="fe ms mt mu mv b">P(d|c)</code>——其中<code class="fe ms mt mu mv b">c</code>是类，<code class="fe ms mt mu mv b">d</code>是特征向量。</li><li id="cb1f" class="mb mc iq kf b kg mk kk ml ko mm ks mn kw mo jx mg mh mi mj bi translated">还有，<code class="fe ms mt mu mv b">P(c,d) = P(c) * P(d|c)</code></li><li id="ac06" class="mb mc iq kf b kg mk kk ml ko mm ks mn kw mo jx mg mh mi mj bi translated">因此，朴素贝叶斯在某些形式模型中，<code class="fe ms mt mu mv b">P(c,d)</code></li><li id="6956" class="mb mc iq kf b kg mk kk ml ko mm ks mn kw mo jx mg mh mi mj bi translated">贝叶斯网</li></ul><p id="2000" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">判别模型是只能用于<strong class="kf ir">判别/分类数据点</strong>的模型。在这种情况下，你只需要建模<code class="fe ms mt mu mv b">P(y|x)</code>(即给定特征向量的分类概率)。</p><p id="cb91" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">判别模型的示例:</p><ul class=""><li id="846c" class="mb mc iq kf b kg lq kk lr ko md ks me kw mf jx mg mh mi mj bi translated">逻辑回归</li><li id="215e" class="mb mc iq kf b kg mk kk ml ko mm ks mn kw mo jx mg mh mi mj bi translated">神经网络</li></ul><p id="a6d9" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">简单来说:一个 G <strong class="kf ir">生成模型</strong>是一个可观察对象<em class="mw"> X </em>的条件概率模型，象征性地给定一个目标 Y，P(X|Y=y)，而一个 D <strong class="kf ir">判别模型</strong>是一个目标<em class="mw"> Y </em>的条件概率模型，象征性地给定一个观察对象 X，P(Y|X=x)。</p><p id="ead5" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">因此，涵盖了所有的基础知识，解释了所有的技术术语，现在是时候将你的眼球转向生成模型的应用，并思考人工智能将如何帮助我们“人类”更具创造力。</p><p id="fb09" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">我知道你一定会猜测，现在像其他人一样，这位作者也将解释隐性模型，如<a class="ae ly" href="https://en.wikipedia.org/wiki/Generative_adversarial_network" rel="noopener ugc nofollow" target="_blank"><strong class="kf ir"/>(<strong class="kf ir">【甘斯】</strong></a>)和显性深度自回归模型，如<a class="ae ly" href="https://papers.nips.cc/paper/6527-conditional-image-generation-with-pixelcnn-decoders.pdf" rel="noopener ugc nofollow" target="_blank">【pixel CNN】</a>或者甚至他也可能解释深层潜在变量模型，如<a class="ae ly" href="https://www.analyticsvidhya.com/blog/2018/06/unsupervised-deep-learning-computer-vision/" rel="noopener ugc nofollow" target="_blank">变分自动编码器</a>，但你们都错了，所以请放松，让大脑平静下来，享受你将要阅读的内容。</p><p id="6e3a" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">现在，在这篇文章的最后一部分，我将向大家介绍这个项目。 <a class="ae ly" href="https://magenta.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kf ir">品红</strong> </a>是一个探索机器学习在艺术和音乐创作过程中的作用的研究项目。</p><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi mx"><img src="../Images/629b30e096cadb30bc7926d5442f6f87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8zYiFP40j8E0GyjXQWPDqQ.png"/></div></div></figure><p id="690b" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">这主要涉及开发新的深度学习和强化学习算法，用于生成歌曲、图像、绘图和其他材料。但这也是在构建智能工具和界面方面的一次探索，允许艺术家和音乐家扩展(而不是取代！)他们使用这些模型的过程。Magenta 是由谷歌大脑团队的一些研究人员和工程师发起的，但许多其他人也为该项目做出了重大贡献。</p><p id="ba20" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">所以，我个人最喜欢的第一个模型是<strong class="kf ir"> <em class="mw">草图——RNN</em></strong>，这是一个矢量绘图的生成模型，它是一个递归神经网络(RNN)，能够构建基于笔划的常见对象的绘图。该模型在代表许多不同类别的人类绘制图像的数据集上进行训练。作者概述了有条件和无条件草图生成框架，并描述了用于以矢量格式生成连贯草图的新的健壮训练方法。</p><p id="94a3" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">在下面的演示中，看看通过在瑜伽图上训练的模型的已学表现(潜在空间)中移动而产生的瑜伽姿势。请注意，当它从站立姿势移动到在瑜伽垫上做的姿势大约 10 秒钟时，它是如何变得困惑的。</p><figure class="lb lc ld le gt lf"><div class="bz fp l di"><div class="mp ma l"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk"><a class="ae ly" href="https://youtu.be/gjEFwFfUwic" rel="noopener ugc nofollow" target="_blank">Sketch-RNN</a></figcaption></figure><p id="375e" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">第二款是献给音乐爱好者的，它被命名为<strong class="kf ir"> MusicVAE。</strong>当一名画家创作一件艺术品时，她首先在艺术家的调色板上混合和探索颜色选项，然后再将它们应用到画布上。这个过程本身就是一种创造性的行为，对最终作品有着深远的影响。</p><p id="136b" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">音乐家和作曲家大多缺乏探索和混合音乐思想的类似设备，但现在 MusicVAE 是一种机器学习模型，允许他们创建混合和探索乐谱的调色板。演示就在下面。</p><figure class="lb lc ld le gt lf"><div class="bz fp l di"><div class="lz ma l"/></div><figcaption class="lm ln gj gh gi lo lp bd b be z dk"><a class="ae ly" href="https://youtu.be/G5JT16flZwM" rel="noopener ugc nofollow" target="_blank">MusicVAE</a></figcaption></figure><p id="2683" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">我只向你们展示了在项目<a class="ae ly" href="https://magenta.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> Magenta </a>下建造的许多模型中的两个，到这个时候你们一定都已经体验到人工智能如何帮助我们扩展而不是取代我们的创造过程。为了了解有关这些创成式模型的更多信息，请浏览参考部分中的指针。</p><p id="b4fe" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">参考资料:</p><ol class=""><li id="838b" class="mb mc iq kf b kg lq kk lr ko md ks me kw mf jx my mh mi mj bi translated"><a class="ae ly" href="https://arxiv.org/pdf/1704.03477.pdf" rel="noopener ugc nofollow" target="_blank">素描的神经表征</a>《纸上素描——RNN》。</li><li id="e405" class="mb mc iq kf b kg mk kk ml ko mm ks mn kw mo jx my mh mi mj bi translated">学习音乐长期结构的层次潜向量模型。</li><li id="858e" class="mb mc iq kf b kg mk kk ml ko mm ks mn kw mo jx my mh mi mj bi translated"><a class="ae ly" href="https://magenta.tensorflow.org/sketch-rnn-demo" rel="noopener ugc nofollow" target="_blank">用神经网络绘制在一起</a> Google AI 博客。</li><li id="854c" class="mb mc iq kf b kg mk kk ml ko mm ks mn kw mo jx my mh mi mj bi translated"><a class="ae ly" href="https://magenta.tensorflow.org/music-vae" rel="noopener ugc nofollow" target="_blank"> MusicVAE:用机器学习创建乐谱调色板</a>谷歌人工智能博客。</li><li id="6fbd" class="mb mc iq kf b kg mk kk ml ko mm ks mn kw mo jx my mh mi mj bi translated">要了解更多信息，请观看来自谷歌大脑团队首席研究科学家 Douglas Eck 的视频。http://g.co/magenta 上的引线。)</li></ol><figure class="lb lc ld le gt lf gh gi paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="gh gi mz"><img src="../Images/4f3fa3da2f3b53eea7f6967651ff8176.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S0Yy7saEymxsZADJsrhBVw.jpeg"/></div></div></figure><p id="26ca" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated"><strong class="kf ir">感谢您的关注</strong></p><p id="4bda" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">你利用你在 T21 的时间阅读我的作品对我来说意味着一切。我完全是这个意思。</p><p id="89c9" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">如果你喜欢这个故事，疯狂鼓掌吧👏<strong class="kf ir"> ) </strong>按钮！这将有助于其他人找到我的工作。</p><p id="5f85" class="pw-post-body-paragraph kd ke iq kf b kg lq ki kj kk lr km kn ko ls kq kr ks lt ku kv kw lu ky kz jx ij bi translated">此外，如果你愿意，可以在 Medium、LinkedIn 或 Twitter 上关注我！我很乐意。</p><div class="na nb gp gr nc nd"><a href="https://medium.com/@naveenmanwani" rel="noopener follow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ir gy z fp ni fr fs nj fu fw ip bi translated">纳文·曼瓦尼培养基</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">阅读纳文·曼瓦尼在媒介上的作品。机器学习工程师，深度学习爱好者|</h3></div></div><div class="nl l"><div class="nm l nn no np nl nq lk nd"/></div></div></a></div><div class="na nb gp gr nc nd"><a href="https://www.linkedin.com/in/naveen-manwani-65491678/" rel="noopener  ugc nofollow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ir gy z fp ni fr fs nj fu fw ip bi translated">Naveen Manwani -机器学习工程师- AIMonk Labs Private Ltd | LinkedIn</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">查看纳文·曼瓦尼在全球最大的职业社区 LinkedIn 上的个人资料。Naveen 有一份工作列在他们的…</h3></div><div class="nr l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">www.linkedin.com</p></div></div><div class="nl l"><div class="ns l nn no np nl nq lk nd"/></div></div></a></div><div class="na nb gp gr nc nd"><a href="https://twitter.com/NaveenManwani17" rel="noopener  ugc nofollow" target="_blank"><div class="ne ab fo"><div class="nf ab ng cl cj nh"><h2 class="bd ir gy z fp ni fr fs nj fu fw ip bi translated">纳文·曼瓦尼(@纳文·曼瓦尼 17) |推特</h2><div class="nk l"><h3 class="bd b gy z fp ni fr fs nj fu fw dk translated">纳文·曼瓦尼的最新推文(@纳文·曼瓦尼 17)。电子和通信工程师，深度学习&amp;…</h3></div><div class="nr l"><p class="bd b dl z fp ni fr fs nj fu fw dk translated">twitter.com</p></div></div><div class="nl l"><div class="nt l nn no np nl nq lk nd"/></div></div></a></div></div></div>    
</body>
</html>