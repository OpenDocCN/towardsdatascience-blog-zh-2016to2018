<html>
<head>
<title>Recommender Engine — Under The Hood</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">推荐引擎——在引擎盖下</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/recommender-engine-under-the-hood-7869d5eab072?source=collection_archive---------2-----------------------#2017-12-18">https://towardsdatascience.com/recommender-engine-under-the-hood-7869d5eab072?source=collection_archive---------2-----------------------#2017-12-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/b69e513b8cf4a315215e6917d80f6e4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N1QKUW8ojc5MiQ9hZIhFiQ.jpeg"/></div></div></figure><p id="677d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们中的许多人在日常生活中被各种各样的推荐轰炸，无论是在电子商务网站还是社交媒体网站上。有些建议看起来很相关，但有些建议会让人产生各种情绪，从困惑到愤怒不等。</p><p id="572a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">基本上有两种类型的推荐系统，基于内容和协同过滤。两者各有利弊，这取决于您想要使用它们的环境。</p><p id="47b3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">基于内容的</strong>:在基于内容的推荐系统中，当向用户推荐项目时，项目的关键字或属性被考虑在内。所以，简而言之，这就像是推荐相似的项目。假设您正在阅读一本关于数据可视化的书，并想寻找同一主题的其他书籍。在这种情况下，基于内容的推荐系统将是合适的。</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi kw"><img src="../Images/fc40a36809d65f820e0e096f3c32063d.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/0*ZZl2bq-NraGfTtpa.jpg"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Image source : <a class="ae lf" href="https://blog.guillaumeagis.eu/recommendation-algorithms-with-apache-mahout/" rel="noopener ugc nofollow" target="_blank">https://blog.guillaumeagis.eu/recommendation-algorithms-with-apache-mahout/</a></figcaption></figure><p id="5636" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">协同过滤</strong>:说到点子上了，下图就是最好的例子。客户A购买了书籍x、y、z，客户B购买了书籍y、z。现在，协同过滤技术会向客户B推荐书籍x。这是协同过滤的优点和缺点。如果书x是一本非虚构的书，而顾客B的喜好完全是虚构的书，这并不重要。建议的相关性可能正确，也可能不正确。通常许多公司使用这种技术，因为它允许他们交叉销售产品。</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi lg"><img src="../Images/917033943bfbab86151055e8e7248d0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/0*7HBfxfjOs39rD2ue.jpg"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Image adapted from <a class="ae lf" href="https://www.balabit.com/blog/recommender-systems-in-anomaly-detection/" rel="noopener ugc nofollow" target="_blank">https://www.balabit.com/blog/recommender-systems-in-anomaly-detection/</a></figcaption></figure><p id="8c42" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">开发基于内容的图书推荐系统——理论</strong></p><p id="60e4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">假设您的图书馆中有一批数据科学书籍，假设您的朋友读了一本关于神经网络的书，并希望阅读同一主题的另一本书，以积累他/她的相关知识。最好的方法是实现一个简单的基于内容的推荐系统。</p><p id="060a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将在这里看三个重要的概念，这三个概念涉及到建立这个基于内容的推荐系统。</p><ul class=""><li id="e87b" class="lh li iq ka b kb kc kf kg kj lj kn lk kr ll kv lm ln lo lp bi translated">向量</li><li id="0824" class="lh li iq ka b kb lq kf lr kj ls kn lt kr lu kv lm ln lo lp bi translated">TF-IDF</li><li id="988e" class="lh li iq ka b kb lq kf lr kj ls kn lt kr lu kv lm ln lo lp bi translated">余弦相似性</li></ul><p id="9f23" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">矢量</strong></p><p id="7f8e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">基本思想是将文本或单词转换成向量，并在向量空间模型中表示。这个想法太美了，从本质上来说，向量的这个想法使得机器学习和人工智能的快速发展成为可能。事实上，Geoffrey Hinton(“深度学习之父”)在MIT technology review <a class="ae lf" href="https://www.technologyreview.com/s/608911/is-ai-riding-a-one-trick-pony/" rel="noopener ugc nofollow" target="_blank">的一篇文章</a>中承认，多伦多的人工智能研究所被命名为“向量研究所”，因为向量的美丽属性在深度学习和神经网络的其他变体领域帮助了他们。</p><p id="e4a4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> TF — IDF </strong></p><p id="e3be" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">TF- IDF代表术语频率和逆文档频率。TF-IDF有助于评估文档中某个单词的重要性。</p><p id="45b7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> TF —词频</strong></p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lv"><img src="../Images/6df5a963a26882f0d62aa72616bdcf6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7jhXPwMrGaNJbbPj.jpg"/></div></div></figure><p id="4a1e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了确定术语/单词在文档中出现的频率，并以向量形式表示文档，让我们将其分解为以下步骤。</p><p id="b1bd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">步骤1 </strong>:创建一个存在于整个文档空间的单词字典(也称为单词包)。我们忽略了一些常用词，也称为停用词，如the，of，a，an，is等，因为这些词非常常见，对我们选择重要词的目标没有帮助</p><p id="2617" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在当前的例子中，我使用了包含50本书标题的文件“test1.csv”。但是为了证明这一点，只需考虑由3个书名(文档)组成整个文档空间。所以B1是一个文档，B2和B3是其他文档。B1、B2、B3共同构成了文档空间。</p><p id="8aea" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">B1 —推荐系统</p><p id="6d49" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">B2——统计学习的要素</p><p id="ae6e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">B3 —推荐系统—高级</p><p id="3b6d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在创建这些词的索引(停止词被忽略)</p><p id="49b2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">1.推荐人2。系统3要素4。统计学5。学习6。先进的</p><p id="c7bd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">第二步</strong>:形成矢量</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lw"><img src="../Images/1c8e66cc8380d40e4fef77bb57f68efd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SGlsrD5FTtpOcvLO.jpg"/></div></div></figure><p id="4f0d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">词频帮助我们识别该词或词在文档中出现的次数，但也有一个固有的问题，TF更重视频繁出现的词/词，而忽略了罕见词/词的重要性。这不是一个理想的情况，因为生僻字包含更多的重要性或信号。这个问题由以色列国防军解决。</p><p id="0df8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有时一个单词/术语在较长的文档中比在较短的文档中出现得更频繁；因此，执行术语频率标准化。</p><p id="bcad" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">TFn =(术语t在文档中出现的次数)/(文档中的总术语数)，其中n表示归一化。</p><p id="f32e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> IDF(逆文档频率):</strong></p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lx"><img src="../Images/b73b1ec43c7db198ba85f2597b21284f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1FfmtLL1j1HSs7kQ.jpg"/></div></div></figure><p id="6b29" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在IDF定义的一些变体中，在文档中没有出现术语的情况下，将1添加到分母，以避免被零除的情况。</p><p id="814e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">基本上，一个简单的定义是:</p><p id="ba49" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">IDF = ln(文档总数/包含术语t的文档数)</p><p id="3692" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，让我们从我们自己的字典或单词包中取一个例子来计算IDF</p><p id="fc3c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们有6个术语或单词，如下所示</p><p id="9008" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">1.推荐人2。系统3要素4。统计学5。学习6。先进的</p><p id="495d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们的文件是:</p><p id="e415" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">B1 —推荐系统</p><p id="1060" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">B2——统计学习的要素</p><p id="55ca" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">B3 —推荐系统—高级</p><p id="4068" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在IDF(w1)= log 3/2；IDF(w2)= log 3/2；IDF(w3)= log 3/1；IDF(W4)= log 3/1；IDF(W5)= log 3/1；IDF(w6) = log 3/1</p><p id="6900" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">(注:取自然对数和w1..w6表示单词/术语)</p><p id="46fc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然后我们又得到一个向量，如下所示:</p><p id="3417" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi">= (0.4054, 0.4054, 1.0986, 1.0986, 1.0986, 1.0986)</p><p id="1d6c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> TF-IDF重量:</strong></p><p id="1af7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在最后一步是得到TF-IDF的重量。TF向量和IDF向量被转换成矩阵。</p><p id="365f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">那么TF-IDF重量表示为:</p><p id="fb16" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> TF-IDF权重= TF (t，d) * IDF(t，D) </strong></p><p id="cb9c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这与我们通过执行以下python代码获得的矩阵相同:</p><pre class="kx ky kz la gt ly lz ma mb aw mc bi"><span id="11e0" class="md me iq lz b gy mf mg l mh mi">tfidf_matrix = tf.fit_transform(ds['Book Title'])</span></pre><p id="e154" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">余弦相似度:</strong></p><p id="fed5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">余弦相似性是两个非零向量之间相似性的度量。向量表示的一个美妙之处是，我们现在可以看到，两个句子有多紧密的联系，基于它们各自的向量所成的角度。</p><p id="d5f0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">余弦值的范围从-1到1。</p><p id="5875" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，如果两个向量形成一个角度0，那么余弦值将是1，这反过来意味着句子彼此密切相关。</p><p id="0611" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果两个向量是正交的，即cos 90,则意味着句子几乎是不相关的。</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mj"><img src="../Images/180b5339e8f2759be555bcbeace913ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*khzm4TObMPzf9pYX.jpg"/></div></div></figure><p id="68ae" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">开发基于内容的图书推荐系统—实现</strong></p><p id="3046" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下面是要点链接，我用python写了几行代码来实现一个简单的基于内容的图书推荐系统。我添加了注释(在#后面的单词)来清楚地说明每一行代码在做什么。</p><figure class="kx ky kz la gt jr"><div class="bz fp l di"><div class="mk ml l"/></div></figure><p id="9c70" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">输出</p><figure class="kx ky kz la gt jr"><div class="bz fp l di"><div class="mk ml l"/></div></figure><p id="b21c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">test1.csv中的id和书名列表如下(显示了20行)</p><figure class="kx ky kz la gt jr"><div class="bz fp l di"><div class="mk ml l"/></div></figure><p id="1df8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">既然您已经阅读了这篇文章，您可能也喜欢阅读……..(嗯没关系；) )</p><p id="edb2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">以下链接也提供了相同的文章:</p><div class="mm mn gp gr mo mp"><a href="https://www.linkedin.com/redir/redirect?url=https%3A%2F%2Fwww%2Elinkedin%2Ecom%2Fpulse%2Fcontent-based-recommender-engine-under-hood-venkat-raman&amp;urlhash=wCLR&amp;_t=tracking_anet" rel="noopener  ugc nofollow" target="_blank"><div class="mq ab fo"><div class="mr ab ms cl cj mt"><h2 class="bd ir gy z fp mu fr fs mv fu fw ip bi translated">如何建立一个简单的基于内容的图书推荐系统</h2><div class="mw l"><h3 class="bd b gy z fp mu fr fs mv fu fw dk translated">我们中的许多人在日常生活中被各种各样的建议轰炸，无论是在电子商务网站还是社交媒体上…</h3></div><div class="mx l"><p class="bd b dl z fp mu fr fs mv fu fw dk translated">www.linkedin.com</p></div></div><div class="my l"><div class="mz l na nb nc my nd jw mp"/></div></div></a></div><p id="9e2a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">来源:</p><p id="7ff2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae lf" href="http://www.tfidf.com/" rel="noopener ugc nofollow" target="_blank"> TF-IDF </a></p><p id="a174" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae lf" href="https://www.kaggle.com/cclark/simple-content-based-recommendation-engine/notebook" rel="noopener ugc nofollow" target="_blank">卡格尔</a></p><p id="8dd4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae lf" href="https://en.wikipedia.org/wiki/Vector_space_model" rel="noopener ugc nofollow" target="_blank">向量空间模型</a></p><p id="9706" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae lf" href="https://deeplearning4j.org/bagofwords-tf-idf" rel="noopener ugc nofollow" target="_blank">深度学习4j </a></p><p id="fb65" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae lf" href="http://scikit-learn.org/stable/modules/metrics.html#cosine-similarity" rel="noopener ugc nofollow" target="_blank"> Sklearn余弦相似度</a></p><p id="f4e7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae lf" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" rel="noopener ugc nofollow" target="_blank">sk learn tfidf矢量器</a></p><p id="5e4b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae lf" href="http://www.markhneedham.com/blog/2016/07/27/scitkit-learn-tfidf-and-cosine-similarity-for-computer-science-papers/" rel="noopener ugc nofollow" target="_blank">马克·李约瑟博客</a></p><p id="08c0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae lf" href="https://www.technologyreview.com/s/608911/is-ai-riding-a-one-trick-pony/" rel="noopener ugc nofollow" target="_blank">麻省理工科技评论</a></p><p id="068f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">代码链接:<a class="ae lf" href="https://gist.github.com/venkarafa/0da815727f1ee098b201c371b60b2d72" rel="noopener ugc nofollow" target="_blank">https://gist . github . com/venkara fa/0da 815727 f1 ee 098 b 201 c 371 b 60 B2 d 72</a></p></div></div>    
</body>
</html>