# 日常生活中的聚类—第 2 页，共 2 页

> 原文：<https://towardsdatascience.com/clustering-for-everyday-life-2-of-2-8c57538ec2ce?source=collection_archive---------3----------------------->

在我的[上一篇文章](https://devklaus.wordpress.com/2017/05/14/clustering-for-everyday-life-1-of-2/)中，我写了关于聚类和 k-means 算法的内容。在这篇文章中，我想用这些概念和 TensorFlow 写一个简单的例子。(并帮助自己计划下一次去哥谭市的旅行)。

对于这个实现，我们需要 Python(我使用 3.7，但 2.x 也可以)和一些包:

*   matplotlib
*   张量流
*   numpy
*   熊猫

安装这些软件包很简单:

*   对于 python 2.x: *pip 安装<包名>*
*   对于 python 3.x: *pip3 安装<包名>*

在任何情况下，您都可以遵循每个软件包文档中的安装说明。

到目前为止还好吗？好了，让我们深入代码:

首先，我定义了问题的参数:

*   点数:1000
*   集群数量:4
*   计算步骤数:100

在这个特殊的例子中，我使用了一组随机生成的 1000 个 GPS 位置作为训练集[从第 27 行到第 36 行]关于位置:45.7±9.1。如果你有一个坐标正确的文件，你可以加载并使用正确的坐标。第 34 行到第 36 行显示了训练集:

在第 42 行中，向量值被转换成张量流可用的常数。

在随机建立了训练集之后，我们需要质心[从 44 到 50 的线]并将其转换为将由 TensorFlow 操纵的变量。这是 K-means 算法的关键，我们需要一组质心来开始迭代。

K-means 的代价函数是点和质心之间的距离，该算法试图最小化该代价函数。正如我在以前的帖子中所写的，两个 GPS 点之间的距离不能用欧几里德距离来计算，有必要引入一种更精确的方法来计算 di 距离，这种方法之一是球面余弦定律。对于这个例子，我使用了近似的球面余弦定律。这种近似对于像城市距离这样的距离非常有效，并且在计算上比整个算法的实现更有效。要了解更多关于这个近似值和误差的信息，请阅读这篇有趣的[帖子](http://jonisalonen.com/2014/computing-distance-between-coordinates-can-be-simple-and-fast/)。[第 53 至 63 行]

最后，更新质心[第 65 行]

第 68 行到第 75 行初始化所有变量，实例化评估图，运行算法并可视化结果:

## 结论:

我的前两篇文章关注的是聚类问题的一种算法:K-means。该算法对数据做了一些假设:

*   每个属性分布的方差是球形的
*   所有变量都有相同的方差
*   每个聚类的先验概率是相同的

如果违反了这些假设，那么算法就失败了。

这种算法的一个可能的缺点是必须事先定义聚类的数量。如果您不知道您的聚类如何，您可以选择另一种聚类算法，如 DBSCAN 或 OPTICS(这些算法基于密度模型而不是质心模型)。或者，您可以在 K-means 中引入后处理步骤，聚合(或分割)两个或更多质心，然后在相同的训练集上重新启动整个算法，但使用新的质心集。

从计算的角度来看，K-means 算法对数据对象的数量是线性的，其他聚类算法具有二次复杂度。所以这是需要记住的重要一点。

*原载于 2017 年 5 月 25 日*[*【devklaus.wordpress.com】*](https://devklaus.wordpress.com/2017/05/25/clustering-for-everyday-life%E2%80%8A-%E2%80%8A2-of-2/)*。*