<html>
<head>
<title>How to Visualize a Decision Tree from a Random Forest in Python using Scikit-Learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用 Scikit-Learn 在 Python 中可视化随机森林中的决策树</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-visualize-a-decision-tree-from-a-random-forest-in-python-using-scikit-learn-38ad2d75f21c?source=collection_archive---------1-----------------------#2018-08-19">https://towardsdatascience.com/how-to-visualize-a-decision-tree-from-a-random-forest-in-python-using-scikit-learn-38ad2d75f21c?source=collection_archive---------1-----------------------#2018-08-19</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/15c04a4495695d1007ec393f3adb6bf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lAhJt7bvEDxT4DEdd29yCA.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="6176" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">有助于理解您的模型的实用程序</h2></div><p id="fc85" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><a class="ae lm" href="https://gist.github.com/WillKoehrsen/ff77f5f308362819805a3defd9495ffd" rel="noopener ugc nofollow" target="_blank">下面是完整的代码</a>:只需复制并粘贴到 Jupyter 笔记本或 Python 脚本中，用您的数据替换并运行:</p><figure class="ln lo lp lq gt is"><div class="bz fp l di"><div class="lr ls l"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Code to visualize a decision tree and save as png (<a class="ae lm" href="https://gist.github.com/WillKoehrsen/ff77f5f308362819805a3defd9495ffd" rel="noopener ugc nofollow" target="_blank">on GitHub here</a>).</figcaption></figure><p id="9bba" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">最终结果是一个完整的决策树图像。</p><figure class="ln lo lp lq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lx"><img src="../Images/52b7bb3f41835385507fed8eb5db8966.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IPLwmH-TJRhEWXW7uaetMw.png"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Decision Tree for Iris Dataset</figcaption></figure><h1 id="92ad" class="ly lz jb bd ma mb mc md me mf mg mh mi kh mj ki mk kk ml kl mm kn mn ko mo mp bi translated">代码解释</h1><ol class=""><li id="ef3b" class="mq mr jb ks b kt ms kw mt kz mu ld mv lh mw ll mx my mz na bi translated"><strong class="ks jc">创建一个模型训练并提取:</strong>我们可以使用一个单独的决策树，但是因为我经常使用<a class="ae lm" href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">随机森林</a>来建模，所以在这个例子中使用了它。(树与树之间会略有不同！).</li></ol><pre class="ln lo lp lq gt nb nc nd ne aw nf bi"><span id="da91" class="ng lz jb nc b gy nh ni l nj nk">from sklearn.ensemble import RandomForestClassifier<br/>model = RandomForestClassifier(n_estimators=10)</span><span id="5f61" class="ng lz jb nc b gy nl ni l nj nk"><em class="nm"># Train</em><br/>model.fit(iris.data, iris.target)<br/><em class="nm"># Extract single tree</em><br/>estimator = model.estimators_[5]</span></pre><p id="ee60" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc"> 2。将树导出为。点文件:</strong>这利用了 Scikit-Learn 中的<code class="fe nn no np nc b">export_graphviz</code>函数。这里有许多参数控制显示的外观和信息。查看文档了解具体信息。</p><pre class="ln lo lp lq gt nb nc nd ne aw nf bi"><span id="4b8a" class="ng lz jb nc b gy nh ni l nj nk">from sklearn.tree import export_graphviz</span><span id="1bb5" class="ng lz jb nc b gy nl ni l nj nk"># Export as dot file<br/>export_graphviz(estimator_limited, <br/>                out_file='tree.dot', <br/>                feature_names = iris.feature_names,<br/>                class_names = iris.target_names,<br/>                rounded = True, proportion = False, <br/>                precision = 2, filled = True)</span></pre><p id="4305" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc"> 3。使用系统命令</strong> : <a class="ae lm" href="https://stackoverflow.com/questions/89228/calling-an-external-command-in-python" rel="noopener ugc nofollow" target="_blank">将 <code class="fe nn no np nc b"><strong class="ks jc">dot</strong></code> <strong class="ks jc">转换为</strong> <code class="fe nn no np nc b"><strong class="ks jc">png</strong></code> <strong class="ks jc">在 Python 中运行系统命令</strong></a>可以方便地执行简单的任务。这需要安装包含点工具的<a class="ae lm" href="https://graphviz.gitlab.io/download/" rel="noopener ugc nofollow" target="_blank"> graphviz。有关转换的完整选项，请查看文档</a>。</p><pre class="ln lo lp lq gt nb nc nd ne aw nf bi"><span id="d1a9" class="ng lz jb nc b gy nh ni l nj nk"># Convert to png<br/>from subprocess import call<br/>call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])</span></pre><p id="3c0f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc"> 4。可视化:最好的可视化出现在 Jupyter 笔记本中。(相当于你可以用<code class="fe nn no np nc b">matplotlib</code>来显示图像)。</strong></p><pre class="ln lo lp lq gt nb nc nd ne aw nf bi"><span id="c178" class="ng lz jb nc b gy nh ni l nj nk"># Display in jupyter notebook<br/>from IPython.display import Image<br/>Image(filename = 'tree.png')</span></pre><h2 id="52fd" class="ng lz jb bd ma nq nr dn me ns nt dp mi kz nu nv mk ld nw nx mm lh ny nz mo oa bi translated">考虑</h2><p id="889c" class="pw-post-body-paragraph kq kr jb ks b kt ms kc kv kw mt kf ky kz ob lb lc ld oc lf lg lh od lj lk ll ij bi translated">有了随机森林，每棵树都将被不同地建造。我使用这些图像来展示决策树(以及随后的随机森林)背后的推理，而不是具体的细节。</p><p id="18f3" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">当您拥有大量要素时，限制树的最大深度会很有帮助。否则，你最终会得到巨大的树，看起来令人印象深刻，但根本无法解读！这是一个包含 50 个特性的完整示例。</p><figure class="ln lo lp lq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oe"><img src="../Images/d61105605b631c6b3de3f8fc0f5ea57c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hW67kyPZZJ6I_7Z8huwDkg.png"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Full decision tree from a real problem (<a class="ae lm" href="https://www.kaggle.com/willkoehrsen/a-complete-introduction-and-walkthrough" rel="noopener ugc nofollow" target="_blank">see here</a>).</figcaption></figure><h1 id="2524" class="ly lz jb bd ma mb mc md me mf mg mh mi kh mj ki mk kk ml kl mm kn mn ko mo mp bi translated">结论</h1><p id="c059" class="pw-post-body-paragraph kq kr jb ks b kt ms kc kv kw mt kf ky kz ob lb lc ld oc lf lg lh od lj lk ll ij bi translated">机器学习仍然受到黑箱问题的困扰，一张图片并不能解决问题！尽管如此，观察单个决策树向我们展示了这种模型(和随机森林)并不是一种无法解释的方法，而是一系列逻辑问题和答案——就像我们在进行预测时形成的一样。请随意为您的数据使用和修改这些代码。</p><p id="823f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">和往常一样，我欢迎反馈、建设性的批评以及倾听您的数据科学项目。可以在推特上找到我<a class="ae lm" href="http://twitter.com/@koehrsen_will" rel="noopener ugc nofollow" target="_blank"> @koehrsen_will </a></p></div></div>    
</body>
</html>