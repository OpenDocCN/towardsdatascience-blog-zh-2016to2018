<html>
<head>
<title>Interpretable Machine Learning with XGBoost</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用XGBoost的可解释机器学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27?source=collection_archive---------0-----------------------#2018-04-17">https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27?source=collection_archive---------0-----------------------#2018-04-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/22fd06962ef9eb65a2512699dbd56174.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T7XtvWyesmYAXM0Y9Jv2Gw.jpeg"/></div></div></figure><h2 id="2f8d" class="iz ja jb bd b dl jc jd je jf jg jh dk ji translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/Model-Interpretability" rel="noopener" target="_blank">模型可解释性</a></h2><div class=""/><p id="658f" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">这是一个关于错误解释你的机器学习模型的危险，以及正确解释它的价值的故事。如果您发现集合树模型(如梯度推进机器或随机森林)的稳健准确性很有吸引力，但也需要解释它们，那么我希望您会发现这是有益的。</p><p id="787d" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">假设我们的任务是为一家银行预测一个人的财务状况。我们的模型越准确，银行赚的钱就越多，但是由于这种预测用于贷款申请，我们也需要在法律上对为什么做出预测做出解释。在对几种模型类型进行实验后，我们发现XGBoost中实现的梯度提升树具有最好的准确性。不幸的是，解释XGBoost为什么做出预测似乎很难，所以我们只能选择退回到线性模型，或者弄清楚如何解释我们的XGBoost模型。没有数据科学家愿意放弃准确性…所以我们决定尝试后者，并解释复杂的XGBoost模型(恰好有1，247棵深度为6的树)。</p><h1 id="956c" class="lf lg jb bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated"><strong class="ak">经典的全球特征重要性度量</strong></h1><p id="3286" class="pw-post-body-paragraph kh ki jb kj b kk md km kn ko me kq kr ks mf ku kv kw mg ky kz la mh lc ld le ij bi translated">第一个显而易见的选择是在Python XGBoost接口中使用plot_importance()方法。它给出了一个非常简单的条形图，代表了我们数据集中每个特性的重要性:(复制这篇文章的代码在<a class="ae mi" href="https://slundberg.github.io/shap/notebooks/Census%20income%20classification%20with%20XGBoost.html" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a>中)</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mj"><img src="../Images/9f6f78488860ccbbe582be71df67a96c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FYaIhrCMXw_D10KOyQHYXA.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Results of running xgboost.plot_importance(model) for a model trained to predict if people will report over $50k of income from the classic “adult” census dataset (using a logistic loss).</figcaption></figure><p id="8020" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">如果我们查看XGBoost返回的特征重要性，我们会发现<em class="ms">年龄</em>支配着其他特征，显然是收入的最重要预测因素。我们可以在这里停下来，向我们的经理报告直观上令人满意的答案:年龄是最重要的特征，其次是每周工作时间和受教育程度。但是作为优秀的数据科学家……我们看了一下文档，发现在XGBoost中有三个度量特性重要性的选项:</p><ol class=""><li id="ee5b" class="mt mu jb kj b kk kl ko kp ks mv kw mw la mx le my mz na nb bi translated"><strong class="kj jl">体重。</strong>一个特征被用于跨所有树分割数据的次数。</li><li id="b691" class="mt mu jb kj b kk nc ko nd ks ne kw nf la ng le my mz na nb bi translated"><strong class="kj jl">封面。</strong>使用某个特征在所有树之间分割数据的次数，这些树由经过这些分割的训练数据点的数量加权。</li><li id="ae1b" class="mt mu jb kj b kk nc ko nd ks ne kw nf la ng le my mz na nb bi translated"><strong class="kj jl">增益。</strong>使用特征进行分割时获得的平均训练损失减少量。</li></ol><p id="323c" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">这些是我们可能在任何基于树的建模包中找到的典型的重要性度量。重量是默认选项，因此我们决定尝试其他两种方法，看看它们是否有所不同:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nh"><img src="../Images/5f1d4ddb6755dd15d2bf181c6226a034.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UEQiHKTnjHJ-swIjcAkRnA.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Results of running xgboost.plot_importance with both importance_type=”cover” and importance_type=”gain”.</figcaption></figure><p id="481a" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">令我们沮丧的是，我们发现XGBoost提供的三个选项中的每一个的特性重要性排序都非常不同！对于覆盖法来说，<em class="ms">资本收益</em>特征似乎是最能预测收入的，而对于收益法来说，<em class="ms">关系状态</em>特征支配了所有其他特征。这应该会让我们在不知道哪种方法是最好的情况下，依赖这些方法来报告特性重要性时感到非常不舒服。</p><h1 id="5b21" class="lf lg jb bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">是什么决定了特性重要性的好坏？</h1><p id="5c55" class="pw-post-body-paragraph kh ki jb kj b kk md km kn ko me kq kr ks mf ku kv kw mg ky kz la mh lc ld le ij bi translated">如何比较一种特征归属方法和另一种特征归属方法并不明显。我们可以测量每种方法在数据清理、偏差检测等任务上的最终用户性能。但是这些任务只是对特征归属方法质量的间接测量。这里，我们将定义两个我们认为任何好的特征归属方法都应该遵循的属性:</p><ol class=""><li id="63c4" class="mt mu jb kj b kk kl ko kp ks mv kw mw la mx le my mz na nb bi translated"><strong class="kj jl">一致性。</strong>每当我们改变一个模型，使它更加依赖于一个特性，那么这个特性的重要性就不会降低。</li><li id="6036" class="mt mu jb kj b kk nc ko nd ks ne kw nf la ng le my mz na nb bi translated"><strong class="kj jl">准确度。</strong>所有特征重要性的总和应等于模型的总重要性。(例如，如果重要性是通过R值来衡量的，那么每个特征的属性总和应该是整个模型的R值)</li></ol><p id="4ffc" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">如果一致性不成立，那么我们不能比较任何两个模型之间的属性特征重要性，因为<em class="ms">然后</em> <em class="ms">具有更高的分配属性并不意味着模型实际上更依赖于那个特征</em>。</p><p id="f381" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">如果准确性不成立，那么我们不知道每个特征的属性如何组合来表示整个模型的输出。我们不能在方法完成后就规范化属性，因为这可能会破坏方法的一致性。</p><h1 id="fe88" class="lf lg jb bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">当前的归因方法是否一致和准确？</h1><p id="5885" class="pw-post-body-paragraph kh ki jb kj b kk md km kn ko me kq kr ks mf ku kv kw mg ky kz la mh lc ld le ij bi translated">回到我们作为银行数据科学家的工作…我们意识到一致性和准确性对我们很重要。事实上，如果一个方法不一致，我们不能保证具有最高属性的特性实际上是最重要的。因此，我们决定使用两个非常简单的树模型来检查每种方法的一致性，这两个树模型与我们在银行的任务无关:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ni"><img src="../Images/2ec53779f37c4c916d2e2e4aa9225039.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CPyNiwei9CSdFkZBcUyqWQ.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Simple tree models over two features. Cough is clearly more important in model B than model A.</figcaption></figure><p id="6608" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">模型的输出是基于个人症状的风险评分。模型A只是二元特征<em class="ms">发烧</em>和<em class="ms">咳嗽</em>的简单“与”函数。模型B具有相同的功能，但是每当<em class="ms">咳嗽</em>为是时，具有+10。为了检查一致性，我们必须定义“重要性”。这里我们将从两个方面定义重要性:1)当我们删除一组特征时，模型的预期精度<em class="ms">T21的变化。2)当我们移除一组特征时，模型的预期<em class="ms">输出</em>的变化。</em></p><p id="6af3" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">重要性的第一个定义度量了特征对模型的全局影响。而第二个定义测量特征对单个预测的个性化影响。在我们的简单树模型中，<em class="ms">咳嗽</em>特征在模型B中显然更重要，当<em class="ms">发烧</em>和<em class="ms">咳嗽</em>都为是时，对于全球重要性和个体预测的重要性都是如此。</p><p id="b054" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">上面的<em class="ms">权重</em>、<em class="ms">覆盖</em>、<em class="ms">增益</em>方法都是全局特征归属方法。但是，当我们在银行部署我们的模型时，我们还需要为每个客户提供个性化的解释。为了检查一致性，我们在简单的树模型上运行了五种不同的特征归属方法:</p><ol class=""><li id="fe57" class="mt mu jb kj b kk kl ko kp ks mv kw mw la mx le my mz na nb bi translated"><strong class="kj jl">树SHAP。</strong>我们提出了一种新的个性化方法。</li><li id="92ff" class="mt mu jb kj b kk nc ko nd ks ne kw nf la ng le my mz na nb bi translated"><strong class="kj jl">萨巴斯。</strong>一种个性化启发式特征归因方法。</li><li id="7d9e" class="mt mu jb kj b kk nc ko nd ks ne kw nf la ng le my mz na nb bi translated"><strong class="kj jl">意思是(|树SHAP|)。</strong>基于个体化树SHAP属性平均大小的全局属性方法。</li><li id="8842" class="mt mu jb kj b kk nc ko nd ks ne kw nf la ng le my mz na nb bi translated"><strong class="kj jl">增益。</strong>与上述XGBoost中使用的方法相同，也等同于scikit-learn树模型中使用的基尼系数。</li><li id="8d6c" class="mt mu jb kj b kk nc ko nd ks ne kw nf la ng le my mz na nb bi translated"><strong class="kj jl">拆分计数。</strong>表示XGBoost中密切相关的“权重”和“覆盖”方法，但使用“权重”方法进行计算。</li><li id="d88d" class="mt mu jb kj b kk nc ko nd ks ne kw nf la ng le my mz na nb bi translated"><strong class="kj jl">排列。</strong>当单个特征在测试数据集中被随机置换时，模型精度的下降。</li></ol><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nj"><img src="../Images/2cd34dbf6e59806966ab3640b2e6d0be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v4r9KuDjJBs2TIB7zw2E4A.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Feature attributions for model A and model B using six different methods. As far we can tell, these methods represent all the tree-specific feature attribution methods in the literature.</figcaption></figure><p id="58b3" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated"><strong class="kj jl">之前除了特征置换的方法都不一致！</strong>这是因为与模型a相比，它们在模型B中对咳嗽的重视程度较低。不一致的方法无法正确地对最有影响的特征给予更多的重视。敏锐的读者会注意到，这种不一致性早在我们研究的经典特征归因方法在同一模型上相互矛盾时就已经出现了。精度属性呢？事实证明，树SHAP、Sabaas和Gain都与前面定义的一样准确，而特征置换和分裂计数则不准确。</p><p id="75bf" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">或许令人惊讶的是，像gain(基尼系数)这样广泛使用的方法会导致如此明显的不一致结果。为了更好地理解为什么会发生这种情况，我们来看看模型A和模型b的增益是如何计算的。为了简单起见，我们假设数据集的25%落在每个叶中，并且每个模型的数据集都有与模型输出完全匹配的标签。</p><p id="bd67" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">如果我们将均方误差(MSE)视为我们的损失函数，那么在模型a中进行任何分割之前，我们从1200的MSE开始，这是来自20的恒定均值预测的误差。在模型A中拆分了<em class="ms">发烧</em>之后，MSE下降到800，因此gain方法将这400的下降归因于<em class="ms">发烧</em>特性。在<em class="ms">咳嗽</em>特征上再次分裂导致MSE为0，增益方法将这800的下降归因于<em class="ms">咳嗽</em>特征。在模型B中，同样的过程导致发烧特征的重要性为800，咳嗽特征的重要性为625:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nk"><img src="../Images/3299ec87a51ec0ffa1960a1314a0e17a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IWBGb4PC7F2q0fszK-Iplw.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Computation of the gain (aka. Gini importance) scores for model A and model B.</figcaption></figure><p id="35d5" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">通常，我们认为靠近树根的特征比靠近树叶的特征更重要(因为树是贪婪地构建的)。然而，增益方法偏向于将更多的重要性归于较低的分裂。这种偏见导致了不一致，当<em class="ms">咳嗽</em>变得更重要时(因此它在根上分裂了)，它的归属重要性实际上下降了。个性化的Saabas方法(由<a class="ae mi" href="https://github.com/andosa/treeinterpreter" rel="noopener ugc nofollow" target="_blank"> treeinterpreter </a>包使用)在我们沿着树向下时计算预测的差异，因此它也遭受了同样的偏向于树中较低位置的分裂。随着树木越来越深，这种偏见只会越来越大。相比之下，树SHAP方法在数学上等同于对所有可能的特征排序的预测差异进行平均，而不仅仅是由它们在树中的位置指定的排序。</p><p id="093b" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">这不是一个巧合，只有树SHAP是一致和准确的。假设我们想要一个既一致又准确的方法，那么只有一种方法来分配特性的重要性。详细内容在我们最近的<a class="ae mi" href="http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions" rel="noopener ugc nofollow" target="_blank"> NIPS论文</a>中，但总结是，来自博弈论的关于利润公平分配的证明导致了机器学习中特征归属方法的唯一性结果。这些独特的值被称为Shapley值，以Lloyd Shapley在20世纪50年代得出的值命名。我们这里使用的SHAP值是与Shapley值相关的几种个性化模型解释方法的统一。树SHAP是一种快速算法，可以在多项式时间内准确计算树的SHAP值，而不是传统的指数运行时间(见<a class="ae mi" href="https://arxiv.org/abs/1802.03888" rel="noopener ugc nofollow" target="_blank"> arXiv </a>)。</p><h1 id="5a7f" class="lf lg jb bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">自信地诠释我们的模型</h1><p id="1252" class="pw-post-body-paragraph kh ki jb kj b kk md km kn ko me kq kr ks mf ku kv kw mg ky kz la mh lc ld le ij bi translated">坚实的理论证明和快速实用的算法相结合，使SHAP价值观成为一个强有力的工具，自信地解释树木模型，如XGBoost的梯度推进机。有了这个新方法，我们回到解释我们的银行XGBoost模型的任务:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nl"><img src="../Images/5390a8fe4ac86f7f4e766f39ebb2d29a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fc0q-o56b1KW8rzMq0bQnQ.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">The global mean(|Tree SHAP|) method applied to the income prediction model. The x-axis is essentially the average magnitude change in model output when a feature is “hidden” from the model (for this model the output has log-odds units). See <a class="ae mi" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank">papers</a> for details, but “hidden” means integrating the variable out of the model. Since the impact of hiding a feature changes depending on what other features are also hidden, Shapley values are used to enforce consistency and accuracy.</figcaption></figure><p id="98a3" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">我们可以看到，<em class="ms">关系</em>特征实际上是最重要的，其次是<em class="ms">年龄</em>特征。由于SHAP值保证了一致性，我们不需要担心在使用增益或分割计数方法之前发现的矛盾。然而，由于我们现在对每个人都有个性化的解释，我们可以做的不仅仅是做一个条形图。我们可以为数据集中的每个客户绘制特征重要性图。<a class="ae mi" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> shap Python包</a>让这变得简单。我们先叫shap。TreeExplainer(模型)。shap_values(X)来解释每个预测，然后调用shap.summary_plot(shap_values，X)来绘制这些解释:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nm"><img src="../Images/0c55eec169690c2ff3d727238972b535.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VY7Lag3AjbEawjUuteftdg.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Every customer has one dot on each row. The x position of the dot is the impact of that feature on the model’s prediction for the customer, and the color of the dot represents the value of that feature for the customer. Dots that don’t fit on the row pile up to show density (there are 32,561 customers in this example). Since the XGBoost model has a logistic loss the x-axis has units of log-odds (Tree SHAP explains the change in the margin output of the model).</figcaption></figure><p id="1066" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">这些特征按平均值(| SHAP树|)排序，因此我们再次将<em class="ms">关系</em>特征视为年收入超过5万美元的最强预测因素。通过绘制特征对每个样本的影响，我们还可以看到重要的异常影响。例如，虽然资本收益在全球范围内并不是最重要的特征，但对一部分客户来说却是最重要的特征。按特征值着色向我们展示了一些模式，比如年轻会降低你挣5万美元以上的机会，而高等教育会增加你挣5万美元以上的机会。</p><p id="c927" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">我们可以在这里停下来向我们的老板展示这个图，但是让我们更深入地挖掘其中的一些特性。对于<em class="ms">年龄</em>特征，我们可以通过绘制年龄SHAP值(对数几率的变化)与年龄特征值的关系来实现:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nn"><img src="../Images/110e0bc1115c641277551086d3fb665a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T15dqSQRJFMxU3wgN4Rkhw.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">The y-axis is how much the <em class="no">age</em> feature changes the log odds of making over $50K annually. The x-axis is the age of the customer. Each dot represents a single customer from the data set.</figcaption></figure><p id="b9a6" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">在这里，我们看到了年龄对收入潜力的明显影响，正如XGBoost模型所捕捉到的那样。请注意，与传统的部分相关图(显示更改特征值时的平均模型输出)不同，这些SHAP相关图显示了交互影响。尽管数据集中的许多人都是20岁，但是他们的年龄对他们预测的影响程度是不同的，正如20岁时点的垂直分布所示。这意味着其他特征正在影响年龄的重要性。为了了解这种影响的部分特征，我们用受教育的年数来给这些点着色，结果发现，在20多岁时，高教育水平会降低年龄的影响，但在30多岁时会提高这种影响:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi np"><img src="../Images/55905647310417b1f216a5749c275bf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2ObHhjeC1Yj58R7Ofkv55Q.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">The y-axis is how much the <em class="no">age</em> feature changes the log odds of making over $50K annually. The x-axis is the age of the customer. Education-Num is the number of years of education the customer has completed.</figcaption></figure><p id="edcc" class="pw-post-body-paragraph kh ki jb kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">如果我们绘制另一张每周工作小时数的依赖关系图，我们会看到，每周工作50小时左右会有更多的好处，如果你已婚，额外工作不太可能意味着高收入:</p><figure class="mk ml mm mn gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nq"><img src="../Images/17c14cbb9ab5271fd8ad20e7ccfa386f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EO5ltTPLoqufclS_UNPnyA.png"/></div></div><figcaption class="mo mp gj gh gi mq mr bd b be z dk">Hours worked per week vs. the impact of the number of hours worked on earning potential.</figcaption></figure><h1 id="96b7" class="lf lg jb bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">解释你自己的模型</h1><p id="8e21" class="pw-post-body-paragraph kh ki jb kj b kk md km kn ko me kq kr ks mf ku kv kw mg ky kz la mh lc ld le ij bi translated">这个简单的演练旨在反映您在设计和部署自己的模型时可能会经历的过程。<a class="ae mi" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> shap包</a>很容易通过pip安装，我们希望它能帮助你满怀信心地探索你的模型。它包含了比本文更多的内容，包括SHAP相互作用值，模型不可知的SHAP值估计，以及其他可视化。笔记本可以在各种有趣的数据集上展示所有这些特征。例如，你可以在一个解释XGBoost死亡率模型的<a class="ae mi" href="https://slundberg.github.io/shap/notebooks/NHANES%20I%20Survival%20Model.html" rel="noopener ugc nofollow" target="_blank">笔记本</a>中，根据你的健康检查，找出你将死的主要原因。对于Python以外的语言，树SHAP也被直接合并到核心的XGBoost和LightGBM包中。</p></div></div>    
</body>
</html>