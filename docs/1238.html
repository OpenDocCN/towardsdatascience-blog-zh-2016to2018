<html>
<head>
<title>An Intuitive Guide to Deep Network Architectures</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深层网络架构的直观指南</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-intuitive-guide-to-deep-network-architectures-65fdc477db41?source=collection_archive---------0-----------------------#2017-08-14">https://towardsdatascience.com/an-intuitive-guide-to-deep-network-architectures-65fdc477db41?source=collection_archive---------0-----------------------#2017-08-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/23ab2b6e1d102dece073c6ea6edc83f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_rCyzi7fQzc_Q1gCqSLM1g.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">GoogLeNet, 2014</figcaption></figure><p id="504e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在过去的几年里，计算机视觉深度学习的许多进展都可以归结为少数几个神经网络架构。抛开所有的数学、代码和实现细节，我想探索一个简单的问题:这些模型如何以及为什么工作？</p><p id="bb1c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在撰写本文时，Keras附带了六个已经内置到库中的预训练模型<a class="ae la" href="https://keras.io/applications/" rel="noopener ugc nofollow" target="_blank">:</a></p><ul class=""><li id="f8ec" class="lb lc iq ke b kf kg kj kk kn ld kr le kv lf kz lg lh li lj bi translated">VGG16</li><li id="8ce4" class="lb lc iq ke b kf lk kj ll kn lm kr ln kv lo kz lg lh li lj bi translated">VGG19</li><li id="6968" class="lb lc iq ke b kf lk kj ll kn lm kr ln kv lo kz lg lh li lj bi translated">ResNet50</li><li id="0c7a" class="lb lc iq ke b kf lk kj ll kn lm kr ln kv lo kz lg lh li lj bi translated">盗梦空间v3</li><li id="da74" class="lb lc iq ke b kf lk kj ll kn lm kr ln kv lo kz lg lh li lj bi translated">例外</li><li id="c7e1" class="lb lc iq ke b kf lk kj ll kn lm kr ln kv lo kz lg lh li lj bi translated">MobileNet</li></ul><p id="9688" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">VGG网络，以及2012年的早期AlexNet，遵循基本conv网络的原型布局:一系列卷积、最大池和激活层，最后是一些全连接的分类层。MobileNet本质上是针对移动应用程序优化的Xception架构的简化版本。然而，剩下的三个真正重新定义了我们看待神经网络的方式。</p><p id="4d1c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这篇文章的其余部分将关注ResNet、Inception和Xception架构背后的直觉，以及为什么它们已经成为计算机视觉中许多后续工作的构建模块。</p><h1 id="4a32" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">雷斯内特</h1><p id="6c51" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">ResNet诞生于一个非常简单的观察:<em class="ms">为什么当你不断增加层数时，非常深的网络表现更差</em>？</p><p id="a6cc" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">直觉上，较深的网络应该不会比较浅的网络表现差，至少在训练时(没有过度拟合的风险)。作为一个思想实验，假设我们已经建立了一个具有<em class="ms"> n </em>层的网络，它达到了一定的精确度。至少，具有<em class="ms"> n+1 </em>层的网络应该能够实现完全相同的精度，只要通过复制相同的前<em class="ms"> n </em>层并对最后一层执行身份映射即可。类似地，<em class="ms"> n+2 </em>、<em class="ms"> n+3 </em>和<em class="ms"> n+4 </em>层的网络都可以继续执行身份映射并达到相同的精度。然而，在实践中，这些更深的网几乎总是降低性能。</p><p id="5d2d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">ResNet的作者将这些问题归结为一个假设:<em class="ms">直接映射很难学习</em>。他们提出了一个解决方案:不要试图学习从x到H(x)的潜在映射，而是学习两者之间的<em class="ms">差异</em>，或者“残差”然后，为了计算H(x ),我们可以将残差加到输入中。</p><p id="648b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">假设残差是F(x)=H(x)-x，现在我们的网不是试图直接学习H(x)，而是试图学习F(x)+x。</p><p id="1aea" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这就产生了您可能见过的著名的ResNet(或“剩余网络”)块:</p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/3ab0ea712533e0b8eb324b61bcb85aef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*5zSgo2L71FJos8XendgCvQ.jpeg"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">ResNet block</figcaption></figure><p id="86bd" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">ResNet中的每个“块”由一系列层和一个将块的输入添加到其输出的“快捷”连接组成。“添加”操作是按元素执行的，如果输入和输出的大小不同，可以使用零填充或投影(通过1x1卷积)来创建匹配的维度。</p><p id="8fac" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果我们回到我们的思想实验，这大大简化了我们身份层的构建。直观地说，学习将F(x)推至0并将输出保留为x比从头开始学习一个恒等式转换要容易得多。一般来说，ResNet给层一个“参考”点——x——来开始学习。</p><p id="076d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这个想法在实践中非常有效。以前，深度神经网络经常遇到<a class="ae la" href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem" rel="noopener ugc nofollow" target="_blank">消失梯度</a>的问题，其中来自误差函数的梯度信号随着它们反向传播到更早的层而呈指数下降。本质上，当错误信号一路传回到早期层时，它们已经小到网络无法学习了。然而，由于ResNets中的梯度信号可以通过快捷连接直接返回到早期层，我们可以突然构建50层、101层、152层，甚至(显然)1000+层的网络，仍然表现良好。在当时，这是一个<em class="ms">巨大的</em>飞跃，超越了之前以22层赢得ILSVRC 2014挑战赛的最先进技术。</p><p id="fa13" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">ResNet是我个人最喜欢的神经网络领域的发展之一。如此多的深度学习论文在没有考虑模型的底层任务的情况下，从数学、优化和训练过程的黑客攻击中获得了微小的改进。ResNet从根本上改变了我们理解神经网络及其学习方式的方式。</p><p id="db26" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">有趣的事实:</p><ul class=""><li id="e9b7" class="lb lc iq ke b kf kg kj kk kn ld kr le kv lf kz lg lh li lj bi translated">1000+层网是开源的！我不会<em class="ms">真的</em>建议你重新训练它，<a class="ae la" href="https://github.com/KaimingHe/resnet-1k-layers" rel="noopener ugc nofollow" target="_blank">但是……</a></li><li id="34d8" class="lb lc iq ke b kf lk kj ll kn lm kr ln kv lo kz lg lh li lj bi translated">如果您觉得功能强大，有点兴奋，我最近将ResNet50移植到了开源的Clojure ML库<a class="ae la" href="https://github.com/thinktopic/cortex" rel="noopener ugc nofollow" target="_blank"> Cortex </a>。尝试一下，看看它与Keras相比如何！</li></ul><h1 id="013b" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">开始</h1><p id="7042" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">如果说ResNet是为了更深入，那么Inception Family则是为了更广泛。尤其是，《盗梦空间》的作者对训练大型网络的计算效率感兴趣。换句话说:<em class="ms">我们如何在不增加计算成本的情况下扩大神经网络的规模？</em></p><p id="e9b0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">最初的论文关注于深度网络的一个新的构建模块，这个模块现在被称为“初始模块”该模块的核心是两个关键见解的产物。</p><p id="2858" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">第一个见解与层操作有关。在传统的conv网络中，每一层都从前一层提取信息，以便将输入数据转换成更有用的表示。但是，每种图层类型提取不同种类的信息。5x5卷积内核的输出告诉我们不同于3x3卷积内核的输出，3x 3卷积内核告诉我们不同于max-pooling内核的输出，等等。在任何给定的层，我们如何知道什么转换提供了最“有用”的信息？</p><p id="c1e2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">洞察力#1:为什么不让模型选择？</p><p id="3d08" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">一个初始模块在同一输入映射<em class="ms"> </em>上并行计算<em class="ms">多个不同的变换</em>，将它们的结果连接成一个输出。换句话说，对于每一层，Inception做一个5x5的卷积变换，<em class="ms">和</em>一个3x3，<em class="ms">和</em>一个max-pool。模型的下一层决定是否(以及如何)使用每条信息。</p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div class="gh gi my"><img src="../Images/14a563b36a751e6b09df5e448b96f711.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*RuR5VAe4WaODcQFrxU6vWw.jpeg"/></div></figure><p id="d91d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这种模型架构增加的信息密度带来了一个突出的问题:我们急剧增加了计算成本。不仅大的(例如5×5)卷积滤波器计算起来固有地昂贵，并排堆叠多个不同的滤波器极大地增加了每层的特征图的数量。这种增长成为我们模型中的致命瓶颈。</p><p id="64a6" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这么想吧。对于添加的每个额外滤波器，我们必须对所有输入映射进行卷积，以计算单个输出。参见下图:从单个过滤器创建一个输出贴图涉及到计算来自前一层的每一个贴图。</p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/418d8afd8588ac1e69878034ee0e6878.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*lGm8_2SBMkAyechJeznyAQ.png"/></div></figure><p id="4408" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">假设有<em class="ms"> M </em>个输入映射。一个额外的过滤器意味着对更多的地图进行卷积；<em class="ms"> N </em>额外的过滤器意味着对<em class="ms"> N*M </em>更多的地图进行卷积。换句话说，正如作者指出的，“任何[过滤器]数量的均匀增加都会导致计算量的二次增加。”我们天真的初始模块只是将过滤器的数量增加了三倍或四倍。从计算上来说，这是一件大坏事。</p><p id="fdfa" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这导致了洞察力#2:使用1x1卷积来执行维度缩减。为了解决计算瓶颈，Inception的作者使用1x1卷积来“过滤”输出的深度。1x1卷积一次只查看一个值，但在多个通道中，它可以提取空间信息并将其压缩到更低的维度。例如，使用20个1×1过滤器，大小为64×64×100(具有100个特征地图)的输入可以被压缩到64×64×20。通过减少输入映射的数量，Inception的作者能够并行堆叠不同的层转换，从而产生同时深(许多层)和“宽”(许多并行操作)的网络。</p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi na"><img src="../Images/b9b9dd5fc65c98db74dd9834701e3db4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aq4tcBl9t5Z36kTDeZSOHA.png"/></div></div></figure><p id="9d7f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这种方法效果如何？《盗梦空间》的第一个版本被称为“GoogLeNet”，是我前面提到的ILSVRC 2014竞赛的22层冠军。Inception v2和v3是在一年后的第二篇论文中开发的，并在几个方面对原始版本进行了改进——最显著的是通过将较大的卷积重构为更容易学习的连续较小的卷积。例如，在v3中，5×5卷积被替换为2个连续的3×3卷积。</p><p id="7051" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">《盗梦空间》迅速成为一个定义性的模型架构。Inception的最新版本v4甚至在每个模块中加入了剩余连接，创造了Inception-ResNet的混合体。然而，最重要的是，Inception展示了设计良好的“网络中的网络”架构的力量，为神经网络的表现能力又增加了一步。</p><p id="bd58" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">有趣的事实:</p><ul class=""><li id="f431" class="lb lc iq ke b kf kg kj kk kn ld kr le kv lf kz lg lh li lj bi translated">最初的《盗梦空间》论文字面上引用了“<a class="ae la" href="http://knowyourmeme.com/memes/we-need-to-go-deeper" rel="noopener ugc nofollow" target="_blank">我们需要更深入</a>”互联网迷因作为其名称的灵感。这一定是knowyourmeme.com第一次被列为谷歌论文的第一参考文献。</li><li id="bf4e" class="lb lc iq ke b kf lk kj ll kn lm kr ln kv lo kz lg lh li lj bi translated">第二篇启始论文(包含v2和v3)是在最初的ResNet论文后一天发布的。2015年12月是深度学习的好时机。</li></ul><h1 id="2f81" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">例外</h1><p id="8ece" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">Xception代表“极限盗梦空间”很像我们之前的两个架构，它重新构建了我们看待神经网络的方式——特别是conv网络。顾名思义，它将盗梦空间的原则发挥到了极致。</p><p id="1d18" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这里有一个假设:“<em class="ms">跨通道相关性和空间相关性是充分解耦的，因此最好不要将它们一起映射</em></p><p id="3374" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这是什么意思？嗯，在传统的conv网中，卷积层寻找跨越<em class="ms">空间</em>和<em class="ms">深度</em>的相关性。让我们再来看看我们的标准卷积层:</p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/418d8afd8588ac1e69878034ee0e6878.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*lGm8_2SBMkAyechJeznyAQ.png"/></div></figure><p id="2b86" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在上图中，过滤器同时考虑了空间维度(每个2x2彩色正方形)和跨通道或“深度”维度(四个正方形的堆叠)。在图像的输入层，这相当于卷积滤镜在所有三个RGB通道上查看一个2x2像素块。问题来了:有什么理由需要我们同时考虑图像区域和通道呢？</p><p id="b08d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在《盗梦空间》中，我们开始将两者稍微分开。我们使用1x1卷积将原始输入投影到几个独立的更小的输入空间，并从每个输入空间中使用不同类型的过滤器来转换这些更小的3D数据块。Xception更进一步。它不是将输入数据划分为几个压缩块，而是分别映射<em class="ms">每个输出通道的空间相关性</em>，然后执行1x1深度方向卷积来捕获跨通道相关性。</p><figure class="mu mv mw mx gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nb"><img src="../Images/5879ddfff66981856ccc9ad9efd34a66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SRBSbojkg48DTUMcP5VVHg.jpeg"/></div></div></figure><p id="7367" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">作者指出，这基本上等同于一种称为“深度方向可分离卷积”的现有操作，它由一个<em class="ms">深度方向卷积</em>(为每个通道独立执行的空间卷积)和一个<em class="ms">点方向卷积</em>(跨通道的1x1卷积)组成。我们可以认为这是首先在2D空间寻找相关性，然后在1D空间寻找相关性。直观地说，这种2D + 1D映射比完全的3D映射更容易学习。</p><p id="659d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">而且很管用！在ImageNet数据集上，Xception略微优于Inception v3，在具有17，000个类的更大的图像分类数据集上，xception远远优于Inception v3。最重要的是，它与Inception具有相同数量的模型参数，这意味着更高的计算效率。Xception要新得多(它于2017年4月问世)，但如上所述，它的架构已经在通过MobileNet为谷歌的移动视觉应用提供支持。</p><p id="51a1" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">有趣的事实:</p><ul class=""><li id="82ff" class="lb lc iq ke b kf kg kj kk kn ld kr le kv lf kz lg lh li lj bi translated">Xception的作者也是Keras的作者。弗朗索瓦·乔莱是活着的上帝。</li></ul><h1 id="2515" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">走向</h1><p id="3997" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">ResNet，Inception，Xception就是这样！我坚信对这些网络有很强的直觉理解，因为它们在研究和工业中无处不在。我们甚至可以在自己的应用程序中使用它们，这种应用程序叫做<em class="ms">迁移学习</em>。</p><p id="daeb" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><a class="ae la" href="http://cs231n.github.io/transfer-learning/" rel="noopener ugc nofollow" target="_blank">迁移学习</a>是机器学习中的一种技术，在这种技术中，我们将来自源领域(例如ImageNet)的知识应用到可能具有明显更少数据点的目标领域。在实践中，这通常包括用来自ResNet、Inception等的预训练权重来初始化模型。或者将其用作特征提取器，或者微调新数据集的最后几个图层。通过迁移学习，这些模型可以重新用于我们想要的任何相关任务，从自动驾驶汽车的物体检测到为视频剪辑生成字幕。</p><p id="3bac" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为了开始迁移学习，Keras有一个很棒的微调模型指南<a class="ae la" href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html" rel="noopener ugc nofollow" target="_blank">这里</a>。如果你觉得这很有趣，那就去看看吧——祝你黑客生涯愉快！</p></div></div>    
</body>
</html>