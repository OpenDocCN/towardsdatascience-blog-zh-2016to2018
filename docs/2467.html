<html>
<head>
<title>Use torchtext to Load NLP Datasets — Part II</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 torchtext 加载 NLP 数据集—第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/use-torchtext-to-load-nlp-datasets-part-ii-f146c8b9a496?source=collection_archive---------2-----------------------#2018-01-29">https://towardsdatascience.com/use-torchtext-to-load-nlp-datasets-part-ii-f146c8b9a496?source=collection_archive---------2-----------------------#2018-01-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="a916" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">序列化和更容易的交叉验证</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/fbffadcb6639bc3913dbdc4a9e31e852.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*cW3u2THy6VDssUY8mhfKwQ.jpeg"/></div><figcaption class="kn ko gj gh gi kp kq bd b be z dk"><a class="ae kr" href="https://pixabay.com/en/paper-document-business-book-text-3091439/" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><div class="ks kt gp gr ku kv"><a rel="noopener follow" target="_blank" href="/use-torchtext-to-load-nlp-datasets-part-i-5da6f1c89d84"><div class="kw ab fo"><div class="kx ab ky cl cj kz"><h2 class="bd ir gy z fp la fr fs lb fu fw ip bi translated">使用 torchtext 加载 NLP 数据集—第一部分</h2><div class="lc l"><h3 class="bd b gy z fp la fr fs lb fu fw dk translated">PyTorch Tensors 管道的简单 CSV 文件</h3></div><div class="ld l"><p class="bd b dl z fp la fr fs lb fu fw dk translated">towardsdatascience.com</p></div></div><div class="le l"><div class="lf l lg lh li le lj kl kv"/></div></div></a></div><p id="dcce" class="pw-post-body-paragraph lk ll iq lm b ln lo jr lp lq lr ju ls lt lu lv lw lx ly lz ma mb mc md me mf ij bi translated">在第一部分中，我们讨论了如何从 csv 文件加载文本数据集，标记文本，并通过<em class="mg"> torchtext </em>将它们放入张量。现在，我们将解决该解决方案中的两个问题(仍然使用有毒评论数据集):</p><ol class=""><li id="2b99" class="mh mi iq lm b ln lo lq lr lt mj lx mk mb ml mf mm mn mo mp bi translated"><strong class="lm ir">加载时间太长</strong>:每次你想运行一个新的实验，重新加载数据集会浪费你很多时间。</li><li id="d9aa" class="mh mi iq lm b ln mq lq mr lt ms lx mt mb mu mf mm mn mo mp bi translated"><strong class="lm ir">交叉验证方法的有限选择</strong>:实际上只有一个选择——可以通过<em class="mg"> seed </em>和<em class="mg"> VAL_RATIO </em>参数控制的随机分割。</li></ol><h2 id="ca5e" class="mv mw iq bd mx my mz dn na nb nc dp nd lt ne nf ng lx nh ni nj mb nk nl nm nn bi translated">序列化</h2><p id="0234" class="pw-post-body-paragraph lk ll iq lm b ln no jr lp lq np ju ls lt nq lv lw lx nr lz ma mb ns md me mf ij bi translated">首先，<code class="fe nt nu nv nw b">TabularDataset</code>不幸的是不能直接序列化。我们从观察开始寻找替代方案，在<code class="fe nt nu nv nw b">__init__</code>方法中，<code class="fe nt nu nv nw b">TabularDataset</code> <a class="ae kr" href="https://github.com/pytorch/text/blob/v0.2.1/torchtext/data/dataset.py#L164" rel="noopener ugc nofollow" target="_blank">将文件读入示例列表</a>:</p><pre class="kg kh ki kj gt nx nw ny nz aw oa bi"><span id="e856" class="mv mw iq nw b gy ob oc l od oe">with io.open(os.path.expanduser(path), encoding="utf8") as f:<br/>    if skip_header:<br/>        next(f)                                   <br/>    examples = [make_example(line, fields) for line in f]</span></pre><p id="7a39" class="pw-post-body-paragraph lk ll iq lm b ln lo jr lp lq lr ju ls lt lu lv lw lx ly lz ma mb mc md me mf ij bi translated">下一个观察是<code class="fe nt nu nv nw b">TabularDataset</code>的超类<code class="fe nt nu nv nw b">Dataset</code>接受一个参数<code class="fe nt nu nv nw b">examples</code>(一个例子列表)。所以现在很清楚，我们需要的是<strong class="lm ir">序列化来自</strong> <code class="fe nt nu nv nw b"><strong class="lm ir">TabularDataset</strong></code> <strong class="lm ir">实例的示例，并根据请求</strong>创建 <code class="fe nt nu nv nw b"><strong class="lm ir">Dataset</strong></code> <strong class="lm ir">实例。额外的好处是序列化了<code class="fe nt nu nv nw b">comment</code>字段实例。</strong></p><p id="990e" class="pw-post-body-paragraph lk ll iq lm b ln lo jr lp lq lr ju ls lt lu lv lw lx ly lz ma mb mc md me mf ij bi translated">更具体地说，以下是一般的工作流程:</p><pre class="kg kh ki kj gt nx nw ny nz aw oa bi"><span id="87c9" class="mv mw iq nw b gy ob oc l od oe">def read_files():<br/>    comment = data.Field(...)<br/>    train = data.TabularDataset(...) <br/>    test  = data.TabularDataset(...)<br/>    comment.build_vocab(...)<br/>    return train.examples, test.examples, comment</span><span id="c351" class="mv mw iq nw b gy of oc l od oe">def restore_dataset(train_examples, test_examples, comment):<br/>    train = data.Dataset(...)<br/>    test  = data.Dataset(...)<br/>    return train, test</span></pre><p id="72ca" class="pw-post-body-paragraph lk ll iq lm b ln lo jr lp lq lr ju ls lt lu lv lw lx ly lz ma mb mc md me mf ij bi translated">前两个返回的变量是重建数据集的基本组件。如果你愿意，你可以改装一个<code class="fe nt nu nv nw b">comment</code>字段实例，但是如果你不这样做，它会更快。初始化数据集时，只需插入<code class="fe nt nu nv nw b">comment</code>作为字段之一。</p><h2 id="99cd" class="mv mw iq bd mx my mz dn na nb nc dp nd lt ne nf ng lx nh ni nj mb nk nl nm nn bi translated">交叉验证</h2><p id="e0fb" class="pw-post-body-paragraph lk ll iq lm b ln no jr lp lq np ju ls lt nq lv lw lx nr lz ma mb ns md me mf ij bi translated">因为现在我们从一系列例子而不是 CSV 文件中创建数据集实例，所以生活变得容易多了。<strong class="lm ir">我们可以按照我们想要的任何方式拆分示例列表</strong>，并为每个拆分创建数据集实例。对于分类任务，我通常更喜欢分层 K-Fold 验证。但因为有毒评论数据集是多标签的，所以更难做分层。我们将在下面的章节中使用简单的 K-Fold 验证。</p><h2 id="45bb" class="mv mw iq bd mx my mz dn na nb nc dp nd lt ne nf ng lx nh ni nj mb nk nl nm nn bi translated">把它放在一起</h2><p id="ac38" class="pw-post-body-paragraph lk ll iq lm b ln no jr lp lq np ju ls lt nq lv lw lx nr lz ma mb ns md me mf ij bi translated">完整代码请参考帖子末尾。以下是新解决方案与第一部分中的旧解决方案之间的一些比较:</p><ol class=""><li id="acb7" class="mh mi iq lm b ln lo lq lr lt mj lx mk mb ml mf mm mn mo mp bi translated">我们使用和以前完全一样的记号赋予器。</li><li id="cee7" class="mh mi iq lm b ln mq lq mr lt ms lx mt mb mu mf mm mn mo mp bi translated">尽管不必创建训练/验证分割，我们仍然需要一个简化的<code class="fe nt nu nv nw b">prepare_csv </code>函数来从原始 CSV 文件中删除<em class="mg"> \n </em>字符。</li><li id="a1a9" class="mh mi iq lm b ln mq lq mr lt ms lx mt mb mu mf mm mn mo mp bi translated">这个简洁的库<code class="fe nt nu nv nw b">joblib</code>可以消除通过<code class="fe nt nu nv nw b">pickle</code>模块显式序列化的需要。它的一个特性是<strong class="lm ir">对输出值</strong>的透明和快速磁盘缓存，这可以通过创建一个缓存设置<code class="fe nt nu nv nw b">MEMORY</code>并在任何想要缓存的函数上使用<code class="fe nt nu nv nw b"><strong class="lm ir">@MEMORY.cache</strong></code> <strong class="lm ir">装饰器</strong>来实现(在本例中，函数<code class="fe nt nu nv nw b">read_files</code>读入 CSV 文件并返回两个示例列表和一个字段实例)。</li><li id="1e14" class="mh mi iq lm b ln mq lq mr lt ms lx mt mb mu mf mm mn mo mp bi translated">主函数<code class="fe nt nu nv nw b">get_dataset</code>现在返回<strong class="lm ir">一个生成器</strong>和<strong class="lm ir">一个测试数据集</strong>。生成器为每次迭代提供一个训练数据集和一个验证数据集，并在您运行所有可用的 K 次迭代后实现 K 重验证。</li></ol><p id="0867" class="pw-post-body-paragraph lk ll iq lm b ln lo jr lp lq lr ju ls lt lu lv lw lx ly lz ma mb mc md me mf ij bi translated">以下是在 5 重验证方案下训练 5 个模型的脚本示例:</p><pre class="kg kh ki kj gt nx nw ny nz aw oa bi"><span id="760c" class="mv mw iq nw b gy ob oc l od oe">train_val_generator, test_dataset = get_dataset(<br/>    fix_length=100, lower=True, vectors="fasttext.en.300d",<br/>    n_folds=5, seed=123<br/>)<br/>for fold, (train_dataset, val_dataset) in \<br/>    enumerate(train_val_generator):<br/>    # Initialize a model here...<br/>    for batch in get_iterator(<br/>        train_dataset, batch_size=32, train=True,<br/>        shuffle=True, repeat=False<br/>    ):<br/>        # Train the model here...<br/>    # Create prediction for val_dataset and get a score...<br/>    # Create inference for test_dataset...</span></pre><p id="b5ac" class="pw-post-body-paragraph lk ll iq lm b ln lo jr lp lq lr ju ls lt lu lv lw lx ly lz ma mb mc md me mf ij bi translated">如果你忘了，这里有一个特征和目标提取的例子:</p><pre class="kg kh ki kj gt nx nw ny nz aw oa bi"><span id="452a" class="mv mw iq nw b gy ob oc l od oe">x = batch.comment_text.data<br/>y = torch.stack([<br/>        batch.toxic, batch.severe_toxic, batch.obscene,<br/>        batch.threat, batch.insult, batch.identity_hate<br/>    ],dim=1)</span></pre><h2 id="0d2d" class="mv mw iq bd mx my mz dn na nb nc dp nd lt ne nf ng lx nh ni nj mb nk nl nm nn bi translated">加速</h2><p id="aa22" class="pw-post-body-paragraph lk ll iq lm b ln no jr lp lq np ju ls lt nq lv lw lx nr lz ma mb ns md me mf ij bi translated">这取决于你的 CPU 的能力和你的磁盘的读取速度。在我的电脑里，第一次调用<code class="fe nt nu nv nw b">get_dataset</code>需要 6 分多钟，之后大约 1 分钟。</p><h2 id="4e18" class="mv mw iq bd mx my mz dn na nb nc dp nd lt ne nf ng lx nh ni nj mb nk nl nm nn bi translated">有毒注释数据集加载器的更新版本</h2><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="og oh l"/></div></figure></div></div>    
</body>
</html>