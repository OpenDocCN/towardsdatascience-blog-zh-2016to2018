<html>
<head>
<title>Deep Learning on the Edge</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">边缘的深度学习</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-learning-on-the-edge-9181693f466c?source=collection_archive---------5-----------------------#2018-06-24">https://towardsdatascience.com/deep-learning-on-the-edge-9181693f466c?source=collection_archive---------5-----------------------#2018-06-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="de27" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在移动和边缘设备上执行深度学习的概述。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0708d95ae861a5b6e9c1dd2b8a051562.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iuSKK3d30UFIb_vNPdftjQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/photos/FO7JIlwjOtU?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Alexandre Debiève</a> on <a class="ae kv" href="https://unsplash.com/search/photos/electronics?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="f7a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">可扩展的深度学习服务取决于几个约束。根据您的目标应用，您可能需要低延迟、增强的安全性或长期成本效益。在这种情况下，将深度学习模型托管在云上可能不是最佳解决方案。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ls"><img src="../Images/c727025cd3b87d8cad2a70eacb8e1126.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*In6L9g43W0RmYOXASC1vtA.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Computing on the Edge (<a class="ae kv" href="https://www.ptgrey.com/edge-computing" rel="noopener ugc nofollow" target="_blank">Source</a>)</figcaption></figure><p id="0f2c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">边缘深度学习</strong>缓解了上述问题，并提供了其他好处。这里的 Edge 指的是在消费者的产品上本地执行的计算。这篇博客探讨了使用边缘计算进行深度学习的<strong class="ky ir">好处</strong>，以及与之相关的<strong class="ky ir">问题</strong>。</p><h1 id="3c3e" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">为什么是 edge？为什么不用云呢？</h1><p id="0aba" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">有太多令人信服的理由支持边缘计算而不是云计算。</p><h2 id="f854" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">1.带宽和延迟</h2><p id="b5dc" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">毫无疑问，对远程服务器的 API 调用有一个有形的往返时间(RTT)。要求近乎即时推断的应用程序无法在这种延迟下正常运行。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nc"><img src="../Images/6753d54813740b89ed005054632d01f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WIqaQsKbqWTPlClBqWzHNQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Latency and Power consumption stats for Object Detection (DET), Tracking (TRA) and Localization (LOC) on four different edge devices (<a class="ae kv" href="https://blog.acolyer.org/2018/04/20/the-architectural-implications-of-autonomous-driving-constraints-and-acceleration/" rel="noopener ugc nofollow" target="_blank">Source</a>)</figcaption></figure><p id="024d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以<strong class="ky ir">自动驾驶汽车</strong>为例。足够大的<strong class="ky ir">潜伏期</strong>会显著增加事故的<strong class="ky ir">风险</strong>。此外，意外事件，如动物穿越或 jay walking 可能发生在短短几帧。在这些情况下，响应时间极其重要。这就是为什么 Nvidia 让他们定制的<a class="ae kv" href="https://www.nvidia.com/en-us/self-driving-cars/drive-platform/" rel="noopener ugc nofollow" target="_blank">板载计算设备</a>在边缘执行推理。</p><p id="eaa0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，当大量设备连接到同一个网络时，有效带宽会减少。这是因为使用通信信道的固有竞争。如果在边缘上进行计算，这可以显著减少。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nd"><img src="../Images/c426314cb25fccb6b7a15918323d7a04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KX645CSfemBCM6mi5xfV1A.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Bandwidth requirement for various applications. (<a class="ae kv" href="https://siliconupdates.blogspot.com/2017/07/augmented-reality-and-virtual-reality.html" rel="noopener ugc nofollow" target="_blank">Source</a>)</figcaption></figure><p id="6121" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以在多台设备上处理 4K 高清视频为例。在本地处理它们将大大节省带宽的使用。这是因为我们不需要将数据上传到云中进行推断。因此，我们可以相对容易地扩展这个网络。</p><h2 id="66b8" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">2.安全和权力下放</h2><p id="3d30" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">商业服务器容易受到攻击和黑客攻击。当然，如果您使用可信的供应商，风险可以忽略不计。但是，为了您收集的数据和您的知识产权(IP)的安全，您需要信任第三方。边缘设备让你对你的 IP 拥有绝对的控制权。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ne"><img src="../Images/0924eef96561ea3b43910a82c02237ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VwgFhNj-vmbd6VZx-NyKIA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Centralized vs Decentralized vs Distributed. (<a class="ae kv" href="https://blog.ethfinex.com/the-significance-of-decentralisation-b7f72655484e" rel="noopener ugc nofollow" target="_blank">Source</a>)</figcaption></figure><p id="acac" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你听说过区块链，你可能对分权或分配很熟悉。尽管如此，在边缘拥有几个设备可以获得去中心化的所有好处。使用<strong class="ky ir">单一 DDoS 攻击</strong>来摧毁整个隐藏设备网络<strong class="ky ir">比中央服务器更难</strong>。这对于使用无人机进行边境巡逻等应用尤其有用。</p><h2 id="b017" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">3.特定于工作的用途(定制)</h2><p id="7245" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">想象一下，你有一个生产玩具的工厂。它有几百个工作站。每个工作站都需要图像分类服务。问题是，每个工作站都有一组不同的对象，训练单个分类器可能是无效的。此外，在<strong class="ky ir">云</strong>上托管<strong class="ky ir">多分类器</strong>将会<strong class="ky ir">昂贵</strong>。</p><p id="ddeb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">成本有效的解决方案是训练针对云上每个部分的分类器，并将<strong class="ky ir">训练的模型</strong>运送到<strong class="ky ir">边缘设备</strong>。现在，这些设备是为他们的工作站定制的。它们将比在所有工作站上预测的分类器具有更好的性能。</p><h2 id="fae7" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">4.群体智能</h2><p id="f0a1" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">继续上面提到的想法，边缘设备也可以帮助训练机器学习模型。这对于<strong class="ky ir">强化学习</strong>特别有用，你可以在<strong class="ky ir">并行</strong>中模拟大量的“情节”。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/d2ce9de8c6fd606f96a8c31d1eb89315.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KYomzpKV5Ub3zjVB6hNqAg.jpeg"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Multiple agents trying to grasp objects. (<a class="ae kv" href="http://robohub.org/deep-learning-in-robotics/" rel="noopener ugc nofollow" target="_blank">Source</a>)</figcaption></figure><p id="f230" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">此外，边缘设备可用于收集数据，用于<strong class="ky ir">在线学习</strong>(或<strong class="ky ir">继续学习</strong>)。例如，我们可以使用多架无人机来勘测一个区域进行分类。使用诸如异步 SGD 之类的优化技术，可以在所有边缘设备中并行<strong class="ky ir">训练单个模型</strong>。它也可以仅仅用于聚集和处理来自各种来源的数据。</p><h2 id="8b66" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">5.裁员</h2><p id="eb65" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">冗余对于强健的内存和网络架构极其重要。网络中一个节点的故障会对其他节点产生严重影响。在我们的例子中，边缘设备可以提供很好的冗余度。如果我们的一个边缘设备(这里是一个节点)发生故障，它的邻居可以暂时接管。这极大地确保了可靠性，并大大减少了停机时间。</p><h2 id="50ee" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">6.从长远来看，成本效益高</h2><p id="c42c" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">从长远来看，云服务将比拥有一套专用的推理设备更加昂贵。如果您的设备具有较大的占空比(也就是说，它们大部分时间都在工作)，这一点尤其正确。此外，如果批量生产，边缘设备会便宜得多，从而显著降低成本。</p><h1 id="d4da" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">边缘深度学习的限制</h1><p id="7ae9" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated"><strong class="ky ir">深度学习</strong>模型以<strong class="ky ir">大</strong>和<strong class="ky ir">计算昂贵</strong>而闻名。将这些模型安装到通常具有节省内存的边缘设备中是一个挑战。有许多方法可以解决这些问题。</p><h2 id="65fa" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">1.参数有效的神经网络</h2><p id="598a" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">神经网络的一个显著特征是其庞大的规模。边缘设备通常不能处理大型神经网络。这促使研究人员在保持准确性的同时，最小化神经网络的规模。两种流行的参数高效神经网络是<a class="ae kv" href="https://arxiv.org/abs/1704.04861" rel="noopener ugc nofollow" target="_blank"> MobileNet </a>和<a class="ae kv" href="https://arxiv.org/abs/1602.07360" rel="noopener ugc nofollow" target="_blank"> SqueezeNet </a>。</p><p id="4779" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> SqueezeNet </strong>采用了许多策略，如后期下采样和滤波器数量减少，以在低参数数量下获得高性能。他们引入了具有“挤压”和“扩展”层的“点火模块”,优化了网络的参数效率。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/7289f288991c6115ecfa5d57dc1b245f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*c5ZTXzakIVkDjC5DGlBhyQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Fire module in the SqueezeNet. (<a class="ae kv" href="https://arxiv.org/pdf/1602.07360.pdf" rel="noopener ugc nofollow" target="_blank">Source</a>)</figcaption></figure><p id="0bcd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> MobileNet </strong>将普通卷积分解为深度方向卷积和 1x1 卷积的组合。这种安排大大减少了所涉及的参数数量。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nh"><img src="../Images/098776dda540e48f0cce9f0ccb62b82d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7EJDG7ypufhx14nIu1Vw9Q.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Top 1 accuracy in the ImageNet dataset with respect to number of Multiply-Accumulates (MACs). (<a class="ae kv" href="https://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html" rel="noopener ugc nofollow" target="_blank">Source</a>)</figcaption></figure><h2 id="4c20" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">2.修剪和截断</h2><p id="1841" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">经过训练的网络中的大量神经元是良性的，对最终的准确性没有贡献。在这种情况下，我们可以<strong class="ky ir">修剪</strong>这样的神经元来节省一些空间。谷歌的<a class="ae kv" href="https://ai.googleblog.com/2018/05/custom-on-device-ml-models.html" rel="noopener ugc nofollow" target="_blank"> Learn2Compress </a>发现，我们可以通过因子 2 获得<strong class="ky ir">大小</strong> <strong class="ky ir">缩减，同时保留 97%的准确率。</strong></p><p id="0958" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">而且，大多数神经网络参数都是 32 位浮点值。另一方面，边缘设备可以被设计为在 8 位值或更少的值上工作。降低精度可以显著减小模型大小。例如，将<strong class="ky ir"> 32 位型号</strong>减少到<strong class="ky ir"> 8 位型号</strong>理想情况下会将型号大小减少到<strong class="ky ir">的 4 倍</strong>。</p><h2 id="2f21" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">3.蒸馏</h2><p id="4bf1" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">蒸馏是使用更大的“教师”网络来教授更小的网络的过程。谷歌的<a class="ae kv" href="https://ai.googleblog.com/2018/05/custom-on-device-ml-models.html" rel="noopener ugc nofollow" target="_blank"> Learn2Compress </a>在他们的尺寸缩减过程中融入了这一点。结合迁移学习，这成为一种在不损失太多准确性的情况下减少模型大小的强大方法。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/2f4416e47cd0bda0a426494e778c7edf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*Id6ZQBu9VgANtd8frCQK-w.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Joint training and distillation approach to learn compact student models. (<a class="ae kv" href="https://ai.googleblog.com/2018/05/custom-on-device-ml-models.html" rel="noopener ugc nofollow" target="_blank">Source</a>)</figcaption></figure><h2 id="0a8f" class="mq lu iq bd lv mr ms dn lz mt mu dp md lf mv mw mf lj mx my mh ln mz na mj nb bi translated">4.优化的微处理器设计</h2><p id="a2b4" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">到目前为止，我们已经讨论了缩小神经网络以适应我们的边缘设备的方法。一种替代(或补充)方法是提升微处理器的性能。</p><p id="987a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最简单的解决方案是在微处理器上安装 GPU，比如广受欢迎的 Nvidia Jetson T1。然而，当大规模部署时，这些设备可能不具有成本效益。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/e50cab91fb4a66b41aec9dbe0552b3fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*KlSkL6KOtxml6s5jgqA7Ag.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Nvidia Jetson (<a class="ae kv" href="https://developer.nvidia.com/embedded/buy/jetson-tx2" rel="noopener ugc nofollow" target="_blank">Source</a>)</figcaption></figure><p id="b238" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一个更有趣的解决方案是使用视觉处理单元(vpu)。英特尔声称他们的 Movidius VPUs 具有“超低功耗的高速性能”。谷歌的<a class="ae kv" href="https://www.movidius.com/news/google-launches-aiy-vision-kit-featuring-intel-movidius-vpu" rel="noopener ugc nofollow" target="_blank"> AIY 套件</a>和英特尔的<a class="ae kv" href="https://www.movidius.com/news/intel-movidius-neural-compute-stick-honored-with-ces-best-of-innovation-award-2018" rel="noopener ugc nofollow" target="_blank">神经计算棒</a>内部使用这种 VPU。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/98f7365ea62f593905392abbd3b3ebdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KSItXzlVVbP37XZ7WW-SJw.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Google AIY’s Vision Bonnet using a Movidius VPU. (<a class="ae kv" href="https://www.zdnet.com/article/google-offers-raspberry-pi-owners-this-new-ai-vision-kit-to-spot-cats-people-emotions/" rel="noopener ugc nofollow" target="_blank">Source</a>)</figcaption></figure><p id="065e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">或者，我们可以使用 FPGAs。它们比 GPU 具有更低功耗，且可以适应更低位(&lt; 32 位)的架构。然而，由于其较低的 FLOPs 等级，与 GPU 相比，性能可能会略有下降。</p><p id="26c9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于大规模部署，定制 ASICs 将是最佳解决方案。制造类似 Nvidia V100 的微架构来加速矩阵乘法可以大大提高性能。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/76fed53296d5ae875e9d50f688365c60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*gzozPNb4SFcWPNkOZeNDZw.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Pascal vs Volta architecture; Nvidia. (<a class="ae kv" href="https://www.nvidia.com/en-us/data-center/tensorcore/" rel="noopener ugc nofollow" target="_blank">Source</a>)</figcaption></figure></div></div>    
</body>
</html>