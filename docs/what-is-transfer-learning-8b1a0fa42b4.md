# 什么是迁移学习？

> 原文：<https://towardsdatascience.com/what-is-transfer-learning-8b1a0fa42b4?source=collection_archive---------1----------------------->

**迁移学习**利用在解决一个问题时获得的知识，并将其应用于另一个不同但相关的问题。

例如，在学习识别汽车时获得的知识可以在一定程度上用于识别卡车。

## 预培训

当我们在**大型数据集(例如:ImageNet)** 上训练网络时，我们训练神经网络的所有参数，因此模型被学习。在你的 GPU 上可能要花几个小时。

## **微调**

我们可以给出新的数据集来微调预训练的 CNN。考虑新数据集几乎类似于用于预训练的原始数据集。由于新数据集是相似的，因此可以使用相同的权重从新数据集提取要素。

1.  如果新数据集非常小，最好只训练网络的最后几层，以避免过度拟合，同时保持所有其他层不变。所以去掉预训练网络的最后几层。添加新层。仅重新训练新层。
2.  **如果新数据集非常大，使用预训练模型的初始权重重新训练整个网络**。

## **如果新数据集与原始数据集差别很大，如何进行微调？**

ConvNet 的早期特征包含更多的**通用特征(如边缘检测器或彩色斑点检测器)**，但 ConvNet 的后期层逐渐变得更加具体到原始数据集中包含的**类的细节。**

较早的图层有助于提取新数据的特征。因此，如果你只得到少量的数据，修复早期的层并重新训练其余的层将会很好。

如果您有大量的数据，您可以使用从预训练网络初始化的权重来重新训练整个网络。