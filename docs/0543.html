<html>
<head>
<title>Creating a Spell Checker with TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 TensorFlow 创建拼写检查</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/creating-a-spell-checker-with-tensorflow-d35b23939f60?source=collection_archive---------2-----------------------#2017-05-18">https://towardsdatascience.com/creating-a-spell-checker-with-tensorflow-d35b23939f60?source=collection_archive---------2-----------------------#2017-05-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/ea332960a453eb2ea64cb945692855ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*jHLjKvTJ8m9kXdCdqPq1WA.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Soon typos will be a thing of the past!</figcaption></figure><p id="4113" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">机器学习最重要的一个方面是处理好干净的数据。自然语言进展项目存在使用人类书写的文本的问题，不幸的是，我们不擅长书写。想想在 Reddit 的帖子和评论数据集中会有多少拼写错误。出于这个原因，我认为一个非常有价值的项目是做一个拼写检查器，这将有助于缓解这些问题。</p><p id="49e1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将在这个项目中使用的模型非常类似于我在我的文章“使用亚马逊评论的文本摘要”(两者都是 seq2seq 模型)中所写的模型，但是我添加了一些额外的代码行，以便可以使用网格搜索来调整架构和超参数，并且可以使用 TensorBoard 来分析结果。如果你想更详细地了解如何将 TensorBoard 添加到你的代码中，那么看看“<a class="ae kw" href="https://medium.com/@Currie32/predicting-movie-review-sentiment-with-tensorflow-and-tensorboard-53bf16af0acf" rel="noopener">用 TensorFlow 和 TensorBoard </a>预测电影评论情绪”。</p><p id="f8de" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">本文的主要焦点将是如何为模型准备数据，我还将讨论模型的其他一些特性。我们将在这个项目中使用 Python 3 和 TensorFlow 1.1。数据由来自<a class="ae kw" href="http://www.gutenberg.org/ebooks/search/?sort_order=downloads" rel="noopener ugc nofollow" target="_blank">古腾堡计划</a>的二十本流行书籍组成。如果你有兴趣扩大这个项目，使它更加准确，有数百本书可以在古腾堡项目上下载。另外，看看用这个模型可以做多好的拼写检查也是很有趣的。</p><p id="a4db" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kx">查看完整代码，这里是其</em> <a class="ae kw" href="https://github.com/Currie32/Spell-Checker" rel="noopener ugc nofollow" target="_blank"> <em class="kx"> GitHub 页面</em> </a> <em class="kx">。</em></p><p id="1f3a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了让您预览这种模式的能力，这里有一些精选的示例:</p><ul class=""><li id="f761" class="ky kz iq ka b kb kc kf kg kj la kn lb kr lc kv ld le lf lg bi translated"><strong class="ka ir"> <em class="kx">拼写</em> </strong> <em class="kx">比较难，</em><strong class="ka ir"><em class="kx">whch</em></strong><em class="kx">就是</em><strong class="ka ir"><em class="kx">wyh</em></strong><em class="kx">你需要每天学习。</em></li><li id="7bb3" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated"><strong class="ka ir">拼写</strong>难，<strong class="ka ir">哪个</strong>是<strong class="ka ir">为什么</strong>你需要每天学习。</li><li id="8e98" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated"><em class="kx">她在</em><strong class="ka ir"><em class="kx">th</em></strong><em class="kx">country</em><strong class="ka ir"><em class="kx">vrey</em></strong><em class="kx">为多莉卖命。</em></li><li id="140e" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">对多莉来说，她在 T4 这个国家的最初几天非常艰难。</li><li id="6746" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated"><strong class="ka ir"> <em class="kx"> Thi </em> </strong> <em class="kx">真是了不起</em><strong class="ka ir"><em class="kx">impression iv</em></strong><em class="kx"/><strong class="ka ir"><em class="kx">thaat</em></strong><em class="kx">我们应该马上调查一下！</em></li><li id="70f3" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">这个确实是令人印象深刻的<strong class="ka ir"/><strong class="ka ir">我们应该马上调查一下</strong>！</li></ul></div><div class="ab cl lm ln hu lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="ij ik il im in"><p id="5fac" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了让事情更有条理，我把所有我们会用到的书都放在他们自己的文件夹里，叫做“书”。下面是我们将用来加载所有书籍的函数:</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="4923" class="mc md iq ly b gy me mf l mg mh">def load_book(path):<br/>    input_file = os.path.join(path)<br/>    with open(input_file) as f:<br/>        book = f.read()<br/>    return book</span></pre><p id="fe26" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们还需要每本书的唯一文件名。</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="a2c6" class="mc md iq ly b gy me mf l mg mh">path = './books/'<br/>book_files = [f for f in listdir(path) if isfile(join(path, f))]<br/>book_files = book_files[1:]</span></pre><p id="7356" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当我们将这两个代码块放在一起时，我们将能够将所有书籍中的文本加载到一个列表中。</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="f395" class="mc md iq ly b gy me mf l mg mh">books = []<br/>for book in book_files:<br/>    books.append(load_book(path+book))</span></pre><p id="f24b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果您想知道每本书有多少单词，您可以使用以下代码行:</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="bde4" class="mc md iq ly b gy me mf l mg mh">for i in range(len(books)):<br/>    print("There are {} words in {}.".format(len(books[i].split()), book_files[i]))</span></pre><p id="d6c9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kx">注:如果不包含</em> <code class="fe mi mj mk ly b">.split()</code> <em class="kx">，则返回每本书的人物数量。</em></p><p id="4207" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">清理这些书的正文相当简单。因为我们将使用字符而不是单词作为模型的输入，所以我们不需要担心删除停用的单词，或者将单词缩短到它们的词干。我们只需要删除不想包含的字符和多余的空格。</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="ad91" class="mc md iq ly b gy me mf l mg mh">def clean_text(text):<br/>    '''Remove unwanted characters and extra spaces from the text'''<br/>    text = re.sub(r'\n', ' ', text) <br/>    text = re.sub(r'[{}<a class="ae kw" href="http://twitter.com/_" rel="noopener ugc nofollow" target="_blank">@_</a>*&gt;()\\#%+=\[\]]','', text)<br/>    text = re.sub('a0','', text)<br/>    text = re.sub('\'92t','\'t', text)<br/>    text = re.sub('\'92s','\'s', text)<br/>    text = re.sub('\'92m','\'m', text)<br/>    text = re.sub('\'92ll','\'ll', text)<br/>    text = re.sub('\'91','', text)<br/>    text = re.sub('\'92','', text)<br/>    text = re.sub('\'93','', text)<br/>    text = re.sub('\'94','', text)<br/>    text = re.sub('\.','. ', text)<br/>    text = re.sub('\!','! ', text)<br/>    text = re.sub('\?','? ', text)<br/>    text = re.sub(' +',' ', text) # Removes extra spaces<br/>    return text</span></pre><p id="7fcb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我将跳过如何制作<code class="fe mi mj mk ly b">vocab_to_int</code>和<code class="fe mi mj mk ly b">int_to_vocab</code>字典，因为这是非常标准的东西，你可以在这个项目的<a class="ae kw" href="https://github.com/Currie32/Spell-Checker" rel="noopener ugc nofollow" target="_blank"> GitHub 页面</a>上找到。但是，我认为有必要向您展示输入数据中包含的字符:</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="a7bd" class="mc md iq ly b gy me mf l mg mh">The vocabulary contains 78 characters.<br/>[' ', '!', '"', '$', '&amp;', "'", ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '&lt;EOS&gt;', '&lt;GO&gt;', '&lt;PAD&gt;', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']</span></pre><p id="34d2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们可以删除更多的特殊字符，或者让文本全部小写，但是我想让这个拼写检查器尽可能有用。</p><p id="3150" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">数据在输入模型之前会被组织成句子。我们将拆分每个时间段的数据，每个时间段后面跟一个空格(“.”).其中一个问题是，有些句子以问号或感叹号结尾，但我们没有考虑到这一点。幸运的是，我们的模型仍然能够学习问号和感叹号的用法，只要这两个句子加起来没有最大句子长度长。</p><p id="27fe" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">仅举一个例子:</p><ul class=""><li id="25e6" class="ky kz iq ka b kb kc kf kg kj la kn lb kr lc kv ld le lf lg bi translated">今天是美好的一天。我想去海滩。<em class="kx">(这将被分成两个输入句子)</em></li><li id="2830" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">今天天气好吗？我想去海滩。<em class="kx">(这将是一个长输入句子)</em></li></ul><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="0cbe" class="mc md iq ly b gy me mf l mg mh">sentences = []<br/>for book in clean_books:<br/>    for sentence in book.split('. '):<br/>        sentences.append(sentence + '.')</span></pre><p id="ae6c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我在 loydhub.com 的 T2 使用 GPU 来训练我的模型(我强烈推荐他们的服务)，这为我节省了几个小时的训练时间。尽管如此，为了正确地调优这个模型，仍然需要 30-60 分钟来运行一次迭代，这就是为什么我限制了数据，以便它不需要更长的时间。这当然会降低我们模型的准确性，但由于这只是个人项目，所以我不介意权衡。</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="86ab" class="mc md iq ly b gy me mf l mg mh">max_length = 92<br/>min_length = 10</span><span id="dce8" class="mc md iq ly b gy ml mf l mg mh">good_sentences = []</span><span id="2f76" class="mc md iq ly b gy ml mf l mg mh">for sentence in int_sentences:<br/>    if len(sentence) &lt;= max_length and len(sentence) &gt;= min_length:<br/>        good_sentences.append(sentence)</span></pre><p id="c7c7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了跟踪这个模型的性能，我将把数据分成训练集和测试集。测试集将由 15%的数据组成。</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="c887" class="mc md iq ly b gy me mf l mg mh">training, testing = train_test_split(good_sentences, <br/>                                     test_size = 0.15, <br/>                                     random_state = 2)</span></pre><p id="0120" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">就像我最近的一些项目一样，我将按长度对数据进行排序。这导致一批句子的长度相似，因此使用较少的填充，并且模型将训练得更快。</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="835b" class="mc md iq ly b gy me mf l mg mh">training_sorted = []<br/>testing_sorted = []</span><span id="f9db" class="mc md iq ly b gy ml mf l mg mh">for i in range(min_length, max_length+1):<br/>    for sentence in training:<br/>        if len(sentence) == i:<br/>            training_sorted.append(sentence)<br/>    for sentence in testing:<br/>        if len(sentence) == i:<br/>            testing_sorted.append(sentence)</span></pre><p id="9e21" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">也许这个项目最有趣/最重要的部分是将句子转换成有错误的句子的功能，这些句子将被用作输入数据。在这个函数中，错误以三种方式之一产生:</p><ul class=""><li id="59df" class="ky kz iq ka b kb kc kf kg kj la kn lb kr lc kv ld le lf lg bi translated">两个字符的顺序将被交换(hlelo ~hello)</li><li id="f5f4" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">会多加一个字母(heljlo ~ hello)</li><li id="bb2f" class="ky kz iq ka b kb lh kf li kj lj kn lk kr ll kv ld le lf lg bi translated">一个字符不会打(helo ~hello)</li></ul><p id="fa30" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">三个错误中任何一个发生的可能性都是相等的，任何一个错误发生的可能性都是 5%。因此，平均每 20 个字符中就有一个包含错误。</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="cd62" class="mc md iq ly b gy me mf l mg mh">letters = ['a','b','c','d','e','f','g','h','i','j','k','l','m',<br/>           'n','o','p','q','r','s','t','u','v','w','x','y','z',]</span><span id="db8f" class="mc md iq ly b gy ml mf l mg mh">def noise_maker(sentence, threshold):<br/>    <br/>    noisy_sentence = []<br/>    i = 0<br/>    while i &lt; len(sentence):<br/>        random = np.random.uniform(0,1,1)<br/>        if random &lt; threshold:<br/>            noisy_sentence.append(sentence[i])<br/>        else:<br/>            new_random = np.random.uniform(0,1,1)<br/>            if new_random &gt; 0.67:<br/>                if i == (len(sentence) - 1):<br/>                    continue<br/>                else:<br/>                    noisy_sentence.append(sentence[i+1])<br/>                    noisy_sentence.append(sentence[i])<br/>                    i += 1<br/>            elif new_random &lt; 0.33:<br/>                random_letter = np.random.choice(letters, 1)[0]<br/>                noisy_sentence.append(vocab_to_int[random_letter])<br/>                noisy_sentence.append(sentence[i])<br/>            else:<br/>                pass     <br/>        i += 1<br/>    return noisy_sentence</span></pre><p id="db0b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">本文中我想向您展示的最后一件事是如何创建批处理。通常，人们会在训练他们的模型之前创建他们的输入数据，这意味着他们有固定数量的训练数据。然而，我们将在训练模型时创建新的输入数据，将<code class="fe mi mj mk ly b">noise_maker</code>应用于每一批数据。这意味着对于每个时期，目标(正确的)句子将通过<code class="fe mi mj mk ly b">noise_maker</code>被反馈，并且应该接收新的输入句子。使用这种方法，从某种稍微夸张的意义上来说，我们拥有无限量的训练数据。</p><pre class="lt lu lv lw gt lx ly lz ma aw mb bi"><span id="5e6a" class="mc md iq ly b gy me mf l mg mh">def get_batches(sentences, batch_size, threshold):<br/>    <br/>    for batch_i in range(0, len(sentences)//batch_size):<br/>        start_i = batch_i * batch_size<br/>        sentences_batch = sentences[start_i:start_i + batch_size]<br/>        <br/>        sentences_batch_noisy = []<br/>        for sentence in sentences_batch:<br/>            sentences_batch_noisy.append(<br/>                noise_maker(sentence, threshold))<br/>            <br/>        sentences_batch_eos = []<br/>        for sentence in sentences_batch:<br/>            sentence.append(vocab_to_int['&lt;EOS&gt;'])<br/>            sentences_batch_eos.append(sentence)<br/>            <br/>        pad_sentences_batch = np.array(<br/>            pad_sentence_batch(sentences_batch_eos))<br/>        pad_sentences_noisy_batch = np.array(<br/>            pad_sentence_batch(sentences_batch_noisy))<br/>        <br/>        pad_sentences_lengths = []<br/>        for sentence in pad_sentences_batch:<br/>            pad_sentences_lengths.append(len(sentence))<br/>        <br/>        pad_sentences_noisy_lengths = []<br/>        for sentence in pad_sentences_noisy_batch:<br/>            pad_sentences_noisy_lengths.append(len(sentence))<br/>        <br/>        yield (pad_sentences_noisy_batch, <br/>               pad_sentences_batch, <br/>               pad_sentences_noisy_lengths, <br/>               pad_sentences_lengths)</span></pre></div><div class="ab cl lm ln hu lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="ij ik il im in"><p id="42bf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这个项目到此为止！尽管结果令人鼓舞，但这一模式仍有局限性。如果有人能按比例放大这个模型或改进它的设计，我将不胜感激！如果你有，请在评论中发表。新设计的一个想法是应用<a class="ae kw" href="https://code.facebook.com/posts/1978007565818999/a-novel-approach-to-neural-machine-translation/?utm_campaign=Artificial%2BIntelligence%2Band%2BDeep%2BLearning%2BWeekly&amp;utm_medium=email&amp;utm_source=Artificial_Intelligence_and_Deep_Learning_Weekly_13" rel="noopener ugc nofollow" target="_blank">博览会的新 CNN 模式</a>(它实现了最先进的翻译效果)。</p><p id="a3c0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">感谢阅读，我希望你学到了新的东西！</p></div></div>    
</body>
</html>