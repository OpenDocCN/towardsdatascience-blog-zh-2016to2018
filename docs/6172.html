<html>
<head>
<title>Getting Started With MarathonEnvs v0.5.0a</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">马拉松入门 v0.5.0a</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/gettingstartedwithmarathonenvs-v0-5-0a-c1054a0b540c?source=collection_archive---------8-----------------------#2018-11-29">https://towardsdatascience.com/gettingstartedwithmarathonenvs-v0-5-0a-c1054a0b540c?source=collection_archive---------8-----------------------#2018-11-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/23c6e3123c8c79acd7b31e53bc00136a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZLR_FBoek4ip7a3CrlvNHA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Marathon Environments for Unity ML-Agents</figcaption></figure><p id="8521" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi la translated">我花了两年时间学习强化学习。我创造了马拉松环境，以帮助探索机器人和运动研究在活跃的布娃娃和虚拟代理领域的视频游戏中的适用性。</p><figure class="lj lk ll lm gt jr"><div class="bz fp l di"><div class="ln lo l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Introduction to Marathon Environments. From Hopper to Backflips</figcaption></figure><h1 id="8c15" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">关于本教程</h1><p id="df7e" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">本教程提供了马拉松环境的入门知识。在此，您将了解到:</p><ul class=""><li id="930a" class="ms mt iq ke b kf kg kj kk kn mu kr mv kv mw kz mx my mz na bi translated">如何设置你的<strong class="ke ir">开发环境</strong> (Unity，MarthonEnvs+ML-Agents+TensorflowSharp)</li><li id="50f9" class="ms mt iq ke b kf nb kj nc kn nd kr ne kv nf kz mx my mz na bi translated">如何让每个代理使用他们预先训练好的模型。</li><li id="d1b8" class="ms mt iq ke b kf nb kj nc kn nd kr ne kv nf kz mx my mz na bi translated">如何<strong class="ke ir">重新培训料斗</strong>代理并遵循<strong class="ke ir"> Tensorboard </strong>中的培训。</li><li id="739f" class="ms mt iq ke b kf nb kj nc kn nd kr ne kv nf kz mx my mz na bi translated">如何修改漏斗奖励功能<strong class="ke ir">训练它跳</strong>。</li></ul><h1 id="6f10" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">关于马拉松环境</h1><p id="d158" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated"><a class="ae ng" href="https://github.com/Unity-Technologies/marathon-envs" rel="noopener ugc nofollow" target="_blank"> Marathon Environments </a>使用 ML-Agents 工具包重新实现了深度强化学习文献中常见的经典连续控制基准集，即 Unity environments。</p><p id="d5b2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">Marathon Environments 与 Unity ML- Agents v0.5 一起发布，包括四个连续控制环境。基于<a class="ae ng" href="https://github.com/deepmind/dm_control" rel="noopener ugc nofollow" target="_blank"> DeepMind 控制套件</a>和<a class="ae ng" href="http://gym.openai.com/envs/#mujoco" rel="noopener ugc nofollow" target="_blank"> OpenAI Gym </a>中可用环境的沃克、霍普、人形和蚂蚁。</p><p id="d92a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">所有的环境都有一个单一的 ML-Agent 大脑，有连续的观察和连续的行动。没有视觉观察。每个动作都与一个电动关节轴相关。使用嵌套关节策略实现多轴关节。每个环境包含 16 个同时训练的代理。</p><p id="dfab" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">马拉松环境主页是 https://github.com/Unity-Technologies/marathon-envs<a class="ae ng" href="https://github.com/Unity-Technologies/marathon-envs" rel="noopener ugc nofollow" target="_blank"/>——如果您有任何问题或疑问，请提出 Github 问题。</p><h1 id="bcee" class="lp lq iq bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">设置您的开发库</h1><h2 id="6694" class="nh lq iq bd lr ni nj dn lv nk nl dp lz kn nm nn md kr no np mh kv nq nr ml ns bi translated">安装 Unity 2017.4 或更高版本</h2><p id="bb85" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">从 Unity 商店下载<a class="ae ng" href="https://store.unity.com/download" rel="noopener ugc nofollow" target="_blank"> Unity </a></p><h2 id="2736" class="nh lq iq bd lr ni nj dn lv nk nl dp lz kn nm nn md kr no np mh kv nq nr ml ns bi translated">设置存储库</h2><p id="37f0" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">转到<a class="ae ng" href="https://github.com/Unity-Technologies/marathon-envs/releases/tag/0.5.0a" rel="noopener ugc nofollow" target="_blank"> GitHub MarathonEnvs 0.5.0a 版本</a>并下载<code class="fe nt nu nv nw b">QuickStart_xxx.zip</code>。</p><p id="ce55" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">快速入门在一个 zip 文件中包含以下内容:</p><ul class=""><li id="6949" class="ms mt iq ke b kf kg kj kk kn mu kr mv kv mw kz mx my mz na bi translated">马拉松-envs-0.5.0a</li><li id="63cd" class="ms mt iq ke b kf nb kj nc kn nd kr ne kv nf kz mx my mz na bi translated">毫升-药剂-0.5-3.0a</li><li id="1473" class="ms mt iq ke b kf nb kj nc kn nd kr ne kv nf kz mx my mz na bi translated">张量流图</li></ul><p id="e7b1" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">解压缩到您的开发文件夹。</p><h2 id="029f" class="nh lq iq bd lr ni nj dn lv nk nl dp lz kn nm nn md kr no np mh kv nq nr ml ns bi translated">设置 Python</h2><p id="a56f" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">跟随优秀的<a class="ae ng" href="https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md#install-python-and-mlagents-package" rel="noopener ugc nofollow" target="_blank"> ML-Agents 文档</a>学习如何设置 python 开发环境。</p></div><div class="ab cl nx ny hu nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="ij ik il im in"><h1 id="9281" class="lp lq iq bd lr ls oe lu lv lw of ly lz ma og mc md me oh mg mh mi oi mk ml mm bi translated">运行预先训练的模型</h1><p id="bf07" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">打开 Unity 和您的项目:</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oj"><img src="../Images/d24a505fe6d39e70d6c64c5a247ad265.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JcuyJLV583XK0IvRQRMnSA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Open Unity and Your Project</figcaption></figure><p id="1cb9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">打开 DeepMindWalker 场景:</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ok"><img src="../Images/37fd81f9361c217521d8fc2480ddbab9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*id1OygYjsNRDhKy5lMsw6w.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Open <code class="fe nt nu nv nw b">UnitySDK⁩\Assets⁩\MarathonEnvs⁩\Environments⁩\DeepMindWalker⁩\Scenes⁩\DeepMindWalker.unity</code></figcaption></figure><p id="5e3a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">按下<strong class="ke ir">播放。</strong>这将运行预训练模型<code class="fe nt nu nv nw b">DeepMindWalker108-1m.bytes</code></p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/1c2b89521f715fc397619d341300523a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*d9tWpBESrZBvTN5Mi4E5RA.gif"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">DeepMind Walker — This model was trained using 16 agents over 1m simulation steps</figcaption></figure><p id="beee" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">步行者</strong>代理有 6 个关节/动作和 41 个观察值。奖励函数对于骨盆速度和骨盆垂直度具有正的奖励信号。对于当前动作状态的努力有一个负的奖励信号，如果身高低于 1.1 米则有一个惩罚。</p></div><div class="ab cl nx ny hu nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="ij ik il im in"><h1 id="f9d9" class="lp lq iq bd lr ls oe lu lv lw of ly lz ma og mc md me oh mg mh mi oi mk ml mm bi translated">人形，漏斗和蚂蚁</h1><p id="515d" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">重复上述步骤运行其他环境:</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/e555b491f49239bdd2ca3aefdcbe2f87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*1dI-AXylQJv13GZIktfr4g.gif"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">DeepMind Humanoid</figcaption></figure><p id="7286" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">人形</strong>智能体有 21 个关节/动作，88 个观察值。奖励函数对于骨盆速度和直立度有一个正信号，对于当前动作状态的努力有一个负信号，如果身高低于 1.2m 则有一个惩罚。它还根据其腿部的相位周期增加额外的奖励。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi om"><img src="../Images/9f59e82e2798dd06b2738e32fa6fab25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*UoPeaqutG2Nc3NEtq1aP3A.gif"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">DeepMind Hopper</figcaption></figure><p id="b15b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">料斗</strong>代理有 4 个关节/动作和 31 个观察值。奖励函数对于骨盆速度和骨盆垂直度具有正的奖励信号。同样，对于当前动作状态的努力有一个负的奖励信号，如果身高低于 1.1 米则有一个惩罚信号。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi on"><img src="../Images/a90822317a1915ea5dff99d2fec4c150.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*uz4ZHE-mYqygz9GUwf4Dzg.gif"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">OpenAI Ant</figcaption></figure><p id="00fd" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">蚂蚁智能体有 8 个关节/动作和 53 个观察值。奖励函数对于骨盆速度具有正的奖励信号，对于当前动作状态的努力具有负的奖励信号，并且如果关节处于它们的极限则具有负的信号。</p></div><div class="ab cl nx ny hu nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="ij ik il im in"><h1 id="2490" class="lp lq iq bd lr ls oe lu lv lw of ly lz ma og mc md me oh mg mh mi oi mk ml mm bi translated">培训绩效</h1><p id="be71" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">这里是每个环境之间的训练性能比较，训练 16 个并发代理。</p><figure class="lj lk ll lm gt jr"><div class="bz fp l di"><div class="oo lo l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">These results are using home PC. All environments where build and trained as executables.</figcaption></figure></div><div class="ab cl nx ny hu nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="ij ik il im in"><h1 id="a98f" class="lp lq iq bd lr ls oe lu lv lw of ly lz ma og mc md me oh mg mh mi oi mk ml mm bi translated">训练料斗</h1><p id="fe46" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">到目前为止，我们已经运行了预训练的模型，然而，真正的乐趣开始于你自己训练和运行实验。首先，我们将重新训练料斗。稍后，我们将修改它的奖励函数来完全改变它的行为。</p><h2 id="41e3" class="nh lq iq bd lr ni nj dn lv nk nl dp lz kn nm nn md kr no np mh kv nq nr ml ns bi translated">切换到训练模式</h2><p id="2472" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">在 Unity 中，选择<code class="fe nt nu nv nw b">Academy -&gt; DeepMindHopperBrain</code>。然后，在检查器中，选择<code class="fe nt nu nv nw b">Brain Type</code>下的<code class="fe nt nu nv nw b">External</code>。顾名思义；代理现在需要外部输入。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi op"><img src="../Images/d50b23ed13ceeefa4bd72fd0b8a9e7db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-hUmGmQPTlKQ5RDSXDqlbw.png"/></div></div></figure><h2 id="f0fc" class="nh lq iq bd lr ni nj dn lv nk nl dp lz kn nm nn md kr no np mh kv nq nr ml ns bi translated">调用培训</h2><p id="da65" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">打开终端或命令窗口，调用您的 python 环境:<code class="fe nt nu nv nw b">source activate ml-agents</code>。转到项目<code class="fe nt nu nv nw b">cd /Development/ml-agents-0.5a/</code>的根目录。</p><p id="0256" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">训练命令包含以下元素:</p><p id="dbe2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><code class="fe nt nu nv nw b">mlagents-learn &lt;trainer-config-file&gt; --train --run-id=&lt;run-identifier&gt;</code></p><ul class=""><li id="bac1" class="ms mt iq ke b kf kg kj kk kn mu kr mv kv mw kz mx my mz na bi translated"><code class="fe nt nu nv nw b">mlagents-learn</code>-ml-代理脚本</li><li id="d82d" class="ms mt iq ke b kf nb kj nc kn nd kr ne kv nf kz mx my mz na bi translated"><code class="fe nt nu nv nw b">&lt;trainer-config-file&gt;</code> -路径和文件名。yaml 配置文件。我们将使用<code class="fe nt nu nv nw b">config/marathon_envs_config.yaml</code></li><li id="853c" class="ms mt iq ke b kf nb kj nc kn nd kr ne kv nf kz mx my mz na bi translated"><code class="fe nt nu nv nw b">--train</code>将 ml-agent 设置为训练模式</li><li id="b219" class="ms mt iq ke b kf nb kj nc kn nd kr ne kv nf kz mx my mz na bi translated"><code class="fe nt nu nv nw b">--run-id=&lt;run-identifier&gt;</code>设置本次训练运行的唯一标识符。(在 Tensorboard 中使用的名称和训练模型文件名)</li></ul><p id="8830" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">然后调用 ml-agents python 脚本:<code class="fe nt nu nv nw b">mlagents-learn config/marathon_envs_config.yaml --train --run-id=hopper001</code></p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oq"><img src="../Images/85005af7a0a6336836238365ecca0f28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bEFphsaJu_kgI8uXudUJ7w.png"/></div></div></figure><p id="24cd" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">最后切换回 Unity，按 play 开始训练。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi or"><img src="../Images/1bb6fbc7fa67bf2dde27837f43c700dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G37Fz_o5eDDwGCSt8A40Lw.png"/></div></div></figure><blockquote class="os ot ou"><p id="1480" class="kc kd ov ke b kf kg kh ki kj kk kl km ow ko kp kq ox ks kt ku oy kw kx ky kz ij bi translated">专业提示:使用可执行文件构建和训练将减少训练时间。更多信息见<a class="ae ng" href="https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Training-ML-Agents.md#training-ml-agents" rel="noopener ugc nofollow" target="_blank"> ML-Agents 培训文件</a>。</p></blockquote></div><div class="ab cl nx ny hu nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="ij ik il im in"><h1 id="3f80" class="lp lq iq bd lr ls oe lu lv lw of ly lz ma og mc md me oh mg mh mi oi mk ml mm bi translated">使用 Tensorboard 监控训练</h1><p id="d61e" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">打开第二个终端或命令窗口，调用您的 python 环境:<code class="fe nt nu nv nw b">source activate ml-agents.</code>转到项目的根目录:<code class="fe nt nu nv nw b">cd /Development/ml-agents-0.5a/</code>。使用<code class="fe nt nu nv nw b">tensorboard --logdir=summaries</code>调用 Tensorboard。最后打开浏览器，指向 Tensorboard 输出:<code class="fe nt nu nv nw b"><a class="ae ng" href="http://yourPcName:6006" rel="noopener ugc nofollow" target="_blank">http://yourPcName:6006</a></code>。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oz"><img src="../Images/c8da19c63ee25f117be94d00e782c04a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KNKOjvwvdv4uN9OouAcVkg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Tensorboard allows you to track training in real time</figcaption></figure></div><div class="ab cl nx ny hu nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="ij ik il im in"><h1 id="6927" class="lp lq iq bd lr ls oe lu lv lw of ly lz ma og mc md me oh mg mh mi oi mk ml mm bi translated">在 Unity 中运行训练好的模型</h1><p id="456a" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">为了查看您新训练的模型，我们需要将训练好的模型文件<code class="fe nt nu nv nw b">models/hopper001-0/editor_Academy_hopper001-0.bytes</code>复制到模型文件夹<code class="fe nt nu nv nw b">.../DeepMindHopper/Models</code></p><p id="2971" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">然后，通过选择<code class="fe nt nu nv nw b">Academy -&gt; DeepMindHopperBrain</code>将大脑设置回内部模式，然后在检查器中，选择<code class="fe nt nu nv nw b">Brain Type</code>下的<code class="fe nt nu nv nw b">Internal</code>。接下来，选择<code class="fe nt nu nv nw b">GraphModel</code>下的<code class="fe nt nu nv nw b">editor_Academy_hopper001-0</code>。</p><p id="1ac4" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">按“运行”查看您的训练模型:</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pa"><img src="../Images/06e8e5e58498c98cdd5d42a52cfdb940.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_HN6pMX2N4AVW4dZWHMFcw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Your newly trained model running in Unity</figcaption></figure></div><div class="ab cl nx ny hu nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="ij ik il im in"><h1 id="c97f" class="lp lq iq bd lr ls oe lu lv lw of ly lz ma og mc md me oh mg mh mi oi mk ml mm bi translated">编辑奖励函数让 hopper 跳起来。</h1><p id="7def" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">现在你明白了基本原理，让我们来玩一玩吧！</p><p id="cda2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">打开<code class="fe nt nu nv nw b">DeepMindHopperAgent.cs</code>你喜欢的代码编辑器。默认情况下，Unity 会安装 Visual Studio，但我更喜欢轻量级、响应性更好的 Visual Studio 代码。</p><p id="875b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">找到<code class="fe nt nu nv nw b">StepRewardHopper101()</code>函数并添加下面一行:</p><pre class="lj lk ll lm gt pb nw pc pd aw pe bi"><span id="ff3c" class="nh lq iq nw b gy pf pg l ph pi">var jumpReward = SensorIsInTouch[0] == 0 ? BodyParts["foot"].transform.position.y + .5f : 0f;</span></pre><p id="0680" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这在脚不接触地面时产生一个奖励信号，并根据脚的高度而增加。</p><blockquote class="os ot ou"><p id="20fb" class="kc kd ov ke b kf kg kh ki kj kk kl km ow ko kp kq ox ks kt ku oy kw kx ky kz ij bi translated">专业提示:通常我们希望所有的观察和奖励保持在-1 到 1 之间的“正常”范围内。然而，ML-Agents 可以在训练期间正常化观察和奖励值，这允许我们稍微偷懒！</p></blockquote><p id="254d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">通过用<code class="fe nt nu nv nw b">jumpReward</code>替换<code class="fe nt nu nv nw b">velocity</code>来更新<code class="fe nt nu nv nw b">reward</code>。它应该是这样的:</p><pre class="lj lk ll lm gt pb nw pc pd aw pe bi"><span id="d5c5" class="nh lq iq nw b gy pf pg l ph pi">var reward = jumpReward<br/>                     + uprightBonus<br/>                     - effortPenality<br/>                     - jointsAtLimitPenality;</span></pre><p id="780a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">确保您的<strong class="ke ir"> <em class="ov">保存</em> </strong> <code class="fe nt nu nv nw b">DeepMindHopperAgent.cs</code>。然后，按照之前的培训步骤，重新培训代理。结果将如下所示:</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi pj"><img src="../Images/09b94d550e3f66013197cf626c7584ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XfOzmx2Ox-iW_Mv6xCxFzg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Hopper is now trained to jump!</figcaption></figure></div><div class="ab cl nx ny hu nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="ij ik il im in"><h1 id="42b8" class="lp lq iq bd lr ls oe lu lv lw of ly lz ma og mc md me oh mg mh mi oi mk ml mm bi translated">更深入</h1><p id="8838" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">下面是一些关于使用和扩展马拉松环境的更多技术细节。</p><p id="2adf" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">奖励</strong>、<strong class="ke ir">终止</strong>和<strong class="ke ir">观察</strong>功能受到 DeepMind 控制套件和 OpenAI.Roboschool 的影响，一个例外是人形机器人，它在奖励中实现了一个阶段功能，以提高训练速度。</p><p id="80d5" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">每个环境都是一个独立的 Unity 场景，每个代理类型都有一个预置，并且包含一个或多个预先训练的 Tensorflow 模型。从 MarathonAgent.cs 继承的自定义代理类用于定义该代理的行为。对于每个环境，开发人员应该实现以下内容:</p><p id="cadc" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><code class="fe nt nu nv nw b">AgentReset()</code>用于初始化代理。它应该为 StepRewardFunction、TerminateFunction 和 ObservationsFunction 设置回调。开发人员应该将模型元素添加到 BodyParts 列表中，并调用<code class="fe nt nu nv nw b">SetupBodyParts()</code>来初始化 body parts。这使得回调能够利用助手函数；例如，<code class="fe nt nu nv nw b">GetForwardBonus("pelvis")</code>根据身体部位与前向向量的距离计算奖金。</p><p id="5abf" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><code class="fe nt nu nv nw b">StepReward()</code>返回一个<code class="fe nt nu nv nw b">float</code>，带有当前动作步骤的奖励。辅助函数包括以下:<code class="fe nt nu nv nw b">GetVelocity("pelvis")</code>返回指定身体部位的速度；<code class="fe nt nu nv nw b">GetEffort()</code>返回当前动作的总和(可以传递一个要忽略的身体部位列表)；并且<code class="fe nt nu nv nw b">GetJointsAtLimitPenality()</code>返回对达到其极限的动作的惩罚。</p><p id="7dad" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果满足终止条件，则<code class="fe nt nu nv nw b">TerminateFunction()</code>返回<code class="fe nt nu nv nw b">true</code>。终止功能通过减少代理暴露于无用的观察来帮助提高训练速度。辅助终止函数包括<code class="fe nt nu nv nw b">TerminateNever()</code>，它永远不会终止(总是返回<code class="fe nt nu nv nw b">false</code>)和<code class="fe nt nu nv nw b">TerminateOnNonFootHitTerrain()</code>，如果不是脚的身体部位与地形发生碰撞，它将返回<code class="fe nt nu nv nw b">true</code>。身体部位在功能<code class="fe nt nu nv nw b">OnTerrainCollision()</code>中定义。一些代理商要求小腿身体部位贴上<code class="fe nt nu nv nw b">"foot"</code>标签，因为它们从足部几何形状中突出来，造成假阳性终止。</p></div><div class="ab cl nx ny hu nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="ij ik il im in"><h1 id="31a1" class="lp lq iq bd lr ls oe lu lv lw of ly lz ma og mc md me oh mg mh mi oi mk ml mm bi translated">包扎</h1><p id="c006" class="pw-post-body-paragraph kc kd iq ke b kf mn kh ki kj mo kl km kn mp kp kq kr mq kt ku kv mr kx ky kz ij bi translated">在本教程中，我们学习了如何安装马拉松环境，运行预训练的 Tensorflow 模型，我们重新训练了 hopper，然后我们学习了如何修改奖励函数来奖励 Hopper 的跳跃。</p><p id="a366" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">这应该给你一个很好的基础，让你用强化学习来尝试马拉松。</p><blockquote class="os ot ou"><p id="fc55" class="kc kd ov ke b kf kg kh ki kj kk kl km ow ko kp kq ox ks kt ku oy kw kx ky kz ij bi translated">P <!-- --> ro 提示:我强烈建议您阅读<a class="ae ng" href="https://github.com/Unity-Technologies/ml-agents/blob/master/docs/" rel="noopener ugc nofollow" target="_blank"> ML-Agents 培训文档</a>以了解有关使用 Unity ML-Agents 的更多详细信息。</p></blockquote><p id="c68f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">你可以在下面的 Github 项目中关注我的一些研究。</p><ul class=""><li id="b765" class="ms mt iq ke b kf kg kj kk kn mu kr mv kv mw kz mx my mz na bi translated"><a class="ae ng" href="https://github.com/Sohojoe/ActiveRagdollStyleTransfer" rel="noopener ugc nofollow" target="_blank">github.com/Sohojoe/ActiveRagdollStyleTransfer</a>——对活动布娃娃运动方式转移的研究(来自动作捕捉数据)</li><li id="5170" class="ms mt iq ke b kf nb kj nc kn nd kr ne kv nf kz mx my mz na bi translated"><a class="ae ng" href="https://github.com/Sohojoe/ActiveRagdollAssaultCourse" rel="noopener ugc nofollow" target="_blank">github.com/Sohojoe/ActiveRagdollAssaultCourse</a>—训练突击课目研究</li><li id="06a0" class="ms mt iq ke b kf nb kj nc kn nd kr ne kv nf kz mx my mz na bi translated"><a class="ae ng" href="https://github.com/Sohojoe/ActiveRagdollControllers" rel="noopener ugc nofollow" target="_blank">github.com/Sohojoe/ActiveRagdollControllers</a>—主动布娃娃控制器的研究</li><li id="0298" class="ms mt iq ke b kf nb kj nc kn nd kr ne kv nf kz mx my mz na bi translated"><a class="ae ng" href="https://github.com/Sohojoe/MarathonEnvsBaselines" rel="noopener ugc nofollow" target="_blank">github.com/Sohojoe/MarathonEnvsBaselines</a>—实验性—开放式健身房/基线</li></ul><p id="6be9" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果您遇到任何问题或 bug，或者有任何疑问，请在该项目的 Github 页面<a class="ae ng" href="https://github.com/Unity-Technologies/marathon-envs" rel="noopener ugc nofollow" target="_blank">https://github.com/Unity-Technologies/marathon-envs</a>提出问题</p></div></div>    
</body>
</html>