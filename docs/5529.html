<html>
<head>
<title>Introduction to Linear Regression in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 中的线性回归简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introduction-to-linear-regression-in-python-c12a072bedf0?source=collection_archive---------0-----------------------#2018-10-24">https://towardsdatascience.com/introduction-to-linear-regression-in-python-c12a072bedf0?source=collection_archive---------0-----------------------#2018-10-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="9f3e" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何用 Python <code class="fe kf kg kh ki b">statsmodels </code> &amp; <code class="fe kf kg kh ki b">scikit-learn libraries.</code>实现线性回归的快速教程</h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi kj"><img src="../Images/85ebf277480c02e3779f6e12e9b5773b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*G1Y_-X14q2xMVHlUuaUUdA.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Example linear regression model using simulated data</figcaption></figure><p id="533a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">线性回归</strong>是一种基本的预测分析技术，使用历史数据来预测输出变量。它在预测建模中很受欢迎，因为它容易理解，可以用简单的英语解释。</p><p id="ae71" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">线性回归模型在一系列行业中有许多实际应用，例如经济学(例如预测增长)、商业(例如预测产品销售、员工绩效)、社会科学(例如从性别或种族预测政治倾向)、医疗保健(例如从体重预测血压水平、从生物因素预测疾病发作)等等。</p><p id="6e94" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">了解如何实现线性回归模型可以挖掘数据中的故事来解决重要问题。我们将使用 Python，因为它是处理和建模数据的强大工具。它有一系列用于线性回归建模的软件包。</p><p id="8a3e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">基本的想法是，如果我们可以用一个线性回归模型来拟合观察到的数据，那么我们就可以用这个模型来预测任何未来的值。例如，假设我们从历史数据中发现，房子的价格(<strong class="kx ir"> <em class="lr"> P </em> </strong>)与房子的大小(<strong class="kx ir"> <em class="lr"> S </em> </strong>)呈线性相关——事实上，我们发现房子的价格正好是其大小的 90 倍。该等式将如下所示:</p><p id="df03" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr"> P = 90*S </em></p><p id="dcf4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有了这个模型，我们就可以预测任何房子的价格。如果我们有一栋 1500 平方英尺的房子，我们可以计算出它的价格:</p><p id="c711" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">P = 90 * 1500 = 135000 美元</em></p><p id="fdcc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这篇博文中，我们涵盖了:</p><ol class=""><li id="8fa5" class="ls lt iq kx b ky kz lb lc le lu li lv lm lw lq lx ly lz ma bi translated">模型背后的基本概念和数学</li><li id="c998" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">如何使用模拟数据从头实现线性回归</li><li id="5aa1" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">如何用<code class="fe kf kg kh ki b">statsmodels</code>实现线性回归</li><li id="426c" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq lx ly lz ma bi translated">如何使用<code class="fe kf kg kh ki b">scikit-learn</code>实现线性回归</li></ol><h2 id="1cdc" class="mg mh iq bd mi mj mk dn ml mm mn dp mo le mp mq mr li ms mt mu lm mv mw mx my bi translated">这篇简短的教程改编自下一期 XYZ<a class="ae mz" href="https://c.next.tech/2G9Hlzn" rel="noopener ugc nofollow" target="_blank">Python 线性回归</a>课程，其中包括浏览器内沙盒环境、要完成的任务以及使用公共数据集的项目。</h2></div><div class="ab cl na nb hu nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="ij ik il im in"><h1 id="e782" class="nh mh iq bd mi ni nj nk ml nl nm nn mo jw no jx mr jz np ka mu kc nq kd mx nr bi translated">基本概念和数学</h1><p id="0e06" class="pw-post-body-paragraph kv kw iq kx b ky ns jr la lb nt ju ld le nu lg lh li nv lk ll lm nw lo lp lq ij bi translated">线性回归模型中有两种变量:</p><ul class=""><li id="c0e4" class="ls lt iq kx b ky kz lb lc le lu li lv lm lw lq nx ly lz ma bi translated"><strong class="kx ir">输入</strong>或<strong class="kx ir">预测变量</strong>是帮助预测输出变量值的变量。就是俗称的<strong class="kx ir"> <em class="lr"> X </em> </strong>。</li><li id="64c2" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq nx ly lz ma bi translated"><strong class="kx ir">输出变量</strong>是我们想要预测的变量。俗称<strong class="kx ir"> <em class="lr"> Y </em> </strong>。</li></ul><p id="249b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了使用线性回归估计<em class="lr"> Y </em>，我们假设等式:</p><blockquote class="ny"><p id="388c" class="nz oa iq bd ob oc od oe of og oh lq dk translated"><strong class="ak"> <em class="oi"> Yₑ = α + β X </em> </strong></p></blockquote><p id="4599" class="pw-post-body-paragraph kv kw iq kx b ky oj jr la lb ok ju ld le ol lg lh li om lk ll lm on lo lp lq ij bi translated">其中<em class="lr"> Y </em> ₑ是基于我们的线性方程的<em class="lr"> Y </em>的估计值或预测值。</p><p id="99b4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们的目标是找到使<em class="lr"> Y </em>和<em class="lr"> Y </em> ₑ.之间的差异最小化的<strong class="kx ir">参数<em class="lr"> α </em> </strong>和<strong class="kx ir"> <em class="lr"> β </em> </strong>的统计显著值</p><p id="3d1a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果我们能够确定这两个参数的最佳值，那么我们将有最佳拟合的<strong class="kx ir">线</strong>，我们可以用它来预测<em class="lr"> Y </em>的值，给定<em class="lr"> X </em>的值。</p><p id="c9f2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">那么，我们如何估算<em class="lr"> α </em>和<em class="lr"> β </em>？我们可以用一种叫做<a class="ae mz" href="https://en.wikipedia.org/wiki/Ordinary_least_squares" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir">普通最小二乘法</strong> </a>的方法。</p><h2 id="5705" class="mg mh iq bd mi mj mk dn ml mm mn dp mo le mp mq mr li ms mt mu lm mv mw mx my bi translated">普通最小二乘法</h2><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/f842b635da37d9f1d321faa5cab0bb80.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*VVA0rF6MWXcw1JmRNFA87g.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Green lines show the difference between actual values Y and estimate values <em class="oi">Y</em>ₑ</figcaption></figure><p id="16db" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最小二乘法的目的是找到使<em class="lr"> Y </em>和<em class="lr"> Y </em> ₑ.之间的平方差之和最小的<em class="lr"> α </em>和<em class="lr"> β </em>的值这里我们不进行推导，但是使用微积分我们可以表明未知参数的值如下:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="oq or di os bf ot"><div class="gh gi op"><img src="../Images/0329cd57d6136dbd3fcf64e418c075ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:394/0*gR-W7RFar9ijxwAa"/></div></div></figure><p id="b702" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">其中<em class="lr"> X̄ </em>是<em class="lr"> X </em>值的平均值，而<em class="lr">ȳ</em>是<em class="lr"> Y </em>值的平均值。</p><p id="1aa3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你熟悉统计学，你可能会把<em class="lr"> β </em>简单地理解为<br/> <em class="lr"> Cov(X，Y) / Var(X)。</em></p><h1 id="0801" class="nh mh iq bd mi ni ou nk ml nl ov nn mo jw ow jx mr jz ox ka mu kc oy kd mx nr bi translated">从头开始线性回归</h1><p id="411f" class="pw-post-body-paragraph kv kw iq kx b ky ns jr la lb nt ju ld le nu lg lh li nv lk ll lm nw lo lp lq ij bi translated">在本文中，我们将使用两个 Python 模块:</p><ul class=""><li id="1e83" class="ls lt iq kx b ky kz lb lc le lu li lv lm lw lq nx ly lz ma bi translated"><code class="fe kf kg kh ki b"><a class="ae mz" href="https://www.statsmodels.org/stable/index.html" rel="noopener ugc nofollow" target="_blank">statsmodels</a></code> —一个模块，为许多不同的统计模型的估计，以及进行统计测试和统计数据探索提供类和函数。</li><li id="49cd" class="ls lt iq kx b ky mb lb mc le md li me lm mf lq nx ly lz ma bi translated"><code class="fe kf kg kh ki b"><a class="ae mz" href="http://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank">scikit-learn</a></code> —为数据挖掘和数据分析提供简单高效工具的模块。</li></ul><p id="19c5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我们开始之前，了解如何从头开始实现这个模型是很有用的。了解包在幕后是如何工作的是很重要的，所以你不能只是盲目地实现模型。</p><p id="9505" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，让我们模拟一些数据，看看预测值(<em class="lr"> Y </em> ₑ)与实际值(<em class="lr"> Y </em>)有何不同:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="5a91" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果运行上述代码(例如，在 Jupyter 笔记本中)，将会输出如下内容:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/e2ab27c602153b1b59a9a3af9f1f5d3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*UEdpbXeIsCvxdg4tQvPjpA.png"/></div></figure><p id="4f72" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了使用 OLS 方法估计<em class="lr"> y </em>，我们需要计算<code class="fe kf kg kh ki b">xmean</code>和<code class="fe kf kg kh ki b">ymean</code>、<em class="lr"> X </em>和<em class="lr"> y </em> ( <code class="fe kf kg kh ki b">xycov</code>)的协方差以及<em class="lr"> X </em> ( <code class="fe kf kg kh ki b">xvar</code>)的方差，然后才能确定<code class="fe kf kg kh ki b">alpha</code>和<code class="fe kf kg kh ki b">beta</code>的值。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oz pa l"/></div></figure><pre class="kk kl km kn gt pc ki pd pe aw pf bi"><span id="930a" class="mg mh iq ki b gy pg ph l pi pj"><strong class="ki ir">Out:</strong><br/>alpha = 2.0031670124623426<br/>beta = 0.32293968670927636</span></pre><p id="6f0c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">太好了，我们现在有了对<code class="fe kf kg kh ki b">alpha</code>和<code class="fe kf kg kh ki b">beta</code>的估计！我们的模型可以写成<em class="lr"> Yₑ = 2.003 + 0.323 X，</em>我们可以做出预测:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oz pa l"/></div></figure><pre class="kk kl km kn gt pc ki pd pe aw pf bi"><span id="17c7" class="mg mh iq ki b gy pg ph l pi pj"><strong class="ki ir">Out:</strong><br/>array([3.91178282, 2.81064315, 3.27775989, 4.29675991, 3.99534802,<br/>       1.69857201, 3.25462968, 2.36537842, 2.40424288, 2.81907292,<br/>       ...<br/>       2.16207195, 3.47451661, 2.65572718, 3.2760653 , 2.77528867,<br/>       3.05802784, 2.49605373, 3.92939769, 2.59003892, 2.81212234])</span></pre><p id="ebdc" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">让我们对照<code class="fe kf kg kh ki b">y</code>的实际值绘制我们的预测<code class="fe kf kg kh ki b">ypred</code>，以便更好地直观理解我们的模型。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oz pa l"/></div></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi pk"><img src="../Images/8cd113e47e908108237dfa2133d84fad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*Cf9q9CQ-SNuplvzuchk0mA.png"/></div></figure><p id="73b1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">蓝线是我们的最佳拟合线，<em class="lr"> Yₑ = 2.003 + 0.323 X. </em>从这个图中我们可以看出，<em class="lr"> X </em>和<em class="lr"> y </em>之间存在正的线性关系。使用我们的模型，我们可以从<em class="lr"> X </em>的任何值预测<em class="lr"> y </em>！</p><p id="f0a1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">例如，如果我们有一个值<em class="lr"> X = 10 </em>，我们可以预测:<br/><em class="lr">yₑ= 2.003+0.323(10)= 5.233。</em></p><h1 id="915b" class="nh mh iq bd mi ni ou nk ml nl ov nn mo jw ow jx mr jz ox ka mu kc oy kd mx nr bi translated">用<code class="fe kf kg kh ki b">statsmodels</code>进行线性回归</h1><p id="c7d4" class="pw-post-body-paragraph kv kw iq kx b ky ns jr la lb nt ju ld le nu lg lh li nv lk ll lm nw lo lp lq ij bi translated">既然我们已经从头开始学习了如何实现线性回归模型，我们将讨论如何使用<code class="fe kf kg kh ki b">statsmodels</code>库中的<code class="fe kf kg kh ki b">ols</code>方法。</p><p id="eac5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了演示这种方法，我们将使用一个非常受欢迎的<code class="fe kf kg kh ki b">advertising</code>数据集，该数据集是关于不同媒体的广告费用以及特定产品的销售额。你可以在这里下载这个数据集<a class="ae mz" href="http://www-bcf.usc.edu/~gareth/ISL/Advertising.csv" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="8cfb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在本例中，我们将只关注<code class="fe kf kg kh ki b">TV</code>变量——我们将探究电视广告支出是否能预测产品的销售数量。让我们从使用<code class="fe kf kg kh ki b">read_csv()</code>将这个 csv 文件作为<code class="fe kf kg kh ki b">pandas</code>数据帧导入开始:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oz pa l"/></div></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi pl"><img src="../Images/95bf8178c4714a1ea5ca1b09abeca414.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*TJVgeBufWNGVbvrJlI5DhQ.png"/></div></figure><p id="708c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，我们使用<code class="fe kf kg kh ki b">statsmodels</code> ' <code class="fe kf kg kh ki b">ols</code>函数初始化我们的简单线性回归模型。这采用公式<code class="fe kf kg kh ki b">y ~ X</code>，其中<code class="fe kf kg kh ki b">X</code>是预测变量(<code class="fe kf kg kh ki b">TV</code>广告成本)<code class="fe kf kg kh ki b">y</code>是输出变量(<code class="fe kf kg kh ki b">Sales</code>)。然后，我们通过调用 OLS 对象的<code class="fe kf kg kh ki b">fit()</code>方法来拟合模型。</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="f92b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们不再需要自己计算<code class="fe kf kg kh ki b">alpha</code>和<code class="fe kf kg kh ki b">beta</code>，因为这种方法会自动为我们计算！调用<code class="fe kf kg kh ki b">model.params</code>会显示模型的参数:</p><pre class="kk kl km kn gt pc ki pd pe aw pf bi"><span id="6d42" class="mg mh iq ki b gy pg ph l pi pj"><strong class="ki ir">Out:</strong><br/>Intercept    7.032594<br/>TV           0.047537<br/>dtype: float64</span></pre><p id="af2b" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我们一直使用的符号中，<em class="lr"> α </em>是截距，<em class="lr"> β </em>是斜率，即<em class="lr"> α </em> = 7.032，<em class="lr"> β </em> = 0.047。</p><p id="c7b0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，模型的等式将是:<strong class="kx ir"> <em class="lr">销售= 7.032+0.047 *电视</em> </strong></p><p id="500f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">简单地说，这意味着平均来说，如果我们在电视广告上花了 100 美元，我们应该可以卖出 11.73 台。</p><p id="48e8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在我们已经拟合了一个简单的回归模型，我们可以尝试使用<code class="fe kf kg kh ki b">.predict</code>方法根据我们刚刚推导出的公式来预测销售额。</p><p id="2bd2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们还可以通过绘制<code class="fe kf kg kh ki b">sales_pred</code>与电视广告成本的对比图来可视化我们的回归模型，以找到最佳拟合线:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oz pa l"/></div></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi pm"><img src="../Images/69f5c0bf9e29ddda3d5456806d812eae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*M9KtWbx17EDWabLS31-mlA.png"/></div></figure><p id="6681" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以看到，电视广告成本和销售额之间存在正线性关系——换句话说，在电视广告上花费更多预测了更高的销售额！</p><p id="589f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有了这个模型，我们可以从电视广告的任何花费中预测销售额。例如，如果我们将电视广告费用增加到 400 美元，我们可以预测销售量将增加到 26 台:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oz pa l"/></div></figure><pre class="kk kl km kn gt pc ki pd pe aw pf bi"><span id="6f01" class="mg mh iq ki b gy pg ph l pi pj"><strong class="ki ir">Out:</strong><br/>0    26.04725<br/>dtype: float64</span></pre><h1 id="9c2c" class="nh mh iq bd mi ni ou nk ml nl ov nn mo jw ow jx mr jz ox ka mu kc oy kd mx nr bi translated">用<code class="fe kf kg kh ki b">scikit-learn</code>进行线性回归</h1><p id="16ea" class="pw-post-body-paragraph kv kw iq kx b ky ns jr la lb nt ju ld le nu lg lh li nv lk ll lm nw lo lp lq ij bi translated">我们已经学会了使用<code class="fe kf kg kh ki b">statsmodels</code>实现线性回归模型…现在让我们学习使用<code class="fe kf kg kh ki b">scikit-learn</code>来实现它！</p><p id="5e86" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">对于这个模型，我们将继续使用<code class="fe kf kg kh ki b">advertising</code>数据集，但这次我们将使用两个预测变量来创建一个<strong class="kx ir">多元线性回归模型</strong>。这是一个简单的线性回归模型，有一个以上的预测值，建模如下:</p><p id="3a03" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir"> <em class="lr"> Yₑ = α + β₁X₁ + β₂X₂ + … + βₚXₚ，</em> </strong>其中<em class="lr"> p </em>为预测数。</p><p id="9ba6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在我们的例子中，我们将使用变量<code class="fe kf kg kh ki b">TV</code>和<code class="fe kf kg kh ki b">Radio</code>预测<code class="fe kf kg kh ki b">Sales</code>，即我们的模型可以写成:</p><p id="b7bd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">销售额= α + β₁*TV + β₂*Radio.</em></p><p id="217f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">首先，我们初始化我们的线性回归模型，然后将模型拟合到我们的预测值和输出变量:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oz pa l"/></div></figure><p id="eb6f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">同样，我们不需要自己计算<code class="fe kf kg kh ki b">alpha</code>和<code class="fe kf kg kh ki b">betas</code>的值——我们只需要为<code class="fe kf kg kh ki b">alpha</code>调用<code class="fe kf kg kh ki b">.intercept_</code>,为带有系数<code class="fe kf kg kh ki b">beta1</code>和<code class="fe kf kg kh ki b">beta2</code>的数组调用<code class="fe kf kg kh ki b">.coef_</code>:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oz pa l"/></div></figure><pre class="kk kl km kn gt pc ki pd pe aw pf bi"><span id="4ca9" class="mg mh iq ki b gy pg ph l pi pj"><strong class="ki ir">Out:</strong><br/>alpha = 2.921099912405138<br/>betas = [0.04575482 0.18799423]</span></pre><p id="b9e1" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">因此，我们的模型可以写成:</p><p id="ca76" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><em class="lr">销量= 2.921+0.046 *电视+0.1880 *收音机。</em></p><p id="8280" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们可以通过简单地使用<code class="fe kf kg kh ki b">.predict()</code>来预测值:</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oz pa l"/></div></figure><pre class="kk kl km kn gt pc ki pd pe aw pf bi"><span id="dcf1" class="mg mh iq ki b gy pg ph l pi pj"><strong class="ki ir">Out:</strong><br/>array([20.555464, 12.345362, 12.337017, 17.617115, 13.223908,<br/>       12.512084, 11.718212, 12.105515,  3.709379, 12.551696,<br/>       ...<br/>       12.454977,  8.405926,  4.478859, 18.448760, 16.4631902,<br/>        5.364512,  8.152375, 12.768048, 23.792922, 15.15754285])</span></pre><p id="2673" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">既然我们已经将多元线性回归模型拟合到我们的数据中，我们就可以根据电视和广播广告成本的任何组合来预测销售额了！例如，如果我们想知道，如果我们在电视广告上投资 300 美元，在广播广告上投资 200 美元，我们会取得多少销售额……我们所要做的就是输入这些数值！</p><figure class="kk kl km kn gt ko"><div class="bz fp l di"><div class="oz pa l"/></div></figure><pre class="kk kl km kn gt pc ki pd pe aw pf bi"><span id="aac2" class="mg mh iq ki b gy pg ph l pi pj"><strong class="ki ir">Out:</strong><br/>[54.24638977]</span></pre><p id="3614" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这意味着，如果我们在电视广告上花 300 美元，在广播广告上花 200 美元，我们预计平均会卖出 54 台。</p></div><div class="ab cl na nb hu nc" role="separator"><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf ng"/><span class="nd bw bk ne nf"/></div><div class="ij ik il im in"><p id="8491" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我希望你喜欢这个关于线性回归基础的简短教程！</p><p id="5c56" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们讲述了如何在 Python 中使用<code class="fe kf kg kh ki b">statsmodels</code>和<code class="fe kf kg kh ki b">scikit-learn</code>来实现线性回归。在实践中，您必须知道如何验证您的模型和测量功效，如何为您的模型选择重要变量，如何处理分类变量，以及何时以及如何执行非线性转换。</p><h2 id="eab4" class="mg mh iq bd mi mj mk dn ml mm mn dp mo le mp mq mr li ms mt mu lm mv mw mx my bi translated">我们有涵盖所有这些主题的完整课程(甚至更多！)<a class="ae mz" href="https://c.next.tech/2G9Hlzn" rel="noopener ugc nofollow" target="_blank">这里</a>在下一届 XYZ，如果你有兴趣学习更多关于 Python 线性回归的知识！</h2></div></div>    
</body>
</html>