<html>
<head>
<title>Getting Data into TensorFlow Estimator Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将数据导入张量流估算模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/getting-data-into-tensorflow-estimator-models-3432f404a8da?source=collection_archive---------2-----------------------#2018-08-26">https://towardsdatascience.com/getting-data-into-tensorflow-estimator-models-3432f404a8da?source=collection_archive---------2-----------------------#2018-08-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/83a4e1a483e4eb3730e828e691adabdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ai_ug7v3rxwdnyiB"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo by <a class="ae kc" href="https://unsplash.com/@cadop?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Mathew Schwartz</a> on <a class="ae kc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="029c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">机器学习是关于你的数据的数量和质量。上述数据通常可从多种来源获得:</p><ul class=""><li id="3a3f" class="lb lc iq kf b kg kh kk kl ko ld ks le kw lf la lg lh li lj bi translated">文本文件(CSV、TSV、Excel)</li><li id="3c6d" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">数据库</li><li id="3ff9" class="lb lc iq kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">流媒体源</li></ul><p id="52e6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">文本文件是由从其他来源提取数据的某个人或某些人提供的，但他们希望您不必亲自提取数据。数据可以在一个或多个文件中，有或没有标题。</p><p id="09a5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">张量流估计器使用输入函数。输入函数的签名返回一组要素和标注。特性是特性名称和数值数组的字典。标签是一组值。需要进行一些管理，比如对数据进行洗牌，然后分批返回。你采取的方法决定了你需要付出多少努力。</p><p id="3015" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们从简单的选项开始。如果你把数据放在一个文件中，你可以把它完全读入内存(所谓的玩具例子)，而且这个文件是以文本分隔的格式(CSV，TSV 等)，所需的工作量是最小的。通常情况下，你可以用 numpy 或 pandas 来读取你的文件。</p><p id="135d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">提醒一下，在使用<code class="fe lp lq lr ls b">tf.estimator</code> API 的时候，需要在训练的时候传入一个输入函数。这是用于训练的函数签名:</p><pre class="lt lu lv lw gt lx ls ly lz aw ma bi"><span id="c868" class="mb mc iq ls b gy md me l mf mg">train(<br/>    input_fn,<br/>    hooks=None,<br/>    steps=None,<br/>    max_steps=None,<br/>    saving_listeners=None<br/>)</span></pre><p id="152e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的重点是<code class="fe lp lq lr ls b">input_fn</code>！我们将使用流行的波士顿住房数据，这些数据在<a class="ae kc" href="https://www.kaggle.com/c/boston-housing" rel="noopener ugc nofollow" target="_blank">这里</a>托管。</p><p id="dc64" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你有 numpy 格式的数据，你可以使用<code class="fe lp lq lr ls b">tf.estimator.inputs.numpy_input_function</code>来获取你的数据。首先，您需要为您的特征定义一个字典:</p><pre class="lt lu lv lw gt lx ls ly lz aw ma bi"><span id="48a7" class="mb mc iq ls b gy md me l mf mg"># extract numpy data from a DataFrame<br/>crim = train_df['crim'].values<br/>zn = train_df['zn'].values<br/>indus = train_df['indus'].values<br/>chas = train_df['chas'].values<br/>nox = train_df['nox'].values<br/>rm = train_df['rm'].values<br/>age = train_df['age'].values<br/>dis = train_df['dis'].values<br/>rad = train_df['rad'].values<br/>tax = train_df['tax'].values<br/>ptratio = train_df['ptratio'].values<br/>black = train_df['black'].values<br/>lstat = train_df['lstat'].values<br/>medv = train_df['medv'].values</span><span id="932f" class="mb mc iq ls b gy mh me l mf mg"># create a dictionary<br/>x_dict = {<br/>    'crim': crim,<br/>    'zn': zn,<br/>    'indus': indus,<br/>    'chas': chas,<br/>    'nox': nox,<br/>    'rm': rm,<br/>    'age': age,<br/>    'dis': dis,<br/>    'rad': rad,<br/>    'tax': tax,<br/>    'ptratio': ptratio,<br/>    'black': black,<br/>    'lstat': lstat<br/>}</span></pre><p id="5a8a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有了字典，我们可以继续定义输入函数。</p><pre class="lt lu lv lw gt lx ls ly lz aw ma bi"><span id="080c" class="mb mc iq ls b gy md me l mf mg">def np_training_input_fn(x, y):<br/>  return tf.estimator.inputs.numpy_input_fn(<br/>      x= x,<br/>      y= y,<br/>      batch_size= 32,<br/>      num_epochs= 5, # this way you can leave out steps from training<br/>      shuffle= True,<br/>      queue_capacity= 5000<br/>  )</span></pre><p id="0d29" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我们的函数中，我们传入 x 和 y，x 是我们的字典，y 是我们的标签。我们还可以传入我们的批量大小、时期数以及是否打乱数据。请注意，你总是想打乱你的数据。批量大小是一个超级参数，你应该凭经验归档。epochs 的数量是您想要查看数据的次数。对于训练，设置任何数字。对于测试，将其设置为 1。</p><p id="feb1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在创建评估器之前，您需要特性列。</p><pre class="lt lu lv lw gt lx ls ly lz aw ma bi"><span id="312b" class="mb mc iq ls b gy md me l mf mg">feature_cols = [tf.feature_column.numeric_column(k) for k in x_dict.keys()]</span><span id="0a54" class="mb mc iq ls b gy mh me l mf mg">lin_model = tf.estimator.LinearRegressor(feature_columns=feature_cols)</span><span id="4bfa" class="mb mc iq ls b gy mh me l mf mg">lin_model.train(np_training_input_fn(x_dict, medv), steps=10)</span></pre><p id="535b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可以省略步骤，以便训练使用在训练输入函数中指定的时段，或者指定用于训练的步骤数。numpy 输入到此为止。</p><p id="07e0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于数据帧，您将继续定义输入函数如下:</p><pre class="lt lu lv lw gt lx ls ly lz aw ma bi"><span id="a63c" class="mb mc iq ls b gy md me l mf mg">def pd_input_fn(df, y_label):<br/>  return tf.estimator.inputs.pandas_input_fn(<br/>      x=df,<br/>      y=df[y_label],<br/>      batch_size = 32,<br/>      num_epochs = 5,<br/>      shuffle = True,<br/>      queue_capacity = 1000,<br/>      num_threads = 1<br/>  )</span></pre><p id="952f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，在上面的方法中，我们继续传入数据帧，并在其中添加标签。如果标签不在您传递给<code class="fe lp lq lr ls b">x</code>的内容中，您将得到一个错误。你把一个系列传给<code class="fe lp lq lr ls b">y</code>。其他参数与处理 numpy 时相同。</p><p id="18df" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该模型在未来会得到同样的对待。创建模型并指定特征列。然后，您继续训练模式。</p><pre class="lt lu lv lw gt lx ls ly lz aw ma bi"><span id="04d6" class="mb mc iq ls b gy md me l mf mg">lin_model = tf.estimator.LinearRegressor(feature_columns=feature_cols)</span><span id="8caa" class="mb mc iq ls b gy mh me l mf mg">lin_model.train(pd_input_fn(train_df, 'medv'), steps=10)</span></pre></div><div class="ab cl mi mj hu mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="ij ik il im in"><p id="b36f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当您可以将数据读入内存时，一切都很好。但是，当你不能的时候会发生什么。当你的训练数据集是 100GB 时会发生什么？</p><p id="25a1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好消息是，这样的数据集通常由分布式系统生成，因此您的文件将是<code class="fe lp lq lr ls b">sharded</code>。这意味着数据将被存储在不同的文件名为<code class="fe lp lq lr ls b">data-0001-of-1000</code>的文件中。</p><p id="5df7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你从未处理过大数据，你的第一个想法可能是使用<code class="fe lp lq lr ls b">glob</code>。不要这样做，除非你知道你正在处理一个玩具的例子。你会耗尽你的记忆，训练也会停止。</p><p id="bd4d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些类型的文件通常没有头文件，这是一件好事。首先，您将定义一个列名列表，这些列名应该按照您的列在文件中存在的顺序排列。其次，定义一个标签列。最后，定义一个缺省值列表，以便在读取过程中遇到缺失值时可以处理它们。</p><pre class="lt lu lv lw gt lx ls ly lz aw ma bi"><span id="71c9" class="mb mc iq ls b gy md me l mf mg">CSV_COLUMNS = ['medv', 'crim', 'zn', 'lstat', 'tax', 'rad', 'chas', 'nox', 'indus', 'ptratio', 'age', 'black', 'rm', 'dis']<br/>LABEL_COLUMN = 'medv'<br/>DEFAULTS = [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]</span></pre><p id="bb76" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们定义一个函数来读入文本数据，并返回我们的格式，就像我们前面的函数处理它们一样。函数创建方式的一个优点是它可以处理通配符，比如<code class="fe lp lq lr ls b">data-*</code>。</p><pre class="lt lu lv lw gt lx ls ly lz aw ma bi"><span id="7b5f" class="mb mc iq ls b gy md me l mf mg"><strong class="ls ir">def</strong> read_dataset(filename, mode, batch_size = 512):<br/>  <strong class="ls ir">def</strong> _input_fn():<br/>    <strong class="ls ir">def</strong> decode_csv(value_column):<br/>      columns = tf.decode_csv(value_column, record_defaults = DEFAULTS)<br/>      features = dict(zip(CSV_COLUMNS, columns))<br/>      label = features.pop(LABEL_COLUMN)<br/>      <strong class="ls ir">return</strong> features, label<br/><br/>    <em class="mp"># Create list of files that match pattern</em><br/>    file_list = tf.gfile.Glob(filename)<br/><br/>    <em class="mp"># Create dataset from file list</em><br/>    dataset = tf.data.TextLineDataset(file_list).map(decode_csv)<br/>    <strong class="ls ir">if</strong> mode == tf.estimator.ModeKeys.TRAIN:<br/>        num_epochs = None <em class="mp"># indefinitely</em><br/>        dataset = dataset.shuffle(buffer_size = 10 * batch_size)<br/>    <strong class="ls ir">else</strong>:<br/>        num_epochs = 1 <em class="mp"># end-of-input after this</em><br/><br/>    dataset = dataset.repeat(num_epochs).batch(batch_size)<br/>    <strong class="ls ir">return</strong> dataset.make_one_shot_iterator().get_next()<br/>  <strong class="ls ir">return</strong> _input_fn</span></pre><p id="1c81" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该函数接受三个参数:一个匹配多个文件的模式、一个模式(训练或评估)和一个批处理大小。注意<code class="fe lp lq lr ls b">read_dataset</code>返回一个函数。我们称这个函数为<code class="fe lp lq lr ls b">_input_fn</code>。在这个函数中，我们有一个名为<code class="fe lp lq lr ls b">decode_csv</code>的函数，它将创建一个字典，提取一个序列，并以我们在本文开头提到的元组格式返回两者。</p><p id="5209" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其次，我们的函数使用<code class="fe lp lq lr ls b">glob</code>创建一个文件名列表。是的，<code class="fe lp lq lr ls b">glob</code>仍然被使用，但是我们不把结果传递给一个<code class="fe lp lq lr ls b">pandas.read_csv()</code>。反而遇到了<code class="fe lp lq lr ls b">tf.data.TextLineDataset()</code>。它有三个参数:文件名列表、压缩格式(none、ZLIB 或 GZIP)和缓冲区大小。<code class="fe lp lq lr ls b">read_csv</code>和<code class="fe lp lq lr ls b">TextLineDataset</code>的主要区别在于，前者将内容读入内存(我们可以批量读取)，而后者返回一个<code class="fe lp lq lr ls b">Iterator</code>。</p><p id="2067" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我们的函数通过调用<code class="fe lp lq lr ls b">map</code>函数，传入<code class="fe lp lq lr ls b">decode_csv</code>，使用<code class="fe lp lq lr ls b">TextLineDataset</code>创建一个数据集。它做的下一件事是检查我们是否处于训练模式。如果不是，我们的历元数被设置为 1。如果是的话，它会被设置为我们想要的任意多个纪元。我们的训练数据集也被打乱了。然后，我们的数据集被设置为重复我们想要的历元数，并根据我们的批量大小进行配置。</p><p id="a070" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我们返回一个一次性迭代器，并调用<code class="fe lp lq lr ls b">get_next()</code>。所有这些工作都由我们前面看到的函数在幕后处理。我们可以使用以下方法创建我们的训练、评估和测试输入函数:</p><pre class="lt lu lv lw gt lx ls ly lz aw ma bi"><span id="9a9c" class="mb mc iq ls b gy md me l mf mg"><strong class="ls ir">def</strong> get_train():<br/>  <strong class="ls ir">return</strong> read_dataset('./train-.*', mode = tf.estimator.ModeKeys.TRAIN)<br/><br/><strong class="ls ir">def</strong> get_valid():<br/>  <strong class="ls ir">return</strong> read_dataset('./valid.csv', mode = tf.estimator.ModeKeys.EVAL)<br/><br/><strong class="ls ir">def</strong> get_test():<br/>  <strong class="ls ir">return</strong> read_dataset('./test.csv', mode = tf.estimator.ModeKeys.EVAL)</span></pre><p id="e039" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">剩下的过程和我们看到的完全一样。我们可以像往常一样创建我们的估计器并训练它。</p><p id="2786" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">对于真正的项目，你将从阅读一个使用熊猫和<code class="fe lp lq lr ls b">tf.estimator.inputs</code>的训练文件开始。但是，要在培训中使用所有文件，您需要使用<code class="fe lp lq lr ls b">tf.data.TextLineDataset</code>。</p><p id="1503" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">快乐编码。</p></div></div>    
</body>
</html>