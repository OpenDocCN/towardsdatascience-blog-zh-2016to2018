<html>
<head>
<title>PyTorch tutorial distilled</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch教程精华</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pytorch-tutorial-distilled-95ce8781a89c?source=collection_archive---------2-----------------------#2017-09-25">https://towardsdatascience.com/pytorch-tutorial-distilled-95ce8781a89c?source=collection_archive---------2-----------------------#2017-09-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c191" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">从TensorFlow迁移到PyTorch</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/871872634896da7759e1ae0681970bdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aqNgmfyBIStLrf9k7d9cng.jpeg"/></div></div></figure><p id="1644" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">当我刚开始研究PyTorch时，几天后我就放弃了。与TensorFlow相比，我很难理解这个框架的核心概念。这就是为什么我把它放在我的“知识书架”上，然后忘记了它。但是不久前，PyTorch的新版本发布了。所以我决定再给它一次机会。过了一段时间，我明白了这个框架真的很容易使用，它让我很高兴用PyTorch编码。在这篇文章中，我会试着解释清楚它的核心概念，这样你会有动力至少现在就试一试，而不是在几年或更久之后。我们将涵盖一些基本原则和一些先进的东西，如学习率调度，自定义层等。</p><h2 id="72ca" class="ln lo iq bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me mf bi translated">资源</h2><p id="f3d1" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">首先，你应该知道PyTorch的<a class="ae ml" href="http://pytorch.org/docs/master/" rel="noopener ugc nofollow" target="_blank">文档</a>和<a class="ae ml" href="http://pytorch.org/tutorials/" rel="noopener ugc nofollow" target="_blank">教程</a>是分开存放的。有时，由于快速的开发和版本变化，他们可能不会见面。所以填免费调查<a class="ae ml" href="http://pytorch.org/tutorials/" rel="noopener ugc nofollow" target="_blank">源代码</a>。它非常清晰明了。最好提一下，有很棒的<a class="ae ml" href="https://discuss.pytorch.org/" rel="noopener ugc nofollow" target="_blank"> PyTorch论坛</a>，在那里你可以问任何合适的问题，你会很快得到答案。对于PyTorch用户来说，这个地方似乎比StackOverflow更受欢迎。</p><h2 id="5ac0" class="ln lo iq bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me mf bi translated">PyTorch as NumPy</h2><p id="7af8" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">所以让我们深入PyTorch本身。PyTorch的主要构件是张量。真的，它们和<a class="ae ml" href="https://docs.scipy.org/doc/numpy-dev/user/quickstart.html" rel="noopener ugc nofollow" target="_blank"> NumPy的</a>很像。Tensors支持很多相同的API，所以有时你可以使用PyTorch作为NumPy的替代。你可能会问这是什么原因。主要目标是PyTorch可以利用GPU，以便您可以将数据预处理或任何其他计算密集型工作转移到机器学习领域。很容易将张量从NumPy转换成PyTorch，反之亦然。让我们检查一些代码示例:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><h2 id="c5a8" class="ln lo iq bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me mf bi translated">从张量到变量</h2><p id="7969" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">张量是PyTorch中令人敬畏的一部分。但主要我们想要的是建立一些神经网络。什么是反向传播？当然我们可以手动实现，但是这是什么原因呢？谢天谢地，自动微分存在。为了支持它，PyTorch <a class="ae ml" href="http://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_autograd.html" rel="noopener ugc nofollow" target="_blank">为你提供了变量</a>。变量是张量之上的包装器。有了它们，我们可以建立我们的计算图，并在以后自动计算梯度。每个变量实例都有两个属性:<code class="fe mo mp mq mr b">.data</code>包含初始张量本身，<code class="fe mo mp mq mr b">.grad</code>包含相应张量的梯度。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="1b11" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">您可能会注意到，我们已经手动计算并应用了我们的梯度。太乏味了。我们有优化器吗？当然啦！</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="6bca" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在我们所有的变量都会自动更新。但是你应该从上一个片段中得到的要点是:在计算新的梯度之前，我们仍然应该手动置零梯度。这是PyTorch的核心概念之一。有时，我们为什么要这样做可能不是很明显，但另一方面，我们可以完全控制我们的渐变，何时以及如何应用它们。</p><h2 id="bb4c" class="ln lo iq bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me mf bi translated">静态与动态计算图</h2><p id="2951" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">PyTorch和TensorFlow的下一个主要区别是它们的图形表示方法。Tensorflow <a class="ae ml" href="https://www.tensorflow.org/programmers_guide/graphs" rel="noopener ugc nofollow" target="_blank">使用静态图</a>，这意味着我们定义它一次，然后一次又一次地执行那个图。在PyTorch中，每次向前传递都会定义一个新的计算图。一开始，这些方法之间的区别并不是很大。但是当你想调试你的代码或者定义一些条件语句时，动态图就变得很少了。您可以直接使用您喜欢的调试器！比较while循环语句的下两个定义TensorFlow中的第一个和PyTorch中的第二个:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="7347" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在我看来，第二个解决办法比第一个容易得多。你对此有什么看法？</p><h2 id="9147" class="ln lo iq bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me mf bi translated">模型定义</h2><p id="3a05" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">好了，现在我们看到在PyTorch中构建一些if/else/while复杂语句很容易。但是让我们回到通常的模型。该框架提供了非常类似于<a class="ae ml" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>的现成层构造器:</p><blockquote class="ms mt mu"><p id="7c87" class="kr ks mv kt b ku kv jr kw kx ky ju kz mw lb lc ld mx lf lg lh my lj lk ll lm ij bi translated"><code class="fe mo mp mq mr b">nn</code>包定义了一组<strong class="kt ir">模块</strong>，大致相当于神经网络层。模块接收输入变量并计算输出变量，但也可以保存内部状态，例如包含可学习参数的变量。<code class="fe mo mp mq mr b">nn</code>包还定义了一组在训练神经网络时常用的有用的损失函数。</p></blockquote><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="dfdd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">此外，如果我们想构建更复杂的模型，我们可以子类化提供的<code class="fe mo mp mq mr b">nn.Module</code>类。当然，这两种方法可以混合使用。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="e83a" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在<code class="fe mo mp mq mr b">__init__</code>方法中，我们应该定义所有将在以后使用的层。在<code class="fe mo mp mq mr b">forward</code>方法中，我们应该提出如何使用已经定义的层的步骤。像往常一样，向后传球将被自动计算。</p><h2 id="88aa" class="ln lo iq bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me mf bi translated">自定义层</h2><p id="b444" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">但是如果我们想定义一些带有非标准backprop的定制模型呢？这里有一个例子——XNOR网络公司:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/af4a68dcdf9eaf7e9e32655fcbaf34dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cjzIFgglAP9xGKg8mlRysQ.png"/></div></div></figure><p id="099c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我不会深究细节，更多关于这种类型的网络，你可以在<a class="ae ml" href="https://arxiv.org/abs/1603.05279" rel="noopener ugc nofollow" target="_blank">初始论文</a>中读到。与我们的问题相关的是，反向传播应该只应用于小于1和大于-1的权重。在PyTorch中，它<a class="ae ml" href="http://pytorch.org/docs/master/notes/extending.html" rel="noopener ugc nofollow" target="_blank">可以很容易地实现</a>:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="3093" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">正如你所看到的，我们应该只定义两个方法:一个用于向前传递，一个用于向后传递。如果我们需要从正向传递中访问一些变量，我们可以将它们存储在<code class="fe mo mp mq mr b">ctx</code>变量中。注意:在以前的API中，向前/向后方法不是静态的，我们将所需的变量存储为<code class="fe mo mp mq mr b">self.save_for_backward(input)</code>，并以<code class="fe mo mp mq mr b">input, _ = self.saved_tensors</code>的形式访问它们。</p><h2 id="d4fd" class="ln lo iq bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me mf bi translated">使用CUDA训练模型</h2><p id="68cc" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">我们之前讨论过如何将一个张量传递给CUDA。但是如果要传递整个模型，从模型本身调用<code class="fe mo mp mq mr b">.cuda()</code>方法就可以了，把每个输入变量包装到<code class="fe mo mp mq mr b">.cuda()</code>就够了。在所有的计算之后，我们应该用<code class="fe mo mp mq mr b">.cpu()</code>方法得到结果。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="e9e5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">此外，PyTorch在源代码中支持直接设备分配:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="428f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因为有时我们希望在CPU和GPU上运行相同的模型，而不修改代码，所以我提出了某种包装器:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><h2 id="ad71" class="ln lo iq bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me mf bi translated">重量初始化</h2><p id="0439" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">在张量流中，权重初始化主要在张量声明期间进行。PyTorch提供了另一种方法——首先，应该声明张量，下一步应该改变张量的权重。权重可以初始化为对张量属性的直接访问，调用<code class="fe mo mp mq mr b">torch.nn.init</code>包中的一堆方法。这个决定可能不是很直接，但当您想要用相同的初始化来初始化某个类型的所有层时，它会变得很有用。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><h2 id="ed94" class="ln lo iq bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me mf bi translated">从反向中排除子图</h2><p id="f805" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">有时，当您想要重新训练模型的某些层或为生产模式做准备时，您可以禁用某些层的亲笔签名机制，这非常有用。为此，<a class="ae ml" href="http://pytorch.org/docs/master/notes/autograd.html" rel="noopener ugc nofollow" target="_blank"> PyTorch提供了两个标志</a> : <code class="fe mo mp mq mr b">requires_grad</code>和<code class="fe mo mp mq mr b">volatile</code>。第一个将禁用当前层的渐变，但子节点仍然可以计算一些。第二个将禁用当前层和所有子节点的自动签名。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><h2 id="fce6" class="ln lo iq bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me mf bi translated">培训过程</h2><p id="0978" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">PyTorch中还存在其他一些附加功能。例如，你可以使用<a class="ae ml" href="http://pytorch.org/docs/master/optim.html#how-to-adjust-learning-rate" rel="noopener ugc nofollow" target="_blank">学习率调度器</a>，它将根据一些规则调整你的学习率。或者，您可以启用/禁用具有单个训练标志的批量定额层和辍学。如果你想很容易改变随机种子分别为CPU和GPU。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="a9ef" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">此外，您可以打印关于您的模型的信息，或者用几行代码保存/加载它。如果你的模型是用<a class="ae ml" href="https://docs.python.org/3/library/collections.html" rel="noopener ugc nofollow" target="_blank"> OrderedDict </a>或基于类的模型来初始化的，那么字符串表示将包含层的名称。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="c382" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">根据PyTorch文档，使用<code class="fe mo mp mq mr b">state_dict()</code>方法的保存模型<a class="ae ml" href="http://pytorch.org/docs/master/notes/serialization.html" rel="noopener ugc nofollow" target="_blank">更可取</a>。</p><h2 id="a6f4" class="ln lo iq bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me mf bi translated">记录</h2><p id="8c7f" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">记录训练过程是非常重要的一部分。不幸的是，PyTorch没有任何类似tensorboard的工具。因此，您可以使用带有<a class="ae ml" href="https://docs.python.org/3/library/logging.html" rel="noopener ugc nofollow" target="_blank"> Python日志模块</a>的普通文本日志，或者尝试一些第三方库:</p><ul class=""><li id="f902" class="na nb iq kt b ku kv kx ky la nc le nd li ne lm nf ng nh ni bi translated"><a class="ae ml" href="https://github.com/oval-group/logger" rel="noopener ugc nofollow" target="_blank">用于实验的简单记录器</a></li><li id="654e" class="na nb iq kt b ku nj kx nk la nl le nm li nn lm nf ng nh ni bi translated"><a class="ae ml" href="https://github.com/torrvision/crayon" rel="noopener ugc nofollow" target="_blank">tensor board的语言无关接口</a></li><li id="bf01" class="na nb iq kt b ku nj kx nk la nl le nm li nn lm nf ng nh ni bi translated"><a class="ae ml" href="https://github.com/TeamHG-Memex/tensorboard_logger" rel="noopener ugc nofollow" target="_blank">在不接触张量流的情况下记录张量板事件</a></li><li id="f4d3" class="na nb iq kt b ku nj kx nk la nl le nm li nn lm nf ng nh ni bi translated"><a class="ae ml" href="https://github.com/lanpa/tensorboard-pytorch" rel="noopener ugc nofollow" target="_blank">py torch的张量板</a></li><li id="6b71" class="na nb iq kt b ku nj kx nk la nl le nm li nn lm nf ng nh ni bi translated"><a class="ae ml" href="https://github.com/facebookresearch/visdom" rel="noopener ugc nofollow" target="_blank">脸书可视化智慧图书馆</a></li></ul><h2 id="3e12" class="ln lo iq bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me mf bi translated">数据处理</h2><p id="c5e9" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">您可能还记得TensorFlow 中提出的<a class="ae ml" href="https://www.tensorflow.org/api_guides/python/reading_data" rel="noopener ugc nofollow" target="_blank">数据加载器，甚至试图实现其中的一些。对我来说，花了大约4个小时或更多的时间来了解所有管道应该如何工作。</a></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi no"><img src="../Images/a5c30489cde9b5e0445c2d6661eb6abe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*S00VU2HiEjNZ35zlj2kqfw.gif"/></div></div><figcaption class="np nq gj gh gi nr ns bd b be z dk">Image source: TensorFlow docs</figcaption></figure><p id="d2e7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最初，我想在这里添加一些代码，但我认为这样的gif将足以解释所有事情如何发生的基本想法。</p><p id="c768" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">PyTorch开发者决定不重新发明轮子。他们只是使用多重处理。要创建您自己的定制数据加载器，从<code class="fe mo mp mq mr b">torch.utils.data.Dataset</code>继承您的类并更改一些方法就足够了:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="d9de" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">你应该知道的两件事。首先，图像尺寸不同于张量流。它们是[batch _ size x channels x height x width]。但是这种转换可以通过预处理步骤<code class="fe mo mp mq mr b">torchvision.transforms.ToTensor()</code>在没有交互的情况下完成。在<a class="ae ml" href="http://pytorch.org/docs/master/torchvision/transforms.html" rel="noopener ugc nofollow" target="_blank">转换包</a>中也有很多有用的实用程序。</p><p id="d0f9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">第二件重要的事情是你可以在GPU上使用固定内存。为此，您只需要为一个<code class="fe mo mp mq mr b">cuda()</code>调用添加一个额外的标志<code class="fe mo mp mq mr b">async=True</code>，并从带有标志<code class="fe mo mp mq mr b">pin_memory=True</code>的数据加载器中获取固定批次。关于此功能<a class="ae ml" href="http://pytorch.org/docs/master/notes/cuda.html#use-pinned-memory-buffers" rel="noopener ugc nofollow" target="_blank">的更多信息在这里</a>讨论。</p><h2 id="4313" class="ln lo iq bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me mf bi translated">最终架构概述</h2><p id="a740" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">现在你知道了模型、优化器和许多其他东西。什么才是把它们全部合并的正确方法？我建议将您的模型和所有包装器拆分成这样的构件:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/a3201e0e69322088ee0e554792fd81dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A-cWYNur2lqDEhUF1_gdCw.png"/></div></div></figure><p id="ecb7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了清楚起见，这里有一些伪代码:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><h2 id="8999" class="ln lo iq bd lp lq lr dn ls lt lu dp lv la lw lx ly le lz ma mb li mc md me mf bi translated">结论</h2><p id="e71e" class="pw-post-body-paragraph kr ks iq kt b ku mg jr kw kx mh ju kz la mi lc ld le mj lg lh li mk lk ll lm ij bi translated">我希望这篇文章能让你理解PyTorch的要点:</p><ul class=""><li id="7d7c" class="na nb iq kt b ku kv kx ky la nc le nd li ne lm nf ng nh ni bi translated">它可以作为Numpy的替代产品</li><li id="42cb" class="na nb iq kt b ku nj kx nk la nl le nm li nn lm nf ng nh ni bi translated">这对于原型制作来说真的很快</li><li id="4a8a" class="na nb iq kt b ku nj kx nk la nl le nm li nn lm nf ng nh ni bi translated">调试和使用条件流很容易</li><li id="d77a" class="na nb iq kt b ku nj kx nk la nl le nm li nn lm nf ng nh ni bi translated">有许多现成的好工具</li></ul><p id="9112" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">PyTorch是一个快速发展的框架，有一个很棒的社区。我认为今天是尝试的最佳时机！</p></div></div>    
</body>
</html>