<html>
<head>
<title>Coding Deep Learning for Beginners — Linear Regression (Part 2): Cost Function</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">初学者深度学习编码—线性回归(第二部分):代价函数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/coding-deep-learning-for-beginners-linear-regression-part-2-cost-function-49545303d29f?source=collection_archive---------1-----------------------#2018-08-08">https://towardsdatascience.com/coding-deep-learning-for-beginners-linear-regression-part-2-cost-function-49545303d29f?source=collection_archive---------1-----------------------#2018-08-08</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/03258c63dbf3f86b6c99db88f716548d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hs3DdhS5IHofA84qrZfmHQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Evaluating model performance during training process. (Source <a class="ae jd" href="http://neuralnetworksanddeeplearning.com/chap3.html" rel="noopener ugc nofollow" target="_blank">http://neuralnetworksanddeeplearning.com/</a>)</figcaption></figure><div class=""/><p id="4974" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是“<strong class="kf jh">初学者深度学习编码</strong>”系列的第 4 篇文章。在这里，你可以在第一篇文章  <em class="lb">的底部找到所有文章</em>、<em class="lb">议程的<em class="lb">链接，以及关于下一篇文章</em> <a class="ae jd" href="https://medium.com/@krzyk.kamil/coding-deep-learning-for-beginners-start-a84da8cb5044" rel="noopener"> <em class="lb">预计发布日期的一般信息。</em>它们也可以在我的</a><a class="ae jd" href="https://github.com/FisherKK/F1sherKK-MyRoadToAI" rel="noopener ugc nofollow" target="_blank">开源文件夹— <strong class="kf jh"> MyRoadToAI </strong> </a>中找到，还有一些迷你项目、演示、教程和链接。</em></p><p id="a310" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你也可以<a class="ae jd" href="https://kamilkrzyk.com/article/coding_deep_learning_series/2018/08/08/coding-deep-learning-for-begginers-linear-regression-cost-function" rel="noopener ugc nofollow" target="_blank">在我的个人网站</a>上阅读这篇文章，为了提高可读性(支持代码语法高亮、LaTeX 方程式等等)，我的个人网站由<a class="ae jd" href="https://jekyllrb.com/" rel="noopener ugc nofollow" target="_blank"> Jekyll </a>主办。</p><h1 id="729f" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">概述</h1><p id="a926" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">上一篇文章介绍了线性回归实施完成后将要解决的问题。目标是预测克拉科夫公寓的价格。数据集由三个特征描述的样本组成:<strong class="kf jh">到城市中心的距离</strong>、<strong class="kf jh">房间</strong>和<strong class="kf jh">大小</strong>。为了简化可视化并提高学习效率，将只使用尺寸特征。</p><p id="0757" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，给出并解释了线性回归模型背后的数学公式。为了使方程完整，它的参数需要有指定的值。然后，该公式准备好返回任何给定输入样本的数值预测。</p><p id="d325" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里描述的两个步骤称为<strong class="kf jh">初始化</strong>和<strong class="kf jh">预测</strong>。两者都被<strong class="kf jh">转化为独立的 Python 函数，并用于创建线性回归模型</strong>，其中所有参数都被初始化为零，并用于根据大小参数预测公寓价格。</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/ca2196e0d8b58a91c7b12f79ac604e56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*mjAJg9YZGVh3b7-sorXHsg.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Code used to prepare the graph is available under this <a class="ae jd" href="https://gist.github.com/FisherKK/942fa9aaaa95be04f75a316a5824343c" rel="noopener ugc nofollow" target="_blank">link</a>.</figcaption></figure><h1 id="0ea4" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">下一个要解决的问题</h1><p id="c8b1" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">由于模型的所有权重和偏差都等于零，具有当前参数的模型将为面积参数的每个值返回零。现在让我们修改参数，看看模型的投影是如何变化的。</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mk"><img src="../Images/d620523a5aeaf473c99e4ad205de2529.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Ba62SxY84fIxF6U-FiZ-g.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Code used to prepare these graphs is available under this <a class="ae jd" href="https://gist.github.com/FisherKK/73eb3ff38fccc865b730ac74cb692b5a" rel="noopener ugc nofollow" target="_blank">link</a>.</figcaption></figure><p id="d673" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有两组参数会导致线性回归模型为每个大小要素值返回不同的公寓价格。由于数据具有线性模式，在适当校准参数后，模型可以成为价格的精确近似值。</p><h2 id="5ace" class="ml ld jg bd le mm mn dn li mo mp dp lm ko mq mr lq ks ms mt lu kw mu mv ly mw bi translated">要回答的问题</h2><p id="f6c1" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">对于哪一组参数，模型返回更好的结果？</p><ul class=""><li id="7f30" class="mx my jg kf b kg kh kk kl ko mz ks na kw nb la nc nd ne nf bi translated">橙色:<code class="fe ng nh ni nj b">w = 3</code>，<code class="fe ng nh ni nj b">b = 200</code></li><li id="bd98" class="mx my jg kf b kg nk kk nl ko nm ks nn kw no la nc nd ne nf bi translated">石灰:<code class="fe ng nh ni nj b">w = 12</code>，<code class="fe ng nh ni nj b">b = -160</code></li></ul><p id="09ce" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">即使有可能通过视觉判断正确猜出答案，<strong class="kf jh">计算机也不会想象——它会比较这些值</strong>。这就是成本函数的用处。</p></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><h1 id="5861" class="lc ld jg bd le lf nw lh li lj nx ll lm ln ny lp lq lr nz lt lu lv oa lx ly lz bi translated">价值函数</h1><p id="b6d8" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">这是一个函数，<strong class="kf jh">测量机器学习模型</strong>对于给定数据的性能。成本函数量化了预测值和期望值之间的误差，并且<strong class="kf jh">以单个实数</strong>的形式呈现。根据问题的不同，成本函数可以用许多不同的方法来构成。成本函数的目的是:</p><ul class=""><li id="1da1" class="mx my jg kf b kg kh kk kl ko mz ks na kw nb la nc nd ne nf bi translated"><strong class="kf jh">最小化</strong>——那么返回值通常称为<strong class="kf jh">成本</strong>、<strong class="kf jh">损失</strong>或<strong class="kf jh">错误</strong>。目标是找到成本函数返回尽可能少的模型参数值。</li><li id="2520" class="mx my jg kf b kg nk kk nl ko nm ks nn kw no la nc nd ne nf bi translated"><strong class="kf jh">最大化</strong>——然后它产生的价值被命名为<strong class="kf jh">奖励</strong>。目标是找到返回数尽可能大的模型参数值。</li></ul><p id="f63f" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">对于依赖梯度下降优化模型参数的算法，每个函数都必须是可微分的。</strong></p><h1 id="ceb6" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">剪裁成本函数</h1><p id="cb20" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">给定一个使用以下公式的模型:</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/8e15c26d98c8a9570adda087437c274d.png" data-original-src="https://miro.medium.com/v2/resize:fit:144/format:webp/1*yR6IbZa9gCfiQG58E7nA1Q.png"/></div></figure><p id="130f" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中:</p><ul class=""><li id="9df1" class="mx my jg kf b kg kh kk kl ko mz ks na kw nb la nc nd ne nf bi translated">ŷ -预测值，</li><li id="1acd" class="mx my jg kf b kg nk kk nl ko nm ks nn kw no la nc nd ne nf bi translated">用于预测或训练的数据的 x 向量，</li><li id="6aba" class="mx my jg kf b kg nk kk nl ko nm ks nn kw no la nc nd ne nf bi translated">重量级。</li></ul><p id="e2c9" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">注意<em class="lb">偏置参数被故意省略</em>。让我们试着找出权重参数的值，所以对于下面的数据样本:</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi oc"><img src="../Images/bf538b05819623bf13f6f9ec0b3fe47f.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*1ul5Qj5VdvzjGnEd7s3VAg.png"/></div></figure><p id="8f3c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">模型的输出尽可能接近:</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi od"><img src="../Images/1f14646558a893388c0be98cfb86afc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*tpV8a-jbnKVKIISx-hzI6w.png"/></div></figure><p id="b09f" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在是时候为权重参数分配一个随机值，并可视化模型的结果。让我们暂时选择<code class="fe ng nh ni nj b">w = 5.0</code>。</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/6ed56472453bfc85d66073e5bd0b98b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*aYjrye1-wgLiH2hNYz87yg.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Code used to prepare the graph is available under this <a class="ae jd" href="https://gist.github.com/FisherKK/86f400f6d88facbf5375286db7029ca2" rel="noopener ugc nofollow" target="_blank">link</a>.</figcaption></figure><p id="f98d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以观察到模型预测与预期值不同。怎么用数学表达？最直接的方法是将两个值相减，看运算结果是否等于零。任何其他结果都意味着值不同。<strong class="kf jh">接收数字的大小提供了关于</strong>错误有多严重的信息。从几何角度来看，可以说<strong class="kf jh">误差是坐标系</strong>中两点之间的距离。让我们将距离定义为:</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi of"><img src="../Images/479b65c79f59ea38827347c445c9e0d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:332/format:webp/1*H0g8syS5kQUGHkGIfxizng.png"/></div></figure><p id="da35" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据公式，计算预测值和期望值之间的误差:</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi og"><img src="../Images/10956f966236d485d3c05ef4e65b9b2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:310/format:webp/1*Z4NmpyEbxKKWkEPvlDdJpQ.png"/></div></figure><p id="e610" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如前所述，成本函数是描述模型性能的单一数字。因此，让我们总结错误。</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/e29b2febfa2bab78c2d1ba863258037a.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*-dY6DuvUKFfhjrPaHwQrqw.png"/></div></figure><p id="6a77" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">然而，现在想象有一百万个点而不是四个。对于在较大数据集上进行预测的模型来说，累积误差会比在较小数据集上进行预测的模型大。因此，这些模型无法进行比较。这就是为什么它必须以某种方式缩放。正确的想法是<strong class="kf jh">将累积误差除以点数</strong>。这样陈述成本是模型对给定数据集产生的误差的平均值。</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oi"><img src="../Images/8a8b94484288108f2dcb26d0a44bf10b.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*pmPfnUGVYOMranuuOS4faw.png"/></div></div></figure><p id="38cc" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不幸的是，这个公式还没有完成。在此之前，<strong class="kf jh">所有情况都必须考虑</strong>，所以现在让我们尝试选择较小的权重，看看创建的成本函数是否有效。现在，权重即将被设置为<code class="fe ng nh ni nj b">w = 0.5</code>。</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/872b7b7473444d4079fb90c6402f3146.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*CIa-faf3AmTwjIby1FQNsQ.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Code used to prepare the graph is available under this <a class="ae jd" href="https://gist.github.com/FisherKK/15eb3f36444fb3dd4ed64c21ab300bfc" rel="noopener ugc nofollow" target="_blank">link</a>.</figcaption></figure><p id="8734" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">预测又一次落空了。然而，与前一种情况相比，不同之处在于预测点低于预期点。数字上的预测更小。成本公式将出现故障，因为计算出的距离为负值。</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/46ad3daec39963faaa7424cce2fbc169.png" data-original-src="https://miro.medium.com/v2/resize:fit:394/format:webp/1*W32nyKK_9SOUrwu0coociA.png"/></div></figure><p id="2e31" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">成本值也是负的:</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ol"><img src="../Images/fb111ea7b928de9a5fa4b174f4fb0aac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*flNlLYOhp_gBWyurSQuUnQ.png"/></div></div></figure><p id="f49c" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">说距离可以有负值是不正确的。可以对高于或低于预期结果的预测附加更大的惩罚(一些成本函数就是这样做的，例如 RMSE)，但<strong class="kf jh">值不应为负，因为它会抵消正误差</strong>。那么将不可能适当地最小化或最大化成本函数。</p><p id="f12a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那么用距离的绝对值来修正问题怎么样？在将距离表示为:</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi om"><img src="../Images/4a11b52b3993d301e5238b2065a8dc77.png" data-original-src="https://miro.medium.com/v2/resize:fit:354/format:webp/1*rDI80s9exPrEFN489rgiPA.png"/></div></figure><p id="a4df" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每个重量值的成本为:</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi on"><img src="../Images/53ce8571b104c4743fd85954fb1af766.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*otJXYZrRbGn6-SsAu6L7eA.png"/></div></figure><p id="926f" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，权重<code class="fe ng nh ni nj b">w = 5.0</code>和<code class="fe ng nh ni nj b">w = 0.5</code>的成本都计算正确了。可以比较这些参数。成本值越小，模型对<code class="fe ng nh ni nj b">w = 0.5</code>的效果越好。</p><p id="a0a5" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">创建的函数称为<a class="ae jd" href="https://en.wikipedia.org/wiki/Mean_absolute_error" rel="noopener ugc nofollow" target="_blank"> <strong class="kf jh">平均绝对误差</strong> </a> <strong class="kf jh">。</strong></p><h1 id="2b66" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">绝对平均误差</h1><p id="b8d5" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">测量一组预测中<strong class="kf jh">平均误差大小的回归度量，不考虑它们的方向。换句话说，它是预测和预期结果之间绝对差异的平均值，其中所有个体偏差都具有同等重要性</strong>。</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/140f8c557d51935105f6fe45d35ccd23.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/0*Swic0H6aelUyYI2B.png"/></div></figure><p id="906b" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中:</p><ul class=""><li id="953d" class="mx my jg kf b kg kh kk kl ko mz ks na kw nb la nc nd ne nf bi translated">i -样本索引，</li><li id="7863" class="mx my jg kf b kg nk kk nl ko nm ks nn kw no la nc nd ne nf bi translated">ŷ -预测值，</li><li id="0e97" class="mx my jg kf b kg nk kk nl ko nm ks nn kw no la nc nd ne nf bi translated">y -期望值，</li><li id="4048" class="mx my jg kf b kg nk kk nl ko nm ks nn kw no la nc nd ne nf bi translated">m -数据集中的样本数。</li></ul><p id="8650" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有时可能会看到预测值和期望值互换的公式形式，但工作原理是一样的。</p><p id="6d78" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们把数学变成代码:</p><figure class="mg mh mi mj gt is"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="b01a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该函数将两个相同大小的数组作为输入:<code class="fe ng nh ni nj b">predictions</code>和<code class="fe ng nh ni nj b">targets</code>。公式的参数<code class="fe ng nh ni nj b">m</code>是样本数，等于发送数组的长度。由于数组具有相同的长度，因此可以同时迭代两个数组。计算每个<code class="fe ng nh ni nj b">prediction</code>和<code class="fe ng nh ni nj b">target</code>之间的差值的绝对值，并加到<code class="fe ng nh ni nj b">accumulated_error</code>变量上。在收集了所有对的误差后，累加的结果由参数<code class="fe ng nh ni nj b">m</code>平均，该参数返回给定数据的平均误差。</p><h1 id="437c" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">均方误差</h1><p id="1f6e" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">最常用和最先解释的<strong class="kf jh">回归指标之一</strong>。<strong class="kf jh">预测和预期结果之间的均方差。</strong>换句话说，MAE 的一种变化，其中不是取差值的绝对值，而是取它们的平方。</p><p id="d5c3" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在 MAE 中，部分误差值等于坐标系中点之间的距离。<strong class="kf jh">关于 MSE，每个部分误差相当于由测量点之间的几何距离产生的正方形的面积。</strong>所有区域面积相加并平均。</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi or"><img src="../Images/aed2cbd82a03052653d775e6542ea780.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*iuffLsSzJK7-ZBa8K95p9A.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Code used to prepare the graph is available under this <a class="ae jd" href="https://gist.github.com/FisherKK/fcd05b0eb3a3d12a680f03c68c5fdb40" rel="noopener ugc nofollow" target="_blank">link</a>.</figcaption></figure><p id="c7eb" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">MSE 公式可以写成这样:</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi os"><img src="../Images/95a48e0e8b19d0bea2e9e6b69038aca5.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/0*v5NxDJHE8Oy8Rf-2.png"/></div></figure><ul class=""><li id="b17f" class="mx my jg kf b kg kh kk kl ko mz ks na kw nb la nc nd ne nf bi translated">i -样本索引，</li><li id="2662" class="mx my jg kf b kg nk kk nl ko nm ks nn kw no la nc nd ne nf bi translated">ŷ -预测值，</li><li id="aff8" class="mx my jg kf b kg nk kk nl ko nm ks nn kw no la nc nd ne nf bi translated">y -期望值，</li><li id="eba7" class="mx my jg kf b kg nk kk nl ko nm ks nn kw no la nc nd ne nf bi translated">m -数据集中的样本数。</li></ul><p id="2ff2" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">MSE 公式有不同的形式，其中分母中没有除以 2。它的存在让 MSE 推导演算更干净。</p><p id="0a7e" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用绝对值计算方程的导数是有问题的。MSE 代之以使用指数运算，因此具有良好的数学性质，这使得与 MAE 相比其导数的计算更容易。当使用依赖于梯度下降算法的模型时，它是相关的。</p><p id="d1c0" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">MSE 可以用 Python 编写如下:</p><figure class="mg mh mi mj gt is"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="bd60" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">与上一段中介绍的<code class="fe ng nh ni nj b">mae(predictions, targets)</code>功能的唯一区别是:</p><ul class=""><li id="849d" class="mx my jg kf b kg kh kk kl ko mz ks na kw nb la nc nd ne nf bi translated"><code class="fe ng nh ni nj b">prediction</code>和<code class="fe ng nh ni nj b">target</code>之差的平方，</li><li id="5072" class="mx my jg kf b kg nk kk nl ko nm ks nn kw no la nc nd ne nf bi translated"><code class="fe ng nh ni nj b">2</code>在求平均分母中。</li></ul><h1 id="7e90" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">MAE 和 MSE 的区别</h1><p id="0a40" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">有更多的回归度量可以用作成本函数，用于测量试图解决回归问题的模型的性能(估计值)。MAE 和 MSE 看起来比较简单，很受欢迎。</p><h2 id="4342" class="ml ld jg bd le mm mn dn li mo mp dp lm ko mq mr lq ks ms mt lu kw mu mv ly mw bi translated">为什么有这么多指标？</h2><p id="5366" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">每个指标都以独特的方式处理观察结果和预期结果之间的差异。<strong class="kf jh">例如，不同的指标，如 RMSE，对低于预期值的预测比高于预期值的预测惩罚力度更大。它的使用可能会导致创建一个返回夸大估计值的模型。</strong></p><p id="1cbc" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">MAE 和 MSE 是如何对待这两点之间的差异的？为了验证这一点，我们来计算不同重量值的成本:</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ot"><img src="../Images/900b099cb1c4be5728f32afcbbb6cf0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EbV2VrPiKSG2NVw2cF7xAQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Table presents the errors of many models created with different weight parameter. Cost of each model was calculated with both MAE and MSE metrics.</figcaption></figure><p id="18e9" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">并显示在图表上:</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ou"><img src="../Images/56cd7f5725a5251f3d1c43d7c38c6f55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_CqqBEbpdnb0MIqS3kMTEQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">The graphs show how metric value change for different values of parameter w. Code used to prepare these graphs is available under this <a class="ae jd" href="https://gist.github.com/FisherKK/ca707f8af758917dd38bc978aab37169" rel="noopener ugc nofollow" target="_blank">link</a>.</figcaption></figure><p id="ab0d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以观察到:</p><ul class=""><li id="4809" class="mx my jg kf b kg kh kk kl ko mz ks na kw nb la nc nd ne nf bi translated">MAE 不会给点与点之间的距离增加任何额外的权重——误差增长是线性的。</li><li id="6b17" class="mx my jg kf b kg nk kk nl ko nm ks nn kw no la nc nd ne nf bi translated">MSE <strong class="kf jh">误差随着距离</strong>值的增大呈指数增长。这是一个度量标准，即<strong class="kf jh">对远离的点增加一个巨大的惩罚，而对接近</strong>预期结果的点增加一个最小的惩罚。误差曲线具有抛物线形状。</li></ul><p id="e55a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">此外，通过检查各种重量值，有可能发现误差等于零的参数。如果使用<code class="fe ng nh ni nj b">w = 2.0</code>来构建模型，那么预测看起来如下:</p><figure class="mg mh mi mj gt is gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/40bdacd82b8bb60cf5a90f8f3e29fa2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*gu9a_UBmG2-mW5qCXWAsZw.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Code used to prepare the graph is available under this <a class="ae jd" href="https://gist.github.com/FisherKK/ece7aa7a6d15a04e2d07293c45c1bd84" rel="noopener ugc nofollow" target="_blank">link</a>.</figcaption></figure><p id="8781" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">当预测和预期结果重叠</strong>时，则每个合理的<strong class="kf jh">成本函数值等于零</strong>。</p><h1 id="8663" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">回答</strong></h1><p id="5350" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">是时候回答这样一个问题了，哪一组参数，<strong class="kf jh">橙</strong>和<strong class="kf jh">石灰</strong>能更好地估计克拉科夫公寓的价格。让我们<strong class="kf jh">用 MSE 来计算两个模型</strong>的误差，看看哪个更低。</p><figure class="mg mh mi mj gt is"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="e6e6" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在前一篇文章中解释了大部分代码。不是调用<code class="fe ng nh ni nj b">init(n)</code>函数，而是手动创建参数字典用于测试目的。注意，这一次两个模型都使用了偏差。函数<code class="fe ng nh ni nj b">predict(x, parameters)</code>用于不同<code class="fe ng nh ni nj b">parameters</code>参数的相同数据。然后名为<code class="fe ng nh ni nj b">orange_pred</code>和<code class="fe ng nh ni nj b">lime_pred</code>的结果预测成为<code class="fe ng nh ni nj b">mse(predictions, targets)</code>函数的参数，该函数分别返回每个模型的误差值。</p><p id="58a0" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">结果如下:</p><ul class=""><li id="f8d5" class="mx my jg kf b kg kh kk kl ko mz ks na kw nb la nc nd ne nf bi translated">橙色:<strong class="kf jh"> 4909.18 </strong></li><li id="b0a4" class="mx my jg kf b kg nk kk nl ko nm ks nn kw no la nc nd ne nf bi translated">石灰:<strong class="kf jh"> 10409.77 </strong></li></ul><p id="6ab3" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这意味着<strong class="kf jh"> orange parameters 以更小的成本创造了更好的模型</strong>。</p></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><h1 id="cd91" class="lc ld jg bd le lf nw lh li lj nx ll lm ln ny lp lq lr nz lt lu lv oa lx ly lz bi translated">摘要</h1><p id="8cfb" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">在本文中，我解释了成本函数的概念——一种允许我们评估模型参数的工具。我已经向您介绍了两个最常用的回归度量 MAE 和 MSE。</p><p id="196d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下一篇文章中，我将向您展示如何使用梯度下降算法来训练模型参数。</p><h1 id="a996" class="lc ld jg bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">下一篇文章</h1><p id="1600" class="pw-post-body-paragraph kd ke jg kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">下一篇文章可从<a class="ae jd" rel="noopener" target="_blank" href="/coding-deep-learning-for-beginners-linear-regression-gradient-descent-fcd5e0fc077d">这里</a>获得。</p></div></div>    
</body>
</html>