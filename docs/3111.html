<html>
<head>
<title>UNDERSTANDING RESIDUAL NETWORKS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解剩余网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-residual-networks-9add4b664b03?source=collection_archive---------1-----------------------#2018-04-10">https://towardsdatascience.com/understanding-residual-networks-9add4b664b03?source=collection_archive---------1-----------------------#2018-04-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/919e90e939119cbf6ad9de1d6fe0e06c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KSh0801FsHBWOhwmPDaacw.png"/></div></div></figure><p id="740f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于大型数据集和强大的 GPU 的可用性，图像识别近年来取得了进展，这使得非常深入的架构训练成为可能。Simonyan 等人,《VGG》的作者证明了通过简单地堆叠更多的层，我们可以提高精确度，在此之前，Yoshua Bengio 在他的专著《学习人工智能的深度架构》中对深度架构的有效性进行了令人信服的理论分析。<br/>在以前的帖子中，我演示了如何将各种技术应用于卷积神经网络，包括批量标准化、丢弃和数据扩充。通过简单地叠加越来越多的卷积-批量归一化-relu 层，能建立更精确的系统吗？在某种程度上，精确度会提高，但是超过大约 25+层，精确度会下降。<br/>明凯等人<!-- --> 2015 <!-- -->首次演示了深度问题，并提出了一个卓越的解决方案，此后允许训练超过<!-- --> 2000 <!-- -->层！越来越准确。在这篇文章中，我将解释他们的技术以及如何应用。<br/>首先，由于渐变消失，许多层的精度下降，随着层深入，渐变变小，导致性能变差。这与过度拟合无关，因此，辍学者无法挽救它。微软亚洲研究院的何和他的同事设计的最终解决方案是引入剩余连接。这只是描述将先前层的输出连接到新层的输出的简单术语。<br/>假设您有一个七层网络。在残差设置中，不仅要将第 1 层的输出传递到第 2 层，还要将第 1 层的输出加到第 2 层的输出上。<br/>在标准网络中用<strong class="ka ir"><em class="kw">【f(x)</em></strong><em class="kw"/><br/>表示每一层<strong class="ka ir"> <em class="kw"> y = f(x) </em> </strong> <br/>然而，在残差网络中，<br/><strong class="ka ir"><em class="kw">y = f(x)+x</em></strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi kx"><img src="../Images/99b5d9dc3a65149de6816233821c0208.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y4c9Kdborja2QPU3V2dlSg.png"/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk">Typical Structure of A Resnet Module</figcaption></figure><p id="c958" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">应用这一原理，作者赢得了 Imagenet <!-- --> 2015 <!-- -->，并在所有标准计算机视觉基准测试中取得了新的最先进的结果。这个想法后来被扩展到深度学习的所有其他领域，包括语音和自然语言处理。</p><p id="0953" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">基础数学讲够了，让我们用代码来弄脏我们的手。</p><p id="2ec5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">标准的两层模块如下</p><pre class="ky kz la lb gt lg lh li lj aw lk bi"><span id="923f" class="ll lm iq lh b gy ln lo l lp lq"><strong class="lh ir">def </strong>Unit(x,filters):<br/><br/>    out = BatchNormalization()(x)<br/>    out = Activation(<strong class="lh ir">"relu"</strong>)(out)<br/>    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=<strong class="lh ir">"same"</strong>)(out)<br/><br/>    out = BatchNormalization()(out)<br/>    out = Activation(<strong class="lh ir">"relu"</strong>)(out)<br/>    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=<strong class="lh ir">"same"</strong>)(out)<br/><br/>    <strong class="lh ir">return </strong>out<br/> </span></pre><p id="7e4a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">概括地说，在这个模块中，我们传入一个输入 x，对它进行批处理规范化— relu- conv2d，然后输出通过同一个堆栈。</p><p id="b757" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下面是一个 resnet 模块</p><pre class="ky kz la lb gt lg lh li lj aw lk bi"><span id="f497" class="ll lm iq lh b gy ln lo l lp lq"><strong class="lh ir">def </strong>Unit(x,filters):<br/>    res = x<br/>    out = BatchNormalization()(x)<br/>    out = Activation(<strong class="lh ir">"relu"</strong>)(out)<br/>    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=<strong class="lh ir">"same"</strong>)(out)<br/><br/>    out = BatchNormalization()(out)<br/>    out = Activation(<strong class="lh ir">"relu"</strong>)(out)<br/>    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=<strong class="lh ir">"same"</strong>)(out)<br/><br/>    out = keras.layers.add([res,out])<br/><br/>    <strong class="lh ir">return </strong>out</span></pre><p id="6cca" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这看起来非常相似，但有一个主要区别，首先，我们存储一个对原始输入的引用“res ”,在通过 batchnorm-relu-conv 层后，我们将输出添加到残差中，为了清楚起见，这是在该行中完成的</p><pre class="ky kz la lb gt lg lh li lj aw lk bi"><span id="13d6" class="ll lm iq lh b gy ln lo l lp lq">out = keras.layers.add([res,out])</span></pre><p id="ccbe" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这部分对应方程<strong class="ka ir"> <em class="kw"> y = f(x) + x </em> </strong></p><p id="c7ce" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，我们可以通过将许多模块堆叠在一起来构建一个 resnet。</p><p id="8f57" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在此之前，我们需要稍微修改一下代码来考虑池。</p><pre class="ky kz la lb gt lg lh li lj aw lk bi"><span id="9545" class="ll lm iq lh b gy ln lo l lp lq"><strong class="lh ir">def </strong>Unit(x,filters,pool=<strong class="lh ir">False</strong>):<br/>    res = x<br/>    <strong class="lh ir">if </strong>pool:<br/>        x = MaxPooling2D(pool_size=(2, 2))(x)<br/>        res = Conv2D(filters=filters,kernel_size=[1,1],strides=(2,2),padding=<strong class="lh ir">"same"</strong>)(res)<br/>    out = BatchNormalization()(x)<br/>    out = Activation(<strong class="lh ir">"relu"</strong>)(out)<br/>    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=<strong class="lh ir">"same"</strong>)(out)<br/><br/>    out = BatchNormalization()(out)<br/>    out = Activation(<strong class="lh ir">"relu"</strong>)(out)<br/>    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=<strong class="lh ir">"same"</strong>)(out)<br/><br/>    out = keras.layers.add([res,out])<br/><br/>    <strong class="lh ir">return </strong>out</span></pre><p id="5498" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">请注意上面的一些内容，当我们合并时，我们输出的维数将不再匹配我们残差的维数，因此，我们不仅将合并应用于输入，而且残差也将通过步长为 1×1 的 conv 变换，该变换将滤波器投影为与输出相同，并且步长为 2 将是维数的一半，就像最大合并一样。</p><p id="6d2d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">解释完之后，我现在将给出完整的答案。</p><pre class="ky kz la lb gt lg lh li lj aw lk bi"><span id="37ad" class="ll lm iq lh b gy ln lo l lp lq"><strong class="lh ir">def </strong>Unit(x,filters,pool=<strong class="lh ir">False</strong>):<br/>    res = x<br/>    <strong class="lh ir">if </strong>pool:<br/>        x = MaxPooling2D(pool_size=(2, 2))(x)<br/>        res = Conv2D(filters=filters,kernel_size=[1,1],strides=(2,2),padding=<strong class="lh ir">"same"</strong>)(res)<br/>    out = BatchNormalization()(x)<br/>    out = Activation(<strong class="lh ir">"relu"</strong>)(out)<br/>    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=<strong class="lh ir">"same"</strong>)(out)<br/><br/>    out = BatchNormalization()(out)<br/>    out = Activation(<strong class="lh ir">"relu"</strong>)(out)<br/>    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=<strong class="lh ir">"same"</strong>)(out)<br/><br/>    out = keras.layers.add([res,out])<br/><br/>    <strong class="lh ir">return </strong>out</span><span id="6e95" class="ll lm iq lh b gy lr lo l lp lq"><strong class="lh ir">def </strong>MiniModel(input_shape):<br/>    images = Input(input_shape)<br/>    net = Conv2D(filters=32, kernel_size=[3, 3], strides=[1, 1], padding=<strong class="lh ir">"same"</strong>)(images)<br/>    net = Unit(net,32)<br/>    net = Unit(net,32)<br/>    net = Unit(net,32)<br/><br/>    net = Unit(net,64,pool=<strong class="lh ir">True</strong>)<br/>    net = Unit(net,64)<br/>    net = Unit(net,64)<br/><br/>    net = Unit(net,128,pool=<strong class="lh ir">True</strong>)<br/>    net = Unit(net,128)<br/>    net = Unit(net,128)<br/><br/>    net = Unit(net, 256,pool=<strong class="lh ir">True</strong>)<br/>    net = Unit(net, 256)<br/>    net = Unit(net, 256)<br/><br/>    net = BatchNormalization()(net)<br/>    net = Activation(<strong class="lh ir">"relu"</strong>)(net)<br/>    net = Dropout(0.25)(net)<br/><br/>    net = AveragePooling2D(pool_size=(4,4))(net)<br/>    net = Flatten()(net)<br/>    net = Dense(units=10,activation=<strong class="lh ir">"softmax"</strong>)(net)<br/><br/>    model = Model(inputs=images,outputs=net)<br/><br/>    <strong class="lh ir">return </strong>model</span></pre><p id="ebf0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这不包括训练代码，你可以看到，下面是训练代码，纪元设置为 50 个纪元。</p><p id="31af" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你可以用<a class="ae ls" href="https://colab.research.google.com" rel="noopener ugc nofollow" target="_blank">谷歌实验室</a>在 GPU 上免费运行这个</p><pre class="ky kz la lb gt lg lh li lj aw lk bi"><span id="6566" class="ll lm iq lh b gy ln lo l lp lq"><em class="kw">#import needed classes<br/></em><strong class="lh ir">import </strong>keras<br/><strong class="lh ir">from </strong>keras.datasets <strong class="lh ir">import </strong>cifar10<br/><strong class="lh ir">from </strong>keras.layers <strong class="lh ir">import </strong>Dense,Conv2D,MaxPooling2D,Flatten,AveragePooling2D,Dropout,BatchNormalization,Activation<br/><strong class="lh ir">from </strong>keras.models <strong class="lh ir">import </strong>Model,Input<br/><strong class="lh ir">from </strong>keras.optimizers <strong class="lh ir">import </strong>Adam<br/><strong class="lh ir">from </strong>keras.callbacks <strong class="lh ir">import </strong>LearningRateScheduler<br/><strong class="lh ir">from </strong>keras.callbacks <strong class="lh ir">import </strong>ModelCheckpoint<br/><strong class="lh ir">from </strong>math <strong class="lh ir">import </strong>ceil<br/><strong class="lh ir">import </strong>os<br/><strong class="lh ir">from </strong>keras.preprocessing.image <strong class="lh ir">import </strong>ImageDataGenerator<br/><br/><br/><strong class="lh ir">def </strong>Unit(x,filters,pool=<strong class="lh ir">False</strong>):<br/>    res = x<br/>    <strong class="lh ir">if </strong>pool:<br/>        x = MaxPooling2D(pool_size=(2, 2))(x)<br/>        res = Conv2D(filters=filters,kernel_size=[1,1],strides=(2,2),padding=<strong class="lh ir">"same"</strong>)(res)<br/>    out = BatchNormalization()(x)<br/>    out = Activation(<strong class="lh ir">"relu"</strong>)(out)<br/>    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=<strong class="lh ir">"same"</strong>)(out)<br/><br/>    out = BatchNormalization()(out)<br/>    out = Activation(<strong class="lh ir">"relu"</strong>)(out)<br/>    out = Conv2D(filters=filters, kernel_size=[3, 3], strides=[1, 1], padding=<strong class="lh ir">"same"</strong>)(out)<br/><br/>    out = keras.layers.add([res,out])<br/><br/>    <strong class="lh ir">return </strong>out<br/><br/><em class="kw">#Define the model<br/><br/><br/></em><strong class="lh ir">def </strong>MiniModel(input_shape):<br/>    images = Input(input_shape)<br/>    net = Conv2D(filters=32, kernel_size=[3, 3], strides=[1, 1], padding=<strong class="lh ir">"same"</strong>)(images)<br/>    net = Unit(net,32)<br/>    net = Unit(net,32)<br/>    net = Unit(net,32)<br/><br/>    net = Unit(net,64,pool=<strong class="lh ir">True</strong>)<br/>    net = Unit(net,64)<br/>    net = Unit(net,64)<br/><br/>    net = Unit(net,128,pool=<strong class="lh ir">True</strong>)<br/>    net = Unit(net,128)<br/>    net = Unit(net,128)<br/><br/>    net = Unit(net, 256,pool=<strong class="lh ir">True</strong>)<br/>    net = Unit(net, 256)<br/>    net = Unit(net, 256)<br/><br/>    net = BatchNormalization()(net)<br/>    net = Activation(<strong class="lh ir">"relu"</strong>)(net)<br/>    net = Dropout(0.25)(net)<br/><br/>    net = AveragePooling2D(pool_size=(4,4))(net)<br/>    net = Flatten()(net)<br/>    net = Dense(units=10,activation=<strong class="lh ir">"softmax"</strong>)(net)<br/><br/>    model = Model(inputs=images,outputs=net)<br/><br/>    <strong class="lh ir">return </strong>model<br/><br/><em class="kw">#load the cifar10 dataset<br/></em>(train_x, train_y) , (test_x, test_y) = cifar10.load_data()<br/><br/><em class="kw">#normalize the data<br/></em>train_x = train_x.astype(<strong class="lh ir">'float32'</strong>) / 255<br/>test_x = test_x.astype(<strong class="lh ir">'float32'</strong>) / 255<br/><br/><em class="kw">#Subtract the mean image from both train and test set<br/></em>train_x = train_x - train_x.mean()<br/>test_x = test_x - test_x.mean()<br/><br/><em class="kw">#Divide by the standard deviation<br/></em>train_x = train_x / train_x.std(axis=0)<br/>test_x = test_x / test_x.std(axis=0)<br/><br/><br/>datagen = ImageDataGenerator(rotation_range=10,<br/>                             width_shift_range=5. / 32,<br/>                             height_shift_range=5. / 32,<br/>                             horizontal_flip=<strong class="lh ir">True</strong>)<br/><br/><em class="kw"># Compute quantities required for featurewise normalization<br/># (std, mean, and principal components if ZCA whitening is applied).<br/></em>datagen.fit(train_x)<br/><br/><br/><br/><em class="kw">#Encode the labels to vectors<br/></em>train_y = keras.utils.to_categorical(train_y,10)<br/>test_y = keras.utils.to_categorical(test_y,10)<br/><br/><em class="kw">#define a common unit<br/><br/><br/></em>input_shape = (32,32,3)<br/>model = MiniModel(input_shape)<br/><br/><em class="kw">#Print a Summary of the model<br/><br/></em>model.summary()<br/><em class="kw">#Specify the training components<br/></em>model.compile(optimizer=Adam(0.001),loss=<strong class="lh ir">"categorical_crossentropy"</strong>,metrics=[<strong class="lh ir">"accuracy"</strong>])<br/><br/><br/><br/>epochs = 50<br/>steps_per_epoch = ceil(50000/128)<br/><br/><em class="kw"># Fit the model on the batches generated by datagen.flow().<br/></em>model.fit_generator(datagen.flow(train_x, train_y, batch_size=128),<br/>                    validation_data=[test_x,test_y],<br/>                    epochs=epochs,steps_per_epoch=steps_per_epoch, verbose=1, workers=4)<br/><br/><br/><em class="kw">#Evaluate the accuracy of the test dataset<br/></em>accuracy = model.evaluate(x=test_x,y=test_y,batch_size=128)<br/>model.save(<strong class="lh ir">"cifar10model.h5"</strong>)</span></pre><p id="b500" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">希望你喜欢这一点，未来的帖子将致力于通过宽度和深度轻松扩展剩余网络的方法，以及调整学习速度的方法。</p><p id="a850" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">玩得开心，别忘了留下一些掌声！</p><p id="dabc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你可以随时在推特上通过<a class="ae ls" href="https://twitter.com/johnolafenwa" rel="noopener ugc nofollow" target="_blank"> @johnolafenwa </a>联系我</p></div></div>    
</body>
</html>