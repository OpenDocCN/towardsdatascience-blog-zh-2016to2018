<html>
<head>
<title>A Beginner’s Guide to Neural Networks: Part One</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络初学者指南:第一部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-beginners-guide-to-neural-networks-b6be0d442fa4?source=collection_archive---------1-----------------------#2017-03-22">https://towardsdatascience.com/a-beginners-guide-to-neural-networks-b6be0d442fa4?source=collection_archive---------1-----------------------#2017-03-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="98c2" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">神经网络背后的动机，以及最基本的网络背后的架构:感知器。</h2></div></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><p id="3b97" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi li translated">人类是难以置信的模式识别机器。我们的大脑处理来自世界的“输入”,对它们进行分类(那是一只蜘蛛；那是冰淇淋)，然后生成一个‘输出’(逃离蜘蛛；品尝冰淇淋)。我们自动地、快速地做到这一点，不费吹灰之力。这和<em class="lr">感觉到</em>有人在生我们的气，或者在我们加速经过时不由自主地读出停车标志是同一个系统。心理学家将这种思维模式称为“系统1”(由Keith Stanovich和Richard West创造)，它包括我们与其他动物共有的先天技能，如感知和恐惧。(还有一个“系统2”，如果你想了解更多这方面的内容，可以看看丹尼尔·卡内曼的<a class="ae ls" href="https://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374533555" rel="noopener ugc nofollow" target="_blank"> <em class="lr">思考，快与慢</em></a>)。</p><p id="4c0b" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">那么这和神经网络有什么关系呢？我马上就到。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/aceff5742d74aa5d9db226b43e963f67.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*QwYAzEP8uBRF4Zk6Q4uPbg.png"/></div></figure><p id="c6a2" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">你毫不费力地认出了上面的数字，对吗？你刚刚<em class="lr">知道</em>第一个数字是5；你不必真的去想它。当然，你的大脑不会说，“啊，那看起来像两条正交的线连接着一个旋转的，没有根据的半圆，所以那是一个5。”设计识别手写数字的规则是不必要的复杂，这就是为什么历史上计算机程序很难识别它们。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="gh gi mb"><img src="../Images/95a63a2895855a6ee3217fbee716e511.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*DFPeFenZ2ZDzJpB9dsMYhw.gif"/></div></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk">Oh, Apple Newton. (Source: Gary Trudeau for Doonesbury)</figcaption></figure><p id="aee1" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">神经网络粗略地模拟了我们大脑解决问题的方式:接受输入，处理它们并生成输出。像我们一样，他们<em class="lr">学习</em>识别模式，但他们是通过<em class="lr">在标记数据集上训练</em>来做到这一点的。在我们进入学习部分之前，让我们看看最基本的人工神经元:感知机，以及它如何处理输入和产生输出。</p><h1 id="d1cb" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated">感知器</h1><p id="85e7" class="pw-post-body-paragraph km kn iq ko b kp nc jr kr ks nd ju ku kv ne kx ky kz nf lb lc ld ng lf lg lh ij bi translated">感知器是由科学家弗兰克·罗森布拉特在20世纪50-60年代开发的，他受到了沃伦·麦卡洛克和沃尔特·皮茨早期工作的启发。虽然今天我们使用人工神经元的其他模型，但它们遵循感知机设定的一般原则。</p><p id="ac65" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">那它们到底是什么？感知器接受几个二进制输入:<em class="lr"> x1，x2，…，</em>并产生一个二进制输出:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/f7873f8c271e4fe7245114643c2e2532.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*QExGFzBqS3u_rO12AIFH_g.png"/></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk">Perceptron with 3 inputs. (Source: <a class="ae ls" href="http://neuralnetworksanddeeplearning.com/chap1.html" rel="noopener ugc nofollow" target="_blank">Michael Nielsen</a>)</figcaption></figure><p id="5745" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">让我们用一个例子来更好地理解这一点。假设你骑自行车去上班。你有两个因素来做出你去上班的决定:天气一定不能坏，而且一定是工作日。天气没什么大不了的，但是周末工作是一个大禁忌。输入必须是二进制的，所以让我们把条件提议为是或否的问题。天气很好？1代表是，0代表否。今天是工作日吗？1是，0否。</p><p id="52bc" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">记住，我不能告诉神经网络这些条件；它必须自己去学习。它如何知道哪些信息对决策最重要？它与叫做<strong class="ko ir">的权重</strong>有关。记得我说过天气没什么大不了的，但周末才是？权重只是这些偏好的数字表示。较高的权重意味着神经网络认为该输入比其他输入更重要。</p><p id="5278" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">对于我们的示例，让我们特意为天气设置合适的权重2，为工作日设置合适的权重6。现在我们如何计算产量？我们简单地将输入与其各自的权重相乘，并对所有输入的所有值求和。例如，如果是一个晴朗的工作日，我们将进行如下计算:</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/eb91d05a3c15836a5929d3468378fc67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/1*78nQnb6zWC5UelDmL1Rugw.gif"/></div></figure><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/e774163ef172b1a6bee954c9fe042c21.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/1*aq8TnLcfwMes-e1cqwX2Rw.gif"/></div></figure><p id="218b" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">这种计算被称为<strong class="ko ir">线性组合</strong>。8是什么意思？我们首先需要定义<strong class="ko ir">阈值。</strong>如果线性组合的值大于阈值，则确定神经网络的输出，0或1(呆在家里或去工作)。假设阈值是5，这意味着如果计算得出的数字小于5，你可以呆在家里，但如果它等于或大于5，那么你就得去工作。</p><p id="a856" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">您已经看到了重量是如何影响产量的。在本例中，我将权重设置为特定的数字，以使示例正常工作，但实际上，我们将权重设置为随机值，然后网络根据使用之前的权重产生的输出误差来调整这些权重。这叫做<strong class="ko ir">训练</strong>神经网络。</p><figure class="lu lv lw lx gt ly gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/a9f37669149a24e799d1b6a51e02f284.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*LqQEd7iO2ECwEzW2vG0OBw.png"/></div><figcaption class="mg mh gj gh gi mi mj bd b be z dk">(Source: Panagiotis Peikidis. Based on <a class="ae ls" href="https://xkcd.com/303/" rel="noopener ugc nofollow" target="_blank">XKCD comic ‘Compiling’</a>)</figcaption></figure><p id="6793" class="pw-post-body-paragraph km kn iq ko b kp kq jr kr ks kt ju ku kv kw kx ky kz la lb lc ld le lf lg lh ij bi translated">回到手写数字识别问题，一个简单的单节点网络(如上图所示)无法做出如此复杂的决定。为了实现这一点，我们需要更复杂的网络，有更多的节点和<em class="lr">隐藏层</em>，使用诸如<em class="lr"> sigmoid激活函数</em>之类的技术来做出决策，并使用<em class="lr">反向传播</em>来学习。第二部中的一切！</p><h2 id="9c30" class="nl ml iq bd mm nm nn dn mq no np dp mu kv nq nr mw kz ns nt my ld nu nv na nw bi translated">接下来:</h2><div class="nx ny gp gr nz oa"><a href="https://medium.com/@nehaludyavar/a-beginners-guide-to-neural-networks-part-two-bd503514c71a" rel="noopener follow" target="_blank"><div class="ob ab fo"><div class="oc ab od cl cj oe"><h2 class="bd ir gy z fp of fr fs og fu fw ip bi translated">神经网络初学者指南:第二部分</h2><div class="oh l"><h3 class="bd b gy z fp of fr fs og fu fw dk translated">#2.偏置、激活函数、隐藏层以及构建更高级的前馈神经网络架构。</h3></div><div class="oi l"><p class="bd b dl z fp of fr fs og fu fw dk translated">medium.com</p></div></div><div class="oj l"><div class="ok l ol om on oj oo lz oa"/></div></div></a></div></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><h2 id="665b" class="nl ml iq bd mm nm nn dn mq no np dp mu kv nq nr mw kz ns nt my ld nu nv na nw bi translated">资源</h2><ol class=""><li id="feb1" class="op oq iq ko b kp nc ks nd kv or kz os ld ot lh ou ov ow ox bi translated"><a class="ae ls" href="http://neuralnetworksanddeeplearning.com/chap1.html" rel="noopener ugc nofollow" target="_blank"> <em class="lr">利用神经网络识别手写数字</em> </a> <em class="lr"> </em>迈克尔尼尔森(Michael Nielsen)著(同级更详细解释)。</li><li id="40a3" class="op oq iq ko b kp oy ks oz kv pa kz pb ld pc lh ou ov ow ox bi translated"><a class="ae ls" href="http://www.deeplearningbook.org/" rel="noopener ugc nofollow" target="_blank"> <em class="lr">深度学习书籍</em> </a>作者伊恩·古德菲勒、约舒阿·本吉奥和亚伦·库维尔(更高级的&amp;技术，假设本科水平的数学知识)。</li><li id="90d0" class="op oq iq ko b kp oy ks oz kv pa kz pb ld pc lh ou ov ow ox bi translated"><a class="ae ls" href="https://www.udacity.com/course/deep-learning-nanodegree-foundation--nd101" rel="noopener ugc nofollow" target="_blank"> <em class="lr"> Udacity深度学习纳米学位基础</em> </a> (17周项目化课程；难度在1的中间。第二。)</li><li id="f97f" class="op oq iq ko b kp oy ks oz kv pa kz pb ld pc lh ou ov ow ox bi translated"><a class="ae ls" href="http://playground.tensorflow.org" rel="noopener ugc nofollow" target="_blank"> <em class="lr"> TensorFlow神经网络游乐场</em> </a> <em class="lr"> </em>(有趣、互动的可视化神经网络在行动)</li></ol></div></div>    
</body>
</html>