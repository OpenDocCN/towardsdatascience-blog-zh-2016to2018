<html>
<head>
<title>node2vec: Embeddings for Graph Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">node2vec:图形数据的嵌入</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/node2vec-embeddings-for-graph-data-32a866340fef?source=collection_archive---------1-----------------------#2018-04-16">https://towardsdatascience.com/node2vec-embeddings-for-graph-data-32a866340fef?source=collection_archive---------1-----------------------#2018-04-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="538f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kl"> Hotlinks </em> </strong> : <br/>原文:<a class="ae km" href="https://arxiv.org/pdf/1607.00653.pdf" rel="noopener ugc nofollow" target="_blank"> node2vec:面向网络的可扩展特征学习，Aditya Grover和Jure Leskovec </a> <br/>算法实现—由我:<a class="ae km" href="https://github.com/eliorc/node2vec" rel="noopener ugc nofollow" target="_blank"> Github repo </a> — Python3 <br/>算法实现—由algo作者:<a class="ae km" href="https://github.com/aditya-grover/node2vec" rel="noopener ugc nofollow" target="_blank"> Github repo(由Aditya Grover)</a>—python 2<br/>Showcase代码:<a class="ae km" href="https://github.com/eliorc/Medium/blob/master/Nod2Vec-FIFA17-Example.ipynb" rel="noopener ugc nofollow" target="_blank"> https://github.com/eliorc</a></p></div><div class="ab cl kn ko hu kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="ij ik il im in"><h1 id="75d7" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">动机</h1><p id="0c20" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">嵌入…这个词每个数据科学家都听过，但大多是在NLP的上下文中。那么，我们为什么还要费心去嵌入东西呢？<br/>在我看来，创建质量嵌入并将其输入模型，与那句名言“垃圾进，垃圾出”正好相反。<br/>当你把低质量的数据输入到你的模型中时，你就把学习的全部负荷放在了你的模型上，因为它必须学习所有能从数据中得出的必要结论。<br/>相反，当您使用质量嵌入时，您已经在数据中加入了一些知识，从而使模型学习问题的任务变得更加容易。<br/>还有一点要思考的是<strong class="jp ir">信息</strong> vs <strong class="jp ir">领域知识</strong>。例如，让我们考虑单词嵌入(word2vec)和单词包表示。<br/>虽然两者都可以拥有关于哪些单词在句子中的全部<strong class="jp ir">信息</strong>，但是单词嵌入还包括<strong class="jp ir">领域知识</strong>比如单词之间的关系等等。<br/>在这篇文章中，我将谈论一种叫做<strong class="jp ir"> node2vec </strong>的技术，它旨在为图中的节点创建嵌入(在G(V，E，W)这个词的意义上)。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi lx"><img src="../Images/60b85bc21517a62422f23dc723f4c6ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YMmSeiS0kjfmU6nPAs3-gg.png"/></div></div></figure><p id="962a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我将解释<strong class="jp ir">它是如何工作的</strong>，最后提供我自己的<strong class="jp ir">Python 3的实现</strong>，还有一些额外的东西。</p><h1 id="fd2c" class="ku kv iq bd kw kx mj kz la lb mk ld le lf ml lh li lj mm ll lm ln mn lp lq lr bi translated">嵌入过程</h1><p id="37d3" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">那么是怎么做的呢？<br/>嵌入本身的学习方式与word2vec的嵌入学习方式相同——使用skip-gram模型。<br/>如果你熟悉word2vec skip-gram模型，很好，如果不熟悉，我推荐<a class="ae km" href="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/" rel="noopener ugc nofollow" target="_blank">这篇很棒的文章</a>，它详细解释了这个模型，从现在开始，我假设你对它很熟悉。</p><p id="5ad2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我能想到的解释node2vec的最自然的方式是解释node2vec如何生成“语料库”——如果我们理解word2vec，我们就已经知道如何嵌入语料库。</p><p id="86f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">那么我们如何从图中生成这个语料库呢？这正是node2vec的创新之处，它以一种智能的方式做到了这一点，这是使用<strong class="jp ir">采样策略</strong>完成的。</p><p id="b19d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了从输入图中生成我们的语料库，让我们把一个语料库看作一组有向无环图，最大出度为1。如果我们考虑一下，这是一个文本句子的完美表现，句子中的每个单词都是一个节点，它指向句子中的下一个单词。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/4fceb5f5760a3f127a601a67348eaefc.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/1*oEuJHzd3iPpord7sFR1AhQ.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Sentence in a graph representation</figcaption></figure><p id="6f36" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过这种方式，我们可以看到word2vec已经可以嵌入图形了，但是是非常特定类型的图形。<br/>然而，大多数图形并没有那么简单，它们可以是(不)定向的，(不)加权的，(循环的)并且在结构上基本上比文本复杂得多。</p><p id="ba62" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了解决这个问题，node2vec使用一个可调整的(通过超参数)采样策略来采样这些有向无环子图。这是通过从图的每个节点生成随机行走来完成的。很简单，对吧？</p><p id="9e5e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们深入研究采样策略如何使用超参数来生成这些子图之前，让我们来看一下这个过程:</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mt"><img src="../Images/e8bf4554812fddf9c6b6a1f5ca2eeb19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3pmstIOig4Qc3lrQS4xrNg.png"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Node2vec embedding process</figcaption></figure><h1 id="4f17" class="ku kv iq bd kw kx mj kz la lb mk ld le lf ml lh li lj mm ll lm ln mn lp lq lr bi translated">抽样策略</h1><p id="0e02" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">现在我们已经有了大致的了解，是时候深入了解了。<br/> Node2vec的采样策略，接受4个参数:<br/> — <strong class="jp ir">步数</strong>:从图中的每个节点生成的随机步数<br/> — <strong class="jp ir">步长</strong>:每次随机步中有多少个节点<br/> — <strong class="jp ir"> P </strong>:返回超参数<br/> — <strong class="jp ir"> Q </strong> : Inout超参数<br/>以及标准的skip-gram参数(上下文窗口大小、迭代次数等)。)</p><p id="6b15" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">前两个超参数非常简单明了。<br/>随机漫步生成算法将遍历图中的每个节点，并将生成&lt; <strong class="jp ir">漫步数量</strong> &gt;随机漫步，长度&lt; <strong class="jp ir">漫步长度</strong> &gt;。<br/> <strong class="jp ir"> Q </strong>和<strong class="jp ir"> P </strong>，用可视化更好解释。<br/>假设你正在随机行走，刚刚从节点&lt; <strong class="jp ir"> <em class="kl"> t </em> </strong> &gt;过渡到下图中的节点&lt;<strong class="jp ir"><em class="kl">v</em></strong>&gt;<strong class="jp ir"/>(摘自文章)。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mu"><img src="../Images/176f067ca5e624add8aa49c3ecda3d7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*44_Ys2JeD8B0NVdbJ4TQlg.png"/></div></div></figure><p id="e517" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从&lt;<strong class="jp ir"> <em class="kl"> v </em> </strong> &gt;过渡到他的任何一个邻居的概率是<br/> &lt; <strong class="jp ir">边权重</strong>&gt;*&lt;<strong class="jp ir">α</strong>&gt;<strong class="jp ir"/>(归一化)，其中&lt; <strong class="jp ir"> α </strong> &gt;取决于超参数。<br/> <strong class="jp ir"> P </strong>控制访问&lt; <strong class="jp ir"> v </strong> &gt;后回到&lt; <strong class="jp ir"> t </strong> &gt;的概率。<br/> <strong class="jp ir"> Q </strong>控制着探索图表中未被发现部分的概率。<br/>直观地说，这有点像tSNE中的困惑参数，它允许你强调图形的局部/全局结构。<br/>不要忘记重量也被考虑在内，所以最终的出行概率是:<br/> 1的函数。行走中的上一个节点<br/> 2。p和Q <br/> 3。边缘重量</p><p id="d8ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">理解这一部分很重要，因为它是node2vec的本质。如果你没有完全理解抽样策略背后的思想，我强烈建议你再读一遍这部分。</p><p id="f6f2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用采样策略，node2vec将生成“句子”(有向子图)，这些句子将用于嵌入，就像word2vec中使用的文本句子一样。如果工作正常，为什么要改变呢？</p></div><div class="ab cl kn ko hu kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="ij ik il im in"><h1 id="4c84" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">代码(展示)</h1><p id="4332" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">现在是将node2vec付诸行动的时候了。你可以在这里找到node2vec测试的完整代码。<br/>我使用node2vec算法的实现作为例子，它增加了对分配节点特定参数(q，p，num_walks和walk length)的支持。</p><p id="cf8b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们要做的是，利用欧洲足球队的形成，嵌入7个不同俱乐部的球队，球员和位置。<br/>我将要使用的数据来自Kaggle 上的<a class="ae km" href="https://www.kaggle.com/artimous/complete-fifa-2017-player-dataset-global" rel="noopener ugc nofollow" target="_blank"> FIFA 17数据集。<br/>在FIFA(eas sports)中，每支球队都可以用一个图形来表示，见下图。</a></p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mv"><img src="../Images/8e3d8835279a250ab00c7e94abf31a76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fZIbuDRFM4HjgppQfJKSAw.jpeg"/></div></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Formation example from FIFA17, easily interpreted as a graph</figcaption></figure><p id="308d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如我们所看到的，每个位置都与其他位置相连，并且在玩游戏时，每个位置都被分配了一个玩家。<br/>这里有几十种不同的地层，它们之间的连通性各不相同。还有一些类型的位置在一些地层中存在，但在其他地层中不存在，例如“LM”位置在这个地层中不存在，但在其他地层中存在。</p><p id="3e89" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就是我们将要做的事情。节点将是球员，球队名称和位置<br/> 2。对于每个团队，创建一个单独的图，其中每个球员节点连接到他的团队名称节点，连接到他的队友节点，并连接到他的队友位置节点。<br/> 3。将node2vec应用到结果图中</p><p id="d075" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">*注意:为了给团队内部和团队之间的每个位置创建单独的节点，我给相似的节点添加了后缀，并且在walk生成之后我已经删除了它们。这是一个技术问题，检查回购中的代码以便更好地理解</em></p><p id="3296" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">输入数据的第一行如下所示(经过一些排列):</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/935307b4227b574993b0bab7b27c8fbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:810/format:webp/1*rqOdekSr1u8cjRWhgNX-Og.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Sample rows from the input data</figcaption></figure><p id="c84c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我们使用FIFA17格式构建图表。<br/>使用我的node2vec包，图必须是<code class="fe mx my mz na b">networkx.Graph</code>的一个实例。<br/>检查图边之后，我们将得到以下结果</p><pre class="ly lz ma mb gt nb na nc nd aw ne bi"><span id="c39e" class="nf kv iq na b gy ng nh l ni nj">for edge in graph.edges:<br/>    print(edge)</span><span id="b08b" class="nf kv iq na b gy nk nh l ni nj">&gt;&gt;&gt; ('james_rodriguez', 'real_madrid')<br/>&gt;&gt;&gt; ('james_rodriguez', 'cm_1_real_madrid')<br/>&gt;&gt;&gt; ('james_rodriguez', 'toni_kroos')<br/>&gt;&gt;&gt; ('james_rodriguez', 'cm_2_real_madrid')<br/>&gt;&gt;&gt; ('james_rodriguez', 'luka_modric')<br/>&gt;&gt;&gt; ('lw_real_madrid', 'cm_1_real_madrid')<br/>&gt;&gt;&gt; ('lw_real_madrid', 'lb_real_madrid')<br/>&gt;&gt;&gt; ('lw_real_madrid', 'toni_kroos')<br/>&gt;&gt;&gt; ('lw_real_madrid', 'marcelo')<br/>...</span></pre><p id="838d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如我们所看到的，每个球员都根据阵型与他的球队、位置和队友联系在一起。<br/>所有附加在位置上的后缀将在走步计算后返回到它们原来的字符串(<code class="fe mx my mz na b">lw_real_madrid</code> → <code class="fe mx my mz na b">lw</code>)。</p><p id="058e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们有了图，我们执行node2vec</p><pre class="ly lz ma mb gt nb na nc nd aw ne bi"><span id="199d" class="nf kv iq na b gy ng nh l ni nj"># pip install node2vec</span><span id="d1f3" class="nf kv iq na b gy nk nh l ni nj">from node2vec import Node2Vec</span><span id="afba" class="nf kv iq na b gy nk nh l ni nj"># Generate walks<br/>node2vec = Node2Vec(graph, dimensions=20, walk_length=16, num_walks=100)</span><span id="bb52" class="nf kv iq na b gy nk nh l ni nj"># Reformat position nodes<br/>fix_formatted_positions = lambda x: x.split('_')[0] if x in formatted_positions else x</span><span id="8eea" class="nf kv iq na b gy nk nh l ni nj">reformatted_walks = [list(map(fix_formatted_positions, walk)) for walk in node2vec.walks]</span><span id="6bcc" class="nf kv iq na b gy nk nh l ni nj">node2vec.walks = reformatted_walks</span><span id="29f6" class="nf kv iq na b gy nk nh l ni nj"># Learn embeddings <br/>model = node2vec.fit(window=10, min_count=1)</span></pre><p id="6773" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们给<code class="fe mx my mz na b">node2vec.Node2Vec</code>一个<code class="fe mx my mz na b">networkx.Graph</code>实例，在使用<code class="fe mx my mz na b">.fit()</code>(它接受任何我们得到的参数<code class="fe mx my mz na b">gensim.models.Word2Vec</code>)后，我们得到一个<code class="fe mx my mz na b">gensim.models.Word2Vec</code>实例。</p><p id="dab4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我们将检查不同节点之间的相似性。<br/>我们期望与一个团队最相似的节点，会是它的队友:</p><pre class="ly lz ma mb gt nb na nc nd aw ne bi"><span id="9fad" class="nf kv iq na b gy ng nh l ni nj">for node, _ in model.most_similar('real_madrid'):<br/>    print(node)</span><span id="d33f" class="nf kv iq na b gy nk nh l ni nj">&gt;&gt;&gt; james_rodriguez<br/>&gt;&gt;&gt; luka_modric<br/>&gt;&gt;&gt; marcelo<br/>&gt;&gt;&gt; karim_benzema<br/>&gt;&gt;&gt; cristiano_ronaldo<br/>&gt;&gt;&gt; pepe<br/>&gt;&gt;&gt; gareth_bale<br/>&gt;&gt;&gt; sergio_ramos<br/>&gt;&gt;&gt; carvajal<br/>&gt;&gt;&gt; toni_kroos</span></pre><p id="2437" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于不熟悉欧洲足球的人来说，这些确实都是皇马的球员！</p><p id="87b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们检查与特定位置的相似性。我们希望球员们踢那个位置，或者更糟糕的是接近那个位置</p><pre class="ly lz ma mb gt nb na nc nd aw ne bi"><span id="5784" class="nf kv iq na b gy ng nh l ni nj"># Right Wingers<br/>for node, _ in model.most_similar('rw'):<br/>    # Show only players<br/>    if len(node) &gt; 3:<br/>        print(node)</span><span id="6c98" class="nf kv iq na b gy nk nh l ni nj">&gt;&gt;&gt; pedro<br/>&gt;&gt;&gt; jose_callejon<br/>&gt;&gt;&gt; raheem_sterling<br/>&gt;&gt;&gt; henrikh_mkhitaryan<br/>&gt;&gt;&gt; gareth_bale<br/>&gt;&gt;&gt; dries_mertens</span><span id="67ce" class="nf kv iq na b gy nk nh l ni nj"># Goal keepers<br/>for node, _ in model.most_similar('gk'):<br/>    # Show only players<br/>    if len(node) &gt; 3:<br/>        print(node)</span><span id="ab92" class="nf kv iq na b gy nk nh l ni nj">&gt;&gt;&gt; thibaut_courtois<br/>&gt;&gt;&gt; gianluigi_buffon<br/>&gt;&gt;&gt; keylor_navas<br/>&gt;&gt;&gt; azpilicueta<br/>&gt;&gt;&gt; manuel_neuer</span></pre><p id="6f3c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在第一次尝试中(右边锋)，我们确实从不同的俱乐部得到了不同的右边锋，再次完美的匹配。<br/>然而在第二次尝试中，我们得到了除Azpilicueta之外的所有守门员，Azpilicueta实际上是一名后卫——这可能是因为守门员与球队没有太多联系，通常只与中后卫有联系。</p><p id="f561" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">效果很好，对吧？在我们结束之前，让我们使用tSNE来降低维度并可视化玩家节点。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/8d65b1b6c0f8790e03d383fada00c387.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*o7X6P8G5_PyydOOshhWDzA.png"/></div><figcaption class="mp mq gj gh gi mr ms bd b be z dk">Visualization of player nodes (tSNE reduced dimensionality)</figcaption></figure><p id="8b4e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">看看吧，我们根据不同的俱乐部得到了漂亮的聚类。</p></div><div class="ab cl kn ko hu kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="ij ik il im in"><h1 id="3a1c" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">最后的话</h1><p id="e8d9" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">图形数据几乎无处不在，如果没有，通常可以放在图形上，但node2vec算法还不太流行。<br/>该算法还通过其超参数赋予了极大的灵活性，因此您可以决定您希望嵌入哪种信息，并且如果您可以选择自己构建图表(并且不是给定的),您的选择是无限的。<br/>希望你会在这篇文章中找到用处，并为你的机器学习武器库增加一个新工具。</p><p id="5a1e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">如果有人想为我的node2vec实现做贡献，请联系我。</em></p></div></div>    
</body>
</html>