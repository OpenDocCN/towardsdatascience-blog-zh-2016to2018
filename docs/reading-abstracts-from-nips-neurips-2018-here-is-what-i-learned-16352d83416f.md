# 阅读 NIPS/NeurIPS 2018 的摘要！以下是我学到的东西

> 原文：<https://towardsdatascience.com/reading-abstracts-from-nips-neurips-2018-here-is-what-i-learned-16352d83416f?source=collection_archive---------8----------------------->

![](img/0f8afc65364b5dc9765619afc3e15e3b.png)

Photo by [chuttersnap](https://unsplash.com/@chuttersnap?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

我决定读完 NIPS/NeurIPS 2018 的所有摘要。但事实证明，在我想要的时间框架内，这在身体上和精神上都是难以置信的。本次会议共收到 1011 篇论文，其中包括 30 篇口头论文、168 篇聚焦论文和 813 篇海报论文，论文接受率为 20.8%。([来源](https://github.com/lixin4ever/Conference-Acceptance-Rate))

我想在会议开始前的 24 小时内读完所有的摘要。我花了 1440 分钟阅读了 1011 篇摘要，平均时间为 1.42 分钟。我完全是愚蠢的，我想把摘要总结成一个迷你摘要，这样当我以后回到它或者分享它时，就可以很容易地理解一个简明的摘要。

我开始阅读摘要，从会议的第一个海报会议“Tue 海报会议 A”(它有 168 篇论文)中选取了 20 篇(前 20 篇)。我花了 210 分钟多一点的时间来阅读和总结(提取方式，提取一些摘要)，平均每篇论文 10.5 分钟。我加快了速度，不太担心总结，我在大约 150 分钟内完成了接下来的 20 个，平均 7.5 分钟。接下来的 20 分钟大约 90 分钟。接下来的 20 分钟大约需要 70-80 分钟。接下来的 20 分钟将在 60-70 分钟内完成。140 篇论文后，我放弃了时间限制，休息了一会儿。

尽管如此，当我结束一个 20 人的小组，去另一个小组时，奇妙的事情发生了。阅读一份扎实的研究调查的浓缩摘要真的令人生畏和不知所措，即使是一份，我也要读 20 份这样的论文并继续读下去。阅读前 20 篇论文，任何我不知道的理论或我不熟悉的主题都会阻止我理解他们正在解决的问题或他们解决方案的价值。

但是，最终我不那么害怕他们使用的理论或他们解决问题的独特新颖性，并把它们视为解决特定限制或扩展现有工作多功能性的灵感或见解。当我阅读摘要时，我感到很容易注意到他们正在解决的问题以及他们的解决方案对该领域的新颖性、有效性和影响。

总的来说，我真的很高兴我让自己阅读了非正常数量的摘要，尽管从很多方面来看这似乎是致命的！！我仍然想阅读会议的所有摘要，但这可能需要一周的时间。我会通知你的。

这些是我必须阅读的论文(除了整个“周二海报会议 A”还有 18 篇论文)和他们的摘要。标签在表现这些论文时并不那么有效，它们仅仅是人类潜在的感知开销，有时被视为感觉。

# [使用椭圆分布的 Wasserstein 空间概括点嵌入](http://papers.nips.cc/paper/8226-generalizing-point-embeddings-using-the-wasserstein-space-of-elliptical-distributions)

基本原则

一种新的嵌入框架，它是数值灵活的，并且扩展了 wessserstein 空间中的点嵌入、椭圆嵌入。Wasserstein 椭圆嵌入更直观，并且产生比具有 Kullback-Leibler 散度的高斯嵌入的替代选择在数值上表现更好的工具。本文通过将椭圆嵌入用于可视化、计算词的嵌入以及反映蕴涵或上下级关系来展示椭圆嵌入的优点。

# [甘人生而平等吗？大规模研究](http://papers.nips.cc/paper/7350-are-gans-created-equal-a-large-scale-study)

系统评估，真正了解

尽管大量的研究活动产生了许多有趣的 GAN 算法，但仍然很难评估哪些算法的性能优于其他算法。我们对最先进的模型和评估方法进行了中立的、多方面的大规模实证研究。我们发现，通过足够的超参数优化和随机重启，大多数模型都可以达到类似的分数。这表明，除了基本的算法变化之外，更高的计算预算和调整也能带来改进。为了克服当前度量的一些限制，我们还提出了几个数据集，在这些数据集上可以计算精度和召回率。我们的实验结果表明，未来的氮化镓研究应基于更系统和客观的评估程序。最后，我们没有发现任何测试算法始终优于在{ cite good fellow 2014 generate }中介绍的不饱和 GAN 的证据。

# [渔网:图像、区域和像素级预测的多功能支柱](http://papers.nips.cc/paper/7356-fishnet-a-versatile-backbone-for-image-region-and-pixel-level-prediction)

基本面，在核心

设计卷积神经网络(CNN)结构以预测不同级别(例如图像级别、区域级别和像素级别)上的对象的基本原理是不同的。通常，专门为图像分类设计的网络结构被直接用作包括检测和分割在内的其他任务的默认主干结构，但是很少有主干结构是在考虑统一为像素级或区域级预测任务设计的网络的优点的情况下设计的，这些预测任务可能需要具有高分辨率的非常深的特征。朝着这个目标，我们设计了一个类似鱼的网络，称为鱼网。在 FishNet 中，所有分辨率的信息都被保留下来，并为最终任务进行优化。此外，我们观察到现有的工作仍然不能直接将梯度信息从深层传播到浅层。我们的设计可以更好的处理这个问题。已经进行了大量的实验来证明鱼网的卓越性能。特别是在 ImageNet-1k 上，FishNet 的精度能够以较少的参数超越 DenseNet 和 ResNet 的性能。渔网被用作 COCO Detection 2018 挑战赛获奖作品的模块之一。该代码可在[https://github.com/kevin-ssy/FishNet](https://github.com/kevin-ssy/FishNet)获得。

# [辉光:具有可逆的 1x1 卷积的生成流](http://papers.nips.cc/paper/8224-glow-generative-flow-with-invertible-1x1-convolutions)

实用神奇，美观大方

具有 1x1 可逆卷积的基于流的生成模型，证明了对数似然和定量样本质量的显著改善。也许最引人注目的是，它证明了朝着简单对数似然目标优化的生成模型能够有效地合成大的和主观上逼真的图像。

# [卷积神经网络的一个有趣的失败和 CoordConv 解决方案](http://papers.nips.cc/paper/8169-an-intriguing-failing-of-convolutional-neural-networks-and-the-coordconv-solution)

有意思，是时候了

我们已经展示了 CNN 对坐标转换任务建模的奇怪无能，展示了 CoordConv 层形式的简单修复，并给出了表明包括这些层可以在广泛的应用中提高性能的结果。在 GAN 中使用 CoordConv 产生的模式崩溃更少，因为高级空间延迟和像素之间的转换变得更容易学习。在 MNIST 检测上训练的更快的 R-CNN 检测模型显示，当使用 CoordConv 时，IOU 提高了 24%,并且在强化学习(RL)领域中，玩 Atari 游戏的代理从 CoordConv 层的使用中显著受益。

# [哪些神经网络架构会产生爆炸和消失梯度？](http://papers.nips.cc/paper/7339-which-neural-net-architectures-give-rise-to-exploding-and-vanishing-gradients)

基础知识，理解

我们给出了随机初始化的全连通网络 N 中梯度的统计行为的严格分析。我们的结果表明，N 的输入-输出雅可比矩阵中的项的平方的经验方差在简单的结构相关常数β中是指数的，由隐藏层宽度的倒数之和给出。当β较大时，N 在初始化时计算的梯度变化很大。我们的方法补充了随机网络的平均场理论分析。从这个观点出发，我们严格地计算了混沌边缘梯度统计的有限宽度修正。

# [具有稀疏和量化通信的分布式深度学习的线性加速分析](http://papers.nips.cc/paper/7519-a-linear-speedup-analysis-of-distributed-deep-learning-with-sparse-and-quantized-communication)

实际的

巨大的通信开销已经成为分布式随机梯度下降(SGD)训练深度神经网络的性能瓶颈。先前的工作已经证明了使用梯度稀疏化和量化来降低通信成本的潜力。然而，对于稀疏和量化通信如何影响训练算法的收敛速度，仍然缺乏了解。本文研究了非凸优化的分布式 SGD 在两种减少通信量的策略下的收敛速度:稀疏参数平均和梯度量化。我们证明了如果稀疏化和量化超参数配置得当，可以达到 *O* (1/√ *MK* )的收敛速度。我们还提出了一种称为周期量化平均(PQASGD)的策略，在保持 *O* (1/√ *MK* )收敛速度的同时，进一步降低了通信开销。我们的评估验证了我们的理论结果，并表明我们的 PQASGD 可以像全通信 SGD 一样快地收敛，而通信数据大小仅为 3 %- 5%。

# [通过激活样本方差的方差进行正则化](http://papers.nips.cc/paper/7481-regularizing-by-the-variance-of-the-activations-sample-variances)

基本原理，标准化

规范化技术在支持深度神经网络的高效且通常更有效的训练中起着重要作用。虽然传统的方法显式归一化的激活，我们建议添加一个损失项代替。这个新的损失项鼓励激活的方差保持稳定，而不是从一个随机小批量到下一个随机小批量变化。最后，我们能够将新的正则项与 batchnorm 方法联系起来，这为它提供了正则化的视角。我们的实验表明，对于 CNN 和全连接网络，在准确性上比 batchnorm 技术有所提高。

# [卷积神经网络的突触强度](http://papers.nips.cc/paper/8218-synaptic-strength-for-convolutional-neural-network)

突触修剪，神经科学

卷积神经网络(CNN)是计算和存储密集型的，这阻碍了它们在移动设备中的部署。受神经科学文献中相关概念的启发，我们提出突触修剪:一种数据驱动的方法，用一种新提出的称为突触强度的参数来修剪输入和输出特征图之间的连接。突触强度被设计为基于其传输的信息量来捕捉连接的重要性。实验结果表明了该方法的有效性。在 CIFAR-10 上，我们为各种 CNN 模型修剪了高达 96%的连接，这导致了显著的大小减少和计算节省。

# [DropMax:自适应变分 Softmax](http://papers.nips.cc/paper/7371-dropmax-adaptive-variational-softmax)

干净的

我们提出了 DropMax，一个随机版本的 softmax 分类器，它在每次迭代中根据每个实例自适应决定的丢弃概率丢弃非目标类。具体来说，我们在类输出概率上覆盖二进制掩蔽变量，这是通过变分推理输入自适应学习的。这种随机正则化具有从具有不同决策边界的指数级分类器中构建集成分类器的效果。此外，对每个实例上的非目标类的辍学率的学习允许分类器更多地关注针对最混乱的类的分类。我们在多个用于分类的公共数据集上验证了我们的模型，在该数据集上，它获得了比常规 softmax 分类器和其他基线显著提高的准确性。对学习到的丢弃概率的进一步分析表明，我们的模型在执行分类时确实更经常地选择混淆类。

# [关系递归神经网络](http://papers.nips.cc/paper/7960-relational-recurrent-neural-networks)

革命的

基于记忆的神经网络通过利用长时间记忆信息的能力来模拟时态数据。然而，还不清楚他们是否也有能力用他们记忆的信息进行复杂的关系推理。在这里，我们首先确认我们的直觉，即标准内存架构可能会在大量涉及理解实体连接方式的任务中挣扎，即，涉及关系推理的任务。然后，我们通过使用一种新的内存模块(关系内存核心(RMC))来改善这些缺陷，这种内存模块采用多头点积注意力来允许内存进行交互。最后，我们在一组任务上测试了 RMC，这些任务可能受益于跨顺序信息的更有能力的关系推理，并显示了在 RL 域(BoxWorld & Mini PacMan)、程序评估和语言建模方面的巨大收益，在 WikiText-103、Project Gutenberg 和 GigaWord 数据集上实现了最先进的结果。

# [在知识图上嵌入逻辑查询](http://papers.nips.cc/paper/7473-embedding-logical-queries-on-knowledge-graphs)

少数方法

学习知识图的低维嵌入是一种用于预测实体之间未观察到的或缺失的边的强大方法。然而，该领域的一个公开挑战是开发能够超越简单边缘预测并处理更复杂逻辑查询的技术，这可能涉及多个未观察到的边缘、实体和变量。例如，给定一个不完整的生物学知识图表，我们可能想要预测“什么药物可能针对与 X 和 Y 疾病都相关的蛋白质？”—需要对可能与疾病 X 和 y 相互作用的所有可能蛋白质进行推理的查询。这里，我们介绍了一个框架，以在不完整的知识图上有效地对合取逻辑查询进行预测，这是一个灵活但易于处理的一阶逻辑子集。在我们的方法中，我们在低维空间中嵌入图节点，并在该嵌入空间中将逻辑运算符表示为学习到的几何运算(例如，平移、旋转)。通过在低维嵌入空间内执行逻辑运算，我们的方法实现了与查询变量的数量成线性的时间复杂度，相比之下，基于简单枚举的方法需要指数复杂度。我们在两个对具有数百万关系的真实世界数据集的应用研究中展示了该框架的效用:预测药物-基因-疾病相互作用网络中的逻辑关系，以及来自流行网络论坛的基于图形的社会相互作用表示。

# [作为多目标优化的多任务学习](http://papers.nips.cc/paper/7334-multi-task-learning-as-multi-objective-optimization)

大问题

在多任务学习中，多个任务被联合解决，在它们之间共享归纳偏差。多任务学习本质上是一个多目标的问题，因为不同的任务可能会发生冲突，需要进行权衡。一个常见的折衷方案是优化一个代理目标，使每个任务损失的加权线性组合最小化。但是，这种解决方法仅在任务不竞争时有效，这种情况很少发生。在本文中，我们明确地将多任务学习视为多目标优化，总目标是找到一个帕累托最优解。为此，我们使用在基于梯度的多目标优化文献中开发的算法。这些算法不能直接应用于大规模学习问题，因为它们与梯度的维度和任务的数量的比例很差。因此，我们提出了一个多目标损失的上限，并表明它可以有效地优化。我们进一步证明，在现实的假设下，优化这个上限会产生一个帕累托最优解。我们将我们的方法应用于各种多任务深度学习问题，包括数字分类、场景理解(联合语义分割、实例分割和深度估计)和多标签分类。我们的方法比最近的多任务学习公式或每任务训练产生更高性能的模型。

# [Mesh-TensorFlow:超级计算机的深度学习](http://papers.nips.cc/paper/8242-mesh-tensorflow-deep-learning-for-supercomputers)

解决方案

批处理分裂(数据并行)是主要的分布式深度神经网络(DNN)训练策略，因为它的普遍适用性及其对单程序多数据(SPMD)编程的适应性。然而，批量分割存在一些问题，包括无法训练非常大的模型(由于内存限制)、高延迟以及小批量时效率低下。所有这些都可以通过更通用的分布策略(模型并行)来解决。不幸的是，有效的模型并行算法往往难以发现、描述和实现，尤其是在大型集群上。我们介绍网格张量流，这是一种用于描述一般分布式张量计算的语言。在数据并行性可以被视为沿着“批处理”维度拆分张量和操作的情况下，在 Mesh-TensorFlow 中，用户可以指定要在多维处理器网格的任何维度上拆分的任何张量维度。一个网格张量流图编译成一个 SPMD 程序，该程序由并行操作和集体通信原语(如 Allreduce)组成。我们使用 Mesh-TensorFlow 来实现变压器序列到序列模型的高效数据并行、模型并行版本。使用多达 512 个核心的 TPU 网格，我们训练了多达 50 亿个参数的变压器模型，超过了 SOTA 在 WMT 的 14 个英语到法语翻译任务和 10 亿词语言建模基准上的结果。网格张量流在[https://github.com/tensorflow/mesh](https://github.com/tensorflow/mesh)可用

我无法停止思考 NeurIPS！！也不写它。

**编辑:**我发表了前两次海报会议的部分论文(330 多篇论文)

[](/neurips-2018-reading-list-from-tue-poster-sessions-a-b-fce561e56be8) [## NIPS/NeurIPS 2018:前两次海报会议的最佳*

### 330 多篇论文的阅读清单，根据它们的效用或优点分组

towardsdatascience.com](/neurips-2018-reading-list-from-tue-poster-sessions-a-b-fce561e56be8)