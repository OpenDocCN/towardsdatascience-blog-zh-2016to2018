<html>
<head>
<title>Build Your First Deep Learning Classifier using TensorFlow: Dog Breed Example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 TensorFlow 构建您的第一个深度学习分类器:狗品种示例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/build-your-first-deep-learning-classifier-using-tensorflow-dog-breed-example-964ed0689430?source=collection_archive---------0-----------------------#2018-04-26">https://towardsdatascience.com/build-your-first-deep-learning-classifier-using-tensorflow-dog-breed-example-964ed0689430?source=collection_archive---------0-----------------------#2018-04-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/13b20cc90a0619c4f61db5bc1b6902a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C1WssIiKpRsfjKrle9IyMQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Convoluted Neural Networks (like the one pictured above) are powerful tools for Image Classification</figcaption></figure><h1 id="c30f" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">介绍</h1><p id="be8d" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">在本文中，我将向您介绍几种技术，帮助您迈出开发算法的第一步，该算法可用于经典的<strong class="lc ir">图像分类</strong>问题:从图像中检测狗的品种。</p><p id="ca65" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">到本文结束时，我们将开发出代码，接受任何用户提供的图像作为输入，并返回对狗的品种的估计。此外，如果检测到人类，该算法将提供最相似的狗品种的估计。</p></div><div class="ab cl md me hu mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="ij ik il im in"><h1 id="4372" class="kc kd iq bd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz bi translated">1.什么是卷积神经网络？</h1><p id="2533" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">卷积神经网络(也称为 CNN 或 ConvNet)是一类<strong class="lc ir">深度神经网络</strong>，已在许多计算机视觉和视觉图像应用中广泛采用。</p><p id="6707" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">一个著名的 CNN 应用案例在斯坦福大学研究小组的<a class="ae mp" href="https://www.nature.com/articles/nature21056?error=cookies_not_supported&amp;code=c8ab8524-38e7-47c0-af7a-5912873b07b6" rel="noopener ugc nofollow" target="_blank">研究论文</a>中有详细描述，他们在论文中展示了使用单一 CNN 对皮肤病变进行分类。仅使用像素和疾病标签作为输入，从图像中训练神经网络。</p><p id="945f" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">卷积神经网络由多层组成，与其他图像分类算法相比，它需要相对较少的预处理。</p><p id="59cb" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">他们通过使用滤镜并将其应用于图像来学习。该算法采用一个小正方形(或“窗口”)并开始在图像上应用它。每个过滤器允许 CNN 识别图像中的特定模式。CNN 寻找图像中过滤器匹配图像内容的部分。</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mq"><img src="../Images/cd84d8d7fbd81dd387918e1255d3964f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7mYVCf8dYiJ0CAa3.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">An example of a CNN Layer Architecture for Image Classification (source: <a class="ae mp" href="https://bit.ly/2vwlegO" rel="noopener ugc nofollow" target="_blank">https://bit.ly/2vwlegO</a>)</figcaption></figure><p id="af7e" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">网络的前几层可以检测简单的特征，如线、圆、边。在每一层中，随着我们越来越深入神经网络的各个层，网络能够结合这些发现，并不断学习更复杂的概念。</p><h2 id="013b" class="mv kd iq bd ke mw mx dn ki my mz dp km ll na nb kq lp nc nd ku lt ne nf ky ng bi translated">1.1 有哪几种层？</h2><p id="a35a" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">CNN 的整体架构由输入层、隐藏层和输出层组成。它们有几种类型的层，例如卷积层、激活层、汇集层、下降层、密集层和软最大层。</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nh"><img src="../Images/7ba53cc5efcc91e54c651d547166e3dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ioq-Yix7ReaRKhESMsM6NA.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Neural Networks consist of an input layer, hidden layers, and an output layer (source: <a class="ae mp" href="https://bit.ly/2Hxhjaw" rel="noopener ugc nofollow" target="_blank">https://bit.ly/2Hxhjaw</a>)</figcaption></figure><p id="2bf0" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">卷积层(或 Conv 层)是构成卷积神经网络的核心。Conv 层由一组滤镜组成。每个过滤器可以被认为是一个小正方形(具有固定的宽度和高度),其延伸通过输入体积的整个深度。</p><p id="dce5" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">在每次通过时，过滤器在输入体积的宽度和高度上“卷积”。这个过程产生一个二维激活图，它给出了该滤波器在每个空间位置的响应。</p><p id="a0c8" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">为了避免过度拟合，池层用于在激活图上应用非线性缩减采样。换句话说，池层在丢弃信息方面很激进，但如果使用得当，也是有用的。在 CNN 架构中，一个池层通常跟随一个或两个 Conv 层。</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ni"><img src="../Images/4e562d930fb687a1d0a9b79263e74c06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mgUGIlgJiPb7ge_Qote9TA.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Pooling layers are used to apply non-linear downsampling on activation maps (source: <a class="ae mp" href="https://bit.ly/2Hxhjaw" rel="noopener ugc nofollow" target="_blank">https://bit.ly/2Hxhjaw</a>)</figcaption></figure><p id="1fc8" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">通过随机忽略某些激活函数，丢弃层也用于减少过拟合，而密集层是完全连接的层，通常位于神经网络的末端。</p><h2 id="f3ff" class="mv kd iq bd ke mw mx dn ki my mz dp km ll na nb kq lp nc nd ku lt ne nf ky ng bi translated">1.2 什么是激活功能？</h2><p id="d939" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">使用激活函数处理层和神经网络的输出，激活函数是添加到隐藏层和输出层的节点。</p><p id="e1ad" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">你会经常发现 ReLu 激活函数用在隐藏层，而最终层通常由 SoftMax 激活函数组成。这个想法是，通过堆叠线性和非线性函数层，我们可以检测大范围的模式，并准确预测给定图像的标签。</p><p id="f4fe" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">SoftMax 通常位于最后一层，它基本上是一个归一化器，产生一个离散的概率分布向量，这对我们来说很好，因为 CNN 的输出是一个图像对应于特定类别的概率。</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nj"><img src="../Images/b39eaeadf45176e5af69452ba7bb0df2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*29VH_NiSdoLJ1jUMLrURCA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">The most common activation functions include the ReLU and Sigmoid activation functions</figcaption></figure><p id="a4e5" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">当涉及到模型评估和性能评估时，选择损失函数。在用于图像分类的 CNN 中，通常选择<a class="ae mp" href="https://aboveintelligent.com/deep-learning-basics-the-score-function-cross-entropy-d6cc20c9f972" rel="noopener ugc nofollow" target="_blank">类别交叉熵</a>(简单地说:它对应于-log(error))。有几种方法可以使用梯度下降来最小化误差——在本文中，我们将依靠“<a class="ae mp" href="http://ruder.io/optimizing-gradient-descent/" rel="noopener ugc nofollow" target="_blank"> rmsprop </a>”，这是一种自适应学习率方法，作为一种以准确性为衡量标准的优化器。</p><h1 id="90f1" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">2.设置算法的构建模块</h1><p id="77e4" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">为了构建我们的算法，我们将使用<a class="ae mp" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>、<a class="ae mp" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>(运行在 TensorFlow 之上的神经网络 API)，以及<a class="ae mp" href="https://opencv.org/" rel="noopener ugc nofollow" target="_blank"> OpenCV </a>(计算机视觉库)。</p><p id="c17d" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">完成该项目时，训练和测试数据集也可用(参见<a class="ae mp" href="https://github.com/udacity/dog-project" rel="noopener ugc nofollow" target="_blank"> GitHub repo </a>)。</p><h2 id="5f2c" class="mv kd iq bd ke mw mx dn ki my mz dp km ll na nb kq lp nc nd ku lt ne nf ky ng bi translated"><strong class="ak"> 2.1 检测图像是否包含人脸</strong></h2><p id="11c2" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">为了检测提供的图像是否是人脸，我们将使用 OpenCV 的<a class="ae mp" href="https://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html" rel="noopener ugc nofollow" target="_blank">人脸检测算法</a>。在使用任何面部检测器之前，标准程序是将图像转换为灰度。下面，<code class="fe nk nl nm nn b">detectMultiScale</code>函数执行<code class="fe nk nl nm nn b">face_cascade</code>中存储的分类器，并将灰度图像作为参数。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><h2 id="9e25" class="mv kd iq bd ke mw mx dn ki my mz dp km ll na nb kq lp nc nd ku lt ne nf ky ng bi translated">2.2 检测图像是否包含狗</h2><p id="25e3" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">为了检测所提供的图像是否包含一张狗的脸，我们将使用一个预训练的<a class="ae mp" href="http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006" rel="noopener ugc nofollow" target="_blank"> ResNet-50 </a>模型，该模型使用<a class="ae mp" href="https://en.wikipedia.org/wiki/ImageNet" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>数据集，该数据集可以将对象从<a class="ae mp" href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a" rel="noopener ugc nofollow" target="_blank"> 1000 个类别</a>中分类。给定一个图像，这个预训练的<a class="ae mp" href="http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006" rel="noopener ugc nofollow" target="_blank"> ResNet-50 模型</a>返回图像中包含的对象的预测。</p><p id="01cb" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">当使用<a class="ae mp" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>作为后端时，<a class="ae mp" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank">Keras</a>CNN 需要一个 4D 数组作为输入。下面的<code class="fe nk nl nm nn b">path_to_tensor</code>函数将彩色图像的字符串值文件路径作为输入，将其调整为 224x224 像素的正方形图像，并返回适合提供给 Keras CNN 的 4D 数组(称为“张量”)。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="9370" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">此外，所有预训练模型都有额外的归一化步骤，即必须从每个图像的每个像素中减去平均像素。这在导入函数<code class="fe nk nl nm nn b">preprocess_input</code>中实现。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="e64f" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">如上面的代码所示，对于最终预测，我们通过获取预测概率向量的<a class="ae mp" href="https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.argmax.html" rel="noopener ugc nofollow" target="_blank"> <em class="nq"> argmax </em> </a>来获得与模型的预测对象类别相对应的整数，我们可以通过使用 ImageNet 标签<a class="ae mp" href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a" rel="noopener ugc nofollow" target="_blank">字典</a>来识别对象类别。</p><h1 id="71aa" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">3.使用迁移学习建立你的 CNN 分类器</h1><p id="9ec4" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">现在我们有了在图像中检测人类和狗的功能，我们需要一种从图像中预测品种的方法。在这一节中，我们将创建一个对狗的品种进行分类的 CNN。</p><p id="773e" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">为了在不牺牲准确性的情况下减少训练时间，我们将使用<a class="ae mp" rel="noopener" target="_blank" href="/transfer-learning-leveraging-insights-from-large-data-sets-d5435071ec5a">转移学习</a>来训练 CNN 这是一种允许我们使用在大型数据集上预先训练好的网络的方法。通过保留早期的层并仅训练新添加的层，我们能够利用通过预训练算法获得的知识并将其用于我们的应用。</p><p id="e2c4" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated"><a class="ae mp" href="https://keras.io/applications/" rel="noopener ugc nofollow" target="_blank"> Keras </a>包括几个预训练的深度学习模型，可用于预测、特征提取和微调。</p><h2 id="5939" class="mv kd iq bd ke mw mx dn ki my mz dp km ll na nb kq lp nc nd ku lt ne nf ky ng bi translated">3.1 模型架构</h2><p id="2964" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">如前所述，<a class="ae mp" href="https://github.com/KaimingHe/deep-residual-networks" rel="noopener ugc nofollow" target="_blank"> ResNet-50 模型</a>输出将成为我们的输入层——称为<em class="nq">瓶颈</em>特性。在下面的代码块中，我们通过运行以下代码来提取与训练、测试和验证集相对应的瓶颈特性。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="2f0d" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">我们将建立我们的模型体系结构，以便 ResNet-50 的最后一个卷积输出作为我们的模型的输入。我们只添加了一个<a class="ae mp" href="https://keras.io/layers/pooling/" rel="noopener ugc nofollow" target="_blank">全局平均池</a>层和一个<a class="ae mp" href="https://keras.io/layers/core/" rel="noopener ugc nofollow" target="_blank">全连接</a>层，其中后者包含每个狗类别的一个节点，并具有一个<a class="ae mp" href="https://keras.io/activations/#softmax" rel="noopener ugc nofollow" target="_blank"> Softmax </a>激活函数。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><pre class="mr ms mt mu gt nr nn ns nt aw nu bi"><span id="9bbc" class="mv kd iq nn b gy nv nw l nx ny">_________________________________________________________________ Layer (type) Output Shape Param # ================================================================= global_average_pooling2d_3 ( (None, 2048) 0 _________________________________________________________________ dense_3 (Dense) (None, 133) 272517 ================================================================= Total params: 272,517 Trainable params: 272,517 Non-trainable params: 0 _________________________________________________________________</span></pre><p id="2dc6" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">正如我们在上面代码的输出中看到的，我们最终得到了一个有 272，517 个参数的神经网络！</p><h2 id="0924" class="mv kd iq bd ke mw mx dn ki my mz dp km ll na nb kq lp nc nd ku lt ne nf ky ng bi translated">3.2 编译和测试模型</h2><p id="cf94" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">现在，我们可以使用 CNN 来测试它在我们的狗图像测试数据集中识别品种的能力。为了微调模型，我们进行了 20 次迭代(或“<a class="ae mp" rel="noopener" target="_blank" href="/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9">时期</a>”)，其中模型的超参数被微调，以减少使用 RMS Prop 优化的损失函数(<a class="ae mp" href="https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/" rel="noopener ugc nofollow" target="_blank">类别交叉熵</a>)。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><pre class="mr ms mt mu gt nr nn ns nt aw nu bi"><span id="3d9b" class="mv kd iq nn b gy nv nw l nx ny">Test accuracy: 80.0239%</span></pre><p id="2d4f" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">该算法提供了一个测试集，测试准确率为<strong class="lc ir"> 80% </strong>。一点都不差！</p><h2 id="3dc0" class="mv kd iq bd ke mw mx dn ki my mz dp km ll na nb kq lp nc nd ku lt ne nf ky ng bi translated">3.3 用模型预测犬种</h2><p id="2eb3" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">现在我们有了算法，让我们编写一个函数，它以图像路径作为输入，并返回由我们的模型预测的狗的品种。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><h1 id="5279" class="kc kd iq bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">4.测试我们的 CNN 分类器</h1><p id="83fa" class="pw-post-body-paragraph la lb iq lc b ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ij bi translated">现在，我们可以编写一个函数，它接受一个图像的文件路径，并首先确定该图像是否包含一个人、一只狗，或者两者都不包含。</p><p id="17c2" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">如果在图像中检测到一只<strong class="lc ir">狗</strong>，返回预测的品种。如果在图像中检测到一个<strong class="lc ir">人</strong>，返回相似的狗品种。如果图像中未检测到<strong class="lc ir">或</strong>，则提供指示错误的输出。</p><figure class="mr ms mt mu gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="eb46" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">我们已经准备好测试这个算法了！让我们在一些样本图像上测试该算法:</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nz"><img src="../Images/dd235e56cb2b229d5343e26ca82b9125.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ye3iACIYpBY78sanJjDpmA.jpeg"/></div></div></figure><p id="0329" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">这些预测在我看来很准确！</p><p id="4d75" class="pw-post-body-paragraph la lb iq lc b ld ly lf lg lh lz lj lk ll ma ln lo lp mb lr ls lt mc lv lw lx ij bi translated">最后，我注意到该算法容易出错，除非它是一个清晰的正面拍摄，图像上的噪声最小。因此，我们需要使算法对噪声更加鲁棒。此外，我们可以用来改进我们的分类器的一种方法是<a class="ae mp" href="https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced" rel="noopener">图像增强</a>，它允许您通过提供训练集中提供的图像的变体来“增强”您的数据。</p></div></div>    
</body>
</html>