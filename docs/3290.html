<html>
<head>
<title>[ CVPR 2014 / Paper Summary ] The Secrets of Salient Object Segmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">【CVPR 2014 /论文摘要】显著对象分割的秘密</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/cvpr-2014-paper-summary-the-secrets-of-salient-object-segmentation-9c777babdc5?source=collection_archive---------7-----------------------#2018-04-28">https://towardsdatascience.com/cvpr-2014-paper-summary-the-secrets-of-salient-object-segmentation-9c777babdc5?source=collection_archive---------7-----------------------#2018-04-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/1a2fd548d704dac1f2c26fb854556e07.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/1*8yOck-8ajke3hGJUtB-6VQ.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Gif from this <a class="ae jy" href="https://giphy.com/gifs/computer-vision-11aRERI0c2KNFu/links" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="eaa6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我已经知道什么是分割，但是我不知道什么是显著对象分割。因此，我决定通过阅读 2014 年 CVPR 上发表的一篇论文来改变这一现状。</p><blockquote class="kx ky kz"><p id="8ae5" class="jz ka la kb b kc kd ke kf kg kh ki kj lb kl km kn lc kp kq kr ld kt ku kv kw ij bi translated">请注意，这篇文章是为了让未来的我回顾并记住这篇文章的内容。</p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="lp lq l"/></div></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="5144" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">显著物体检测/注视预测</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lr"><img src="../Images/3c9635aefd10243e6aa5da0e72179004.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ndPIvM_2lfD0kX8K.jpg"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image from this <a class="ae jy" href="https://mmcheng.net/msra10k/" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="e464" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">显著的</strong> →最显著的或最重要的。(来自<a class="ae jy" href="https://www.google.ca/search?q=salient+def&amp;rlz=1C1CHBF_enCA771CA771&amp;oq=Salient+def&amp;aqs=chrome.0.69i59j0j69i61j69i60j69i61j0.717j0j7&amp;sourceid=chrome&amp;ie=UTF-8" rel="noopener ugc nofollow" target="_blank">谷歌搜索</a>)</p><p id="18cc" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">因此，从上面的图像中，我们可以得出结论，显著对象检测是一个用于分割图像中最重要的对象的术语。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/b750f69b90e597b6cebdfcd5ece4e9e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*gh1bVYBo7hhDwmFC6oaguA.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image from this <a class="ae jy" href="https://arxiv.org/pdf/1611.09571.pdf" rel="noopener ugc nofollow" target="_blank">paper</a></figcaption></figure><p id="7de8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">从上面的论文中我们可以得出结论，当我们希望预测人眼在观看图像时看得最多的地方时，使用术语注视预测。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="4e00" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">摘要</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/b3ed743bd693e2a2fcebe15d38e43ae7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*m2r48HPQfjkILRk0Sezawg.png"/></div></figure><p id="4cde" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这篇文章声称，我们目前评估显著对象基准的方式存在巨大的偏差(称为数据集偏差)。(请记住，本文发表于 2014 年。)此外，本文还介绍了一种显著对象分割的新方法，该方法优于现有的模型。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="c597" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">简介</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/447bab7c493cc03da527686b90b1fdf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*MZ3pr3bmSqQrcw7sTMCWig.png"/></div></figure><p id="915b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">所以在我们继续之前，我们需要知道一个术语。</p><blockquote class="kx ky kz"><p id="e923" class="jz ka la kb b kc kd ke kf kg kh ki kj lb kl km kn lc kp kq kr ld kt ku kv kw ij bi translated"><strong class="kb ir">数据集设计偏差</strong> →一种特殊类型的偏差，由实验者对数据集图像的非自然选择引起。(更多信息<a class="ae jy" href="https://medium.com/microsoft-design/how-to-recognize-exclusion-in-ai-ec2d6d89f850" rel="noopener">请点击此处</a>)</p></blockquote><p id="cae0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这篇论文的作者告诉我们两件事。计算机视觉中的显著性不是一个明确定义的术语，它可以被理解为 a)分割，其中我们分割图像中最重要的对象，或者 b)眼睛注视预测。然而，现有的方法存在两个问题。</p><ol class=""><li id="838d" class="lz ma iq kb b kc kd kg kh kk mb ko mc ks md kw me mf mg mh bi translated">如果一个模型专注于一个问题，它往往会忽略与另一个问题的联系。</li><li id="47dd" class="lz ma iq kb b kc mi kg mj kk mk ko ml ks mm kw me mf mg mh bi translated">如果一个模型在一个数据集上进行基准测试，它往往会过度适应该数据集，从而产生固有的偏差。</li></ol></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="e867" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">相关作品</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mn"><img src="../Images/94d1f7954cb69c70fe212cfed724bd20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7ad5LrEtFBh9JSakqrOJSA.png"/></div></div></figure><p id="331c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">该论文再次描述了每个问题是什么，例如注视预测是眼睛凝视预测，并且对于显著对象分割是试图分割给定图像中最重要的对象的任务。本文还讨论了对象识别任务(我们试图在它们各自的每一类中找到对象)与显著对象分割之间的联系。最后，作者讨论了一个数据集偏差，这在视觉显著性分析中心偏差是一个巨大的问题。这是当实验参与者专注于观看图像的中心，而摄影师想要将焦点对准图像的中心时的原因。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="9f8d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">数据集分析</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/2c877b61ae6069804735dcd10f8b9e7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*nXkSr8AulJ1E-FhcVunLGg.png"/></div></figure><p id="3aab" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这一节的题目是巨大的，主要是因为它是本文的核心贡献之一。我不得不说，我不知道他们做的所有统计分析的细节，但是，一旦我研究了他们。我一定会再写一篇博文。</p><p id="61f8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">在帕斯卡数据集<br/> </strong>上的心理物理实验在这里，作者进行了一些实验来收集用于注视预测的地面真实数据<a class="ae jy" href="http://host.robots.ox.ac.uk/pascal/VOC/voc2010/" rel="noopener ugc nofollow" target="_blank">帕斯卡 2010 数据 se </a> t 上</p><p id="85d6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">评估数据集一致性</strong> <br/>为了比较不同标注者(来自之前的实验)之间的一致程度，作者进行了一些广泛的分析，以了解受试者之间的一致性。(对于显著对象分割以及注视预测)。作者发现一个有趣的事实是…..(如下所示)</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/1c19674d38182848570501ec8f48e162.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*Jj6JJKu2MmkhgmHlIxGWbg.png"/></div></figure><p id="4d2d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">基准测试<br/> </strong>在这里，作者比较了许多执行显著对象分割的先进算法，并发现当算法没有在<a class="ae jy" href="http://ivrlwww.epfl.ch/supplementary_material/RK_CVPR09/" rel="noopener ugc nofollow" target="_blank"> FT 数据集</a>上训练时，它们的性能显著下降。</p><p id="7517" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">数据集设计偏差<br/> </strong>作者在这一节真的是全力以赴，他们进行了很多统计分析，比如比较局部颜色对比度、全局颜色对比度、局部 gPB 边界强度、对象大小等。他们把建国总结成一段话</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/ca2d78f478c5e9e62293a0ac1144a76e.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*-tLKZ9x8gHQ_rLb9pBdxSA.png"/></div></figure><p id="d414" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">基本上，在 FT 数据集中，在我们想要分割的对象和该对象的背景图像之间存在强烈的对比。这使得模型更容易学习如何分割对象，但不能很好地概括。</p><p id="63ee" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">注视和 F-measure </strong> <br/>这里作者讨论了中心偏差问题的影响，以及许多最先进的算法抵消中心偏差问题的方法。例如，在<a class="ae jy" href="http://jov.arvojournals.org/article.aspx?articleid=2192215" rel="noopener ugc nofollow" target="_blank"> AWS </a>和<a class="ae jy" href="https://ieeexplore.ieee.org/document/5963689/" rel="noopener ugc nofollow" target="_blank"> SIG </a>中，他们在 s-AUC 中对其算法性能进行了基准测试，消除了中心偏差问题。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="b56a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">从注视到显著物体检测</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mr"><img src="../Images/9680d0d0914694243b3f79a421431ca9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xzzIb-NpNxy82D9q.png"/></div></div></figure><p id="62f7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于这一部分，上面的图片，一步一步地描述了作者的方法来执行显著的对象分割，这是一个惊人的工作。(他们声称这很简单，但在我看来真的一点也不简单…)</p><ol class=""><li id="d210" class="lz ma iq kb b kc kd kg kh kk mb ko mc ks md kw me mf mg mh bi translated">使用<a class="ae jy" href="http://www.robots.ox.ac.uk:5000/~vgg/rg/papers/constrainedmincut.pdf" rel="noopener ugc nofollow" target="_blank"> CPMC </a>执行无监督分割方法</li><li id="5c02" class="lz ma iq kb b kc mi kg mj kk mk ko ml ks mm kw me mf mg mh bi translated">获得对象内注视的空间分布</li><li id="10b0" class="lz ma iq kb b kc mi kg mj kk mk ko ml ks mm kw me mf mg mh bi translated">具有一个函数，其中给定一个建议的对象候选遮罩及其固定图(来自步骤 1 和 2)，估计该区域相对于地面实况的重叠分数(交集/并集)。</li></ol></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="edca" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结论</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/742b40401b58a3395fd4b4679651c40e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*Eh5_YUkK8YFdNG2obximgA.png"/></div></figure><p id="2cbf" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同样，本文已经证明了在注视预测和显著对象检测之间存在强相关性的事实。使用这种知识，他们提出了一种执行显著对象分割的新方法，其中他们首先执行片段生成过程，然后使用注视预测的显著性评分机制。最后，本文还描述了数据集中的偏差，这在视觉显著性分析中心偏差是一个巨大的问题。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="1ac3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">遗言</strong></p><p id="6ccb" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这篇论文包含了大量的信息，并且作为显著对象分割任务以及眼睛注视跟踪的非常好的介绍。非常有趣…</p><p id="3aa9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 给我，如果你想看我所有写作的列表，请<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">在这里查看我的网站</a>。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的 twitter <a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，并访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。如果你感兴趣的话，我还做了解耦神经网络的比较。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="6ac0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="40d5" class="lz ma iq kb b kc kd kg kh kk mb ko mc ks md kw me mf mg mh bi translated">李，杨，侯，x，科赫，c，瑞格，J. M .，，尤耶，A. L. (2014)。显著对象分割的秘密。佐治亚理工学院。</li><li id="d540" class="lz ma iq kb b kc mi kg mj kk mk ko ml ks mm kw me mf mg mh bi">MSRA10K Salient Object Database. (2014). 南开大学媒体计算实验室. Retrieved 28 April 2018, from <a class="ae jy" href="https://mmcheng.net/msra10k/" rel="noopener ugc nofollow" target="_blank">https://mmcheng.net/msra10k/</a></li><li id="285a" class="lz ma iq kb b kc mi kg mj kk mk ko ml ks mm kw me mf mg mh bi translated">(2018).Arxiv.org。检索于 2018 年 4 月 28 日，来自<a class="ae jy" href="https://arxiv.org/pdf/1611.09571.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1611.09571.pdf</a></li><li id="2da7" class="lz ma iq kb b kc mi kg mj kk mk ko ml ks mm kw me mf mg mh bi translated">如何识别 AI 中的排斥—微软设计—中？(2017).中等。检索于 2018 年 4 月 28 日，来自<a class="ae jy" href="https://medium.com/microsoft-design/how-to-recognize-exclusion-in-ai-ec2d6d89f850" rel="noopener">https://medium . com/Microsoft-design/how-to-recognize-exclusion-in-ai-EC 2d 6d 89 f 850</a></li><li id="a22f" class="lz ma iq kb b kc mi kg mj kk mk ko ml ks mm kw me mf mg mh bi translated">帕斯卡视觉对象类挑战 2010 (VOC2010)。(2018).Host.robots.ox.ac.uk 检索 2018 年 4 月 28 日，来自<a class="ae jy" href="http://host.robots.ox.ac.uk/pascal/VOC/voc2010/" rel="noopener ugc nofollow" target="_blank">http://host.robots.ox.ac.uk/pascal/VOC/voc2010/</a></li><li id="1d2f" class="lz ma iq kb b kc mi kg mj kk mk ko ml ks mm kw me mf mg mh bi translated">频率调谐显著区域检测。(2018).Ivrlepfl.ch 于 2018 年 4 月 28 日检索，来自 http://ivrlwww.epfl.ch/supplementary_material/RK_CVPR09/<a class="ae jy" href="http://ivrlwww.epfl.ch/supplementary_material/RK_CVPR09/" rel="noopener ugc nofollow" target="_blank"/></li><li id="891b" class="lz ma iq kb b kc mi kg mj kk mk ko ml ks mm kw me mf mg mh bi translated">图像签名:突出稀疏的显著区域。(2018).Ieeexplore.ieee.org。检索于 2018 年 4 月 28 日，来自 https://ieeexplore.ieee.org/document/5963689/<a class="ae jy" href="https://ieeexplore.ieee.org/document/5963689/" rel="noopener ugc nofollow" target="_blank"/></li><li id="2164" class="lz ma iq kb b kc mi kg mj kk mk ko ml ks mm kw me mf mg mh bi translated">加西亚-迪亚兹，a .，莱博兰，v .，Fdez-Vidal，x .，和帕尔多，X. (2012 年)。光学可变性、视觉显著性和眼睛注视之间的关系:一种计算方法。视觉杂志，12(6)，17–17。doi:10.1167/12.6.17</li></ol></div></div>    
</body>
</html>