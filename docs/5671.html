<html>
<head>
<title>A brief Introduction to Support Vector Machine</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">支持向量机简介</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-brief-introduction-to-support-vector-machine-adf0f103a80f?source=collection_archive---------14-----------------------#2018-11-02">https://towardsdatascience.com/a-brief-introduction-to-support-vector-machine-adf0f103a80f?source=collection_archive---------14-----------------------#2018-11-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/488520ccdd4819575168b74b5c706a0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QRD9cnsROioDuQ1lQeaE7g.jpeg"/></div></div></figure><p id="b71c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">支持向量机(SVM)是最流行的机器学习分类器之一。它属于监督学习算法的范畴，并使用边缘的概念在类之间进行分类。它给出了比 KNN，决策树和朴素贝叶斯分类器更好的准确性，因此非常有用。</p><h1 id="cdf1" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">谁应该阅读这篇文章</h1><p id="c0c9" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">任何对机器学习概念有所了解并对学习 SVM 感兴趣的人。如果你是这个领域的初学者，先浏览一下<a class="ae lz" rel="noopener" target="_blank" href="/machine-learning-for-beginners-d247a9420dab">这篇</a>文章。</p><p id="f76f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">读完这篇文章，你会知道:</p><ol class=""><li id="05bd" class="ma mb iq ka b kb kc kf kg kj mc kn md kr me kv mf mg mh mi bi translated">SVM 到底是什么</li><li id="ec2f" class="ma mb iq ka b kb mj kf mk kj ml kn mm kr mn kv mf mg mh mi bi translated">如何使用 Sklearn (Python)的 SVM 分类器</li><li id="2637" class="ma mb iq ka b kb mj kf mk kj ml kn mm kr mn kv mf mg mh mi bi translated">调整其参数以获得更好的结果</li></ol><p id="c23d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">所以让我们开始吧！</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h1 id="d3af" class="kw kx iq bd ky kz mv lb lc ld mw lf lg lh mx lj lk ll my ln lo lp mz lr ls lt bi translated">什么是 SVM？</h1><p id="e072" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">如前所述，SVM 属于用于分类的监督算法类别。让我们从两个类的例子开始:</p><p id="4b10" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">给定类 X1 和 X2，我们想要找到最好地分离这两个类的判定边界，即具有最小误差。</p><p id="05da" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">SVM 用一个<strong class="ka ir"> <em class="na">【超平面】</em> </strong>做到了这一点。这个超平面在二维数据的情况下可以是一条直线，在三维数据的情况下可以是一个平面。</p><figure class="nc nd ne nf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nb"><img src="../Images/329f589482187e3f5f135a8dec846217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/0*LqJ35BlMaAWGfPLv.png"/></div></div></figure><p id="0c1c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">不用深入幕后的数学，让我们了解一些基本的功能。</p><p id="4718" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">支持向量机使用了<strong class="ka ir"><em class="na">‘支持向量</em>’</strong>的概念，支持向量是离超平面最近的点。</p><p id="7ad7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在上面的例子中，红线表示分隔两个类(蓝色星形和红色圆形)的决策边界，连字符线表示我们的'<strong class="ka ir"><em class="na">' Margin '</em></strong>，即我们想要的两个类的支持向量之间的差距。</p><blockquote class="ng nh ni"><p id="5709" class="jy jz na ka b kb kc kd ke kf kg kh ki nj kk kl km nk ko kp kq nl ks kt ku kv ij bi translated">界限很重要</p></blockquote><p id="7591" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">边缘是在支持向量的帮助下定义的(因此得名)。在我们的示例中，黄色的星星和黄色的圆圈是定义边距的支持向量。间隙越大，分类器工作得越好。因此，支持向量在开发分类器中起着重要的作用。</p><p id="bb08" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">测试数据中的每一个新数据点都将根据这个余量进行分类。如果它位于它的右侧，它将被归类为红色圆圈，否则被归类为蓝色星星。</p><p id="9701" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最棒的是，SVM 还可以对非线性数据进行分类。</p><figure class="nc nd ne nf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nm"><img src="../Images/c40d70fb81c96ad17f82767f0286b87a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WPin9_Rxa7YRYGWJ.png"/></div></div></figure><p id="a7b6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在非线性数据的情况下，事情变得有点棘手。这里 SVM 使用了<strong class="ka ir">K<em class="na">ernel-trick</em>’</strong>，它使用一个核函数将非线性数据映射到更高维度，这样它就变成线性的，并在那里找到决策边界。</p><p id="404e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">无论是线性数据还是非线性数据，SVM 总是使用核函数，但当数据以其当前形式不可分时，它的主要功能就会发挥作用。这里，核函数为分类问题增加了维度。</p><p id="98fe" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在让我们看一些代码。</p></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h1 id="847e" class="kw kx iq bd ky kz mv lb lc ld mw lf lg lh mx lj lk ll my ln lo lp mz lr ls lt bi translated">使用支持向量机</h1><p id="9570" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">在 Sklearn 的帮助下，您只需几行代码就可以利用 SVM 分类器的强大功能。</p><pre class="nc nd ne nf gt nn no np nq aw nr bi"><span id="0e1f" class="ns kx iq no b gy nt nu l nv nw">from sklearn import svm </span><span id="ff03" class="ns kx iq no b gy nx nu l nv nw">#Our linear classifier<br/>clf = svm.SVC(kernel='linear') </span><span id="e32f" class="ns kx iq no b gy nx nu l nv nw">''' <br/>X_train is your training data y_train are the corresponding labels y_pred are the predicted samples of the test data X_test <br/>'''</span><span id="2134" class="ns kx iq no b gy nx nu l nv nw">#Training our classifier on training set with labels<br/>clf.fit(X_train, y_train)</span><span id="4821" class="ns kx iq no b gy nx nu l nv nw">#Predicting output on the Test set <br/>y_pred = clf.predict(X_test) </span><span id="c15e" class="ns kx iq no b gy nx nu l nv nw">#Finding the Accuracy <br/>print("Accuracy:",metrics.accuracy_score(y_test, y_pred))</span></pre><p id="03cc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这种情况下，我们使用的是线性内核，如你所见。根据问题的不同，您可以使用不同类型的内核函数:</p><ul class=""><li id="0b5e" class="ma mb iq ka b kb kc kf kg kj mc kn md kr me kv ny mg mh mi bi translated">线性的</li><li id="7e44" class="ma mb iq ka b kb mj kf mk kj ml kn mm kr mn kv ny mg mh mi bi translated">多项式</li><li id="1a84" class="ma mb iq ka b kb mj kf mk kj ml kn mm kr mn kv ny mg mh mi bi translated">径向基函数</li><li id="247e" class="ma mb iq ka b kb mj kf mk kj ml kn mm kr mn kv ny mg mh mi bi translated">高斯的</li><li id="b559" class="ma mb iq ka b kb mj kf mk kj ml kn mm kr mn kv ny mg mh mi bi translated">拉普拉斯（侯爵）</li></ul><p id="920e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">…以及更多。选择正确的核函数对于构建分类器非常重要。在下一节中，我们将调整超参数，使我们的分类器更好。</p><p id="d5ce" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你可以在这里访问完整的代码<a class="ae lz" href="https://github.com/aditya1994/Machine-Learning-Data-Science-Scripts/blob/master/SVM.py" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="0397" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你觉得无聊，这里有一只可爱的猫！</p><figure class="nc nd ne nf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nz"><img src="../Images/3969445c7920a472910c262ca32c2213.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/0*xVCO6kFL8keODteE.jpg"/></div></div></figure></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h1 id="ee31" class="kw kx iq bd ky kz mv lb lc ld mw lf lg lh mx lj lk ll my ln lo lp mz lr ls lt bi translated">调谐参数</h1><p id="a790" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><strong class="ka ir">内核</strong>:我们已经讨论过内核函数有多重要。根据问题的性质，必须选择正确的核函数，因为核函数定义了为问题选择的超平面。<a class="ae lz" href="https://data-flair.training/blogs/svm-kernel-functions/" rel="noopener ugc nofollow" target="_blank">这里的</a>是最常用的内核函数列表。</p><p id="61ff" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">正规化:听说过过度拟合这个词吗？如果你没有，我认为你应该从这里的<a class="ae lz" href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" rel="noopener ugc nofollow" target="_blank">学习一些基础知识。在 SVM，为了避免过度拟合，我们选择软边界，而不是硬边界，即我们故意让一些数据点进入我们的边界(但我们仍然惩罚它)，这样我们的分类器就不会过度拟合我们的训练样本。这里有一个重要的参数γ(γ),它控制 SVM 的过拟合。伽玛越高，超平面尝试匹配训练数据的程度越高。因此，选择最佳伽马值以避免过拟合和欠拟合是关键。</a></p><p id="ef88" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">误差罚分:</strong>参数 C 代表对 SVM 错误分类的误差罚分。它保持了更平滑的超平面和错误分类之间的折衷。如前所述，为了避免分类器过拟合，我们允许一些错误分类。</p><p id="4a87" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这些是用于调整 SVM 分类器的最重要的参数。</p><p id="d744" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">总的来说，SVM 具有许多优点，因为它提供高精度，具有低复杂性，并且对于非线性数据也非常有效。缺点是，与朴素贝叶斯等其他算法相比，它需要更多的训练时间。</p><p id="dca1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这就是支持向量机！如果你有任何问题，请在评论中告诉我。</p><p id="1fdc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">恭喜你坚持到帖子的最后！</p><p id="292a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是给你的饼干</p><figure class="nc nd ne nf gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oa"><img src="../Images/64ae0c47c90504510b9bd2b5c7340c41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WE2DXEU7XW0ieQZS.jpg"/></div></div></figure></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><blockquote class="ng nh ni"><p id="b4a2" class="jy jz na ka b kb kc kd ke kf kg kh ki nj kk kl km nk ko kp kq nl ks kt ku kv ij bi translated">如果你喜欢这篇文章，别忘了加上<em class="iq">掌声</em>！</p></blockquote><p id="8d40" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="na">原载于 2018 年 11 月 2 日</em><a class="ae lz" href="https://adityarohilla.com/2018/11/02/a-brief-introduction-to-support-vector-machine/" rel="noopener ugc nofollow" target="_blank"><em class="na">【adityarohilla.com】</em></a><em class="na">。</em></p></div></div>    
</body>
</html>