<html>
<head>
<title>Semi-Supervised Learning and GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">半监督学习和 GANs</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/semi-supervised-learning-and-gans-f23bbf4ac683?source=collection_archive---------3-----------------------#2018-04-03">https://towardsdatascience.com/semi-supervised-learning-and-gans-f23bbf4ac683?source=collection_archive---------3-----------------------#2018-04-03</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/3a1ced1e366d86acb040926def238c41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*03MhbwhjJgvPw4d8-BpysA.jpeg"/></div></div></figure><p id="be36" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">文森特·梵高在 1889 年画了这幅美丽的艺术作品:“星夜”，今天我的甘模型(我喜欢称之为甘·高:P)画了一些 MNIST 数字，只有 20%的标记数据！！它是如何实现这一非凡壮举的？…让我们来看看</p><h1 id="b3b6" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated"><strong class="ak">简介</strong></h1><p id="038a" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><strong class="ka ir"> <em class="lz">什么是半监督学习</em> </strong> <em class="lz">？</em></p><p id="c22a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">大多数深度学习分类器需要大量的标记样本才能很好地泛化，但获得这样的数据是一个昂贵而困难的过程。为了处理这种限制<em class="lz">提出了半监督学习</em>，这是一类利用少量已标记数据和大量未标记数据的技术。许多机器学习研究人员发现，未标记数据在与少量标记数据结合使用时，可以大大提高学习精度。GANs 在<em class="lz">半监督学习</em>中表现出了很大的潜力，其中分类器可以用很少的标记数据获得良好的性能。</p><p id="bdec" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="lz">甘斯背景</em> </strong></p><p id="a101" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">gan 是深度生成模型的成员。它们特别有趣，因为它们没有明确表示数据所在空间的概率分布。相反，它们通过从概率分布中抽取样本，提供了一些与概率分布不太直接交互的方式。</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ma"><img src="../Images/2bb2351295e1b904d55a7ee4f9c10ecf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ikkuGcxDBmtb6FTr."/></div></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk">Architecture of a Vanilla GAN</figcaption></figure><p id="2b37" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">甘的基本想法是在两个玩家之间建立一个<strong class="ka ir">游戏</strong>:</p><ul class=""><li id="d1c4" class="mj mk iq ka b kb kc kf kg kj ml kn mm kr mn kv mo mp mq mr bi translated">A <strong class="ka ir"> <em class="lz">发生器 G </em> </strong>:以随机噪声<strong class="ka ir"> <em class="lz"> z </em> </strong>为输入，输出一幅图像<strong class="ka ir"> <em class="lz"> x </em> </strong>。它的参数被调整，以便在它生成的假图像上从鉴别器得到高分。</li><li id="f06e" class="mj mk iq ka b kb ms kf mt kj mu kn mv kr mw kv mo mp mq mr bi translated">A <strong class="ka ir"> <em class="lz">鉴别器 D </em> </strong>:取图像<strong class="ka ir"> <em class="lz"> x </em> </strong>作为输入，输出反映其为真实图像的置信度的分数。它的参数被调整为当由真实图像馈送时具有高分，当由生成器馈送假图像时具有低分。</li></ul><p id="c262" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我建议您浏览一下<a class="ae mx" rel="noopener" target="_blank" href="/overview-of-gans-generative-adversarial-networks-part-i-ac78ec775e31">这个</a>和<a class="ae mx" href="http://blog.aylien.com/introduction-generative-adversarial-networks-code-tensorflow/" rel="noopener ugc nofollow" target="_blank">这个</a>，了解更多关于他们工作和优化目标的细节。现在，让我们稍微转动一下轮子，谈谈 GANs 最突出的应用之一，半监督学习。</p><h1 id="e29c" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated"><strong class="ak">直觉</strong></h1><p id="d1f3" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">鉴别器的标准结构只有一个输出神经元用于分类 R/F 概率。我们同时训练两个网络，并在训练后丢弃鉴别器，因为它仅用于改进生成器。</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi my"><img src="../Images/ee41632ce799949d16f854e5ca5c4dea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eUswmkbNil97ewejs_vDnQ.png"/></div></div></figure><p id="c201" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于半监督任务，除了 R/F 神经元之外，鉴别器现在将有 10 个以上的神经元用于 MNIST 数字的分类。此外，这一次它们的角色发生了变化，我们可以在训练后丢弃生成器，它的唯一目标是生成未标记的数据以提高鉴别器的性能。</p><h2 id="ba5c" class="mz kx iq bd ky na nb dn lc nc nd dp lg kj ne nf lk kn ng nh lo kr ni nj ls nk bi translated">现在，鉴别器变成了 11 类分类器，其中 1 个神经元(R/F 神经元)代表假数据输出，另外 10 个神经元代表具有类的真实数据。必须谨记以下几点:</h2><ul class=""><li id="61d0" class="mj mk iq ka b kb lu kf lv kj nl kn nm kr nn kv mo mp mq mr bi translated">当来自数据集的真实无监督数据被馈送时，断言 R/F 神经元输出标签= 0</li><li id="863c" class="mj mk iq ka b kb ms kf mt kj mu kn mv kr mw kv mo mp mq mr bi translated">当来自生成器的假的无监督数据被馈送时，断言 R/F 神经元输出标签= 1</li><li id="64c1" class="mj mk iq ka b kb ms kf mt kj mu kn mv kr mw kv mo mp mq mr bi translated">当输入实际监控数据时，置位 R/F 输出标签= 0，相应标签输出= 1</li></ul><p id="0b09" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">不同数据源的这种组合将有助于鉴别器比仅提供一部分标记数据更准确地分类。</p><h1 id="1a24" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">体系结构</h1><p id="45bd" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">现在是时候用一些代码:D 弄脏我们的手了</p><p id="6cb2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="lz">甄别器</em> </strong></p><p id="ea9d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来的架构类似于 DCGAN <a class="ae mx" href="https://arxiv.org/pdf/1511.06434.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中提出的架构。我们使用步长卷积来降低特征向量的维度，而不是任何池层，并对所有层应用一系列 leaky_relu、dropout 和 BN 来稳定学习。对于输入层和最后一层，BN 被丢弃(为了特征匹配)。最后，我们执行全局平均池，以在特征向量的空间维度上取平均值。这将张量维数压缩为一个值。拼合要素后，将添加 11 个类别的密集图层，并激活 softmax 以实现多类别输出。</p><figure class="mb mc md me gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="4148" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> <em class="lz">发电机</em> </strong></p><p id="8393" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">发生器结构被设计成反映鉴频器的空间输出。分数步长卷积用于增加表示的空间维度。噪声 z 的 4-D 张量的输入被馈送，其经历一系列转置卷积、relu、BN(除了在输出层)和丢失操作。最后，tanh 激活映射范围(-1，1)内的输出图像。</p><figure class="mb mc md me gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><h1 id="bddc" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">模型损失</h1><p id="6d97" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">我们首先通过将实际标签附加为零来为整批准备一个扩展标签。这样做是为了在输入标记数据时将 R/F 神经元输出置为 0。通过将假图像的 R/F 神经元输出置为 1，将真实图像置为 0，可以将未标记数据的鉴别器损失视为二进制 sigmoid 损失。</p><figure class="mb mc md me gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="32be" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">生成器损失是假图像损失和特征匹配损失的组合，假图像损失错误地将 R/F 神经元输出断言为 0，特征匹配损失惩罚训练数据上的某组特征的平均值和生成样本上的该组特征的平均值之间的平均绝对误差<em class="lz">。</em></p><figure class="mb mc md me gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><h1 id="b86a" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">培养</h1><p id="4762" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">训练图像的大小从[batch_size，28，28，1]调整到[batch_size，64，64，1]以适应生成器/鉴别器架构。计算损耗、精度和生成的样本，并观察其在每个时期的改进。</p><figure class="mb mc md me gt jr"><div class="bz fp l di"><div class="no np l"/></div></figure><h1 id="5a55" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">结论</h1><p id="c61f" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">由于 GPU 访问受限，训练进行了 5 个时期和 20%的标记率。为了获得更好的结果，建议使用具有更低标记率的更多训练时段。完整的代码笔记本可以在<a class="ae mx" href="https://github.com/raghav64/SemiSuper_GAN/blob/master/SSGAN.py" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><figure class="mb mc md me gt jr gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/31ee3625b646b4506983376966135752.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*IeU0yDFHjtQIVmYQCZWRJA.jpeg"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk">Training Results</figcaption></figure><p id="0e93" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">无监督学习被认为是 AGI 领域的一个空白。为了弥补这一差距，GANs 被认为是学习低标记数据复杂任务的潜在解决方案。随着半监督学习领域新方法的出现，我们可以预期这种差距将会缩小。</p><p id="96d1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果我不提及我从这个美丽的<a class="ae mx" rel="noopener" target="_blank" href="/semi-supervised-learning-with-gans-9f3cb128c5e">博客</a>，这个<a class="ae mx" href="https://github.com/nejlag/Semi-Supervised-Learning-GAN/blob/master/SSL_GAN.ipynb" rel="noopener ugc nofollow" target="_blank">实现</a>以及我在类似项目中工作的同事的帮助中获得的灵感，那将是我的失职。</p><p id="8c84" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">下次见！！Kz </strong></p></div></div>    
</body>
</html>