# 谷歌 Duplex 是否符合伦理道德？

> 原文：<https://towardsdatascience.com/is-google-duplex-ethical-and-moral-f66a23637640?source=collection_archive---------8----------------------->

[![](img/64846b7c2aaa9c7b115f6c385a5701db.png)](https://www.flickr.com/photos/142305740@N05/33433114166)

昨天，在 Google IO 期间，一个名为 [Duplex](https://ai.googleblog.com/2018/05/duplex-ai-system-for-natural-conversation.html) 的项目通过电话在对 Google 助手的请求和真实世界中的真实业务之间建立了接口。

你可以在这里看到令人印象深刻的演示:

AI 社区的许多人立即欢呼这是这些技术结合的巨大进步。

然而，有一些担忧:

虽然我总是有点怀疑对一项没有被用来做坏事的技术的任何普遍和直接的反弹，但关于这一点有非常好的观点应该讨论。

# 这合乎道德吗？

上周，我开始了微软 edX 的在线课程，名为“[数据和分析中的道德和法律](https://courses.edx.org/courses/course-v1:Microsoft+DAT249x+1T2018a/course/)我最感兴趣的是他们看待伦理价值的一个非常简单的框架。

它分为两个价值集:1)基于他人福祉的价值(在这种情况下是在公司接到电话的人)和 2)基于我自己福祉的价值(谷歌和我的混合物)。关于他人的幸福，它包括:不痛苦、自主、平等。我自己的幸福集中在优秀的品格和信任上。

让我们逐一了解这些值:

*   **无痛苦**——在这种情况下，接听电话的人似乎不会以某种方式遭受痛苦。如果有什么不同的话，我敢打赌，这部机器会以一种一致的方式更加礼貌，并且直奔主题，这样人们就不会没完没了地打电话。
*   自主性——接听电话的人仍然可以做出他们认为合适的反应，他们可以问他们需要的问题，他们甚至可以拒绝接听电话。
*   **平等** —有一种可能性是缺乏平等，因为我使用这样的服务来节省我的时间，但不尊重接收者的时间。一个很好的问题是，对于那些不尊重我通过支持自动化系统在时间上平等的愿望的企业，我们如何权衡这一点？
*   **人品卓越** —如果它确实宣布这是代表我的助理预订，我看不出这对我的人品卓越有什么损害。
*   **信任** —这是最有问题的价值观。随着越来越多这样的电话被拨打，人们会相信 Duplex 或任何他们自称的呼叫者吗？

# 道德吗？

谷歌有这项服务道德吗？可能吗？我不认为他们试图用这项技术来“作恶”。

有人使用这项服务道德吗？大概？这是基于他们的道德准则，他们也持有自己。不幸的是，我们都倾向于在不同时间持有不同道德的大杂烩。

在社会中，我们确实试图从道德上思考自己，但这实际上是法律强制执行的问题，因为除了 Twitter 上的人群呼喊之外，没有道德法庭。

# 合法吗？

根据我对 [robocalls](https://www.robokiller.com/blog/robocalls/) 的了解，是的，这是合法的。例如，对于“大量收件人”来说，它不是“不相关或不适当的”

然而，我不确定企业是否可以从技术上完全拒绝这类电话。

这是否意味着我们应该监管这些技术？大概吧。尽管如此，魔鬼绝对存在于细节之中…

虽然这是一个伟大的点，关于如何规范类比不是 100%。我们为天然气这样做不是因为这是道德/伦理的事情，而是因为它是危险的。

我最大的担忧是，当涉及到州强制规定时，它们只会让谷歌的地位更加稳固。他们有资金/时间/人员来支持采用这些标准。较小的公司由于资源有限，没有竞争力。

# 是以人为中心吗？

我发现这个问题更容易回答，我打赌这就是谷歌创造 Duplex 的原因。这对圈内的每个人都有帮助。

对于想要预订的人来说，他们可以节省打电话和与商家谈判的时间。这就是像无缝这样的服务如此受欢迎的原因。

对于接到电话的人来说，他们正在为一家不想以某种方式允许自动预订的公司工作。这是系统与之交互的最简单的方式。只是刚好是语音。

一个很大的问题是，企业是否应该选择退出这种类型的界面。当然，这可能会引起客户的敌意，但这是他们经营业务的选择。

有人问过在企业工作的人是否会介意吗？他们会在乎吗？

# 坏人呢？

大多数人关心的是其他人可能利用这项技术作恶的方式。例如，我们可以想象你可能开始接到机器人的电话，这些机器人专注于向你出售分时度假，通过要求虚假付款来欺骗你，以及一般的数据捕获。

一项技术的所有不好的使用是否意味着我们不应该拥有这项技术？事实显然并非如此。这方面的一个稻草人将是用于恐怖袭击的汽车是否应该被禁止。当然，汽车带来的好处超过了这个非常小的案例。

# 细微差别

如果有的话，这是一个棘手的话题。需要对上下文进行细微的区分。

这将会引起很多愤怒和偏袒。

我们应该进行这些讨论，我们应该谈谈，在我们生活的这个混乱的世界里，相信我们所相信的东西意味着什么。

我很想听听你的想法。

# 关于克里斯·巴特勒

我帮助团队理解他们应该用以人工智能为中心的解决方案解决的真正的商业问题。我们工作的团队通常被要求用他们拥有的数据“做一些有趣的事情”。我们通过偶发事件相关性帮助他们避免局部极值，并专注于解决巨大的业务问题。我的背景包括在微软、KAYAK 和 Waze 等公司超过 18 年的产品和业务开发经验。在 Philosophie，我创造了像机器的[移情映射](https://uxdesign.cc/robots-need-love-too-empathy-mapping-for-ai-59585ad3548d)和[困惑映射](/robots-are-wrong-too-confusion-mapping-for-the-worst-case-2e01b7e19936)这样的技术，以便在构建人工智能产品时创建跨团队的一致性。如果你想了解更多或通过、[、LinkedIn](https://www.linkedin.com/in/chrisbu/) 或访问[、http://philosophie.is/human-centered-ai](http://philosophie.is/human-centered-ai)与[联系。](mailto:chrisbutler@philosophie.is)