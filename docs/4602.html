<html>
<head>
<title>How to Run Parallel Data Analysis in Python using Dask Dataframes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用 Dask 数据帧在 Python 中运行并行数据分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/trying-out-dask-dataframes-in-python-for-fast-data-analysis-in-parallel-aa960c18a915?source=collection_archive---------1-----------------------#2018-08-25">https://towardsdatascience.com/trying-out-dask-dataframes-in-python-for-fast-data-analysis-in-parallel-aa960c18a915?source=collection_archive---------1-----------------------#2018-08-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/5f0c3d8ecb70794fdbf6fa63524f7e68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SQtRhdtx46Lq1LLvFwbc0Q.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Your mind on multi-cores. source: <a class="ae kc" href="https://pixabay.com/en/universe-star-space-cosmos-sky-1351865/" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><p id="5209" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">有时候，你打开一个包含 Python 的熊猫的大数据集，试图获得一些指标，整个事情就可怕地冻结了。<br/>如果你从事大数据工作，你知道如果你使用熊猫，你可能会为一个系列的简单平均值等待整整一分钟，我们甚至不要调用<em class="lb">应用</em>。这只是几百万行的数据！当你达到数十亿时，你最好开始使用 Spark 或其他东西。</p><p id="7815" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">不久前我发现了这个工具:一种加速 Python 中数据分析的方法，而不必获得更好的基础设施或转换语言。如果你的数据集很大，它最终会感到有限，但它比普通的熊猫要好得多，可能正好适合你的问题——特别是如果你没有做大量的重新索引。</p><p id="8bc1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">可以在</em> <a class="ae kc" href="https://www.saturncloud.io/s/freehosted/?utm_source=Luciano%20Strika-%20Dask%20Dataframes&amp;utm_medium=saturn%20free%20hosted" rel="noopener ugc nofollow" target="_blank"> <em class="lb">土星云</em> </a> <em class="lb">上马上免费使用 Dask！<br/>土星云是一个端到端的数据科学+机器学习平台，允许数据科学家在云中使用 Dask 扩展他们的 Python 项目。</em></p><h2 id="182a" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">Dask 是什么？</h2><p id="5a6f" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">Dask 是一个开源项目，它为您提供了对 NumPy 数组、Pandas 数据帧和常规列表的抽象，允许您使用多核处理对它们并行运行操作。</p><p id="49b9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里有一段直接来自教程的摘录:</p><blockquote class="ma mb mc"><p id="8dc5" class="kd ke lb kf b kg kh ki kj kk kl km kn md kp kq kr me kt ku kv mf kx ky kz la ij bi translated">Dask 提供了模拟 NumPy、lists 和 Pandas 的高级数组、Bag 和 DataFrame 集合，但可以在不适合主存的数据集上并行操作。对于大型数据集，Dask 的高级集合是 NumPy 和 Pandas 的替代方案。</p></blockquote><p id="5b55" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">听起来就很牛逼！我开始尝试本文的 Dask 数据框架，并对它们运行了几个基准测试。</p><p id="1d06" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">(要查看 Dask 在机器学习中的更多应用，请查看我的</em> <a class="ae kc" href="https://www.datastuff.tech/machine-learning/k-means-clustering-unsupervised-learning-for-recommender-systems/" rel="noopener ugc nofollow" target="_blank"> <em class="lb">并行 k 均值聚类教程</em> </a> <em class="lb"> ) </em></p><h2 id="371a" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">阅读文档</h2><p id="2f25" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">我做的第一件事是阅读官方文档，看看在 Dask 的而不是常规数据帧中到底推荐做什么。以下是来自<a class="ae kc" href="http://dask.pydata.org/en/latest/dataframe.html" rel="noopener ugc nofollow" target="_blank">官方文件</a>的相关部分:</p><ul class=""><li id="ccbd" class="mg mh iq kf b kg kh kk kl ko mi ks mj kw mk la ml mm mn mo bi translated">操作大型数据集，即使这些数据集不适合内存</li><li id="91a2" class="mg mh iq kf b kg mp kk mq ko mr ks ms kw mt la ml mm mn mo bi translated">通过使用多个内核加速长时间计算</li><li id="077d" class="mg mh iq kf b kg mp kk mq ko mr ks ms kw mt la ml mm mn mo bi translated">使用标准的 Pandas 操作(如 groupby、join 和时序计算)对大型数据集进行分布式计算</li></ul><p id="7865" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，它列出了一些使用 Dask 数据帧时速度非常快的东西:</p><ul class=""><li id="740f" class="mg mh iq kf b kg kh kk kl ko mi ks mj kw mk la ml mm mn mo bi translated">算术运算(乘法或加法)</li><li id="48f8" class="mg mh iq kf b kg mp kk mq ko mr ks ms kw mt la ml mm mn mo bi translated">常见聚合(平均值、最小值、最大值、总和等。)</li><li id="3334" class="mg mh iq kf b kg mp kk mq ko mr ks ms kw mt la ml mm mn mo bi translated">调用<em class="lb"> apply(只要它沿着索引-也就是说，不在 groupby('y ')之后，其中' y '不是索引-) </em></li><li id="6ba5" class="mg mh iq kf b kg mp kk mq ko mr ks ms kw mt la ml mm mn mo bi translated">调用 value_counts()、drop_duplicates()或 corr()</li><li id="0f7c" class="mg mh iq kf b kg mp kk mq ko mr ks ms kw mt la ml mm mn mo bi translated">用<em class="lb"> loc </em>、<em class="lb"> isin </em>过滤，行选择</li></ul><figure class="mu mv mw mx gt jr"><div class="bz fp l di"><div class="my mz l"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Just a small brush up on filtering Dataframes, in case you find it useful.</figcaption></figure><h2 id="d71a" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">如何使用 Dask 数据帧</h2><p id="00aa" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">Dask 数据帧与 Pandas 数据帧具有相同的 API，除了聚合和<em class="lb">应用</em>被延迟计算，并且需要通过调用<em class="lb">计算</em>方法来计算。为了生成 Dask 数据帧，你可以像在 Pandas 中一样简单地调用<em class="lb"> read_csv </em>方法，或者，给定一个 Pandas 数据帧<em class="lb"> df </em>，你可以只调用</p><pre class="mu mv mw mx gt na nb nc nd aw ne bi"><span id="04b3" class="lc ld iq nb b gy nf ng l nh ni">dd = ddf.from_pandas(df, npartitions=N)</span></pre><p id="4c8e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">其中<em class="lb"> ddf </em>是您导入 Dask 数据帧时使用的名称，而<em class="lb"> npartitions </em>是告诉数据帧您想要如何对其进行分区的参数。</p><p id="9f38" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据 StackOverflow 的说法，建议将数据帧划分为与计算机内核数量一样多的分区，或者是该数量的几倍，因为每个分区将在不同的线程上运行，如果数量太多，它们之间的通信将变得过于昂贵。</p><h2 id="b580" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">变脏:让我们进行基准测试！</h2><p id="b519" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">我做了一个 Jupyter 笔记本来测试这个框架，并在 Github 上发布了这个框架，以防你想亲自测试或者运行它。</p><p id="2144" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我运行的基准测试可在 Github 的笔记本中找到，但以下是主要的测试:</p><figure class="mu mv mw mx gt jr"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="1e96" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这里<em class="lb"> df3 </em>是一个普通的熊猫数据帧，有 2500 万行，使用我的<a class="ae kc" href="http://www.datastuff.tech/data-science/exploratory-data-analysis-with-pandas-and-jupyter-notebooks/" rel="noopener ugc nofollow" target="_blank">熊猫教程</a>中的脚本生成(列是<em class="lb">姓名</em>和<em class="lb">薪水</em>，从列表中随机抽取)。我取了一个 50 行的数据集，并将其连接了 500000 次，因为我对分析本身并不太感兴趣，而只对运行它所花费的时间感兴趣。</p><p id="5b63" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb"> dfn </em>就是基于<em class="lb"> df3 </em>的 Dask 数据帧。</p><h2 id="aa9d" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">第一批结果:不太乐观</h2><p id="9601" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">我首先用 3 个分区进行了测试，因为我只有 4 个内核，不想让我的电脑超负荷工作。我在 Dask 上得到了非常糟糕的结果，也不得不等待很长时间才能得到它们，但我担心这可能是因为我做的分区太少了:</p><pre class="mu mv mw mx gt na nb nc nd aw ne bi"><span id="5cfa" class="lc ld iq nb b gy nf ng l nh ni">204.313940048 seconds for get_big_mean<br/>39.7543280125 seconds for get_big_mean_old</span><span id="fb60" class="lc ld iq nb b gy nj ng l nh ni">131.600986004 seconds for get_big_max<br/>43.7621600628 seconds for get_big_max_old</span><span id="07b9" class="lc ld iq nb b gy nj ng l nh ni">120.027213097 seconds for get_big_sum<br/>7.49701309204 seconds for get_big_sum_old</span><span id="5c64" class="lc ld iq nb b gy nj ng l nh ni">0.581165790558 seconds for filter_df<br/>226.700095892 seconds for filter_df_old</span></pre><p id="5883" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以看到，当我使用 Dask 时，大多数操作都变慢了很多。这给了我暗示，我可能不得不使用更多的分区。生成惰性求值所花费的时间也可以忽略不计(在某些情况下不到半秒)，所以如果我重用它们，它不会随着时间的推移而摊销。</p><p id="e406" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我还用<em class="lb">应用</em>方法尝试了这个测试:</p><figure class="mu mv mw mx gt jr"><div class="bz fp l di"><div class="my mz l"/></div></figure><p id="57a2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">得到了非常相似的结果:</p><pre class="mu mv mw mx gt na nb nc nd aw ne bi"><span id="cffa" class="lc ld iq nb b gy nf ng l nh ni">369.541605949 seconds for apply_random<br/>157.643756866 seconds for apply_random_old</span></pre><p id="5e6b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，一般来说，大多数操作变得比原来慢两倍，尽管过滤器快得多。我担心也许我也应该调用<em class="lb">计算机</em>来处理这个问题，所以对这个结果要有所保留。</p><h2 id="1a69" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">更多分区:惊人的速度</h2><p id="6107" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">在这样令人沮丧的结果之后，我认为可能是我没有使用足够的分区。毕竟，这样做的全部意义在于并行运行，所以也许我只需要更多的并行化？因此，我对 8 个分区进行了相同的测试，下面是我得到的结果(我省略了非并行数据帧的结果，因为它们基本相同):</p><pre class="mu mv mw mx gt na nb nc nd aw ne bi"><span id="fea8" class="lc ld iq nb b gy nf ng l nh ni">3.08352184296 seconds for get_big_mean<br/>1.3314101696 seconds for get_big_max<br/>1.21639800072 seconds for get_big_sum<br/>0.228978157043 seconds for filter_df</span><span id="40ef" class="lc ld iq nb b gy nj ng l nh ni">112.135010004 seconds for apply_random<br/>50.2007009983 seconds for value_count_test</span></pre><p id="706f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">没错！大多数操作比常规数据帧快十倍以上，甚至<em class="lb">应用</em>也变得更快了！我还运行了<em class="lb"> value_count </em>测试，它只是在<em class="lb"> salary </em>系列上调用了<em class="lb"> value_count </em>方法。对于上下文，请记住，当我在常规数据帧上运行这个测试时，在等待了整整十分钟之后，我不得不终止这个进程。这次只用了 50 秒！<br/>所以基本上我只是用错了工具，而且速度相当快。比普通的数据帧快得多。</p><h2 id="1f35" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">最终外卖</h2><p id="3900" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">鉴于我们刚刚在一台非常旧的 4 核电脑上一分钟内处理了 2500 万行数据，我可以想象这在行业内会有多么巨大。所以我的建议是，下次您必须在本地或从单个 AWS 实例处理数据集时，尝试一下这个框架。相当快。</p><p id="0dc6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我希望你觉得这篇文章有趣或有用！编写它花费的时间比我预期的要多得多，因为一些基准测试花费了<em class="lb">这么长的时间</em>。请告诉我在阅读本文之前您是否听说过 Dask，以及您是否在工作中或项目中使用过它。也请告诉我是否还有其他我没有提到的很酷的特性，或者我做错了什么！你的反馈和评论是我写作的最大原因，因为我也在从中学习。</p><h2 id="3177" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">数据科学家的进一步阅读:</h2><ul class=""><li id="a2a5" class="mg mh iq kf b kg lv kk lw ko nk ks nl kw nm la ml mm mn mo bi translated"><a class="ae kc" href="https://www.datastuff.tech/machine-learning/autoencoder-deep-learning-tensorflow-eager-api-keras/" rel="noopener ugc nofollow" target="_blank">自动编码器:深度学习与 TensorFlow 的热切执行</a>其中我介绍了 TensorFlow 的 Keras API，并训练自动编码器进行图像压缩。</li><li id="85cb" class="mg mh iq kf b kg mp kk mq ko mr ks ms kw mt la ml mm mn mo bi translated"><a class="ae kc" href="https://www.datastuff.tech/machine-learning/lstm-how-to-train-neural-networks-to-write-like-lovecraft/" rel="noopener ugc nofollow" target="_blank"> LSTM:教神经网络像洛夫克拉夫特一样写作</a>在这里我解释了 LSTM 神经网络是如何工作的，并用它来生成文本。</li><li id="ed88" class="mg mh iq kf b kg mp kk mq ko mr ks ms kw mt la ml mm mn mo bi translated"><a class="ae kc" href="https://www.datastuff.tech/data-science/5-probability-distributions-every-data-scientist-should-know/" rel="noopener ugc nofollow" target="_blank">每个数据科学家都应该知道的 5 种概率分布</a>在这些概率分布中，你可以学到一些非常常用的统计学基础知识……以及不那么基础的知识。</li></ul><p id="e8e1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="lb">关注我，获取更多 Python 教程、技巧和诀窍！如果您喜欢这篇文章，请查看我的网站</em>  <em class="lb">或关注我的微博</em><a class="ae kc" href="http://twitter.com/strikingloo" rel="noopener ugc nofollow" target="_blank"><em class="lb"/></a><em class="lb">。</em></p><p id="89fa" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你想成为一名数据科学家，可以看看我推荐的<a class="ae kc" href="https://www.datastuff.tech/data-science/3-machine-learning-books-that-helped-me-level-up-as-a-data-scientist/" rel="noopener ugc nofollow" target="_blank">机器学习书籍</a>。</p></div></div>    
</body>
</html>