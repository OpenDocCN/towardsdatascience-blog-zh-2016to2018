<html>
<head>
<title>Implementation of Cluster Centroid based Majority Under-sampling Technique (CCMUT) in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于聚类质心的多数欠采样技术在 Python 中的实现</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementation-of-cluster-centroid-based-majority-under-sampling-technique-ccmut-in-python-f006a96ed41c?source=collection_archive---------7-----------------------#2018-10-25">https://towardsdatascience.com/implementation-of-cluster-centroid-based-majority-under-sampling-technique-ccmut-in-python-f006a96ed41c?source=collection_archive---------7-----------------------#2018-10-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/6ecf1186f3609201bef15ec061ce1a00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QTgZPY8w8-kdMh_xL1hkyg.jpeg"/></div></div></figure><p id="ab2c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在机器学习和深度学习中，<strong class="kd iu">数据不平衡</strong>分别是许多分类算法和深度神经网络性能下降的主要原因。<strong class="kd iu">不平衡数据</strong>是指属于不同类或类别的实例或样本数量不相等，差异显著。二进制不平衡数据的一个这样的例子是 19668 个，其中有 2 个类，但包含不相等数量的实例，76，090 个实例带有标签“0 ”,而 76，090 个实例带有标签“1 ”:</p><figure class="la lb lc ld gt ju gh gi paragraph-image"><div class="gh gi kz"><img src="../Images/3009916f03d08d725287a3cc6e61a1b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*E4WS0UjX99kO1M33BPqZCQ.png"/></div><figcaption class="le lf gj gh gi lg lh bd b be z dk"><strong class="bd li">Binary Imbalanced Data</strong></figcaption></figure><p id="a1e4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了最小化不平衡的程度，必须将<strong class="kd iu">数据挖掘</strong>和<strong class="kd iu">特征空间几何</strong>整合到解决机器学习分类问题的经典方法中。有许多用于数据平衡的数据挖掘方法。一种重要的方法是<strong class="kd iu">基于聚类质心的多数欠采样技术</strong> ( <strong class="kd iu"> CCMUT </strong>)。</p><p id="12a3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在多数欠采样中，不重要(或不那么重要)的实例在多数样本中被移除。在 CCMUT 中，重要和不重要实例的划分是通过使用特征空间几何上的<strong class="kd iu">聚类</strong>概念来完成的。</p><p id="7923" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">聚类是一种无监督的学习方法。但是 CCMUT 仅使用寻找聚类质心的概念(聚类是围绕属于多数类的数据点创建的)，因为实例已经被标记。通过在属于特征空间中多数类的数据点上获得所有特征的平均特征向量<strong class="kd iu">来找到聚类质心。</strong></p><p id="5bea" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在找到多数类的聚类质心之后，在特征空间中距离聚类质心<strong class="kd iu">最远的属于该聚类(多数类)的实例</strong>被认为是最不重要的实例。相反，属于多数类的实例，即在特征空间中最接近聚类质心的实例<strong class="kd iu">，</strong>被认为是最重要的实例。</p><p id="b2e8" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">因此，在 CCMUT 中，属于多数类的实例根据其重要性被删除，欠采样的样本数取决于欠采样或 CCMUT 的<strong class="kd iu"> %。</strong></p></div><div class="ab cl lj lk hx ll" role="separator"><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo lp"/><span class="lm bw bk ln lo"/></div><div class="im in io ip iq"><p id="395b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">CCMUT 的 Python 实现:</strong></p><p id="d7c0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">从实现角度来看，特征空间几何中的所有距离都被认为是<strong class="kd iu">欧几里德距离</strong>。</p><p id="7276" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">下面以函数 CCMUT()的形式给出了 CCMUT 的 Python 实现，它采用:</p><ol class=""><li id="ee14" class="lq lr it kd b ke kf ki kj km ls kq lt ku lu ky lv lw lx ly bi translated">多数样本矩阵= X</li><li id="be23" class="lq lr it kd b ke lz ki ma km mb kq mc ku md ky lv lw lx ly bi translated">CCMUT 或欠采样的百分比= f</li></ol><p id="6590" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">作为自变量，并返回欠采样后的多数样本矩阵= X_f。</p><pre class="la lb lc ld gt me mf mg mh aw mi bi"><span id="0b7f" class="mj mk it mf b gy ml mm l mn mo">import numpy as np<br/>from math import sqrt</span><span id="aad3" class="mj mk it mf b gy mp mm l mn mo">def <strong class="mf iu">CCMUT</strong>(X,f):<br/>    # 1. finding cluster centroid....<br/>    cluster_centroid = np.sum(X,axis=0)/X.shape[0]<br/>    # 2. finding <strong class="mf iu">Euclidean Distance </strong>from cluster centroid to samples<br/>    euclidean = [None]*X.shape[0]<br/>    for i in range(0,X.shape[0]):<br/>        euclidean[i] = sqrt(sum((cluster_centroid-X[i])**2))<br/>    # 3. tracking indices of samples in descending order of distance<br/>    indices = list(reversed(sorted(range(len(euclidean)), <br/>    key = lambda j: euclidean[j])))<br/>    # 4. removing the instances or under-sampling order-wise....<br/>    X_f = np.delete(X, indices[:int(f/100*X.shape[0])], axis=0)<br/>    # 5. returning the under-sampled Majority Sample Matrix<br/>    return X_f</span></pre><p id="9a15" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">因此，使用多数样本矩阵和%欠采样调用 CCMUT()，将获得欠采样多数样本矩阵。显然，在欠采样之后，它不会以大幅度或差异被称为<strong class="kd iu">多数。</strong></p><p id="8290" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">此后，欠采样的多数样本矩阵可以与少数样本矩阵连接(在 CCMUT 之前被分离),并被混洗以用于使用机器学习的预测分析或预测分类模型开发。</p><p id="ef56" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">也有许多可用的研究，其中 CCMUT 已被直接应用或经过某些修正。</p><ol class=""><li id="3cc5" class="lq lr it kd b ke kf ki kj km ls kq lt ku lu ky lv lw lx ly bi translated">使用 AdaBoost 改进说话人确认决策的基于聚类的欠采样技术<em class="mq">IAPR 模式识别统计技术国际联合研讨会(SSPR) </em>。施普林格，柏林，海德堡，2004。</li><li id="eaa2" class="lq lr it kd b ke lz ki ma km mb kq mc ku md ky lv lw lx ly bi translated">甄子丹、秀珍和李月诗。"不平衡数据分布的基于聚类的欠采样方法."<em class="mq">专家系统与应用</em>36.3(2009):5718–5727。</li><li id="1556" class="lq lr it kd b ke lz ki ma km mb kq mc ku md ky lv lw lx ly bi translated">拉赫曼、莫斯塔菲祖尔和戴维斯。“不平衡心血管数据的基于聚类的欠采样。”世界工程大会会议录。第三卷。2013.</li><li id="c4c6" class="lq lr it kd b ke lz ki ma km mb kq mc ku md ky lv lw lx ly bi translated">Sobhani，Parinaz，Herna Viktor 和 Stan Matwin。“使用集成方法和基于聚类的欠采样从不平衡数据中学习。”<em class="mq">采矿复杂模式新前沿国际研讨会</em>。施普林格，查姆，2014 年。</li><li id="f264" class="lq lr it kd b ke lz ki ma km mb kq mc ku md ky lv lw lx ly bi translated">Srividhya 和 R. Mallika。"基于欠采样的聚类同心圆处理不平衡数据."<em class="mq">中东科学研究杂志</em>24(2016):314–319。</li><li id="2e2e" class="lq lr it kd b ke lz ki ma km mb kq mc ku md ky lv lw lx ly bi translated">阿奴拉达、那伽苏里和 g .帕萨萨拉迪瓦尔玛。"基于抽样技术聚类的非平衡数据分类方法."<em class="mq">印度科技期刊</em> 10.18 (2017)。</li><li id="856b" class="lq lr it kd b ke lz ki ma km mb kq mc ku md ky lv lw lx ly bi translated">阿拉法特，医学博士亚希尔，萨贝拉霍克，和万德医学博士法里德。“基于聚类的欠采样随机森林多类不平衡分类。”<em class="mq"> 2017 第十一届软件、知识、信息管理与应用国际会议(SKIMA) </em>。IEEE，2017。</li></ol></div></div>    
</body>
</html>