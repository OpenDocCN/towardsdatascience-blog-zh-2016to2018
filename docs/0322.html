<html>
<head>
<title>Natural Language Processing with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python进行自然语言处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/natural-language-processing-with-python-b3aad16f578f?source=collection_archive---------3-----------------------#2017-04-17">https://towardsdatascience.com/natural-language-processing-with-python-b3aad16f578f?source=collection_archive---------3-----------------------#2017-04-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="ae6b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有许多方法可以使用自然语言处理，也称为NLP。在这篇博客中，我们将讨论计数矢量器，以及它在制作模型时如何有用。</p><p id="78da" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们从什么是NLP开始。这是一种将单词转化为数值的方法，这样我们就可以根据这些数据进行分析并建立预测模型。</p><p id="aa3f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我喜欢用例子来展示，所以今天我们将根据类别用不同的电子邮件从sklearn中读取数据集。我们将只阅读其中的四个类别，并在它们上面练习使用nlp。我们将制作一个模型来确定电子邮件是否属于某个类别。</p><p id="f750" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我们需要阅读一些字典</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="3acd" class="ku kv iq kq b gy kw kx l ky kz"><strong class="kq ir">import</strong> <strong class="kq ir">pandas</strong> <strong class="kq ir">as</strong> <strong class="kq ir">pd</strong><br/><strong class="kq ir">import</strong> <strong class="kq ir">numpy</strong> <strong class="kq ir">as</strong> <strong class="kq ir">np</strong><br/><strong class="kq ir">import</strong> <strong class="kq ir">matplotlib.pyplot</strong> <strong class="kq ir">as</strong> <strong class="kq ir">plt</strong><br/>%matplotlib inline<br/><em class="la"><br/># Getting that SKLearn Dataset</em> <br/><strong class="kq ir">from</strong> <strong class="kq ir">sklearn.datasets</strong> <strong class="kq ir">import</strong> fetch_20newsgroups</span></pre><p id="c8f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这给了我们一些可以使用的库，并通过我们的电子邮件信息从sklearn导入数据集。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="f18f" class="ku kv iq kq b gy kw kx l ky kz">categories = [<br/>    'alt.atheism',<br/>    'talk.religion.misc',<br/>    'comp.graphics',<br/>    'sci.space',<br/>]<br/><em class="la"># Setting out training data</em><br/>data_train = fetch_20newsgroups(subset='train',categories=categories,<br/>                                shuffle=True, random_state=42,<br/>                                remove=('headers', 'footers', 'quotes'))<br/><em class="la"># Setting our testing data</em><br/>data_test = fetch_20newsgroups(subset='test', categories=categories,<br/>                               shuffle=True, random_state=42,<br/>                               remove=('headers', 'footers', 'quotes'))</span></pre><p id="34c9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这个代码块中，我们决定了我们想要的4个类别。然后制作我们的训练集和测试集。我们将类别设置为与上述四个类别相同，并删除了页眉、页脚和引号。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="e44f" class="ku kv iq kq b gy kw kx l ky kz">data_train.keys() #tells us what keys are in our dataset</span><span id="0071" class="ku kv iq kq b gy lb kx l ky kz">len(data_train['data']) #looks at the length of the data_train<br/>len(data_train['target'])#looks at the length of the data_test</span></pre><p id="98fe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们要确保数据列和目标列的长度相等，否则在建模时会出现错误。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="eac2" class="ku kv iq kq b gy kw kx l ky kz"><strong class="kq ir">from</strong> <strong class="kq ir">sklearn.feature_extraction.text</strong> <strong class="kq ir">import</strong> CountVectorizer<br/><em class="la"><br/># Setting the vectorizer just like we would set a model</em> <br/>cvec = CountVectorizer(stop_words='english')</span><span id="de06" class="ku kv iq kq b gy lb kx l ky kz"><em class="la"># Fitting the vectorizer on our training data</em> cvec.fit(data_train['data'])</span></pre><p id="72f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将cvec设置为等于CountVectorizer，这样以后就可以方便地调用它了。此外，我在stop_words = 'english '中添加了。这是用我们常用的英语单词，如“the”、“a”、“and”等。这是有用的，所以我们不要把我们的模型建立在这些实际上没有预测意义的单词上。然后，它需要安装在data_train['data']上。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="427d" class="ku kv iq kq b gy kw kx l ky kz">X_train = pd.DataFrame(cvec.transform(data_train['data']).todense(),<br/>                       columns=cvec.get_feature_names())</span></pre><p id="7bd3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这一步是转换训练数据。的。todense()将把它变成一个矩阵(并且很容易转换成pandas DataFrame)。使columns = cvec.get_feature_names()将使每一列等于我们正在分析的一个不同的单词。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="ef19" class="ku kv iq kq b gy kw kx l ky kz"><em class="la"># Which words appear the most.</em><br/>word_counts = X_train.sum(axis=0)<br/>word_counts.sort_values(ascending = False).head(20)</span></pre><p id="47c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我制作了一个单词计数器，它将查看我们转换后的X_train并向上计数单词，制作sort_values(升序= False)将从最高计数的单词开始，到最低计数的单词。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="f609" class="ku kv iq kq b gy kw kx l ky kz">names = data_train['target_names']</span></pre><p id="7892" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">名称现在等于我们最初读入数据帧的4个类别。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="af57" class="ku kv iq kq b gy kw kx l ky kz">X_test = pd.DataFrame(cvec.transform(data_test['data']).todense(),<br/>                      columns=cvec.get_feature_names())</span></pre><p id="c006" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，我们需要像上面对X_train所做的那样转换我们的X_test。</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="51c4" class="ku kv iq kq b gy kw kx l ky kz">y_test = data_test['target']</span></pre><p id="8141" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">并设置我们的y_test来测试我们的模型有多精确</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="3ee4" class="ku kv iq kq b gy kw kx l ky kz"><strong class="kq ir">from</strong> <strong class="kq ir">sklearn.linear_model</strong> <strong class="kq ir">import</strong> LogisticRegression<br/>lr = LogisticRegression()<br/>lr.fit(X_train, y_train) <br/>lr.score(X_test, y_test)</span></pre><p id="9283" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的最后一步是在X_train和y_train上拟合我们的模型，然后在X_test和y_test上测试我们的模型。lr.score(X_test，y_test)让我们知道我们的模型执行得有多好。在这种情况下，它大约有75%准确性。</p></div></div>    
</body>
</html>