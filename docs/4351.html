<html>
<head>
<title>Fine-tuning XGBoost in Python like a boss</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">像老板一样在 Python 中微调 XGBoost</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fine-tuning-xgboost-in-python-like-a-boss-b4543ed8b1e?source=collection_archive---------0-----------------------#2018-08-10">https://towardsdatascience.com/fine-tuning-xgboost-in-python-like-a-boss-b4543ed8b1e?source=collection_archive---------0-----------------------#2018-08-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="b698" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">XGBoost(或 e<strong class="jp ir">X</strong>treme<strong class="jp ir">G</strong>radient<strong class="jp ir">Boost</strong>ing)不再被引入，它在太多的数据科学竞赛中被证明是相关的，如果你刚刚开始使用它，它仍然是一个很难微调的模型。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/4918c75ee0ca37c485544492a783037b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b7nswbO9BHxFvO4TfFCU_Q@2x.jpeg"/></div></div></figure><p id="d61b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为什么微调是关键？因为如果你有大数据集，你对 5 个不同的参数进行简单的网格搜索，每个参数有 5 个可能的值，那么你将有 5⁵= 3125 次迭代。如果一次迭代需要运行 10 分钟，那么在获得参数之前，您将有超过 21 天的等待时间(我不说 Python 崩溃，不让您知道，并且您在意识到它之前等待了太长时间)。</p><p id="8271" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这里，我想你首先正确地完成了你的特性工程工作。特别是分类特征，因为 XGBoost 不接受输入中的分类特征。</p><h1 id="6b8a" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">1.列车测试分割、评估指标和提前停车</h1><p id="5d70" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">在进行参数优化之前，先花些时间设计模型的诊断框架。</p><p id="eb0a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">XGBoost Python api 提供了一种方法，通过增量树的数量来评估增量性能。它使用两个参数:“eval _ set”——通常是训练集和测试集——以及相关的“eval_metric”来测量这些评估集上的误差。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="8789" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">绘制结果的时间:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/4f0f2a9dd36c1278ca4ba307ce25cf60.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*abL-fkJnhfOzdpGwRGSzMA.png"/></div></figure><p id="e2d5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在分类误差图上:看起来我们的模型学习了很多，直到 350 次迭代，然后误差非常缓慢地减少。这反映在测试集上，当迭代次数从 350 增加时，我们不一定看到性能。有了这个，你已经可以考虑在 350 棵树后进行切割，并为将来的参数调整节省时间。</p><p id="cc8b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你不使用 scikit-learn api，而是使用纯 XGBoost Python api，那么还有<a class="ae md" href="https://xgboost.readthedocs.io/en/latest/python/python_intro.html#early-stopping" rel="noopener ugc nofollow" target="_blank">提前停止参数</a>，它可以帮助你自动减少树的数量。</p><h1 id="0649" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">2.是时候微调我们的模型了</h1><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="ma mb l"/></div></figure><p id="6184" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当您还没有运行任何模型时，从哪里开始呢？</p><ol class=""><li id="062b" class="me mf iq jp b jq jr ju jv jy mg kc mh kg mi kk mj mk ml mm bi translated">为关键输入填充合理的值:<br/><strong class="jp ir">learning _ rate</strong>:0.01<br/><strong class="jp ir">n _ estimators</strong>:100 如果你的数据量很大，1000 如果是中低的<br/><strong class="jp ir">max _ depth</strong>:3<br/><strong class="jp ir">子样本</strong>:0.8<br/><strong class="jp ir">col sample _ bytree</strong>:1<br/><strong class="jp ir">gamma</strong></li><li id="66e2" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">运行 model.fit(eval_set，eval_metric)并诊断您的第一次运行，特别是 n_ <strong class="jp ir">估计器</strong>参数</li><li id="378a" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">优化<strong class="jp ir">最大深度</strong>参数。它表示每棵树的深度，即每棵树中使用的不同特征的最大数量。我建议从一个低的<strong class="jp ir"> max_depth </strong>(例如 3)开始，然后递增 1，当增加它没有性能增益时停止。这将有助于简化您的模型，避免过度拟合</li><li id="0a6f" class="me mf iq jp b jq mn ju mo jy mp kc mq kg mr kk mj mk ml mm bi translated">现在玩一下学习率和避免过拟合的特性:<br/> <strong class="jp ir"> learning_rate </strong>:通常在 0.1 到 0.01 之间。如果你关注的是性能，并且有足够的时间，在增加树的数量的同时，逐渐降低学习速度。<br/> <strong class="jp ir">子样本</strong>，这是每棵树用于构建该树的行数百分比。我建议不要取出太多行，因为性能会下降很多。取 0.8 到 1 之间的值。<br/> <strong class="jp ir"> colsample_bytree </strong>:每棵树使用的列数。为了避免一些列在预测中占据过多的份额(就像在推荐系统中，当你推荐了购买最多的产品而忘记了长尾理论)，去掉一个适当比例的列。如果您有许多列(尤其是如果您进行了一次热编码)，则值为 0.3 到 0.8；如果您只有几列，则值为 0.8 到 1。<br/> <strong class="jp ir"> gamma </strong>:通常被误解的参数，它作为一个正则化参数。要么 0，要么 1，要么 5。</li></ol><p id="7649" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可以走了！</p><p id="9ce5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">参数<strong class="jp ir"> base_score </strong>什么都没给我。要么是和收敛没关系，要么是不知道怎么用。</p><h1 id="c5e5" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">3.其他备注</h1><p id="b246" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">查看<a class="ae md" rel="noopener" target="_blank" href="/interpreting-random-forest-and-other-black-box-models-like-xgboost-80f9cc4a3c38"> feature_importance 表</a>，并确定解释超出其应有范围的变量。你的数据可能有偏差！你的模型和参数都不相关。</p><p id="a589" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">比较两个模型的预测，其中一个模型比另一个模型多使用一个变量。具体比较预测不同的数据(预测类不同)。</p><p id="6188" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请记住，在实际项目中，如果您今天将 XGBoost 模型工业化，明天您将希望改进该模型，例如通过向模型添加新的特性或简单地添加新的数据。为了比较这两个模型，绘制属于类别 1 的概率(风险= proba &gt; 50%)，如下所示:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/662b5b6d753a0b51b0b1359b93a7ddcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*TvQlxuu7sw-jhyzBQ96Kag.png"/></div></figure><p id="fdfc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你会知道你的新型号与旧型号相比如何，它们哪里相似，哪里不同。同样，绘制两个 feature_importance 表，并比较两个模型中最相关的要素。</p><p id="5655" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我希望这篇文章对你有用，如果有用，考虑至少给 50 次掌声:)</p></div></div>    
</body>
</html>