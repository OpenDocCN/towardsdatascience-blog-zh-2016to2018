<html>
<head>
<title>6 Steps To Write Any Machine Learning Algorithm From Scratch: Perceptron Case Study</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始编写任何机器学习算法的 6 个步骤:感知器案例研究</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/6-steps-to-write-any-machine-learning-algorithm-from-scratch-perceptron-case-study-335f638a70f3?source=collection_archive---------4-----------------------#2018-09-27">https://towardsdatascience.com/6-steps-to-write-any-machine-learning-algorithm-from-scratch-perceptron-case-study-335f638a70f3?source=collection_archive---------4-----------------------#2018-09-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/a5bbdcfa0008ff7505e6c7337d7d2be1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RRhMRYvyPr71WhJ-.jpg"/></div></div></figure><p id="4b74" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从零开始编写一个<a class="ae kw" href="https://www.dataoptimal.com/machine-learning-from-scratch/" rel="noopener ugc nofollow" target="_blank"> <strong class="ka ir">机器学习算法</strong> </a>是一次极其有益的学习经历。</p><p id="2f63" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">它为你提供了“啊哈！”当你终于明白时，你就会明白引擎盖下到底发生了什么。</p><p id="6ce9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一些算法只是比其他算法更复杂，所以从简单的开始，比如<a class="ae kw" href="https://en.wikipedia.org/wiki/Perceptron" rel="noopener ugc nofollow" target="_blank">单层感知器</a>。</p><p id="a275" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我将使用感知器作为案例研究，带您通过以下 6 个步骤从头开始编写算法:</p><ol class=""><li id="df9f" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv lc ld le lf bi translated">对算法有基本的了解</li><li id="cc8e" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">寻找一些不同的学习资源</li><li id="703e" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">将算法分成块</li><li id="f675" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">从一个简单的例子开始</li><li id="04cd" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">通过可信实施进行验证</li><li id="04be" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">写下你的过程</li></ol><h1 id="cf18" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">获得基本的理解</h1><p id="0cfc" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">这又回到了我最初的陈述。如果你不了解基础知识，不要从头开始研究算法。</p><p id="7482" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">至少，你应该能够回答以下问题:</p><ul class=""><li id="6eba" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv mo ld le lf bi translated">这是什么？</li><li id="22dc" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv mo ld le lf bi translated">它通常用于什么？</li><li id="b37e" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv mo ld le lf bi translated">这个什么时候不能用？</li></ul><p id="1bbf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于感知器，让我们继续回答这些问题:</p><ul class=""><li id="9de6" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv mo ld le lf bi translated">单层感知器是最基本的神经网络。它通常用于二元分类问题(1 或 0，“是”或“否”)。</li><li id="4d42" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv mo ld le lf bi translated">一些简单的用途可能是情绪分析(正面或负面反应)或贷款违约预测(“将违约”、“不会违约”)。对于这两种情况，决策边界需要是线性的。</li><li id="5f9c" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv mo ld le lf bi translated">如果决策边界是非线性的，你真的不能用感知器。对于这些问题，您需要使用不同的方法。</li></ul><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mp"><img src="../Images/8b4edb3544d84f2a5a30f13223caa0fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oUOT0Id5iL-CEjnG.jpg"/></div></div></figure><h1 id="74f2" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">使用不同的学习资源</h1><p id="43ec" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">对模型有了基本的了解之后，就该开始做研究了。</p><p id="e0a3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有些人用课本学得更好，有些人用视频学得更好。</p><p id="dd2a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">就我个人而言，我喜欢反复使用各种类型的资源。</p><p id="d219" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于数学细节，<a class="ae kw" href="https://www.dataoptimal.com/data-science-books-2018/" rel="noopener ugc nofollow" target="_blank">教科书</a>做得很好，但是对于更实际的例子，我更喜欢博客帖子和 YouTube 视频。</p><p id="e6b6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于感知器，这里有一些很好的来源:</p><p id="d276" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">教科书</strong></p><ul class=""><li id="0ada" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv mo ld le lf bi translated"><a class="ae kw" href="https://web.stanford.edu/~hastie/Papers/ESLII.pdf" rel="noopener ugc nofollow" target="_blank">统计学习的要素</a>，第。4.5.1</li><li id="5427" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv mo ld le lf bi translated"><a class="ae kw" href="https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf" rel="noopener ugc nofollow" target="_blank">理解机器学习:从理论到算法</a>，Sec。21.4</li></ul><p id="d215" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">博客</strong></p><ul class=""><li id="585b" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv mo ld le lf bi translated"><a class="ae kw" href="https://machinelearningmastery.com/implement-perceptron-algorithm-scratch-python/" rel="noopener ugc nofollow" target="_blank">如何用 Python 从零开始实现感知器算法</a>，作者 Jason Brownlee</li><li id="fc31" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv mo ld le lf bi translated"><a class="ae kw" href="https://sebastianraschka.com/Articles/2015_singlelayer_neurons.html" rel="noopener ugc nofollow" target="_blank">单层神经网络和梯度下降</a>，塞巴斯蒂安·拉什卡</li></ul><p id="61ed" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">视频</strong></p><ul class=""><li id="512a" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv mo ld le lf bi translated"><a class="ae kw" href="https://www.youtube.com/watch?v=5g0TPrxKK6o" rel="noopener ugc nofollow" target="_blank">感知器训练</a></li><li id="16ca" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv mo ld le lf bi translated"><a class="ae kw" href="https://www.youtube.com/watch?v=1XkjVl-j8MM" rel="noopener ugc nofollow" target="_blank">感知器算法如何工作</a></li></ul><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mu"><img src="../Images/87829d0685331f26f00078e96a546340.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0YVSpqb8M3sQnFR-.jpg"/></div></div></figure><h1 id="ebd5" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">将算法分成块</h1><p id="557e" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">现在我们已经收集了我们的资源，是时候开始学习了。</p><p id="fe48" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">与其从头到尾阅读一章或一篇博文，不如从略读章节标题和其他重要信息开始。</p><p id="d6c9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">写下要点，并尝试概述算法。</p><p id="e14c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在浏览了源代码之后，我将感知器分成了以下 5 个部分:</p><ol class=""><li id="1169" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv lc ld le lf bi translated">初始化权重</li><li id="8a19" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">用输入乘以权重，然后求和</li><li id="6b86" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">将结果与阈值进行比较，以计算输出(1 或 0)</li><li id="6620" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">更新权重</li><li id="113c" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">重复</li></ol><p id="5e47" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们详细地看一下每一个。</p><p id="fd9b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 1。初始化权重</strong></p><p id="262f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">首先，我们将初始化权重向量。</p><p id="e697" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">权重的数量需要与特征的数量相匹配。假设我们有三个特征，这就是权重向量的样子</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mv"><img src="../Images/4f860645671992d283f2e9d17321c70e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9WTTF8LE9Eqhmdnc.jpg"/></div></div></figure><p id="91fb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">权重向量通常用零初始化，所以我将继续使用这个例子。</p><h1 id="7de8" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">2.将权重乘以输入并求和</h1><p id="c8e3" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">接下来，我们将权重乘以输入，然后求和。</p><p id="3033" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了更容易理解，我在第一行中给权重和它们相应的特征着色。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mw"><img src="../Images/da9488f9044b44fd91b7fd9832e4ddfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*soCEJylhawYqMTr9.jpg"/></div></div></figure><p id="7b2e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在我们将权重乘以特征之后，我们将它们相加。这也称为点积。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/6f6c7b0a1f266c4ffe139dc1701a5489.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BMgAXe4eoeJFN-N0.jpg"/></div></div></figure><p id="ca8a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最终结果是 0。我将把这个临时结果称为“f”。</p><h1 id="bd60" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">3.与阈值比较</h1><p id="c6e3" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">计算完点积后，我们需要将其与阈值进行比较。</p><p id="f475" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我已经选择使用 0 作为我的阈值，但是你可以使用它来尝试一些不同的数字。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/b1d9b18102187112b01bb1f6492adaae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SsIOqZsmYpBNW-aA.jpg"/></div></div></figure><p id="a60e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于我们计算的点积“f ”( 0)不大于我们的阈值(0 ),所以我们的估计值等于零。</p><p id="b9e2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我将估算值表示为带帽子的 y(也称为“y 帽子”)，下标 0 对应于第一行。你可以用 1 代替第一行，这并不重要。我只是选择从 0 开始。</p><p id="fd5f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果我们将这个结果与实际值进行比较，我们可以看到我们当前的权重没有正确预测实际输出。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/8d75d7aac7a4186f6b52422e1476e1fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UDbkD-YPFlr3ui6I.jpg"/></div></div></figure><p id="d1c2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于我们的预测是错误的，我们需要更新权重，这将我们带到下一步。</p><h1 id="a191" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">4.更新权重</h1><p id="7bbe" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">接下来，我们将更新权重。这是我们要用的等式:</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/2944938979a92c1eac80d4176d553b0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7C53mG0dOwC64qaF.jpg"/></div></div></figure><p id="0a3f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">基本思想是，我们在迭代“n”时调整当前权重，以便我们获得新的权重用于下一次迭代“n+1”。</p><p id="b6f8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">要调整权重，需要设定一个“学习率”。这由希腊字母“eta”表示。</p><p id="d74b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我选择使用 0.1 作为学习率，但是你可以使用不同的数字，就像阈值一样。</p><p id="d532" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">以下是我们目前所掌握信息的简要总结:</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi my"><img src="../Images/5ad1745e114258334e902eac09560066.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-6UEultkd_Ovyzdu.jpg"/></div></div></figure><p id="d6cd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在让我们继续计算迭代 n=2 的新权重。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/7af416813b80195c56f503463ce18197.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZF8MFmjZ06gDE0uY.jpg"/></div></div></figure><p id="9b71" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们已经成功完成了感知器算法的第一次迭代。</p><h1 id="9101" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">5.重复</h1><p id="e7d3" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">由于我们的算法没有计算出正确的输出，我们需要继续下去。</p><p id="9215" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">通常我们需要多次迭代。遍历数据集中的每一行，我们每次都会更新权重。</p><p id="afef" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对数据集的一次完整扫描被称为“时期”</p><p id="3766" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于我们的数据集有 3 行，我们需要三次迭代来完成 1 个时期。</p><p id="097d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们可以设置总的迭代次数或次数来继续执行算法。也许我们想要指定 30 次迭代(或者 10 个时期)。</p><p id="7540" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">与阈值和学习率一样，历元数也是一个可以随意使用的参数。</p><p id="c4ee" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在下一次迭代中，我们移动到第二行特性。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/877cf4b1c5dc0a98b4b1f2065f953298.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*m5sSpVTXKQQv1Xx_.jpg"/></div></div></figure><p id="937b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我不会重复每一步，但下面是点积的下一个计算:</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/e6cacb829bd9dd2cb9b8336a4a80ccb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4R6VUM_FWvXjY1Aw.jpg"/></div></div></figure><p id="053b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，我们将比较点积和阈值来计算新的估计值，更新权重，然后继续。如果我们的数据是线性可分的，感知器就会收敛。</p><h1 id="1ee1" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">从一个简单的例子开始</h1><p id="d9fe" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">既然我们已经手工将算法分成了几个块，是时候开始用代码实现它了。</p><p id="8de0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了简单起见，我总是喜欢从一个非常小的“玩具数据集”开始</p><p id="5999" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于这类问题，一个很好的小型线性可分数据集是一个<a class="ae kw" href="https://en.wikipedia.org/wiki/NAND_gate" rel="noopener ugc nofollow" target="_blank">与非门</a>。这是数字电子中常用的逻辑门。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/9897f57955243840b63e470cf2001486.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FLPGiYAiV1cyHTJQ.jpg"/></div></div></figure><p id="0fbf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">由于这是一个相当小的数据集，我们可以手工输入到 Python 中。</p><p id="a119" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我将添加一个虚拟特征“x0 ”,它是一列 1。我这样做是为了让我们的模型计算偏置项。</p><p id="af65" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您可以将偏差视为截距项，它正确地允许我们的模型将两个类别分开。</p><p id="5a4f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下面是输入数据的代码:</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="0957" class="nf lm iq nb b gy ng nh l ni nj"># Importing libraries<br/># NAND Gate<br/># Note: x0 is a dummy variable for the bias term<br/>#     x0  x1  x2<br/>x = [[1., 0., 0.],<br/>     [1., 0., 1.],<br/>     [1., 1., 0.],<br/>     [1., 1., 1.]]</span><span id="c50c" class="nf lm iq nb b gy nk nh l ni nj">y =[1.,<br/>    1.,<br/>    1.,<br/>    0.]</span></pre><p id="b8b4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">与上一节一样，我将分块逐步完成算法，一边编写代码一边测试。</p><h1 id="6ee8" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">1.初始化权重</h1><p id="4426" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">第一步是初始化权重。</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="204b" class="nf lm iq nb b gy ng nh l ni nj"># Initialize the weights<br/>import numpy as np<br/>w = np.zeros(len(x[0]))</span><span id="68ad" class="nf lm iq nb b gy nk nh l ni nj">Out:<br/>[ 0.  0.  0.]</span></pre><p id="1f95" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">请记住，权重向量的长度需要与特征的数量相匹配。对于这个与非门例子，长度是 3。</p><h1 id="fc06" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">2.将权重乘以输入并求和</h1><p id="1e97" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">接下来，我们将权重乘以输入，然后求和。</p><p id="60f2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">另一个名称是“点积”</p><p id="a367" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">同样，我们可以使用 Numpy 轻松地执行这个操作。我们将使用的方法是<code class="fe nl nm nn nb b">.dot()</code>。</p><p id="a9d3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们从权重向量和第一行特征的点积开始。</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="ae6a" class="nf lm iq nb b gy ng nh l ni nj"># Dot Product<br/>f = np.dot(w, x[0])<br/>print f</span><span id="f88e" class="nf lm iq nb b gy nk nh l ni nj">Out:<br/>0.0</span></pre><p id="89a7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">不出所料，结果是 0。</p><p id="29a5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了与上一节的注释保持一致，我将点积赋给了变量“f”。</p><h1 id="ef4d" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">3.与阈值进行比较</h1><p id="3670" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">计算完点积后，我们准备将结果与阈值进行比较，以预测输出。</p><p id="31ec" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">同样，我将与上一节的笔记保持一致。</p><p id="3d55" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我将使阈值“z”等于 0。如果点积“f”大于 0，我们的预测将是 1。否则就是零。</p><p id="6f45" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">请记住，预测通常用一克拉表示，也称为“帽子”。我将把预测赋给的变量是<code class="fe nl nm nn nb b">yhat</code>。</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="2441" class="nf lm iq nb b gy ng nh l ni nj"># Activation Function<br/>z = 0.0<br/>if f &gt; z:<br/>    yhat = 1.<br/>else:<br/>    yhat = 0.<br/>    <br/>print yhat</span><span id="6df2" class="nf lm iq nb b gy nk nh l ni nj">Out:<br/>0.0</span></pre><p id="db53" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">不出所料，预测值为 0。</p><p id="dc42" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你会注意到，在代码上方的注释中，我称之为“激活函数”。这是对我们正在做的事情的更正式的描述。</p><p id="5cee" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">看一下 NAND 输出的第一行，我们可以看到实际值是 1。由于我们的预测是错误的，我们需要继续更新权重。</p><h1 id="b1fb" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">4.更新权重</h1><p id="345b" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">现在我们已经做出了预测，我们准备更新权重。</p><p id="a06e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这样做之前，我们需要设定一个学习率。为了与前面的例子保持一致，我将学习率“eta”的值指定为 0.1。</p><p id="5a92" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我将对每个权重的更新进行硬编码，以便于阅读。</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="74f5" class="nf lm iq nb b gy ng nh l ni nj"># Update the weights<br/>eta = 0.1<br/>w[0] = w[0] + eta*(y[0] - yhat)*x[0][0]<br/>w[1] = w[1] + eta*(y[0] - yhat)*x[0][1]<br/>w[2] = w[2] + eta*(y[0] - yhat)*x[0][2]<br/><br/>print w</span><span id="5ff5" class="nf lm iq nb b gy nk nh l ni nj">Out:<br/>[ 0.1  0.   0. ]</span></pre><p id="de87" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们可以看到我们的权重现在已经更新了，所以我们准备继续。</p><h1 id="dbe7" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">5.重复</h1><p id="6753" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">现在我们已经完成了每一步，是时候把所有东西放在一起了。</p><p id="211e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们还没有讨论的最后一点是我们的损失函数。这是我们试图最小化的函数，在我们的例子中是平方和(SSE)误差。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi no"><img src="../Images/f7cef1127bf890506f32885411c12eb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VS3dgKWHA4WVt7GG.jpg"/></div></div></figure><p id="f1a9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是我们将用来计算我们的误差，并看看模型是如何执行的。</p><p id="3e7a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">综合来看，完整的函数如下所示:</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="caea" class="nf lm iq nb b gy ng nh l ni nj">import numpy as np<br/><br/># Perceptron function<br/>def perceptron(x, y, z, eta, t):<br/>    '''<br/>    Input Parameters:<br/>        x: data set of input features<br/>        y: actual outputs<br/>        z: activation function threshold<br/>        eta: learning rate<br/>        t: number of iterations<br/>    '''<br/>    <br/>    # initializing the weights<br/>    w = np.zeros(len(x[0]))      <br/>    n = 0                        <br/>    <br/>    # initializing additional parameters to compute sum-of-squared errors<br/>    yhat_vec = np.ones(len(y))     # vector for predictions<br/>    errors = np.ones(len(y))       # vector for errors (actual - predictions)<br/>    J = []                         # vector for the SSE cost function<br/>    <br/>    while n &lt; t: for i in xrange(0, len(x)): # dot product f = np.dot(x[i], w) # activation function if f &gt;= z:                               <br/>                yhat = 1.                               <br/>            else:                                   <br/>                yhat = 0.<br/>            yhat_vec[i] = yhat<br/>            <br/>            # updating the weights<br/>            for j in xrange(0, len(w)):             <br/>                w[j] = w[j] + eta*(y[i]-yhat)*x[i][j]<br/>                <br/>        n += 1<br/>        # computing the sum-of-squared errors<br/>        for i in xrange(0,len(y)):     <br/>           errors[i] = (y[i]-yhat_vec[i])**2<br/>        J.append(0.5*np.sum(errors))<br/>        <br/>    return w, J</span></pre><p id="34e3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们已经编写了完整的感知器，让我们继续运行它:</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="f7fc" class="nf lm iq nb b gy ng nh l ni nj">#     x0  x1  x2<br/>x = [[1., 0., 0.],<br/>     [1., 0., 1.],<br/>     [1., 1., 0.],<br/>     [1., 1., 1.]]<br/><br/>y =[1.,<br/>    1.,<br/>    1.,<br/>    0.]<br/><br/>z = 0.0<br/>eta = 0.1<br/>t = 50<br/><br/>print "The weights are:"<br/>print perceptron(x, y, z, eta, t)[0]<br/><br/>print "The errors are:"<br/>print perceptron(x, y, z, eta, t)[0]</span><span id="3d39" class="nf lm iq nb b gy nk nh l ni nj">Out:<br/>The weights are:<br/>[ 0.2 -0.2 -0.1]<br/>The errors are:<br/>[0.5, 1.5, 1.5, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</span></pre><p id="8c22" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">看一下误差，我们可以看到误差在第 6 次迭代时变为 0。对于剩余的迭代，它保持为 0。</p><p id="743a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当误差达到 0 并停留在那里时，我们知道我们的模型已经收敛。这告诉我们，我们的模型已经正确地“学习”了适当的权重。</p><p id="9a6e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在下一节中，我们将使用我们在更大的数据集<br/>上计算的权重来进行预测。</p><h1 id="3e5e" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">通过可信实施进行验证</h1><p id="9732" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">到目前为止，我们已经找到了不同的学习资源，手工完成了算法，并用一个简单的例子在代码中进行了测试。</p><p id="19aa" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在是时候将我们的结果与可信的实现进行比较了。为了比较，我们将使用 scikit-learn 的<a class="ae kw" href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html" rel="noopener ugc nofollow" target="_blank">感知机</a>。</p><p id="13eb" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将通过以下步骤进行比较:</p><ol class=""><li id="07ff" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv lc ld le lf bi translated">导入数据</li><li id="cd94" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">将数据分成训练/测试集</li><li id="64e1" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">训练我们的感知器</li><li id="953c" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">测试感知器</li><li id="82d4" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv lc ld le lf bi translated">比较 scikit-learn 感知器</li></ol><h1 id="5c4a" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">1.导入数据</h1><p id="4a77" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">让我们从导入数据开始。你可以在这里获得数据集<a class="ae kw" href="https://github.com/dataoptimal/posts/blob/master/algorithms%20from%20scratch/dataset.csv" rel="noopener ugc nofollow" target="_blank">的副本。</a></p><p id="d1f8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是一个线性可分离的数据集，我创建它是为了确保感知器能够工作。为了确认，让我们继续绘制数据。</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="d59c" class="nf lm iq nb b gy ng nh l ni nj">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/><br/>df = pd.read_csv("dataset.csv")<br/>plt.scatter(df.values[:,1], df.values[:,2], c = df['3'], alpha=0.8)</span></pre><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/52d61846d1db8bc139ee0c448ecddfbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/0*x-2hP2hpyIezqPJE.jpg"/></div></figure><p id="8be6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">看一下这个图，很容易看出我们可以用一条直线将这些数据分开。</p><p id="fb9f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在我们继续之前，我将解释我上面的绘图代码。</p><p id="c429" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我使用 Pandas 导入 csv，它会自动将数据放入 dataframe 中。</p><p id="d673" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了绘制数据，我必须从数据帧中提取值，这就是我使用<code class="fe nl nm nn nb b">.values</code>方法的原因。</p><p id="ae4a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这些特性在第 1 列和第 2 列中，所以这就是我在散点图函数中使用它们的原因。列 0 是 1 的伪特征，我包括它是为了计算截距。这应该与我们在上一节中对与非门所做的事情很相似。</p><p id="eff1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后，我在散点图函数中使用<code class="fe nl nm nn nb b">c = df['3'], alpha = 0.8</code>给两个类着色。输出是第 3 列中的数据(0 或 1)，所以我告诉函数使用第 3 列给两个类着色。</p><p id="baba" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你可以在这里找到 Matplotlib 散点图函数<a class="ae kw" href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html" rel="noopener ugc nofollow" target="_blank">的更多信息</a>。</p><h1 id="45de" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">2.将数据分成训练/测试集</h1><p id="d688" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">既然我们已经确认了数据可以线性分离，那么是时候拆分数据了。</p><p id="0d4d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在与测试数据集不同的数据集上训练模型始终是一种很好的做法。这有助于避免过度拟合。</p><p id="b927" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有不同的方法可以做到这一点，但是为了简单起见，我只使用一个训练集和一个测试集。</p><p id="5a45" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我将从整理我的数据开始。如果您看一下原始文件，您会看到数据是按行分组的，输出(第三列)中有 0，然后是所有的 1。我想改变一下，增加一些随机性，所以我要打乱它。</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="459d" class="nf lm iq nb b gy ng nh l ni nj">df = df.values  <br/>                <br/>np.random.seed(5)<br/>np.random.shuffle(df)</span></pre><p id="a689" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我首先将数据从 dataframe 改为 numpy 数组。这将使我将要使用的许多 numpy 函数更容易使用，比如<code class="fe nl nm nn nb b">.shuffle</code>。</p><p id="c2de" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了使结果对你来说是可重复的，我设置了一个随机种子(5)。完成后，尝试改变随机种子，看看结果如何变化。</p><p id="ad66" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">接下来，我将把 70%的数据分成一个训练集，30%的数据分成一个测试集。</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="7cfe" class="nf lm iq nb b gy ng nh l ni nj">train = df[0:int(0.7*len(df))]<br/>test = df[int(0.7*len(df)):int(len(df))]</span></pre><p id="c9aa" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后一步是分离出训练集和测试集的特征和输出。</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="6c5c" class="nf lm iq nb b gy ng nh l ni nj">x_train = train[:, 0:3]<br/>y_train = train[:, 3]<br/><br/>x_test = test[:, 0:3]<br/>y_test = test[:, 3]</span></pre><p id="44b5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了这个例子，我为我的训练/测试集选择了 70%/30%，但是我鼓励你研究其他方法，比如<a class="ae kw" href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)" rel="noopener ugc nofollow" target="_blank"> k 倍交叉验证</a>。</p><h1 id="f75c" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">3.训练我们的感知器</h1><p id="ece6" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">接下来，我们将训练我们的感知器。</p><p id="05c7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这非常简单，我们只是要重用我们在上一节中构建的代码。</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="e47d" class="nf lm iq nb b gy ng nh l ni nj">def perceptron_train(x, y, z, eta, t):<br/>    '''<br/>    Input Parameters:<br/>        x: data set of input features<br/>        y: actual outputs<br/>        z: activation function threshold<br/>        eta: learning rate<br/>        t: number of iterations<br/>    '''<br/>    <br/>    # initializing the weights<br/>    w = np.zeros(len(x[0]))      <br/>    n = 0                        <br/>    <br/>    # initializing additional parameters to compute sum-of-squared errors<br/>    yhat_vec = np.ones(len(y))     # vector for predictions<br/>    errors = np.ones(len(y))       # vector for errors (actual - predictions)<br/>    J = []                         # vector for the SSE cost function<br/>    <br/>    while n &lt; t:          for i in xrange(0, len(x)):                                           # dot product             f = np.dot(x[i], w)                                   # activation function             if f &gt;= z:                               <br/>                yhat = 1.                               <br/>            else:                                   <br/>                yhat = 0.<br/>            yhat_vec[i] = yhat<br/>            <br/>            # updating the weights<br/>            for j in xrange(0, len(w)):             <br/>                w[j] = w[j] + eta*(y[i]-yhat)*x[i][j]<br/>                <br/>        n += 1<br/>        # computing the sum-of-squared errors<br/>        for i in xrange(0,len(y)):     <br/>           errors[i] = (y[i]-yhat_vec[i])**2<br/>        J.append(0.5*np.sum(errors))<br/>        <br/>    return w, J<br/><br/>z = 0.0<br/>eta = 0.1<br/>t = 50<br/><br/>perceptron_train(x_train, y_train, z, eta, t)</span></pre><p id="e958" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们来看看权重和误差平方和。</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="9637" class="nf lm iq nb b gy ng nh l ni nj">w = perceptron_train(x_train, y_train, z, eta, t)[0]<br/>J = perceptron_train(x_train, y_train, z, eta, t)[1]<br/><br/>print w<br/>print J</span><span id="50ac" class="nf lm iq nb b gy nk nh l ni nj">Out:<br/>[-0.5        -0.29850122  0.35054929]<br/>[4.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</span></pre><p id="1df2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">权重现在对我们来说意义不大，但是我们将在下一节中使用这些数字来测试我们的感知机。我们还将使用权重来比较我们的模型和 scikit-learn 模型。</p><p id="99a0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">看一看误差平方和，我们可以看到我们的感知机已经收敛，这是我们所期望的，因为数据是线性可分的。</p><h1 id="7dc9" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">4.测试我们的感知机</h1><p id="b0b0" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">现在是时候测试我们的感知机了。为此，我们将构建一个小的<code class="fe nl nm nn nb b">perceptron_test</code>函数。</p><p id="5cb2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这与我们已经看到的非常相似。该函数采用我们使用<code class="fe nl nm nn nb b">perceptron_train</code>函数和特性计算的权重的点积，以及激活函数来进行预测。</p><p id="dd3a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们唯一没见过的是<code class="fe nl nm nn nb b">accuracy_score</code>。这是 scikit-learn 的一个评估指标函数。你可以在这里了解更多。</p><p id="98c8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">将所有这些放在一起，代码如下所示:</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="1751" class="nf lm iq nb b gy ng nh l ni nj">from sklearn.metrics import accuracy_score<br/><br/>w = perceptron_train(x_train, y_train, z, eta, t)[0]<br/><br/>def perceptron_test(x, w, z, eta, t):<br/>    y_pred = []<br/>    for i in xrange(0, len(x-1)):<br/>        f = np.dot(x[i], w)   <br/><br/>        # activation function<br/>        if f &gt; z:                               <br/>            yhat = 1                               <br/>        else:                                   <br/>            yhat = 0<br/>        y_pred.append(yhat)<br/>    return y_pred<br/><br/>y_pred = perceptron_test(x_test, w, z, eta, t)<br/><br/>print "The accuracy score is:"<br/>print accuracy_score(y_test, y_pred)</span><span id="6c0d" class="nf lm iq nb b gy nk nh l ni nj">Out:<br/>The accuracy score is:<br/>1.0</span></pre><p id="70b5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">1.0 分表示我们的模型对所有测试数据做出了正确的预测。这个数据集显然是可分离的，所以我们可以预期这个结果。</p><h1 id="102e" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">5.比较 scikit-learn 感知器</h1><p id="bc1e" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">最后一步是将我们的结果与 scikit-learn 的感知器进行比较。这是该模型的代码:</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="9b39" class="nf lm iq nb b gy ng nh l ni nj">from sklearn.linear_model import Perceptron<br/><br/># training the sklearn Perceptron<br/>clf = Perceptron(random_state=None, eta0=0.1, shuffle=False, fit_intercept=False)<br/>clf.fit(x_train, y_train)<br/>y_predict = clf.predict(x_test)</span></pre><p id="776b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们已经训练了模型，让我们将权重与模型计算的权重进行比较。</p><pre class="mq mr ms mt gt na nb nc nd aw ne bi"><span id="bf12" class="nf lm iq nb b gy ng nh l ni nj">Out:<br/>sklearn weights:<br/>[-0.5        -0.29850122  0.35054929]<br/>my perceptron weights:<br/>[-0.5        -0.29850122  0.35054929]</span></pre><p id="10e2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">scikit-learn 模型的重量与我们的重量相同。这意味着我们的模型工作正常，这是个好消息。</p><p id="4881" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在我们结束之前，还有几个小问题要讨论一下。在 scikit-learn 模型中，我们必须将随机状态设置为“None ”,并关闭洗牌。我们已经设置了一个随机种子并打乱了数据，所以我们不需要再次这样做。</p><p id="3b76" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们还必须将学习率“eta0”设置为 0.1，以与我们的模型一致。</p><p id="99a6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后一点是截距。因为我们已经包含了一个 1 的伪特征列，我们正在自动拟合截距，所以我们不需要在 scikit-learn 感知器中打开它。</p><p id="23cd" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这些看起来都是次要的细节，但是如果我们不设置这些，我们将无法重现与我们的模型相同的结果。</p><p id="2ce6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是很重要的一点。在使用模型之前，阅读文档并理解所有不同设置的作用是非常重要的。</p><h1 id="6eb3" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">写下你的过程</h1><p id="e69d" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">这个过程的最后一步可能是最重要的。</p><p id="94e6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您已经完成了学习、做笔记、从头开始编写算法以及与可信实现进行比较的所有工作。不要让所有的好工作都白费了！</p><p id="9207" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">记录流程非常重要，原因有二:</p><ul class=""><li id="2be2" class="kx ky iq ka b kb kc kf kg kj kz kn la kr lb kv mo ld le lf bi translated">你会获得更深的理解，因为你正在把你刚刚学到的东西教给别人。</li><li id="91bf" class="kx ky iq ka b kb lg kf lh kj li kn lj kr lk kv mo ld le lf bi translated">你可以把它展示给潜在雇主。</li></ul><p id="063d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">表明你可以从机器学习库中实现一个算法是一回事，但如果你能从头开始自己实现它，那就更令人印象深刻了。</p><p id="37af" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">展示你的作品的一个很好的方式是使用 GitHub Pages 作品集。</p><h1 id="ff08" class="ll lm iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">结论</h1><p id="1e86" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">在这篇文章中，我们学习了如何从头开始实现<a class="ae kw" href="https://www.dataoptimal.com/machine-learning-from-scratch/" rel="noopener ugc nofollow" target="_blank">感知器</a>。</p><p id="3c96" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">更重要的是，我们学会了如何找到有用的学习资源，以及如何将一个算法分解成块。</p><p id="6c95" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然后，我们学习了如何使用玩具数据集用代码实现和测试算法。</p><p id="3075" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后，我们将模型的结果与可信的实现进行了比较。</p><p id="4ec7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是在更深层次上学习算法的一个很好的方法，这样你就可以自己实现它。</p><p id="2b4f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">大多数时候你会使用一个可信的实现，但是如果你真的想更深入地了解底层发生了什么，从头实现它是一个很好的练习！</p></div></div>    
</body>
</html>