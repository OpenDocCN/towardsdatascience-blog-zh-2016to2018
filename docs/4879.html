<html>
<head>
<title>Introducing TFServe: Simple and easy HTTP server for tensorflow model inference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TFServe 简介:用于 tensorflow 模型推理的简单易用的 HTTP 服务器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/introducing-tfserve-simple-and-easy-http-server-for-tensorflow-model-inference-582ea1b07da8?source=collection_archive---------12-----------------------#2018-09-12">https://towardsdatascience.com/introducing-tfserve-simple-and-easy-http-server-for-tensorflow-model-inference-582ea1b07da8?source=collection_archive---------12-----------------------#2018-09-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/35995e81464f001adfdb8c792f17d058.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DrKc7wEs4O5q6mwUCy0dCg.jpeg"/></div></div></figure><p id="dd49" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">机器学习最有趣(也是最有趣)的部分是利用你花时间训练的模型。虽然有很多关于如何训练模型的资源，但我们经常发现很难弄清楚如何部署一个使用训练好的模型进行推理(即进行预测)的系统。TFServe 是一个框架，旨在通过 HTTP 服务器以简单和容易的方式为 tensorflow 模型提供服务。</p><p id="1d15" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">TFServe 是构建在<a class="ae kw" href="https://github.com/encode/apistar" rel="noopener ugc nofollow" target="_blank"> apistar </a>之上的微框架。要安装它，只需运行:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="aa58" class="lg lh iq lc b gy li lj l lk ll">$ pip install tfserve</span></pre><h1 id="075f" class="lm lh iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">如何使用 TFServe？</h1><p id="d3a5" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">让我们从这个常见的场景开始。你已经发现了一个惊人的 Tensorflow Inception CNN 模型，该模型由 Google 在 ImageNet 上训练。<strong class="ka ir">您</strong> <strong class="ka ir">希望构建一个使用该模型进行推理的 HTTP 服务。</strong></p><p id="9e77" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从描述中可以看出，该模型接收 224x224 的标准化 RGB 图像，并返回最可能的类(从 ImageNet 中的 1000 个类中)。你下载模型，得到一个<code class="fe mo mp mq lc b">frozen_graph.pb</code>(或者类似的)文件。</p><p id="d230" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="mr">现在怎么办？关于如何让它运行的说明涉及到关于模型架构(你对此一无所知)、TF 服务或其他工具的知识。<strong class="ka ir">运行 HTTP 服务器进行推理有多难？这里是</strong> <code class="fe mo mp mq lc b"><strong class="ka ir">tfserve</strong></code> <strong class="ka ir">发挥作用的地方:</strong></em></p><h2 id="a3a6" class="lg lh iq bd ln ms mt dn lr mu mv dp lv kj mw mx lz kn my mz md kr na nb mh nc bi translated">你需要 5 个零件:</h2><ol class=""><li id="2e09" class="nd ne iq ka b kb mj kf mk kj nf kn ng kr nh kv ni nj nk nl bi translated"><strong class="ka ir">模型文件</strong>:可以是<code class="fe mo mp mq lc b">.pb</code>文件，也可以是包含<code class="fe mo mp mq lc b">ckpt</code>文件的模型目录。</li><li id="a8b1" class="nd ne iq ka b kb nm kf nn kj no kn np kr nq kv ni nj nk nl bi translated"><strong class="ka ir">输入张量名称</strong>:图形输入张量的名称。</li><li id="5a73" class="nd ne iq ka b kb nm kf nn kj no kn np kr nq kv ni nj nk nl bi translated"><strong class="ka ir">输出张量名称</strong>:图形的输出张量名称。</li><li id="9eae" class="nd ne iq ka b kb nm kf nn kj no kn np kr nq kv ni nj nk nl bi translated"><code class="fe mo mp mq lc b">encode</code> : python 函数，接收请求体数据并输出一个<code class="fe mo mp mq lc b">dict</code>映射输入张量名称到输入<em class="mr"> numpy </em>值。</li><li id="cbb3" class="nd ne iq ka b kb nm kf nn kj no kn np kr nq kv ni nj nk nl bi translated"><code class="fe mo mp mq lc b">decode</code> : python 函数，接收一个<code class="fe mo mp mq lc b">dict</code>映射输出张量名称到输出<em class="mr"> numpy </em>值并返回 HTTP 响应。</li></ol><h2 id="2c8a" class="lg lh iq bd ln ms mt dn lr mu mv dp lv kj mw mx lz kn my mz md kr na nb mh nc bi translated">输入和输出张量名称？</h2><p id="548f" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">您可能知道，每个张量流图张量都有一个唯一的名称。这个名称是在创建图形时声明的。你需要向<code class="fe mo mp mq lc b">tfserve</code>指定输入张量的名称。输出张量也是如此。</p><blockquote class="nr ns nt"><p id="c364" class="jy jz mr ka b kb kc kd ke kf kg kh ki nu kk kl km nv ko kp kq nw ks kt ku kv ij bi translated">但是我已经从一些 Tensorflow repo 下载了这个模型，我不知道输入/输出张量的名称！</p></blockquote><p id="4473" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">不要惊慌。只需使用<code class="fe mo mp mq lc b"> tfserve.helper.estimate_io_tensors</code>函数了解可能的 i/o 张量供您选择。</p><p id="535e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">举个例子，</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="6016" class="lg lh iq lc b gy li lj l lk ll">&gt; import tfserve import helper<br/>&gt; helper.estimate_io_tensors("frozen_model.pb")</span><span id="5739" class="lg lh iq lc b gy nx lj l lk ll">Possible INPUT tensors:<br/>        import/img:0<br/><br/>Possible OUTPUT tensors:<br/>        pred/out:0<br/>        pred/softmax_out:0</span></pre><blockquote class="nr ns nt"><p id="812f" class="jy jz mr ka b kb kc kd ke kf kg kh ki nu kk kl km nv ko kp kq nw ks kt ku kv ij bi translated"><em class="iq">太好了！</em>我将需要<code class="fe mo mp mq lc b">import/img:0</code>作为我的输入张量，需要<code class="fe mo mp mq lc b">pred/softmax_out:0</code>作为我的输出张量(这将是一个多类概率分布)。</p></blockquote><h2 id="b121" class="lg lh iq bd ln ms mt dn lr mu mv dp lv kj mw mx lz kn my mz md kr na nb mh nc bi translated">编码功能</h2><p id="4af9" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">实现一个函数，该函数接收 HTTP 请求主体数据并输出一个将输入张量名称映射到输入<code class="fe mo mp mq lc b">numpy</code>值的<code class="fe mo mp mq lc b">dict</code>。</p><p id="7090" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在图像分类示例之后，<code class="fe mo mp mq lc b">encode</code>函数将接收 HTTP 请求主体中提供的二进制数据，并应输出一个映射“<code class="fe mo mp mq lc b">import/img:0</code>”到 224x224 标准化 RGB <code class="fe mo mp mq lc b">numpy</code>图像的<code class="fe mo mp mq lc b">dict</code>:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="abaa" class="lg lh iq lc b gy li lj l lk ll">def encode(request_data):<br/>    with tempfile.NamedTemporaryFile(mode="wb", suffix=".jpg") as f:<br/>        f.write(request_data)<br/>        img = PIL.Image.open(f.name).resize((224, 224)) <br/>        img = np.asarray(img) / 255.<br/><br/>    return {"import/img:0": img}</span></pre><h2 id="f7ff" class="lg lh iq bd ln ms mt dn lr mu mv dp lv kj mw mx lz kn my mz md kr na nb mh nc bi translated">解码功能</h2><p id="80b3" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">实现一个函数，该函数接收将输出张量名称映射到输出值并返回 HTTP 响应。</p><p id="500f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在图像分类示例之后，<code class="fe mo mp mq lc b">decode</code>函数将接收到一个将“<code class="fe mo mp mq lc b">pred/softmax_out:0</code>”映射到一个 1000 大小的数组的<code class="fe mo mp mq lc b">dict</code>映射，该数组具有分类概率。我希望返回一个 JSON 对象，如下所示:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="5b67" class="lg lh iq lc b gy li lj l lk ll">{<br/>    class: "german shepard",<br/>    prob: 0.98,<br/>}</span></pre><p id="89b7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">它包含关于最可能的类的信息。</p><p id="fd1e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然后，<code class="fe mo mp mq lc b">decode</code>功能将会是:</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="f539" class="lg lh iq lc b gy li lj l lk ll">def decode(outputs):<br/>    p = outputs["<!-- -->pred/softmax_out:0<!-- -->"]<br/>    index = np.argmax(p)<br/>    return {<br/>               "class": index_to_class_name(index),<br/>               "prob": float(p[index])<br/>           }</span></pre><h2 id="0bd5" class="lg lh iq bd ln ms mt dn lr mu mv dp lv kj mw mx lz kn my mz md kr na nb mh nc bi translated">运行服务器</h2><p id="dbfd" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">您现在可以运行提供上述所有 5 个部分的服务器(<em class="mr">模型路径、输入张量、输出张量、</em> <code class="fe mo mp mq lc b"><em class="mr">encode</em></code> <em class="mr">和</em> <code class="fe mo mp mq lc b"><em class="mr">decode</em></code> <em class="mr">函数</em>):</p><pre class="kx ky kz la gt lb lc ld le aw lf bi"><span id="1e98" class="lg lh iq lc b gy li lj l lk ll">from tfserve import TFServeApp</span><span id="6d96" class="lg lh iq lc b gy nx lj l lk ll">app = TFServeApp("frozen_graph.pb", ["import/img:0"],<br/>                 ["pred/softmax_out:0"], encode, decode)</span><span id="2b0f" class="lg lh iq lc b gy nx lj l lk ll">app.run('127.0.0.1', 5000, debug=True)</span></pre><h1 id="344e" class="lm lh iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">如何向模型发送实际图像？</h1><p id="17fe" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">服务器将在<code class="fe mo mp mq lc b">127.0.0.1:5000</code>启动并运行。为了运行模型，您应该向<code class="fe mo mp mq lc b">/</code>发送一个<code class="fe mo mp mq lc b"><strong class="ka ir">POST</strong></code>请求，并将二进制图像作为请求体。您应该得到在<code class="fe mo mp mq lc b">decode</code>函数中实现的 JSON 响应。</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ny"><img src="../Images/aa183a2602e0541f50078199fb981f5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*YRGYRAwR0loT4fiWs4zH8w.gif"/></div></div><figcaption class="nz oa gj gh gi ob oc bd b be z dk">Using the server through <a class="ae kw" href="https://www.getpostman.com/" rel="noopener ugc nofollow" target="_blank">Postman</a></figcaption></figure><p id="98b8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">您可以在请求正文中提供任何类型的数据。你只需要在<code class="fe mo mp mq lc b">encode</code>函数中正确处理它，就可以得到图形的输入张量。</p><p id="3d73" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，您可以在 HTTP 响应中返回任何类型的数据(例如，除了 JSON 对象之外，它还可以包含带有分段信息的二进制图像)。您只需要在<code class="fe mo mp mq lc b">decode</code>函数中构建响应。</p><h1 id="2a44" class="lm lh iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">结论</h1><p id="be5f" class="pw-post-body-paragraph jy jz iq ka b kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv ij bi translated">有了<code class="fe mo mp mq lc b">tfserve</code>，运行一个 tensorflow 训练好的模型真的简单又容易。只需提供模型路径、输入/输出张量名称、将请求数据转换成输入张量的<code class="fe mo mp mq lc b">encode</code>函数和将输出张量转换成响应的<code class="fe mo mp mq lc b">decode</code>函数。就是这样！<code class="fe mo mp mq lc b">tfserve</code>会处理剩下的。</p><h1 id="8495" class="lm lh iq bd ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi bi translated">有关更多信息，请访问项目网站！</h1><div class="od oe gp gr of og"><a href="https://github.com/iitzco/tfserve" rel="noopener  ugc nofollow" target="_blank"><div class="oh ab fo"><div class="oi ab oj cl cj ok"><h2 class="bd ir gy z fp ol fr fs om fu fw ip bi translated">iitzco/tfserve</h2><div class="on l"><h3 class="bd b gy z fp ol fr fs om fu fw dk translated">将 TF 模型作为 HTTP API 简单方便地提供。通过在…上创建帐户，为 iitzco/tfserve 的发展做出贡献</h3></div><div class="oo l"><p class="bd b dl z fp ol fr fs om fu fw dk translated">github.com</p></div></div><div class="op l"><div class="oq l or os ot op ou jw og"/></div></div></a></div><p id="8107" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="mr">喜欢这个项目吗？</em>在 github 回购上留个⭐！</p></div></div>    
</body>
</html>