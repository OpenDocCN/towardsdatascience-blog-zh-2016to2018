<html>
<head>
<title>YOLO Object Detection with OpenCV and Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 OpenCV 和 Python 的 YOLO 物体检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/yolo-object-detection-with-opencv-and-python-21e50ac599e9?source=collection_archive---------3-----------------------#2018-08-22">https://towardsdatascience.com/yolo-object-detection-with-opencv-and-python-21e50ac599e9?source=collection_archive---------3-----------------------#2018-08-22</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/b582b8092085897c55163eb5777d60e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*Ic-ME4SgJeIgRDZvZu0ivw.jpeg"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image Source: <a class="ae jy" href="https://github.com/pjreddie/darknet/blob/master/data/dog.jpg" rel="noopener ugc nofollow" target="_blank">darknet github repo</a></figcaption></figure><p id="3d1b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果你一直在关注物体探测领域的进步，你可能已经习惯了听到“YOLO”这个词。这已经成了一个流行词。</p><h1 id="4e69" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">YOLO 到底是什么？</h1><p id="5c45" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">YOLO(你只看一次)是一种进行物体检测的方法。这是代码如何检测图像中的对象背后的算法/策略。</p><p id="7b6a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这个想法的官方实现可以通过<a class="ae jy" href="https://pjreddie.com/darknet/" rel="noopener ugc nofollow" target="_blank"> DarkNet </a>(作者用 C 从头开始的神经网络实现)获得。它在<a class="ae jy" href="https://github.com/pjreddie/darknet" rel="noopener ugc nofollow" target="_blank"> github </a>上可供人们使用。</p><p id="e941" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">早期的检测框架以不同的比例多次查看图像的不同部分，并重新利用图像分类技术来检测对象。这种方法既慢又低效。</p><p id="413a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">YOLO 采取了完全不同的方法。它只查看整个图像一次，并通过网络一次，检测对象。因此得名。它非常快。这就是它如此受欢迎的原因。</p><p id="6238" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">还有其他流行的对象检测框架，如<strong class="kb ir">更快的 R-CNN </strong>和<strong class="kb ir"> SSD </strong>也广泛使用。</p><p id="4d39" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在这篇文章中，我们将看看如何在 OpenCV 中使用预先训练好的 YOLO 模型，并立即开始检测物体。</p></div><div class="ab cl ma mb hu mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="ij ik il im in"><h1 id="baa9" class="kx ky iq bd kz la mh lc ld le mi lg lh li mj lk ll lm mk lo lp lq ml ls lt lu bi translated">OpenCV dnn 模块</h1><p id="5bbf" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">DNN(深度神经网络)模块最初是<code class="fe mm mn mo mp b">opencv_contrib</code> repo 的一部分。去年它已经被转移到<code class="fe mm mn mo mp b">opencv</code> repo 的主分支，使用户能够在 OpenCV 本身内部对预训练的深度学习模型进行推理。</p><p id="191b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">(这里需要注意的一点是，<code class="fe mm mn mo mp b">dnn</code>模块不是用来培训的。只是为了对图像/视频进行推理。)</p><p id="e407" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最初只支持 Caffe 和 Torch 型号。随着时间的推移，对 TensorFlow 等不同框架/库的支持正在增加。</p><p id="9c95" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最近增加了对 YOLO/暗网的支持。我们将使用 OpenCV dnn 模块和预训练的 YOLO 模型来检测常见对象。</p><h1 id="2d01" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">我们开始吧..</h1><p id="1ca3" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">说够了。让我们开始写代码。(显然是用 Python)</p><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="mu mv l"/></div></figure><h2 id="a4ba" class="mw ky iq bd kz mx my dn ld mz na dp lh kk nb nc ll ko nd ne lp ks nf ng lt nh bi translated">安装依赖项</h2><p id="649f" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">要执行我们将要编写的代码，需要做以下事情。</p><ul class=""><li id="bc33" class="ni nj iq kb b kc kd kg kh kk nk ko nl ks nm kw nn no np nq bi translated">Python 3</li><li id="5244" class="ni nj iq kb b kc nr kg ns kk nt ko nu ks nv kw nn no np nq bi translated">Numpy</li><li id="a373" class="ni nj iq kb b kc nr kg ns kk nt ko nu ks nv kw nn no np nq bi translated">OpenCV Python 绑定</li></ul><h2 id="ec9d" class="mw ky iq bd kz mx my dn ld mz na dp lh kk nb nc ll ko nd ne lp ks nf ng lt nh bi translated">Python 3</h2><p id="0d90" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">如果你用的是 Ubuntu，很可能已经安装了 Python 3。在终端运行<code class="fe mm mn mo mp b">python3</code>检查是否安装。如果没有安装，请使用</p><p id="aed5" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><code class="fe mm mn mo mp b">sudo apt-get install python3</code></p><p id="4511" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于 macOS，请参考我之前关于 macOS 的<a class="ae jy" href="https://www.arunponnusamy.com/deep-learning-setup-macos.html" rel="noopener ugc nofollow" target="_blank">深度学习设置</a>的帖子。</p><p id="281b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果你需要一个起点，我强烈推荐使用 Python <code class="fe mm mn mo mp b">virtualenvironment.</code>看看我之前的<a class="ae jy" href="https://www.arunponnusamy.com/deep-learning-setup-macos.html" rel="noopener ugc nofollow" target="_blank">帖子</a>。</p><h2 id="fed9" class="mw ky iq bd kz mx my dn ld mz na dp lh kk nb nc ll ko nd ne lp ks nf ng lt nh bi translated">Numpy</h2><p id="1ac1" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated"><code class="fe mm mn mo mp b">pip install numpy</code></p><p id="3d05" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这将安装<code class="fe mm mn mo mp b">numpy.</code>确保 pip 链接到 Python 3.x ( <code class="fe mm mn mo mp b">pip -V</code>将显示此信息)</p><p id="4db0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果需要，使用<code class="fe mm mn mo mp b">pip3</code>。如果尚未安装，使用<code class="fe mm mn mo mp b">sudo apt-get install python3-pip</code>获取<code class="fe mm mn mo mp b">pip3</code>。</p><h2 id="fd98" class="mw ky iq bd kz mx my dn ld mz na dp lh kk nb nc ll ko nd ne lp ks nf ng lt nh bi translated">OpenCV-Python</h2><p id="a553" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">您需要从 github<a class="ae jy" href="http://github.com/opencv/opencv" rel="noopener ugc nofollow" target="_blank">上的 master 分支的源代码中编译 OpenCV 来获得 Python 绑定。(推荐)</a></p><p id="04c5" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">Adrian Rosebrock 在 PyImageSearch 上就此写了一篇很好的博文。(从主分支下载源代码，而不是从存档下载)</p><p id="3063" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果您被从源代码获取 OpenCV Python 绑定的指令弄得不知所措，您可以使用</p><p id="2525" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><code class="fe mm mn mo mp b">pip install opencv-python</code></p><p id="ced6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这不是由 OpenCV.org 官方维护的。这是一个社区维护的。感谢奥利-佩卡·海尼索的努力。</p><h2 id="eb63" class="mw ky iq bd kz mx my dn ld mz na dp lh kk nb nc ll ko nd ne lp ks nf ng lt nh bi translated">命令行参数</h2><p id="7059" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">该脚本需要四个输入参数。</p><ul class=""><li id="bbef" class="ni nj iq kb b kc kd kg kh kk nk ko nl ks nm kw nn no np nq bi translated">输入图像</li><li id="a245" class="ni nj iq kb b kc nr kg ns kk nt ko nu ks nv kw nn no np nq bi translated">YOLO 配置文件</li><li id="0249" class="ni nj iq kb b kc nr kg ns kk nt ko nu ks nv kw nn no np nq bi translated">预先训练的 YOLO 举重</li><li id="820f" class="ni nj iq kb b kc nr kg ns kk nt ko nu ks nv kw nn no np nq bi translated">包含类名的文本文件</li></ul><p id="3657" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">所有这些文件都可以在我整理的 github 知识库中找到。(readme 中提供了下载预训练重量的链接。)</p><p id="1948" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">您也可以通过键入以下内容在“终端”中下载预训练的重量</p><p id="85e3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><code class="fe mm mn mo mp b">wget <a class="ae jy" href="https://pjreddie.com/media/files/yolov3.weights" rel="noopener ugc nofollow" target="_blank">https://pjreddie.com/media/files/yolov3.weights</a></code></p><p id="507e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这个特定的模型是在微软的 COCO 数据集(上下文中的公共对象)上训练的。它能够检测 80 种常见物体。完整名单见<a class="ae jy" href="https://github.com/arunponnusamy/object-detection-opencv/blob/master/yolov3.txt" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><p id="ea7e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">输入图像可以是你的选择。样品输入可在<a class="ae jy" href="https://github.com/arunponnusamy/object-detection-opencv" rel="noopener ugc nofollow" target="_blank"> repo </a>中获得。</p><p id="e5cb" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">通过键入以下命令运行脚本</p><p id="1f2b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><code class="fe mm mn mo mp b">$ python yolo_opencv.py --image dog.jpg --config yolov3.cfg --weights yolov3.weights --classes yolov3.txt</code></p><h1 id="6368" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">准备输入</h1><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="8f98" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">读取输入图像并获得其宽度和高度。</p><p id="4f5e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">读取包含人类可读形式的类名的文本文件，并将类名提取到一个列表中。</p><p id="bc46" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">为不同的类生成不同的颜色来绘制边界框。</p><p id="456d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><code class="fe mm mn mo mp b">net = cv2.dnn.readNet(args.weights, args.config)</code></p><p id="5366" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">上面一行读取权重和配置文件并创建网络。</p><pre class="mq mr ms mt gt nw mp nx ny aw nz bi"><span id="e234" class="mw ky iq mp b gy oa ob l oc od">blob = cv2.dnn.blobFromImage(image, scale, (Width,Height), (0,0,0), True, crop=False)</span><span id="16bc" class="mw ky iq mp b gy oe ob l oc od">net.setInput(blob)</span></pre><p id="b26a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">上面的线准备输入图像运行通过深度神经网络。</p><h1 id="1967" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">输出图层和边界框</h1><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="d862" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">通常，在顺序 CNN 网络中，在末端将只有一个输出层。在我们使用的 YOLO v3 架构中，有多个输出层给出预测。<code class="fe mm mn mo mp b">get_output_layers()</code>函数给出了输出图层的名称。输出层不与任何下一层相连。</p><p id="6bd7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><code class="fe mm mn mo mp b">draw_bounding_box()</code>函数在给定的预测区域上绘制矩形，并在方框上写入类名。如果需要，我们也可以写置信值。</p><h1 id="e5f7" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">运行推理</h1><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="7af1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><code class="fe mm mn mo mp b">outs = net.forward(get_output_layers(net))</code></p><p id="71bd" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">上面的线是通过网络进行精确前馈的地方。关键时刻到了。如果我们不指定输出图层名称，默认情况下，它将仅从最终输出图层返回预测。任何中间输出层都将被忽略。</p><p id="9d78" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们需要检查来自每个输出层的每个检测，以获得类 id、置信度和边界框角，更重要的是忽略弱检测(具有低置信度值的检测)。</p><h1 id="be1a" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">非最大抑制</h1><figure class="mq mr ms mt gt jr"><div class="bz fp l di"><div class="mu mv l"/></div></figure><p id="61b8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">尽管我们忽略了弱检测，但仍会有许多重复的检测和重叠的边界框。非最大抑制会删除重叠程度高的长方体。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div class="gh gi of"><img src="../Images/503f0aaee04e641370b9e622a5a3e3e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*3LS9tykmcGuAF0AJ9NUDFQ.jpeg"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Source: <a class="ae jy" href="https://www.pyimagesearch.com/2018/05/14/a-gentle-guide-to-deep-learning-object-detection/" rel="noopener ugc nofollow" target="_blank">PyImageSearch</a></figcaption></figure><p id="8610" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最后，我们查看剩下的检测，并在它们周围绘制边界框，显示输出图像。</p><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/45efa2ec039bb3f02f4c1efd43695635.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*ascIesw5uWI97GijbE5nPg.jpeg"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk"><a class="ae jy" href="https://github.com/pjreddie/darknet/blob/master/data/person.jpg" rel="noopener ugc nofollow" target="_blank">source</a></figcaption></figure><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/90094a8c18ca43b0395978e43ca61c4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*lFvexyLmk2nlObZpuPNzMA.jpeg"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk"><a class="ae jy" href="https://c8.alamy.com/comp/D5E4G0/woman-on-bicycle-waiting-at-stop-sign-to-cross-busy-road-salt-creek-D5E4G0.jpg" rel="noopener ugc nofollow" target="_blank">source</a></figcaption></figure><figure class="mq mr ms mt gt jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/f5cc8fe62f6f239405b23b362a26ff04.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*_lCVXD47OeLgf781YM3D1A.jpeg"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">I do not own copyright for the images used in this post. All are from Google Images.</figcaption></figure><h1 id="9e97" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">摘要</h1><p id="9f67" class="pw-post-body-paragraph jz ka iq kb b kc lv ke kf kg lw ki kj kk lx km kn ko ly kq kr ks lz ku kv kw ij bi translated">在这篇文章中，我们看了如何使用 OpenCV dnn 模块和预训练的 YOLO 模型来进行物体检测。我们只是触及了表面。物体检测有更多的功能。</p><p id="54eb" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们还可以训练一个模型来检测我们自己感兴趣的对象，这些对象没有包含在预训练的模型中。我将在未来更多地报道对象检测，包括其他框架，如更快的 R-CNN 和 SSD。请务必<a class="ae jy" href="http://eepurl.com/dtoOc9" rel="noopener ugc nofollow" target="_blank">订阅</a>我的<a class="ae jy" href="http://arunponnusamy.com" rel="noopener ugc nofollow" target="_blank">博客</a>，以便在新帖子发布时得到通知。</p><p id="b8cc" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">目前就这些。感谢阅读。我希望这篇文章对开始物体检测有用。欢迎在评论中分享你的想法，或者你可以在 twitter 上联系我。</p><p id="4fed" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">和平。</p></div></div>    
</body>
</html>