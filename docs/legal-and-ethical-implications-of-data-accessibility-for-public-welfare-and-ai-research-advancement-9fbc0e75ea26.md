# 数据可访问性对公共福利和人工智能研究进展的法律和伦理影响

> 原文：<https://towardsdatascience.com/legal-and-ethical-implications-of-data-accessibility-for-public-welfare-and-ai-research-advancement-9fbc0e75ea26?source=collection_archive---------5----------------------->

*本文与* [*加布里埃尔·帕里斯·加尼翁*](https://www.linkedin.com/in/gabrielle-paris-077179124/) *、Propulsio 360 商业顾问律师 LLP* 合著

每一个专注于人工智能的组织都希望并需要同样的东西:更多的数据来训练他们的算法。毫无疑问，今天深度学习系统的许多成功都是基于大型数据集的可用性和收集，这些数据集通常由用户自己提供，以换取免费使用这些服务。

![](img/eb96fe1a2ee38c3cef500f910ce04823.png)

Photo by [Matam Jaswanth](https://unsplash.com/photos/LyPq-Bq97kM?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/social-media?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

1 月早些时候，在蒙特利尔大都会商会组织的[人工智能战略论坛](http://www.ccmm.ca/en/m_strategic_forums_ai_0118/)上，Element AI 研究小组主任 Valérie Bécaert 向商界发表了关于共享数据以使所有组织都能使用人工智能的重要性的演讲。在大数据聚集在少数强大公司手中的时代，这延续了经济不平等，并破坏了人工智能在社会事业中的应用。随着时间的推移，这种差距也必然会加大。科技巨头成倍增加他们的数据收集应用程序，并阻止访问这些专有数据，即使是自己生成这些数据的用户——参见脸书生成的影子档案。[1]

> 更开放的数据获取政策的另一个积极成果是促进科学界、初创企业和面向公益的非营利公司的研究。

到 2030 年，专家预测人工智能将为世界经济贡献高达 15.7 万亿美元[2]。如果什么都不做，没有为数据可访问性颁布标准，这些利润将直接落入极少数人手中。为了让人工智能的发展成为社会流动性的载体，这些收益和随后的财富创造必须以公平的方式进行分配。我们认为，对大型数据集(这对训练深度学习系统至关重要)的可访问性可以将这项技术的集体使用更多地导向公共福利。

此外，有时，个人、公司和非营利组织(它们通常是大型科技公司的数据生成者)受到他们的摆布。他们对自己生成的数据以及如何使用这些数据缺乏控制，也可能产生负面影响。当他们从使用大科技的产品中获得的东西与后者的商业目标不一致时，他们会发现自己无能为力。例如，脸书最近宣布将改变他们的算法，降低出版商帖子的重要性，这对新闻提供商和其他十多年来一直依赖脸书传播信息的企业来说是灾难性的。

![](img/756fe5b35f6cf0e877be781f9dc6721d.png)

Photo by [William Iven](https://unsplash.com/photos/DfMMzzi3rmg?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/facebook?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

现在让我们考虑以下事实:

> 研究公司 IDC 预测，到 2025 年，数字生态系统中捕获的数据将达到 180 zetta byte(zetta byte = 1 后跟 21 个 0)[3]
> 
> 亚马逊使用卡车拉着集装箱来管理他们的 AWS 集群所需的存储空间量。[3]

这为我们提供了一个强有力的指标，表明正在收集的关于用户及其在线行为的数据量只增不减。这些公司盈利的核心原因之一来自于他们将这些数据货币化的能力，并随后通过数据经纪人将这些数据出售给广告商。[4]

鉴于创造赚钱产品和服务对数据的严重依赖，以公平的方式访问此类数据对于市场正常化和提高市场竞争力更为重要，从用户角度来看，这可能会带来更好的结果。

![](img/1b372529e46037280e8606d5bd4e0cd0.png)

Photo by [Scott Webb](https://unsplash.com/photos/yekGLpc3vro?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/law?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

# **要求访问公共数据的初创公司**

随着大型组织收集的大数据不断具有越来越大的市场价值，初创公司开始向法院寻求授权，以获得对这些数据的访问权。

> 这些小公司声称，公司对公开可用数据的控制代表着反竞争行为。

2016 年，hiQ Labs 是一家初创公司，它使用 LinkedIn 的公开数据来构建能够预测员工行为的算法，例如他们何时可能辞职以及相应地提升谁，该公司收到了 LinkedIn 的停止函，称收集他们的公开数据违反了该公司的使用条款。hiQ 实验室将此案告上法庭，因为他们的商业模式完全依赖于他们从 LinkedIn 获得的这些公共数据。[5]

2017 年 8 月，旧金山的美国地区法官 Edward Chen 支持 hiQ Labs，并命令 LinkedIn 在 24 小时内删除任何阻止 hiQ Labs 访问公共档案的技术。在他看来，通过阻止 hiQ 访问 LinkedIn 公共档案来维护控制权可能是一种限制竞争的手段，这违反了加利福尼亚州的法律。此案的最终口头辩论预计将于 2018 年 3 月进行。

# 访问加拿大的房地产数据

在加拿大，竞争局对多伦多房地产委员会提起诉讼，该委员会是一家非营利公司，经营一个收集房地产信息并向其成员发布的在线系统。TREB 的政策限制其成员交流和分发其收集的一些数据，如销售价格。

![](img/94df75563baa3dee94b932a1e1891e19.png)

Photo by [Giammarco Boscaro](https://unsplash.com/photos/OPzWvgL-upY?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/legal?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

竞争管理局辩称，这种对数字化数据的限制性分发阻止了竞争，也阻碍了创新和新商业模式的出现，因为它禁止房地产经纪人在其网站上发布销售数据。2017 年 12 月，联邦上诉法院支持竞争局，并命令 TREB 允许其成员在网上分享上市房产的销售历史。[6]

> 这一决定预计将在加拿大对组织如何在市场上分发数据和请求更开放的数据产生广泛的影响。

因此，拥有更加开放的公共数据集可以促进更加面向公益的商品和服务的发展。

**我们的建议如下:**创建数据共享标准，这些标准由垂直行业驱动，以支持研究人员、年轻企业家等。为公众利益制造产品和服务。通用数据保护条例(GDPR) [7]将于 2018 年 5 月 25 日生效，这开创了一个宽松的先例(当公司要求他们能够在他们要求时以标准化格式提供关于用户的数据)——随着这一条例的生效，看看公司如何决定采用可以跨不同数据处理器解释的标准将是有趣的(该术语在 GDPR 用于指用户可以在不同服务提供商之间切换)。

# 公共数据共享的一些潜在缺点

更开放的数据政策也有其寒蝉效应。即使公开共享匿名化的数据集也可能是一项挑战，因为复杂的统计方法加上马赛克效应(一种用于组合来自不同来源的信息以创建更丰富的目标概况的技术)可能会逆转匿名化过程。事实上，考虑到去年 41%的加拿大公司在安全漏洞后有敏感数据被盗，数据共享可能会危及用户敏感信息的隐私。[8]

这一点已经在过去多次得到证明。其中一种情况是，用户的性取向是从网飞公开发布的数据集[9]中的电影评级中推断出来的，这是通过交叉引用 IMDB 上对这些数据集之间常见的某些罕见电影的评级来实现的。

在另一个案例中，AOL 向公众发布了搜索查询，具体到用户的家庭住址、医疗需求、宠物主人等等。[10]

还必须考虑到，尽管用户可能已经接受通过条款和条件收集和分享其个人数据，但他们的同意是否实际有效仍存在争议。当与深度学习方法结合时，不同数据集的链接也可能导致身份欺诈的风险[11]。为了保护用户的隐私，我们需要制定法律和技术机制，在保护个人隐私的同时，鼓励和平衡这些数据集的共享。

另一个想法可能是允许类似微支付的报酬模式，在这种模式下，可以获得用户的明确同意，使用他们的数据执行特定的活动。用户对其数据隐私的强烈需求以及他们对侵犯这一权利的服务的潜在抵制可能会刺激这种行为。

你同意来自企业的大型数据集有助于推动公益研究的观点吗？做这件事的最好方法是什么？在评论区分享你的想法，让我们知道。

> *关于我在人工智能道德发展方面所做工作的更多信息，请访问*[*https://ATG-abhishek . github . io*](https://atg-abhishek.github.io)

**参考文献:**

[1]脸书如何找出你见过的每个人—[https://gizmodo . com/How-Facebook-figures-out-every one-you ve-even-met-1819822691](https://gizmodo.com/how-facebook-figures-out-everyone-youve-ever-met-1819822691)

[2]人工智能将为全球经济增加 15.7 万亿美元—[https://www . Bloomberg . com/news/articles/2017-06-28/AI-seen-adding-15-7 万亿美元—全球经济的游戏规则改变者](https://www.bloomberg.com/news/articles/2017-06-28/ai-seen-adding-15-7-trillion-as-game-changer-for-global-economy)

[3]数据正在催生新经济—[https://www . economist . com/news/briefing/21721634-how-it-shaping-up-Data-rise-new-economy](https://www.economist.com/news/briefing/21721634-how-it-shaping-up-data-giving-rise-new-economy)

[4]数据经纪人呼吁透明度和问责制—[https://www . FTC . gov/system/files/documents/reports/DATA-BROKERS-Call-Transparency-account ability-report-federal-trade-commission-may-2014/140527 DATA broker report . pdf](https://www.ftc.gov/system/files/documents/reports/data-brokers-call-transparency-accountability-report-federal-trade-commission-may-2014/140527databrokerreport.pdf)

[5] LinkedIn 无法阻止 Startup 抓取公共个人资料数据，美国法官规则—[https://gadgets . ndtv . com/social-networking/news/LinkedIn-Cannot-Block-Startup-From-Scraping-Public-Profile-Data-US-Judge-Rules-1738096](https://gadgets.ndtv.com/social-networking/news/linkedin-cannot-block-startup-from-scraping-public-profile-data-us-judge-rules-1738096)

[6]上诉法院维持命令房地产经纪人公开房屋销售数据的裁决——http://www.cbc.ca/news/business/treb-court-ruling-1.4428262

[7]欧盟 GDPR—[https://www.eugdpr.org/](https://www.eugdpr.org/)

[8]安全漏洞代价高昂—[https://www . investment executive . com/news/industry-news/Security-breakes-prove-cost/](https://www.investmentexecutive.com/news/industry-news/security-breaches-prove-costly/)

[9]Arvind Narayan an 和 Vitaly Shmatikov 对大型数据集进行稳健的去匿名化处理—[https://arxiv.org/pdf/cs/0610105.pdf](https://arxiv.org/pdf/cs/0610105.pdf)

[10]AOL 搜索者暴露了一张脸№4417749—[http://www.nytimes.com/2006/08/09/technology/09aol.html](http://www.nytimes.com/2006/08/09/technology/09aol.html)

[11]Abhishek Gupta 著《欺诈的演变:大规模数据泄露和广泛人工智能解决方案部署时代的伦理含义》——[https://www.itu.int/en/journal/001/Pages/12.aspx](https://www.itu.int/en/journal/001/Pages/12.aspx)