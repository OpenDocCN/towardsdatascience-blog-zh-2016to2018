<html>
<head>
<title>Ten Machine Learning Algorithms You Should Know to Become a Data Scientist</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">成为数据科学家应该知道的十个机器学习算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/ten-machine-learning-algorithms-you-should-know-to-become-a-data-scientist-8dc93d8ca52e?source=collection_archive---------1-----------------------#2018-03-14">https://towardsdatascience.com/ten-machine-learning-algorithms-you-should-know-to-become-a-data-scientist-8dc93d8ca52e?source=collection_archive---------1-----------------------#2018-03-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/71d9f256767a795b8e46b0c33ec95c95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kfTtbiN7TEppfvIDYeMnhw.jpeg"/></div></div></figure><p id="e7c2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">机器学习从业者性格各异。虽然其中一些是“我是 X 方面的专家，X 可以对任何类型的数据进行训练”，其中 X =某种算法，但其他一些则是“适合合适工作人员的合适工具”。他们中的很多人还订阅了《百事通》。“一个硕士”战略，他们在一个领域有深厚的专业知识，对机器学习的不同领域略有了解。也就是说，没有人可以否认这样一个事实，即作为实践数据科学家，我们必须了解一些常见的机器学习算法的基础知识，这将有助于我们处理我们遇到的新领域问题。这是一个关于常见机器学习算法和快速资源的旋风式旅行，可以帮助你开始使用它们。</p><h1 id="4504" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">1.主成分分析/奇异值分解</h1><p id="ba51" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">PCA 是一种无监督的方法，用于理解由向量组成的数据集的全局属性。这里分析数据点的协方差矩阵，以了解哪些维度(大多数)/数据点(有时)更重要(即它们之间的方差高，但与其他维度的协方差低)。考虑矩阵的顶部 PC 的一种方法是考虑其具有最高特征值的特征向量。SVD 本质上也是一种计算有序分量的方法，但是你不需要得到点的协方差矩阵来得到它。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lz"><img src="../Images/248fb20082a641c74895921282b86d4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HjYtbYvrP5ko0HC7YBX4cA.png"/></div></div></figure><p id="a278" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这种算法通过获得维数减少的数据点来帮助人们对抗维数灾难。</p><h1 id="fc08" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">图书馆:</h1><p id="d86e" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.svd.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/scipy/reference/generated/scipy . Lina LG . SVD . html</a></p><p id="26b9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/modules/generated/sk learn . decomposition . PCA . html</a></p><h1 id="152d" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">入门教程:</h1><p id="15f0" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">【https://arxiv.org/pdf/1404.1100.pdf T4】</p><h1 id="77e8" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">2a。最小二乘法和多项式拟合</h1><p id="1a7d" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">还记得你大学时的数值分析代码吗，你曾经用直线和曲线来拟合点，得到一个方程。您可以使用它们在机器学习中拟合低维度的非常小的数据集的曲线。(对于大型数据或多维数据集，您可能最终会过度适应，所以不要费心)。OLS 有一个封闭形式的解决方案，所以你不需要使用复杂的优化技术。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/ac3e3f666c9db2b1bcd4645def9de86e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/1*x7hjx5Lk_SvrteIYqAnx5g.jpeg"/></div></figure><p id="0382" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">显而易见，使用该算法来拟合简单曲线/回归</p><h1 id="d514" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">图书馆:</h1><p id="1382" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/numpy/reference/generated/numpy . linalg . lstsq . html</a>https://docs . scipy . org/doc/numpy-1 . 10 . 0/reference/generated/numpy . poly fit . html</p><h1 id="bda6" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">入门教程:</h1><p id="5308" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="https://lagunita.stanford.edu/c4x/HumanitiesScience/StatLearning/asset/linear_regression.pdf" rel="noopener ugc nofollow" target="_blank">https://lag unita . Stanford . edu/c4x/humanitisescience/StatLearning/asset/linear _ regression . pdf</a></p><h1 id="e084" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">2b。约束线性回归</h1><p id="071e" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">最小二乘法可能会与数据中的异常值、伪场和噪声混淆。因此，我们需要约束来减少我们在数据集上拟合的线的方差。正确的方法是拟合线性回归模型，这将确保权重不会出现错误。模型可以有 L1 范数(LASSO)或 L2 (Ridge Regression)或两者都有(弹性回归)。均方损耗得到优化。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mg"><img src="../Images/2900fd0fc1557576dff40c504b428fcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pVbeQKc9qvtYRAIO4F9pdA.jpeg"/></div></div></figure><p id="9292" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用这些算法用约束条件拟合回归线，避免过度拟合并从模型中屏蔽噪声维度。</p><h1 id="7c01" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">图书馆:</h1><p id="7b9a" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="http://scikit-learn.org/stable/modules/linear_model.html" rel="noopener ugc nofollow" target="_blank">http://scikit-learn.org/stable/modules/linear_model.html</a></p><h1 id="8a63" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">入门教程:</h1><p id="d0bc" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="https://www.youtube.com/watch?v=5asL5Eq2x0A" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=5asL5Eq2x0A</a></p><p id="397d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="https://www.youtube.com/watch?v=jbwSCwoT51M" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=jbwSCwoT51M</a></p><h1 id="617e" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">3.k 表示聚类</h1><p id="6ba8" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">大家最喜欢的无监督聚类算法。给定一组向量形式的数据点，我们可以根据它们之间的距离进行聚类。这是一种期望最大化算法，它迭代地移动聚类的中心，然后用每个聚类中心来增加点数。该算法采用的输入是要生成的聚类的数量以及它将尝试收敛聚类的迭代次数。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/448e8d4f681dcfee7f41b0b0101d334c.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*ZPx88gYG1DsTwGmjBOc5Aw.png"/></div></figure><p id="4c63" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">顾名思义，您可以使用该算法在数据集中创建 K 个聚类</p><h1 id="8f62" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">图书馆:</h1><p id="4943" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/modules/generated/sk learn . cluster . k means . html</a></p><h1 id="4eef" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">入门教程:</h1><p id="f879" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="https://www.youtube.com/watch?v=hDmNF9JG3lo" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=hDmNF9JG3lo</a></p><p id="e03c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="https://www.datascience.com/blog/k-means-clustering" rel="noopener ugc nofollow" target="_blank">https://www.datascience.com/blog/k-means-clustering</a></p><h1 id="05fb" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">4.逻辑回归</h1><p id="5604" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">逻辑回归是在应用权重后进行非线性(sigmoid 函数最常用，或者您也可以使用 tanh)应用的约束线性回归，因此将输出限制为接近+/-类(在 sigmoid 的情况下为 1 和 0)。使用梯度下降来优化交叉熵损失函数。新手注意:逻辑回归用于分类，而不是回归。您也可以将逻辑回归视为一个单层神经网络。使用梯度下降或 L-BFGS 等优化方法来训练逻辑回归。NLP 的人会经常把它用在最大熵分类器的名字上。</p><p id="45a7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是乙状结肠的样子:</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/3ce2eeb70cc956378d25475bfb96d61b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1132/format:webp/1*Sb5O5yzsZmfVgiePgGln1Q.jpeg"/></div></figure><p id="2e83" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用 LR 训练简单但非常健壮的分类器。</p><h1 id="1a80" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">图书馆:</h1><p id="3358" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/modules/generated/sk learn . linear _ model。LogisticRegression.html</a></p><h1 id="6809" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">入门教程:</h1><p id="399c" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">https://www.youtube.com/watch?v=-la3q9d7AKQ<a class="ae me" href="https://www.youtube.com/watch?v=-la3q9d7AKQ" rel="noopener ugc nofollow" target="_blank"/></p><h1 id="b7bb" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">5.SVM(支持向量机)</h1><p id="64e0" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">支持向量机是线性模型，如线性/逻辑回归，区别在于它们具有不同的基于边际的损失函数(支持向量的推导是我见过的与特征值计算一起的最漂亮的数学结果之一)。您可以使用优化方法优化损失函数，如 L-BFGS 甚至 SGD。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/becbd2185f1c9f0af23297576a861473.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*_qnx-GnWBNYlpeEy9Z7aWQ.jpeg"/></div></figure><p id="ed4e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">支持向量机的另一个创新是在数据上使用内核来支持工程师。如果你有很好的领域洞察力，你可以用更聪明的内核替换旧的 RBF 内核并从中获利。</p><p id="bec1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">支持向量机可以做的一件独特的事情是学习一类分类器。</p><p id="75e3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">支持向量机可用于训练分类器(甚至回归器)</p><h1 id="a13f" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">图书馆:</h1><p id="e1f5" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/modules/generated/sk learn . SVM . SVC . html</a></p><h1 id="b91b" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">入门教程:</h1><p id="ed52" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="https://www.youtube.com/watch?v=eHsErlPJWUU" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=eHsErlPJWUU</a></p><p id="5126" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">注:</strong>在 SKLearn 的<a class="ae me" href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/modules/generated/sk learn . linear _ model 中可以找到基于 SGD 的逻辑回归和支持向量机训练。SGDClassifier.html</a>，我经常使用它，因为它让我用一个通用的界面检查 LR 和 SVM。您还可以使用迷你批处理在&gt; RAM 大小的数据集上训练它。</p><h1 id="50eb" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">6.前馈神经网络</h1><p id="7d43" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">这些基本上是多层逻辑回归分类器。由非线性(sigmoid、tanh、relu + softmax 和酷炫的新卢瑟)分隔的多层权重。它们的另一个流行名称是多层感知器。FFNNs 可以作为自动编码器用于分类和无监督的特征学习。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/869e71a6c484a5f8f0994900267f535c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*Njzm1u6cgWMzJwvgBK1ABg.jpeg"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk"><em class="mp">Multi-Layered perceptron</em></figcaption></figure><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/05cb7154853d7a6db5783154db4f92a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*32eXUEJTlPbfUWPPBxa5CQ.jpeg"/></div><figcaption class="ml mm gj gh gi mn mo bd b be z dk"><em class="mp">FFNN as an autoencoder</em></figcaption></figure><p id="d962" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">FFNNs 可用于训练分类器或提取特征作为自动编码器</p><h1 id="8ff0" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">图书馆:</h1><p id="ab3e" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/modules/generated/sk learn . neural _ network。MLP classifier . html # sk learn . neural _ network。MLP 分类器</a></p><p id="0aab" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/modules/generated/sk learn . neural _ network。MLPRegressor.html</a></p><p id="8124" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="https://github.com/keras-team/keras/blob/master/examples/reuters_mlp_relu_vs_selu.py" rel="noopener ugc nofollow" target="_blank">https://github . com/keras-team/keras/blob/master/examples/Reuters _ MLP _ relu _ vs _ selu . py</a></p><h1 id="d0bd" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">入门教程:</h1><p id="8820" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="http://www.deeplearningbook.org/contents/mlp.html" rel="noopener ugc nofollow" target="_blank">http://www.deeplearningbook.org/contents/mlp.html</a></p><p id="5d66" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="http://www.deeplearningbook.org/contents/autoencoders.html" rel="noopener ugc nofollow" target="_blank">http://www.deeplearningbook.org/contents/autoencoders.html</a></p><p id="0363" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="http://www.deeplearningbook.org/contents/representation.html" rel="noopener ugc nofollow" target="_blank">http://www . deep learning book . org/contents/representation . html</a></p><h1 id="a58c" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">7.卷积神经网络</h1><p id="7b83" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">当今世界上几乎任何基于视觉的机器学习结果都是使用卷积神经网络实现的。它们可以用于图像分类、对象检测甚至图像分割。由 Yann Lecun 在 80 年代末 90 年代初发明的 Convnets 具有卷积层的功能，卷积层充当分层特征提取器。你也可以在文本中使用它们(甚至是图表)。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mr"><img src="../Images/d7e585483906dd3baba4a3f7f22b8d36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qwlwaeaw8ZoMJlioAw4zGw.png"/></div></div></figure><p id="760c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用 convnets 进行最先进的图像和文本分类、对象检测、图像分割。</p><h1 id="2ec4" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">图书馆:</h1><p id="1cf7" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="https://developer.nvidia.com/digits" rel="noopener ugc nofollow" target="_blank">https://developer.nvidia.com/digits</a></p><p id="3d68" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="https://github.com/kuangliu/torchcv" rel="noopener ugc nofollow" target="_blank">https://github.com/kuangliu/torchcv</a></p><p id="b9e7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="https://github.com/chainer/chainercv" rel="noopener ugc nofollow" target="_blank">https://github.com/chainer/chainercv</a></p><p id="4df6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="https://keras.io/applications/" rel="noopener ugc nofollow" target="_blank">https://keras.io/applications/</a></p><h1 id="128a" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">入门教程:</h1><p id="63d7" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="http://cs231n.github.io/" rel="noopener ugc nofollow" target="_blank">http://cs231n.github.io/</a></p><p id="928d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="https://adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/" rel="noopener ugc nofollow" target="_blank">https://adeshpande 3 . github . io/A-初学者% 27s-理解指南-卷积神经网络/ </a></p><h1 id="6ff2" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">8.递归神经网络(RNNs):</h1><p id="9a4d" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">RNNs 通过在时间 t 对聚合器状态和时间 t 的输入递归地应用相同的权重集来对序列建模(假设序列在时间 0 具有输入..t..t，并且在从 RNN 的 t-1 步输出的每个时间 t 具有隐藏状态)。现在很少使用纯 rnn，但是它的对应物如 LSTMs 和 GRUs 在大多数序列建模任务中是最先进的。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/de4deb6e6d80ef45dcc950533bb68f01.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*QFge9bi7_guc4HLzmdKJag.jpeg"/></div></figure><p id="033e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">RNN(如果这里是一个密集连接的单元和一个非线性，现在 f 一般是 LSTMs 或 GRUs)。LSTM 单位，在纯 RNN 中用来代替普通致密层。</p><figure class="ma mb mc md gt jr gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/3e9b168a3f9265763bdeb3cd70390ac3.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*L6a7zn51aI8H3xRD1iKSDA.jpeg"/></div></figure><p id="4fec" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">将 RNNs 用于任何序列建模任务，特别是文本分类、机器翻译、语言建模</p><h1 id="735d" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">图书馆:</h1><p id="53b7" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">https://github.com/tensorflow/models<a class="ae me" href="https://github.com/tensorflow/models" rel="noopener ugc nofollow" target="_blank">(谷歌的很多很酷的 NLP 研究论文都在这里)</a></p><p id="4979" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="https://github.com/wabyking/TextClassificationBenchmark" rel="noopener ugc nofollow" target="_blank">https://github.com/wabyking/TextClassificationBenchmark</a></p><p id="5ab5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="http://opennmt.net/" rel="noopener ugc nofollow" target="_blank">http://opennmt.net/</a></p><h1 id="cb29" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">入门教程:</h1><p id="559c" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="http://cs224d.stanford.edu/" rel="noopener ugc nofollow" target="_blank">http://cs224d.stanford.edu/</a></p><p id="9136" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="http://www.wildml.com/category/neural-networks/recurrent-neural-networks/" rel="noopener ugc nofollow" target="_blank">http://www . wild ml . com/category/neural-networks/recurrent-neural-networks/</a></p><p id="0055" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p><h1 id="ea57" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">9.条件随机场</h1><p id="8fa3" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">CRF 可能是概率图形模型(PGM)家族中最常用的模型。它们像 RNNs 一样用于序列建模，也可以与 RNNs 结合使用。在神经机器翻译系统出现之前，CRF 是最先进的，在许多具有小数据集的序列标记任务中，它们仍然会比 rnn 学习得更好，rnn 需要更大量的数据来概括。它们还可以用于其他结构化预测任务，如图像分割等。CRF 对序列的每个元素(比如一个句子)建模，使得相邻元素影响序列中组件的标签，而不是所有标签都彼此独立。</p><p id="f252" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用 CRF 标记序列(文本、图像、时间序列、DNA 等)。)</p><h1 id="43c6" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">图书馆:</h1><p id="5205" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="https://sklearn-crfsuite.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">https://sklearn-crfsuite.readthedocs.io/en/latest/</a></p><h1 id="2d81" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">入门教程:</h1><p id="3981" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/" rel="noopener ugc nofollow" target="_blank">http://blog . echen . me/2012/01/03/有条件随机字段简介/ </a></p><p id="85ed" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Hugo Larochelle 在 Youtube 上的 7 部分系列讲座:【https://www.youtube.com/watch?v=GF3iSJkgPbA T4】</p><h1 id="995d" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">10.决策树</h1><p id="b357" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">比方说，给我一张 Excel 表格，里面有各种水果的数据，我必须说出哪些看起来像苹果。我要做的是问一个问题“哪些水果又红又圆？”把所有回答是和不是的水果分开。现在，所有又红又圆的水果可能不是苹果，也不是所有的苹果都是又红又圆的。所以我会问一个问题“哪些水果上有红色或黄色的颜色提示？”红色和圆形的水果，并会问“哪些水果是绿色和圆形的？”不是红色和圆形的水果。根据这些问题，我可以相当准确地说出哪些是苹果。这一连串的问题就是决策树。但是，这是一个基于我直觉的决策树。直觉无法处理高维复杂的数据。我们必须通过查看标记数据来自动提出一连串的问题。这就是基于机器学习的决策树所做的事情。像 CART trees 这样的早期版本曾经用于简单数据，但是随着数据集越来越大，偏差-方差权衡需要用更好的算法来解决。现在使用的两种常见的决策树算法是随机森林(在属性的随机子集上构建不同的分类器，并将它们组合起来输出)和提升树(在其他树的顶部训练一系列树，纠正下面的树的错误)。</p><p id="30a0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">决策树可以用来分类数据点(甚至回归)</p><h1 id="69d2" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">图书馆</h1><p id="2be5" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/modules/generated/sk learn . ensemble . randomforestclassifier . html</a></p><p id="fc2e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/modules/generated/sk learn . ensemble . gradientboostingclassifier . html</a></p><p id="6f8b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="http://xgboost.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">http://xgboost.readthedocs.io/en/latest/</a></p><p id="6def" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="https://catboost.yandex/" rel="noopener ugc nofollow" target="_blank">https://catboost.yandex/</a></p><h1 id="f005" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">入门教程:</h1><p id="c45b" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="http://xgboost.readthedocs.io/en/latest/model.html" rel="noopener ugc nofollow" target="_blank">http://xgboost.readthedocs.io/en/latest/model.html</a></p><p id="a15e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">https://arxiv.org/abs/1511.05741<a class="ae me" href="https://arxiv.org/abs/1511.05741" rel="noopener ugc nofollow" target="_blank"/></p><p id="50f3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">【https://arxiv.org/abs/1407.7502 T4】</p><p id="aaa0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="http://education.parrotprediction.teachable.com/p/practical-xgboost-in-python" rel="noopener ugc nofollow" target="_blank">http://education . parrot prediction . teachable . com/p/practical-xgboost-in-python</a></p><h1 id="d719" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">TD 算法(最好有)</h1><p id="efe0" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">如果你仍然想知道上述任何方法如何解决像 DeepMind 那样击败围棋世界冠军的任务，它们不能。我们之前讨论的所有 10 种算法都是模式识别，而不是策略学习器。为了学习解决多步骤问题的策略，如赢得一盘棋或玩雅达利游戏机，我们需要让世界上没有代理，并从它面临的奖励/惩罚中学习。这种类型的机器学习被称为强化学习。该领域最近的许多(不是全部)成功是将一个康文网络或一个 LSTM 的感知能力与一套称为时间差异学习的算法相结合的结果。其中包括 Q-Learning、SARSA 和其他一些变体。这些算法是对贝尔曼方程的巧妙运用，以获得一个损失函数，该函数可以用代理从环境中获得的回报来训练。</p><p id="0640" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这些算法主要用于自动玩:D 游戏，也用于语言生成和对象检测中的其他应用。</p><h1 id="d6c8" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">图书馆:</h1><p id="9409" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae me" href="https://github.com/keras-rl/keras-rl" rel="noopener ugc nofollow" target="_blank">https://github.com/keras-rl/keras-rl</a></p><p id="09e7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae me" href="https://github.com/tensorflow/minigo" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/minigo</a></p><h1 id="14fd" class="kw kx iq bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">入门教程:</h1><p id="ba4d" class="pw-post-body-paragraph jy jz iq ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">抢免费的萨顿和巴尔托的书:<a class="ae me" href="https://web2.qatar.cmu.edu/~gdicaro/15381/additional/SuttonBarto-RL-5Nov17.pdf" rel="noopener ugc nofollow" target="_blank">https://web 2 . Qatar . CMU . edu/~ GDI caro/15381/additional/Sutton barto-RL-5 nov17 . pdf</a></p><p id="3791" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">观看大卫·西尔弗课程:<a class="ae me" href="https://www.youtube.com/watch?v=2pWv7GOvuf0" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=2pWv7GOvuf0</a></p><p id="8222" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是 10 种机器学习算法，你可以通过学习成为一名数据科学家。</p><p id="01b9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你也可以在这里阅读关于机器学习库<a class="ae me" href="https://blog.paralleldots.com/data-science/lesser-known-machine-learning-libraries-part-ii/" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="ae5f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们希望你喜欢这篇文章。请<a class="ae me" href="http://https//user.apis.paralleldots.com/signing-up?utm_source=blog&amp;utm_medium=chat&amp;utm_campaign=paralleldots_blog" rel="noopener ugc nofollow" target="_blank">注册</a>免费的 ParallelDots 账户，开始你的 AI 之旅。你也可以在这里查看我们的 API<a class="ae me" href="https://www.paralleldots.com/ai-apis" rel="noopener ugc nofollow" target="_blank">的演示。</a></p><p id="59b3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">点击阅读原文<a class="ae me" href="https://blog.paralleldots.com/data-science/machine-learning/ten-machine-learning-algorithms-know-become-data-scientist/" rel="noopener ugc nofollow" target="_blank">。</a></p></div></div>    
</body>
</html>