<html>
<head>
<title>Automatic Vision Object Tracking</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动视觉目标跟踪</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/automatic-vision-object-tracking-347af1cc8a3b?source=collection_archive---------4-----------------------#2018-03-17">https://towardsdatascience.com/automatic-vision-object-tracking-347af1cc8a3b?source=collection_archive---------4-----------------------#2018-03-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="4580" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一种平移/倾斜伺服设备，帮助摄像机使用视觉自动跟踪彩色对象。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/db170d226700093698c84a16b4629361.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*l7cBuKfSs58E34BV."/></div></div></figure><h1 id="6629" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">1.介绍</h1><p id="955f" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">在之前的教程中，我们探讨了如何<a class="ae ma" href="https://www.hackster.io/mjrobot/pan-tilt-multi-servo-control-b67791" rel="noopener ugc nofollow" target="_blank">控制平移/倾斜伺服设备</a>来定位PiCam。现在我们将使用我们的设备来帮助相机自动跟踪彩色物体，如下图所示:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/cc61f2b565596ff13cd13d0ff3189472.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/0*EWNnVYMo3DsouKX8."/></div></figure><p id="e862" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是我第一次使用OpenCV，我必须承认，我爱上了这个神奇的“开源计算机视觉库”。</p><p id="f550" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae ma" href="https://opencv.org/" rel="noopener ugc nofollow" target="_blank"> OpenCV </a>对于学术和商业用途都是免费的。它有C++，C，Python和Java接口，支持Windows，Linux，Mac OS，iOS和，Android。在我的OpenCV系列教程中，我们将重点关注Raspberry Pi(所以，Raspbian是OS)和Python。OpenCV是为计算效率而设计的，非常注重实时应用。所以，它非常适合物理计算项目！</p><h1 id="89d1" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">2.安装OpenCV 3包</h1><p id="be6c" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">我用的是Raspberry Pi V3，更新到了Raspbian (Stretch)的最新版本，所以安装OpenCV的最好方法是遵循Adrian Rosebrock开发的优秀教程:<a class="ae ma" href="https://www.pyimagesearch.com/2017/09/04/raspbian-stretch-install-opencv-3-python-on-your-raspberry-pi/" rel="noopener ugc nofollow" target="_blank"> Raspbian Stretch:在你的Raspberry Pi上安装OpenCV 3+Python</a>。</p><p id="70e8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我尝试了几种不同的指南在我的Pi上安装OpenCV。阿德里安的教程是最好的。我建议你也这样做，一步一步地遵循他的指导方针。</p><p id="f83a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦您完成了Adrian的教程，您就应该有一个OpenCV虚拟环境，可以在您的Pi上运行我们的实验。</p><p id="02c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们进入虚拟环境，确认OpenCV 3安装正确。</p><p id="0e22" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Adrian建议每次打开新终端时运行命令“source ”,以确保系统变量设置正确。</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="2ed9" class="mh ky iq md b gy mi mj l mk ml">source ~/.profile</span></pre><p id="b5d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，让我们进入虚拟环境:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="e1b0" class="mh ky iq md b gy mi mj l mk ml">workon cv</span></pre><p id="9c9c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果您在提示前看到文本(cv ),则您处于<em class="mm"> cv虚拟</em>环境中:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="606b" class="mh ky iq md b gy mi mj l mk ml">(cv) pi@raspberry:~$</span></pre><p id="cf87" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Adrian提醒注意，<strong class="jp ir"> <em class="mm"> cv Python虚拟环境</em> </strong>完全独立于Raspbian Stretch下载中包含的默认Python版本。因此，全局站点包目录中的任何Python包对于cv虚拟环境都是不可用的。类似地，任何安装在cv的site-packages中的Python包对于Python的全局安装都是不可用的。</p><p id="4f6a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，在Python解释器中输入:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="0e08" class="mh ky iq md b gy mi mj l mk ml">python</span></pre><p id="1cca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">并确认您运行的是3.5(或更高)版本</p><p id="6b6c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在解释器内部(会出现" &gt; &gt; &gt; ")，导入OpenCV库:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="e9b3" class="mh ky iq md b gy mi mj l mk ml">import cv2</span></pre><p id="6dcf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果没有出现错误消息，则OpenCV已正确安装在您的PYTHON虚拟环境中。</p><p id="60ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您也可以检查安装的OpenCV版本:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="aeee" class="mh ky iq md b gy mi mj l mk ml">cv2.__version__</span></pre><p id="04e6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">3.3.0应该会出现(或者将来可能发布的更高版本)。上面的终端打印屏幕显示了前面的步骤。</p><h1 id="049a" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">3.测试您的相机</h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/2992b0125749b08b577b619c39f7855e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*jZqMTb-YJ-tYzkuP."/></div></figure><p id="20dc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦你在RPi中安装了OpenCV，让我们测试一下你的相机是否工作正常。</p><p id="5ae6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我假设你已经在你的Raspberry Pi上安装了PiCam。</p><p id="2cdd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在您的IDE上输入以下Python代码:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="c780" class="mh ky iq md b gy mi mj l mk ml">import numpy as np<br/>import cv2<br/>cap = cv2.VideoCapture(0)</span><span id="1e4f" class="mh ky iq md b gy mo mj l mk ml">while(True):<br/>    ret, frame = cap.read()<br/>    frame = cv2.flip(frame, -1) # Flip camera vertically<br/>    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)<br/>    <br/>    cv2.imshow('frame', frame)<br/>    cv2.imshow('gray', gray)<br/>    if cv2.waitKey(1) &amp; 0xFF == ord('q'):<br/>        break</span><span id="b2ff" class="mh ky iq md b gy mo mj l mk ml">cap.release()<br/>cv2.destroyAllWindows()</span></pre><p id="2d5e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上述代码将捕获PiCam生成的视频流，并以BGR彩色和灰色模式显示。</p><p id="f38e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，由于组装的方式，我垂直旋转了我的相机。如果不是你的情况，评论或删除“翻转”命令行。</p><p id="8c5f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你也可以从我的GitHub下载代码:<a class="ae ma" href="https://github.com/Mjrovai/OpenCV-Object-Face-Tracking/blob/master/simpleCamTest.py" rel="noopener ugc nofollow" target="_blank"> simpleCamTest.py </a></p><p id="d464" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要执行，请输入命令:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="dca2" class="mh ky iq md b gy mi mj l mk ml">python simpleCamTest.py</span></pre><p id="6f09" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要完成该程序，您必须按键盘上的[q]或[Ctrl] + [C]键</p><p id="38b9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">图为结果。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/72a82aa2ef64a0da1ee6c73278b55054.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*pqbSHPObaRuUzftJ."/></div></figure><p id="1615" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">了解OpenCV的更多内容，可以关注教程:<a class="ae ma" href="https://pythonprogramming.net/loading-video-python-opencv-tutorial/" rel="noopener ugc nofollow" target="_blank">加载-视频-python-OpenCV-教程</a></p><h1 id="9ae1" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">4.用OpenCV实现Python中的颜色检测</h1><p id="23b9" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">我们将尝试完成的一件事是检测和跟踪某种颜色的物体。为此，我们必须对OpenCV如何解释颜色有更多的了解。</p><p id="b4e5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Henri Dang用OpenCV 用Python写了一个很棒的关于<a class="ae ma" href="https://henrydangprg.com/2016/06/26/color-detection-in-python-with-opencv/" rel="noopener ugc nofollow" target="_blank">颜色检测的教程。</a></p><p id="298d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通常，我们的相机将以RGB颜色模式工作，这可以理解为可以由红、绿、蓝三种颜色的光组成的所有可能的颜色。我们将在这里用BGR(蓝色、绿色、红色)代替。</p><p id="f935" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如上所述，对于BGR，像素由3个参数表示，蓝色、绿色和红色。每个参数通常有一个从0到255的值(或十六进制的0到FF)。例如，计算机屏幕上的纯蓝色像素的B值为255，G值为0，R值为0。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/09f9f0107e5a65139b66b3582b35fa70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*MaBRY76pPYp9RaG0."/></div></figure><p id="5ef7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">OpenCV使用HSV(色调、饱和度、值)颜色模型，它是RGB颜色模型的替代表示，由计算机图形研究人员在20世纪70年代设计，以更接近人类视觉感知颜色生成属性的方式:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/a95eaaf6e8fa20d4756e0761cdb69bd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*w2nAGGNOqvmVoi1Q."/></div></figure><p id="9dda" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">太好了。因此，如果您想使用OpenCV跟踪某种颜色，您必须使用HSV模型来定义它。</p><h2 id="e6ef" class="mh ky iq bd kz mp mq dn ld mr ms dp lh jy mt mu ll kc mv mw lp kg mx my lt mz bi translated">例子</h2><p id="4a22" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">比方说，我必须跟踪一个黄色物体，如上图所示的塑料盒。容易的部分是找到它的BGR元素。你可以用任何设计程序去找(我用的是PowerPoint)。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/78d2678e40d662d0ffe64227954519fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*U9YtcUNNUJuMgp9_."/></div></figure><p id="e817" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我的案例中，我发现:</p><ul class=""><li id="058c" class="na nb iq jp b jq jr ju jv jy nc kc nd kg ne kk nf ng nh ni bi translated">蓝色:71</li><li id="c84e" class="na nb iq jp b jq nj ju nk jy nl kc nm kg nn kk nf ng nh ni bi translated">绿色:234</li><li id="d69d" class="na nb iq jp b jq nj ju nk jy nl kc nm kg nn kk nf ng nh ni bi translated">红色:213</li></ul><p id="4217" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，我们必须将BGR (71，234，213)模型转换为HSV模型，这将由范围的上限和下限来定义。为此，让我们运行下面的代码:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="2fea" class="mh ky iq md b gy mi mj l mk ml">import sys<br/>import numpy as np<br/>import cv2</span><span id="b78e" class="mh ky iq md b gy mo mj l mk ml">blue = sys.argv[1]<br/>green = sys.argv[2]<br/>red = sys.argv[3]  </span><span id="ad92" class="mh ky iq md b gy mo mj l mk ml">color = np.uint8([[[blue, green, red]]])<br/>hsv_color = cv2.cvtColor(color, cv2.COLOR_BGR2HSV)<br/>hue = hsv_color[0][0][0]</span><span id="e25d" class="mh ky iq md b gy mo mj l mk ml">print("Lower bound is :"),<br/>print("[" + str(hue-10) + ", 100, 100]\n")<br/>print("Upper bound is :"),<br/>print("[" + str(hue + 10) + ", 255, 255]")</span></pre><p id="da76" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你也可以从我的GitHub下载代码:<a class="ae ma" href="https://github.com/Mjrovai/OpenCV-Object-Face-Tracking/blob/master/bgr_hsv_converter.py" rel="noopener ugc nofollow" target="_blank"> bgr_hsv_converter.py </a></p><p id="17cb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要执行该命令，请输入以下命令，并将之前找到的BGR值作为参数:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="69a3" class="mh ky iq md b gy mi mj l mk ml">python bgr_hsv_converter.py 71 234 213</span></pre><p id="5045" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该程序将打印我们的对象颜色的上下边界。</p><p id="1cf5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这种情况下:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="30e5" class="mh ky iq md b gy mi mj l mk ml">lower bound: [24, 100, 100]</span></pre><p id="4666" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">和</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="69a9" class="mh ky iq md b gy mi mj l mk ml">upper bound: [44, 255, 255]</span></pre><p id="218a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">终端打印屏幕显示结果。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/ab6d79af33ac543573e3c066d4550740.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*kwJWAzeXfCMtfIrN."/></div></figure><p id="5c61" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，同样重要的是，让我们看看一旦我们确定了对象的颜色，OpenCV如何“屏蔽”它:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="a4bf" class="mh ky iq md b gy mi mj l mk ml">import cv2<br/>import numpy as np</span><span id="0f74" class="mh ky iq md b gy mo mj l mk ml"># Read the picure - The 1 means we want the image in BGR<br/>img = cv2.imread('yellow_object.JPG', 1) </span><span id="b62c" class="mh ky iq md b gy mo mj l mk ml"># resize imag to 20% in each axis<br/>img = cv2.resize(img, (0,0), fx=0.2, fy=0.2)</span><span id="6229" class="mh ky iq md b gy mo mj l mk ml"># convert BGR image to a HSV image<br/>hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) </span><span id="37a8" class="mh ky iq md b gy mo mj l mk ml"># NumPy to create arrays to hold lower and upper range <br/># The “dtype = np.uint8” means that data type is an 8 bit integer<br/>lower_range = np.array([24, 100, 100], dtype=np.uint8) <br/>upper_range = np.array([44, 255, 255], dtype=np.uint8)</span><span id="0ade" class="mh ky iq md b gy mo mj l mk ml"># create a mask for image<br/>mask = cv2.inRange(hsv, lower_range, upper_range)</span><span id="af6e" class="mh ky iq md b gy mo mj l mk ml"># display both the mask and the image side-by-side<br/>cv2.imshow('mask',mask)<br/>cv2.imshow('image', img)</span><span id="3d12" class="mh ky iq md b gy mo mj l mk ml"># wait to user to press [ ESC ]<br/>while(1):<br/>  k = cv2.waitKey(0)<br/>  if(k == 27):<br/>    break</span><span id="748d" class="mh ky iq md b gy mo mj l mk ml">cv2.destroyAllWindows()</span></pre><p id="ad1c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你也可以从我的GitHub下载代码:<a class="ae ma" href="https://github.com/Mjrovai/OpenCV-Object-Face-Tracking/blob/master/colorDetection.py" rel="noopener ugc nofollow" target="_blank"> colorDetection.py </a></p><p id="2a4d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要执行，输入下面的命令，在你的目录中有一张你的目标对象的照片(在我的例子中:yellow_object。JPG):</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="67c9" class="mh ky iq md b gy mi mj l mk ml">python colorDetection.py</span></pre><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mn"><img src="../Images/87530ee5a5203726a0d7134b02a636d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*5Y45ZVvLf-6eR3XH."/></div></div></figure><p id="cfcb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面的图片将显示原始图像(“图像”)以及应用蒙版后对象的外观(“蒙版”)。</p><h1 id="3c2a" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">5.物体运动跟踪</h1><p id="d656" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">现在我们知道如何使用蒙版“选择”我们的对象，让我们使用相机实时跟踪它的运动。为此，我用OpenCV tutoria  l基于<a class="ae ma" href="https://www.pyimagesearch.com/2015/09/14/ball-tracking-with-opencv/" rel="noopener ugc nofollow" target="_blank"> Adrian Rosebrock的球跟踪编写了我的代码</a></p><p id="b971" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我强烈建议你详细阅读阿德里安的教程。</p><p id="0545" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，确认你是否安装了<em class="mm"> imutils库</em>。它是Adrian收集的OpenCV便利函数，使一些基本任务(如调整大小或翻转屏幕)变得更加容易。如果没有，请输入以下命令，在您的虚拟Python环境中安装库:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="f5c1" class="mh ky iq md b gy mi mj l mk ml">pip install imutils</span></pre><p id="a3f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来，从我的GitHub下载代码<a class="ae ma" href="https://github.com/Mjrovai/OpenCV-Object-Face-Tracking/blob/master/ball_tracking.py" rel="noopener ugc nofollow" target="_blank"> ball_tracking.py </a>，并使用以下命令执行它:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="018b" class="mh ky iq md b gy mi mj l mk ml">python ball_traking.py</span></pre><p id="7660" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，您将看到类似于下面的gif:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/bf2008b3d9f6772a36042cf78d1ce888.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/0*IJslMc33QrepSY95."/></div></figure><p id="87ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基本上，它和Adrian的代码是一样的，除非是“视频垂直翻转”,这是我用下面一行代码得到的:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="27d8" class="mh ky iq md b gy mi mj l mk ml">frame = imutils.rotate(frame, angle=180)</span></pre><p id="735c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">另外，请注意，所使用的遮罩边界是我们在上一步中获得的。</p><h1 id="518d" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">6.测试GPIOs</h1><p id="088e" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">现在我们已经玩了OpenCV的基础，让我们安装一个LED到我们的RPi，并开始与我们的GPIOs交互。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/dd3a45b45481bf5a42ae8486077cdc32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*NR-X9UCx9qmbjBrm."/></div></figure><p id="c055" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">遵循上面的电路图:LED的阴极将通过220欧姆的电阻器连接到GPIO 21，其阳极连接到GND。</p><p id="8fdf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们在虚拟Python环境中测试我们的LED。</p><p id="b05f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请记住，RPi有可能。您的Python虚拟环境中没有安装GPIO！要解决这个问题，一旦您到达那里(记得确认(cv)在您的终端中)，您需要使用pip将其安装到您的虚拟环境中:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="c9c2" class="mh ky iq md b gy mi mj l mk ml">pip install RPi.GPIO</span></pre><p id="6849" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们使用python脚本来执行一个简单的测试:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="7a0d" class="mh ky iq md b gy mi mj l mk ml">import sys<br/>import time<br/>import RPi.GPIO as GPIO</span><span id="397e" class="mh ky iq md b gy mo mj l mk ml"># initialize GPIO and variables<br/>redLed = int(sys.argv[1])<br/>freq = int(sys.argv[2])<br/>GPIO.setmode(GPIO.BCM)<br/>GPIO.setup(redLed, GPIO.OUT)<br/>GPIO.setwarnings(False)</span><span id="eeac" class="mh ky iq md b gy mo mj l mk ml">print("\n [INFO] Blinking LED (5 times) connected at GPIO {0} \<br/>at every {1} second(s)".format(redLed, freq))<br/>for i in range(5):<br/>    GPIO.output(redLed, GPIO.LOW)<br/>    time.sleep(freq)<br/>    GPIO.output(redLed, GPIO.HIGH)<br/>    time.sleep(freq)</span><span id="5652" class="mh ky iq md b gy mo mj l mk ml"># do a bit of cleanup<br/>print("\n [INFO] Exiting Program and cleanup stuff \n")<br/>GPIO.cleanup()</span></pre><p id="5e08" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该代码将接收一个GPIO号和LED闪烁的频率(秒)作为参数。LED将闪烁5次，程序将被终止。请注意，在终止之前，我们将释放GPIOs。</p><p id="a670" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以，要执行这个脚本，你必须输入参数，<em class="mm"> LED GPIO </em>和<em class="mm">频率</em>。</p><p id="aa13" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="d8ee" class="mh ky iq md b gy mi mj l mk ml">python LED_simple_test.py 21 1</span></pre><p id="b90b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上述命令将使连接到“GPIO 21”的红色LED每“1”秒闪烁5次。</p><p id="9b53" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">文件<a class="ae ma" href="https://github.com/Mjrovai/OpenCV-Object-Face-Tracking/blob/master/GPIO_LED_test.py" rel="noopener ugc nofollow" target="_blank"> GPIO_LED_test.py </a>可以从我的GitHub下载</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mn"><img src="../Images/20a157d6ab9b12e164b2d253757e5914.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*c09K9ImNkENzfrqq."/></div></div></figure><p id="1ffd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面的终端打印屏幕显示了结果(当然，您应该确认LED在闪烁。</p><p id="2c3f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，让我们使用OpenCV和一些基本的GPIO东西。</p><h1 id="0f7b" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">7.识别颜色和GPIO交互</h1><p id="77ed" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">让我们开始将OpenCV代码与GPIO交互集成。我们将从最后一个OpenCV代码开始，我们将在其上集成GPIO-RPI库，因此我们将在相机发现我们的彩色对象时打开红色LED。这一步使用的代码基于Adrian的优秀教程<a class="ae ma" href="https://www.pyimagesearch.com/2016/05/09/opencv-rpi-gpio-and-gpio-zero-on-the-raspberry-pi/" rel="noopener ugc nofollow" target="_blank"> OpenCV，RPi。GPIO，和树莓Pi上的GPIO零点</a>:</p><p id="c842" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先要做的是“创建”我们的LED，将其连接到特定的GPIO:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="4333" class="mh ky iq md b gy mi mj l mk ml">import RPi.GPIO as GPIO<br/>redLed = 21<br/>GPIO.setmode(GPIO.BCM)<br/>GPIO.setwarnings(False)<br/>GPIO.setup(redLed, GPIO.OUT)</span></pre><p id="78d9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其次，我们必须初始化我们的LED(关闭):</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="a6ee" class="mh ky iq md b gy mi mj l mk ml">GPIO.output(redLed, GPIO.LOW)<br/>ledOn = False</span></pre><p id="3857" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，在循环中，当找到对象时会创建“圆圈”,我们将打开LED:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="6a0e" class="mh ky iq md b gy mi mj l mk ml">GPIO.output(redLed, GPIO.HIGH)<br/>ledOn = True</span></pre><p id="a60b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们从我的GitHub下载完整的代码:<a class="ae ma" href="https://github.com/Mjrovai/OpenCV-Object-Face-Tracking/blob/master/object_detection_LED.py" rel="noopener ugc nofollow" target="_blank"> object_detection_LED.py </a></p><p id="8ece" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用以下命令运行代码:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="f174" class="mh ky iq md b gy mi mj l mk ml">python object_detection_LED.py</span></pre><p id="f6f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是结果。注意:每次检测到物体时，LED(左下角)都会亮起:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/637f82225a06c480138fd7efe70fece9.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/0*onGY9YyDNbgN-Vjp."/></div></figure><p id="0074" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">尝试不同的对象(颜色和格式)。你会看到，一旦遮罩边界内的颜色匹配，LED就会打开。</p><p id="1bf0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面的视频展示了一些经验。请注意，只有处于颜色范围内的黄色物体才会被检测到，从而打开LED。具有不同颜色的对象被忽略。</p><p id="86b1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们在这里仅使用上一步中解释的LED。我做视频的时候已经把云台组装好了，所以忽略它。我们将在下一步处理平移/倾斜机制。</p><h1 id="3b4e" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">8.平移倾斜机构</h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/5e137b623c1debc2404202e7a16f988c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*cLfYYL85fPMG89kt."/></div></figure><p id="8188" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">既然我们已经玩了OpenCV和GPIO的基础，让我们安装我们的平移/倾斜机制。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/4003a5fd1284602164b4002e020d1bf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*9buxAYZ7-RQldG0C."/></div></figure><blockquote class="no np nq"><p id="ac6b" class="jn jo mm jp b jq jr js jt ju jv jw jx nr jz ka kb ns kd ke kf nt kh ki kj kk ij bi translated"><em class="iq">详情请访问我的教程:</em> <a class="ae ma" href="https://www.instructables.com/id/Pan-Tilt-Multi-Servo-Control/" rel="noopener ugc nofollow" target="_blank"> <em class="iq">云台多伺服控制</em> </a></p></blockquote><p id="9c95" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">伺服系统应连接到外部5V电源，其数据引脚(在我的例子中，它们的黄色接线)连接到Raspberry Pi GPIO，如下所示:</p><ul class=""><li id="2f4d" class="na nb iq jp b jq jr ju jv jy nc kc nd kg ne kk nf ng nh ni bi translated">GPIO 17 == &gt;倾斜伺服</li><li id="b08e" class="na nb iq jp b jq nj ju nk jy nl kc nm kg nn kk nf ng nh ni bi translated">GPIO 27 == &gt;平移伺服</li></ul><p id="78b3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">不要忘记将gnd连接在一起==&gt; Raspberry Pi —伺服—外部电源)</p><p id="a000" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以选择在Raspberry Pi GPIO和服务器数据输入引脚之间串联一个1K欧姆的电阻。这将保护你的RPi以防伺服问题。</p><p id="cb02" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们也利用这个机会，在我们的虚拟Python环境中测试我们的伺服系统。</p><p id="1594" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们使用Python脚本对我们的驱动程序执行一些测试:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="0d5d" class="mh ky iq md b gy mi mj l mk ml">from time import sleep<br/>import RPi.GPIO as GPIO</span><span id="854c" class="mh ky iq md b gy mo mj l mk ml">GPIO.setmode(GPIO.BCM)<br/>GPIO.setwarnings(False)</span><span id="03b3" class="mh ky iq md b gy mo mj l mk ml">def setServoAngle(servo, angle):<br/>	pwm = GPIO.PWM(servo, 50)<br/>	pwm.start(8)<br/>	dutyCycle = angle / 18. + 3.<br/>	pwm.ChangeDutyCycle(dutyCycle)<br/>	sleep(0.3)<br/>	pwm.stop()</span><span id="a17f" class="mh ky iq md b gy mo mj l mk ml">if __name__ == '__main__':<br/>	import sys<br/>	servo = int(sys.argv[1])<br/>	GPIO.setup(servo, GPIO.OUT)<br/>	setServoAngle(servo, int(sys.argv[2]))<br/>	GPIO.cleanup()</span></pre><p id="5773" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上面代码的核心是函数setServoAngle(伺服，角度)。这个函数接收一个伺服GPIO号和一个伺服必须定位的角度值作为参数。一旦这个函数的输入是“角度”，我们必须将其转换为等效占空比。</p><p id="9481" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要执行该脚本，必须输入<em class="mm">伺服GPIO </em>和<em class="mm">角度</em>作为参数。</p><p id="ab83" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">例如:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="a4ce" class="mh ky iq md b gy mi mj l mk ml">python angleServoCtrl.py 17 45</span></pre><p id="35d7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上述命令将连接在GPIO 17(“倾斜”)上的伺服定位为“仰角”45度。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/b648053b9bad5cbd2e7d4226517845a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/0*5rURGlTPGM-k1c5E."/></div></figure><p id="0bd4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">文件<a class="ae ma" href="https://github.com/Mjrovai/OpenCV-Object-Face-Tracking/blob/master/angleServoCtrl.py" rel="noopener ugc nofollow" target="_blank">angleservocctrl . py</a>可以从我的GitHub下载</p><h1 id="1d17" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">9.寻找物体的实时位置</h1><p id="b0e7" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">这里的想法是使用平移/倾斜机制将对象定位在屏幕的中间。坏消息是，首先我们必须知道物体的实时位置。但好消息是，一旦我们已经有了物体中心的坐标，这是非常容易的。</p><p id="6d9d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，让我们把之前使用的“object_detect_LED”代码修改为打印被发现对象的x，y坐标。</p><p id="e917" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从我的GitHub下载代码:<a class="ae ma" href="https://github.com/Mjrovai/OpenCV-Object-Face-Tracking/blob/master/Object_Tracking/objectDetectCoord.py" rel="noopener ugc nofollow" target="_blank"> objectDetectCoord.py </a></p><p id="2b4a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">代码的“核心”是我们找到对象并在它的中心画一个红点的圆的部分。</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="55bf" class="mh ky iq md b gy mi mj l mk ml"># only proceed if the radius meets a minimum size<br/>if radius &gt; 10:<br/>	# draw the circle and centroid on the frame,<br/>	# then update the list of tracked points<br/>	cv2.circle(frame, (int(x), int(y)), int(radius),<br/>		(0, 255, 255), 2)<br/>	cv2.circle(frame, center, 5, (0, 0, 255), -1)<br/>			<br/>	# print center of circle coordinates<br/>	mapObjectPosition(int(x), int(y))<br/>			<br/>	# if the led is not already on, turn the LED on<br/>	if not ledOn:<br/>		GPIO.output(redLed, GPIO.HIGH)<br/>		ledOn = True</span></pre><p id="8ba1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们将中心坐标“导出”到<em class="mm"> mapObjectPosition(int(x)，int(y)) </em>函数，以便打印其坐标。功能下方:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="4faa" class="mh ky iq md b gy mi mj l mk ml">def mapObjectPosition (x, y):<br/>    print ("[INFO] Object Center coordinates at \<br/>    X0 = {0} and Y0 =  {1}".format(x, y))</span></pre><p id="e985" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">运行该程序，我们将在终端上看到(x，y)位置坐标，如上所示。移动物体，观察坐标。我们会意识到x从0到500(从左到右)，y从o到350(从上到下)。见上图。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/3084651796655a0abdca1cbc6b2e8ac9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*KlTqM5nedcAVLQln."/></div></figure><p id="4a01" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">太好了！现在，我们必须使用这些坐标作为平移/倾斜跟踪系统的起点</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/9a283ffd75eee07b63b0c4edcb1ee71c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*-udqFJ5gRQNdBqde."/></div></figure><h1 id="b05a" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">10.物体位置跟踪系统</h1><p id="f06d" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">我们希望我们的对象总是在屏幕上居中。因此，让我们定义，例如，我们将认为我们的对象“居中”，如果:</p><ul class=""><li id="3ef0" class="na nb iq jp b jq jr ju jv jy nc kc nd kg ne kk nf ng nh ni bi translated">220 &lt; x &lt; 280</li><li id="53a8" class="na nb iq jp b jq nj ju nk jy nl kc nm kg nn kk nf ng nh ni bi translated">160 &lt; y &lt; 210</li></ul><p id="98f5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这些界限之外，我们必须移动我们的平移/倾斜机构来补偿偏差。基于此，我们可以构建函数<em class="mm">mapservosition(x，y) </em>如下。请注意，此功能中用作参数的“x”和“y”与我们之前用于打印中心位置的参数相同:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="c3dd" class="mh ky iq md b gy mi mj l mk ml"># position servos to present object at center of the frame<br/>def mapServoPosition (x, y):<br/>    global panAngle<br/>    global tiltAngle<br/>    if (x &lt; 220):<br/>        panAngle += 10<br/>        if panAngle &gt; 140:<br/>            panAngle = 140<br/>        positionServo (panServo, panAngle)<br/>    if (x &gt; 280):<br/>        panAngle -= 10<br/>        if panAngle &lt; 40:<br/>            panAngle = 40<br/>        positionServo (panServo, panAngle)<br/>    if (y &lt; 160):<br/>        tiltAngle += 10<br/>        if tiltAngle &gt; 140:<br/>            tiltAngle = 140<br/>        positionServo (tiltServo, tiltAngle)<br/>    if (y &gt; 210):<br/>        tiltAngle -= 10<br/>        if tiltAngle &lt; 40:<br/>            tiltAngle = 40<br/>        positionServo (tiltServo, tiltAngle)</span></pre><p id="5c3f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基于(x，y)坐标，使用功能<em class="mm">位置伺服(伺服，角度)生成伺服位置命令。</em>例如，假设y位置是“50”，这意味着我们的对象几乎在屏幕的顶部，这可以解释为我们的“摄像机视线”是“低的”(比如说120度的倾斜角)，所以我们必须“减小”倾斜角(比如说100度)，所以摄像机视线将是“向上的”，对象将在屏幕上“向下”(y将增加到比如说190度)。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/a1fa103043e18e6000d3896ed332337c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*ge-flqm6YV3bHizd."/></div></figure><p id="fe3c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">上图显示了几何方面的示例。</p><p id="1ffc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">想想全景摄像机将如何操作。请注意，屏幕不是镜像的，这意味着如果你将对象移动到“你的左边”，一旦你与相机相对，它将在屏幕上移动到“你的右边”。</p><p id="c5fb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">函数positionServo(伺服，角度)可以写成:</p><pre class="km kn ko kp gt mc md me mf aw mg bi"><span id="1048" class="mh ky iq md b gy mi mj l mk ml">def positionServo (servo, angle):<br/>    os.system("python angleServoCtrl.py " + str(servo) + " " + <br/>              str(angle))<br/>    print("[INFO] Positioning servo at GPIO {0} to {1} \<br/>    degrees\n".format(servo, angle))</span></pre><p id="ba2a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将调用之前显示的脚本进行伺服定位。</p><p id="f405" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，angleServoCtrl.py必须与objectDetectTrac.py位于同一目录中</p><p id="5057" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">完整的代码可以从我的GitHub下载:<a class="ae ma" href="https://github.com/Mjrovai/OpenCV-Object-Face-Tracking/blob/master/Object_Tracking/objectDetectTrack.py" rel="noopener ugc nofollow" target="_blank"> objectDetectTrack.py </a></p><p id="e460" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面的gif展示了我们的项目工作的一个例子:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/7912c06c65726e5e1a5f60da521579e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/0*CsE_19QURjVVXlWg."/></div></figure><h1 id="e06d" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">11.结论</h1><p id="f783" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">一如既往，我希望这个项目可以帮助其他人找到进入令人兴奋的电子世界的方法！</p><p id="5a83" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">详情和最终代码，请访问我的GitHub仓库:<a class="ae ma" href="https://github.com/Mjrovai/OpenCV-Object-Face-Tracking" rel="noopener ugc nofollow" target="_blank">OpenCV-Object-Face-Tracking</a></p><p id="98bb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">更多项目，请访问我的博客:<a class="ae ma" href="https://mjrobot.org/" rel="noopener ugc nofollow" target="_blank">MJRoBot.org</a></p><p id="1bac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是我的下一个教程，我们将探索“人脸跟踪和检测”:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/c48253c5fad4a55685dc29231011ef6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/0*3i4UQyVSQRHR2rc8."/></div></figure><p id="1546" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">来自世界南部的Saludos！</p><p id="48c8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我的下一篇文章再见！</p><p id="cdcb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">谢谢你，</p><p id="415c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">马塞洛</p></div></div>    
</body>
</html>