# 数据问题

> 原文：<https://towardsdatascience.com/the-data-question-b6a8b60dc934?source=collection_archive---------19----------------------->

我们需要多少数据来构建这个计算机视觉分类器？这是数据问题。根据我的经验，数据问题几乎出现在我们接手的每个计算机视觉项目中，答案通常是“视情况而定”和其他人一起，State Farm 数据科学界一直在研究数据量对深度神经网络的影响，今年我们取得了一些重大进展。

![](img/a1120ee6e102ea2024ae7c97618db4d0.png)

Photo by [Chris Ried](https://unsplash.com/@cdr6934?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral)

# 数据问题

第一次有人问我，“*我们需要多少数据？*“早在 2014 年，我就在研究一种通过照片评估车辆损坏的图像分类器。这是一项艰巨的任务，因为相关的标记数据短缺，因此，分类器的整体性能很好，但不如业务领域所希望的那样好。在讨论这个令人乏味的结果时，我发现我不知道建立这种深度神经网络需要多少数据。

在接下来的几年里，我们开发了一些试探法，试图回答这个持续的数据量难题。然而，数据问题从未消失。在为计算机视觉构建深度神经网络时，大多数数据科学家和机器学习工程师都同意，标记良好的高质量数据往往供不应求。我们希望更全面地了解数据量和深度神经网络错误之间的关系，尤其是在使用迁移学习时。

# 数据量案例研究

谷歌研究院和卡耐基梅隆大学的孙辰、阿比纳夫·什里瓦斯塔瓦、绍拉布·辛格和阿比纳夫·古普塔最近进行了一项联合[案例研究](https://arxiv.org/pdf/1707.02968.pdf)，他们在测量网络误差的同时，用越来越多的数据增量训练了一个深度神经网络。他们发现，网络的性能随着训练数据量的对数而线性提高。换句话说，数据越多，网络性能越好。

这项研究的结果表明，更多的数据总是有助于减少深度神经网络的错误。我们提出了自己的疑问:如果更多的数据有助于深度学习，迁移学习会发生什么？从这一点出发，我们借此机会调查了数据量对迁移学习的影响。

# 迁移学习

在计算机视觉的实际商业应用中，我们很少从零开始训练一个深度神经网络；相反，我们使用一种叫做迁移学习的技术。通过迁移学习，我们可以将在一般图像识别任务上训练的深度神经网络应用于新的问题领域。深度神经网络只需要学习新的分类任务，而不是图像识别的基础知识。我们这样做是因为它在目标域中需要的数据要少得多。虽然源域数据集可能需要数百万幅图像，但目标域数据集只需要数千幅相关图像。例如，我们可能会从另一名研究人员在 [ImageNet](http://www.image-net.org/) 上训练的深度神经网络开始，ImageNet 是一个使用一百万张图像的 1000 类分类器，然后将该网络应用于识别猫和狗之间差异的任务。在这样做的时候，我们可能只需要目标域中的几百张图片就足够了，而从头开始我们可能需要几百万张。

# 数据量和迁移学习

我们的机器学习研究人员受到了孙等人的工作和发现的启发。这引发了我们的好奇心。如果我们把他们研究中的实验扩展到学习应用中会怎么样？我们想知道目标域中的数据量如何影响深度神经网络的性能。具体来说，我们想知道网络是否会随着数据量的增加而不断改进。迁移学习的应用产生了第二个重要问题。源域和目标域之间的相似性会影响您需要的数据量吗？例如，如果你从一个接受过架构培训的网络开始，并试图转移到一个完全不同的领域，如人脸，这是否需要比源和目标领域更相似的*更多的*数据？

这些问题引导我们进行自己的实验，并在 2017 年 12 月撰写我们的第一篇论文。结果，[我们的工作](https://arxiv.org/pdf/1712.04008.pdf)发表在斯普林格的《智能系统和计算进展》上。我们被要求在 2018 年 10 月温哥华的未来技术大会上分享我们的发现。

# 关于迁移学习，我们学到了什么

我们的结果与 Sun 等人的结果一致。在目标领域中，在多个问题中，网络性能随着数据量的日志而增加，直到我们用完数据。更多相关的训练数据似乎总是有帮助的，而且据我们所知，永远没有“足够的数据”。正如我们提到的，这种关系是对数级的，因此每单位网络性能似乎需要指数级的更多数据。

我们还发现在源/目标分布相似性和数据量之间存在关系。随着源/目标相似性的偏离，数据量似乎变得更加重要。这种关系不太清楚，需要做更多的工作。

# 那么，我们回答了“数据问题”了吗？

也许吧。如果今天有人问我“数据问题”，我会回答说，更多相关的训练数据似乎总是有助于减少深度神经网络错误；但是我不能告诉你需要多少数据来实现一个特定的目标指标。

从我前面提到的那些启发中，我们可以猜测，对于一个简单的二进制分类问题，我们可以使用跨类似源和目标域的迁移学习，从每类 1000 个图像中获得足够的性能。即使我们从这些数据中获得的性能并不足够，我们也可以肯定地说，更多的数据将改善深度神经网络。我们可能永远也不会明确回答“数据问题”我们相信这里还有更多工作要做，我们当然希望我们的工作能激励其他研究人员继续阐明这种关系。

要了解更多关于迁移学习的信息，请查看我们来自 AnacondaCon 的名为“只有少量数据的深度学习”的[演示文稿](https://www.youtube.com/watch?v=ilpFzOPznJk)