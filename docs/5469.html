<html>
<head>
<title>Replacing your Word Embeddings by Contextualized Word Vectors</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用语境化的单词向量代替你的单词嵌入</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/replacing-your-word-embeddings-by-contextualized-word-vectors-9508877ad65d?source=collection_archive---------5-----------------------#2018-10-20">https://towardsdatascience.com/replacing-your-word-embeddings-by-contextualized-word-vectors-9508877ad65d?source=collection_archive---------5-----------------------#2018-10-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/4d8f98905faa1f4a52c0f8d39294413f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*s1euvPbDYv5grquW"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">“high-rise buildings” by <a class="ae kf" href="https://unsplash.com/@mparente?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Micaela Parente</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="9563" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">受 Mikolov 等人(2013)和 Pennington 等人(2014)的影响，单词嵌入成为初始化 NLP 项目的基本步骤。之后又引入了很多嵌入如<a class="ae kf" rel="noopener" target="_blank" href="/combing-lda-and-word-embeddings-for-topic-modeling-fe4a1315a5b4">LDA 2 vec</a>(Moody Christopher，2016)<a class="ae kf" rel="noopener" target="_blank" href="/besides-word-embedding-why-you-need-to-know-character-embedding-6096a34a3b10">字符嵌入</a>，doc2vec 等等。今天，我们有了新的嵌入，即语境化的单词嵌入。这种想法是相似的，但他们实现了相同的目标，即使用更好的单词表示来解决 NLP 任务。</p><p id="aa02" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">看完这篇帖子，你会明白:</p><ul class=""><li id="a628" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated">语境化的词向量设计</li><li id="373e" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">体系结构</li><li id="7f06" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">履行</li><li id="3f92" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">拿走</li></ul><h1 id="80a7" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">语境化的词向量设计</h1><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mq"><img src="../Images/82d153c87e7893662820ed44b0af7373.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nezTPWuKVR5B_nlH"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">“white sand beach under white sky” by <a class="ae kf" href="https://unsplash.com/@boredbanker?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Itchy Feet</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="b088" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">受 CNN 的启发，McCAnn 等人专注于训练编码器，并将其转换为其他任务，以便可以利用更好的单词表示。不使用 skip-gram (Mikolov 等人，2013 年)或矩阵分解(Pennington 等人，2014 年)，而是利用机器翻译来构建上下文化的词向量(CoVe)。</p><p id="bc30" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设机器翻译(MT)足够通用以捕获单词的“含义”，我们建立一个编码器和解码器架构来训练 MT 的模型。之后，我们将编码器层“转移”到其他 NLP 任务(如分类问题和问题回答问题)中转移单词向量。</p><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mv"><img src="../Images/20b979a57c8144a468d7afca72251106.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HSqYzxsbONUCujQ3jc0q2Q.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">McCann B., Bradbury J., Xiong C., Socher R. (2017)</figcaption></figure><p id="4b49" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">图 a 显示了如何为机器翻译训练模型。给出单词向量(例如 GloVe ),以便我们可以从模型中获得上下文向量(CoVe)。</p><h1 id="3b12" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">体系结构</h1><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/00252219f7fdb38c477c7d6c4a2f18da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*MTnt2HzYrso5Zx-QVaLb1g.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">McCann B., Bradbury J., Xiong C., Socher R. (2017)</figcaption></figure><p id="b24b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">图 b 显示了重用结果 a 中的编码器并将其应用于其他 NLP 问题。</p><figure class="mr ms mt mu gt ju gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/60bb02eba44d2b91bfcedfa86bb36d87.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*Z7XYLnSQ2fYNfZTuVYIayQ.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">McCann B., Bradbury J., Xiong C., Socher R. (2017)</figcaption></figure><p id="4b7a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如图 b 所示，“特定任务模型”的输入是单词向量(例如 GloVe 或 word2vec)和编码器(即来自 MT 的结果)。因此，McCann 等人引入了上述公式来获得新词嵌入(串联 GloVe(w)和 CoVe(w))。</p><p id="85e6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="ki iu"> <em class="my">实现</em> </strong></p><p id="5bd3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在此之前，您需要安装相应的库(从 CoVe github 复制):</p><pre class="mr ms mt mu gt mz na nb nc aw nd bi"><span id="89a2" class="ne lt it na b gy nf ng l nh ni">git clone https://github.com/salesforce/cove.git # use ssh: git@github.com:salesforce/cove.git<br/>cd cove<br/>pip install -r requirements.txt<br/>python setup.py develop<br/># On CPU<br/>python test/example.py --device -1<br/># On GPU<br/>python test/example.py</span></pre><p id="5b70" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您在“pip install-r requirements . txt”上遇到问题，您可以用以下命令替换它</p><pre class="mr ms mt mu gt mz na nb nc aw nd bi"><span id="4d64" class="ne lt it na b gy nf ng l nh ni">conda install -c pytorch pytorch<br/>pip install -e git+<a class="ae kf" href="https://github.com/jekbradbury/revtok.git#egg=revtok" rel="noopener ugc nofollow" target="_blank">https://github.com/jekbradbury/revtok.git#egg=revtok</a><br/>pip install <a class="ae kf" href="https://github.com/pytorch/text/archive/master.zip" rel="noopener ugc nofollow" target="_blank">https://github.com/pytorch/text/archive/master.zip</a></span></pre><p id="1718" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果用 Keras (Tensorflow)，可以按照这个<a class="ae kf" href="https://github.com/rgsachin/CoVe/blob/master/PortFromPytorchToKeras.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>建 CoVe。但是，在原来的笔记本上有一些问题，你可以看看我修改的版本作为参考。问题在于原始凹穴(pytorch 将层名称从“rnn”更新为“rnn1”)。<a class="ae kf" href="https://github.com/rgsachin/CoVe" rel="noopener ugc nofollow" target="_blank">预训练模型</a>(下载 Keras_CoVe.h5)也可用。</p><p id="61e4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">另一方面，你也可以使用预先转换的 Keras 版本。</p><pre class="mr ms mt mu gt mz na nb nc aw nd bi"><span id="291a" class="ne lt it na b gy nf ng l nh ni"># Init CoVe Model<br/>cove_model = keras.models.load_model(cove_file)</span><span id="b703" class="ne lt it na b gy nj ng l nh ni"># Init GloVe Model<br/>glove_model = GloVeEmbeddings()        glove_model.load_model(dest_dir=word_embeddings_dir, process=False)</span><span id="8157" class="ne lt it na b gy nj ng l nh ni"># Encode sentence by GloVe<br/>x_embs = glove_model.encode(tokens)</span><span id="5f3f" class="ne lt it na b gy nj ng l nh ni"># Encode GloVe vector by CoVe<br/>x_embs = cove_model.predict(x_embs)</span></pre><h1 id="d182" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">拿走</h1><p id="655d" class="pw-post-body-paragraph kg kh it ki b kj nk kl km kn nl kp kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">要访问所有代码，可以访问这个<a class="ae kf" href="https://github.com/makcedward/nlp/blob/master/sample/nlp-embeddings-word-cove.ipynb" rel="noopener ugc nofollow" target="_blank"> github </a> repo。</p><ul class=""><li id="35b9" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated">CoVe <strong class="ki iu">需要标签数据</strong>来获得上下文单词向量。</li><li id="71cf" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated"><strong class="ki iu">用手套建造洞穴</strong></li><li id="4299" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">CoVe <strong class="ki iu">无法解决 OOV 问题</strong>它建议使用零向量来表示未知单词。</li></ul><h1 id="dd23" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">关于我</h1><p id="49f6" class="pw-post-body-paragraph kg kh it ki b kj nk kl km kn nl kp kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">我是湾区的数据科学家。专注于数据科学、人工智能，尤其是 NLP 和平台相关领域的最新发展。你可以通过<a class="ae kf" href="http://medium.com/@makcedward/" rel="noopener">媒体博客</a>、<a class="ae kf" href="https://www.linkedin.com/in/edwardma1026" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae kf" href="https://github.com/makcedward" rel="noopener ugc nofollow" target="_blank"> Github </a>联系我。</p><h1 id="ee43" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">参考</h1><p id="ce06" class="pw-post-body-paragraph kg kh it ki b kj nk kl km kn nl kp kq kr nm kt ku kv nn kx ky kz no lb lc ld im bi translated">放大图片作者:Michael b ...在翻译中学习:语境化的词向量。2017.<a class="ae kf" href="http://papers.nips.cc/paper/7209-learned-in-translation-contextualized-word-vectors.pdf" rel="noopener ugc nofollow" target="_blank">http://papers . nips . cc/paper/7209-learned-in-translation-contextualized-word-vectors . pdf</a></p><p id="a1dc" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://github.com/salesforce/cove" rel="noopener ugc nofollow" target="_blank">py torch 的小海湾</a>(原文)</p><p id="cbeb" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae kf" href="https://github.com/rgsachin/CoVe" rel="noopener ugc nofollow" target="_blank">喀拉斯湾</a></p></div></div>    
</body>
</html>