<html>
<head>
<title>Decision Trees — Pruning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">决策树—修剪</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/decision-trees-pruning-4241cc266fef?source=collection_archive---------7-----------------------#2018-07-20">https://towardsdatascience.com/decision-trees-pruning-4241cc266fef?source=collection_archive---------7-----------------------#2018-07-20</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/a3380aa4942623df459647f9e154d492.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zEQSDCKf6Dm0A0-X"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">image by Sarah Dorweiler on <a class="ae jd" href="http://unsplash.com/" rel="noopener ugc nofollow" target="_blank">unsplash.com</a></figcaption></figure><div class=""/><p id="1b25" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我的上一篇博客关注的是决策树的概念，它是随机森林机器学习算法的基础。因为这只是一篇很短的博客(4 分钟阅读)，我没有深究细节，但是嵌入了一些(希望)有用的链接。</p><p id="49fc" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我想更进一步，涵盖:</p><ul class=""><li id="1a8f" class="lb lc jg kf b kg kh kk kl ko ld ks le kw lf la lg lh li lj bi translated">随机森林如何使用决策树</li><li id="70e3" class="lb lc jg kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">过度拟合的问题以及如何识别它</li><li id="1992" class="lb lc jg kf b kg lk kk ll ko lm ks ln kw lo la lg lh li lj bi translated">修剪决策树以限制过度拟合问题。</li></ul><p id="0835" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">正如您将看到的，R 中的机器学习非常简单，通常只需要几行代码就可以让模型运行起来。尽管有用，算法使用的默认设置很少是理想的。</p><p id="4736" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下代码是准备分类树模型的示例。我使用了“rpart”包，但是“caret”是另一种选择。</p><p id="ac55" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Model = rpart(分类器~预测器，data = train_data，method = "class "，control = rpart.control(###))</p><p id="5109" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">“分类器”是模型预测的特征，“预测器”是数据集中的独立特征，用于确定分类器结果的概率。</p><p id="7b13" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">method = "class "语句将确保为分类器(为因子类型变量)做出预测。例如，准备与贷款偿还数据集相关的脚本。分类器是申请人是否“偿还”或“违约”债务，有许多特征(列)可用于预测这一结果。随机森林算法使用许多决策树，这些决策树是使用训练数据的随机段准备的。然后，测试数据集中的每个观察值通过每个树运行，以独立地对分类器的结果进行预测。由最大数量的树预测的分类代表模型的预测。如果大多数树预测贷款将被偿还，那么这就是模型的预测。</p><p id="0523" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">测试数据$预测</p><p id="3777" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Once a prediction vector was created, the overall accuracy of the models could be calculated and a confusion matrix produced showing which of the two outcomes (repaid and default) the model was best at predicting.</p><p id="f3ca" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">准确度</strong> =平均值(测试数据$预测==测试数据$实际结果)</p><p id="018b" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf jh">混淆矩阵</strong> =表格(测试数据$预测，测试数据$实际 _ 结果)</p><p id="a71d" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在我在 Data Camp 完成的一个活动中，我比测试标准决策树和我修剪过的版本的准确性的要求更进一步。修剪的原因是由基本算法准备的树可能倾向于过度拟合，因为它们变得非常大和复杂。下面我展示了使用不带调整参数的基本算法生成的决策树。不要担心字体太小而无法阅读，我只是简单地强调了在没有添加控制参数的情况下树可以有多复杂。</p><figure class="lq lr ls lt gt is gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/95bae59e91b2a2d42cc234807437f216.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*a-Mz-VSlFjTKp8Ej.png"/></div></figure><p id="f77a" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我修剪树的时候，我测试了 minsplit(在被‘修剪’之前出现在叶子中的观察数量)和 maxdepth(一个分支中的最大节点数量)的不同值。如果你喜欢快速更新的话，这个术语在我之前的博客中已经全部介绍过了！</p><figure class="lq lr ls lt gt is gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/f252a680fc4df14ec68c6cbab79aecee.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*mu_1bTqHACI5V-zp.png"/></div></figure><p id="7b7e" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我发现一个复杂度显著降低的树实际上提供了一点准确性的提高——我的目标是保持准确性稳定！原始模型在违约和已偿还住房贷款方面产生了类似的准确性水平，而新模型在预测违约贷款方面有了显著改善，其已偿还贷款预测的准确性下降较小。这将是值得探索的，但是复杂性的大幅降低仍然产生了很好的结果。</p><figure class="lq lr ls lt gt is gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/8561ef7fca0689238e0cf28c1e55dac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*SWcmkoLcP8SZbVod.png"/></div></figure><p id="c9e2" class="pw-post-body-paragraph kd ke jg kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这是我为标准树和修剪树准备的代码。只有少量的代码，还有很大的改进空间！</p><pre class="lq lr ls lt gt lu lv lw lx aw ly bi"><span id="2251" class="lz ma jg lv b gy mb mc l md me"># Trees prepared with no pruning<br/># prepare model<br/>lm &lt;- rpart(outcome ~ ., data = loans_train, method = “class”, control = rpart.control(cp = 0))</span><span id="7160" class="lz ma jg lv b gy mf mc l md me"># prepare prediction</span><span id="7e97" class="lz ma jg lv b gy mf mc l md me">loans_test$PredLM &lt;- predict(lm,loans_test, type = “class”)</span><span id="e797" class="lz ma jg lv b gy mf mc l md me"># calculate overall accuracy</span><span id="0fa3" class="lz ma jg lv b gy mf mc l md me">mean(loans_test$PredLM == loans_test$outcome)</span><span id="45f4" class="lz ma jg lv b gy mf mc l md me"># prepare confusion matrix</span><span id="d4c1" class="lz ma jg lv b gy mf mc l md me">table(loans_test$PredLM,loans_test$outcome)</span><span id="2707" class="lz ma jg lv b gy mf mc l md me"># plot tree</span><span id="136e" class="lz ma jg lv b gy mf mc l md me">rpart.plot(lm, type = 3, box.palette = c(“red”, “green”), fallen.leaves = TRUE)</span><span id="e464" class="lz ma jg lv b gy mf mc l md me"># Trees prepared with pruning</span><span id="0e90" class="lz ma jg lv b gy mf mc l md me"># prepare model</span><span id="8aec" class="lz ma jg lv b gy mf mc l md me">lmp &lt;- rpart(outcome ~ ., data = loans_train, method = “class”, control = rpart.control(cp = 0, minsplit = 250, maxdepth = 6))</span><span id="20ed" class="lz ma jg lv b gy mf mc l md me"># prepare prediction</span><span id="c20b" class="lz ma jg lv b gy mf mc l md me">loans_test$PredLMP &lt;- predict(lmp,loans_test, type = “class”)</span><span id="cf15" class="lz ma jg lv b gy mf mc l md me"># calculate overall accuracy</span><span id="e0b9" class="lz ma jg lv b gy mf mc l md me">mean(loans_test$PredLMP == loans_test$outcome)</span><span id="7f5e" class="lz ma jg lv b gy mf mc l md me"># prepare confusion matrix</span><span id="8041" class="lz ma jg lv b gy mf mc l md me">table(loans_test$PredLMP,loans_test$outcome)</span><span id="fc16" class="lz ma jg lv b gy mf mc l md me"># plot tree</span><span id="1335" class="lz ma jg lv b gy mf mc l md me">rpart.plot(lmp, type = 3,cex = .7, box.palette = c(“red”, “green”), fallen.leaves = TRUE)</span></pre></div></div>    
</body>
</html>