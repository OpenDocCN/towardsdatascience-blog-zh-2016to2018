<html>
<head>
<title>Teaching machines to speak and improvise blues jazz</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">教机器说话和即兴演奏布鲁斯爵士乐</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/teaching-machines-to-speak-and-improvise-blues-jazz-283571983c89?source=collection_archive---------10-----------------------#2017-07-09">https://towardsdatascience.com/teaching-machines-to-speak-and-improvise-blues-jazz-283571983c89?source=collection_archive---------10-----------------------#2017-07-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="9861" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于本周的文章，我想重点关注<em class="kl">长短期记忆</em> (LSTM)模型的例子，因为它们是我在深度学习中遇到的最优雅的概念之一。他们还为<a class="ae km" href="https://research.googleblog.com/2016/09/a-neural-network-for-machine.html" rel="noopener ugc nofollow" target="_blank">谷歌翻译</a>提供动力，帮助<a class="ae km" href="https://eng.uber.com/neural-networks/" rel="noopener ugc nofollow" target="_blank">优步预测极端事件期间的需求</a>，让亚马逊回声<a class="ae km" href="http://www.allthingsdistributed.com/2016/11/amazon-ai-and-alexa-for-all-aws-apps.html" rel="noopener ugc nofollow" target="_blank">听起来像真人</a>，教<a class="ae km" href="http://ieeexplore.ieee.org/document/4059310/?reload=true" rel="noopener ugc nofollow" target="_blank">机器人外科医生打结</a>，甚至谱写<a class="ae km" href="http://people.idsia.ch/~juergen/blues/" rel="noopener ugc nofollow" target="_blank">新的布鲁斯爵士乐</a>。</p><h2 id="3a21" class="kn ko iq bd kp kq kr dn ks kt ku dp kv jy kw kx ky kc kz la lb kg lc ld le lf bi translated">挑战:我的狗有四只…</h2><p id="8bfa" class="pw-post-body-paragraph jn jo iq jp b jq lg js jt ju lh jw jx jy li ka kb kc lj ke kf kg lk ki kj kk ij bi translated">假设我让你猜句子<em class="kl">“我的狗有四条腿……”</em>中的下一个作品，你可能会说“腿”。在这种情况下，最后一个单词的上下文在紧邻的前一个单词内。除了知道句子的主语是“狗”，你不需要任何上下文。<em class="kl">递归神经网络</em> (RNNs) <em class="kl"> </em>特别擅长做这类预测，当上下文和预测之间的差距很小时。</p><p id="8147" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是如果我说的不是上面的，而是:</p><p id="4cd7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">“我有一只叫查理的狗。查理喜欢在我出去的时候追棍子，追猫，吃我的鞋子。查理有四个…”</p><p id="b02d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你也会猜“腿”。但那只是因为你<strong class="jp ir">记得</strong>的相关上下文，即“查理”是我的“狗”。相关的上下文并不是紧接在前面的单词的一部分，而是在故事的开头。对于这类问题——当上下文和预测之间的差距很大时——rnn 很快就会崩溃。这就是长短期记忆模型的用武之地。</p><h2 id="a7a8" class="kn ko iq bd kp kq kr dn ks kt ku dp kv jy kw kx ky kc kz la lb kg lc ld le lf bi translated">你的记忆是做什么的？</h2><p id="d1cb" class="pw-post-body-paragraph jn jo iq jp b jq lg js jt ju lh jw jx jy li ka kb kc lj ke kf kg lk ki kj kk ij bi translated">想想你自己的记忆。它有效地做了三件事:</p><ol class=""><li id="6e28" class="ll lm iq jp b jq jr ju jv jy ln kc lo kg lp kk lq lr ls lt bi translated"><strong class="jp ir">记录新信息</strong>(输入门)—<em class="kl">“我回到家，把钥匙放在烤箱旁边”</em></li><li id="7a99" class="ll lm iq jp b jq lu ju lv jy lw kc lx kg ly kk lq lr ls lt bi translated"><strong class="jp ir">忘记一些信息</strong>(忘记门)–<em class="kl">忘记钥匙在烤箱旁边</em></li><li id="92fd" class="ll lm iq jp b jq lu ju lv jy lw kc lx kg ly kk lq lr ls lt bi translated"><strong class="jp ir">向前传递剩余信息</strong>(输出门)–<strong class="jp ir"/><em class="kl">我回到家，把钥匙放在某个地方</em></li></ol><p id="b2f0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">LSTMs 使用上述三个函数来为它试图预测的事物提供上下文。然后，它每次接受一小组单词(例如，“我有一只狗……”)，以(a)预测下一个单词(“叫查理”)和(b)记住句子的上下文(“狗”)。然后，当它需要预测句子后半部分的下一个单词(“查理有四个……”)时，它依靠记忆通知它我们在这里谈论的是一只狗，因此可能的答案是“腿”。</p><p id="e529" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">LSTMs 已经被证明在长时间内保持相关的上下文信息是非常有效的。</p><figure class="ma mb mc md gt me gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/b7cd1a479156d1bc6c3b2fab37b70453.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*38GcmBB4fbc5XDdTlerVPw.png"/></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk">A memory cell. It takes as an input 1) new information + 2) outputted memory from an earlier cell. It then forgets some of its information. Finally, it outputs 1) a prediction + 2) the input into the <strong class="bd ml"><em class="mm">next </em></strong><em class="mm">memory cell. Source: deeplearning.net</em></figcaption></figure><h2 id="f6af" class="kn ko iq bd kp kq kr dn ks kt ku dp kv jy kw kx ky kc kz la lb kg lc ld le lf bi translated">给机器人类语言</h2><p id="61a2" class="pw-post-body-paragraph jn jo iq jp b jq lg js jt ju lh jw jx jy li ka kb kc lj ke kf kg lk ki kj kk ij bi translated">如果你在 Mac / iOS 上阅读这篇文章，试试这个:<strong class="jp ir">突出显示这一段，然后进入编辑- &gt;语音- &gt;开始朗读</strong> (OSX) <strong class="jp ir">或点击朗读</strong> (iOS)。</p><p id="9432" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">或者，这里有一个你会听到的例子:</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mn mo l"/></div><figcaption class="mh mi gj gh gi mj mk bd b be z dk">A basic text-to-speech (not using LSTMs). Notice how it sounds monotone and not like a human. <a class="ae km" href="https://www.youtube.com/watch?v=RXznVo_JurI" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="b067" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">虽然你能理解字面意思，但它听起来显然不像人类。它是单调的，声音不像人类那样掌握同样的语调。在高层次上，您可以将人类语言视为以下内容的组合:</p><ol class=""><li id="50b9" class="ll lm iq jp b jq jr ju jv jy ln kc lo kg lp kk lq lr ls lt bi translated">你说的话</li><li id="057e" class="ll lm iq jp b jq lu ju lv jy lw kc lx kg ly kk lq lr ls lt bi translated">你使用的音高</li><li id="683e" class="ll lm iq jp b jq lu ju lv jy lw kc lx kg ly kk lq lr ls lt bi translated">你发音的节奏</li></ol><p id="9e11" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(1)很容易做到，因为<em class="kl">通常</em>不是上下文相关的。警告是一个异义词(两个单词拼写相同，但发音和含义不同，如“我们必须擦亮波兰家具”或“请关上你靠近的门”)。</p><p id="2fd7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是(2)和(3)(音高/节奏)是<em class="kl">高度</em>语境化的，基于你试图传达的内容(想象一下如果小马丁·路德·金的“我有一个梦想”演讲被苹果单调的 Safari 阅读器阅读)。高级语言语音系统，如百度的<a class="ae km" href="http://research.baidu.com/deep-voice-production-quality-text-speech-system-constructed-entirely-deep-neural-networks/" rel="noopener ugc nofollow" target="_blank">或亚马逊的</a><a class="ae km" href="http://www.allthingsdistributed.com/2016/11/amazon-ai-and-alexa-for-all-aws-apps.html" rel="noopener ugc nofollow" target="_blank">Polly</a>(Alexa 背后的声音)通过对人类声音的音高和节奏进行编码来解决这一问题，并应用 LSTMs 不仅预测下一个单词，还预测下一个单词的音高和节奏。</p><p id="3db2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里有一个使用不同的 TTS 系统阅读的两个英语句子的例子。你会注意到第三个——<a class="ae km" href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/" rel="noopener ugc nofollow" target="_blank">谷歌的 WaveNet </a>，它使用 lst ms——听起来更像人类。</p><figure class="ma mb mc md gt me"><div class="bz fp l di"><div class="mp mo l"/></div></figure><h1 id="1ff7" class="mq ko iq bd kp mr ms mt ks mu mv mw kv mx my mz ky na nb nc lb nd ne nf le ng bi translated">用 LSTMs 创作蓝调爵士乐</h1><p id="cc93" class="pw-post-body-paragraph jn jo iq jp b jq lg js jt ju lh jw jx jy li ka kb kc lj ke kf kg lk ki kj kk ij bi translated">Eck 和 Schmidhüber 将 LSTMs 应用于音乐创作，通过随机选择符合布鲁斯风格音乐形式的旋律来训练他们的模型。具体来说，他们训练他们的 LSTM 学习如何生成新的旋律结构，以“适应”和弦结构。这是第一次使用神经网络来捕捉音乐中的<em class="kl">全局音乐结构</em>(即歌曲早期部分的上下文记忆)，而不是<em class="kl">局部音乐结构</em>(就像 RNNs 能够做的那样)。</p><p id="7deb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae km" href="http://people.idsia.ch/~juergen/blues/lstm_0224_2200.mp3" rel="noopener ugc nofollow" target="_blank">这是一个示例输出</a>。虽然它不是 B. B. King，但它非常好，并且显示了我们离用 LSTMs 生成高级爵士乐有多近。</p></div></div>    
</body>
</html>