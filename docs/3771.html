<html>
<head>
<title>Inside the Mind of a Neural Network with Interactive Code in Tensorflow (Histogram, Activation, Interior/Integral Gradients) [ Manual Back Prop with TF ]</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 Tensorflow(直方图、激活、内部/整体梯度)中具有交互式代码的神经网络的思维内部[带 TF 的手动背部道具]</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/inside-the-mind-of-a-neural-network-with-interactive-code-in-tensorflow-histogram-activation-a4dff0963103?source=collection_archive---------6-----------------------#2018-06-16">https://towardsdatascience.com/inside-the-mind-of-a-neural-network-with-interactive-code-in-tensorflow-histogram-activation-a4dff0963103?source=collection_archive---------6-----------------------#2018-06-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/fc3d1213f02c28b907c69eccc7510dae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*Y8_BVqyj3ESgBd_tT09YMw.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">GIF from this <a class="ae jy" href="https://giphy.com/gifs/trippy-9lRBSGg6l68Hm" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="f277" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">很长时间以来，我一直想了解我的模型的内部运作。从今天开始，我希望了解与这个主题相关的话题。在这篇文章中，我想涵盖三个主题，权重直方图，可视化神经元的激活，<a class="ae jy" href="https://arxiv.org/pdf/1703.01365.pdf" rel="noopener ugc nofollow" target="_blank">内部/积分梯度。</a></p><blockquote class="kx ky kz"><p id="5fd4" class="jz ka la kb b kc kd ke kf kg kh ki kj lb kl km kn lc kp kq kr ld kt ku kv kw ij bi translated"><strong class="kb ir">请注意，这篇文章是为了我未来的自己来回顾这些材料。</strong></p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="6c34" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">在</strong>上阅读之前</p><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="lp lq l"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Original Video from TechTalksTV (<a class="ae jy" href="https://vimeo.com/user72337760" rel="noopener ugc nofollow" target="_blank">https://vimeo.com/user72337760</a>) If any problem arises I will delete the video asap. Original video Link here: <a class="ae jy" href="https://vimeo.com/238242575" rel="noopener ugc nofollow" target="_blank">https://vimeo.com/238242575</a></figcaption></figure><p id="579a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这个视频超出了本文的范围，但它确实帮助我理解了内部和积分梯度，以及如何理解神经网络内部工作的概述。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="51e7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">数据集/网络架构/精确度/类别号</strong></p><div class="ll lm ln lo gt ab cb"><figure class="lr jr ls lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/53a81f3b923cfdb7960bfd7489318c66.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*UTT-slzftCA3GEhHfLcADg.png"/></div></figure><figure class="lr jr mb lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/01745f1cda31ff697224117997206bd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1452/format:webp/1*zp4mus_kus7-rtUYjx-YZQ.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk mc di md me">Image from this website</figcaption></figure></div><p id="4c35" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">红色矩形</strong> →输入图像(32*32*3) <br/> <strong class="kb ir">黑色矩形</strong> →与 ELU 卷积()有/无平均池<br/> <strong class="kb ir">橙色矩形</strong> → Softmax 进行分类</p><p id="7923" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">像往常一样，我们将使用 CIFAR 10 数据集来训练我们的<a class="ae jy" rel="noopener" target="_blank" href="/iclr-2015-striving-for-simplicity-the-all-convolutional-net-with-interactive-code-manual-b4976e206760">全卷积网络</a>，并尝试了解为什么网络会将某些图像预测到它的类别中。</p><p id="2429" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">有一点需要注意，因为这篇文章更多的是关于了解网络的内部运作。我将只使用测试集中的 50 张图片来衡量准确性。</p><div class="ll lm ln lo gt ab cb"><figure class="lr jr mf lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/22675df1dc10d6627b5fc190816c6fa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*cMAoKN4CLpuzmysGMFxN7w.png"/></div></figure><figure class="lr jr mf lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/67b0edc49b6275367cb7769e20340a60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*ogbFSdNdoTS_ihnGNvKxvw.png"/></div></figure></div><p id="51fa" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图像</strong> →测试图像(50 张图像)的精度/时间成本<br/> <strong class="kb ir">右图像</strong> →训练图像(50000 张图像)的精度/时间成本</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mg"><img src="../Images/b76f8614df2f96afdd7fefdc73f7335f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DSlnNXg9LzKIGrH-ppDHlQ.png"/></div></div></figure><p id="d2ac" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，该模型在第 7 个时期的最终精度为 81%。(如果您希望访问完整的培训日志，<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/Understanding_Concepts/COUNTERFACTUALS/viz/z_viz.txt" rel="noopener ugc nofollow" target="_blank">请点击此处</a>。)最后，让我们看看每个类的每个数字代表什么。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/efde651320b841737a867e82dcdb7d08.png" data-original-src="https://miro.medium.com/v2/resize:fit:380/format:webp/1*RbDCXexqffZMcsXUXksIYQ.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image from this <a class="ae jy" href="https://github.com/EN10/CIFAR" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="c2e6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">权重直方图(训练前/后)</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/07e0a5a475447e2fe0996cb57d4cba51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*Hsu1fFUCa24yOxhH37Czhg.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Histogram of weighs before training</figcaption></figure><p id="2b03" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">上图是每一层的权重直方图，为了便于可视化，我将每一层直方图分为三层。在最左侧，我们可以观察到权重的平均值通常为 0，标准偏差(stddev)值在 0.04 到 0.06 之间。这是意料之中的，因为我们用不同的 stddev 值声明了每个层。此外，一些曲线比其他曲线小的原因是由于每层的权重数不同。(例如，层 0 仅具有 3 * 3 * 128 的权重，而层 2 具有 3 * 128 * 128 的权重。)</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/e68fa224b4f90da484da03c7064a4629.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*hq3CXcSQ0TBaJC3vZJgpQA.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Different stddev values</figcaption></figure><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/8bd5b5d780a9a80155c39f3b681a6dfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*idASsiljOSGHJ2zOC7GeNA.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Histogram of weighs after training</figcaption></figure><p id="4bc7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">马上，我们可以观察到一个明显的差异。尤其是前三层。分布的范围从-5 增加到 5。然而，看起来大部分权重存在于-1 和 1 之间(或者接近于零。)对于第 4 层到第 6 层，看起来平均值和最后三层一样发生了偏移。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="5d40" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">可视化某些层的激活值</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/ac9aecf162653b2f84fd0cbbe1b6e2e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:306/format:webp/1*5Pkv0VO1DMpwXvXJyHHSbw.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Test Input for the network</figcaption></figure><p id="02e9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">使用由<a class="ae jy" href="https://arxiv.org/pdf/1506.06579.pdf" rel="noopener ugc nofollow" target="_blank">约辛斯基和他的同事</a>完成的技术，让我们想象上面的图像是如何在第 3、6 和 9 层之后被修改的。(请注意，我最初在这篇<a class="ae jy" href="https://medium.com/@awjuliani/visualizing-neural-network-layer-activation-tensorflow-tutorial-d45f8bf7bbc4" rel="noopener">博文</a>中发现了<a class="ae jy" href="https://medium.com/@awjuliani?source=post_header_lockup" rel="noopener">亚瑟·朱利安尼</a>使用的方法。)</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/c803a561058e2373106ea2d4051e962c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*jKiSdxG3DV-73ae1_lpfgA.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Activation after layer 3</figcaption></figure><p id="43b4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">绿框</strong> →捕捉绿色值的通道<br/> <strong class="kb ir">蓝框</strong> →捕捉蓝色值的通道</p><p id="2f0b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在有 128 个频道，所以我就不一一列举了。相反，我会想象前 27 个通道，如上所示。我们可以看到，在第 3 层之后，某些颜色值在网络中被捕获。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/f8cdba8ec9e9b9d7938f2ff88fe9deb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*rIJz9v0n1Yf8L2xqdjKFFg.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Activation for layer 6</figcaption></figure><p id="6c5d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">红色框</strong> →捕捉红色的通道</p><p id="8121" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">然而，在第六层之后，似乎某些过滤器能够比绿色或蓝色更好地捕捉红色。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/589f77ad2b8cd298fa58af8750f2d459.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*acyhAd98Q7pHjQUxrpWBlg.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Activation after layer 9</figcaption></figure><p id="d647" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最后，在第九层之后(就在全局平均汇集之前)，我们可以可视化深度为 1 的每个通道(因此它看起来像灰度图像)。然而(至少对我来说)，它似乎不是人类可以理解的。所有的图片都可以在这里找到<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/tree/master/Understanding_Concepts/COUNTERFACTUALS/viz" rel="noopener ugc nofollow" target="_blank"/>并且我创建了一个 GIF 来累积所有的变化。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/0457e8dd6cb7ad2ecb3d14ef1c487fdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/1*rIb0oJPAPEZ2mZdHwJnHTA.gif"/></div></figure><p id="76ae" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">GIF 的顺序</strong> →输入图像，第 3 层后激活，第 6 层后激活，第 9 层后激活</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="0230" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">内部渐变/正负属性</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/093e703ee625064518da43210d4101e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*9XabkHrJYU0GNdZ2B8QSTg.png"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">alpha value of 1.0</figcaption></figure><p id="727c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在让我们使用<a class="ae jy" rel="noopener" target="_blank" href="/google-iclr-2017-paper-summary-gradients-of-counterfactuals-6306510935f2">内部渐变</a>，阿尔法值为…<br/> 0.01，0.01，0.03，0.04，0.1，0.5，0.6，0.7，0.8，1.0(与原始输入相同)，来形象化的表现网络的内部运作。</p><div class="ll lm ln lo gt ab cb"><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/44b8ee9c2b8fb8a9df4cdfd87c909695.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*4-Wbe7nTmR_jYitL9Wu4Ng.png"/></div></figure><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/6faff2f381a999029dfacae375a8ed1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*AGR0mMzluNF8yd1lUt-Wlg.png"/></div></figure><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/b9f001f28e0e51a6233ff1b67cb406c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*hh2JJ9-QkTm2LHKVmdiH0A.png"/></div></figure></div><div class="ab cb"><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/99081fa0f6cbf7af56a471f7d3773d54.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*5Kc2bisLmAhWnrBZ_wf0SQ.png"/></div></figure><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/e6fcbfc963a0bd71b2a6bd3cde354996.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*rA-xI2kz4BeY4T9Ag3bWSw.png"/></div></figure><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/d1b97ec2f03b98c99fd8b9f5f263910f.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*U16rgP3BE5BpXg_nipOIxQ.png"/></div></figure></div><div class="ab cb"><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/c92a6e0c8a570799b02aa14861a6e241.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*jIQWfWkLtkOrgbLeFiKz5Q.png"/></div></figure><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/36e1dd6226af0d8f1723242ca9c9f4a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*BIZVSjCJaSlvQU1MTaTORw.png"/></div></figure><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/c62d7554b201133ac0f006844716ef62.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*_3OmDNxpQXQa5kvkinoTCA.png"/></div></figure></div><p id="6ee4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">上面的所有图像都代表了相对于具有不同 alpha 值的输入的梯度。我们可以观察到，随着 alpha 值的增加，由于网络中的饱和度，梯度变得更接近 0(黑色)。当我们以 gif 格式查看所有图像时，我们可以清楚地看到渐变是如何变化的。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mp"><img src="../Images/b748a50079ecd595ed314aae28f26d78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*sOaCgUWpnn7CsZg4hpOqzg.gif"/></div></div></figure><p id="de88" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">然而，我能够做出一个有趣的观察，随着 alpha 值变小，我的网络无法做出正确的预测。如下所示，当 alpha 值很小(0.01)时，网络通常预测 3 或 4。(猫/鹿)</p><div class="ll lm ln lo gt ab cb"><figure class="lr jr mf lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/7bd1632891b989af29c10405325238b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*oVmsr5gO0zhUxBVaI-borA.png"/></div></figure><figure class="lr jr mf lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/cd737a2fac644eaefb18c89ef835e476.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*IUXpry8UCPX__JUWGP0edA.png"/></div></figure></div><p id="d244" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">红框</strong> →车型预测</p><p id="1b27" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">但是随着 alpha 值的增加，最终达到 1.0，我们可以观察到模型的准确性增加了。最后，让我们看看每个 alpha 值的渐变的正负属性。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/dd1c980a50ce4f235023bcec0cb6d73f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*IfeHMwWW84xKqMXgmlZ5Nw.png"/></div></figure><p id="0b7d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">蓝色像素→ </strong>正属性覆盖原始图像<br/> <strong class="kb ir">红色像素→ </strong>负属性覆盖原始图像</p><div class="ll lm ln lo gt ab cb"><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/92ede355e3ec55ec39d1ff596a70b087.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*uFO5NwaHeGHq1JoBA3uEXA.png"/></div></figure><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/746d014515f6c30eadcc54d046e625f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*iIca1wXMi9deXx-eqxtT7Q.png"/></div></figure><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/947d1cb7d0407eb992cef4fcf4ddda3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*g6JvkZ1bHW4iwhzLv6Ej7w.png"/></div></figure></div><div class="ab cb"><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/0dfef96fee6a694191c17afce08c0ae8.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*4IuvPQsyGZY-T0x2uClHGg.png"/></div></figure><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/a6bd2ab9c3328e5a5e75ebb24384a542.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*m-FmBib92k8OcPw2xYGI2A.png"/></div></figure><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/2e671da9a6ddaebb1b4bbdd8bb5465de.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*9pd8H34K7VWDL1WZNAxvSA.png"/></div></figure></div><div class="ab cb"><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/526979533b9b8de07f871edcd23c0dc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*C30jCAj-2BQXCxpdKeq74g.png"/></div></figure><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/946184d083f9a12f01d7108c4728b9f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*e3w_7K5-7vVDNvSK1REAvg.png"/></div></figure><figure class="lr jr mo lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/239057fbb9a329d89cd3775857517372.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*BoeUDqrmG1kEVSxMntADIQ.png"/></div></figure></div><p id="f193" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同样，如果我们用这些图像创建一个 gif，会更容易看到变化。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/245cc0456ed34a8ec32e658ecded9bc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*Y10MrJ1SpeIfYOuoq6KCOA.gif"/></div></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="e8bd" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">积分梯度/正负属性</strong></p><div class="ll lm ln lo gt ab cb"><figure class="lr jr mf lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/9d4dd34baeb89901ba164dca6c779c03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*ox8XzFuozWqBKAlxoBQHzg.png"/></div></figure><figure class="lr jr mf lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><img src="../Images/0f3f80a297a8746095598833c1011e97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*FiWUQI9c6DPBAm94bhd88A.png"/></div></figure></div><p id="d90b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左图</strong> →步长为 3000 的积分梯度<a class="ae jy" href="https://en.wikipedia.org/wiki/Riemann_sum" rel="noopener ugc nofollow" target="_blank">黎曼近似</a> <br/> <strong class="kb ir">右图</strong> →蓝色表示正属性，红色表示负属性</p><p id="3587" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最后，当我们使用积分梯度来可视化梯度时，我们可以观察到类似上面的东西。我发现的一个非常有趣的事实是，网络是如何预测马(7)、狗(5)和鹿(4)的。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/f06a50c0e709400c33b5e4619a01629b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*L03RFLrSMahsorbYUTIx7w.png"/></div></figure><p id="9a9b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">让我们先看看原始图像，如左上图所示，中间的图像是马，右边的图像是羊。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/adbbb305a65eb281f966afdba1588f47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*uanppoxdYSOqmAaR2BNqkA.png"/></div></figure><p id="6d78" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">当我们可视化积分梯度时，我们可以看到一些有趣的东西。如中间的图片所示，网络认为马的头部是最重要的。但是，只拍头部的时候，网络以为是狗的形象。(它看起来有点像一只狗)。类似的故事对于右图，当网络只考虑到只有一只羊的头时，它预测为看到一只狗。</p><p id="39e8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">然而</strong>，如最左边的图像所示，当网络获得一匹马的整体形状(包括人类的某个部分)时，它会正确地将图像识别为一匹马。太神奇了！</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="6878" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">互动码</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/cbbe49a233e2e082ffc652606ad9565d.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*FOHvx1hg9XQMo9kyFmnYKQ.png"/></div></figure><p id="e8d8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于 Google Colab，你需要一个 Google 帐户来查看代码，而且你不能在 Google Colab 中运行只读脚本，所以在你的操场上复制一份。最后，我永远不会请求允许访问你在 Google Drive 上的文件，仅供参考。编码快乐！同样为了透明，我在 github 上上传了所有的训练日志。</p><p id="114a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">要访问这篇文章的代码，请<a class="ae jy" href="https://colab.research.google.com/drive/1ld8_40udZbnWALV1pU582JphXUZD-npn" rel="noopener ugc nofollow" target="_blank">点击这里</a>，培训<a class="ae jy" href="https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/Understanding_Concepts/COUNTERFACTUALS/viz/z_viz.txt" rel="noopener ugc nofollow" target="_blank">日志点击这里。</a></p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="7a1b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">最后的话</strong></p><p id="ffda" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">由于这个领域仍在成长和发展，将会有新的方法和发现。(我希望我也能为这些发现做出贡献。).最后，如果你想访问来自论文原作者的代码"<a class="ae jy" href="https://arxiv.org/abs/1703.01365" rel="noopener ugc nofollow" target="_blank"><em class="la"/></a><a class="ae jy" href="https://github.com/ankurtaly/Integrated-Gradients/blob/master/attributions.ipynb" rel="noopener ugc nofollow" target="_blank">请点击这里</a>。</p><p id="d00f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 给我，如果你想看我所有写作的列表，请在这里查看我的网站。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的推特<a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或者我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。我还实现了<a class="ae jy" href="https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec" rel="noopener">广残网，请点击这里查看博文 pos </a> t。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="9d6c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="d5ec" class="mt mu iq kb b kc kd kg kh kk mv ko mw ks mx kw my mz na nb bi translated"><a class="ae jy" href="http://Axiom/definition/theorem/proof" rel="noopener ugc nofollow" target="_blank">http://公理/定义/定理/证明</a>。(2018).YouTube。检索于 2018 年 6 月 14 日，来自<a class="ae jy" href="https://www.youtube.com/watch?v=OeC5WuZbNMI" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=OeC5WuZbNMI</a></li><li id="4232" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">公理—字典定义。(2018).Vocabulary.com。检索于 2018 年 6 月 14 日，来自<a class="ae jy" href="https://www.vocabulary.com/dictionary/axiom" rel="noopener ugc nofollow" target="_blank">https://www.vocabulary.com/dictionary/axiom</a></li><li id="b98e" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">深度网络的公理化属性--穆昆德.孙达拉扬，安库尔.塔利，严琦琦。(2017).Vimeo。检索于 2018 年 6 月 14 日，来自<a class="ae jy" href="https://vimeo.com/238242575" rel="noopener ugc nofollow" target="_blank">https://vimeo.com/238242575</a></li><li id="50c9" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">STL-10 数据集。(2018).Cs.stanford.edu。检索于 2018 年 6 月 15 日，来自 https://cs.stanford.edu/~acoates/stl10/<a class="ae jy" href="https://cs.stanford.edu/~acoates/stl10/" rel="noopener ugc nofollow" target="_blank"/></li><li id="6043" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">贝嫩森河(2018)。分类数据集结果。rodrigob . github . io . 2018 年 6 月 15 日检索，来自<a class="ae jy" href="http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#53544c2d3130" rel="noopener ugc nofollow" target="_blank">http://rodrigob . github . io/are _ we _ there _ yet/build/classification _ datasets _ results . html # 53544 C2 d 3130</a></li><li id="9679" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">[复本]，H. (2018)。如何在 Matplotlib (python)中隐藏轴和网格线？堆栈溢出。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/45148704/how-to-hide-axes-and-gridlines-in-matplotlib-python" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/45148704/how-to-hide-axes-and-gridlines-in-matplotlib-python</a></li><li id="c85f" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">VanderPlas，J. (2018)。多重支线剧情| Python 数据科学手册。jakevdp . github . io . 2018 年 6 月 16 日检索，来自<a class="ae jy" href="https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html" rel="noopener ugc nofollow" target="_blank">https://jakevdp . github . io/python datascience handbook/04.08-multiple-subplots . html</a></li><li id="b924" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">Matplotlib . py plot . subplot-Matplotlib 2 . 2 . 2 文档。(2018).Matplotlib.org。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html" rel="noopener ugc nofollow" target="_blank">https://matplotlib . org/API/_ as _ gen/matplotlib . py plot . subplot . html</a></li><li id="311a" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">matplotlib，m. (2018)。matplotlib 中超过 9 个支线剧情。堆栈溢出。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/4158367/more-than-9-subplots-in-matplotlib" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/4158367/more-than-9-subplots-in-matplotlib</a></li><li id="0c92" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">pylab_examples 示例代码:subplots _ demo . py—Matplotlib 2 . 0 . 0 文档。(2018).Matplotlib.org。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://matplotlib.org/2.0.0/examples/pylab_examples/subplots_demo.html" rel="noopener ugc nofollow" target="_blank">https://matplotlib . org/2 . 0 . 0/examples/pylab _ examples/subplots _ demo . html</a></li><li id="c826" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">Matplotlib . py plot . hist-Matplotlib 2 . 2 . 2 文档。(2018).Matplotlib.org。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.hist.html" rel="noopener ugc nofollow" target="_blank">https://matplotlib . org/API/_ as _ gen/matplotlib . py plot . hist . html</a></li><li id="2096" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">Python？，I. (2018)。在 Python 中有没有一个干净的生成折线图的方法？。堆栈溢出。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/27872723/is-there-a-clean-way-to-generate-a-line-histogram-chart-in-python" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/27872723/is-there-a-clean-way-to-generate-a-line-histogram-chart-in-python</a></li><li id="7378" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">Pyplot 文本— Matplotlib 2.2.2 文档。(2018).Matplotlib.org。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://matplotlib.org/gallery/pyplots/pyplot_text.html#sphx-glr-gallery-pyplots-pyplot-text-py" rel="noopener ugc nofollow" target="_blank">https://matplotlib . org/gallery/py plots/py plot _ text . html # sphx-glr-gallery-py plots-py plot-text-py</a></li><li id="a596" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">【谷歌/ ICLR 2017 /论文摘要】反事实的梯度。(2018).走向数据科学。检索于 2018 年 6 月 16 日，来自<a class="ae jy" rel="noopener" target="_blank" href="/google-iclr-2017-paper-summary-gradients-of-counterfactuals-6306510935f2">https://towards data science . com/Google-iclr-2017-paper-summary-gradients-of-counter factuals-6306510935 F2</a></li><li id="1747" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">NumPy . transpose—NumPy 1.14 版手册。(2018).Docs.scipy.org。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.transpose.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/numpy-1 . 14 . 0/reference/generated/numpy . transpose . html</a></li><li id="4ee0" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">命令，G. (2018)。Git 在一个命令中添加和提交。堆栈溢出。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/4298960/git-add-and-commit-in-one-command" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/4298960/git-add-and-commit-in-one-command</a></li><li id="e5ba" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">如何将图像切片为红色，g. (2018)。如何使用 misc.imread. Stack 溢出将图像分割为红色、绿色和蓝色通道。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/37431599/how-to-slice-an-image-into-red-green-and-blue-channels-with-misc-imread" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/37431599/how-to-slice-a image-into-red-green-and-blue-channels-with-misc-imread</a></li><li id="70fd" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">如何在 Windows 10 上安装 Bash shell 命令行工具？(2016).Windows 中央。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://www.windowscentral.com/how-install-bash-shell-command-line-windows-10" rel="noopener ugc nofollow" target="_blank">https://www . windows central . com/how-install-bash-shell-command-line-windows-10</a></li><li id="25df" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">Google Colab 免费 GPU 教程—深度学习火鸡—中等。(2018).中等。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d" rel="noopener">https://medium . com/deep-learning-turkey/Google-colab-free-GPU-tutorial-e 113627 b9f5d</a></li><li id="02c8" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">安装— imgaug 0.2.5 文档。(2018).img aug . readthe docs . io . 2018 年 6 月 16 日检索，来自<a class="ae jy" href="http://imgaug.readthedocs.io/en/latest/source/installation.html" rel="noopener ugc nofollow" target="_blank">http://img aug . readthe docs . io/en/latest/source/installation . html</a></li><li id="9525" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">NumPy . absolute—NumPy 1.14 版手册。(2018).Docs.scipy.org。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.absolute.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/numpy-1 . 14 . 0/reference/generated/numpy . absolute . html</a></li><li id="fe24" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">NumPy . clip—NumPy 1.10 版手册。(2018).Docs.scipy.org。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.clip.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/numpy-1 . 10 . 0/reference/generated/numpy . clip . html</a></li><li id="a909" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">NumPy . percentile—NumPy 1.14 版手册。(2018).Docs.scipy.org。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.percentile.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/numpy/reference/generated/numpy . percentile . html</a></li><li id="7880" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">CIFAR-10 和 CIFAR-100 数据集。(2018).Cs.toronto.edu。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank">https://www.cs.toronto.edu/~kriz/cifar.html</a></li><li id="ebd6" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">[ ICLR 2015 ]追求简单:具有交互码的全卷积网。(2018).走向数据科学。检索于 2018 年 6 月 16 日，来自<a class="ae jy" rel="noopener" target="_blank" href="/iclr-2015-striving-for-simplicity-the-all-convolutional-net-with-interactive-code-manual-b4976e206760">https://towards data science . com/iclr-2015-forwards-for-simplicity-the-all-convolutional-net-with-interactive-code-manual-b 4976 e 206760</a></li><li id="bbc4" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">EN10/CIFAR。(2018).GitHub。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://github.com/EN10/CIFAR" rel="noopener ugc nofollow" target="_blank">https://github.com/EN10/CIFAR</a></li><li id="0fe3" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">深度网络的公理化属性--穆昆德.孙达拉扬，安库尔.塔利，严琦琦。(2017).Vimeo。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://vimeo.com/238242575" rel="noopener ugc nofollow" target="_blank">https://vimeo.com/238242575</a></li><li id="fc4d" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">(2018).Arxiv.org。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://arxiv.org/pdf/1506.06579.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1506.06579.pdf</a></li><li id="ac80" class="mt mu iq kb b kc nc kg nd kk ne ko nf ks ng kw my mz na nb bi translated">黎曼和。(2018).En.wikipedia.org。检索于 2018 年 6 月 16 日，来自<a class="ae jy" href="https://en.wikipedia.org/wiki/Riemann_sum" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Riemann_sum</a></li></ol></div></div>    
</body>
</html>