<html>
<head>
<title>Neural Networks from a Bayesian Perspective</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯视角下的神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/neural-networks-from-a-bayesian-perspective-ad8cacc7588e?source=collection_archive---------4-----------------------#2018-08-06">https://towardsdatascience.com/neural-networks-from-a-bayesian-perspective-ad8cacc7588e?source=collection_archive---------4-----------------------#2018-08-06</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/f3595ad3054352f6731d1fcd826d99ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1XBZ8ocyjdSxP5VCiUvXzg.jpeg"/></div></div></figure><p id="ea1a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">无论从从业者的角度还是对于许多不同机器学习应用程序的最终用户来说，理解模型不知道什么都是很重要的。在我们之前的博客文章中，我们讨论了不同类型的不确定性。我们解释了如何使用它来解释和调试我们的模型。</p><p id="0dc3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这篇文章中，我们将讨论在深度神经网络中获得不确定性的不同方法。让我们从贝叶斯的角度来看神经网络。</p><h1 id="8d0b" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">贝叶斯学习 101</h1><p id="4480" class="pw-post-body-paragraph kb kc it kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">贝叶斯统计允许我们根据证据(数据)和我们对世界的先验知识得出结论。这常常与只考虑证据的频率主义统计形成对比。先验知识捕获了我们对哪个模型生成了数据的信念，或者那个模型的权重是什么。我们可以使用模型权重的<em class="md">先验分布</em> p(w)来表示这种信念。</p><p id="6349" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">随着我们收集更多的数据，我们更新先验分布，并使用贝叶斯法则将其转化为<em class="md">后验分布</em>，这一过程称为<em class="md">贝叶斯更新</em>:</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div class="gh gi me"><img src="../Images/01b3d4c48fea9da04ea10df6b9839491.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*iG_jZ05lXo97QeNshpEVGg.png"/></div></figure><p id="fe94" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这个等式引入了贝叶斯学习中的另一个关键角色——可能性<em class="md"/>，定义为 p(y|x，w)。这一项表示在给定模型权重<em class="md"> w </em>的情况下，数据的可能性有多大。</p><h1 id="0434" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">贝叶斯视角下的神经网络</h1><p id="d51b" class="pw-post-body-paragraph kb kc it kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">神经网络的目标是估计可能性 p(y|x，w)。即使你没有明确地这样做，也是如此，例如<a class="ae kz" href="https://www.jessicayung.com/mse-as-maximum-likelihood" rel="noopener ugc nofollow" target="_blank">当你最小化 MSE </a>时。</p><p id="203d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">为了找到最佳的模型权重，我们可以使用<em class="md">最大似然估计</em> (MLE):</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mj"><img src="../Images/a261eadcc8589c508bdc7230edaea509.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rWY2S4QkHSD5G5C0kXWvRw.png"/></div></div></figure><p id="a762" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">或者，我们可以使用我们的先验知识，表示为权重的先验分布，并最大化后验分布。这种方法被称为<em class="md">最大先验估计</em> (MAP) <strong class="kd iu"> : </strong></p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mk"><img src="../Images/c7c322c406a7ae50541ce7a5777b49c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7iYHTt42UvOaCXV5mSMOFA.png"/></div></div></figure><p id="aa32" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">代表我们的先验的项<em class="md"> logP(w) </em>充当正则化项。选择均值为 0 的高斯分布作为先验，你将得到 L2 正则化的数学等价。</p><p id="e7b4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">既然我们开始将神经网络视为概率性生物，我们就可以开始享受乐趣了。首先，谁说我们必须在训练过程结束时输出一组权重？如果我们不学习模型的权重，而是学习权重的分布，会怎么样？这将允许我们估计权重的不确定性。那么我们该怎么做呢？</p><h1 id="9914" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">一旦你去贝叶斯，你永远不会回来</h1><p id="6b12" class="pw-post-body-paragraph kb kc it kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">我们再次从权重的先验分布开始，目的是找到它们的后验分布。这一次，我们将对所有可能的权重进行平均，而不是直接优化网络的权重(称为边缘化)。</p><p id="56ed" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在推断时，我们不是采用最大化后验分布(或最大似然法，如果我们使用最大似然法)的单一权重集，而是考虑所有可能的权重，按其概率进行加权。这通过使用积分来实现:</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ml"><img src="../Images/991568a2f6dd4d04fa1236b3782f0190.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ll9k3E53XDOSSJaEgPQWTA.png"/></div></div></figure><p id="b04d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="md"> x </em>是我们要推断<em class="md"> y </em>的数据点，<em class="md"> X </em>，<em class="md"> Y </em>是训练数据。第一项 p(y|x，w)是我们良好的旧可能性，第二项 p(w|X，Y)是给定数据时模型权重的后验概率。</p><p id="b8db" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以把它想象成一个由每个模型的概率加权的模型集合。事实上，这相当于无限数量的神经网络的集合，具有相同的架构，但具有不同的权重。</p><h1 id="8a34" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">我们到了吗？</h1><p id="6307" class="pw-post-body-paragraph kb kc it kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">啊，问题就在这里！事实证明，这个积分在大多数情况下是难以处理的。这是因为后验概率无法通过分析来评估。</p><p id="e61a" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这个问题不是贝叶斯神经网络独有的。在贝叶斯学习的许多情况下，你会遇到这个问题，多年来已经开发了许多克服这个问题的方法。我们可以把这些方法分为两类:变分推断法和抽样法。</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mm"><img src="../Images/1dac4d1584ab16d83c0e99afd1e83fae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IYUzJxzbB_gYLwQynrOJZg.png"/></div></div></figure><h2 id="f852" class="mn lb it bd lc mo mp dn lg mq mr dp lk km ms mt lo kq mu mv ls ku mw mx lw my bi translated">蒙特卡罗抽样</h2><p id="8f79" class="pw-post-body-paragraph kb kc it kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">我们有麻烦了。后验分布是难以处理的。如果我们不用计算真实分布的积分，而是用从中抽取的样本的平均值来逼近它，会怎么样？一种方法是<a class="ae kz" rel="noopener" target="_blank" href="/a-zero-math-introduction-to-markov-chain-monte-carlo-methods-dcba889e0c50">马尔可夫链蒙特卡罗</a>——你用期望的分布作为它的平衡分布来构造一个马尔可夫链。</p><h2 id="cb29" class="mn lb it bd lc mo mp dn lg mq mr dp lk km ms mt lo kq mu mv ls ku mw mx lw my bi translated">变分推理</h2><p id="0b0f" class="pw-post-body-paragraph kb kc it kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">另一种解决方案是用来自易处理族的不同分布来近似真实的难处理分布。为了测量两个分布的相似性，我们可以使用 KL 散度:</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/357e1bd1cdaa4a90a9dbdc78c002b100.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*vnkWQl8Rqf_lFgt98DStUA.png"/></div></figure><p id="bdc1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">设<em class="md"> q </em>是由θ参数化的变分分布。我们希望找到最小化 KL 散度的θ值:</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div class="gh gi me"><img src="../Images/4a263002ecca5aef731253dc9da616ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*92HfheZdC_yaaW3pAxv5DQ.png"/></div></figure><p id="4a5c" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">看看我们得到的:第一项是变分分布和先验分布之间的 KL 散度。第二项是关于<em class="md"> q </em> θ的可能性。因此，我们在寻找能够最好地解释数据的<em class="md"> q </em> θ，但另一方面，它又尽可能接近先验分布。这只是将正则化引入神经网络的另一种方式！</p><p id="c767" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在我们有了 qθ，我们可以用它来做预测:</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div class="gh gi na"><img src="../Images/aedcb42f976215fe55a0a76586f362af.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*F0MjIP31zdlQ9Jrni_z5YA.png"/></div></figure><p id="ebeb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">以上提法来自 deep mind2015 年的一部<a class="ae kz" href="http://proceedings.mlr.press/v37/blundell15.html" rel="noopener ugc nofollow" target="_blank">作品。类似的想法由</a><a class="ae kz" href="http://proceedings.mlr.press/v37/blundell15.html" rel="noopener ugc nofollow" target="_blank">格雷夫斯</a>于 2011 年提出，并追溯到<a class="ae kz" href="http://www.cs.toronto.edu/~fritz/absps/colt93.pdf" rel="noopener ugc nofollow" target="_blank">辛顿和范坎普</a>于 1993 年提出。NIPS 贝叶斯深度学习研讨会上的<a class="ae kz" href="https://www.youtube.com/watch?v=FD8l2vPU5FY" rel="noopener ugc nofollow" target="_blank">主题演讲</a>非常好地概述了这些想法多年来是如何演变的。</p><p id="7732" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">好吧，但是如果我们不想从零开始训练一个模型呢？如果我们有一个训练好的模型，我们想从这个模型中得到不确定性估计，该怎么办？我们能做到吗？</p><p id="6849" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">事实证明，如果我们在训练中使用辍学，我们实际上可以。</p><figure class="mf mg mh mi gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nb"><img src="../Images/c622afea9f50a472894150c09f835255.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jRSBtNk1G02Q2KqrC5tv_Q.jpeg"/></div></div><figcaption class="nc nd gj gh gi ne nf bd b be z dk">Professional data scientists contemplating the uncertainty of their model — an illustration</figcaption></figure><h2 id="a4a8" class="mn lb it bd lc mo mp dn lg mq mr dp lk km ms mt lo kq mu mv ls ku mw mx lw my bi translated">辍学是一种不确定性</h2><p id="ba1c" class="pw-post-body-paragraph kb kc it kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated"><a class="ae kz" href="http://jmlr.org/papers/v15/srivastava14a.html" rel="noopener ugc nofollow" target="_blank">辍学</a>是一种经常使用的做法。在训练时，你随机抽取节点样本，并删除它们，也就是说，将它们的输出设置为 0。动机呢？您不希望过度依赖特定的节点，这可能意味着过度适应。</p><p id="549d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在 2016 年，<a class="ae kz" href="http://proceedings.mlr.press/v48/gal16.pdf" rel="noopener ugc nofollow" target="_blank"> Gal 和 Ghahramani </a>表明，如果你也在推理时应用 dropout，你可以很容易地得到一个不确定性估计量:</p><ol class=""><li id="22ad" class="ng nh it kd b ke kf ki kj km ni kq nj ku nk ky nl nm nn no bi translated">多次推断 y|x，每次采样一组不同的节点以排除。</li><li id="9c6f" class="ng nh it kd b ke np ki nq km nr kq ns ku nt ky nl nm nn no bi translated">对预测值进行平均，得到最终的预测值 E(y|x)。</li><li id="0f9a" class="ng nh it kd b ke np ki nq km nr kq ns ku nt ky nl nm nn no bi translated">计算预测的样本方差。</li></ol><p id="521d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">就是这样！你得到了方差的估计！这种方法背后的<a class="ae kz" href="http://www.cs.ox.ac.uk/people/yarin.gal/website/blog_3d801aa532c1ce.html" rel="noopener ugc nofollow" target="_blank">直觉</a>是，训练过程可以被认为是同时训练 2^m 不同的模型——其中 m 是网络中的节点数量:每个没有被遗漏的节点子集定义了一个新的模型。所有模型都共享它们没有丢失的节点的权重。在每一批中，这些模型的随机抽样集被训练。</p><p id="0406" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">训练结束后，你手中就有了一套模型。如果你如上所述在推理时使用这个集合，你就得到这个集合的不确定性。</p><h1 id="2f46" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">抽样方法与变分推断</h1><p id="f889" class="pw-post-body-paragraph kb kc it kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">就<a class="ae kz" href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff" rel="noopener ugc nofollow" target="_blank">偏差-方差权衡</a>而言，变分推断有很高的偏差，因为我们选择了分布族。这是我们正在做的一个强有力的假设，和任何强有力的假设一样，它会引入偏见。然而，它很稳定，方差很小。</p><p id="ee8b" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">另一方面，抽样方法具有较低的偏差，因为我们不对分布进行假设。这是以高方差为代价的，因为结果取决于我们抽取的样本。</p><h1 id="0fec" class="la lb it bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">最后的想法</h1><p id="7515" class="pw-post-body-paragraph kb kc it kd b ke ly kg kh ki lz kk kl km ma ko kp kq mb ks kt ku mc kw kx ky im bi translated">能够估计模型的不确定性是一个热门话题。在医疗辅助和自动驾驶汽车等高风险应用中，了解这一点非常重要。这也是一个很有价值的工具，可以了解哪些数据有利于模型，因此我们可以去获取它。</p><p id="bc11" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在这篇文章中，我们介绍了一些获得模型不确定性估计的方法。还有更多的方法，所以如果你对此感到非常不确定，继续寻找更多的数据🙂</p><p id="e1c4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在下一篇文章中，我们将向您展示如何在推荐系统中使用不确定性，特别是如何应对<a class="ae kz" href="https://en.wikipedia.org/wiki/Multi-armed_bandit" rel="noopener ugc nofollow" target="_blank">探索-开发挑战</a>。敬请关注。</p><p id="53fa" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="md">这是与我们在今年 KDD 会议的研讨会上提交的论文相关的系列文章的第二篇:</em> <a class="ae kz" href="https://arxiv.org/abs/1711.02487" rel="noopener ugc nofollow" target="_blank"> <em class="md">深度密度网络和推荐系统中的不确定性</em> </a> <em class="md">。</em></p><p id="1242" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><em class="md">第一篇帖子可以在</em> <a class="ae kz" href="https://engineering.taboola.com/using-uncertainty-interpret-model" rel="noopener ugc nofollow" target="_blank"> <em class="md">这里找到</em> </a> <em class="md">。</em></p></div><div class="ab cl nu nv hx nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="im in io ip iq"><p id="41d3" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这是一个与<a class="ob oc ep" href="https://medium.com/u/5d840e4443e4?source=post_page-----ad8cacc7588e--------------------------------" rel="noopener" target="_blank"> Inbar Naor </a>的联合帖子。最初发表于<a class="ae kz" href="https://engineering.taboola.com/neural-networks-bayesian-perspective" rel="noopener ugc nofollow" target="_blank">engineering.taboola.com</a></p></div></div>    
</body>
</html>