<html>
<head>
<title>Learning to perform linear filtering using natural image data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">学习使用自然图像数据执行线性滤波</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learning-to-perform-linear-filtering-using-natural-image-data-db289d0b0457?source=collection_archive---------3-----------------------#2018-07-10">https://towardsdatascience.com/learning-to-perform-linear-filtering-using-natural-image-data-db289d0b0457?source=collection_archive---------3-----------------------#2018-07-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/c50a1ed8e0d3586af208eb7c3c8df624.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MKwRzhDRNnF1y0JYNbxP2w.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Traditional Norwegian hut in Skibotn (Image by author).</figcaption></figure><div class=""/><p id="8eb8" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">卷积神经网络通常从训练数据中学习有用的特征。根据任务的不同，第一个卷积层的特征可能代表训练数据的一些基本内容。例如，在图像数据中，所学习的特征可以表示边缘和斑点。在网络的后续层中，学习到的特征可以表示更抽象、更高级别的实体。</p><p id="444d" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">可视化所学习的特征，以及它们如何及时发展，可能提供关于网络如何学习的有用信息。实际上，网络架构几乎总是比仅仅几层深得多，这使得很难直观地解释和分析所学习的特征，因为卷积核的总量很高。</p><p id="ce62" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">然而，我们可以演示卷积核权重如何随着网络通过受控实验的学习而随时间发展。很容易陈述学习任务，使得网络应该学习的特征已经预先知道，即产生训练数据的过程和参数被很好地定义并且完全在我们的控制之下。这可以通过构建一个极其简单的单层卷积网络并训练它使用各种内核执行线性滤波来实现。</p><p id="d923" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在下面的实验中，我们将 Sobel 边缘滤波(图像处理和计算机视觉中边缘检测的典型方法)应用于数据集，并训练我们的模型来执行类似的线性映射。我们还试图从数据中学习更多的任意线性滤波器，其核的大小比 Sobel 滤波的情况稍大。</p><p id="f11e" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">该演示有望建立关于神经网络中的卷积层如何对输入数据进行操作、卷积核权重如何在训练期间进行以及神经网络的训练如何可以被视为最小化问题的直觉。</p><p id="dcd0" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">首先，我们必须对输入图像数据 X 应用线性滤波，以便获得原始图像的滤波版本 Y。形式上，线性滤波操作可以总结如下:</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div class="gh gi la"><img src="../Images/9b886b37a7dadaa2157b64e4dee87170.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*16wONuBIgoHlTg-HvPZulw.png"/></div></figure><figure class="lb lc ld le gt is gh gi paragraph-image"><div class="gh gi lf"><img src="../Images/c49dedbe72e644d082ff9651fe278de3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*kvf4LCUCi9nX9FoG4ENN_A.png"/></div></figure><p id="8147" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">线性滤波器是一种定义明确的操作，适用于我们能想到的任何参数集(卷积核)或输入数据。</p><p id="6504" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们现在可以建立一个单层、单核、卷积神经网络，它近似于线性滤波操作。毕竟，在线性滤波器和卷积神经网络中，两种情况下执行的计算完全相同，只是卷积核参数不同，我们将从数据中了解这一点。</p><p id="ecf4" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们可以在线性滤波器和卷积神经网络之间得出以下联系:</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div class="gh gi lg"><img src="../Images/844734998f9c9361f3e98a0ff634241b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*Dib0PZFF5kz3jlQMC2nv1Q.png"/></div></figure><p id="ce7a" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">学习任务现在可以表述为最小化问题，其中线性滤波器的输出和卷积神经网络的输出之间的均方误差被最小化:</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi lh"><img src="../Images/8f3c29eeba52c590f6b910b738d63e60.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/1*WqyxnAC_lZjQGuc-3K4_Uw.png"/></div></div></figure><p id="5820" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">应用于图像数据的线性滤波器的参数被称为卷积核。我们将首先在 x 方向上，然后在 y 方向上，用称为 Sobel 算子的 3×3 卷积核来过滤图像数据，从而开始我们的实验。Sobel 算子给出如下:</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div class="gh gi li"><img src="../Images/9a12b9b0fe382b271e3fde73b1b5af2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*9Oxj4vX9Mpzs0rYouRQesA.png"/></div></figure><p id="60ae" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">对于实验，我们将使用运行在 TensorFlow 之上的 Keras 框架。</p><h2 id="5f0f" class="lj lk jf bd ll lm ln dn lo lp lq dp lr kn ls lt lu kr lv lw lx kv ly lz ma mb bi translated">x 方向的 Sobel 滤波器</h2><p id="22ee" class="pw-post-body-paragraph kc kd jf ke b kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv mg kx ky kz ij bi translated">首先，我们必须为图像预处理定义几个辅助函数。加载数据集，将图像转换为灰度，归一化图像强度范围，并对数据集中的每个图像执行线性滤波。</p><figure class="lb lc ld le gt is"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="f7e8" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">作为训练和测试数据，我们将利用城市和自然场景类别-数据集(<a class="ae mj" href="http://cvcl.mit.edu/Papers/IJCV01-Oliva-Torralba.pdf" rel="noopener ugc nofollow" target="_blank">奥利瓦，A. &amp;托拉尔巴，A. (2001)。模拟场景的形状:麻省理工学院计算视觉认知实验室收集的空间包络</a>的整体表示。</p><p id="5f5b" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">原始数据集由八个类别的自然场景彩色图像(分辨率:256 x 256)组成，其中我们使用了三个类别:街道、市中心和高楼。这样，我们获得了足够大小的训练和测试集(764 个训练样本和 192 个测试样本),使得训练不会遭受过拟合，并且训练也可以通过在合理的时间帧内利用更适中的硬件来执行。所选的类别代表具有强烈边缘的自然场景(大范围的人类建筑)，这有助于我们比较结果。</p><p id="3240" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">下面，我们可以观察到属于数据集的原始图像的可视化、图像的灰度转换和 Sobel 滤波版本:</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mk"><img src="../Images/1f83db8b7aff780f45acc55abc799eb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iVzR_NI33W_tI-gOI7oyjg.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Original image (left), Grayscale image (middle) and Sobel filtered image in x-direction (right).</figcaption></figure><p id="6099" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们将只在单通道图像上使用线性滤波器。在实践中，这意味着模型被训练成将灰度转换图像映射成 Sobel 滤波图像。</p><p id="1de7" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">接下来，我们定义模型:具有线性激活的单层、单核、卷积网络，即，激活函数是恒等式。卷积核的大小被选择为 3×3，以符合 Sobel 滤波器的大小。</p><p id="5939" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">使用具有内斯特罗夫动量的随机梯度下降优化器来训练 100 个时期的模型。在每个时期，保存卷积层权重用于进一步可视化。</p><figure class="lb lc ld le gt is"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="4475" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">训练完成后，我们可以绘制训练和验证损失图，以查看训练是否过度拟合。</p><figure class="lb lc ld le gt is"><div class="bz fp l di"><div class="mh mi l"/></div></figure><figure class="lb lc ld le gt is gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/800c83afadb7225e6924933f8bdeb8c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*UoNmffwleTvyfz_McfiUtQ.png"/></div></figure><p id="1985" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在整个训练过程中，训练和验证损失是稳定的，模型似乎是收敛的。</p><p id="f24b" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在可以将每个时期的保存的权重可视化为矩阵格式的数值，以及更直观的格式，其中数值表示可视化中的像素强度值。声明用于执行可视化的函数，并且为每个时期创建可视化。</p><figure class="lb lc ld le gt is"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="7667" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在我们有了每个时期的可视化效果，我们可以从它们创建一个 gif 电影来看看权重是如何变化的。</p><figure class="lb lc ld le gt is"><div class="bz fp l di"><div class="mh mi l"/></div></figure><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mm"><img src="../Images/e8bdc005e8b3ce42e2cb25a30d02a55d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*m9oLmyp6IN-9dxJnzg5D9w.gif"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">The progress of the convolution layer weights as the model is trained. The weight values converge close to the Sobel operator in x-direction.</figcaption></figure><p id="83f3" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在 gif 电影中，随着学习的进行，卷积核权重如何向 Sobel x 方向滤波器收敛是相当明显的。在前 10 到 15 个时期收敛很快，之后收敛速度明显稳定下来。如果学习任务比我们在这个实验中使用的简单线性过滤操作更复杂，我们仍然会看到类似的行为。卷积核的值将收敛到某个最佳配置，该配置将从数据中提取有用的特征。在这个实验中，有用的特征是由 Sobel 算子给出的图像 x 方向的边缘。我们能够找到产生第一手训练数据的几乎精确的卷积核参数，主要是因为我们的问题陈述非常简单。然而，对于真实世界的问题，这很少发生，因为训练数据通常不是从输入到输出的线性映射。</p><p id="4593" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为了测试该模型，我们可以看到与 x 方向上的 Sobel 滤波相比，该模型的预测看起来如何。</p><figure class="lb lc ld le gt is"><div class="bz fp l di"><div class="mh mi l"/></div></figure><figure class="lb lc ld le gt is gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/43b1fbfa3aeeff5a5cc076f1f5c8e55d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*6bY30I0VlIGK0hPlAysyDA.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Output of the model (left) and the same image filtered with Sobel operator in x-direction (right).</figcaption></figure><p id="ff5f" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在图中(顶部)，我们可以观察到模型的输出和 x 方向上并排的 Sobel 滤波的结果。目测，两幅图像看起来相似。事实上，在强度值中，人们应该仅发现图像之间的微小差异，因为所学习的卷积核收敛到接近原始 Sobel 算子的值。</p><h2 id="b23f" class="lj lk jf bd ll lm ln dn lo lp lq dp lr kn ls lt lu kr lv lw lx kv ly lz ma mb bi translated">y 方向的 Sobel 滤波器</h2><p id="ab36" class="pw-post-body-paragraph kc kd jf ke b kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv mg kx ky kz ij bi translated">同样的代码也可以利用 Sobel 算子在 y 方向上执行线性滤波。我们所要做的就是改变图像过滤功能，在 y 方向而不是 x 方向执行过滤，再次加载并过滤训练数据，并用新数据训练模型。</p><figure class="lb lc ld le gt is"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="197d" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在下图中，我们可以观察到 Sobel 过滤器现在如何在垂直方向(y 方向)上强调图像强度边缘。</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mk"><img src="../Images/b86854f11df956617b1c874c2dac784b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*20U6lLTnr7AhTPWvTg51TQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Original image (left), Grayscale image (middle) and Sobel filtered image in y-direction (right).</figcaption></figure><p id="42a2" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们可以再次观察到，当网络从训练数据中学习时，卷积核权重如何在 y 方向上朝着 Sobel 滤波器前进。收敛行为非常类似于先前在 x 方向上使用 Sobel 算子的情况。</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mm"><img src="../Images/9f979fc18ea963930b7be594b3dea343.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*uGd4lUBSYWsMxciU86jkCg.gif"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">The progress of the convolution layer weights as the model is trained. The weight values converge close to the Sobel operator in y-direction.</figcaption></figure><p id="d4f2" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">同样，在下图中，模型的输出和相同测试图像的 Sobel 滤波版本具有相似的外观。对于人眼来说，不可能分辨出这两幅图像的区别。</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/2f5c8fe4490d0f2007e3313ad6d1e687.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*-2E13U6a6M8UUJA0Cc4aHg.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Output of the model (left) and the same image filtered with Sobel operator in y-direction (right).</figcaption></figure></div><div class="ab cl mo mp hu mq" role="separator"><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt mu"/><span class="mr bw bk ms mt"/></div><div class="ij ik il im in"><h2 id="e0df" class="lj lk jf bd ll lm ln dn lo lp lq dp lr kn ls lt lu kr lv lw lx kv ly lz ma mb bi translated">笑脸过滤器</h2><p id="4fac" class="pw-post-body-paragraph kc kd jf ke b kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv mg kx ky kz ij bi translated">之前学习的 Sobel 滤波器非常简单，只需要学习少量的参数。让我们看看，如果我们可以学习一个更大的核线性滤波器。</p><p id="1cca" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们将在下面的实验中使用的过滤器内核是一个 32 x 32 像素的笑脸(谢谢 Leo 的想法:)。加载过滤器内核，并通过用笑脸内核过滤灰度图像来创建训练数据。由于大的内核大小，内核基本上延伸到图像边界之外。图像边界用零填充，以抵消卷积导致的图像分辨率的降低。</p><figure class="lb lc ld le gt is"><div class="bz fp l di"><div class="mh mi l"/></div></figure><figure class="lb lc ld le gt is gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/e4944468ba0a30b6aa7489f9b91ef736.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*lEhtMUfzGFY2shbN1RjhEQ.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">The normalized smiley face filter kernel.</figcaption></figure><p id="2e8c" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在下图中，我们可以看到笑脸过滤图像与原始图像和灰度转换图像相比的样子。</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mk"><img src="../Images/683878fd84b6ec7d3ec04307cc088f03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iKRFZXZihJ4fpbmhbxKyyA.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Original image (left), Grayscale image (middle) and smiley face filtered image (right).</figcaption></figure><p id="4ff6" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们的模型再次是一个简单的单层、单核、卷积神经网络，其中激活函数是身份。这一次，我们根据笑脸内核的大小，将内核大小设置为 32 x 32。作为对之前实验的增强，我们将基本的随机梯度下降优化器改为更强大的 Adam 优化器。</p><figure class="lb lc ld le gt is"><div class="bz fp l di"><div class="mh mi l"/></div></figure><p id="247a" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">该模型被训练 100 个时期，并且在每个时期存储卷积核权重。训练和验证损失在大约 10 个时期内快速收敛，之后可以在两个损失值中看到小的波动。</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/4729035046f6be270302b4a357d913dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*SACbc9GyLOLyV3DT1QWJCw.png"/></div></figure><p id="569e" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">存储的卷积核权重值现在可以可视化并组合成 gif 电影。结果很有启发性:该模型似乎惊人地学习了原始的笑脸过滤器内核，正如在下面的 gif 电影中可以观察到的那样。卷积核权重相对较早地呈现笑脸的形状，大约在十个时期之后，但是权重仍然包含大量噪声。随着训练的进行，噪声慢慢消失，并且相邻的权重值相对于彼此变得更加恒定。</p><p id="c0e0" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">通过分析验证损失和卷积核权重的进展，可以进行重要的观察。即使验证损失在第十个时期后看起来是平坦的，卷积核权重仍然朝着原始笑脸核发展足够的量。训练和验证损失曲线的线性比例有时可能会有点误导，因为初始损失值可能会在损失测量的后期改进中主导损失可视化。</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/e2f207dfcf6dbc790cab06680fcd57d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*2gjtTNegIYfHWgi4ZcA7MA.gif"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">The progress of the convolution layer weights as the model is trained. The weight values converge close to the smiley face filter.</figcaption></figure><p id="3c6c" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在我们有了一个训练好的模型，我们可以可视化并比较模型的输出和一个笑脸过滤测试图像的结果。在下图中，我们可以观察模型和笑脸过滤器内核如何产生与测试图像相似的外观。类似于 Sobel 滤波的图像，以及由从数据学习 Sobel 滤波的模型产生的图像，很难将笑脸滤波的图像与模型的输出区分开。</p><figure class="lb lc ld le gt is gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/6716f67f15e1d387adc8fffa1e7bbb92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*qaVnFwhi6LVS3Zh1SfL8Ww.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Output of the model (left) and the same image filtered with the smiley face kernel (right).</figcaption></figure><h2 id="b45e" class="lj lk jf bd ll lm ln dn lo lp lq dp lr kn ls lt lu kr lv lw lx kv ly lz ma mb bi translated">最后的话</h2><p id="e61c" class="pw-post-body-paragraph kc kd jf ke b kf mc kh ki kj md kl km kn me kp kq kr mf kt ku kv mg kx ky kz ij bi translated">我希望使用线性滤波器的三个实验足够清楚地展示了当网络从数据中学习时，卷积核权重是如何发展的。此外，我希望您能够获得一些见解，以便理解卷积层对输入数据的操作方式。这些实验的结果没有直接推广到卷积神经网络被用于例如图像分类的情况，而是为理解卷积层背后的现象和作为优化问题的学习提供了基础。</p><p id="7b35" class="pw-post-body-paragraph kc kd jf ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果你对在自己的电脑上运行实验感兴趣，这里有一个 github 文件夹的链接，其中包含重复实验所需的一切:<a class="ae mj" href="https://github.com/vexcel/Keras-LearnLinearFilter" rel="noopener ugc nofollow" target="_blank">https://github.com/vexcel/Keras-LearnLinearFilter</a>。</p></div></div>    
</body>
</html>