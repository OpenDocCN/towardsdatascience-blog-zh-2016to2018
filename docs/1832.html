<html>
<head>
<title>PGGAN Creates Realistic Faces</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PGGAN创建逼真的面孔</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/progressive-gans-new-training-trend-for-2018-c18cb0190239?source=collection_archive---------3-----------------------#2017-10-31">https://towardsdatascience.com/progressive-gans-new-training-trend-for-2018-c18cb0190239?source=collection_archive---------3-----------------------#2017-10-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="7cdb" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">2018年深度学习的新趋势</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi kf"><img src="../Images/1833736e6d0fac254d48e74c1a0c47ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*eMds9x9x6bFUhNbzGPakXQ.jpeg"/></div></figure><p id="5c70" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi lj translated">Ian Goodfellow早在2014年就在蒙特利尔大学发明了世代对抗网络。他们已经有了一个很好的开始，显示出图像生成质量的潜在增长，打破了以前由受限玻尔兹曼机器、可变自动编码器等设定的所有基准。这个框架仍然是生成高质量图像的最成功的方法之一。此外，该框架产生易于处理的网络(与通过近似推理计算的RBM相反),且很容易仅使用误差反向传播来训练。</p><p id="f2ed" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">多年来，GANs的许多变体被发明出来，但第一个最成功的进展是DCGAN，它生成了质量更好的图像，还发现了各种稳定训练过程的技术，因为众所周知，随着一个网络变得比另一个更强，学习无法完成，GANs在训练时非常不稳定。另一个问题是模式崩溃，生成器无法生成新的图像。除了训练问题，GANs很快转向不同的方向，如生成高分辨率图像，图像修复，制作音乐等。</p><h1 id="b864" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">进步甘斯</h1><p id="3c1a" class="pw-post-body-paragraph kn ko iq kp b kq mk jr ks kt ml ju kv kw mm ky kz la mn lc ld le mo lg lh li ij bi translated">最近，在撰写本文时，NVIDIA的一项研究揭示了一种训练GANs的新技术，他们称之为<strong class="kp ir"><em class="mp">GANs</em></strong>的渐进生长。他们采取了一种完全不同且出乎意料的训练方法。并且这种技术产生新颖的并且不容易与原作或赝品相区分的真实图像。</p><p id="bec4" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">只是看一看👀观看下面的视频，了解这种新训练方法的潜力！</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mq mr l"/></div><figcaption class="ms mt gj gh gi mu mv bd b be z dk">Celebrity Face Generation (Novel Faces)</figcaption></figure><h2 id="605c" class="mw lt iq bd lu mx my dn ly mz na dp mc kw nb nc me la nd ne mg le nf ng mi nh bi translated">扩大网络</h2><p id="d710" class="pw-post-body-paragraph kn ko iq kp b kq mk jr ks kt ml ju kv kw mm ky kz la mn lc ld le mo lg lh li ij bi translated">他们用于训练网络的方法是，首先从生成器<strong class="kp ir"> <em class="mp"> G </em> </strong>生成4x4分辨率的图像，并将它们与缩放到相同分辨率的真实图像一起送入鉴别器<strong class="kp ir"><em class="mp"/></strong>进行训练。请注意，他们使用的图像来自CelebA数据集，尺寸为1024x1024。现在，在网络学习对于宽空间特征饱和之后，两个网络都随着更高分辨率的层慢慢淡入到<strong class="kp ir"> <em class="mp"> G </em> </strong>和<strong class="kp ir"> <em class="mp"> D </em> </strong>中。</p><p id="759d" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">研究人员使用残差网络，通过增加残差网络存在的权重，将这些更高分辨率的卷积层淡化到两个网络中。卷积分辨率(新层)增加了2倍，在这种情况下是从4×4增加到8×8。这意味着现在<strong class="kp ir"> <em class="mp"> G </em> </strong>生成8×8图像(而不是以前的4×4图像)并作为8×8图像输入到<strong class="kp ir"> <em class="mp"> D </em> </strong>中。原始实像也被缩放到8×8，用于将它们馈送到<strong class="kp ir"> <em class="mp"> D </em> </strong>。<strong class="kp ir"> <em class="mp"> G </em> </strong>和<strong class="kp ir"> <em class="mp"> D </em> </strong>的先前4×4卷积层仍然保持可训练。</p><blockquote class="ni nj nk"><p id="0c78" class="kn ko mp kp b kq kr jr ks kt ku ju kv nl kx ky kz nm lb lc ld nn lf lg lh li ij bi translated">网络的渐隐进入<strong class="kp ir"> <em class="iq"> G </em> </strong>和<strong class="kp ir"> <em class="iq"> D </em> </strong>借助残差网络让较高分辨率层渐隐进入网络而不影响训练有素的较低分辨率层。</p></blockquote><p id="77ab" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">图层被对称地淡入<strong class="kp ir"> <em class="mp"> G </em> </strong>和<strong class="kp ir"> <em class="mp"> D </em> </strong>中。通过将分辨率增加2倍，分辨率逐步增加到1024x1024。这种方式网络学习图像的宽空间特征和更高分辨率层中的局部空间特征，因为<em class="mp">GANs增长，因此称为GANs的渐进增长</em>。</p><p id="f3ee" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">虽然有些图像是不正确的，例如有时头发和前额混在一起，有些照片中的眼睛彼此不相似，等等。但总的来说，网络生成的图像非常好，而且还是高清的！</p><h1 id="981f" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">接下来呢？</h1><p id="4a26" class="pw-post-body-paragraph kn ko iq kp b kq mk jr ks kt ml ju kv kw mm ky kz la mn lc ld le mo lg lh li ij bi translated">为了更深入的理解，请看一下研究论文:<a class="ae no" href="http://research.nvidia.com/sites/default/files/pubs/2017-10_Progressive-Growing-of//karras2017gan-paper.pdf" rel="noopener ugc nofollow" target="_blank">为了提高质量、稳定性和变化而进行的GANs渐进生长</a>。还可以在GitHub上查看我的推理(生成器)网络对<a class="ae no" href="https://github.com/rahulbhalley/Progressive-Growing-of-GANs" rel="noopener ugc nofollow" target="_blank">的实现。代码是用PyTorch编写的，可以让你从潜在空间生成图像。</a></p><p id="882d" class="pw-post-body-paragraph kn ko iq kp b kq kr jr ks kt ku ju kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">在<a class="ae no" href="https://github.com/rahulbhalley" rel="noopener ugc nofollow" target="_blank"> GitHub </a>、<a class="ae no" href="https://www.instagram.com/rahulbhalley" rel="noopener ugc nofollow" target="_blank"> Instagram </a>、<a class="ae no" href="https://twitter.com/Rahul_Bhalley" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上追踪我。</p></div></div>    
</body>
</html>