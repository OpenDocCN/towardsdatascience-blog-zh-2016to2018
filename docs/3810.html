<html>
<head>
<title>End to End — Predictive model using Python framework</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">端到端—使用 Python 框架的预测模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/end-to-end-python-framework-for-predictive-modeling-b8052bb96a78?source=collection_archive---------0-----------------------#2018-06-21">https://towardsdatascience.com/end-to-end-python-framework-for-predictive-modeling-b8052bb96a78?source=collection_archive---------0-----------------------#2018-06-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/690951c66363b3820b1f26a7e1d6227a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MOwA9cDS0ro96i3g4w5sqg.jpeg"/></div></div></figure><p id="c226" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">预测建模总是一项有趣的任务。花费的主要时间是了解企业需要什么，然后确定您的问题。下一步是根据需求定制解决方案。当我们解决许多问题时，我们明白可以用一个框架来建立我们的第一批模型。这个框架不仅给你更快的结果，它还帮助你根据结果计划下一步。</p><p id="08c5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在本文中，我们将看到如何将基于 Python 的框架应用于各种预测建模任务。这将涵盖/触及 CRISP-DM 流程中的大部分领域。那么什么是 CRISP-DM 呢？</p><div class="kw kx gp gr ky kz"><a href="https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining" rel="noopener  ugc nofollow" target="_blank"><div class="la ab fo"><div class="lb ab lc cl cj ld"><h2 class="bd ir gy z fp le fr fs lf fu fw ip bi translated">数据挖掘的跨行业标准流程-维基百科</h2><div class="lg l"><h3 class="bd b gy z fp le fr fs lf fu fw dk translated">数据挖掘的跨行业标准过程，称为 CRISP-DM，是一个数据挖掘过程模型，它描述了…</h3></div><div class="lh l"><p class="bd b dl z fp le fr fs lf fu fw dk translated">en.wikipedia.org</p></div></div><div class="li l"><div class="lj l lk ll lm li ln jw kz"/></div></div></a></div><p id="7eec" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下面是代码的链接。在本文中，为了简洁起见，我跳过了许多代码。阅读本文时，请遵循边上的 Github 代码。</p><div class="kw kx gp gr ky kz"><a href="https://github.com/Sundar0989/EndtoEnd---Predictive-modeling-using-Python" rel="noopener  ugc nofollow" target="_blank"><div class="la ab fo"><div class="lb ab lc cl cj ld"><h2 class="bd ir gy z fp le fr fs lf fu fw ip bi translated">sundar 0989/EndtoEnd—-使用 Python 进行预测建模</h2><div class="lg l"><h3 class="bd b gy z fp le fr fs lf fu fw dk translated">通过在 GitHub 上创建帐户，为使用 Python 的端到端预测建模开发做出贡献。</h3></div><div class="lh l"><p class="bd b dl z fp le fr fs lf fu fw dk translated">github.com</p></div></div><div class="li l"><div class="lo l lk ll lm li ln jw kz"/></div></div></a></div><p id="9051" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">本文中讨论的框架分为 9 个不同的领域，我将它们与它们在 CRISP DM 过程中所处的位置联系起来。</p><blockquote class="lp lq lr"><p id="3cd2" class="jy jz ls ka b kb kc kd ke kf kg kh ki lt kk kl km lu ko kp kq lv ks kt ku kv ij bi translated">加载数据集— <em class="iq">数据理解</em></p></blockquote><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="78c9" class="mf mg iq mb b gy mh mi l mj mk"><strong class="mb ir">import</strong> <strong class="mb ir">pandas</strong> <strong class="mb ir">as</strong> <strong class="mb ir">pd</strong><br/><br/>df = pd.read_excel("bank.xlsx")</span></pre><blockquote class="lp lq lr"><p id="f754" class="jy jz ls ka b kb kc kd ke kf kg kh ki lt kk kl km lu ko kp kq lv ks kt ku kv ij bi translated">数据转换— <em class="iq">数据准备</em></p></blockquote><p id="1a93" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在，我们有了熊猫数据框架中的数据集。接下来，我们分别使用 df.info()和 df.head()查看变量描述和数据集内容。使用下面的代码将目标变量(' Yes'/'No ')转换为(1/0)。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="efc2" class="mf mg iq mb b gy mh mi l mj mk">df['target'] = df['y'].apply(<strong class="mb ir">lambda</strong> x: 1 <strong class="mb ir">if</strong> x == 'yes' <strong class="mb ir">else</strong> 0)</span></pre><blockquote class="lp lq lr"><p id="8afc" class="jy jz ls ka b kb kc kd ke kf kg kh ki lt kk kl km lu ko kp kq lv ks kt ku kv ij bi translated">描述性统计— <em class="iq">数据理解</em></p></blockquote><p id="4f88" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">探索性统计帮助建模者更好地理解数据。在这个框架中有一些这样的统计数据。首先，我们使用下面的代码检查数据集中每一列的缺失值。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="8902" class="mf mg iq mb b gy mh mi l mj mk">df.isnull().mean().sort_values(ascending=<strong class="mb ir">False</strong>)*100</span></pre><p id="e0b0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">其次，我们使用下面的代码检查变量之间的相关性。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="d149" class="mf mg iq mb b gy mh mi l mj mk"><strong class="mb ir">import</strong> <strong class="mb ir">seaborn</strong> <strong class="mb ir">as</strong> <strong class="mb ir">sns</strong><br/><strong class="mb ir">import</strong> <strong class="mb ir">matplotlib.pyplot</strong> <strong class="mb ir">as</strong> <strong class="mb ir">plt</strong><br/>%matplotlib inline<br/>corr = df.corr()<br/>sns.heatmap(corr, <br/>        xticklabels=corr.columns,<br/>        yticklabels=corr.columns)</span></pre><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/19be47c4b7d7bd53dde84592604818d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*XBCsuDco0DCL3qKjcwOiKw.png"/></div></figure><p id="9e9a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后，在框架中，我加入了一个宁滨算法，该算法自动将输入变量纳入数据集中，并创建一个二元图(输入与目标)。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="10f1" class="mf mg iq mb b gy mh mi l mj mk">bar_color = '#058caa'<br/>num_color = '#ed8549'<br/><br/>final_iv,_ = data_vars(df1,df1['target'])<br/>final_iv = final_iv[(final_iv.VAR_NAME != 'target')]<br/>grouped = final_iv.groupby(['VAR_NAME'])<br/><strong class="mb ir">for</strong> key, group <strong class="mb ir">in</strong> grouped:<br/>    ax = group.plot('MIN_VALUE','EVENT_RATE',kind='bar',color=bar_color,linewidth=1.0,edgecolor=['black'])<br/>    ax.set_title(str(key) + " vs " + str('target'))<br/>    ax.set_xlabel(key)<br/>    ax.set_ylabel(str('target') + " %")<br/>    rects = ax.patches<br/>    <strong class="mb ir">for</strong> rect <strong class="mb ir">in</strong> rects:<br/>        height = rect.get_height()<br/>        ax.text(rect.get_x()+rect.get_width()/2., 1.01*height, str(round(height*100,1)) + '%', <br/>                ha='center', va='bottom', color=num_color, fontweight='bold')</span></pre><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/a99b6a8c6c84566381e57732fe3d4dca.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*LZSYofs7VohpoyMDZAb4tg.png"/></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">The values in the bottom represent the start value of the bin.</figcaption></figure><blockquote class="lp lq lr"><p id="0041" class="jy jz ls ka b kb kc kd ke kf kg kh ki lt kk kl km lu ko kp kq lv ks kt ku kv ij bi translated">变量选择— <em class="iq">数据准备</em></p></blockquote><p id="4ca1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">请阅读我下面的文章，关于在这个框架中使用的变量选择过程。基于投票系统选择变量。我们使用不同的算法来选择特征，然后最后每个算法为他们选择的特征投票。最终投票数用于选择建模的最佳特征。</p><div class="kw kx gp gr ky kz"><a href="https://medium.com/@sundarstyles89/variable-selection-using-python-vote-based-approach-faa42da960f0" rel="noopener follow" target="_blank"><div class="la ab fo"><div class="lb ab lc cl cj ld"><h2 class="bd ir gy z fp le fr fs lf fu fw ip bi translated">使用 Python 的变量选择—基于投票的方法</h2><div class="lg l"><h3 class="bd b gy z fp le fr fs lf fu fw dk translated">变量选择是预测建模过程中的关键步骤之一。这是一门艺术。简单来说…</h3></div><div class="lh l"><p class="bd b dl z fp le fr fs lf fu fw dk translated">medium.com</p></div></div><div class="li l"><div class="mr l lk ll lm li ln jw kz"/></div></div></a></div><blockquote class="lp lq lr"><p id="722a" class="jy jz ls ka b kb kc kd ke kf kg kh ki lt kk kl km lu ko kp kq lv ks kt ku kv ij bi translated">模型— <em class="iq">建模</em></p></blockquote><p id="58fa" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">到目前为止，80%的预测模型工作已经完成。为了完成剩下的 20%,我们将数据集分成训练/测试，并对数据尝试各种算法，然后选择最佳算法。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="b42d" class="mf mg iq mb b gy mh mi l mj mk"><strong class="mb ir">from</strong> <strong class="mb ir">sklearn.cross_validation</strong> <strong class="mb ir">import</strong> train_test_split<br/><br/>train, test = train_test_split(df1, test_size = 0.4)<br/>train = train.reset_index(drop=<strong class="mb ir">True</strong>)<br/>test = test.reset_index(drop=<strong class="mb ir">True</strong>)<br/><br/>features_train = train[list(vif['Features'])]<br/>label_train = train['target']<br/>features_test = test[list(vif['Features'])]<br/>label_test = test['target']</span></pre><p id="c59d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们在训练数据集上应用不同的算法，并在测试数据上评估性能，以确保模型是稳定的。该框架包括随机森林、逻辑回归、朴素贝叶斯、神经网络和梯度推进的代码。我们可以根据需要添加其他型号。下面提供了随机森林代码。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="1693" class="mf mg iq mb b gy mh mi l mj mk"><strong class="mb ir">from</strong> <strong class="mb ir">sklearn.ensemble</strong> <strong class="mb ir">import</strong> RandomForestClassifier<br/>clf = RandomForestClassifier()<br/><br/>clf.fit(features_train,label_train)<br/><br/>pred_train = clf.predict(features_train)<br/>pred_test = clf.predict(features_test)<br/><br/><strong class="mb ir">from</strong> <strong class="mb ir">sklearn.metrics</strong> <strong class="mb ir">import</strong> accuracy_score<br/>accuracy_train = accuracy_score(pred_train,label_train)<br/>accuracy_test = accuracy_score(pred_test,label_test)<br/><br/><strong class="mb ir">from</strong> <strong class="mb ir">sklearn</strong> <strong class="mb ir">import</strong> metrics<br/>fpr, tpr, _ = metrics.roc_curve(np.array(label_train), clf.predict_proba(features_train)[:,1])<br/>auc_train = metrics.auc(fpr,tpr)<br/><br/>fpr, tpr, _ = metrics.roc_curve(np.array(label_test), clf.predict_proba(features_test)[:,1])<br/>auc_test = metrics.auc(fpr,tpr)</span></pre><blockquote class="lp lq lr"><p id="d615" class="jy jz ls ka b kb kc kd ke kf kg kh ki lt kk kl km lu ko kp kq lv ks kt ku kv ij bi translated">超参数整定— <em class="iq">建模</em></p></blockquote><p id="7556" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，还可以调整模型的超参数来提高性能。下面是一段代码。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="df7d" class="mf mg iq mb b gy mh mi l mj mk"><strong class="mb ir">from</strong> <strong class="mb ir">sklearn.model_selection</strong> <strong class="mb ir">import</strong> RandomizedSearchCV<br/><strong class="mb ir">from</strong> <strong class="mb ir">sklearn.ensemble</strong> <strong class="mb ir">import</strong> RandomForestClassifier<br/><br/>n_estimators = [int(x) <strong class="mb ir">for</strong> x <strong class="mb ir">in</strong> np.linspace(start = 10, stop = 500, num = 10)]<br/>max_features = ['auto', 'sqrt']<br/>max_depth = [int(x) <strong class="mb ir">for</strong> x <strong class="mb ir">in</strong> np.linspace(3, 10, num = 1)]<br/>max_depth.append(<strong class="mb ir">None</strong>)<br/>min_samples_split = [2, 5, 10]<br/>min_samples_leaf = [1, 2, 4]<br/>bootstrap = [<strong class="mb ir">True</strong>, <strong class="mb ir">False</strong>]<br/><br/>random_grid = {'n_estimators': n_estimators,<br/>               'max_features': max_features,<br/>               'max_depth': max_depth,<br/>               'min_samples_split': min_samples_split,<br/>               'min_samples_leaf': min_samples_leaf,<br/>               'bootstrap': bootstrap}<br/><br/>rf = RandomForestClassifier()<br/><br/>rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 2, verbose=2, random_state=42, n_jobs = -1)<br/>rf_random.fit(features_train, label_train)</span></pre><blockquote class="lp lq lr"><p id="b526" class="jy jz ls ka b kb kc kd ke kf kg kh ki lt kk kl km lu ko kp kq lv ks kt ku kv ij bi translated">最终模型和模型性能— <em class="iq">评估</em></p></blockquote><p id="0c50" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">目前，我们选择了能提供更高精度值的最终模型。然而，我们还没有完成。我们需要基于各种度量来评估模型性能。该框架包含计算实际与预测值交叉表、ROC 曲线、十分位数、KS 统计、提升图、实际与预测图、增益图的代码。我们将在下面逐一介绍。</p><ol class=""><li id="9596" class="ms mt iq ka b kb kc kf kg kj mu kn mv kr mw kv mx my mz na bi translated"><strong class="ka ir">交叉表</strong></li></ol><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="a21d" class="mf mg iq mb b gy mh mi l mj mk">pd.crosstab(label_train,pd.Series(pred_train),rownames=['ACTUAL'],colnames=['PRED'])</span></pre><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/b2d19dfc5d4c4478c7bda898c94ab925.png" data-original-src="https://miro.medium.com/v2/resize:fit:324/format:webp/1*b3Ks6ka1FA8Ra0P8zBikSg.png"/></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">Crosstab of Actual vs Predicted values</figcaption></figure><p id="a46b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 2。ROC/AUC 曲线或 c 统计</strong></p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="c4e3" class="mf mg iq mb b gy mh mi l mj mk">from bokeh.charts import Histogram<br/>from ipywidgets import interact<br/>from bokeh.plotting import figure<br/>from bokeh.io import push_notebook, show, output_notebook<br/>output_notebook()</span><span id="bcc4" class="mf mg iq mb b gy nc mi l mj mk">from sklearn import metrics<br/>preds = clf.predict_proba(features_train)[:,1]</span><span id="613b" class="mf mg iq mb b gy nc mi l mj mk">fpr, tpr, _ = metrics.roc_curve(np.array(label_train), preds)<br/>auc = metrics.auc(fpr,tpr)</span><span id="fb61" class="mf mg iq mb b gy nc mi l mj mk">p = figure(title="ROC Curve - Train data")<br/>r = p.line(fpr,tpr,color='#0077bc',legend = 'AUC = '+ str(round(auc,3)), line_width=2)<br/>s = p.line([0,1],[0,1], color= '#d15555',line_dash='dotdash',line_width=2)<br/>show(p)</span></pre><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/450fc141d231b729d9c5c6ea51946612.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*7PhhAwUzDIwjBI4lPKP_jw.png"/></div></figure><p id="0034" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 3。十分位数图和 Kolmogorov Smirnov (KS)统计数据</strong></p><p id="3d01" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在后端执行一个宏来生成下图。黄色突出显示的数字是 KS 统计值。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="a159" class="mf mg iq mb b gy mh mi l mj mk">deciling(scores_train,['DECILE'],'TARGET','NONTARGET')</span></pre><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ne"><img src="../Images/85a1de9d97e625d2e3e923275725debd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*owg7p3a9eNywn-PZSabzBg.png"/></div></div></figure><p id="5011" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir"> 4。提升图、实际与预测图、收益图</strong></p><p id="3b0a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">与十分位数图类似，宏用于生成下面的图。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="e3d5" class="mf mg iq mb b gy mh mi l mj mk">gains(lift_train,['DECILE'],'TARGET','SCORE')</span></pre><figure class="lw lx ly lz gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nf"><img src="../Images/51e873b4c61c3d17daf804131478787c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-TXQmEDAJpNzKBg8x7EVhA.png"/></div></div></figure><blockquote class="lp lq lr"><p id="daff" class="jy jz ls ka b kb kc kd ke kf kg kh ki lt kk kl km lu ko kp kq lv ks kt ku kv ij bi translated">保存模型以备将来使用— <em class="iq">部署</em></p></blockquote><p id="9a04" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后，我们开发了我们的模型并评估了所有不同的指标，现在我们准备在生产中部署模型。部署前的最后一步是保存我们的模型，这是使用下面的代码完成的。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="306f" class="mf mg iq mb b gy mh mi l mj mk"><strong class="mb ir">import</strong> <strong class="mb ir">pandas</strong><br/><strong class="mb ir">from</strong> <strong class="mb ir">sklearn.externals</strong> <strong class="mb ir">import</strong> joblib<br/><br/>filename = 'final_model.model'<br/>i = [d,clf]<br/>joblib.dump(i,filename)</span></pre><p id="58e6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这里，“clf”是模型分类器对象，“d”是标签编码器对象，用于将字符转换为数字变量。</p><blockquote class="lp lq lr"><p id="eb3e" class="jy jz ls ka b kb kc kd ke kf kg kh ki lt kk kl km lu ko kp kq lv ks kt ku kv ij bi translated">评分新数据— <em class="iq">部署</em></p></blockquote><p id="fa57" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了评分，我们需要将模型对象(clf)和标签编码器对象加载回 python 环境。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="b26a" class="mf mg iq mb b gy mh mi l mj mk"><em class="ls"># Use the code to load the model</em><br/>filename = 'final_model.model'<br/><br/><strong class="mb ir">from</strong> <strong class="mb ir">sklearn.externals</strong> <strong class="mb ir">import</strong> joblib<br/>d,clf=joblib.load(filename)</span></pre><p id="5fa6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">然后，我们加载新的数据集并传递给评分宏。</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="c1ea" class="mf mg iq mb b gy mh mi l mj mk"><strong class="mb ir">def</strong> score_new(features,clf):<br/>    score = pd.DataFrame(clf.predict_proba(features)[:,1], columns = ['SCORE'])<br/>    score['DECILE'] = pd.qcut(score['SCORE'].rank(method = 'first'),10,labels=range(10,0,-1))<br/>    score['DECILE'] = score['DECILE'].astype(float)<br/>    <strong class="mb ir">return</strong>(score)</span></pre><p id="1941" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们用下面的代码调用这个宏</p><pre class="lw lx ly lz gt ma mb mc md aw me bi"><span id="8b06" class="mf mg iq mb b gy mh mi l mj mk">scores = score_new(new_score_data,clf)</span></pre><p id="fb40" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">就是这样。我们已经给新数据打分了。本文提供了技术代码的高级概述。如果您需要讨论任何特别的事情，或者您对任何模块有反馈，请留下评论或通过<a class="ae ng" href="http://www.linkedin.com/in/sundarkrishnan1" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系我。</p><p id="30d5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">玩得开心！</p></div><div class="ab cl nh ni hu nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="ij ik il im in"><p id="f734" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我发布了一个 python 包，它将执行本文中提到的一些任务——WOE 和 IV，双变量图表，变量选择。如果你有兴趣使用软件包版本，请阅读下面的文章。</p><div class="kw kx gp gr ky kz"><a rel="noopener follow" target="_blank" href="/introducing-xverse-a-python-package-for-feature-selection-and-transformation-17193cdcd067"><div class="la ab fo"><div class="lb ab lc cl cj ld"><h2 class="bd ir gy z fp le fr fs lf fu fw ip bi translated">Xverse 介绍！—用于要素选择和变换的 python 包</h2><div class="lg l"><h3 class="bd b gy z fp le fr fs lf fu fw dk translated">Xverse 是 X Universe 的缩写，它是一个用于机器学习的 python 包，可以帮助数据科学家利用特性…</h3></div><div class="lh l"><p class="bd b dl z fp le fr fs lf fu fw dk translated">towardsdatascience.com</p></div></div><div class="li l"><div class="no l lk ll lm li ln jw kz"/></div></div></a></div></div></div>    
</body>
</html>