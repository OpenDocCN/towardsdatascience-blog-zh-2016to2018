<html>
<head>
<title>Predicting Hotel Bookings with User Search Parameters</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用用户搜索参数预测酒店预订</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/predicting-hotel-bookings-with-user-search-parameters-8c570ab24805?source=collection_archive---------7-----------------------#2018-07-31">https://towardsdatascience.com/predicting-hotel-bookings-with-user-search-parameters-8c570ab24805?source=collection_archive---------7-----------------------#2018-07-31</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/4b0af0547d417f7795d56768815f8fb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5gDjxOjv1RRBFjFk7Xd6KQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Photo credit: Pixabay</figcaption></figure><p id="e79f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">一家酒店市场数据和基准公司<a class="ae la" href="https://www.strglobal.com/" rel="noopener ugc nofollow" target="_blank"> STR </a>和谷歌发布了一份<a class="ae la" href="https://str.com/str-google-research1" rel="noopener ugc nofollow" target="_blank">报告</a>显示，跟踪酒店搜索结果可以对酒店预订量进行可靠的估计。因此，我们今天的目标是尝试建立一个机器学习模型，根据用户的搜索和与该用户事件相关的其他属性来预测用户事件的结果(预订或只是点击)。</p><h1 id="189c" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">数据</h1><p id="2be9" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">数据是公开的，可以从<a class="ae la" href="https://www.kaggle.com/c/expedia-hotel-recommendations/data" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载。我们只使用训练集。下表提供了数据集的模式。</p><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div class="gh gi me"><img src="../Images/537d8e9f7efc6035ef8b7bd1870f6be0.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/format:webp/1*qx6uN9Zr1Y2BVtm_yCAv5Q.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 1</figcaption></figure><pre class="mf mg mh mi gt mj mk ml mm aw mn bi"><span id="0587" class="mo lc iq mk b gy mp mq l mr ms">import datetime<br/>import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>%matplotlib inline</span><span id="b724" class="mo lc iq mk b gy mt mq l mr ms">from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.decomposition import PCA<br/>from sklearn.metrics import classification_report<br/>from sklearn.metrics import confusion_matrix  <br/>from sklearn.metrics import accuracy_score</span><span id="f5b2" class="mo lc iq mk b gy mt mq l mr ms">df = pd.read_csv('train.csv.gz', sep=',').dropna()<br/>df = df.sample(frac=0.01, random_state=99)</span></pre><p id="b652" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">为了能够在本地处理，我们将使用 1%的数据。之后我们还有大量的 241179 条记录。</p><pre class="mf mg mh mi gt mj mk ml mm aw mn bi"><span id="5ebb" class="mo lc iq mk b gy mp mq l mr ms">df.shape</span></pre><p id="120e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> <em class="mu"> (241179，24) </em> </strong></p><pre class="mf mg mh mi gt mj mk ml mm aw mn bi"><span id="3549" class="mo lc iq mk b gy mp mq l mr ms">count_classes = pd.value_counts(df['is_booking'], sort = True).sort_index()<br/>count_classes.plot(kind = 'bar')<br/>plt.title("Booking or Not booking")<br/>plt.xlabel("Class")<br/>plt.ylabel("Frequency")</span></pre><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/40adeb46d4e6a465400b99792f67f09a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*s8TMVcA0yMDdoifU6OUSAw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 2</figcaption></figure><p id="e656" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">很明显我们的数据很不平衡。我们将不得不处理它。</p><h1 id="044a" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak">特征工程</strong></h1><p id="1d61" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">该过程包括创建新列，如年、月、计划时间和酒店住宿。然后移除我们不再需要的柱子。</p><pre class="mf mg mh mi gt mj mk ml mm aw mn bi"><span id="cdf2" class="mo lc iq mk b gy mp mq l mr ms">df["date_time"] = pd.to_datetime(df["date_time"]) <br/>df["year"] = df["date_time"].dt.year  <br/>df["month"] = df["date_time"].dt.month</span><span id="8ec7" class="mo lc iq mk b gy mt mq l mr ms">df['srch_ci']=pd.to_datetime(df['srch_ci'],infer_datetime_format = True,errors='coerce')<br/>df['srch_co']=pd.to_datetime(df['srch_co'],infer_datetime_format = True,errors='coerce')</span><span id="9530" class="mo lc iq mk b gy mt mq l mr ms">df['plan_time'] = ((df['srch_ci']-df['date_time'])/np.timedelta64(1,'D')).astype(float)<br/>df['hotel_nights']=((df['srch_co']-df['srch_ci'])/np.timedelta64(1,'D')).astype(float)</span><span id="8d6b" class="mo lc iq mk b gy mt mq l mr ms">cols_to_drop = ['date_time', 'srch_ci', 'srch_co', 'user_id']<br/>df.drop(cols_to_drop, axis=1, inplace=True)</span></pre><p id="5b4d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">使用热图绘制关联矩阵，以探索特征之间的关联。</p><pre class="mf mg mh mi gt mj mk ml mm aw mn bi"><span id="993a" class="mo lc iq mk b gy mp mq l mr ms">correlation = df.corr()<br/>plt.figure(figsize=(18, 18))<br/>sns.heatmap(correlation, vmax=1, square=True,annot=True,cmap='viridis')</span><span id="d01e" class="mo lc iq mk b gy mt mq l mr ms">plt.title('Correlation between different fearures')</span></pre><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mw"><img src="../Images/fc59845540287c9526be50807da3033b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kaDHqGj0JxOOEEVfp4eejw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 3</figcaption></figure><p id="f090" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们看不到任何两个变量有非常密切的关联。</p><h1 id="1d0c" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak">不平衡数据的处理</strong></h1><p id="b78b" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">我将使用欠采样方法来创建重采样数据帧。</p><pre class="mf mg mh mi gt mj mk ml mm aw mn bi"><span id="9ba3" class="mo lc iq mk b gy mp mq l mr ms">booking_indices = df[df.is_booking == 1].index<br/>random_indices = np.random.choice(booking_indices, len(df.loc[df.is_booking == 1]), replace=False)<br/>booking_sample = df.loc[random_indices]</span><span id="328e" class="mo lc iq mk b gy mt mq l mr ms">not_booking = df[df.is_booking == 0].index<br/>random_indices = np.random.choice(not_booking, sum(df['is_booking']), replace=False)<br/>not_booking_sample = df.loc[random_indices]</span><span id="cdd0" class="mo lc iq mk b gy mt mq l mr ms">df_new = pd.concat([not_booking_sample, booking_sample], axis=0)</span><span id="b131" class="mo lc iq mk b gy mt mq l mr ms">print("Percentage of not booking clicks: ", len(df_new[df_new.is_booking == 0])/len(df_new))<br/>print("Percentage of booking clicks: ", len(df_new[df_new.is_booking == 1])/len(df_new))<br/>print("Total number of records in resampled data: ", len(df_new))</span></pre><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/00dae4698f1f117a068246eb72cbbe14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ojVAbOTnLJ9vaty5XRKSmQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 4</figcaption></figure><p id="cb2d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">混洗重新采样的数据帧</strong>。</p><pre class="mf mg mh mi gt mj mk ml mm aw mn bi"><span id="e9b8" class="mo lc iq mk b gy mp mq l mr ms">df_new = df_new.sample(frac=1).reset_index(drop=True)</span></pre><p id="400a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">为新数据帧分配特征和标签</strong>。</p><pre class="mf mg mh mi gt mj mk ml mm aw mn bi"><span id="f344" class="mo lc iq mk b gy mp mq l mr ms">X = df_new.loc[:, df_new.columns != 'is_booking']<br/>y = df_new.loc[:, df_new.columns == 'is_booking']</span></pre><h1 id="16f6" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak"> PCA </strong></h1><p id="e223" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated">主成分分析(PCA)是一种统计技术，通过选择捕捉关于数据集的最大信息的最重要特征，将高维数据转换为低维数据。我们希望主成分分析能帮助我们找出方差最大的成分。</p><p id="eb2a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">标准化数据集</strong>。</p><pre class="mf mg mh mi gt mj mk ml mm aw mn bi"><span id="71ec" class="mo lc iq mk b gy mp mq l mr ms">scaler = StandardScaler()<br/>X=scaler.fit_transform(X)<br/>X</span></pre><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi my"><img src="../Images/6759faf3907d7cc807953d6ab8c115c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4byzyMn4iMo97_VtQ6gLjQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 5</figcaption></figure><p id="9dd8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">应用五氯苯甲醚。我们的数据中有 23 个特征</strong>。</p><pre class="mf mg mh mi gt mj mk ml mm aw mn bi"><span id="3a2c" class="mo lc iq mk b gy mp mq l mr ms">pca = PCA(n_components=23)<br/>pca.fit(X)</span></pre><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mz"><img src="../Images/eecbc8659300d2cd2171edf722a6ca48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AP-ofItBoqD22YdcDtJWSA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 6</figcaption></figure><p id="d5db" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">计算特征值</strong>。</p><pre class="mf mg mh mi gt mj mk ml mm aw mn bi"><span id="545d" class="mo lc iq mk b gy mp mq l mr ms">var=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=3)*100)<br/>var</span></pre><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi na"><img src="../Images/7df2977c753c129c5062e744b9503766.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VvbeDpSR3aqZA9MGkIklfA.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 7</figcaption></figure><p id="2700" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在上面的数组中，我们看到第一个特征解释了数据集内 9.6%的方差，而前两个特征解释了 17.8%，依此类推。如果我们使用所有的特征，我们就可以获得数据集中 100%的方差，因此我们可以通过实现一个额外的特征来获得一些方差。没有任何突出的特征。</p><p id="61c3" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">分类选择</strong>。</p><pre class="mf mg mh mi gt mj mk ml mm aw mn bi"><span id="0b4a" class="mo lc iq mk b gy mp mq l mr ms">plt.ylabel('% Variance Explained')<br/>plt.xlabel('# of Features')<br/>plt.title('PCA Analysis')<br/>plt.style.context('seaborn-whitegrid')</span><span id="68a3" class="mo lc iq mk b gy mt mq l mr ms">plt.plot(var)</span></pre><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/40a21e7725b757084659663dacc968b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*0142643J55_3lUtY_7lHkw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 8</figcaption></figure><p id="10e0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">根据上面的图，很明显我们应该保留所有的 23 个特征。</p><h1 id="5407" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak">训练、预测和绩效评估</strong></h1><p id="3e69" class="pw-post-body-paragraph kc kd iq ke b kf lz kh ki kj ma kl km kn mb kp kq kr mc kt ku kv md kx ky kz ij bi translated"><strong class="ke ir">随机森林分类器</strong></p><pre class="mf mg mh mi gt mj mk ml mm aw mn bi"><span id="027c" class="mo lc iq mk b gy mp mq l mr ms">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)</span><span id="f01c" class="mo lc iq mk b gy mt mq l mr ms">pca = PCA()  <br/>X_train = pca.fit_transform(X_train)  <br/>X_test = pca.transform(X_test)</span><span id="83bd" class="mo lc iq mk b gy mt mq l mr ms">classifier = RandomForestClassifier(max_depth=2, random_state=0)  <br/>classifier.fit(X_train, y_train)</span><span id="df9a" class="mo lc iq mk b gy mt mq l mr ms">y_pred = classifier.predict(X_test)</span><span id="066b" class="mo lc iq mk b gy mt mq l mr ms">cm = confusion_matrix(y_test, y_pred)  <br/>print(cm)  <br/>print('Accuracy', accuracy_score(y_test, y_pred))</span></pre><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/d662348b9fde027f4ed9d6fe5e4c2331.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*Hl1I6BVhJtYvJpsLotk87A.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 9</figcaption></figure><p id="ea5f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">逻辑回归</strong></p><pre class="mf mg mh mi gt mj mk ml mm aw mn bi"><span id="40d0" class="mo lc iq mk b gy mp mq l mr ms">from sklearn.linear_model import LogisticRegression<br/>from sklearn.pipeline import Pipeline</span><span id="e0d4" class="mo lc iq mk b gy mt mq l mr ms">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)<br/>pca = PCA(n_components=23)<br/>logReg = LogisticRegression()</span><span id="cb1e" class="mo lc iq mk b gy mt mq l mr ms">pipe = Pipeline([('pca', pca), ('logistic', logReg)])<br/>pipe.fit(X_train, y_train)<br/>y_pred = pipe.predict(X_test)</span><span id="940b" class="mo lc iq mk b gy mt mq l mr ms">cm = confusion_matrix(y_test, y_pred)  <br/>print(cm)  <br/>print('Accuracy', accuracy_score(y_test, y_pred))</span></pre><figure class="mf mg mh mi gt jr gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/0c877d638c764cdc242b70c500ef4e9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*S9KHhIlKko-w5GiCQUmXOw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Figure 10</figcaption></figure><p id="f39b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们可以通过<a class="ae la" href="http://scikit-learn.org/stable/modules/grid_search.html" rel="noopener ugc nofollow" target="_blank">彻底的网格搜索</a>将结果提高到 70%。但是在本地运行需要很长时间。我不会在这里尝试。</p><p id="f6fc" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">正如你所看到的，从我们现有的数据来预测酒店预订并不是一件容易的事情。我们需要更多的功能，如平均每日房价，用户以前的预订历史，是否有特别促销，酒店在线评论等等。</p><p id="42c8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">机器学习前的数据收集入门！</p><p id="aa26" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">源代码可以在<a class="ae la" href="https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Predict%20hotel%20booking.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。享受这周剩下的时光吧！</p></div></div>    
</body>
</html>