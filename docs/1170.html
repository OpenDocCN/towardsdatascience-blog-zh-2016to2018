<html>
<head>
<title>Building a real time object recognizer for iOS</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为 iOS 构建实时对象识别器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-a-real-time-object-recognizer-for-ios-a678d2baf8f0?source=collection_archive---------3-----------------------#2017-08-05">https://towardsdatascience.com/building-a-real-time-object-recognizer-for-ios-a678d2baf8f0?source=collection_archive---------3-----------------------#2017-08-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="c0e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用 CoreML 和 Swift</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/5006c69b970c5e49781309fe9f1518c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HOmbarPbQeI2NqTVk6Z1Jw.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Credits — Apple (<a class="ae lb" href="https://developer.apple.com/documentation/coreml" rel="noopener ugc nofollow" target="_blank">https://developer.apple.com/documentation/coreml</a>)</figcaption></figure><p id="edd5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">CoreML 是 WWDC 2017 上宣布的令人兴奋的功能之一。它是苹果的框架，可以用来将机器学习集成到你的应用程序中，全部离线😉。</p><blockquote class="lc ld le"><p id="b3f6" class="jn jo lf jp b jq jr js jt ju jv jw jx lg jz ka kb lh kd ke kf li kh ki kj kk ij bi translated">Core ML 允许您将各种各样的机器学习模型集成到您的应用程序中。除了支持超过 30 种层类型的广泛深度学习，它还支持标准模型，如树集成、支持向量机和广义线性模型。因为它建立在 Metal 和 Accelerate 等底层技术之上，所以 Core ML 无缝地利用 CPU 和 GPU 来提供最大的性能和效率。你可以在设备上运行机器学习模型，这样数据就不需要离开设备进行分析。—苹果关于机器学习的文档(<a class="ae lb" href="https://developer.apple.com/machine-learning/" rel="noopener ugc nofollow" target="_blank">https://developer.apple.com/machine-learning/</a>)</p></blockquote><p id="5009" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当你深入了解预测是如何发生的以及发生在哪里时，CoreML 的重要性就显现出来了。到目前为止，每个人都习惯于将机器学习集成到应用程序中，在托管服务器中进行预测。如果它是一个对象识别应用程序，您必须从设备中捕获帧，将这些数据发送到预测引擎，等到图像完全上传到服务器，并最终获得输出。这种方法主要有两个问题——网络延迟和用户隐私。现在，所有这些处理都可以在设备中进行，从而减少了这两个问题。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi lj"><img src="../Images/14acf7e2949ea2e63e83a4c3da8e5b42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*ynkoTTq6QwHY8Dl9ma0r1w.png"/></div></figure><h1 id="7edb" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">从头开始构建</h1><p id="f019" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">我们可以尝试使用 CoreML 并为此实现一个简单的设备上解决方案。我将在不提及 iOS 或 Swift 基础知识的情况下讲述重要步骤。</p><p id="f60e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们要做的第一件事是获得一个 iOS 11 设备和 Xcode 9。</p><p id="4ee0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你不熟悉机器学习，看看这里的简介。或者你可以从这里得到一个很高层次的概述。</p><h2 id="3991" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">机器学习</h2><p id="dbee" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">这种技术赋予计算机学习的能力，而不需要明确地编码问题的解决方案。</p><p id="3eed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里基本上涉及两个过程——训练和预测。</p><p id="5d15" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">训练</strong>是我们给模型不同组的输入(和相应的输出)来从模式中学习的过程。这个被训练的模型被给予一个它以前没有见过的输入，以便<strong class="jp ir">根据它早先的观察来预测</strong>。</p><h2 id="35d6" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">选择模型</h2><p id="1e50" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">所以我们要做的第一件事就是为你的项目选择一个好的模型。有许多预先训练好的模型可用于图像识别。或者你甚至可以训练自己的模型来获得更好的体验。</p><p id="c36a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从<a class="ae lb" href="https://developer.apple.com/machine-learning/" rel="noopener ugc nofollow" target="_blank">苹果的机器学习门户</a>有好的模型可以作为 CoreML 模型。或者如果你有自己的模型，你可以使用苹果公司的<a class="ae lb" href="https://pypi.python.org/pypi/coremltools" rel="noopener ugc nofollow" target="_blank"> CoreML 工具</a>将其转换成 CoreML 支持的模型。</p><p id="cbfc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我选择了苹果门户中可用的 Inception V3 库。</p><blockquote class="lc ld le"><p id="8ad3" class="jn jo lf jp b jq jr js jt ju jv jw jx lg jz ka kb lh kd ke kf li kh ki kj kk ij bi translated"><strong class="jp ir"> Inception v3 </strong> —从一组 1000 个类别中检测图像中存在的主要对象，例如树木、动物、食物、车辆、人等等。</p></blockquote><h2 id="1aa9" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">创建 iOS 项目</h2><p id="f2fe" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">您可以使用 swift 创建一个基本的 iOS 项目，并为此创建一个包含视频预览层和标签的视图控制器。</p><h2 id="905c" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">从视频预览中获取帧</h2><p id="e5a7" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">像往常一样获取当前帧，这是我们已经知道的。这在这篇入侵代码<a class="ae lb" href="https://www.invasivecode.com/weblog/AVFoundation-Swift-capture-video/" rel="noopener ugc nofollow" target="_blank">文章</a>中有解释。</p><h2 id="6ec1" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">使用 Inception v3 进行预测</h2><p id="53ab" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">当一个输入图像给你一个它知道的类别集合中的一个的概率时，考虑我们的初始模型作为黑盒。</p><p id="e408" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从 Apple 的门户网站下载模型，将其拖放到您的项目中。您可以从 Xcode 中看到模型描述。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mz"><img src="../Images/2f9bf9ac0a3e80d7a1dd5ea61481a087.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fZcj-CWP9EWn1whPn5-Ebg.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Inceptionv2.mlmodel in model viewer of Xcode</figcaption></figure><p id="daab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以看到，该模型将 299x299 像素的图像作为输入，并给出输出:</p><ul class=""><li id="8030" class="na nb iq jp b jq jr ju jv jy nc kc nd kg ne kk nf ng nh ni bi translated">图像最可能属于的类别</li><li id="1aca" class="na nb iq jp b jq nj ju nk jy nl kc nm kg nn kk nf ng nh ni bi translated">每个类别的概率列表</li></ul><p id="3c06" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以利用这些参数中的任何一个来确定类别。我用的第一个是字符串，直接打印在屏幕上。</p><p id="c86d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您还可以看到，Xcode 直接从 mlmodel 对象创建了一个 swift 模型(Inceptionv3.swift)。你不必为此做任何额外的改动。</p><h2 id="f4b0" class="mn ll iq bd lm mo mp dn lq mq mr dp lu jy ms mt ly kc mu mv mc kg mw mx mg my bi translated">使用</h2><p id="c317" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">我们可以利用 Xcode 生成的预测 API，如下所示:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="72c1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">预测很简单:</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="no np l"/></div></figure><p id="c19d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是它需要一个 CVPixelBuffer 的对象而不是 UIImage 来进行预测，hackingwithswift.com 的家伙在“机器学习和视觉”一节中对此做了很好的解释。</p><p id="becc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我已经创建了 UIImage 类别，该类别与 resize API 一起对此进行了抽象。</p><figure class="km kn ko kp gt kq"><div class="bz fp l di"><div class="no np l"/></div></figure><h1 id="b157" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">最终建筑</h1><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi nq"><img src="../Images/b1baded53488c9f08517653f12822df3.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*dBWY7pNErAKgWcspS2vn1w.jpeg"/></div></figure><h1 id="5da9" class="lk ll iq bd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh bi translated">结果</h1><p id="0bb2" class="pw-post-body-paragraph jn jo iq jp b jq mi js jt ju mj jw jx jy mk ka kb kc ml ke kf kg mm ki kj kk ij bi translated">该应用程序能够正确识别几乎所有提供的输入。</p><div class="km kn ko kp gt ab cb"><figure class="nr kq ns nt nu nv nw paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><img src="../Images/5d3a7683dcab63ea3bd0a5c80d001bda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*HVpPHedjuKq8spdZ-OHPKw.jpeg"/></div></figure><figure class="nr kq ns nt nu nv nw paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><img src="../Images/ab1f2da0399512e33ea31831701bb649.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*uIHcl6n5_PBvFSiXimaPXw.jpeg"/></div></figure></div><div class="ab cb"><figure class="nr kq ns nt nu nv nw paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><img src="../Images/1492b1aaae27eef0a5cc447eb00c0402.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*K_lFmUYbkcGPUT6iUrwi0w.jpeg"/></div></figure><figure class="nr kq ns nt nu nv nw paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><img src="../Images/c26598378757a2554b376d6c4f2e39ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*gTFZ300g8MAkD-1OHu8_mg.jpeg"/></div></figure></div><p id="7c77" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从回购中获取完整代码—<a class="ae lb" href="https://github.com/m25lazi/inception" rel="noopener ugc nofollow" target="_blank">https://github.com/m25lazi/inception</a>。⭐️，如果你喜欢的话。</p></div></div>    
</body>
</html>