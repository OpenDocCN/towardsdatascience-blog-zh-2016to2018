<html>
<head>
<title>A Complete Machine Learning Walk-Through in Python: Part Two</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 中完整的机器学习演练:第二部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-complete-machine-learning-project-walk-through-in-python-part-two-300f1f8147e2?source=collection_archive---------3-----------------------#2018-05-17">https://towardsdatascience.com/a-complete-machine-learning-project-walk-through-in-python-part-two-300f1f8147e2?source=collection_archive---------3-----------------------#2018-05-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/a7dd34aac42e4d7cf353f6e2bf140f57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-zQ8TGzcKyFllVOFBAUXwg.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="d5a8" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">模型选择、超参数调整和评估</h2></div><p id="8bd0" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">组装解决问题所需的所有机器学习部件可能是一项艰巨的任务。在这一系列文章中，我们将使用真实世界的数据集来实现机器学习工作流，以了解各种技术是如何结合在一起的。</p><p id="2151" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><a class="ae lm" rel="noopener" target="_blank" href="/a-complete-machine-learning-walk-through-in-python-part-one-c62152f39420">在第一篇文章</a>中，我们清理并结构化了数据，进行了探索性的数据分析，开发了一组在我们的模型中使用的特性，并建立了一个我们可以用来衡量性能的基线。在本文中，我们将了解如何在 Python 中实现和比较几个机器学习模型，执行超参数调整以优化最佳模型，并在测试集上评估最终模型。</p><p id="1a04" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这个项目的完整代码是 GitHub 上的<a class="ae lm" href="https://github.com/WillKoehrsen/machine-learning-project-walkthrough" rel="noopener ugc nofollow" target="_blank">，与本文对应的</a><a class="ae lm" href="https://github.com/WillKoehrsen/machine-learning-project-walkthrough/blob/master/Machine%20Learning%20Project%20Part%202.ipynb" rel="noopener ugc nofollow" target="_blank">第二本笔记本在这里</a>。您可以随意使用、共享和修改代码！</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="32e1" class="lu lv jb bd lw lx ly lz ma mb mc md me kh mf ki mg kk mh kl mi kn mj ko mk ml bi translated">模型评估和选择</h1><p id="4e79" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">提醒一下，我们正在进行一项监督回归任务:<a class="ae lm" href="http://www.nyc.gov/html/gbee/html/plan/ll84_scores.shtml" rel="noopener ugc nofollow" target="_blank">使用纽约市建筑能源数据</a>，我们希望开发一个模型，可以预测建筑的<a class="ae lm" href="https://www.energystar.gov/buildings/facility-owners-and-managers/existing-buildings/use-portfolio-manager/interpret-your-results/what" rel="noopener ugc nofollow" target="_blank">能源之星得分</a>。我们的重点是预测的准确性和模型的可解释性。</p><p id="50e5" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">有<a class="ae lm" href="http://scikit-learn.org/stable/supervised_learning.html" rel="noopener ugc nofollow" target="_blank">吨的机器学习模型</a>可供选择，决定从哪里开始可能是令人生畏的。虽然<a class="ae lm" href="https://docs.microsoft.com/en-us/azure/machine-learning/studio/algorithm-cheat-sheet" rel="noopener ugc nofollow" target="_blank">有一些图表</a>试图告诉你使用哪种算法，但我更喜欢尝试几种，看看哪种效果最好！机器学习仍然是一个主要由<a class="ae lm" href="https://www.quora.com/How-much-of-deep-learning-research-is-empirical-versus-theoretical" rel="noopener ugc nofollow" target="_blank">经验(实验)而不是理论结果</a>驱动的领域，并且几乎不可能<a class="ae lm" href="http://www.statsblogs.com/2014/01/25/machine-learning-lesson-of-the-day-the-no-free-lunch-theorem/" rel="noopener ugc nofollow" target="_blank">提前知道哪个模型会做得最好</a>。</p><p id="221b" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">一般来说，从简单、可解释的模型(如线性回归)开始是一个好主意，如果性能不够好，就转向更复杂但通常更精确的方法。下图显示了准确性与可解释性权衡的(极不科学的)版本:</p><figure class="ms mt mu mv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mr"><img src="../Images/eecd378c22b9f5cb3b65e15052163fb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NkffR5Ufy_h4RfSVpTJ2iQ.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk">Interpretability vs. Accuracy (<a class="ae lm" href="http://blog.fastforwardlabs.com/2017/09/01/LIME-for-couples.html" rel="noopener ugc nofollow" target="_blank">Source</a>)</figcaption></figure><p id="ea2b" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们将评估涵盖复杂性范围的五种不同模型:</p><ul class=""><li id="7a76" class="na nb jb ks b kt ku kw kx kz nc ld nd lh ne ll nf ng nh ni bi translated"><strong class="ks jc">线性回归</strong></li><li id="cab3" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll nf ng nh ni bi translated"><strong class="ks jc">K-最近邻回归</strong></li><li id="ff4e" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll nf ng nh ni bi translated"><strong class="ks jc">随机森林回归</strong></li><li id="c138" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll nf ng nh ni bi translated"><strong class="ks jc">梯度推进回归</strong></li><li id="a18e" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll nf ng nh ni bi translated"><strong class="ks jc">支持向量机回归</strong></li></ul><p id="616f" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在这篇文章中，我们将着重于实现这些方法，而不是它们背后的理论。对于任何对学习背景感兴趣的人，我强烈推荐<a class="ae lm" href="http://www-bcf.usc.edu/~gareth/ISL/" rel="noopener ugc nofollow" target="_blank">统计学习入门</a>(网上免费提供)或<a class="ae lm" href="http://shop.oreilly.com/product/0636920052289.do" rel="noopener ugc nofollow" target="_blank">使用 Scikit-Learn 和 TensorFlow </a>进行机器学习。这两本教科书都很好地解释了理论，并分别展示了如何有效地使用 R 和 Python 中的方法。</p><h2 id="e003" class="no lv jb bd lw np nq dn ma nr ns dp me kz nt nu mg ld nv nw mi lh nx ny mk nz bi translated">输入缺失值</h2><p id="cf2e" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">虽然我们在清理数据时删除了丢失值超过 50%的列，但仍然有相当多的观察值丢失。机器学习模型无法处理任何缺失的值，所以我们必须填充它们，这是一个被称为插补的<a class="ae lm" href="https://en.wikipedia.org/wiki/Imputation_(statistics)" rel="noopener ugc nofollow" target="_blank">过程。</a></p><p id="dba7" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">首先，我们将读入所有数据，并提醒自己它看起来像什么:</p><pre class="ms mt mu mv gt oa ob oc od aw oe bi"><span id="cd4c" class="no lv jb ob b gy of og l oh oi">import pandas as pd<br/>import numpy as np</span><span id="7cad" class="no lv jb ob b gy oj og l oh oi"># Read in data into dataframes <br/>train_features = pd.read_csv('data/training_features.csv')<br/>test_features = pd.read_csv('data/testing_features.csv')<br/>train_labels = pd.read_csv('data/training_labels.csv')<br/>test_labels = pd.read_csv('data/testing_labels.csv')</span><span id="8956" class="no lv jb ob b gy oj og l oh oi"><strong class="ob jc">Training Feature Size:  (6622, 64)<br/>Testing Feature Size:   (2839, 64)<br/>Training Labels Size:   (6622, 1)<br/>Testing Labels Size:    (2839, 1)</strong></span></pre><figure class="ms mt mu mv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ok"><img src="../Images/534c7641efc4ab2422d38ab0b730dcf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DSDwIKdBlT2BRyWKIKAtrw.png"/></div></div></figure><p id="233b" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">每个值<code class="fe ol om on ob b">NaN</code>代表一个缺失的观察值。虽然有多种<a class="ae lm" href="https://www.omicsonline.org/open-access/a-comparison-of-six-methods-for-missing-data-imputation-2155-6180-1000224.php?aid=54590" rel="noopener ugc nofollow" target="_blank">方法来填充缺失数据</a>，但我们将使用一种相对简单的方法，即中位数插补。这会用列的中值替换列中所有缺失的值。</p><p id="4f4c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在下面的代码中，我们创建了一个策略设置为 median 的<a class="ae lm" href="http://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn </a> <code class="fe ol om on ob b">Imputer</code>对象。然后我们在训练数据上训练这个对象(使用<code class="fe ol om on ob b">imputer.fit</code>，并用它来填充训练和测试数据中缺失的值(使用<code class="fe ol om on ob b">imputer.transform</code>)。这意味着用来自<em class="oo">训练数据</em>的相应中值来填充<em class="oo">测试数据</em>中的缺失值。</p><p id="3a43" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">(我们必须以这种方式进行插补，而不是对所有数据进行训练，以避免<a class="ae lm" href="https://www.kaggle.com/dansbecker/data-leakage" rel="noopener ugc nofollow" target="_blank">测试数据泄漏</a>的问题，即来自测试数据集的信息溢出到训练数据中。)</p><pre class="ms mt mu mv gt oa ob oc od aw oe bi"><span id="cbda" class="no lv jb ob b gy of og l oh oi"># Create an imputer object with a median filling strategy<br/>imputer = Imputer(strategy='median')</span><span id="8fd8" class="no lv jb ob b gy oj og l oh oi"># Train on the training features<br/>imputer.fit(train_features)</span><span id="a9f6" class="no lv jb ob b gy oj og l oh oi"># Transform both training data and testing data<br/>X = imputer.transform(train_features)<br/>X_test = imputer.transform(test_features)</span><span id="9e38" class="no lv jb ob b gy oj og l oh oi"><strong class="ob jc">Missing values in training features:  0<br/>Missing values in testing features:   0</strong></span></pre><p id="3ba3" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">所有的特征现在都有真实的有限值，没有遗漏的例子。</p><h2 id="7023" class="no lv jb bd lw np nq dn ma nr ns dp me kz nt nu mg ld nv nw mi lh nx ny mk nz bi translated">特征缩放</h2><p id="5d0a" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated"><a class="ae lm" href="https://en.wikipedia.org/wiki/Feature_scaling" rel="noopener ugc nofollow" target="_blank">缩放</a>是指改变特征范围的一般过程。<a class="ae lm" href="https://stats.stackexchange.com/questions/121886/when-should-i-apply-feature-scaling-for-my-data" rel="noopener ugc nofollow" target="_blank">这是必要的</a>，因为特征以不同的单位测量，因此涵盖不同的范围。诸如<a class="ae lm" href="https://stats.stackexchange.com/questions/305906/feature-scaling-in-svm-does-it-depend-on-the-kernel" rel="noopener ugc nofollow" target="_blank">支持向量机</a>和 K-最近邻之类的方法考虑了观测值之间的距离度量，这些方法受到特征范围的显著影响，并且缩放允许它们学习。虽然像<a class="ae lm" href="https://stats.stackexchange.com/questions/121886/when-should-i-apply-feature-scaling-for-my-data" rel="noopener ugc nofollow" target="_blank">线性回归和随机森林</a>这样的方法实际上并不需要特性缩放，但是当我们比较多个算法时，采取这一步骤仍然是最佳实践。</p><p id="db9b" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们将通过将每个特征放在 0 到 1 的范围内来缩放特征。这是通过取特性的每个值，减去特性的最小值，然后除以最大值减去最小值(范围)来完成的。这种特定版本的缩放通常被称为<a class="ae lm" href="https://machinelearningmastery.com/normalize-standardize-machine-learning-data-weka/" rel="noopener ugc nofollow" target="_blank">标准化，另一个主要版本被称为标准化</a>。</p><p id="0966" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">虽然这个过程很容易手工实现，但是我们可以使用 Scikit-Learn 中的<code class="fe ol om on ob b">MinMaxScaler</code>对象来实现。这种方法的代码与插补的代码相同，只是用了一个定标器而不是插补器！同样，我们确保仅使用训练数据进行训练，然后转换所有数据。</p><pre class="ms mt mu mv gt oa ob oc od aw oe bi"><span id="46df" class="no lv jb ob b gy of og l oh oi"># Create the scaler object with a range of 0-1<br/>scaler = MinMaxScaler(feature_range=(0, 1))</span><span id="ae9a" class="no lv jb ob b gy oj og l oh oi"># Fit on the training data<br/>scaler.fit(X)</span><span id="1928" class="no lv jb ob b gy oj og l oh oi"># Transform both the training and testing data<br/>X = scaler.transform(X)<br/>X_test = scaler.transform(X_test)</span></pre><p id="2ecc" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">现在，每个要素的最小值为 0，最大值为 1。缺失值插补和特征缩放是几乎任何机器学习管道中都需要的两个步骤，因此了解它们是如何工作的是一个好主意！</p><h2 id="dd2c" class="no lv jb bd lw np nq dn ma nr ns dp me kz nt nu mg ld nv nw mi lh nx ny mk nz bi translated">在 Scikit-Learn 中实现机器学习模型</h2><p id="bc73" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">在我们清理和格式化数据的所有工作之后，实际上用模型创建、训练和预测是相对简单的。我们将使用 Python 中的<a class="ae lm" href="http://scikit-learn.org/stable/documentation.html" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn 库</a>，它有很好的文档和一致的模型构建语法。一旦您知道如何在 Scikit-Learn 中制作一个模型，您就可以快速实现各种算法。</p><p id="421b" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们可以用梯度推进回归器来说明模型创建、训练(使用<code class="fe ol om on ob b">.fit</code>)和测试(使用<code class="fe ol om on ob b">.predict</code>)的一个例子:</p><figure class="ms mt mu mv gt is"><div class="bz fp l di"><div class="op oq l"/></div></figure><pre class="ms mt mu mv gt oa ob oc od aw oe bi"><span id="ad3b" class="no lv jb ob b gy of og l oh oi"><strong class="ob jc">Gradient Boosted Performance on the test set: MAE = 10.0132</strong></span></pre><p id="35a7" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">模型创建、训练和测试都是一行！为了构建其他模型，我们使用相同的语法，只是改变了算法的名称。结果如下所示:</p><figure class="ms mt mu mv gt is gh gi paragraph-image"><div class="gh gi or"><img src="../Images/794b2c0bf5b032cf67b219fde94dbb66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*qxn8YBJoPSopwmI1tjeZSw.png"/></div></figure><p id="4853" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">为了客观地看待这些数字，使用目标的中值计算的原始基线是 24.5。显然，机器学习适用于我们的问题，因为在基线上有显著的改进！</p><p id="8e34" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><a class="ae lm" href="https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/" rel="noopener ugc nofollow" target="_blank">梯度提升回归量</a> (MAE = 10.013)略胜随机森林(10.014 MAE)。这些结果并不完全公平，因为我们主要使用超参数的默认值。<a class="ae lm" href="http://pyml.sourceforge.net/doc/howto.pdf" rel="noopener ugc nofollow" target="_blank">特别是在支持向量机</a>等模型中，性能高度依赖于这些设置。尽管如此，我们将从这些结果中选择梯度推进回归变量进行模型优化。</p><h1 id="9696" class="lu lv jb bd lw lx os lz ma mb ot md me kh ou ki mg kk ov kl mi kn ow ko mk ml bi translated">用于模型优化的超参数调整</h1><p id="8024" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">在机器学习中，在我们选择了一个模型之后，我们可以通过调整模型超参数来优化它。</p><p id="969e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">首先，什么是<a class="ae lm" href="https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/" rel="noopener ugc nofollow" target="_blank">超参数，它们与参数</a>有何不同？</p><ul class=""><li id="7aa1" class="na nb jb ks b kt ku kw kx kz nc ld nd lh ne ll nf ng nh ni bi translated">模型<strong class="ks jc">超参数</strong>最好被认为是数据科学家在训练前设置的机器学习算法的设置。例如随机森林中的树木数量或 K-最近邻算法中使用的邻居数量。</li><li id="a4b0" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll nf ng nh ni bi translated">模型<strong class="ks jc">参数</strong>是模型在训练期间学习的内容，例如线性回归中的权重。</li></ul><p id="a566" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">控制超参数通过改变模型中<a class="ae lm" rel="noopener" target="_blank" href="/overfitting-vs-underfitting-a-conceptual-explanation-d94ee20ca7f9">欠拟合和过拟合</a>之间的平衡来影响模型性能。欠拟合是指我们的模型不够复杂(它没有足够的自由度)来学习从特征到目标的映射。一个欠拟合模型有<a class="ae lm" href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff" rel="noopener ugc nofollow" target="_blank">高偏差</a>，我们可以通过使我们的模型更复杂来纠正它。</p><p id="dd91" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">过度拟合是指我们的模型基本上记住了训练数据。过度拟合模型具有<a class="ae lm" href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff" rel="noopener ugc nofollow" target="_blank">高方差</a>，我们可以通过正则化来限制模型的复杂度，从而对其进行校正。欠拟合和过拟合模型都不能很好地概括测试数据。</p><p id="abb6" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">选择正确的超参数的问题是，对于每个机器学习问题，最佳集合都是不同的！因此，找到最佳设置的唯一方法是在每个新数据集上尝试多种设置。幸运的是，Scikit-Learn 有许多方法可以让我们有效地评估超参数。此外，像<a class="ae lm" href="https://epistasislab.github.io/tpot/" rel="noopener ugc nofollow" target="_blank"> TPOT 上位实验室</a>这样的项目正在尝试使用<a class="ae lm" href="https://en.wikipedia.org/wiki/Genetic_programming" rel="noopener ugc nofollow" target="_blank">遗传编程</a>这样的方法来优化超参数搜索。在这个项目中，我们将坚持用 Scikit-Learn 来做这件事，但是请继续关注 auto-ML 场景的更多工作！</p><h2 id="eba3" class="no lv jb bd lw np nq dn ma nr ns dp me kz nt nu mg ld nv nw mi lh nx ny mk nz bi translated">交叉验证随机搜索</h2><p id="2ead" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">我们将实施的特定超参数调整方法称为交叉验证随机搜索:</p><ul class=""><li id="355e" class="na nb jb ks b kt ku kw kx kz nc ld nd lh ne ll nf ng nh ni bi translated"><a class="ae lm" href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Random_search" rel="noopener ugc nofollow" target="_blank"> <strong class="ks jc">随机搜索</strong> </a>指的是我们将用来选择超参数的技术。我们定义一个网格，然后随机抽样不同的组合，而不是网格搜索，我们穷尽地尝试每一个组合。(令人惊讶的是，<a class="ae lm" href="http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf" rel="noopener ugc nofollow" target="_blank">随机搜索的表现几乎和网格搜索一样好</a>，运行时间大幅减少。)</li><li id="3957" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll nf ng nh ni bi translated"><a class="ae lm" href="https://www.openml.org/a/estimation-procedures/1" rel="noopener ugc nofollow" target="_blank"> <strong class="ks jc">交叉验证</strong> </a>是我们用来评估超参数选定组合的技术。我们使用 K-Fold 交叉验证，而不是将训练集分成单独的训练集和验证集，这减少了我们可以使用的训练数据量。这包括将训练数据分成 K 个折叠，然后经历一个迭代过程，其中我们首先在 K-1 个折叠上训练，然后在第 K 个折叠上评估性能。我们重复这个过程 K 次，在 K 重交叉验证结束时，我们取 K 次迭代中每一次的平均误差作为最终的性能测量。</li></ul><p id="e63e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">K = 5 的 K 倍交叉验证的思想如下所示:</p><figure class="ms mt mu mv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ox"><img src="../Images/717e2d1efd3f47a7cb449307b09eea1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rgba1BIOUys7wQcXcL4U5A.png"/></div></div><figcaption class="mw mx gj gh gi my mz bd b be z dk">K-Fold Cross Validation with K = 5 (<a class="ae lm" href="https://my.oschina.net/Bettyty/blog/751627" rel="noopener ugc nofollow" target="_blank">Source</a>)</figcaption></figure><p id="6c93" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">使用交叉验证执行随机搜索的整个过程是:</p><ol class=""><li id="08c7" class="na nb jb ks b kt ku kw kx kz nc ld nd lh ne ll oy ng nh ni bi translated">建立一个超参数网格来评估</li><li id="8563" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll oy ng nh ni bi translated">随机抽样超参数组合</li><li id="4989" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll oy ng nh ni bi translated">使用所选组合创建模型</li><li id="3775" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll oy ng nh ni bi translated">使用 K-fold 交叉验证评估模型</li><li id="be1e" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll oy ng nh ni bi translated">确定哪些超参数效果最好</li></ol><p id="4cb2" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">当然，我们实际上并不手动完成这项工作，而是让 Scikit-Learn 的<code class="fe ol om on ob b">RandomizedSearchCV</code>来处理所有的工作！</p><h2 id="2d5d" class="no lv jb bd lw np nq dn ma nr ns dp me kz nt nu mg ld nv nw mi lh nx ny mk nz bi translated">轻微分流:<a class="ae lm" href="https://en.wikipedia.org/wiki/Gradient_boosting" rel="noopener ugc nofollow" target="_blank">梯度升压法</a></h2><p id="a7ed" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">由于我们将使用梯度推进回归模型，我至少应该给一点背景知识！该模型是一种集成方法，这意味着它是由许多弱学习者构建而成的，在这种情况下是个体决策树。一种<a class="ae lm" href="https://machinelearningmastery.com/bagging-and-random-forest-ensemble-algorithms-for-machine-learning/" rel="noopener ugc nofollow" target="_blank"> bagging 算法，如随机森林</a>并行训练弱学习者，并让他们投票做出预测，而一种<a class="ae lm" href="https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/" rel="noopener ugc nofollow" target="_blank">增强方法</a>如梯度增强，依次训练学习者，每个学习者“专注于”前一个学习者所犯的错误。</p><p id="2793" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">助推方法近年来变得流行，并经常赢得机器学习比赛。<a class="ae lm" href="http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/" rel="noopener ugc nofollow" target="_blank">梯度提升方法</a>是一种特殊的实现方式，它使用梯度下降，通过在先前学习者的残差上顺序训练学习者来最小化成本函数。梯度增强的 Scikit-Learn 实现通常被认为不如其他库(如<a class="ae lm" href="http://xgboost.readthedocs.io/en/latest/model.html" rel="noopener ugc nofollow" target="_blank"> XGBoost </a>)有效，但它对于我们的小数据集来说足够好，并且相当准确。</p><h2 id="6768" class="no lv jb bd lw np nq dn ma nr ns dp me kz nt nu mg ld nv nw mi lh nx ny mk nz bi translated">返回超参数调谐</h2><p id="6a08" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">在梯度增强回归器中有许多超参数需要调整，您可以查看<a class="ae lm" href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor" rel="noopener ugc nofollow" target="_blank"> Scikit-Learn 文档</a>了解详情。我们将优化以下超参数:</p><ul class=""><li id="bbcd" class="na nb jb ks b kt ku kw kx kz nc ld nd lh ne ll nf ng nh ni bi translated"><code class="fe ol om on ob b">loss</code>:最小化损失函数</li><li id="5266" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll nf ng nh ni bi translated"><code class="fe ol om on ob b">n_estimators</code>:要使用的弱学习器(决策树)的数量</li><li id="836a" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll nf ng nh ni bi translated"><code class="fe ol om on ob b">max_depth</code>:每个决策树的最大深度</li><li id="2832" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll nf ng nh ni bi translated"><code class="fe ol om on ob b">min_samples_leaf</code>:决策树的一个叶节点所需的最小样本数</li><li id="3ca3" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll nf ng nh ni bi translated"><code class="fe ol om on ob b">min_samples_split</code>:拆分决策树节点所需的最小样本数</li><li id="88c1" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll nf ng nh ni bi translated"><code class="fe ol om on ob b">max_features</code>:用于分割节点的最大特征数</li></ul><p id="1c10" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我不确定是否有人真正理解所有这些是如何相互作用的，找到最佳组合的唯一方法是尝试它们！</p><p id="8d7e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在下面的代码中，我们构建了一个超参数网格，创建了一个<code class="fe ol om on ob b">RandomizedSearchCV</code>对象，并对 25 个不同的超参数组合使用 4 重交叉验证来执行超参数搜索:</p><figure class="ms mt mu mv gt is"><div class="bz fp l di"><div class="op oq l"/></div></figure><p id="7a61" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">执行搜索后，我们可以检查<code class="fe ol om on ob b">RandomizedSearchCV</code>对象以找到最佳模型:</p><pre class="ms mt mu mv gt oa ob oc od aw oe bi"><span id="7d11" class="no lv jb ob b gy of og l oh oi"># Find the best combination of settings<br/>random_cv.best_estimator_</span><span id="2284" class="no lv jb ob b gy oj og l oh oi"><strong class="ob jc">GradientBoostingRegressor(loss='lad', max_depth=5,<br/>                          max_features=None,<br/>                          min_samples_leaf=6,<br/>                          min_samples_split=6,<br/>                          n_estimators=500)</strong></span></pre><p id="d062" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">然后，我们可以使用这些结果，通过为网格选择接近这些最佳值的参数来执行网格搜索。然而，进一步的调整不太可能显著改进我们的模型。一般来说，适当的特征工程对模型性能的影响要比最广泛的超参数调整大得多。这是应用于机器学习的<a class="ae lm" href="http://www.picnet.com.au/blogs/guido/2018/04/13/diminishing-returns-machine-learning-projects/" rel="noopener ugc nofollow" target="_blank">收益递减定律</a>:特征工程让你走了大部分路，而超参数调整通常只提供很小的好处。</p><p id="c176" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们可以尝试的一个实验是改变估计器(决策树)的数量，同时保持其余的超参数不变。这直接让我们观察这个特定设置的效果。参见<a class="ae lm" href="https://github.com/WillKoehrsen/machine-learning-project-walkthrough/blob/master/Machine%20Learning%20Project%20Part%202.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本了解</a>的实现，但以下是结果:</p><figure class="ms mt mu mv gt is gh gi paragraph-image"><div class="gh gi oz"><img src="../Images/6557bab3a9f2e4683e9f7864536aacfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*uWmCwuPHyKhLhBBWXzGnJQ.png"/></div></figure><p id="2622" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">随着模型使用的树的数量增加，训练和测试误差都减小。然而，训练误差比测试误差下降得更快，我们可以看到我们的模型过度拟合:它在训练数据上表现非常好，但在测试集上不能达到同样的性能。</p><p id="32ad" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们总是预计测试集的性能至少会有所下降(毕竟，模型可以看到训练集的真实答案)，但是显著的差距<a class="ae lm" href="https://www.kdnuggets.com/2015/01/clever-methods-overfitting-avoid.html" rel="noopener ugc nofollow" target="_blank">表明过度拟合</a>。我们可以通过获取更多的训练数据来解决过度拟合问题，或者通过 hyerparameters 来降低我们模型的<a class="ae lm" href="https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/" rel="noopener ugc nofollow" target="_blank">复杂性。在这种情况下，我们将把超参数留在原处，但我鼓励任何人尝试减少过度拟合。</a></p><p id="0772" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">对于最终的模型，我们将使用 800 个估计量，因为这在交叉验证中产生了最低的误差。现在，是时候测试这个模型了！</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="6f5c" class="lu lv jb bd lw lx ly lz ma mb mc md me kh mf ki mg kk mh kl mi kn mj ko mk ml bi translated">对测试集进行评估</h1><p id="70ff" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">作为负责任的机器学习工程师，我们确保不让我们的模型在任何训练点看到测试集。因此，我们可以使用<a class="ae lm" href="https://www.coursera.org/learn/deep-neural-network/lecture/cxG1s/train-dev-test-sets" rel="noopener ugc nofollow" target="_blank">测试集性能作为我们的模型在现实世界中部署时的性能指标</a>。</p><p id="1fc7" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">对测试集进行预测并计算性能相对简单。这里，我们将默认梯度推进回归器的性能与调整后的模型进行比较:</p><pre class="ms mt mu mv gt oa ob oc od aw oe bi"><span id="8ca5" class="no lv jb ob b gy of og l oh oi"># Make predictions on the test set using default and final model<br/>default_pred = default_model.predict(X_test)<br/>final_pred = final_model.predict(X_test)</span><span id="4357" class="no lv jb ob b gy oj og l oh oi"><strong class="ob jc">Default model performance on the test set: MAE = 10.0118.<br/>Final model performance on the test set:   MAE = 9.0446.</strong></span></pre><p id="2245" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">超参数调整将模型的精度提高了约 10%。根据不同的用例，10%可能是一个巨大的改进，但这需要大量的时间投入！</p><p id="23ac" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我们还可以使用 Jupyter 笔记本中的<code class="fe ol om on ob b">%timeit</code> magic 命令来计时训练这两个模型需要多长时间。首先是默认模型:</p><pre class="ms mt mu mv gt oa ob oc od aw oe bi"><span id="fb6c" class="no lv jb ob b gy of og l oh oi">%%timeit -n 1 -r 5<br/>default_model.fit(X, y)</span><span id="4b33" class="no lv jb ob b gy oj og l oh oi"><strong class="ob jc">1.09 s ± 153 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)</strong></span></pre><p id="4e5a" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">1 秒训练似乎很合理。最终调优的模型没有这么快:</p><pre class="ms mt mu mv gt oa ob oc od aw oe bi"><span id="786e" class="no lv jb ob b gy of og l oh oi">%%timeit -n 1 -r 5<br/>final_model.fit(X, y)</span><span id="2627" class="no lv jb ob b gy oj og l oh oi"><strong class="ob jc">12.1 s ± 1.33 s per loop (mean ± std. dev. of 5 runs, 1 loop each)</strong></span></pre><p id="d870" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这展示了机器学习的一个基本方面:它总是一个权衡取舍的游戏。我们必须不断地平衡准确性和可解释性，<a class="ae lm" href="https://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">偏差和方差</a>，准确性和运行时间，等等。正确的混合最终取决于问题。在我们的例子中，相对而言，运行时间增加 12 倍是很大的，但从绝对意义上来说，并不显著。</p><p id="cad3" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">一旦我们有了最终的预测，我们就可以研究它们，看看它们是否表现出任何明显的偏差。左侧是预测值和实际值的密度图，右侧是残差直方图:</p><div class="ms mt mu mv gt ab cb"><figure class="pa is pb pc pd pe pf paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/32e9ad32c45a54850087b518fa1157f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1014/format:webp/1*Ey4RSqK3ohbgpAcFIGJshQ.png"/></div></figure><figure class="pa is pg pc pd pe pf paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><img src="../Images/5b02a6e7db067319f1f92ac20c16e2d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*HXhygqxKQej3W3x2Gr7aQw.png"/></div><figcaption class="mw mx gj gh gi my mz bd b be z dk ph di pi pj">Density Plot of Predicted and Actual Values (left) and Histogram of Residuals (right)</figcaption></figure></div><p id="685d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">模型预测似乎遵循实际值的分布，尽管密度峰值更接近于训练集的中值(66)，而不是真正的密度峰值(接近 100)。残差接近正态分布，尽管我们看到一些大的负值，其中模型预测远低于真实值。在下一篇文章中，我们将更深入地解读这个模型的结果。</p><h1 id="cbb8" class="lu lv jb bd lw lx os lz ma mb ot md me kh ou ki mg kk ov kl mi kn ow ko mk ml bi translated">结论</h1><p id="07ce" class="pw-post-body-paragraph kq kr jb ks b kt mm kc kv kw mn kf ky kz mo lb lc ld mp lf lg lh mq lj lk ll ij bi translated">在本文中，我们介绍了机器学习工作流程中的几个步骤:</p><ul class=""><li id="5b7c" class="na nb jb ks b kt ku kw kx kz nc ld nd lh ne ll nf ng nh ni bi translated">缺失值的插补和特征的缩放</li><li id="79fd" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll nf ng nh ni bi translated">几种机器学习模型的评估和比较</li><li id="eb07" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll nf ng nh ni bi translated">使用随机网格搜索和交叉验证的超参数调谐</li><li id="cc3a" class="na nb jb ks b kt nj kw nk kz nl ld nm lh nn ll nf ng nh ni bi translated">评估测试集上的最佳模型</li></ul><p id="8afd" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">这项工作的结果表明，机器学习适用于使用可用数据预测建筑物能源之星得分的任务。使用梯度增强回归器，我们能够预测测试集上的分数在真实值的 9.1 分之内。此外，我们看到超参数调优可以提高模型的性能，但在时间投入方面要付出很大的代价。这是我们在开发机器学习解决方案时必须考虑的众多权衡之一。</p><p id="ed7d" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">在第三篇文章中(<a class="ae lm" rel="noopener" target="_blank" href="/a-complete-machine-learning-walk-through-in-python-part-three-388834e8804b">此处</a>)，我们将深入观察我们创造的黑箱，并试图理解我们的模型是如何做出预测的。我们还将确定影响能源之星评分的最大因素。虽然我们知道我们的模型是准确的，但我们想知道<strong class="ks jc">为什么</strong>会做出这样的预测，这告诉了我们什么问题！</p><p id="b330" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">一如既往，我欢迎反馈和建设性的批评，可以通过 Twitter <a class="ae lm" href="https://twitter.com/koehrsen_will" rel="noopener ugc nofollow" target="_blank"> @koehrsen_will </a>联系。</p></div></div>    
</body>
</html>