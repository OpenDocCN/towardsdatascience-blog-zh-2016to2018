<html>
<head>
<title>Bayesian Neural Networks with Random Inputs for Model Based Reinforcement Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于模型强化学习的随机输入贝叶斯神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/bayesian-neural-networks-with-random-inputs-for-model-based-reinforcement-learning-36606a9399b4?source=collection_archive---------3-----------------------#2017-07-21">https://towardsdatascience.com/bayesian-neural-networks-with-random-inputs-for-model-based-reinforcement-learning-36606a9399b4?source=collection_archive---------3-----------------------#2017-07-21</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="dd42" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我在这里描述我们最近的ICLR论文[1][<a class="ae kl" href="https://github.com/siemens/policy_search_bb-alpha" rel="noopener ugc nofollow" target="_blank">code</a>][<a class="ae kl" href="https://www.youtube.com/watch?v=0H3EkUPENSY)" rel="noopener ugc nofollow" target="_blank">talk</a>]，它介绍了一种基于模型的强化学习的新方法。这项工作的主要作者是<strong class="jp ir"> Stefan Depeweg </strong>，他是我共同指导的慕尼黑工业大学的博士生。</p><p id="2700" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">关键贡献在于我们的模型:<strong class="jp ir">具有随机输入的贝叶斯神经网络</strong>，其输入层包含输入特征和随机变量，这些变量通过网络向前传播，并在输出层转换为任意噪声信号。</p><p id="a37b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">随机输入使我们的模型能够<strong class="jp ir">自动</strong>捕获<strong class="jp ir">复杂的噪声模式</strong>，提高我们基于模型的模拟的质量，并在实践中产生更好的策略。</p><h1 id="e1cd" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">问题描述</strong></h1><p id="8c18" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">我们处理随机动力系统中的策略搜索问题。例如，要操作燃气轮机等工业系统:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi lp"><img src="../Images/d2a2ac88f16a3216a68a51b82ac7bb6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*U7GN3vcDfOuVgLZtAlq8wg.png"/></div></figure><p id="0f97" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些系统的抽象如下所示。系统的当前状态表示为s_t，并且与每个状态s_t相关联的是由函数<em class="lx"> c </em>给出的成本<em class="lx"> c </em> (s_t)。在每个时间步，我们施加一个动作a_t，它将影响下一个时间步s_t+1的系统状态。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi ly"><img src="../Images/73b3c01e12c5c618533131debc512eff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/0*q0tODjpVTLSzreiS."/></div></figure><p id="8c5e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从s_t到s_t+1的转变不仅由动作a_t决定，还由一些我们无法控制的噪声信号决定。该噪声信号由图中的方块表示。在涡轮机的例子中，噪声的产生是因为我们观察到的状态仅由传感器测量值组成，这些测量值是对系统真实状态的不完整描述。</p><p id="6bac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了控制系统，我们可以使用一个策略函数a _ t = 𝜋(s_t；𝜃)将当前状态s_t映射到动作a_t，例如𝜋(；𝜃)可以是具有权重𝜃.的神经网络</p><p id="a336" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们的目标是找到一种策略(𝜃的一个值),它将在一系列状态轨迹上产生平均<strong class="jp ir">较低的成本函数值。例如，我们的目标是最小化</strong></p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/1e220f1761084985fb14ab32056b2f70.png" data-original-src="https://miro.medium.com/v2/resize:fit:404/format:webp/0*gxObBzlVunpFfIMg.png"/></div></figure><p id="472b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意，上面的表达式是随机的，因为它取决于初始状态S1的选择和状态转换中的随机噪声。</p><h1 id="0cf6" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">批量强化学习</strong></h1><p id="1764" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">我们考虑<strong class="jp ir">批量强化学习场景</strong>，在学习过程中我们不会与系统交互。这种情况在现实世界的工业设置中很常见，例如涡轮机控制，在这种情况下，探索受到限制，以避免对系统造成可能的损害。</p><p id="4fe5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，为了找到最佳策略，我们只有从已经运行的系统获得的状态转换形式的一批数据<em class="lx"> D </em> = {(s_t，a_t，s_t+1)}，并且我们将不能收集任何额外的数据。</p><p id="c62d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我们从<em class="lx"> D </em>得知p(s_t+1|s_t，a_t)的模型，即下一个状态s_t+1的预测分布，作为当前状态s_t和应用的动作a_t的函数。然后我们把这个模型和政策联系起来，得到p(s_t+1|s_t，a _ t = 𝜋(s_t；𝜃)，它描述了系统在𝜋(政策控制下的演变；𝜃).</p><p id="75fd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">先前的分布可用于执行<strong class="jp ir">展开</strong>或状态轨迹的模拟。我们从随机采样的状态s_1开始，然后从p(s_t+1|s_t，a _ t = 𝜋(s_t；𝜃))来获得状态S1，…，s_T的轨迹</p><p id="91b0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，可以在采样的s_1，…，s_T上评估成本函数，以逼近cost(𝜃).这种近似的梯度可用于执行随机优化，并在产生平均低值cost(𝜃).的方向上移动</p><h1 id="a8e7" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">最优控制中噪声的影响</strong></h1><p id="13df" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">状态转换中存在的噪声会显著影响最优策略。这可以通过<strong class="jp ir">醉酒蜘蛛</strong>的故事来说明，这个故事最初是由Bert Kappen [2]提出的，我们在这里用它作为一个激励的例子。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi ma"><img src="../Images/630d56bb808d225a31afa20b757e22c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*xwuUeYgaIZuJVQyYKR34Jg.png"/></div></figure><p id="f205" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一只蜘蛛有两条回家的路:要么过桥，要么绕湖行走。在没有噪声的情况下，桥接选项更受青睐，因为它更短。然而，在大量饮酒后，蜘蛛的动作可能会随机向左或向右偏离。因为桥很窄，而且蜘蛛不喜欢游泳，所以现在更喜欢沿着湖走。</p><p id="58ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">前面的例子显示了<strong class="jp ir">噪声如何显著影响最优控制</strong>。例如，最佳策略可以根据噪声水平是高还是低而改变。因此，我们希望通过以高精度捕获状态转换数据中存在的任何噪声模式，在基于模型的强化学习中获得显著的改进。</p><h1 id="78e4" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">具有随机输入的贝叶斯神经网络</strong></h1><p id="d143" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">在实践中，大多数状态转移数据的建模方法只是假设s_t+1中的<strong class="jp ir">加性高斯噪声</strong>，即，</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi mb"><img src="../Images/a77d0c9ce80b65d46c4cfeaf3bb840e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/0*w8b8h-T0jahs84qL.png"/></div></figure><p id="db9d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中<em class="lx"> f_W </em>例如是具有权重<em class="lx"> W </em>的神经网络。在这种情况下，通过最大可能性学习<em class="lx"> W </em>是非常容易的。然而，加性高斯噪声的假设在现实世界中不太可能成立。</p><p id="8b10" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过使用<em class="lx"> f_W </em>中的<strong class="jp ir">随机输入</strong>可以获得更灵活的过渡动态噪声模型。特别是，我们可以假设</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/41a9717e3f317ea775f7e53462958e5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/0*6cweHELT2GpWKIzw.png"/></div></figure><p id="05cd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在该模型下，输入噪声变量z_t可以通过<em class="lx"> f_W </em>以复杂的方式进行变换，以在s_t+1中产生作为s_t和a_t的函数的任意随机模式。</p><p id="852b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，现在学习<em class="lx"> W </em>不再能够通过最大似然法来完成，因为z_t是未知的。一个解决方案是遵循<strong class="jp ir">贝叶斯方法</strong>并在<em class="lx"> W </em>和z_t上使用后验分布。该分布捕捉了我们在看到<em class="lx"> D </em>中的数据后对这些变量可能取值的不确定性。</p><p id="32cb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">计算精确的后验概率是困难的，但是我们可以学习高斯近似法。这种近似的参数可以通过最小化相对于真实后验概率的偏差来调整。<strong class="jp ir">变分贝叶斯(VB) </strong>是一种流行的方法，它通过最小化Kullback-Leibler散度来工作。</p><h1 id="cda9" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak"> α发散最小化</strong></h1><p id="ac1a" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">不使用VB，我们通过<strong class="jp ir">最小化</strong><strong class="jp ir">α-散度</strong>【3，4】<strong class="jp ir">来学习分解的高斯近似<em class="lx"> q </em>。</strong>通过改变该散度中的α值，我们可以在符合真实后验概率p 中的一个模式或旨在覆盖<em class="lx"> p </em>中的多个模式的解之间进行平滑插值，如下图所示:</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi md"><img src="../Images/daa48ab73a7f95a05784e336ec447ac7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/0*_o4rUl-yxs8YTBpH."/></div></figure><p id="d918" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有趣的是，VB是α = 0时α散度最小化的一个特例。另一个众所周知的近似贝叶斯推断方法是期望传播，它是在α = 1时获得的。在我们的实验中，我们使用<strong class="jp ir"> α = 0.5 </strong>，因为这通常在实践中产生更好的概率预测[4]。</p><h1 id="25df" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">玩具示例的结果</strong></h1><p id="0a52" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">下图显示了我们的贝叶斯神经网络在两个玩具例子中随机输入的结果。每个示例的训练数据显示在最左边的列中。第一行显示了<strong class="jp ir">双模态</strong>预测分布的问题。底部一行显示了<strong class="jp ir">异方差</strong>噪声的问题(噪声幅度取决于输入)。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi me"><img src="../Images/1ae2a86d65b4a5fd83f617191aec207f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*H-qLdWDICOC_iljd."/></div></div></figure><p id="9634" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">中间一列显示了用仅假设加性高斯噪声的模型获得的预测。该模型不能捕捉数据中的双模态或异方差。最右边的列显示了我们的贝叶斯神经网络对随机输入的预测，它可以自动识别数据中存在的随机模式的类型。</p><h1 id="5f51" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">湿鸡问题的结果</strong></h1><p id="acd1" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">我们现在考虑一个强化学习基准，其中一名划独木舟的人正在二维河流上划桨，如下图中最左侧的图所示。河流中有一个<strong class="jp ir">漂流</strong>将独木舟者推向位于顶部的<strong class="jp ir">瀑布</strong>，漂流右侧较强，左侧较弱。如果划独木舟的人掉进了瀑布，他必须从河底重新开始。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi me"><img src="../Images/fd208b889753600f92343e66d5edf050.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7Kw4V6VCSCXNahp6."/></div></div></figure><p id="f654" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">河中还有<strong class="jp ir">湍流</strong>，左边变强，右边变弱。划独木舟的人离瀑布越近，得到的奖励就越高。因此，他会想靠近瀑布，但不要太近，这样他可能会掉下去。这个问题被称为<em class="lx"> wetchicken </em>是因为它和游戏<em class="lx">小鸡</em>有相似之处。</p><p id="7437" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">湍流和瀑布将使wetchicken成为一个高度随机的基准:从瀑布上落下的可能性导致了状态转换中的双模态，而变化的湍流引入了异方差。</p><p id="242c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">图中间的图可视化了使用我们的贝叶斯神经网络随机输入发现的策略。这是一个近乎最优的策略，在这个策略中，划独木舟的人试图停留在x ≃ 3.5度和y ≃ 2.5度的位置。</p><p id="87d4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">右图显示了使用高斯过程(GP)模型发现的策略，该模型仅假设了加性高斯噪声。由于GP不能捕获数据中存在的复杂噪声模式，因此所产生的策略在实践中表现很差。</p><h1 id="0183" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">工业基准的结果</strong></h1><p id="260d" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">我们还在实验中评估了我们的贝叶斯神经网络在随机输入下的性能，该实验使用了一个称为<em class="lx">“工业基准”</em>【5】的工业系统模拟器。根据作者的说法:“‘工业基准’旨在现实的意义上，它包括了我们发现在工业应用中至关重要的各种方面。”</p><p id="e5a3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下图显示了对于一个固定的动作序列，使用对应于1)假设加性高斯噪声(MLP)的多层感知器和2)变分贝叶斯(VB)或3)α= 0.5的α-散度最小化训练的贝叶斯神经网络的模型产生的展开。模拟轨迹以蓝色显示，由“工业基准”生成的地面真实轨迹以红色显示。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><div class="gh gi me"><img src="../Images/10c1fd8d59c88cd6ef565e2fc9083cf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LNHJBgD4rs6M_1BR."/></div></div></figure><p id="da10" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该图清楚地显示了使用我们的贝叶斯神经网络通过随机输入和α-散度最小化产生的展开如何更接近地面真实轨迹。</p><h1 id="867a" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">结论</strong></h1><p id="31c0" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">我们已经看到，在学习最优策略时，考虑过渡动态中复杂的噪声模式是很重要的。我们的带有随机输入的贝叶斯神经网络是捕捉这种复杂噪声模式的最先进的模型。通过用<strong class="jp ir"> </strong> α = 0.5最小化α-散度，我们能够在这样的贝叶斯神经网络中执行精确的近似推断。这使我们能够产生现实的基于模型的模拟，可以用来学习更好的政策。</p><h1 id="1c88" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">延伸阅读</strong></h1><p id="24ee" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">在[6]中，我们研究了具有随机输入的贝叶斯神经网络预测中不确定性的分解。不确定性来源于a)由于数据有限(认知不确定性)而缺乏关于网络权重的知识，或者b)网络的随机输入(随机不确定性)。在[6]中，我们展示了如何将这两种类型的不确定性应用于主动学习和安全强化学习。</p><p id="601e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们还推荐<a class="ae kl" href="http://alexgkendall.com/computer_vision/bayesian_deep_learning_for_safe_ai/" rel="noopener ugc nofollow" target="_blank">这篇</a> <strong class="jp ir"> </strong>由Alex Kendall撰写的关于计算机视觉深度神经网络中前述两种不确定性的优秀博文。</p><h1 id="2023" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">参考</h1><p id="e94b" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">[1]德佩韦格s .、埃尔南德斯-洛巴托J. M .、多希-维勒兹f .和乌德卢夫特S. <strong class="jp ir">贝叶斯神经网络在随机动力系统中的学习和政策搜索</strong>，ICLR，2017。</p><p id="345f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[2] H.J .卡彭特。<strong class="jp ir">最优控制理论的路径积分和对称破缺。</strong>统计力学杂志:理论与实验，P11011页，2005年。</p><p id="0f48" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[3]明卡，托马斯·p .<strong class="jp ir">发散度量和信息传递</strong>。技术报告，微软研究院，2005年。</p><p id="29f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[4]埃尔南德斯-洛巴托J. M .，李y .，罗兰m .，布伊T. D .，埃尔南德斯-洛巴托d .和特纳R. E. <strong class="jp ir">黑盒阿尔法散度最小化</strong>，ICML，2016</p><p id="6be9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[5]丹尼尔·海因、亚历山大·亨切尔、沃尔克马尔·斯特津、米歇尔·托基奇和斯特芬·乌德勒夫特。<strong class="jp ir">“工业基准”简介</strong>。arXiv预印本arXiv:1610.03793，2016年</p><p id="4e2c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">[6] Depeweg，Stefan等.<strong class="jp ir">具有潜在变量的贝叶斯神经网络中的不确定性分解</strong>。<em class="lx"> arXiv预印本arXiv:1706.08495 </em> (2017)。</p></div></div>    
</body>
</html>