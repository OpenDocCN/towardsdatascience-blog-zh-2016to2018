<html>
<head>
<title>Principal Component Analysis Network in Tensorflow with Interactive Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Tensorflow 中带交互代码的主成分分析网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/principal-component-analysis-network-in-tensorflow-with-interactive-code-7be543047704?source=collection_archive---------10-----------------------#2018-06-05">https://towardsdatascience.com/principal-component-analysis-network-in-tensorflow-with-interactive-code-7be543047704?source=collection_archive---------10-----------------------#2018-06-05</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/fc5644d85d01dc65f8f4ef9a01675cca.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*cqbry371_pbePdf195-sVA.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">GIF from this <a class="ae jy" href="https://giphy.com/gifs/loop-vaporwave-oSYflamt3IEjm" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="2c06" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">从<a class="ae jy" href="https://medium.com/@SeoJaeDuk/principal-component-analysis-pooling-in-tensorflow-with-interactive-code-pcap-43aa2cee9bb" rel="noopener">主成分分析池层</a>的自然延伸将是在该层之外制作一个完整的神经网络。我想知道这是否可能，以及它在<a class="ae jy" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST 数据上的表现是好是坏。</a></p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="3a4a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">主成分分析池层</strong></p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi le"><img src="../Images/75a060c084b01e185a0b74ea5ecfe2d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UUtG7ZwbvGbsCgS8fQ2A0Q.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image from this <a class="ae jy" href="https://medium.com/@SeoJaeDuk/principal-component-analysis-pooling-in-tensorflow-with-interactive-code-pcap-43aa2cee9bb" rel="noopener">website</a></figcaption></figure><p id="83af" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于不熟悉 PCAP 的人，请先阅读这篇<a class="ae jy" href="https://medium.com/@SeoJaeDuk/principal-component-analysis-pooling-in-tensorflow-with-interactive-code-pcap-43aa2cee9bb" rel="noopener">博客。</a>基本思想是合并层，如最大或平均合并操作执行维数减少，不仅节省计算能力，而且作为正则化。<a class="ae jy" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank"> PCA 是一种降维技术，将相关变量转换成一组线性不相关变量的值，称为主成分</a>。我们可以利用这个操作来做与最大/平均池类似的工作。</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="aa82" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">由大多数池层组成的网络</strong></p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi ln"><img src="../Images/673d159b90c486e21e45c64b7ecc58a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tAkznCs1PF_3AV2ZgtdIUQ.png"/></div></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Image from this <a class="ae jy" href="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/pooling_layer.html" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="0b65" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在我知道你在想什么了，在执行分类的时候有一个只由池层组成的网络是没有意义的。你是完全正确的！它没有！但我只是想试着玩玩。</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="6511" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">数据集/网络架构</strong></p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi lo"><img src="../Images/af301655ffdb640a84c7f64d03bbccbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*21quPCqYH0lkwRedrGVnPA.png"/></div></div></figure><p id="6780" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">蓝色矩形</strong> → PCAP 或最大池层<br/> <strong class="kb ir">绿色矩形</strong> →卷积层增加通道尺寸+ <a class="ae jy" rel="noopener" target="_blank" href="/iclr-2015-striving-for-simplicity-the-all-convolutional-net-with-interactive-code-manual-b4976e206760">全局平均池操作</a></p><p id="0db9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">网络本身非常简单，只有四个池层和一个卷积层来增加信道大小。然而，为了使尺寸匹配，我们将把每个图像下采样为 16*16 的尺寸。因此张量的形状是…</p><p id="8079" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">【批量，16，16，1】→【批量，8，8，1】→【批量，4，4，1】→<br/>【批量，2，2，1】→【批量，1，1，1】→【批量，1，1，10】→<br/>【批量，10】</p><p id="567f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">并且我们可以像任何其他网络一样使用软最大层来执行分类。</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="cf78" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果:主成分网络</strong></p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi lp"><img src="../Images/ed4261a27ee87643c01ea39632dd2a92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*861lL149Szg_8nX9N9ajew.png"/></div></div></figure><p id="072b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，训练准确率停滞在 18 %,这是可怕的 LOL。但我怀疑网络从一开始就没有足够的学习能力，这是它能做到的最好的。然而，我想看看每个 PCAP 层如何转换图像。</p><div class="lf lg lh li gt ab cb"><figure class="lq jr lr ls lt lu lv paragraph-image"><img src="../Images/426db6e3e300dd4b0f6b7c2f28c3a626.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*5Y8enZp-wXOdiQBQxMrauQ.png"/></figure><figure class="lq jr lw ls lt lu lv paragraph-image"><img src="../Images/ff6a7b37e1004d09e34bb706e9b73259.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*mqs_U5lA-Lxva88WCPmACQ.png"/></figure></div><div class="ab cb"><figure class="lq jr lx ls lt lu lv paragraph-image"><img src="../Images/b4e12a864fedb344d1d806b6f2b40dcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*NdTceK8ZzIJmC58OSpHdOQ.png"/></figure><figure class="lq jr ly ls lt lu lv paragraph-image"><img src="../Images/8c8a324c30fea68553e5125c859f6d78.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*2p75eMaryMtkmGhOXd71mg.png"/><figcaption class="ju jv gj gh gi jw jx bd b be z dk lz di ma mb">Generated Image when input is 7</figcaption></figure></div><div class="ab cb"><figure class="lq jr lr ls lt lu lv paragraph-image"><img src="../Images/34e553a7548fa0fb6466be9ef6e80129.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*Dl5e7JwDz2rq8OD8yYuMHg.png"/></figure><figure class="lq jr lw ls lt lu lv paragraph-image"><img src="../Images/ea42db374eff7a5f1d53b2d5ab473b61.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*c7aEXiNUGF8LOzFbqpSP3w.png"/></figure></div><div class="ab cb"><figure class="lq jr lx ls lt lu lv paragraph-image"><img src="../Images/94205db9dafa9a2288ab9db2764d833a.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*1dISzvxrPCSyh7CnNx-ROw.png"/></figure><figure class="lq jr ly ls lt lu lv paragraph-image"><img src="../Images/621b1cfe4f6bf028e759b7b235cf34e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*71U8bUKnSALdt9yisLAQew.png"/><figcaption class="ju jv gj gh gi jw jx bd b be z dk lz di ma mb">Generated Image when input is 2</figcaption></figure></div><div class="ab cb"><figure class="lq jr lr ls lt lu lv paragraph-image"><img src="../Images/3020b2a88c3c204b77ec44f484792171.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*Hne5mzVn_83QY4AiBqZeyg.png"/></figure><figure class="lq jr lw ls lt lu lv paragraph-image"><img src="../Images/66ef11230ba1361d6d0365427c3da28f.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*oSOpgPnSZIj9oXpadlNf5Q.png"/></figure></div><div class="ab cb"><figure class="lq jr lx ls lt lu lv paragraph-image"><img src="../Images/d49c98d5272d64cb363b513782f07e61.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*4cmTXLzdQnYK33dkEVo4yw.png"/></figure><figure class="lq jr ly ls lt lu lv paragraph-image"><img src="../Images/49fa5c19e7671d9060defe2f7acf2925.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*ZXk6xBQ5Amtcm-o0EUUHLg.png"/><figcaption class="ju jv gj gh gi jw jx bd b be z dk lz di ma mb">Generated Image when input is 1</figcaption></figure></div><p id="7da3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左上图</strong> →原始输入<br/> <strong class="kb ir">右上图</strong> →第一层后<br/> <strong class="kb ir">左下图</strong> →第二层后<br/> <strong class="kb ir">右下图</strong> →第四层后</p><p id="f24a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我们可以观察到的一个明显的模式是亮度的变化。例如，如果左上像素在第二层中是白色的，则该像素在下一层中将变为黑色。目前，我不能 100%确定为什么会发生这种情况，但随着更多的研究，我希望知道确切的原因。</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="081a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果:最大共享网络</strong></p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi mc"><img src="../Images/a185bfe33231ed08dd7829648b87214c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LPdUF5hvvLyu7BzZFTKRSA.png"/></div></div></figure><p id="738a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，当我们用 max pooling 操作替换所有 PCAP 层时，我们可以观察到训练图像的精度停滞在 14%左右，这证实了网络从一开始就没有足够的学习能力。</p><div class="lf lg lh li gt ab cb"><figure class="lq jr lr ls lt lu lv paragraph-image"><img src="../Images/426db6e3e300dd4b0f6b7c2f28c3a626.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*5Y8enZp-wXOdiQBQxMrauQ.png"/></figure><figure class="lq jr lw ls lt lu lv paragraph-image"><img src="../Images/e1d4ee6e49afe285bb6ed452a4075e84.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*MwnqovBrEKNib7x-tlh8gw.png"/></figure></div><div class="ab cb"><figure class="lq jr lx ls lt lu lv paragraph-image"><img src="../Images/ce53a41c2cb4739cf982fe108471ed3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*eAxnloRu5iOzwYwQdF0XVA.png"/></figure><figure class="lq jr ly ls lt lu lv paragraph-image"><img src="../Images/1b4c2aa730967453817090e37ab83cf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*rlj0W4WjgBv3UMzKS_wvyw.png"/><figcaption class="ju jv gj gh gi jw jx bd b be z dk lz di ma mb">Generated Image when input is 7</figcaption></figure></div><div class="ab cb"><figure class="lq jr lr ls lt lu lv paragraph-image"><img src="../Images/34e553a7548fa0fb6466be9ef6e80129.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*Dl5e7JwDz2rq8OD8yYuMHg.png"/></figure><figure class="lq jr lw ls lt lu lv paragraph-image"><img src="../Images/868465c847f4df776cb727fcc259c920.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*Y_iMdOBHRJMRu6kZeZvnXw.png"/></figure></div><div class="ab cb"><figure class="lq jr lx ls lt lu lv paragraph-image"><img src="../Images/720e8eb2d889852416b3654149e488c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*o40m3TrGVOl2Tf_DdGLSEw.png"/></figure><figure class="lq jr ly ls lt lu lv paragraph-image"><img src="../Images/5d98a84e06cb31f1a1a3de1302123a0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*1RbWklKZ3OQQhRmJyIn_uw.png"/><figcaption class="ju jv gj gh gi jw jx bd b be z dk lz di ma mb">Generated Image when input is 2</figcaption></figure></div><div class="ab cb"><figure class="lq jr lr ls lt lu lv paragraph-image"><img src="../Images/3020b2a88c3c204b77ec44f484792171.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*Hne5mzVn_83QY4AiBqZeyg.png"/></figure><figure class="lq jr lw ls lt lu lv paragraph-image"><img src="../Images/fffb0c0e6332a6ba96ff5ea5edd7e208.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*Uzwtut8BAkVwnYKu4uly7Q.png"/></figure></div><div class="ab cb"><figure class="lq jr lx ls lt lu lv paragraph-image"><img src="../Images/e042219830d71800024209ed6acc24e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*h8EHpSSOWSNGX9g1Kp5UlQ.png"/></figure><figure class="lq jr ly ls lt lu lv paragraph-image"><img src="../Images/e9539af7ab9c476d9cf4ae2d8dd433d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*wElqJdVzrK_zDkKB6XEK-A.png"/><figcaption class="ju jv gj gh gi jw jx bd b be z dk lz di ma mb">Generated Image when input is 1</figcaption></figure></div><p id="2ed3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左上图像</strong> →原始输入<br/> <strong class="kb ir">右上图像</strong> →第一层后<br/> <strong class="kb ir">左下图像</strong> →第二层后<br/> <strong class="kb ir">右下图像</strong> →第四层后</p><p id="51ed" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">与 PCAP 相反，使用最大池，我们可以清楚地观察到具有最高亮度的像素移动到下一层。这是意料之中的，因为这就是最大池的作用。</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="1159" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">交互代码</strong></p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="gh gi md"><img src="../Images/062b54db04d29398d5bc25f4d395b347.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JgDj7MEHELg_t8Pbt_99DA.png"/></div></div></figure><p id="459f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于 Google Colab，你需要一个 Google 帐户来查看代码，而且你不能在 Google Colab 中运行只读脚本，所以在你的操场上复制一份。最后，我永远不会请求允许访问你在 Google Drive 上的文件，仅供参考。编码快乐！</p><p id="4832" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">要使用<a class="ae jy" href="https://colab.research.google.com/drive/1dZHcbCGuOmBDr16N4lRWyxqTafHUenFQ" rel="noopener ugc nofollow" target="_blank"> PCAP 访问网络，请点击这里。</a> <br/>要使用<a class="ae jy" href="https://colab.research.google.com/drive/1Qrqp5NbZzhIZb0o0jbL9VFNE7dF6wuY5" rel="noopener ugc nofollow" target="_blank">最大池访问网络，请单击此处</a>。</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="251a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">最后的话</strong></p><p id="17f4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我从一开始就没有对这个网络抱太大希望，但我希望在训练/测试图像上至少有 30%的准确率。</p><p id="8874" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 给我，如果你希望看到我所有写作的列表，请在这里查看我的网站。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的 twitter 上关注我<a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>，访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或者我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。我还实现了<a class="ae jy" href="https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec" rel="noopener">广残网，请点击这里查看博文</a> t。</p></div><div class="ab cl kx ky hu kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="ij ik il im in"><p id="9b7d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="528f" class="mf mg iq kb b kc kd kg kh kk mh ko mi ks mj kw mk ml mm mn bi translated">50000 有 28 个因子。(2018).Factornumber.com。检索于 2018 年 6 月 3 日，来自<a class="ae jy" href="http://factornumber.com/?page=50000" rel="noopener ugc nofollow" target="_blank">http://factornumber.com/?page=50000</a></li><li id="665a" class="mf mg iq kb b kc mo kg mp kk mq ko mr ks ms kw mk ml mm mn bi translated">终端？，H. (2018)。如何在终端中重命名文件？。问 Ubuntu。检索于 2018 年 6 月 3 日，来自<a class="ae jy" href="https://askubuntu.com/questions/280768/how-to-rename-a-file-in-terminal" rel="noopener ugc nofollow" target="_blank">https://askubuntu . com/questions/280768/how-to-rename-a-file-in-terminal</a></li><li id="fcb4" class="mf mg iq kb b kc mo kg mp kk mq ko mr ks ms kw mk ml mm mn bi translated">中学 _y，H. (2018)。用 Seaborn + Pandas 带 secondary_y. Stack 溢出出图时如何去掉网格线？检索于 2018 年 6 月 3 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/26868304/how-to-get-rid-of-grid-lines-when-plotting-with-seaborn-pandas-with-secondary" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/26868304/how-to-ride-of-grid-lines-when-plotting-with-seaborn-pandas-with-secondary</a></li><li id="3bc2" class="mf mg iq kb b kc mo kg mp kk mq ko mr ks ms kw mk ml mm mn bi translated">[复本]，H. (2018)。如何在 Matplotlib (python)中隐藏轴和网格线？堆栈溢出。检索于 2018 年 6 月 3 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/45148704/how-to-hide-axes-and-gridlines-in-matplotlib-python" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/45148704/how-to-hide-axes-and-gridlines-in-matplotlib-python</a></li><li id="9943" class="mf mg iq kb b kc mo kg mp kk mq ko mr ks ms kw mk ml mm mn bi translated">MNIST 手写数字数据库，Yann LeCun，Corinna Cortes 和 Chris Burges。(2018).Yann.lecun.com。检索于 2018 年 6 月 3 日，来自<a class="ae jy" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank">http://yann.lecun.com/exdb/mnist/</a></li><li id="dc40" class="mf mg iq kb b kc mo kg mp kk mq ko mr ks ms kw mk ml mm mn bi translated">TensorFlow？，W. (2018)。TensorFlow 中最大汇集 2D 层的输出张量是什么？。堆栈溢出。检索于 2018 年 6 月 3 日，来自<a class="ae jy" href="https://stackoverflow.com/questions/43453712/what-is-output-tensor-of-max-pooling-2d-layer-in-tensorflow" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/43453712/what-is-output-tensor-of-max-pooling-2d-layer-in-tensor flow</a></li><li id="3d17" class="mf mg iq kb b kc mo kg mp kk mq ko mr ks ms kw mk ml mm mn bi translated">主成分分析。(2018).En.wikipedia.org。检索于 2018 年 6 月 3 日，来自<a class="ae jy" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Principal_component_analysis</a></li><li id="bbc9" class="mf mg iq kb b kc mo kg mp kk mq ko mr ks ms kw mk ml mm mn bi translated">桑托斯大学(2018)。混合层人工智能。Leonardo araujosantos . git books . io . 2018 年 6 月 3 日检索，来自<a class="ae jy" href="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/pooling_layer.html" rel="noopener ugc nofollow" target="_blank">https://Leonardo araujosantos . git books . io/artificial-intelligence/content/pooling _ layer . html</a></li><li id="9c8b" class="mf mg iq kb b kc mo kg mp kk mq ko mr ks ms kw mk ml mm mn bi translated">[ ICLR 2015 ]追求简单:具有交互码的全卷积网。(2018).走向数据科学。检索于 2018 年 6 月 3 日，来自<a class="ae jy" rel="noopener" target="_blank" href="/iclr-2015-striving-for-simplicity-the-all-convolutional-net-with-interactive-code-manual-b4976e206760">https://towards data science . com/iclr-2015-力争简单-所有卷积-网络-交互-代码-手册-b4976e206760 </a></li></ol></div></div>    
</body>
</html>