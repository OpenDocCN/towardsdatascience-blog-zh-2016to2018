<html>
<head>
<title>5 Frequently Asked Questions in Data Scientist Interviews</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学家访谈中的 5 个常见问题</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/5-frequently-asked-questions-in-data-scientist-interviews-6fb3eeeb497?source=collection_archive---------6-----------------------#2018-10-18">https://towardsdatascience.com/5-frequently-asked-questions-in-data-scientist-interviews-6fb3eeeb497?source=collection_archive---------6-----------------------#2018-10-18</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="2c44" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最近被一些刚毕业的学生问到如何准备数据科学家面试的问题。一般来说，数据科学家或机器学习工程师面试由 3 部分组成:<strong class="js iu">数学</strong>、<strong class="js iu">统计</strong>和<strong class="js iu">机器学习算法</strong>。本文最后会建议一些有用的备考资料。在这里，我们将讨论 5 个常见问题及其答案，让您了解如何回答数据科学家面试问题。</p><ul class=""><li id="c310" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn kt ku kv kw bi translated">什么是权重和偏差？</li><li id="571e" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">你用过 ReLU 功能吗？你能解释它是如何工作的吗？</li><li id="d82f" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">浮点数是如何存储在 32 位计算机内存中的？</li><li id="246e" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">什么是梯度下降和随机梯度下降？它们之间的区别是什么？</li><li id="0907" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">什么是反向传播？</li></ul><p id="c478" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">什么是权重和偏差？</strong></p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/b1e7496f7efdd7caf00d95a3d2825f41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kTlElTIDZTRLZo8v"/></div></div><figcaption class="lo lp gj gh gi lq lr bd b be z dk">weight and bias</figcaption></figure><p id="5ecc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">权重和偏差是模型的可学习参数。权值和偏差值在训练前随机初始化，训练时由 TensorFlow 自动计算。以下代码是更新权重和偏差的示例:</p><pre class="ld le lf lg gt ls lt lu lv aw lw bi"><span id="ffde" class="lx ly it lt b gy lz ma l mb mc"># How we train<br/>train_step = tf.train.<strong class="lt iu">GradientDescentOptimizer</strong>(0.02).minimize(<strong class="lt iu">cross_entropy</strong>)</span></pre><p id="6561" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">你用过 ReLU 功能吗？你能解释它是如何工作的吗？</strong></p><p id="deef" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">ReLU 代表整流线性单元，是一个简单的非线性激活函数。任何负输入被设置为零，而正输入保持不变。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi md"><img src="../Images/5a927665a27aeb72cd641d72fb48caaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/1*HIdq3BSO5N-MxK3C2xDJMw.png"/></div><figcaption class="lo lp gj gh gi lq lr bd b be z dk">ReLU formula</figcaption></figure><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi me"><img src="../Images/b2aeb724e7d1dd953ddbef56a62e9092.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*4t7ehnWYBqj9a3jSzQ7OTw.png"/></div></figure><p id="8cb3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">ReLU 广泛应用于神经网络和深度学习。它作为线性开关工作。如果你不需要它，你就“关掉”它；如果你需要它，你就“打开”它。TensorFlow 通过<a class="ae mf" href="https://www.tensorflow.org/api_guides/python/nn#Activation_Functions" rel="noopener ugc nofollow" target="_blank"> tf.nn </a>模块提供 ReLU 及其变体(<a class="ae mf" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" rel="noopener ugc nofollow" target="_blank">noise ReLU，Leaky ReLUs，ELUs </a>)。例如，下面用 tf.nn.relu 创建了一个卷积层(用于 CNN ):</p><pre class="ld le lf lg gt ls lt lu lv aw lw bi"><span id="7b57" class="lx ly it lt b gy lz ma l mb mc">import tensorflow as tf</span><span id="1554" class="lx ly it lt b gy mg ma l mb mc">conv_layer = tf.layers.conv2d(inputs=input_layer, filters=64,        kernel_size=[3, 3], padding='same', <strong class="lt iu">activation=tf.nn.relu</strong>)</span></pre><p id="b003" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">浮点数在 32 位计算机内存中是如何存储的？</strong></p><p id="02b2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">是的，这是一个“低级”问题，要求考生具备一些计算机硬件的背景知识。在 IEEE 754 标准中，浮点数的比特排列如下:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mh"><img src="../Images/4ab7667fc9534591bcb99003a06c7e77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*U_n4le3A-w0dAcbF"/></div></div><figcaption class="lo lp gj gh gi lq lr bd b be z dk">photo credit to <a class="ae mf" href="https://en.wikipedia.org/wiki/Single-precision_floating-point_format" rel="noopener ugc nofollow" target="_blank">wikipedia</a></figcaption></figure><ul class=""><li id="83d4" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn kt ku kv kw bi translated">符号(1 位):确定数字的符号</li><li id="3f6d" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">指数(8 位):IEEE 754 中的指数偏差是 127，我们需要从值中减去 127</li><li id="b497" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated">分数(23 位):有一个值为 1 的隐式前导位</li></ul><p id="08c3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因此，我们可以推导出真正的价值是</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/20b87fb2277ad5bb2c47025e06905a87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*1qyn-TaXm9jzFc0PEqHjUw.png"/></div></figure><p id="8813" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这里，我可以展示如何将基数为 10 的实数<strong class="js iu"> 12.875 </strong>转换成 IEEE 754 二进制 32 格式。</p><ul class=""><li id="4bea" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn kt ku kv kw bi">12 = 8 + 4 = 1100</li><li id="6df3" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi">.875 = 0.5 + 0.25 + 0.125 = 2^-1 + 2 ^ -2 + 2^-3</li></ul><p id="e212" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所以 12.875 的二进制表示应该如下:</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi mj"><img src="../Images/6a53e5462caefaba1dd76467d0dba1b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G5dA2-piH-DtiNBqCwQFUQ.png"/></div></div></figure><p id="0f2b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这种情况下，数字是正数，所以符号位是<code class="fe mk ml mm lt b">0</code>；指数是 3，加上 127(指数偏差)我们得到<code class="fe mk ml mm lt b">130 = 1000 0010</code>；分数是= <code class="fe mk ml mm lt b">10011100000000000000000.</code></p><p id="6219" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">由此我们可以形成实数 12.875 的 32 位 IEEE 754 二进制 32 格式表示，如下:<code class="fe mk ml mm lt b">0-10000010-10011100000000000000000.</code></p><p id="fd4e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">什么是梯度下降和随机梯度下降？它们之间的区别是什么？</strong></p><p id="be92" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">想象你正从山顶走下一座小山，你的下一步是什么？梯度下降(GD)和随机梯度下降(SGD)是从当前位置计算下一步的两种常用方法。</p><p id="e915" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">GD 和 SGD 是深度学习中的优化器，通过慢慢地将权重(模型的参数)推向更好的结果。在实践中，您可以使用 GD 和 SGD 来训练和比较全连接网络。SGD 优化模型将比 GD 更准确，并且所需的训练时间更少。</p><p id="8830" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在每一步，SGD 都采取非常小的一步而不是一大步，并使用微小的随机样本而不是完整的数据。SGD 是有效的，因为每次的数据集较小，并且通过多次执行来弥补。您可以使用 TensorFlow 函数<a class="ae mf" href="https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/keras/optimizers/SGD" rel="noopener ugc nofollow" target="_blank">TF . contrib . keras . optimizer . SGD</a>逐步训练更深入、更准确的模型。</p><p id="54b4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><strong class="js iu">什么是反向传播？</strong></p><p id="2604" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">基于梯度的优化器通常使用反向传播来调整<strong class="js iu">多层神经网络</strong>中神经元的权重。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/a36d1633b7e3717a8007b26ae506cab3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*arztzSOJ1lWN2Dr4yWeGuA.png"/></div><figcaption class="lo lp gj gh gi lq lr bd b be z dk">multi-layered neural network</figcaption></figure><p id="8e20" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">反向传播包括以下步骤:</p><ol class=""><li id="719e" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn mo ku kv kw bi translated">当输入向量呈现给网络时，它通过网络一层一层地向前传播，直到到达输出层。</li><li id="36d9" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn mo ku kv kw bi translated">损失函数计算网络输出与其预期输出之间的差异(称为“误差”)。</li><li id="d085" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn mo ku kv kw bi translated">为输出层中的每个神经元计算结果误差值。</li><li id="d40e" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn mo ku kv kw bi translated">然后，误差值从输出通过网络传播回来，直到每个神经元具有反映其对原始输出的贡献的相关误差值。</li><li id="6cf7" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn mo ku kv kw bi translated">反向传播使用这些误差值来计算损失函数的梯度。</li><li id="6e4d" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn mo ku kv kw bi translated">这个梯度被馈送到优化方法，该优化方法又使用它来更新权重，以试图最小化损失函数。</li></ol><p id="f0c1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">通常，输入向量的规范化可以提高模型的性能。</p><p id="03bb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">本文列出了 5 个常见问题及答案，供您参考。对于准备工作，我推荐古德费勒、本吉奥和库维尔的《深度学习》一书。</p><ul class=""><li id="f4d9" class="ko kp it js b jt ju jx jy kb kq kf kr kj ks kn kt ku kv kw bi translated">数学&amp;统计:第二、三、四章足以为这类面试中的理论问题做准备/修改</li><li id="69bc" class="ko kp it js b jt kx jx ky kb kz kf la kj lb kn kt ku kv kw bi translated"><strong class="js iu">机器学习算法</strong>:第 5 章，60 页左右，简明易懂</li></ul><p id="70a8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">如果你看完了深度学习圣经，我还会推荐<a class="ae mf" href="https://mml-book.github.io/" rel="noopener ugc nofollow" target="_blank">《机器学习的数学》</a><a class="ae mf" href="https://github.com/ShuaiW/data-science-question-answer#statistics-and-ml-in-general" rel="noopener ugc nofollow" target="_blank">《数据科学问答》</a>。</p><p id="9762" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">采访总是检查数据科学家难题中缺失部分的好方法。作为数据科学家，我们可以称之为评估或测量。期望是你表现好，而不是完美。尽你所能学习和准备。你所能做的就是尽你最大的努力。</p><p id="a502" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">你都准备好了。祝你好运！</p></div></div>    
</body>
</html>