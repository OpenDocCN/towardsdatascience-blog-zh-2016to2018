<html>
<head>
<title>[ Paper Summary ] TandemNet: Distilling Knowledge from Medical Images Using Diagnostic Reports as Optional Semantic References</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">[论文摘要] TandemNet:使用诊断报告作为可选语义参考从医学图像中提取知识</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/paper-summary-tandemnet-distilling-knowledge-from-medical-images-using-diagnostic-reports-as-4643911a2aa0?source=collection_archive---------14-----------------------#2018-06-24">https://towardsdatascience.com/paper-summary-tandemnet-distilling-knowledge-from-medical-images-using-diagnostic-reports-as-4643911a2aa0?source=collection_archive---------14-----------------------#2018-06-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/450a10aadf21ce59ae511f74a1d8e668.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*rH-y9yzKUny5VQ9zbIjrPA.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">GIF from this <a class="ae jy" href="https://giphy.com/gifs/season-16-the-simpsons-16x11-xT5LMGfQrJPpmXKUEM" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="76b9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我不知道我从哪里得到这篇论文，但我想读它。</p><blockquote class="kx ky kz"><p id="7c1b" class="jz ka la kb b kc kd ke kf kg kh ki kj lb kl km kn lc kp kq kr ld kt ku kv kw ij bi translated"><strong class="kb ir">请注意，这篇帖子是给未来的自己看的，回顾这篇论文上的材料，而不是从头再看一遍。</strong></p></blockquote></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><figure class="ll lm ln lo gt jr"><div class="bz fp l di"><div class="lp lq l"/></div></figure></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="84a0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">摘要</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lr"><img src="../Images/4e1fd103a8073d938c50d186f018d06f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TlW6DH_jbR66pg9g62ByDw.png"/></div></div></figure><p id="32d1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这篇论文太酷了，所以作者决定将诊断报告作为网络的输入，而不是仅仅依赖图像的特征。此外，作者还引入了一个双重注意力模型，最后，他们能够创建一个模型，其中有效地整合了来自多模态的知识，并产生了高性能。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="5069" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">简介</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lw"><img src="../Images/40828abe9bdf2b5e2b95f7c3701e9faf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZGd83RUUbxXUGl4lrARIsg.png"/></div></div></figure><p id="6a5c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">当我们想到一个人如何成为一名成功的医生时，不仅他们从 CT 或 MRI 扫描中学习，而且其他资深医生也解释了每个图像中发生的事情。受这种想法的启发，作者决定用不同形式的输入制作一个分类模型。网络架构如下所示。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lx"><img src="../Images/750332721446577578a3c4f3678c76e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bxt8n6c9iTPg3JOV23wGLQ.png"/></div></div></figure><p id="1fe2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这个网络要么只接受图像作为输入，要么接受一对图像和文本。它还可以生成医疗报告。然而，我有一个问题，如果医疗记录已经告诉网络诊断是什么，想要有一个 CNN 的点？</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="61be" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">方法</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ly"><img src="../Images/51409b99f40087a9935716c0afdfcf99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*65964KWr5vArL78G2yhCLg.png"/></div></div></figure><p id="14f4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在本节中，作者首先描述了网络架构。对于 CNN，他们决定用 Res Wide architecture，对于语言模型，他们决定用 LSTM。此外，他们制作了一个新颖的双注意模型，其中他们不仅接收图像数据(用 V 表示)，还接收文本数据(用 S 表示)</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/1c69836e44ef12abe421f3770496f05e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*aIRr7H5h3ikBJKP8sENQVg.png"/></div></figure><p id="c1f4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">此外，作者还介绍了两种推广网络的方法。<br/> <strong class="kb ir"> 1)视觉跳过连接</strong> →其中图像特征像 res net 架构一样跳过连接以增加梯度流<br/> <strong class="kb ir"> 2)随机模态自适应</strong> →其中文本数据被丢弃，使得网络不必依赖于文本数据。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="b115" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">实验</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi ma"><img src="../Images/0c45bdecfbb5fb42ae2ff33cde9211d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vfxiRK5gSRuSARrYnJGb_w.png"/></div></div></figure><p id="f27e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在这里，作者描述了他们如何获得数据，他们总共能够获得 1000，500*500*3 张图像，病理学家为每张图像提供了一段关于核多形性、细胞拥挤、细胞极性、有丝分裂和核仁突出的内容。接下来，他们描述了如何使用<a class="ae jy" href="https://github.com/torch/torch7" rel="noopener ugc nofollow" target="_blank"> Torch7 </a>来实现串联网络。(使用 SGD)。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mb"><img src="../Images/4d1ee432e092af791555eb44686f6671.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Lzb6pk3o0YFjVm0_GJ_tA.png"/></div></div></figure><p id="eaf3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，我们可以观察到串联网络比其他比较网络具有更高的准确性。(以相当大的幅度。)</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/2827e7b588287f2d8d1587ed311cd732.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*QXN698hKFoSbDytnWGhs1A.png"/></div></figure><p id="6eee" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">上面没有提到的事实是，他们有一个 LSTM 的辍学层，他们发现了一个与辍学率和使用文本数据相反的模式。随着辍学率的增加，模型使用的文本数据越来越少，反之亦然。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi md"><img src="../Images/3ad5bc446718d9c67e278dec81c1b4d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xt2tLGk433DgVWiiefcpcQ.png"/></div></div></figure><p id="b2b5" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">此外，当他们可视化每个数据点的隐藏表示时，他们发现使用文本数据可以更好地分布聚类。(t-SNE)</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi me"><img src="../Images/92486da04588a84eeaee4719f11057fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TX4Q8teBXhOyksDOtsrDHQ.png"/></div></div></figure><p id="ee70" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">他们将视觉注意力掩模放大到与原始图像相同的尺寸，并将其重叠。之后，他们与病理学家认为最重要的位置进行了比较，并能够发现两个区域之间的高度相关性。当模型同时使用文本和图像时，相关性增加。</p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi mf"><img src="../Images/b1d1bbc8859cd7b4522855686bbb9e80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i6NHAtfMbSvPmZdG2b6gpw.png"/></div></div></figure><p id="7076" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最后，使用来自“用于生成图像描述的深度视觉语义排列”的知识，他们也能够生成医疗报告，并且看起来做得很好。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="0ec1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结论</strong></p><figure class="ll lm ln lo gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lw"><img src="../Images/159ba2bad3b71dd5182308f7b38d736d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XLbQxm-rMDQ36WhoMyF90g.png"/></div></div></figure><p id="d10f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">总之，本文作者介绍了一种新颖的网络，称为 TandemNet，它以文本和图像作为输入来执行分类，并获得了较好的结果。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="85b2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">遗言</strong></p><p id="5012" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">我在医疗领域看到的最有趣的网络架构之一。</p><p id="2397" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 给我，如果你想看我所有写作的列表，请<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">在这里查看我的网站</a>。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的 twitter <a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，并访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。我也实现了<a class="ae jy" href="https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec" rel="noopener">广残网，请点击这里查看博文 pos </a> t。</p></div><div class="ab cl le lf hu lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ij ik il im in"><p id="5e8c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="55f9" class="mg mh iq kb b kc kd kg kh kk mi ko mj ks mk kw ml mm mn mo bi translated">张，张，杨(2017)。TandemNet:使用诊断报告作为可选的语义参考从医学图像中提取知识。Arxiv.org。检索于 2018 年 6 月 24 日，来自<a class="ae jy" href="https://arxiv.org/abs/1708.03070" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1708.03070</a></li><li id="29ea" class="mg mh iq kb b kc mp kg mq kk mr ko ms ks mt kw ml mm mn mo bi translated">火炬/火炬 7。(2018).GitHub。检索于 2018 年 6 月 24 日，来自<a class="ae jy" href="https://github.com/torch/torch7" rel="noopener ugc nofollow" target="_blank">https://github.com/torch/torch7</a></li><li id="0616" class="mg mh iq kb b kc mp kg mq kk mr ko ms ks mt kw ml mm mn mo bi translated">(2018).Cs.stanford.edu。检索于 2018 年 6 月 24 日，来自<a class="ae jy" href="https://cs.stanford.edu/people/karpathy/cvpr2015.pdf" rel="noopener ugc nofollow" target="_blank">https://cs.stanford.edu/people/karpathy/cvpr2015.pdf</a></li></ol></div></div>    
</body>
</html>