<html>
<head>
<title>How to customize distributed training when using the TensorFlow Estimator API</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用TensorFlow Estimator API时如何定制分布式培训</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-configure-the-train-and-evaluate-loop-of-the-tensorflow-estimator-api-45c470f6f8d?source=collection_archive---------6-----------------------#2018-04-09">https://towardsdatascience.com/how-to-configure-the-train-and-evaluate-loop-of-the-tensorflow-estimator-api-45c470f6f8d?source=collection_archive---------6-----------------------#2018-04-09</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="a08e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">TensorFlow的Estimator API提供了一个简单的高级API来训练机器学习模型。您可以在估计器上使用train()、evaluate()或predict()方法。然而，大多数情况下，培训是在一个循环中以分布式的方式进行的，在培训过程中定期进行评估。为此，您将使用train_and_evaluate循环:</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="135e" class="ku kv iq kq b gy kw kx l ky kz">tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)</span></pre><p id="8931" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本文中，我将讨论您可能希望在train_spec和eval_spec中指定哪些内容。总之，这些选项允许train_and_evaluate提供一种强大的、可定制的方法来进行分布式培训。</p><p id="34e5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里有一个完整的train_and_evaluate(完整代码在<a class="ae la" href="https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive/06_structured/babyweight/trainer/model.py#L152" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上)。我将挑选出不同的部分来讨论:</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="18f3" class="ku kv iq kq b gy kw kx l ky kz">def train_and_evaluate(output_dir):<br/>    EVAL_INTERVAL = 300 # seconds</span><span id="0e6c" class="ku kv iq kq b gy lb kx l ky kz">    run_config = tf.estimator.RunConfig(save_checkpoints_secs = EVAL_INTERVAL,<br/>                                        keep_checkpoint_max = 3)<br/>    estimator = tf.estimator.DNNLinearCombinedRegressor(<br/>        model_dir = output_dir,<br/>        ...<br/>        config = run_config)<br/>    <br/>    estimator = tf.contrib.estimator.add_metrics(estimator, my_rmse)</span><span id="1051" class="ku kv iq kq b gy lb kx l ky kz">    train_spec = tf.estimator.TrainSpec(<br/>        input_fn = read_dataset('train', tf.estimator.ModeKeys.TRAIN, BATCH_SIZE),<br/>        max_steps = TRAIN_STEPS)</span><span id="6637" class="ku kv iq kq b gy lb kx l ky kz">    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn, exports_to_keep=None)</span><span id="6a3f" class="ku kv iq kq b gy lb kx l ky kz">    eval_spec = tf.estimator.EvalSpec(<br/>        input_fn = read_dataset('eval', tf.estimator.ModeKeys.EVAL, 2**15),  # no need to batch in eval<br/>        steps = None,<br/>        start_delay_secs = 60, # start evaluating after N seconds<br/>        throttle_secs = EVAL_INTERVAL,  # evaluate every N seconds<br/>        exporters = exporter)</span><span id="1137" class="ku kv iq kq b gy lb kx l ky kz">    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)</span></pre><figure class="kl km kn ko gt ld gh gi paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="gh gi lc"><img src="../Images/465b0563cf996f6944b237d3d4a9f0a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_eTXUJCbqbWLKfC8nkmZtg.jpeg"/></div></div><figcaption class="lk ll gj gh gi lm ln bd b be z dk">train_and_evaluate() is highly customizable</figcaption></figure><h2 id="53fe" class="ku kv iq bd lo lp lq dn lr ls lt dp lu jy lv lw lx kc ly lz ma kg mb mc md me bi translated">运行配置</h2><p id="463b" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated"><a class="ae la" href="https://www.tensorflow.org/api_docs/python/tf/estimator/RunConfig" rel="noopener ugc nofollow" target="_blank"> RunConfig </a>允许您控制检查点被写出的频率。检查点是Estimator支持容错的方式。如果训练群集的主要(或主节点)失败，训练将从检查点恢复。检查次数越多，机器故障造成的损失就越少。当然，检查点本身会消耗CPU和存储，所以这是一个权衡。在我的示例中，我要求每300秒执行一次检查点操作(以限制CPU开销)，并且只保存最后3个检查点(以限制存储开销):</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="c344" class="ku kv iq kq b gy kw kx l ky kz">run_config = tf.estimator.RunConfig(save_checkpoints_secs = 300, <br/>                                    keep_checkpoint_max = 3)</span></pre><p id="403d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您还可以根据训练步骤的数量来指定检查点间隔——最初，这看起来更简单，也更有吸引力。然而，如果您认识到检查点是关于故障恢复的，您将很快认识到按时间指定这是一个更好的选择。Estimator足够聪明，不会编写检查点，除非训练工作实际上已经取得了进展。</p><p id="7f4b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，run_config是作为参数传递给估计器的:</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="326e" class="ku kv iq kq b gy kw kx l ky kz">estimator = tf.estimator.DNNLinearCombinedRegressor(<br/>        model_dir = output_dir,<br/>        ...<br/>        config = run_config)</span></pre><h2 id="de92" class="ku kv iq bd lo lp lq dn lr ls lt dp lu jy lv lw lx kc ly lz ma kg mb mc md me bi translated">评估指标</h2><p id="e752" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">默认情况下，预构建的估计器(如LinearRegressor和DNNClassifier)会预先指定它们将评估的指标。例如，对于LinearRegressor，这是average_loss，即均方误差。一个常见的需求是评估其他指标。您可以通过<a class="ae la" href="https://www.tensorflow.org/api_docs/python/tf/contrib/estimator/add_metrics" rel="noopener ugc nofollow" target="_blank"> add_metrics </a>来实现:</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="52da" class="ku kv iq kq b gy kw kx l ky kz">estimator = tf.contrib.estimator.add_metrics(estimator, my_rmse)</span></pre><p id="a26f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一种常见的模式——扩展Estimator的方法是对其进行包装并添加额外的功能。在这种情况下，有一个贡献函数能够添加指标。my_rmse是一个函数，它返回此类指标的字典:</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="6eca" class="ku kv iq kq b gy kw kx l ky kz">def my_rmse(labels, predictions):<br/>    pred_values = predictions['predictions']<br/>    return {<br/>      'rmse': tf.metrics.root_mean_squared_error(labels, pred_values)<br/>    }</span></pre><h2 id="1ed1" class="ku kv iq bd lo lp lq dn lr ls lt dp lu jy lv lw lx kc ly lz ma kg mb mc md me bi translated">训练批量</h2><p id="4694" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">梯度是一次对一批训练样本进行计算的。该批次的大小由训练输入函数控制:</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="179a" class="ku kv iq kq b gy kw kx l ky kz">train_spec = tf.estimator.TrainSpec(<br/>  input_fn = read_dataset('train', ModeKeys.TRAIN, 40),<br/>  max_steps = TRAIN_STEPS)</span></pre><p id="d922" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您的输入函数可能使用TensorFlow数据集API，其中批处理只是对数据集的一个调用:</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="eba3" class="ku kv iq kq b gy kw kx l ky kz">dataset = dataset.repeat(num_epochs).batch(batch_size)</span></pre><p id="15bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是，请注意，num_epochs在分布式训练中的表现不同。训练时间由训练步数控制，而不是由重复输入数据控制。因此，将模式传递给输入函数是很重要的，因为您可能希望随机排列训练示例并无限期地读取训练数据:</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="f0ba" class="ku kv iq kq b gy kw kx l ky kz">if mode == tf.estimator.ModeKeys.TRAIN:<br/>   num_epochs = None # indefinitely<br/>   dataset = dataset.shuffle(buffer_size = NWORKERS * batch_size)</span></pre><p id="640f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为什么洗牌？这是因为，在分布式训练中，每个工人在一批上计算梯度，然后梯度更新在所有工人中平均。显然，如果你的所有员工都在处理相同的数据，那就没有意义了。因此，您要求数据集打乱数据，以便每个工人看到不同的批次。</p><p id="aded" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在评估期间，num_epochs将为1，但是您可以通过适当地设置评估步骤的数量来评估数据集的一部分(这将在下面介绍)。</p><h2 id="e03a" class="ku kv iq bd lo lp lq dn lr ls lt dp lu jy lv lw lx kc ly lz ma kg mb mc md me bi translated">火车步骤</h2><p id="6772" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">TrainSpec的第二个参数表示要训练多少步:</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="855a" class="ku kv iq kq b gy kw kx l ky kz">train_spec = tf.estimator.TrainSpec(<br/>  input_fn = read_dataset('train', ModeKeys.TRAIN, BATCH_SIZE),<br/>  max_steps = TRAIN_STEPS)</span></pre><p id="72ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">记住，训练步骤包括对一批训练样本进行梯度计算。<a class="ae la" href="https://www.tensorflow.org/api_docs/python/tf/estimator/TrainSpec" rel="noopener ugc nofollow" target="_blank"> TrainSpec </a>需要训练模型的最大步数。注意，这是max_steps，而不是steps。如果您有一个对应于步骤#1800的检查点，并且您指定max_steps=2000，那么训练将在1800恢复，并且只进行200步！恢复训练的能力是一个重要的属性，但是请确保您完全理解这意味着什么:要从头开始训练，您需要清除输出目录，以便没有预先存在的检查点。</p><p id="c1c0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">还要注意，这是控制你训练时间的因素——它实际上覆盖了输入函数中的num_epochs。</p><h2 id="9118" class="ku kv iq bd lo lp lq dn lr ls lt dp lu jy lv lw lx kc ly lz ma kg mb mc md me bi translated">出口商</h2><p id="d805" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">检查点不同于导出。检查点是关于故障恢复的，并且包括保存完整的训练状态(权重、全局步数等。).导出是关于创建服务签名。最常见的情况是，您将导出神经网络的预测头或输出节点，但有时，您也会想要导出嵌入节点。</p><p id="781b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我的例子中，我在培训结束时导出:</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="8952" class="ku kv iq kq b gy kw kx l ky kz">exporter = tf.estimator.LatestExporter('exporter', serving_input_fn, exports_to_keep=None)</span></pre><p id="e2ce" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">导出的模型将被写入名为“exporter”的目录，并且服务输入函数指定最终用户将被期望向预测服务提供什么。如果要保留与最后5个检查点对应的导出，可以指定exports_to_keep=5。</p><h2 id="2b9c" class="ku kv iq bd lo lp lq dn lr ls lt dp lu jy lv lw lx kc ly lz ma kg mb mc md me bi translated">评估批量</h2><p id="8fb7" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">训练批次大小大约是计算梯度的样本数。然而，在评估期间，没有计算梯度。在评估期间，成批读取数据以避免过度分配内存缓冲区的唯一原因。因此，请指定一个更大的批量:</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="d5fa" class="ku kv iq kq b gy kw kx l ky kz">input_fn = read_dataset('eval', tf.estimator.ModeKeys.EVAL, 2**15)</span></pre><p id="0ed9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">训练批次大小约为100，而评估批次大小可以设置为一个批次的总内存使用量约为32MB，显然，确切的数量取决于训练数据在内存中占用的空间。</p><h2 id="cb2e" class="ku kv iq bd lo lp lq dn lr ls lt dp lu jy lv lw lx kc ly lz ma kg mb mc md me bi translated">评估步骤</h2><p id="f7d9" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">评估时，可以通过在EvalSpec中指定steps=None对整个数据集进行评估:</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="7131" class="ku kv iq kq b gy kw kx l ky kz">eval_spec = tf.estimator.EvalSpec(<br/>        input_fn = ...,<br/>        steps = None</span></pre><p id="ee2a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是，如果数据集很大，这可能会带来相当大的开销。在培训期间进行评估的唯一原因是为了监控，并且您希望监控在某种程度上是轻量级的。因此，一个好的折衷办法是指定足够大的步骤数，使评估在统计上是稳健的。这取决于您的数据，但100往往是一个常见的选择:</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="0627" class="ku kv iq kq b gy kw kx l ky kz">eval_spec = tf.estimator.EvalSpec(<br/>        input_fn = ...,<br/>        steps = 100</span></pre><p id="55af" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为我们的batch_size是2 * 15(或32k)，所以100个步骤对应于大约320万个示例，我们的想法是对这个大数字进行评估已经足够稳定了。</p><h2 id="5f55" class="ku kv iq bd lo lp lq dn lr ls lt dp lu jy lv lw lx kc ly lz ma kg mb mc md me bi translated">评估油门</h2><p id="b33e" class="pw-post-body-paragraph jn jo iq jp b jq mf js jt ju mg jw jx jy mh ka kb kc mi ke kf kg mj ki kj kk ij bi translated">默认情况下，Estimator将在每次检查点时进行评估。您可以在评估上指定一个限制，以便更频繁地进行检查点操作(用于故障恢复)，但减少评估次数(用于监控)。这样做的原因是检查点相对较快，但评估可能较慢，尤其是在评估整个数据集时:</p><pre class="kl km kn ko gt kp kq kr ks aw kt bi"><span id="1e61" class="ku kv iq kq b gy kw kx l ky kz">eval_spec = tf.estimator.EvalSpec(<br/>        input_fn = ...,<br/>        steps = EVAL_STEPS,<br/>        start_delay_secs = 60, # start evaluating after N seconds<br/>        throttle_secs = 600,  # evaluate every N seconds<br/>        exporters = exporter)</span></pre><p id="5a1b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如您所见，train_and_evaluate提供了一种强大的、可定制的方法来进行分布式培训。</p></div></div>    
</body>
</html>