<html>
<head>
<title>[Learning Note] Single Shot MultiBox Detector with Pytorch — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">[学习笔记]带 Pytorch 的单次多盒检测器—第 1 部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/learning-note-single-shot-multibox-detector-with-pytorch-part-1-38185e84bd79?source=collection_archive---------1-----------------------#2017-07-24">https://towardsdatascience.com/learning-note-single-shot-multibox-detector-with-pytorch-part-1-38185e84bd79?source=collection_archive---------1-----------------------#2017-07-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="f1ef" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最近我在尝试学习<a class="ae kl" href="http://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> Pytorch </a>以及一些物体检测深度学习算法。因此，为了一举两得，我决定阅读由 Max deGroot 撰写的<a class="ae kl" href="https://arxiv.org/abs/1512.02325" rel="noopener ugc nofollow" target="_blank">单次多盒检测器论文</a>以及其中一篇<a class="ae kl" href="https://github.com/amdegroot/ssd.pytorch" rel="noopener ugc nofollow" target="_blank"> Pytorch 实现。</a></p><p id="5713" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">诚然，我在理解论文中的一些观点时有些困难。看了实现，挠了一会儿头，我想我至少弄明白了其中的一部分。所以下面是我在第一遍和第二遍阅读后对一些混淆概念的笔记。</p><h2 id="745e" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">网络结构</h2><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi lf"><img src="../Images/1e1cc79dac2c3310c9f4abf7c3e4c73e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pPxrkm4Urz04Ez65mwWE9Q.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">SSD Architecture taken from the original paper</figcaption></figure><p id="0a6d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，单次多盒检测器(SSD)使用在 ILSVRC CLS-LOC 数据集上预训练的 VGG-16 结构，并增加一些额外的卷积层。相关代码位于<a class="ae kl" href="https://github.com/amdegroot/ssd.pytorch/blob/master/ssd.py" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir"> ssd.py </strong> </a>:</p><pre class="lg lh li lj gt lv lw lx ly aw lz bi"><span id="cbdb" class="km kn iq lw b gy ma mb l mc md">base = {<br/>    '300': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, <br/>            'C', 512, 512, 512, 'M', 512, 512, 512],<br/>    '512': [],<br/>}<br/>extras = {<br/>    '300': [256, 'S', 512, 128, 'S', 256, 128, 256, 128, 256],<br/>    '512': [],<br/>}</span></pre><p id="35d7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">“m”表示内核大小为 2、步幅为 2 的最大池。“c”表示相同的最大池化，但带有在原始结构中没有出现的<code class="fe me mf mg lw b">ceil_mode=True</code>。我的理解是<code class="fe me mf mg lw b">ceil_mode=True</code>处理输入高度或宽度不能被 2 整除的情况，所以在输出中会有一些单元格来自 1x2，2x1，1x1 max 池。不知道为什么会在那里，但应该没什么区别。</p><p id="2dc5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">“S”表示一个<code class="fe me mf mg lw b">stride=2</code>和<code class="fe me mf mg lw b">padding=1</code>卷积层，过滤器的数量在列表中紧随其后(例如，第一个“S”有 512 个过滤器)。</p><pre class="lg lh li lj gt lv lw lx ly aw lz bi"><span id="7eb1" class="km kn iq lw b gy ma mb l mc md">def vgg(cfg, i, batch_norm=False):<br/>    layers = []<br/>    in_channels = i<br/>    for v in cfg:<br/>        if v == 'M':<br/>            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]<br/>        elif v == 'C':<br/>            layers += [nn.MaxPool2d(<br/>                kernel_size=2, stride=2, ceil_mode=True)]<br/>        else:<br/>            conv2d = nn.Conv2d(<br/>                in_channels, v, kernel_size=3, padding=1)<br/>            if batch_norm:<br/>                layers += [<br/>                    conv2d, nn.BatchNorm2d(v), <br/>                    nn.ReLU(inplace=True)]<br/>            else:<br/>                layers += [conv2d, nn.ReLU(inplace=True)]<br/>            in_channels = v<br/>    pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)<br/>    conv6 = nn.Conv2d(<br/>                512, 1024, kernel_size=3, padding=6, dilation=6)<br/>    conv7 = nn.Conv2d(1024, 1024, kernel_size=1)<br/>    layers += [pool5, conv6,<br/>               nn.ReLU(inplace=True), conv7,<br/>               nn.ReLU(inplace=True)]<br/>    return layers</span></pre><p id="b4ca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，它向原始 VGG 结构添加了一个 conv6 (1024 个 3×3 卷积滤波器，膨胀=6，填充=6)和一个 conv7 (1024 个 1×1 卷积滤波器)层。</p><pre class="lg lh li lj gt lv lw lx ly aw lz bi"><span id="494f" class="km kn iq lw b gy ma mb l mc md">def add_extras(cfg, i, batch_norm=False):<br/>    # Extra layers added to VGG for feature scaling<br/>    layers = []<br/>    in_channels = i<br/>    flag = False<br/>    for k, v in enumerate(cfg):<br/>        if in_channels != 'S':<br/>            if v == 'S':<br/>                layers += [<br/>                    nn.Conv2d(in_channels, cfg[k + 1],<br/>                        kernel_size=(1, 3)[flag], stride=2,<br/>                        padding=1)]<br/>            else:<br/>                layers += [<br/>                   nn.Conv2d(<br/>                     in_channels, v, kernel_size=(1, 3)[flag])]<br/>            flag = not flag<br/>        in_channels = v<br/>    return layer</span></pre><p id="f532" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">额外层的构建使用一个旋转的 3x3 和 1x1 内核大小，可选的“S”标志表示<code class="fe me mf mg lw b">stride=2</code>和<code class="fe me mf mg lw b">padding=1</code>，正如我们已经提到的。</p><p id="e8c5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们已经讨论了网络结构。现在是时候继续实际预测/检测物体的类别和位置了。</p><h2 id="ae18" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">预测方案</h2><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mh"><img src="../Images/8b7014160ab64ecdffb202ed009600c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Ulm6qFQ7qWZPUc2hW58Xw.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Figure taken from the original paper</figcaption></figure><p id="6922" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">SSD 的一个关键概念是将神经网络中的中间层作为特征图。然后，它对要素地图运行 3x3 卷积过滤器，对默认框(Python 代码中的先前框)进行分类和预测偏移。每个位置有 4 或 6 个相应的默认框。自然地，较低层中的默认框较小，因为较低层捕获了输入图像的更精细的细节。</p><p id="5918" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于每个默认框，我们预测:</p><ol class=""><li id="9c13" class="mi mj iq jp b jq jr ju jv jy mk kc ml kg mm kk mn mo mp mq bi translated">它属于某一类的概率</li><li id="a8dd" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated">默认框中心的 x 和 y 偏移量</li><li id="29c6" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated">宽度和高度缩放到默认框的宽度和高度</li></ol><p id="e2b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae kl" href="https://github.com/amdegroot/ssd.pytorch/blob/master/ssd.py" rel="noopener ugc nofollow" target="_blank">中的默认框设置<strong class="jp ir"> ssd.py </strong> </a> <strong class="jp ir"> : </strong></p><pre class="lg lh li lj gt lv lw lx ly aw lz bi"><span id="912d" class="km kn iq lw b gy ma mb l mc md">mbox = {<br/>    # number of boxes per feature map location    <br/>    '300': [4, 6, 6, 6, 4, 4],  <br/>    '512': [],<br/>}<br/></span><span id="02c9" class="km kn iq lw b gy mw mb l mc md">def multibox(vgg, extra_layers, cfg, num_classes):<br/>    loc_layers = []<br/>    conf_layers = []<br/>    vgg_source = [24, -2]<br/>    for k, v in enumerate(vgg_source):<br/>        loc_layers += [<br/>            nn.Conv2d(vgg[v].out_channels,<br/>                      cfg[k] * 4, kernel_size=3, padding=1)]<br/>        conf_layers += [<br/>            nn.Conv2d(vgg[v].out_channels,<br/>                      cfg[k] * num_classes, kernel_size=3,<br/>                      padding=1)]<br/>    for k, v in enumerate(extra_layers[1::2], 2):<br/>        loc_layers += [<br/>            nn.Conv2d(v.out_channels, cfg[k]<br/>                      * 4, kernel_size=3, padding=1)]<br/>        conf_layers += [<br/>            nn.Conv2d(v.out_channels, cfg[k]<br/>                      * num_classes, kernel_size=3, padding=1)]<br/>    return vgg, extra_layers, (loc_layers, conf_layers)<br/></span><span id="6d32" class="km kn iq lw b gy mw mb l mc md">def build_ssd(phase, size=300, num_classes=21):<br/>    if phase != "test" and phase != "train":<br/>        print("Error: Phase not recognized")<br/>        return<br/>    if size != 300:<br/>        print("Error: Sorry only SSD300 is supported currently!")<br/>        return<br/>    return SSD(<br/>        phase, *multibox(vgg(base[str(size)], 3),<br/>                         add_extras(extras[str(size)], 1024),<br/>                         mbox[str(size)], num_classes),     <br/>        num_classes<br/>    )</span></pre><p id="30ec" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">SSD 使用 VGG 模型中的两个层— Conv4_3 和 Conv7/FC7，它们对应于层索引 24 和-2(即 relu 激活之前)。这种获得层次的方式有点不靠谱。如果我们决定在 VGG 构造中使用 use <code class="fe me mf mg lw b">batch_norm=True</code>，多框构造将会得到错误的层。额外的层也应该如此，但事实上<code class="fe me mf mg lw b">batch_norm=True</code>甚至还没有在<code class="fe me mf mg lw b">add_extras()</code>中实现。</p><p id="2519" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">对于额外的图层，我们在每两层中使用第二层作为特征地图。一个奇怪的部分是，因为最后一层 Conv11_2 具有形状(256，1，1)，所以 3x3 卷积不是真正必要的。我猜这只是为了代码结构的简单。</p><p id="f1c6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意，每个默认盒子应该有<code class="fe me mf mg lw b">num_class</code> + 4 (x，y，w，h)个输出。</p><h2 id="083a" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">锻炼</h2><figure class="lg lh li lj gt lk gh gi paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="gh gi mx"><img src="../Images/a352a202b478931e5efbcc73f19e5811.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BalxG70fAc_WGKz1tFGroQ.png"/></div></div><figcaption class="lr ls gj gh gi lt lu bd b be z dk">Table taken from the original paper</figcaption></figure><p id="4e83" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">尝试验证 SSD300 中默认盒子的数量(实现的那个)。</strong></p><h2 id="eb9e" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">解决办法</h2><ol class=""><li id="5014" class="mi mj iq jp b jq my ju mz jy na kc nb kg nc kk mn mo mp mq bi translated">Conv4_3: 38 * 38 * 4 = 5776</li><li id="d81b" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated">Conv7: 19 * 19 * 6 = 2166</li><li id="03ab" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated">Conv8_2: 10 * 10 * 6 = 600</li><li id="ad1d" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated">Conv9_2: 5 * 5 * 6 = 150</li><li id="9997" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated">Conv10_2: 3 * 3 * 4 = 36</li><li id="ca2e" class="mi mj iq jp b jq mr ju ms jy mt kc mu kg mv kk mn mo mp mq bi translated">Conv11_2: 4</li></ol><p id="81ad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">总计:5776+ 2166 + 600 + 150 + 36 + 4 = 8732</p><p id="3c3c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，此计算包括填充单元格中的默认框，这些默认框将始终为零，因此基本上是无用的框。</p><p id="a621" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">附加练习</strong>:计算 SSD300 中有效默认框的数量。</p><h2 id="ac57" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">待续</h2><p id="b7ad" class="pw-post-body-paragraph jn jo iq jp b jq my js jt ju mz jw jx jy nd ka kb kc ne ke kf kg nf ki kj kk ij bi translated">我们仍然没有讨论如何将这些默认框映射回输入图像中的实际位置，如何挑选与地面事实相匹配的正确默认框，以及如何构造损失函数来训练网络。这些问题将在下一篇文章中讨论。</p><p id="bb06" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(2017/07/28 更新:以下是该系列第二部的<a class="ae kl" href="https://medium.com/towards-data-science/learning-note-single-shot-multibox-detector-with-pytorch-part-2-dd96bdf4f434" rel="noopener">和第三部</a>的<a class="ae kl" href="https://medium.com/@ceshine/learning-note-single-shot-multibox-detector-with-pytorch-part-3-f0711caa65ad" rel="noopener">的链接。)</a></p><p id="1511" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(2018/07/12 更新:有人私下问了我一个有趣的问题。在此人的允许下，该问答被转贴于此:</p><p id="e5a4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">问:<em class="ng">我试图阅读纸质 VGG-16 和固态硬盘，到处都提到固态硬盘使用 VGG-16 架构，但原始纸张中的固态硬盘架构图像从尺寸(38x38x512)开始，但 VGG-16 架构中唯一可用的尺寸是(224x224x64)、(112x112x128)、(56x56x256)等等，但没有它的(38 X 38 X 512)。</em></p><p id="139a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">答:<em class="ng">注意 VGG16 的(官方)输入图像尺寸是 224，SSD 的是 300。对于 224，特征映射如你所说演化为(224，224，64)，(112，112，128)，(56，56，256)和(28，28，512)。但如果将(300，300，3)图像输入放入 VGG16 架构。特征映射演变为(300，300，64)，(150，150，128)，(75，75，256)，(38，38，512)。</em>)</p></div></div>    
</body>
</html>