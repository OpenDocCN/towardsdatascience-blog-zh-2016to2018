<html>
<head>
<title>What Keras Models Are Missing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Keras 车型缺什么</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-keras-models-are-missing-89b47cc5a4fa?source=collection_archive---------11-----------------------#2018-08-30">https://towardsdatascience.com/what-keras-models-are-missing-89b47cc5a4fa?source=collection_archive---------11-----------------------#2018-08-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><blockquote class="jn jo jp"><p id="50d0" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated"><strong class="jt ir">TL；Keras 模型缺少“模型信心”我们需要知道一个深度学习模型的“置信度”，才能信任和使用它。模型“信心”比高预测概率更微妙。</strong></p></blockquote><p id="5385" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">首先，背景故事。我认识一个团队，他们建立了一个很棒的分类模型来识别“重要”的文档，然后将它们传递给人类专家。他们使用了所有很酷的 NLP 技巧:自定义单词嵌入、语言模型、注意力机制……他们用贝叶斯优化找到了最佳的模型架构和超参数。该模型的精确度与人类相当，并有可能节省数百万美元。人们可能想知道还缺少什么？</p><p id="6d74" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">事实证明，问题在于人类专家不可能审阅模型预测为重要的所有文档。我不会透露具体的用例，但人们可以想象一个为疾病诊断筛选患者病历的假设场景。无论哪种方式，我们都受到资源的限制，只想追求模型对什么“有信心”，以控制假阳性率。<strong class="jt ir">但是“模特自信”到底是什么意思呢？</strong></p><p id="fb10" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">让我们把问题简化为二元分类。模型预测只是 0 到 1 之间的概率。我们可能会认为，预测概率越接近 1，意味着“信心”越高。但实际上模型预测只是一个点估计，它代表了“最佳猜测”，但没有量化“模型置信度”“模型置信度”的最佳量化是一个置信区间，或<a class="ae ks" href="https://en.wikipedia.org/wiki/Credible_interval" rel="noopener ugc nofollow" target="_blank">贝叶斯可信区间</a>。</p><p id="81f4" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">我们可以有两个 0.8 的点估计，但一个置信区间可以是(0.5，0.9)，而另一个置信区间是(0.75，0.85)。第二个估计会比第一个更“有信心”。另一方面，我们可以有两个区间估计:(0.5，0.6)和(0.3，0.9)。尽管区间估计值较低，但区间估计值越窄，提供的信息就越多，因为模型更“可靠”</p><blockquote class="jn jo jp"><p id="ad93" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated">对我来说，(0.5，0.6)表示“模型知道它不知道”，(0.3，0.9)表示“模型不知道它是否知道。”</p></blockquote><p id="ba5c" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">怎么会这样？同样的预测概率怎么会有不同的置信区间？让我们看一个玩具二维例子。下面是 500 点，两个维度都遵循标准正态分布。当一个人将真实数据居中并缩放至平均值 0 和标准差 1 时，这是理想的情况。然后使用二次决策边界对这些点进行着色/分类。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi kt"><img src="../Images/fab579e6eae4aceac7a4774fbafcb1b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0oXG-0qzCm-vLgjRIxbT1A.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Simulated data points to be classified.</figcaption></figure><p id="07cb" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">由于这些点显然不能线性分离，神经网络将是一个强大的模型选择(如果我没有告诉你真正的模型是二次的)。这里我们建立一个简单的一层神经网络，有 100 个隐藏单元。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi lj"><img src="../Images/a204a26dc087bcd1acfe71096300491e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FXcOmIdWiZw0qH8f_6Nw_w.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Shallow neural network with relatively large hidden layer.</figcaption></figure><p id="6b02" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">在仅仅训练了几个时期之后，神经网络做得相当好，并且恢复了决策边界。在这一点上，有人可能会说“喀拉斯万岁”，然后就到此为止。当新数据出现时，我们会采用模型预测的高概率，可能高于某个阈值。这可能是机器/深度学习在实践中的大部分时间是如何完成的，没有数据工程和模型调整。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi lj"><img src="../Images/ace32473469681a2bc63365b54718f63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fwyk62pEt7wLkrsLiC5Efg.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Neural network decision boundary.</figcaption></figure><p id="da8f" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">然而，到目前为止，我们真的没有“模型信心”为了得到那个，我们可以<a class="ae ks" href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)" rel="noopener ugc nofollow" target="_blank">引导</a>数据 50 次，并获得决策边界的经验分布。下图显示了决策界限可能会有很大变化。特别是，模型在中心附近最“自信”,因为蓝色波段在那里最窄。当我们向两边移动时，模型变得不那么“自信”,正如蓝色曲线的高可变性所暗示的那样。</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi lj"><img src="../Images/eae366ab2b139e272da17ed43aade644.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3waoaHKnOPoTF34---cLUg.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Empirical distribution of decision boundaries.</figcaption></figure><p id="cba2" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">考虑两个数据点的模型预测，一个靠近中心，一个向右。如果两个数据点离决策边界的距离相等，则它们的点估计值将相同，但置信区间可能会非常不同。实际上，我们有两个预测分布，它们具有大致相同的均值/中值，但形状截然不同，因此完全没有可比性的“众数置信度”在前面的上下文中，我们会将更多的资源分配给模型更“有信心”的数据点</p><figure class="ku kv kw kx gt ky gh gi paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="gh gi kt"><img src="../Images/77a774db7d8413a87b5a42c6e5a765c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7_OyuP_0RWbEWPwUAFY5_g.png"/></div></div><figcaption class="lf lg gj gh gi lh li bd b be z dk">Predictive distributions at two different data points</figcaption></figure><blockquote class="jn jo jp"><p id="333c" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated">“模型可信度”本质上是数据不确定性的产物。凭直觉认为，在数据可预测的情况下，模型应该更“自信”，而在数据不确定的情况下，模型应该更“不自信”。</p></blockquote><p id="b6c1" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">回到良好的旧回归模型，数据不确定性表现在<a class="ae ks" href="https://en.wikipedia.org/wiki/Leverage_(statistics)" rel="noopener ugc nofollow" target="_blank">杠杆</a>方面。从数学上来说，数据不确定性出现在 X 分布的边界附近，这里附近的数据点很少。这种想法在深度学习中尤为重要，原因有二。</p><p id="4e13" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">首先，深度学习模型倾向于更高维度，尽管有过多的数据，但<a class="ae ks" href="https://en.wikipedia.org/wiki/Curse_of_dimensionality" rel="noopener ugc nofollow" target="_blank">维数灾难</a>将会杀死我们。第二，当我们对图像和文本等数据使用深度学习时，很难想象边界上有什么，因为图像/文本的空间远比数字的欧几里德空间复杂。</p><p id="c8c3" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb kp kd ke kf kq kh ki kj kr kl km kn ko ij bi translated">这意味着，深度学习模型仍然可能不“自信”，即使它们在数百万个数据点上进行训练。此外，我们将更难评估深度学习模型的“可信度”。事实上，这是一个重要而令人兴奋的研究领域。最有希望的解决方案是<a class="ae ks" href="http://bayesiandeeplearning.org/" rel="noopener ugc nofollow" target="_blank">贝叶斯深度学习</a>。最后，我推荐牛津大学的 Yarin Gal 撰写的一篇深入的<a class="ae ks" href="http://www.cs.ox.ac.uk/people/yarin.gal/website/blog_3d801aa532c1ce.html" rel="noopener ugc nofollow" target="_blank">博客文章</a>，以供进一步阅读。</p></div></div>    
</body>
</html>