<html>
<head>
<title>Interactively analyse 100GB of JSON data with Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Spark交互式分析100 GB JSON数据</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/interactively-analyse-100gb-of-json-data-with-spark-e018f9436e76?source=collection_archive---------2-----------------------#2017-09-04">https://towardsdatascience.com/interactively-analyse-100gb-of-json-data-with-spark-e018f9436e76?source=collection_archive---------2-----------------------#2017-09-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="5e03" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你知道有史以来印刷的最重的书是什么吗？让我们通过使用Python中的<a class="ae kl" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Spark </a>探索<a class="ae kl" href="https://openlibrary.org/" rel="noopener ugc nofollow" target="_blank">开放库</a>数据集来找出答案。</p><p id="3592" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">本教程的目的是教育，最初由<strong class="jp ir">Valentin Dali bard博士</strong>和<strong class="jp ir">Raoul-Gabriel Urma博士</strong>:<a class="ae kl" href="https://cambridgespark.com/content/tutorials/interactively-analyse-100GB-of-JSON-data-with-Spark/index.html" rel="noopener ugc nofollow" target="_blank">https://Cambridge Spark . com/content/tutorials/interactive-analyze-100 GB-of-JSON-data-with-Spark/index . html</a></p><p id="82a5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您将初步了解Spark中的一些可用操作，以及如何使用这些操作来交互式地探索在Excel等简单工具中不方便使用(由于大小和结构)的数据集。您还将看到如何在Spark中轻松表达MapReduce操作。注意，我们使用Spark以一种方便的方式运行一个特别的分析。还有其他方法可以分析这个数据集，比如使用<a class="ae kl" href="http://impala.apache.org/" rel="noopener ugc nofollow" target="_blank"> Impala </a>。</p><p id="aed5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在本教程中，您将学习:</p><ul class=""><li id="a94d" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">如何开始使用Spark，</li><li id="67ac" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">如何使用<code class="fe la lb lc ld b">map</code>、<code class="fe la lb lc ld b">flatMap</code>、<code class="fe la lb lc ld b">filter</code>和<code class="fe la lb lc ld b">reduce</code>模式，以及</li><li id="adb1" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">如何使用<code class="fe la lb lc ld b">groupByKey</code>和<code class="fe la lb lc ld b">reduceByKey</code>功能。</li></ul><h1 id="7baa" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">数据集</h1><p id="d8c7" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">开放图书馆是一项旨在为“每本已出版的书创建一个网页”的倡议您可以在终端中使用以下命令下载他们的数据集，该数据集大约有20GB的压缩数据。<code class="fe la lb lc ld b">--continue</code>标志让您可以分几次下载数据。</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="7566" class="mp lf iq ld b gy mq mr l ms mt">wget --continue <a class="ae kl" href="http://openlibrary.org/data/ol_cdump_latest.txt.gz" rel="noopener ugc nofollow" target="_blank">http://openlibrary.org/data/ol_cdump_latest.txt.gz</a></span></pre><p id="6dfe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然后，您可以使用以下命令提取数据—您需要大约100GB的可用空间:</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="44b5" class="mp lf iq ld b gy mq mr l ms mt">gunzip -k ol_cdump_latest.txt.gz | cut -f 5 &gt; ol_cdump.json</span></pre><p id="17d6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要使用EC2上的数据集，请将其上传到亚马逊S3。使用以下命令，使用您的S3存储段名称，将数据上传到S3。像前三步一样，这一步需要时间来完成。</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="e7ce" class="mp lf iq ld b gy mq mr l ms mt">aws s3 cp ol_cdump.json s3://my_bucket</span></pre><p id="1623" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">或者，如果你想处理更小的数据集以节省时间，你可以从https://s3-eu-west-1.amazonaws.com/csparkdata/ol_cdump.json的<a class="ae kl" href="https://s3-eu-west-1.amazonaws.com/csparkdata/ol_cdump.json" rel="noopener ugc nofollow" target="_blank">下载一个数据样本。下面的技术是可行的，但是结果会有所不同。</a></p><p id="88d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你想在本地分析数据，你可以在你自己的机器上安装PySpark，忽略Amazon的设置，直接跳到数据分析。</p><h1 id="6889" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">启动亚马逊EMR</h1><p id="8837" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">如果您想在集群上开始使用Spark，一个简单的选项是<a class="ae kl" href="https://aws.amazon.com/emr/" rel="noopener ugc nofollow" target="_blank">Amazon Elastic MapReduce(EMR)</a>。它为您提供了一个包含几台预配置了Spark的机器的集群。如果您需要快速处理存储在S3上的大型文件，这将非常有用。</p><p id="d20e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里有一个youtube视频向你展示如何开始:</p><figure class="mh mi mj mk gt mu"><div class="bz fp l di"><div class="mv mw l"/></div></figure><h1 id="2dd7" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">开始一本齐柏林飞船笔记本</h1><p id="8885" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">亚马逊EMR Spark实例与<a class="ae kl" href="http://zeppelin-project.org/" rel="noopener ugc nofollow" target="_blank"> Zeppelin笔记本</a>一起提供:jupyter笔记本的替代品，直接运行在Spark之上。点击亚马逊EMR上的Zeppelin链接，打开Zeppelin笔记本。</p><p id="539c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">Zeppelin允许在同一个笔记本中使用多种语言。使用单元格顶部的<code class="fe la lb lc ld b">%pyspark</code>来运行Python命令。</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="ab18" class="mp lf iq ld b gy mq mr l ms mt">%pyspark<br/>print("Hello")</span></pre><p id="c074" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">或者，您可以执行shell指令:</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="ea3d" class="mp lf iq ld b gy mq mr l ms mt">%sh<br/>echo "World !"</span></pre><h1 id="b78b" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">导入数据集</h1><p id="4893" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">第一步是在一个<em class="mx"> Spark RDD </em>中加载数据集:一个抽象数据处理方式的数据结构——在分布式模式下，数据在机器之间分割——并允许您应用不同的数据处理模式，如过滤、映射和简化。要了解更多关于rdd以及本教程其余主题的信息，请查看<a class="ae kl" href="https://cambridgespark.com/courses/bigdata" rel="noopener ugc nofollow" target="_blank">我们的大数据训练营</a>。</p><p id="acc1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以读取文件，并使用操作<code class="fe la lb lc ld b">textFile</code>将每一行转换成RDD的一个元素。</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="dd86" class="mp lf iq ld b gy mq mr l ms mt">path = "s3://my_bucket/ol_cdump.json"<br/>raw_data = sc.textFile(path)</span></pre><p id="ee37" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请注意，如果您正在使用文件的本地副本，您可以将一个标准文件路径(例如，<code class="fe la lb lc ld b">ol_cdump.json</code>)传递给该函数。</p><p id="1f74" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">RDD中的每个元素都是代表一个json值的单个字符串。因此，第二步是在Python字典中转化这些元素，以便更容易地分析它们。<code class="fe la lb lc ld b">json.loads</code>函数将一个JSON值解析成一个Python字典。方法<code class="fe la lb lc ld b">.map(f)</code>返回一个新的RDD，其中<code class="fe la lb lc ld b">f</code>已经应用于原始RDD中的每个元素。将两者结合起来解析RDD的所有行。</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="f95b" class="mp lf iq ld b gy mq mr l ms mt">import json<br/>dataset = raw_data.map(json.loads)<br/>dataset.persist()</span></pre><p id="e009" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意，代码还调用了方法<code class="fe la lb lc ld b">.persist()</code>来缓存内存中的RDD，以便以后可以直接重用。</p><p id="60ed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">RDD数据集中的每个元素现在都是一个将键映射到值的字典。</p><figure class="mh mi mj mk gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi my"><img src="../Images/82500600322d7c0b1532042cd2ad3e77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c12O0y7XVH6oVvSg06ROZw.png"/></div></div></figure><h1 id="c06c" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">探索性数据分析</h1><p id="c480" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">您可以从找出条目的数量开始:</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="f946" class="mp lf iq ld b gy mq mr l ms mt">dataset.count()</span></pre><p id="8826" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这将返回<em class="mx"> 126，107，177 </em>。还不错，书挺多的！</p><p id="a10b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">您可以使用<code class="fe la lb lc ld b">first</code>操作偷偷查看数据，返回第一个元素。或者，<code class="fe la lb lc ld b">take(k)</code>返回第一个<code class="fe la lb lc ld b">k</code>元素的列表</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="65f8" class="mp lf iq ld b gy mq mr l ms mt">dataset.take(10)</span></pre><p id="0359" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">输出相当长。但是你会看到返回的条目包含了<code class="fe la lb lc ld b">number_of_pages</code>、<code class="fe la lb lc ld b">title</code>、<code class="fe la lb lc ld b">weight</code>、<code class="fe la lb lc ld b">isbn_10</code>等书籍属性。</p><p id="0b1c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了理解您所拥有的数据的形状，您可以提取字典中所有可用的不同键。你可能想再次使用<code class="fe la lb lc ld b">map</code>操作，但是你必须使用<code class="fe la lb lc ld b">flatMap</code>来代替。实际上，对于每一个字典，您提取一个键列表，所以<code class="fe la lb lc ld b">map</code>将产生一个键列表的RDD。使用<code class="fe la lb lc ld b">flatMap</code>，所有的键都被折叠成一个单一的平面RDD。考虑<code class="fe la lb lc ld b">flatMap</code>的一种方式是，它允许您对每个元素应用一对多的转换，而不是像<code class="fe la lb lc ld b">map</code>那样一对一。</p><p id="ac4c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这个RDD键上，您可以使用<code class="fe la lb lc ld b">distinct</code>删除重复的键。最后，使用<code class="fe la lb lc ld b">collect</code>操作将惟一键的RDD提取到一个Python列表中。</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="cf0d" class="mp lf iq ld b gy mq mr l ms mt">keys = dataset.flatMap(<strong class="ld ir">lambda</strong> d: d.keys()).distinct().collect()<br/>len(keys)</span></pre><p id="8752" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有<em class="mx"> 504 </em>唯一键！一本书有很多不同的属性。</p><p id="a4c1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">实际上，并不是所有的JSON对象都有相同的属性:经常会缺少属性。例如，数据库可能提到一本书的页数，但不一定提到它的印刷尺寸。这就是你从真实世界的数据中得到的。在开放图书馆数据集中，你会发现很多多样性！为了探索这种多样性，您可以使用<code class="fe la lb lc ld b">groupByKey</code>对每个元素的属性数量进行分组:</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="ec68" class="mp lf iq ld b gy mq mr l ms mt">groups = dataset.map(<strong class="ld ir">lambda</strong> e: (len(e.keys()), e)).groupByKey()</span></pre><p id="fcff" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">但是坚持住！这实际上根本不是好的做法！您可以拥有一个最常见的键数，其中包含大量与该键相关联的数据，比如20GB。在这种情况下，您将创建一个20GB的Python列表，这会使您的机器崩溃或导致交换。</p><p id="2995" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">计算相同结果的更好方法是使用<code class="fe la lb lc ld b">reduceByKey</code>:</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="da90" class="mp lf iq ld b gy mq mr l ms mt">count_per_key = (<br/>    dataset<br/>    .map(<strong class="ld ir">lambda</strong> e: (len(e.keys()), 1))<br/>    .reduceByKey(<strong class="ld ir">lambda</strong> x, y: x + y)<br/>    .collect()<br/>  )</span></pre><p id="d9f2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe la lb lc ld b">reduceByKey</code>操作将为每个键生成的<code class="fe la lb lc ld b">1</code>相加，最终返回每个属性的计数。Zeppelin在这里非常有用，因为它让您可以通过其界面直接可视化结果:</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="bb7d" class="mp lf iq ld b gy mq mr l ms mt">print("%table")<br/><strong class="ld ir">for</strong> e in count_per_key:<br/>  print("%d\t%d" % (e[0], e[1]))</span></pre><figure class="mh mi mj mk gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nf"><img src="../Images/90642eea0b52e8ee7415b8ca3bc331ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*niTwIVb3IOYEOuRVBe5NrA.png"/></div></div></figure><h1 id="15c4" class="le lf iq bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">告诉我重量</h1><p id="fe32" class="pw-post-body-paragraph jn jo iq jp b jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk ij bi translated">你设法获得了一些关于数据的见解。不如来点更有趣的东西，你可以在高级晚宴上提出来？你很幸运。JSON的一个属性是每本书的重量。你好奇想知道最重的书是什么吗？让我们希望这至少是一本有趣的书。当您浏览数据集时，您会注意到<code class="fe la lb lc ld b">weight</code>属性有不同的单位:kg、g、盎司、磅等。一切都很乱！你将需要一个函数，可以正常化的重量，所以你可以比较每本书:</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="01e5" class="mp lf iq ld b gy mq mr l ms mt"><strong class="ld ir">def</strong> sanitizedWeight(weight_str):<br/>  w = convertToKilograms(weight_str)<br/>  <strong class="ld ir">if</strong> w &gt; 1e6:  <em class="mx">#books above 1e6 kg are errors</em><br/>    <strong class="ld ir">return</strong> 0.0<br/>  <strong class="ld ir">else</strong>:<br/>    <strong class="ld ir">return</strong> w</span><span id="98a1" class="mp lf iq ld b gy ng mr l ms mt"><strong class="ld ir">def</strong> convertToKilograms(weight_str):<br/>  result = weight_str.split()<br/>  <strong class="ld ir">if</strong>(len(result)) != 2:<br/>    <strong class="ld ir">return</strong> 0<br/>  <strong class="ld ir">try</strong>:<br/>    number = float(result[0])<br/>  <strong class="ld ir">except</strong> ValueError:<br/>    <strong class="ld ir">return</strong> 0<br/>  <strong class="ld ir">if</strong>(result[1] == 'pounds' or result[1] == 'lb' or result[1] == 'lbs'):<br/>    <strong class="ld ir">return</strong> number * 453.592 * 1e-3<br/>  <strong class="ld ir">elif</strong>(result[1] == 'ounces' or result[1] == 'oz' or result[1] == 'oz.'):<br/>    <strong class="ld ir">return</strong> number * 28.35 * 1e-3<br/>  <strong class="ld ir">elif</strong>(result[1] == 'grams' or result[1] == 'gms' or result[1] == 'g'):<br/>    <strong class="ld ir">return</strong> number * 1e-3<br/>  <strong class="ld ir">elif</strong>(result[1] == 'kilograms' or result[1] == 'kilo' or result[1] == 'kg'):<br/>    <strong class="ld ir">return</strong> number<br/>  <strong class="ld ir">else</strong>:<br/>    <strong class="ld ir">return</strong> 0</span></pre><p id="729f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意，仍有少数带有权重属性的书籍被该函数忽略。有些重量的数字和单位之间没有空格，有些是不寻常的大写字母(GM，KGms)，有些是错别字(ounds)，有些是其他奇怪的符号。让我们把重点放在分析数据集上——但是如果您愿意，可以随意改进这个解析器。</p><p id="8893" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要找到最重的书，你只需要迭代数据并减少它，每次选择最重的书。</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="3726" class="mp lf iq ld b gy mq mr l ms mt">heaviest_book = (<br/>    dataset<br/>    .filter(<strong class="ld ir">lambda</strong> e: "weight" in e and "title" in e)<br/>    .map(<strong class="ld ir">lambda</strong> e: (e, sanitizedWeight(e["weight"])))<br/>    .reduce(<strong class="ld ir">lambda</strong> x, y: x <strong class="ld ir">if</strong> x[1]&gt;y[1] <strong class="ld ir">else</strong> y)<br/>  )</span></pre><p id="7a37" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">那么答案是什么呢？不幸的是，这是一个有点失望，输出是一本书的<em class="mx"> 200，000磅</em>(刚刚超过90公吨)与扼杀标题！</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="49fa" class="mp lf iq ld b gy mq mr l ms mt">({… u'weight': u'200000 pounds', …,  u'title': u'u fool,stupid', …}, 90718.40000000001)</span></pre><p id="6f41" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">显然有人在数据库中插入了一个虚拟条目！这有点令人失望。</p><p id="bd8a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">想象一下书是什么时候出版的怎么样？您可以使用所学的操作生成以下查询:</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="1923" class="mp lf iq ld b gy mq mr l ms mt">booksWithDate = (<br/>    dataset<br/>    .filter(<strong class="ld ir">lambda</strong> e: "publish_date" in e)<br/>    .map(<strong class="ld ir">lambda</strong> e: (e["publish_date"], 1))<br/>    .reduceByKey(<strong class="ld ir">lambda</strong> x, y: x + y)<br/>    .collect()<br/>  )</span><span id="d80f" class="mp lf iq ld b gy ng mr l ms mt"><strong class="ld ir">def</strong> is_int(s):<br/>  <strong class="ld ir">try</strong>:<br/>    t = int(s)<br/>    <strong class="ld ir">return</strong> True<br/>  <strong class="ld ir">except</strong> ValueError:<br/>    <strong class="ld ir">return</strong> False</span><span id="e176" class="mp lf iq ld b gy ng mr l ms mt">booksWithDate = (<br/>    dataset<br/>    .filter(<strong class="ld ir">lambda</strong> e: "publish_date" in e)<br/>    .filter(<strong class="ld ir">lambda</strong> e: len(e["publish_date"]) &gt;=4)<br/>    .filter(<strong class="ld ir">lambda</strong> e: is_int(e["publish_date"][-4:]))<br/>    .map(<strong class="ld ir">lambda</strong> e: (int(e["publish_date"][-4:]), 1))<br/>    .reduceByKey(<strong class="ld ir">lambda</strong> x, y: x+y)<br/>    .collect()<br/>  )</span></pre><p id="8153" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">同样，在处理真实年份之前，您需要处理和清理数据。您现在可以使用Zeppelin中的可视化功能来获得一个不错的分布:</p><pre class="mh mi mj mk gt ml ld mm mn aw mo bi"><span id="7945" class="mp lf iq ld b gy mq mr l ms mt">print("%table")<br/><strong class="ld ir">for</strong> r in d:<br/>  print("%d\t%d" % (r[0], r[1]))</span></pre><figure class="mh mi mj mk gt mu gh gi paragraph-image"><div role="button" tabindex="0" class="mz na di nb bf nc"><div class="gh gi nh"><img src="../Images/c2002be15bcbee9fe2d1e216c52e5814.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9PRJWIPxd-7O1Rd_.png"/></div></div></figure><p id="347f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">如果您对Spark和大数据系统更感兴趣，请查看我们即将举办的网络研讨会系列:</strong></p><div class="ni nj gp gr nk nl"><a href="https://cambridgespark.com/webinar" rel="noopener  ugc nofollow" target="_blank"><div class="nm ab fo"><div class="nn ab no cl cj np"><h2 class="bd ir gy z fp nq fr fs nr fu fw ip bi translated">数据科学网络研讨会系列</h2><div class="ns l"><h3 class="bd b gy z fp nq fr fs nr fu fw dk translated">在世界各地加入我们，了解数据科学、大数据分析和在以下领域使用的先进技术…</h3></div><div class="nt l"><p class="bd b dl z fp nq fr fs nr fu fw dk translated">cambridgespark.com</p></div></div><div class="nu l"><div class="nv l nw nx ny nu nz nd nl"/></div></div></a></div></div><div class="ab cl oa ob hu oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="ij ik il im in"><p id="c49d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">与此同时，你可以测试你的星火技能，尝试找到这些问题的答案:</strong></p><ul class=""><li id="1ca0" class="km kn iq jp b jq jr ju jv jy ko kc kp kg kq kk kr ks kt ku bi translated">数据集里哪个作者写的或者合著的书最多？</li><li id="6246" class="km kn iq jp b jq kv ju kw jy kx kc ky kg kz kk kr ks kt ku bi translated">数据集中哪一类书最受欢迎？</li></ul></div></div>    
</body>
</html>