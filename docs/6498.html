<html>
<head>
<title>Generative Adversarial Networks (GAN)- An AI — 'Cat and Mouse Game'</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成对抗网络(GAN)-人工智能-“猫和老鼠的游戏”</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/art-of-generative-adversarial-networks-gan-62e96a21bc35?source=collection_archive---------9-----------------------#2018-12-16">https://towardsdatascience.com/art-of-generative-adversarial-networks-gan-62e96a21bc35?source=collection_archive---------9-----------------------#2018-12-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/1cdd62700f6860bff974bf4ea23cd438.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0sy8_NFeJXzqgqFs.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><strong class="bd kc">Art of Generative Adversarial Networks</strong></figcaption></figure><p id="f0e9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">帖子中提到的所有作品的代码链接:-</p><div class="lb lc gp gr ld le"><a href="https://github.com/pankajkishore/Code" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab fo"><div class="lg ab lh cl cj li"><h2 class="bd ir gy z fp lj fr fs lk fu fw ip bi translated">pankajkishore/代码</h2><div class="ll l"><h3 class="bd b gy z fp lj fr fs lk fu fw dk translated">在 GitHub 上创建一个帐户，为 pankajkishore/代码开发做出贡献。</h3></div><div class="lm l"><p class="bd b dl z fp lj fr fs lk fu fw dk translated">github.com</p></div></div><div class="ln l"><div class="lo l lp lq lr ln ls jw le"/></div></div></a></div><p id="5292" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们有幸参与了商业数据科学课程的最终项目“生成对抗网络”项目。虽然我们可以选择任何其他主题作为我们的最终项目，但我们继续挑战训练 GAN 从由 880 张大小为 28*28 的 X 射线图像组成的数据集学习生成 X 射线图像。该项目由 Pankaj Kishore、Jitender 和 Karthik 完成。我们最初的想法是探索 GAN，并在此过程中使用 Tensorflow 编写我们自己的代码来训练 GAN 生成 X 射线图像。我将简要介绍一下我们项目的旅程。</p><h1 id="6eb9" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated"><strong class="ak">数据收集</strong></h1><p id="ad14" class="pw-post-body-paragraph kd ke iq kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">第一步是为鉴别器收集足够数量的训练数据集来训练我们的神经网络。我们从下面提到的网站中提取数据:-</p><div class="lb lc gp gr ld le"><a href="https://nihcc.app.box.com/v/ChestXray-NIHCC/folder/37178474737" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab fo"><div class="lg ab lh cl cj li"><h2 class="bd ir gy z fp lj fr fs lk fu fw ip bi translated">箱子</h2><div class="ll l"><h3 class="bd b gy z fp lj fr fs lk fu fw dk translated">编辑描述</h3></div><div class="lm l"><p class="bd b dl z fp lj fr fs lk fu fw dk translated">nihcc.app.box.com</p></div></div></div></a></div><p id="802c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦我们有了足够数量的数据，我们就尝试使用 GAN 进行探索，并对现有数据集实施 GAN，以学习并在我们的数据集上应用相同的实施技术。</p><h1 id="36d6" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated"><strong class="ak">初学</strong></h1><h2 id="f783" class="mw lu iq bd lv mx my dn lz mz na dp md ko nb nc mh ks nd ne ml kw nf ng mp nh bi translated">1.MNIST 数据集</h2><p id="4689" class="pw-post-body-paragraph kd ke iq kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">我们首先通过 MNIST 数据集进行了探索，并找到了足够的在线资源来在 MNIST 数据集上训练我们的第一个 GAN 模型，这被认为是最容易训练的。事实证明，当我们探索代码并理解 GAN 背后的基本原理时，训练它确实非常容易，而且是一种很好的学习体验。我们在 MNIST 数据集上尝试了 GAN 的许多变体。我们尝试的各种变化如下:</p><blockquote class="ni nj nk"><p id="47e0" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated">香草甘</p><p id="ebb4" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated">条件 GAN</p><p id="eccf" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated">瓦瑟斯坦·甘</p><p id="0d75" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated">DCGAN</p><p id="b959" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated">VAE</p></blockquote><p id="f9cb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们获得的结果质量非常好，我们只需稍微调整一下代码就能达到这个结果。我们有趣地发现，为生成器添加更多的隐藏层对图像质量没有影响。我们也尝试了变分自动编码器(VAE)，从下面的链接引用 Ashish Bora 的代码，得到了足够好的结果。</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div class="gh gi np"><img src="../Images/e9aa3d367214080eded5bc07cbf56422.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*gyXAICL4EBhivCSi8ZNsIQ.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">DCGAN</figcaption></figure><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/ca83d6d348fc06d800fea4548a511323.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*TXxdTy1cWZWZLgpnPCwXLQ.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">VAE generated Image</figcaption></figure><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/6a77ff43ed7b813e7f7218b28430a1a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*3T_K1JP5ZOv3uFrdWX637g.png"/></div></figure><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/2dff82b5223ee7b80bfda0a73b430474.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/1*-Eq4PF0dlp2-ynHVgDYteA.gif"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><strong class="bd kc">MNIST at different Epochs through VAE</strong></figcaption></figure><div class="lb lc gp gr ld le"><a href="https://github.com/AshishBora/csgm" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab fo"><div class="lg ab lh cl cj li"><h2 class="bd ir gy z fp lj fr fs lk fu fw ip bi translated">AshishBora/csgm</h2><div class="ll l"><h3 class="bd b gy z fp lj fr fs lk fu fw dk translated">复制论文结果的代码:“使用生成模型的压缩感知”。- AshishBora/csgm</h3></div><div class="lm l"><p class="bd b dl z fp lj fr fs lk fu fw dk translated">github.com</p></div></div><div class="ln l"><div class="nw l lp lq lr ln ls jw le"/></div></div></a></div><p id="400f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> 2。时尚 MNIST </strong></p><p id="9769" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们在时尚 MNIST 数据集上尝试了 MNIST 的相同变化，并且成功地能够为不同的分类器项目生成图像。这导致我们的兴趣转向更大的魔鬼，那就是为 X 射线图像编写我们自己的代码，看看我们是否能为我们的图像编写同样的代码。我们从深入了解甘开始，并乐于分享在整个旅程中学到的几个关键概念。适合我们的架构如下</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div class="gh gi nx"><img src="../Images/7a259076d5bae67ab777dc4e3449c546.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*W53LHWNJNDdwUgge3LwI5Q.png"/></div></figure><p id="55fc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为时尚 MNIST 代码生成的图像:-</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div class="gh gi ny"><img src="../Images/e0b5fde41a7d4aeddbbe7ed9d8b29d12.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*ndLwHxvQ14WgKNCCObCUog.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">99000 epochs</figcaption></figure><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div class="gh gi nz"><img src="../Images/87e4c66c7c2ff1bf20ac6194959d5eba.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*1KfKnHeZ0-aimF83JeLdnQ.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">60000 epochs</figcaption></figure><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/8a61979700b6adf7d034c5334017a85d.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*XNmnBAwvZ9DnM1O4yQdDZQ.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">40000 epochs</figcaption></figure><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div class="gh gi ob"><img src="../Images/d2d24ef4d6293dead46028fcdb7cc08f.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/1*aFlRgdE2TQ6qMayze-v6pg.gif"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><strong class="bd kc">Fashion MNIST GIF at different epochs</strong></figcaption></figure><h1 id="f750" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated"><strong class="ak">生成性对抗网络概述</strong></h1><p id="6eeb" class="pw-post-body-paragraph kd ke iq kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">除非你在过去一年左右的时间里一直住在小屋下，否则深度学习领域的每个人——甚至一些没有参与深度学习的人——都听过并谈论过 GANs。GANs 或生成对抗网络是深度神经网络，是数据的生成模型。这意味着，给定一组训练数据，GANs 可以学习估计数据的潜在概率分布。这非常有用，因为除了其他事情之外，我们现在可以从学习到的概率分布中生成样本，这些样本可能不存在于原始训练集中。</p><p id="1199" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">生成对抗网络实际上是两个相互竞争的深层网络。给定一个训练集<strong class="kf ir"><em class="nl"/></strong>(比如几千张猫的图像)，生成器网络<strong class="kf ir"><em class="nl">【G(X)</em></strong>，将一个随机向量作为输入，并尝试生成与训练集中的图像相似的图像。鉴别器网络<strong class="kf ir"> <em class="nl"> D(x) </em> </strong>是一个二元分类器，它试图根据训练集<strong class="kf ir"> <em class="nl"> X </em> </strong>来区分真正的猫图像和生成器生成的假猫图像。因此，生成器网络的工作是学习数据在<strong class="kf ir"> <em class="nl"> X </em> </strong>中的分布，以便它可以产生真实的猫图像，并确保鉴别器不能区分来自训练集的猫图像和来自生成器的猫图像。鉴别者需要学习跟上生成器，不断尝试新的技巧来生成假的猫图像并愚弄鉴别者。</p><p id="cc8f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最终，如果一切顺利，生成器(或多或少)会了解训练数据的真实分布，并变得非常擅长生成真实的猫图像。鉴别器不再能够区分训练集 cat 图像和生成的 cat 图像。</p><p id="b43e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从这个意义上说，这两个网络不断地试图确保对方没有很好地完成他们的任务。那么，这到底是怎么回事呢？</p><p id="218b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">另一种看待 GAN 设置的方式是，鉴别器试图通过告诉发生器真实的猫图像是什么样子来引导它。最终，生成器发现了它，并开始生成看起来真实的猫图像。训练 GANs 的方法类似于博弈论中的最小最大算法，两个网络试图实现所谓的相对于彼此的纳什均衡。</p><p id="2a8d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">发生器和鉴别器之间发生的事情这里是一个<a class="ae oc" href="https://en.wikipedia.org/wiki/Zero-sum_game" rel="noopener ugc nofollow" target="_blank"> <em class="nl"> 2 人零和游戏</em> </a> <em class="nl">。</em>换句话说，在每一步中，生成器试图最大化鉴别器对图像进行错误分类的机会，而鉴别器反过来试图最大化其对输入图像进行正确分类的机会。</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi od"><img src="../Images/5e1d4a2e81a46401dabbf5155998808e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cxnqsjXYP-lx-3afYsuxXQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">A simple flowchart of a GAN</figcaption></figure><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oe"><img src="../Images/fa02a0f285989815e9e9140ccfdcc1a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rf3U2WusFS2zu2ANOahWGQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Discriminator</figcaption></figure><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/b30a554d250f8141ea1d59d0792f0fd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SS8exw-Ub_SbMfdp9s-G4w.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Generator</figcaption></figure><p id="9a7c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦我们学会了这些课程，我们就开始动手实践并写出我们自己对所学概念的实现。</p><h2 id="5692" class="mw lu iq bd lv mx my dn lz mz na dp md ko nb nc mh ks nd ne ml kw nf ng mp nh bi translated">网络背后的数学</h2><p id="aa85" class="pw-post-body-paragraph kd ke iq kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">深度学习或机器学习都是关于<a class="ae oc" href="https://en.wikipedia.org/wiki/Mathematical_optimization" rel="noopener ugc nofollow" target="_blank">优化函数</a>或者特别是最小化算法的损失。我们用梯度下降来实现。</p><p id="f4a2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">假设 X 是我们的真实数据集，Z 是正态分布噪声。设<em class="nl"> p(z) </em>为来自潜在空间 z 的数据<em class="nl"> G </em>和<em class="nl"> D </em>分别为生成网络和判别网络的可微函数。<em class="nl"> D(x) </em>表示数据来自真实数据集 x 的概率，我们训练 D 使概率<em class="nl"> log(D(x)) </em>最大化，训练 G 使<em class="nl"> log(1 — D(G(z))最小化。</em>简而言之，它们彼此进行如上所述的最小最大博弈，并获得全局最优。</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div class="gh gi og"><img src="../Images/20b18bbc9269518e738c4e9c8c226688.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*XiAXk60ur-NeZm2c49s7nA.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">GAN ( Loss function )</figcaption></figure><p id="7783" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上述功能为我们的生成性对抗网络提供了损失功能。现在，需要注意的是<em class="nl">log(1-D(G(z))</em>会饱和，所以我们不会最小化它，而是最大化<em class="nl"> log(D(G(z))。</em></p><p id="1eb1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了证明生成网络生成的样本与 X 完全相同，我们需要在数学上更深入，使用<a class="ae oc" href="https://en.wikipedia.org/wiki/Kullback–Leibler_divergence" rel="noopener ugc nofollow" target="_blank"> Kullback-Leibler 散度</a>定理和<a class="ae oc" href="https://en.wikipedia.org/wiki/Jensen–Shannon_divergence" rel="noopener ugc nofollow" target="_blank"> Jensen-Shannon 散度</a>。</p><p id="d738" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用的来源:-</p><div class="lb lc gp gr ld le"><a href="https://medium.com/@rajatgupta310198/generative-adversarial-networks-a-simple-introduction-4fd576ab14a" rel="noopener follow" target="_blank"><div class="lf ab fo"><div class="lg ab lh cl cj li"><h2 class="bd ir gy z fp lj fr fs lk fu fw ip bi translated">生成对抗网络-简单介绍。</h2><div class="ll l"><h3 class="bd b gy z fp lj fr fs lk fu fw dk translated">现在人们对深度学习的研究如此热情。这样的结果，每天或每月都有一个新的…</h3></div><div class="lm l"><p class="bd b dl z fp lj fr fs lk fu fw dk translated">medium.com</p></div></div><div class="ln l"><div class="oh l lp lq lr ln ls jw le"/></div></div></a></div><h1 id="dbcf" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated"><strong class="ak">生成 X 射线图像:- </strong></h1><p id="ea5f" class="pw-post-body-paragraph kd ke iq kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated"><strong class="kf ir">问题陈述:- </strong></p><p id="48e9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">重要特征的高质量描绘是用于疾病的精确诊断和/或评估的生物医学图像解释中的关键组成部分。通过利用大量的训练图像，基于卷积神经网络(CNN)的深度学习(DL)技术已经被证明在图像分类和分割任务中非常成功，在生物医学图像解释中潜在地承诺更高的吞吐量和更一致的结果。由 DL 增强的计算机化工具被迅速证明是提高生物医学图像解释准确性的最先进的解决方案。此外，研究人员已经报告了生成对抗网络(GAN)模型的成功训练，以生成合成训练图像，作为解决训练集稀缺的潜在解决方案。</p><p id="495d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">下图显示了 GAN 网络的基本概念。在图片中，生成器试图产生合成图像来欺骗鉴别器，而鉴别器试图将合成图像与真实图像区分开来。</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oi"><img src="../Images/4b567be850c3912847589d7dc68b915c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sgAHc3nx9ewAoe7UUcIIug.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">General GAN architecture</figcaption></figure><h1 id="d755" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">当前的挑战</h1><p id="d1ef" class="pw-post-body-paragraph kd ke iq kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">为深度学习训练 CNN 通常需要大量标记的训练图像数据，由于专家标注的费用，这在生物医学领域仍然是一个挑战。虽然研究人员已经报告了生成对抗网络(GAN)模型的成功训练，以生成合成图像作为解决训练集瓶颈的潜在解决方案，但是及时训练 CNN 和 GAN 可能需要领域专家的编程经验和技能集。我们的目标是为最终用户提供一个简化的工作流程，以促进快速利用 GAN 网络为 DL 培训制作合成放射学图像</p><h1 id="0e13" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated"><strong class="ak">提出的解决方案</strong></h1><p id="4e04" class="pw-post-body-paragraph kd ke iq kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">我们尝试实现 GAN 来生成 X 射线图像，并开始为生成器和鉴别器创建简单的函数。我们最初为鉴别器和生成器设计了三层。使用的激活函数是发生器的泄漏 relu 和鉴别器的 relu。使用 glorot_init 函数将随机噪声也输入到真实图像中。我们通过使用批量标准化调整和缩放激活来标准化输入层。</p><p id="2bed" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">鉴别器和发生器的损失函数如下</p><p id="5ff0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">#损失函数</p><blockquote class="ni nj nk"><p id="1a20" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated">disc _ loss = TF . reduce _ mean(TF . nn . sigmoid _ cross _ entropy _ with _ logits(logits = r _ logits，labels = TF . ones _ like(r _ logits))+TF . nn . sigmoid _ cross _ entropy _ with _ logits(logits = f _ logits，labels=tf.zeros_like(f_logits))</p><p id="f752" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated">gen _ loss = TF . reduce _ mean(TF . nn . sigmoid _ cross _ entropy _ with _ logits(logits = f _ logits，labels=tf.ones_like(f_logits)))</p></blockquote><p id="bcb9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">鉴别器和生成器的步距和学习步骤如下</p><p id="d615" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">gen _ step = TF . train . rmspropoptimizer(learning _ rate = 0.001)。最小化(gen_loss，var_list=gen_vars) # G 训练步骤</p><p id="a034" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">disc _ step = TF . train . rmspropoptimizer(learning _ rate = 0.001)。最小化(disc_loss，var_list=disc_vars) # G 训练步骤</p><p id="c50c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们编写了一个简单的函数来产生随机噪声(假图像),并将其与真实图像一起提供给鉴别器。使用的时期是 1000，我们第一次训练神经网络的样本数是 851，下一次是 5000 个样本(下采样数据集)。我们得到的输出图像真的是噪音，我们意识到了错误，为什么我们没有得到正确的输出。来自我们代码的图像截图:-</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/3af32be7c5c06d8edfe8d459095074ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:136/format:webp/1*1E9pGLS_xbWRu7_0-8F9JQ.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Input Images to Discriminator</figcaption></figure><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/a53018a89871f63bd096eb7959569159.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*yxXeEqST1XlSsxMJPI1fWw.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Output Image generated</figcaption></figure><p id="fa9e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">导致发电机实际上什么也没学到的潜在原因有很多，仅举几个例子</p><blockquote class="ni nj nk"><p id="f30e" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated"><strong class="kf ir">输入鉴别器的低分辨率质量图像</strong></p><p id="fd02" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated"><strong class="kf ir">将实际的 1240*1240 图像下采样为 28*28 </strong></p><p id="b76e" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated"><strong class="kf ir">没有足够的数据集供神经网络学习</strong></p><p id="e921" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated"><strong class="kf ir">梯度下降消失问题，因为鉴别器太成功了，以至于发生器梯度消失并且什么也没学到</strong></p><p id="16e8" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated"><strong class="kf ir">模式崩溃:发生器崩溃，产生有限数量的样本</strong></p></blockquote><p id="756d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们尝试的越多，从上面的样本中产生的空白越多，输出就越好。即使经过无数次尝试，我们也无法从 GAN 中生成高质量的图像，因为我们拥有的数据集存在局限性。</p><h1 id="ba7a" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated"><strong class="ak">口袋妖怪一代</strong></h1><p id="448d" class="pw-post-body-paragraph kd ke iq kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">在尝试从 NIH 网站创建 X 射线图像失败后，我们想到尝试我们的代码来生成口袋妖怪，以确保这可能是一个数据集问题。不幸的是，我们取得了不错的成绩，但不是很好。下面是从我们的 X 射线代码生成的口袋妖怪</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ol"><img src="../Images/ccb25ed8e222a41a5af01c71e209a3ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9cDG5tpE3DFxwuJHbw7A0g.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><strong class="bd kc">Pokemon’s from X-ray code</strong></figcaption></figure><p id="288b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">肯定比 x 光图像好。然后，我们试着运行由一个流行的机器学习程序 Youtuber Siraj Raval 创建的代码(这是他从 moxiegushi 借来的)。</p><div class="lb lc gp gr ld le"><a href="https://github.com/llSourcell/Pokemon_GAN" rel="noopener  ugc nofollow" target="_blank"><div class="lf ab fo"><div class="lg ab lh cl cj li"><h2 class="bd ir gy z fp lj fr fs lk fu fw ip bi translated">llSourcell/口袋妖怪 _GAN</h2><div class="ll l"><h3 class="bd b gy z fp lj fr fs lk fu fw dk translated">Pokemon _ GAN——这是 Siraj Raval 在 Youtube 上发布的“用一个生成对抗网络生成 Pokemon”的代码</h3></div><div class="lm l"><p class="bd b dl z fp lj fr fs lk fu fw dk translated">github.com</p></div></div><div class="ln l"><div class="om l lp lq lr ln ls jw le"/></div></div></a></div><p id="dde3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">代码需要稍微修改，以适应从 Kaggle 网站收集的 851 个口袋妖怪的更高级的数据集。代码被修改，以处理更高分辨率的口袋妖怪以及训练鉴别器。结果是惊人的，尽管它需要很多时间来运行。代码的架构如下</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi on"><img src="../Images/77ecab81156651c53849667ac28db8c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BtPMj8CKF6Ad3kdNgqkazw.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Architecture for Pokemon</figcaption></figure><h1 id="df0e" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">关于鉴别器</h1><p id="df93" class="pw-post-body-paragraph kd ke iq kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">在<code class="fe oo op oq or b">DCGAN</code>架构中，鉴别器<code class="fe oo op oq or b">D</code>是卷积神经网络(<code class="fe oo op oq or b">CNN</code>)，它应用许多过滤器从图像中提取各种特征。鉴别器网络将被训练以区分原始图像和生成的图像。卷积的过程如下图所示:</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div class="gh gi os"><img src="../Images/bc82f0ec624b9c38a588a708d2534659.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/0*tyXVMbqBxQJPoysz"/></div></figure><h1 id="a7a5" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">关于发电机</h1><p id="3451" class="pw-post-body-paragraph kd ke iq kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">被训练来生成图像以欺骗鉴别器的生成器 G 被训练来从随机输入生成图像。在 DCGAN 架构中，发生器由对输入进行上采样的卷积网络表示。目标是处理小的输入，并产生大于输入的输出。它的工作原理是将输入扩展到中间为零，然后在这个扩展区域上进行卷积处理。该区域上的卷积将导致下一层的更大输入。向上采样的过程如下所示:</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div class="gh gi os"><img src="../Images/78e1cffd72fc753399b13bd2672f8769.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/0*09BnsdDaAFy-0sfd"/></div></figure><p id="8752" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">根据不同的来源，您可以找到上采样过程的各种注释。有时它们被称为全卷积、网络内上采样、分数步长卷积、反卷积等等。</p><h1 id="cdb3" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">发电机网络结构概述</h1><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ot"><img src="../Images/13594b31e82bd154c112db559a000d55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2T0padTyKMFnIjv7T-uqKg.png"/></div></div></figure><h1 id="abd1" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated">DCGAN 超参数</h1><p id="4b22" class="pw-post-body-paragraph kd ke iq kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">每个人都注意到的一件事是，GANs 的计算成本非常高。人们通常忽略的是 GANs 相对于超参数是多么脆弱。gan 在某些参数下工作得非常好，但在其他参数下则不然。目前，调谐这些旋钮是网络架构设计艺术的一部分。我们决定采用的超参数如下:</p><h1 id="a0f6" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated"><strong class="ak">超参数</strong></h1><p id="b5cd" class="pw-post-body-paragraph kd ke iq kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">64 件的小批量</p><p id="c3f4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">重量从标准= 0.02 升的正态分布初始化</p><p id="3d80" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Relu 斜率= 0.2</p><p id="de60" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">学习率= 0.0002 的 Adam 优化器</p><p id="9d05" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">动量= 0.5</p><h1 id="0022" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated"><strong class="ak">结果</strong></h1><p id="7f76" class="pw-post-body-paragraph kd ke iq kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">鉴于有限的时间和相关的成本，我们没有完全训练我们的模型，但口袋妖怪产生了 1300 个时代，我在下面附上:-</p><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ou"><img src="../Images/243ad6c56ba4423919a51f26606c6486.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mAzbafCE3ak-hz8LEMrTMQ.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Pokemon after 1300 epochs</figcaption></figure><figure class="nq nr ns nt gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ov"><img src="../Images/513a19735720a22cbd2f8d6de5de06d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*50iJvJpyBwcWHqInkKYAQA.gif"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><strong class="bd kc">Pokemon Generation for incremental Epochs</strong></figcaption></figure><h1 id="ff69" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated"><strong class="ak">项目的主要收获:- </strong></h1><p id="ca1a" class="pw-post-body-paragraph kd ke iq kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">在这个项目上工作是一次很棒的经历，尽管它真的很有挑战性，但它打开了我们的视野，让我们看到了神奇神经网络可以提供的所有新的可能性。我们从错误中学到了很多，并意识到我们需要做的可能的修改，以使 GAN 为我们的 X 射线图像数据集工作。关键要点是</p><blockquote class="ni nj nk"><p id="5be8" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated"><strong class="kf ir">训练一只甘真的很难</strong></p><p id="578f" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated"><strong class="kf ir">为了获得更好的结果，我们需要结合其他因素进行批量标准化。</strong></p><p id="064e" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated"><strong class="kf ir">需要注意梯度下降和损失值，以确保没有发生器或鉴别器达到零值</strong></p><p id="26d9" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated"><strong class="kf ir"> Relu 激活功能是真正的朋友。</strong></p><p id="13a4" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated"><strong class="kf ir">需要实施卷积网络，它们确实适用于大多数数据集，如果不是所有数据集的话</strong></p><p id="6351" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated">我们需要 GPU 来训练 GAN，除非你能等上几年，否则在 CPU 上训练是不可能的！！</p></blockquote><h1 id="f194" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated"><strong class="ak">未来前景:</strong></h1><p id="2510" class="pw-post-body-paragraph kd ke iq kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">我们可以尝试很多事情，首先尝试生成质量为 64*64 的图像，而不是我们目前尝试生成的 256*256，看看这是否能提高图像质量。我们肯定会继续研究 X 射线图像，并尝试实现卷积神经网络，看看我们是否能生成更好的图像。收集大约 100，000 幅图像的训练数据可能有助于更好地训练 CNN 模型，并可能大大提高生成器图像的质量。虽然这可能会变得更加棘手和困难，但如果 CNN 工作得更好，我们会喜欢实现更高分辨率图像或彩色图像的解决方案，看看 GAN 的表现如何。我们甚至想尝试 X 射线图像的变化编码器，看看是否有所帮助。我们甚至想尝试我们在网上找到的东西，比如:-</p><blockquote class="ni nj nk"><p id="a685" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated">迷你批次辨别:让生成器在一个“迷你批次”中对多个图像进行分类，而不是只对一个图像进行分类</p><p id="c1f9" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated">虚拟批次标准化:每个示例都基于参考批次的样本进行标准化</p></blockquote><h1 id="9e7f" class="lt lu iq bd lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq bi translated"><strong class="ak">结论:</strong></h1><p id="66e0" class="pw-post-body-paragraph kd ke iq kf b kg mr ki kj kk ms km kn ko mt kq kr ks mu ku kv kw mv ky kz la ij bi translated">这个项目确实为我们可以用神经网络尝试的许多实现提供了动力。它确实吸引了所有人的注意，很难不欣赏甘可能带来的无限可能性。在这个项目中，我们在使用 Tensorflow 或 cloud 方面确实学到了很多。我们意识到实际训练一个 GAN 是多么困难，即使事情可能在一个数据集上工作，也不一定意味着它在另一个给定的数据集上会以同样的方式工作。GANs 的概念并不难理解(即<a class="ae oc" href="https://medium.com/@naokishibuya/understanding-generative-adversarial-networks-4dafc963f2ef" rel="noopener">理解生成性对抗网络</a>)。但是实现它们以产生高质量的图像可能是棘手的。考虑到 GAN 的无限商机，我可以在未来陈述几个:-</p><p id="43cd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">GANS 可能用于:</p><blockquote class="ni nj nk"><p id="7723" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated">监督学习:</p></blockquote><ul class=""><li id="a5e1" class="ow ox iq kf b kg kh kk kl ko oy ks oz kw pa la pb pc pd pe bi translated">根据{某些约束}尽可能准确地预测，例如公平性</li><li id="d729" class="ow ox iq kf b kg pf kk pg ko ph ks pi kw pj la pb pc pd pe bi translated">不平衡分类中的数据扩充</li><li id="12d7" class="ow ox iq kf b kg pf kk pg ko ph ks pi kw pj la pb pc pd pe bi translated">离群点检测</li><li id="91e5" class="ow ox iq kf b kg pf kk pg ko ph ks pi kw pj la pb pc pd pe bi translated">向量-2-向量预测，例如具有任意损失的多标签预测，其不假设标签独立于特征的条件</li></ul><blockquote class="ni nj nk"><p id="7db7" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated">半监督:</p></blockquote><ul class=""><li id="8fa3" class="ow ox iq kf b kg kh kk kl ko oy ks oz kw pa la pb pc pd pe bi translated">在现实生活的数据集中，经常会出现只有一小部分数据被标记的情况。</li></ul><blockquote class="ni nj nk"><p id="727f" class="kd ke nl kf b kg kh ki kj kk kl km kn nm kp kq kr nn kt ku kv no kx ky kz la ij bi translated">无人监督:</p></blockquote><ul class=""><li id="4cf1" class="ow ox iq kf b kg kh kk kl ko oy ks oz kw pa la pb pc pd pe bi translated">矩阵完成</li><li id="8e81" class="ow ox iq kf b kg pf kk pg ko ph ks pi kw pj la pb pc pd pe bi translated">嵌入</li></ul><p id="5150" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">感谢大家的阅读！！希望你喜欢我们在 GAN 的天真尝试，我们真的希望继续工作，为任何数据集更新一些更棒的结果！！</p><p id="1c41" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">帖子引用的其他链接:</strong></p><p id="b386" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae oc" href="https://philparadis.wordpress.com/2017/04/24/training-gans-better-understanding-and-other-improved-techniques/" rel="noopener ugc nofollow" target="_blank">https://Phil Paradis . WordPress . com/2017/04/24/training-gans-better-understanding-and-other-improved-techniques/</a></p><p id="0522" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae oc" href="https://arxiv.org/abs/1701.00160" rel="noopener ugc nofollow" target="_blank"> NIPS 2016 GAN 教程</a></p><p id="2e0d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae oc" href="https://arxiv.org/abs/1411.1784" rel="noopener ugc nofollow" target="_blank">有条件的甘</a></p></div></div>    
</body>
</html>