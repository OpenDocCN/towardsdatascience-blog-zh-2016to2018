<html>
<head>
<title>Deep Neural Network implemented in pure SQL over BigQuery</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在BigQuery上用纯SQL实现的深度神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deep-neural-network-implemented-in-pure-sql-over-bigquery-f3ed245814d3?source=collection_archive---------2-----------------------#2018-03-13">https://towardsdatascience.com/deep-neural-network-implemented-in-pure-sql-over-bigquery-f3ed245814d3?source=collection_archive---------2-----------------------#2018-03-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/8e5d34e582b4325ad1840d3156fa58b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vkRNZC8JHK0mdRDOSFjIHA.jpeg"/></div></div></figure><figure class="jz ka kb kc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jy"><img src="../Images/7c96ff3b88a8d3d77907faf8c85c0a1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*elgKXNqyQ6e07jgL."/></div></div></figure><p id="0c22" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这篇文章中，我们将纯粹用SQL实现一个基本的深度神经网络。神经网络训练的端到端步骤(包括前向传递和反向传播)将作为BigQuery上的单个SQL查询来实现。由于它运行在Bigquery上，实际上我们是在100到1000台服务器上执行分布式神经网络训练。听起来很酷！对吗？</p><p id="9219" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">也就是说，请注意，这是一个有趣的项目，用来测试SQL和BigQuery的局限性，并从声明性数据转换的角度来看神经网络训练。这是在没有任何实际应用的情况下完成的，尽管我将在最后讨论一些实际的研究意义。让我们开始吧。</p><p id="2fb1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将从一个简单的基于神经网络的分类器开始。它的输入维数为2，输出为二进制。我们将有一个2维的隐藏层和ReLU激活函数。输出层将有一个最终带有softmax函数的二维输出。我们在实现网络时将遵循的步骤是Karpathy的CS231n <a class="ae lb" href="https://cs231n.github.io/neural-networks-case-study/" rel="noopener ugc nofollow" target="_blank">教程</a>中所示的Python示例的基于SQL的版本。</p><h2 id="c252" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">模型</h2><p id="73f0" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">该模型具有以下参数:</p><p id="b2b4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">输入隐藏</strong></p><ul class=""><li id="14b9" class="ma mb iq kf b kg kh kk kl ko mc ks md kw me la mf mg mh mi bi translated"><code class="fe mj mk ml mm b">W</code> : 2x2权重矩阵(元素:<code class="fe mj mk ml mm b">w_00, w_01, w_10, w_11</code>)</li><li id="0663" class="ma mb iq kf b kg mn kk mo ko mp ks mq kw mr la mf mg mh mi bi translated"><code class="fe mj mk ml mm b">B</code> : 2x1偏置矢量(元素:<code class="fe mj mk ml mm b">b_0, b_1</code>)</li></ul><p id="d8bd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">隐藏到输出</strong></p><ul class=""><li id="ac13" class="ma mb iq kf b kg kh kk kl ko mc ks md kw me la mf mg mh mi bi translated"><code class="fe mj mk ml mm b">W2</code> : 2x2权重矩阵(元素:<code class="fe mj mk ml mm b">w2_00, w2_01, w2_10, w2_11</code>)</li><li id="f64c" class="ma mb iq kf b kg mn kk mo ko mp ks mq kw mr la mf mg mh mi bi translated"><code class="fe mj mk ml mm b">B2</code> : 2x1偏置矢量(元素:<code class="fe mj mk ml mm b">b2_0, b2_1</code>)</li></ul><p id="c90f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">训练数据存储在BigQuery表中，其中列<code class="fe mj mk ml mm b">x1</code>和<code class="fe mj mk ml mm b">x2</code>具有输入，y具有输出，如下所示(表名:<code class="fe mj mk ml mm b">example_project.example_dataset.example_table</code>)。</p><figure class="jz ka kb kc gt jr gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/541219da613ab443edaf397e87506cac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/0*9gdQaAz8fG7e_TRd."/></div></figure><p id="dfce" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如前所述，我们将把整个训练作为一个SQL查询来实现。训练完成后，查询将返回参数值。正如您可能已经猜到的，这将是一个嵌套很深的查询。我们将逐步构建来准备这个查询。我们将从最里面的子查询开始，然后我们将一个接一个地添加嵌套的外层。</p><h2 id="0dbf" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">前进传球</h2><p id="75e6" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">最初，我们将为权重参数<code class="fe mj mk ml mm b">W</code>和<code class="fe mj mk ml mm b">W2</code>分配随机正常值，并为偏差参数<code class="fe mj mk ml mm b">B</code>和<code class="fe mj mk ml mm b">B2</code>分配零值。<code class="fe mj mk ml mm b">W</code>和<code class="fe mj mk ml mm b">W2</code>的随机值可以在SQL本身中生成。为简单起见，我们将在外部生成这些值，并在SQL查询中使用。用于初始化参数的内部子查询是:</p><figure class="jz ka kb kc gt jr"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="5aba" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请注意，表<code class="fe mj mk ml mm b">example_project.example_dataset.example_table</code>已经包含列<code class="fe mj mk ml mm b">x1</code>、<code class="fe mj mk ml mm b"> x2</code>和<code class="fe mj mk ml mm b">y</code>。模型参数将作为附加列添加到上述查询的结果中。</p><p id="c4b5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">接下来，我们将计算隐藏层。我们将用包含元素<code class="fe mj mk ml mm b">d0</code>和<code class="fe mj mk ml mm b">d1</code>的矢量<code class="fe mj mk ml mm b">D</code>来表示隐藏层。我们需要执行矩阵运算:<code class="fe mj mk ml mm b">D = np.maximum(0, np.dot(X, W) + B)</code>，其中<code class="fe mj mk ml mm b">X</code>表示输入向量(元素<code class="fe mj mk ml mm b">x1</code>和<code class="fe mj mk ml mm b">x2</code>)。该矩阵运算首先将<code class="fe mj mk ml mm b">X</code>乘以<code class="fe mj mk ml mm b">W</code>中的权重，然后加上偏置向量<code class="fe mj mk ml mm b">B</code>。然后，结果通过非线性<code class="fe mj mk ml mm b">ReLu</code>激活函数，该函数将负值设置为0。SQL中的等效查询是:</p><figure class="jz ka kb kc gt jr"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="dc18" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面的查询在前一个内部子查询的结果中添加了两个新列<code class="fe mj mk ml mm b">d0</code>和<code class="fe mj mk ml mm b">d1</code>。上述查询的输出如下所示。</p><figure class="jz ka kb kc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mv"><img src="../Images/d1a50deb43044a0d5c0a6b9a5b1adfa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9-WEbNFNvM8HLhc1."/></div></div></figure><p id="d85c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就完成了输入到隐藏层的转换。现在我们将执行隐藏层到输出层的转换。</p><p id="7508" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们将计算输出图层的分数。公式为:<code class="fe mj mk ml mm b">scores = np.dot(D, W2) + B2</code>。然后，我们将对分数应用softmax函数，以获得每个类别的预测概率。SQL中等效的内部子查询是:</p><figure class="jz ka kb kc gt jr"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="b8df" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这就完成了神经网络的正向传递。接下来，我们将基于预测输出(<code class="fe mj mk ml mm b">probs</code>)与预期输出(<code class="fe mj mk ml mm b">Y</code>)的比较，进行反向传播以调整模型参数。</p><p id="4bbb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">首先，我们将计算当前预测导致的总损失。我们将使用交叉熵损失函数来计算损失。我们将首先计算每个例子中正确类别的预测概率的负对数。交叉熵损失只不过是在<code class="fe mj mk ml mm b">X</code>和<code class="fe mj mk ml mm b">Y</code>的所有实例中这些值的平均值。自然对数是一个<a class="ae lb" href="http://mathworld.wolfram.com/IncreasingFunction.html" rel="noopener ugc nofollow" target="_blank">递增函数</a>。因此，直观地将损失定义为正确类别的预测概率的对数的负值。如果正确类别的预测概率很高，则损失会很低。相反，如果正确类别的预测概率较低，丢失率将会较高。</p><p id="8b71" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了减少过度拟合的机会，我们还将添加L2正则化。在总损失中，我们将包括<code class="fe mj mk ml mm b">0.5*reg*np.sum(W*W) + 0.5*reg*np.sum(W2*W2)</code>，其中<code class="fe mj mk ml mm b">reg</code>是一个超参数。在损失中包括这个函数将会惩罚权重向量中的高幅度值。</p><p id="1696" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在查询中，我们还将统计训练示例的数量(<code class="fe mj mk ml mm b">num_examples</code>)。这在以后计算平均值时会很有用。计算总损失的SQL查询是:</p><figure class="jz ka kb kc gt jr"><div class="bz fp l di"><div class="mt mu l"/></div></figure><h2 id="3894" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">反向传播</h2><p id="49c8" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">接下来，对于反向传播，我们将计算每个参数相对于损耗的偏导数。我们将使用链式法则从最后一层开始逐层计算。首先，我们将通过使用交叉熵和softmax函数的导数来计算分数的梯度。与此对应的查询是:</p><figure class="jz ka kb kc gt jr"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="fcbe" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">回想一下，我们使用<code class="fe mj mk ml mm b">scores = np.dot(D, W2) + B2</code>计算分数。因此，基于分数的导数(称为<code class="fe mj mk ml mm b">dscores</code>，我们可以计算隐藏层D的梯度和模型参数<code class="fe mj mk ml mm b">W2</code>和<code class="fe mj mk ml mm b">B2</code>。相应的查询是:</p><figure class="jz ka kb kc gt jr"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="e12f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以类似的方式进行，我们知道<code class="fe mj mk ml mm b">D = np.maximum(0, np.dot(X, W) + B)</code>。因此，通过使用<code class="fe mj mk ml mm b">D</code>的导数，我们可以计算<code class="fe mj mk ml mm b">W</code>和<code class="fe mj mk ml mm b">B</code>的导数。计算<code class="fe mj mk ml mm b">X</code>的导数没有意义，因为它不是模型参数或使用任何模型参数计算。计算<code class="fe mj mk ml mm b">W</code>和<code class="fe mj mk ml mm b">B</code>的导数的查询是:</p><figure class="jz ka kb kc gt jr"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="1f1e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">最后，我们将使用它们各自的梯度更新模型参数<code class="fe mj mk ml mm b">W, B, W2</code>和<code class="fe mj mk ml mm b">B2</code>。这可以通过<code class="fe mj mk ml mm b">param -= learning_rate * d_param</code>来计算，其中<code class="fe mj mk ml mm b">learning_rate</code>是一个参数。在<code class="fe mj mk ml mm b">dW</code>和<code class="fe mj mk ml mm b">dW2</code>中还将增加一个额外的因子<code class="fe mj mk ml mm b">reg*weight</code>，以将<code class="fe mj mk ml mm b">L2</code>正则化合并到梯度计算中。我们还将删除临时列，如<code class="fe mj mk ml mm b">dw_00</code>、<code class="fe mj mk ml mm b">correct_logprobs</code>等。它是我们在内部子查询中创建的，只保留训练数据(列<code class="fe mj mk ml mm b">x1</code>、<code class="fe mj mk ml mm b">x2</code>和<code class="fe mj mk ml mm b">y</code>)和模型参数(权重和偏差)。相应的查询是:</p><figure class="jz ka kb kc gt jr"><div class="bz fp l di"><div class="mt mu l"/></div></figure><p id="1efe" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这完成了正向传递和反向传播的一次迭代。上述查询将提供权重和偏差的更新值。样本结果如下所示:</p><figure class="jz ka kb kc gt jr gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/055a53b5e25fdf12718d95c45dbbeae3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/0*gyF1SIikDUqf-c9X."/></div></figure><p id="176d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了进行更多的训练迭代，我们将递归地执行上述所有步骤。我们可以使用一个简单的Python函数来实现。该代码可在<a class="ae lb" href="https://github.com/harisankarh/nn-sql-bq/blob/master/training.py" rel="noopener ugc nofollow" target="_blank">链接</a>中找到。随着我们增加更多的迭代，查询得到了大量的嵌套。执行10次训练迭代的结果查询可在<a class="ae lb" href="https://github.com/harisankarh/nn-sql-bq/blob/master/out.txt" rel="noopener ugc nofollow" target="_blank">链接</a>中获得。</p><p id="4cfc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于大量的嵌套和查询的复杂性，当我试图在BigQuery中执行它时，遇到了多个资源限制。与遗留的SQL方言相比，Bigquery的标准SQL方言具有更好的伸缩性。即使使用标准SQL，对于具有100k个实例的数据集，也很难执行10次以上的迭代。由于资源的限制，我们将在一个简单的决策边界上评估这个模型，这样我们就可以通过少量的迭代获得相当好的精度。</p><p id="c2e5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用一个简单的数据集，其输入<code class="fe mj mk ml mm b">x1</code>和<code class="fe mj mk ml mm b">x2</code>是从均值为0、方差为1的正态分布中采样的。二进制输出y简单地检查<code class="fe mj mk ml mm b">x1 + x2</code>是否大于零。为了在10次迭代内训练得更快，我们将使用2.0的高学习率(注意:在实践中不推荐这么高的值，因为学习可能会发散)。应用上述查询10次迭代，得到如下所示的学习模型参数。</p><figure class="jz ka kb kc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mx"><img src="../Images/5ef36f3ca4ea53f0c5bfd17310dfada2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*eAl4cdF_AZ20quZG."/></div></div></figure><p id="0dd2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们将使用Bigquery的'<a class="ae lb" href="https://cloud.google.com/bigquery/docs/writing-results#saving_query_results_to_a_table" rel="noopener ugc nofollow" target="_blank"> save to table </a>'功能将结果存储到一个新表中。现在，我们可以通过仅执行正向传递，然后比较预测结果和预期结果，来检查训练数据的准确性。这个查询片段在<a class="ae lb" href="https://github.com/harisankarh/nn-sql-bq/blob/master/query_for_prediction.sql" rel="noopener ugc nofollow" target="_blank">链接</a>中。我们能够通过10次迭代获得93%的准确度(在单独的测试数据集上准确度是相似的)。</p><figure class="jz ka kb kc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jy"><img src="../Images/7c96ff3b88a8d3d77907faf8c85c0a1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*elgKXNqyQ6e07jgL."/></div></div></figure><p id="b3cc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们能进行大约100次迭代，我们将获得超过99%的准确率。</p><h2 id="3235" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">最佳化</h2><p id="da73" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">这就结束了在BigQuery中使用纯SQL实现深度神经网络的有趣项目。我们将何去何从？正如我们看到的，资源限制是限制数据集大小和我们可以执行的训练迭代次数的因素。除了希望谷歌放松资源限制，我们可以做多种优化来解决这个问题。</p><ul class=""><li id="5249" class="ma mb iq kf b kg kh kk kl ko mc ks md kw me la mf mg mh mi bi translated">我们可以创建中间表和多个SQL查询来执行更多的迭代。例如，前10次迭代的结果可以存储在中间表中。现在可以在这个中间表上应用相同的训练查询来执行接下来的10次迭代。因此，实际上，我们已经执行了20次训练迭代。这可以重复多次，以执行大量的迭代。</li><li id="7791" class="ma mb iq kf b kg mn kk mo ko mp ks mq kw mr la mf mg mh mi bi translated">我们可以尽可能使用函数的函数，而不是在每一步都添加外部查询。例如，我们可以在一个子查询中计算<code class="fe mj mk ml mm b">scores</code>和<code class="fe mj mk ml mm b">probs</code>，而不是两个嵌套的子查询。</li><li id="3280" class="ma mb iq kf b kg mn kk mo ko mp ks mq kw mr la mf mg mh mi bi translated">在上面的例子中，我保留了所有的中间列，直到最后一个外部查询。其中一些，比如<code class="fe mj mk ml mm b">correct_logprobs</code>，可以提前删除(尽管SQL引擎可能会自动执行这种优化)。</li><li id="9485" class="ma mb iq kf b kg mn kk mo ko mp ks mq kw mr la mf mg mh mi bi translated">可以探索用户定义函数(UDF)的应用。如果感兴趣，您可以查看一个<a class="ae lb" href="https://github.com/groovenauts/QueryItSmart/blob/master/whatisit.md" rel="noopener ugc nofollow" target="_blank">项目</a>，其中使用BigQuery UDF进行模型服务(但是，不使用SQL或UDF进行训练)。</li></ul><h2 id="3ca7" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">含义</h2><p id="b4d0" class="pw-post-body-paragraph kd ke iq kf b kg lv ki kj kk lw km kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">现在，让我们看看深度学习环境中分布式SQL引擎的更深层含义。BigQuery和Presto之类的仓库SQL引擎的一个局限性是查询处理是使用CPU而不是GPU来执行的。使用GPU加速的SQL数据库(如blazingdb和mapd)检查结果会很有趣。一种简单的检验方法是使用分布式SQL引擎执行查询和数据分发，并使用GPU加速数据库执行本地计算。</p><p id="fcc2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">退一步，我们可以看到，现在，执行分布式深度学习是很难的。几十年来，大量的研究工作已经深入到分布式SQL引擎中，从而产生了查询规划、数据分区、操作符放置、检查点、多查询调度等技术。其中一些可以纳入分布式深度学习。如果你对这些方面感兴趣，请看看这篇关于分布式数据库和深度学习的一般研究讨论的<a class="ae lb" href="https://sigmodrecord.org/publications/sigmodRecord/1606/pdfs/04_vision_Wang.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>。</p><p id="21a1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">希望你和我一样开心！请在下面分享你的评论和想法。我很乐意回应。</p></div></div>    
</body>
</html>