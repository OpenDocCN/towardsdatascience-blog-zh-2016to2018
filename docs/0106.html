<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://towardsdatascience.com/generating-text-with-deep-learning-8d3ffec3305b?source=collection_archive---------1-----------------------#2017-03-11">https://towardsdatascience.com/generating-text-with-deep-learning-8d3ffec3305b?source=collection_archive---------1-----------------------#2017-03-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><p id="94ff" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi jn translated"><span class="l jo jp jq bm jr js jt ju jv di"> G </span> <strong class="ir jw">用深度学习生成文本</strong></p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div class="gh gi jx"><img src="../Images/f89d44159776a4bf092a2b5dd5415b99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*DTJQqJ2yctqBcczPjcSYLg.jpeg"/></div></figure><p id="b453" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated">在这个时代，深度学习似乎无处不在，它现在甚至在你的手机中，并为手机上的各种应用程序提供动力，特别是语音聊天助手。在这篇博文中，我们将探索如何使用深度学习生成文本，首先，我们需要建立一个可以模拟语言的模型。</p><p id="85f0" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated"><strong class="ir jw">语言模型</strong></p><p id="bd23" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated">语言模型是能够模拟自然语言的模型。语言模型的目标是理解单词的流动，并且能够在给定单个单词或一长串单词的情况下预测接下来是哪个单词或标点符号。由于对建立聊天机器人和机器翻译模型的兴趣，他们最近得到了很多关注，机器翻译模型使用语言模型来产生响应。在它们的核心，语言模型是建模<strong class="ir jw"> <em class="kf"> P(W|T) </em> </strong>在这种情况下，W 是下一个单词，T 是在它之前出现的所有单词和标点符号的上下文。</p><p id="0126" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated"><strong class="ir jw">深度学习架构</strong></p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div class="gh gi kg"><img src="../Images/f675f066a5a87f56f3c56e75527ef1ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*C6NvE3FyvO5TOXzDBKNm9g.jpeg"/></div></figure><p id="caf9" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated"><strong class="ir jw">词向量</strong></p><p id="e24b" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated">单词向量是将给定单词表示为数字向量的一种方式，例如，我们可以将单词<strong class="ir jw"><em class="kf">I</em></strong><em class="kf">a</em>s 表示为类似于<em class="kf"/><strong class="ir jw"><em class="kf">【0.05，0.85，-0.25，0.97】的向量。</em> </strong>将单词表示为向量背后的动机是相似的单词有相似的单词向量，下面是单词向量的 t-SNE 投影。</p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="gh gi kh"><img src="../Images/8afa34a5eeb9f897119014901da13807.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xsjuepBTKkBG1hr-ECpGKg.png"/></div></div><figcaption class="km kn gj gh gi ko kp bd b be z dk">t-SNE representation of word vectors: Credit to the University of <a class="ae kq" href="http://www.cs.toronto.edu/~nitish/csc321/assignment1.html" rel="noopener ugc nofollow" target="_blank">Toronto</a></figcaption></figure><p id="7b1b" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated">这种表征使得人们能够了解单词通常聚集的空间。这也意味着，如果在训练中遇到没有见过的单词，也可以推广新单词的单词向量。要了解更多关于单词向量的知识，请查阅下面关于单词向量的论文。</p><p id="8a00" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated"><strong class="ir jw">递归神经网络</strong></p><p id="1192" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated">递归神经网络是能够通过时间或其他顺序输入来保持记忆的网络。从上图中可以看出，在每一个时间步，RNN 都能看到之前的状态，以及当前嵌入的单词，这使得它能够对过去和现在进行编码。RNN 隐藏图层的公式可以用以下公式表示:</p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div class="gh gi kr"><img src="../Images/bd3579720c27bf3b9fe7fedc79afe703.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/1*xtEBLTW_5qGqbOAS-1G2Fw.jpeg"/></div></figure><ul class=""><li id="9f3f" class="ks kt iq ir b is it iw ix ja ku je kv ji kw jm kx ky kz la bi translated"><em class="kf"> h(t) </em>表示当前时间步的状态</li><li id="2265" class="ks kt iq ir b is lb iw lc ja ld je le ji lf jm kx ky kz la bi translated"><em class="kf"> h(t-1) </em>代表前一时间步。</li><li id="65a5" class="ks kt iq ir b is lb iw lc ja ld je le ji lf jm kx ky kz la bi translated"><em class="kf"> H </em>是一个正方形矩阵，即<em class="kf"> h x h，</em>这是模型的超参数。每个先前的时间步长乘以相同的矩阵</li><li id="0596" class="ks kt iq ir b is lb iw lc ja ld je le ji lf jm kx ky kz la bi translated"><em class="kf"> e(t) </em>是在当前时间步嵌入的单词</li><li id="d909" class="ks kt iq ir b is lb iw lc ja ld je le ji lf jm kx ky kz la bi translated"><em class="kf"> I </em>是一个变换矩阵，它将当前嵌入变换成一个<em class="kf"> h x h </em>矩阵，这样它可以被加到先前的时间步<em class="kf">。</em>这个矩阵的大小为<em class="kf">嵌入大小 x 隐藏大小</em></li><li id="83d4" class="ks kt iq ir b is lb iw lc ja ld je le ji lf jm kx ky kz la bi translated"><em class="kf"> b1 </em>这里是偏置项。</li></ul><p id="497a" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated">sigmoid 函数:</p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div class="gh gi lg"><img src="../Images/182dfea2150c475cada20ce78ad1ac1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*8SJcWjxz8j7YtY6K-DWxKw.png"/></div></figure><p id="07ce" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated">这是一个在<strong class="ir jw"> 0 </strong>和<strong class="ir jw"> 1 之间挤压输入的功能。</strong>β是一个学习参数，会被更新。rnn 对于神经网络来说是非常复杂和令人着迷的构建模块。虽然我只给出了一个 RNN 的鸟瞰图，下面的<a class="ae kq" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank">博客</a>有一个关于 RNN 和更复杂类型的 rnn 的极好的深度解释。</p><p id="cdeb" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated"><strong class="ir jw"> Softmax </strong></p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div class="gh gi lh"><img src="../Images/f2682721246333aa3b5c2c51e56b6501.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*JapDJa9Z7TbFd6NMbkyozQ.png"/></div></figure><p id="8b83" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated">softmax 是语言模型网络的最后一层，是选择输出哪个单词的层。softmax 的工作原理是对输入进行归一化，并输出一个总和为 1 的向量。具有最高值的条目本质上具有最高的概率。</p><p id="91bf" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated"><strong class="ir jw">损失函数</strong></p><p id="4eda" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated">交叉熵损失用于根据网络输出的单词来训练网络。交叉熵损失函数具有以下公式:</p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div class="gh gi li"><img src="../Images/1dc3ca9d630b20eae46f00f7cb4ec496.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*iQDQmWuuhClc1Xf4_k6k-A.png"/></div></figure><p id="dc06" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated">y 本身是真实的目标值，而 y_hat 是预测值。要记住的最重要的事情是，Y 向量只会在正确的类中为 1，而在其他地方为 0。目的是增加正确类别的概率，并减少竞争类别的概率。使用输出的对数，因为当对数函数接近 0 时，其值急剧下降</p><figure class="jy jz ka kb gt kc gh gi paragraph-image"><div class="gh gi jx"><img src="../Images/2de83a63acbc4aa72c21102c7a357205.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*3Hm-ZlHvrnw2powURqcvoQ.gif"/></div></figure><p id="c45a" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated">为正确类别输出的概率越低，梯度就越陡。</p><p id="c0b5" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated"><strong class="ir jw">评估指标:</strong></p><p id="2574" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated">语言模型使用困惑作为评估标准，可以写成 2 的损失次方。困惑衡量的是输出的分布与实际有多接近，越低越好。困惑也代表了模型的不确定性。困惑度告诉我们对于给定的输出，模型考虑多少个单词，困惑度为 100 意味着模型可以以同样可能的概率选择 100 个单词，我们希望这个数字尽可能低，因为较低的选择对应于选择实际正确单词的较高可能性。</p><p id="b6c0" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated"><a class="ae kq" href="http://www.sntnc.net" rel="noopener ugc nofollow" target="_blank"> <strong class="ir jw"> SNTNC 网</strong> </a></p><p id="bbdf" class="pw-post-body-paragraph io ip iq ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ij bi translated">我邀请大家一起来探索<a class="ae kq" href="http://www.sntnc.net" rel="noopener ugc nofollow" target="_blank"> sntnc 网</a>。如果你产生了一个非常有趣或滑稽的结果，请随意发表在评论中！</p></div></div>    
</body>
</html>