<html>
<head>
<title>Feature Selection in Text Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本分类中的特征选择</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/feature-selection-on-text-classification-1b86879f548e?source=collection_archive---------7-----------------------#2018-11-15">https://towardsdatascience.com/feature-selection-on-text-classification-1b86879f548e?source=collection_archive---------7-----------------------#2018-11-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/82d7846d523a7c446ae49666b9de1e82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QQUhuRgF0N1A-ZhMWKFESA.jpeg"/></div></div></figure><p id="c620" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi kw translated"><span class="l kx ky kz bm la lb lc ld le di"> W </span>当建立机器学习模型进行文本分类时，有很多特征。因为特征是由词构成的，所以语料库的上下文更宽，特征的维度更高。当我为新闻分类、情感分析、网页分类等构建机器学习时，就会发生这种情况。</p><p id="d7b8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这些特征消耗大量的时间和计算能力来得到结果。例如，我需要半个小时的时间来获得情绪分析的结果，用 3 种算法进行基准测试，然后我想到了一些事情，是否可以只选择一些对某些类别重要的单词？</p><p id="f56d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">几十年来，特征选择一直是一个研究课题，它被应用于生物信息学、图像识别、图像检索、文本挖掘等许多领域。理论上，特征选择方法可以基于统计学、信息论、流形和粗糙集。</p><p id="788c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">特征选择方法可以分为 4 类。过滤器、包装器、嵌入式和混合方法。<strong class="ka ir">过滤器</strong>对特征空间进行统计分析，以选择有区别的特征子集。另一方面,<strong class="ka ir">包装器</strong>方法选择各种特征子集，首先使用分类器识别然后评估。当<strong class="ka ir">嵌入</strong>方法时，特征选择过程被嵌入分类的训练阶段。<strong class="ka ir">混合</strong>方法利用了过滤器和包装器方法的优点。</p><p id="41e2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">实际上，Scikit-learn 上有一些可用的特性选择，如卡方检验、方差阈值和互信息。Sklearn 还提供了 SelectKBest，用于选择您想要进行的功能。但是我最近看了很多关于这个的论文。我发现了许多特征选择技术，尤其是过滤方法，我在研究中发现了 30 多种过滤方法，并且还在继续。</p><p id="81ce" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一些包装器方法的算法也发展起来解决这个问题。使用生物启发算法也称为元启发式算法被应用于该方法，例如遗传算法、粒子群优化、萤火虫算法、蚁群优化、人工蜂群等等。如果要应用包装器方法，可以使用<a class="ae lf" href="http://aarongarrett.github.io/inspyred/" rel="noopener ugc nofollow" target="_blank">inspired</a>或者<a class="ae lf" href="https://github.com/tadatoshi/metaheuristic_algorithms_python" rel="noopener ugc nofollow" target="_blank">meta heuristic _ algorithms _ python</a>。</p><p id="435a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最近有很多论文改进了以前的特征选择，其中一些解决了冗余特征，一些解决了最大化相关性。这里是我想让你知道的最近的特征选择算法。</p><p id="f8f9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">多元相对判别准则</strong> [1]</p><p id="1333" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">而特征选择的目的是选择具有最大鉴别能力的紧凑特征子集，这要求在所选特征子集内具有与类别标签的高相关性和低冗余度。建议 MRDC 在评估过程中考虑相关性和冗余概念。关于 MRDC 是如何工作的，首先使用相对区分标准度量来计算每个特征的相关性，然后使用皮尔逊相关来计算特征之间的相关值。</p><p id="abc8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">最小冗余-最大新分类信息</strong> [2]</p><p id="9f08" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有两组用于特征选择，一组集中于最小化冗余，另一组最大化新的分类信息。专注于最小化特征冗余的方法不考虑新的分类信息，反之亦然，从而导致选择具有大量新分类信息但高冗余的特征，或者具有低冗余但几乎没有新分类信息的特征。</p><p id="db67" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Gao 等人提出了一种混合特征选择方法，该方法通过考虑两种类型的特征冗余来集成两组特征选择方法，并且克服了上面提到的局限性。</p><p id="b95c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">MNCI 先生考虑了新的分类信息和特征冗余。特征冗余可以分为两类:类相关特征冗余和类无关特征冗余。这两种类型的特征冗余对于特征选择都很重要。</p><p id="0571" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">特色选择器</strong>【3】</p><p id="1987" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">云萨尔等人提出了一种新的基于过滤器的概率特征选择方法。考虑到对术语特征的某些要求，DFS 选择有区别的特征，而排除无信息的特征。该方法试图回答这样一个共同的问题，即用户正在寻找新的技术来选择有区别的特征，从而可以提高分类精度并减少<strong class="ka ir">处理时间</strong>。</p><p id="cc5e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在他们的论文中，他们将 DFS 与一些流行的过滤方法进行了比较，如卡方检验、信息增益、基尼指数和偏离泊松分布进行时间分析。结果给出 DFS (0.0343s)，GI (0.0371s)，CHI2 (0.0632s)，IG (0.0693s)，DP (0.0797s)越小越好。</p><p id="9823" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">有一些流行的数据集用于文本分类任务。<a class="ae lf" href="http://jmcauley.ucsd.edu/data/amazon/" rel="noopener ugc nofollow" target="_blank">比如亚马逊评论</a>、<a class="ae lf" href="http://ai.stanford.edu/~amaas/data/sentiment/" rel="noopener ugc nofollow" target="_blank">电影评论</a>、<a class="ae lf" href="http://qwone.com/~jason/20Newsgroups/" rel="noopener ugc nofollow" target="_blank"> 20 个新闻组</a>、<a class="ae lf" href="http://www.daviddlewis.com/resources/testcollections/reuters21578/" rel="noopener ugc nofollow" target="_blank">路透社-21578 </a>。都是很好的开始。</p><p id="dcdf" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，流行的算法用于基准特征选择，如朴素贝叶斯，KNN，决策树，SVM，K-Means，层次聚类。朴素贝叶斯是文本分类中最流行的方法。</p><p id="d0f0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">[1]拉巴尼，m .，莫拉迪，p .，艾哈迈德扎尔，f .，贾利利，m .，2018。文本分类问题中一种新的多元滤波特征选择方法。人工智能的工程应用。</p><p id="9e0f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">[2]高，魏，胡，李，张，张，王，等，2018 .综合两组特征评价标准的特征选择。专家系统及其应用。</p><p id="9f7e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">[3]阿·云萨尔，南·古纳尔，2012 年。一种新的文本分类概率特征选择方法。基于知识的系统。</p><h2 id="9677" class="lg lh iq bd li lj lk dn ll lm ln dp lo kj lp lq lr kn ls lt lu kr lv lw lx ly bi translated">如果你喜欢这篇文章，请随意点击鼓掌按钮👏🏽如果你对接下来的帖子感兴趣，一定要在 medium 上关注我</h2></div></div>    
</body>
</html>