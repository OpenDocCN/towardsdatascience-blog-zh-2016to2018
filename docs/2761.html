<html>
<head>
<title>Working with Text Data — From Quality to Quantity</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">处理文本数据—从质量到数量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/working-with-text-data-from-quality-to-quantity-1e9d8aa773dd?source=collection_archive---------7-----------------------#2018-03-01">https://towardsdatascience.com/working-with-text-data-from-quality-to-quantity-1e9d8aa773dd?source=collection_archive---------7-----------------------#2018-03-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/1a42a89c35befa65fda81e0673178b59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*SuGtuWOZZ1KoDAYb96ANlw.gif"/></div></div></figure><div class=""/><div class=""><h2 id="a545" class="pw-subtitle-paragraph kb jd je bd b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks dk translated">注意你的语言:有毒评论的挑战</h2></div><p id="d790" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">由于互联网上的大量文本数据，文本处理和分析变得越来越普遍。从拼写检查等相对简单的任务到监视网络活动等更加不祥的任务，基本项目是将语言和哲学的特殊性(如意义、内涵和上下文)转换为有意义的数学对象，然后可以输入到ML算法中。</p><p id="68c2" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">让我们揭开这个问题的表面，看看解决这个问题的基本方法。假设我们有一组文档(也称为<em class="lp">语料库</em>)要分析。这些文档可以是推文、句子甚至整本书。要将文档转换为向量，一个简单的尝试是对我们的词汇表V中的所有单词进行排序，并让文档<em class="lp"> d </em>由向量<em class="lp"> v，</em>表示，其中<em class="lp"> </em>如果<em class="lp"> d </em>包含我们的词汇表中的第<em class="lp"> i到第</em>个单词，则该向量中的第<em class="lp"> i到第</em>个条目为1，否则为0。这个过程的一个显而易见的结果是，我们的语料库中的所有文档都由相同大小的向量来表示，即我们的词汇量的大小|V|。<strong class="kv jf">这里的缺点是我们已经失去了所有的语言结构，</strong>这被恰当地称为<em class="lp">单词袋</em>模型。我们所获得的是我们词汇表中每个单词的数据特征。重新获得文档局部结构的一种方法是通过添加ngrams来扩大我们的词汇量。这些只是被视为一个单元的n个连续单词(将我们的词汇单元称为'<em class="lp">记号'</em>而不是单词更合适)，这一变化允许我们考虑频繁共现的单词。</p><p id="701f" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">一个小小的改进是跟踪单词在文档中出现的次数，因此我们使用单词在文档中的频率，通常称为术语频率(TF ),而不是上面公式中的1。现在，一个重要的词可能频繁出现，但频繁出现的词不一定重要；像‘the’和‘of’这样的词很少给出关于文档内容的信息。考虑到这一点，我们将使用与语料库中单词的频率成反比的权重，而不是仅使用单词的TF值，这通常被称为逆文档频率(IDF ),通常被认为是</p><figure class="lr ls lt lu gt iv gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/6b75bea78068aa07588c31e10790ab56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*fUdCSEWkDE3ZiRMHT8ZZ4A.png"/></div></figure><p id="9bd2" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">TF和IDF具有相反的趋势，如果该单词在文档中频繁出现，则TF值大(根据定义),如果该单词在语料库中的文档中频繁出现，则IDF权重低。这就是流行的TF-IDF方案的提法。</p><p id="fcc0" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">让我们玩玩这个概念，并将其应用于维基百科评论数据，作为<a class="ae lv" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上<a class="ae lv" href="https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge" rel="noopener ugc nofollow" target="_blank"> <em class="lp">有毒评论分类挑战</em> </a>的一部分。</p><figure class="lr ls lt lu gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi lw"><img src="../Images/7973a05b7e209895fecc0748f3aea653.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*auQHrX6ONkGGWBYGvpYOYg.png"/></div></div></figure><p id="41cd" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">这里的数据由维基百科的文本评论组成，其中一些评论被贴上了一个或多个标签——“有毒”、“严重_有毒”、“淫秽”、“威胁”、“侮辱”和“身份_仇恨”。这里我们的文档是单独的评论，目的是学习一些模式，并用零个或多个上述标签来标记一个新的评论。让我们使用python中的sklearn来看看TF-IDF的实际功能。</p><p id="82a4" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">首先，我们导入数据(名为test和train的两个CSV文件)和一些python库:</p><pre class="lr ls lt lu gt lx ly lz ma aw mb bi"><span id="e43b" class="mc md je ly b gy me mf l mg mh">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import string</span><span id="edc2" class="mc md je ly b gy mi mf l mg mh">from sklearn.feature_extraction.text import TfidfVectorizer<br/>from sklearn.feature_extraction.text import CountVectorizer,<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.model_selection import cross_val_score<br/><br/>train = pd.read_csv('..\train.csv').fillna(' ')<br/>test = pd.read_csv('..\test.csv').fillna(' ')</span><span id="7c6e" class="mc md je ly b gy mi mf l mg mh">train_text = train['comment_text']<br/>test_text = test['comment_text']</span></pre><p id="2c02" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">文本数据通常需要一些清理，但如果我们希望使用上述方案来识别包含侮辱性和有毒语言的评论，这一点更重要。我们不应该将'<em class="lp"> F*** </em>'和'<em class="lp"> F**k </em>'视为不同的词，因为这会混淆我们的TF值。尽管有这样的警告，让我们满足于下面的简单函数str_clean()并清理测试和训练文档集合。</p><pre class="lr ls lt lu gt lx ly lz ma aw mb bi"><span id="8c9d" class="mc md je ly b gy me mf l mg mh"># Replace all elements of punct by white spaces and delete all  numbers and a few chosen punctuation </span><span id="7682" class="mc md je ly b gy mi mf l mg mh">import string<br/>from nltk.stem import PorterStemmer<br/>ps = PortStemmer()<br/>def str_clean(text):<br/>    punct = '():[]?.,|_^-&amp;&gt;&lt;;!"/%'  <br/>    table = str.maketrans(punct, ' '*len(punct), "0123456789$#'=")<br/>    cleaned_comment = []<br/>    for word in text.split():<br/>        cleaned_comment.extend(word.translate(table).split())<br/>        cleaned_comment = [ps.stem(word) for word in<br/>                                                  cleaned_comment]<br/>    return " ".join(cleaned_comment)</span></pre><p id="bd76" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在上面的代码块中，我们用空格替换了一些标点符号，并删除了一些数字和标点符号。最后，我们使用了nltk包中的一个特殊的“词干分析器”将一些单词转换成它们的“词根形式”——例如，“哔”、“哔”和“哔”到“哔”。这允许我们忽略单词的某些形式，因为它们本身是不同的单词。</p><pre class="lr ls lt lu gt lx ly lz ma aw mb bi"><span id="10d0" class="mc md je ly b gy me mf l mg mh">train_text = train_text.map(lambda x: str_clean(x))<br/>test_text = test_text.map(lambda x: str_clean(x))</span></pre><p id="927e" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">Scikit-Learn有一个内置函数<strong class="kv jf"> TfidfVectorizer </strong>，它将语料库作为输入，输出文档的TF-IDF向量——这正是我们所需要的。我们现在需要做的就是应用<strong class="kv jf"> fit_transform </strong>方法来获得所需的矩阵。该函数有多个参数，有助于获得更好的结果；<em class="lp">小写</em>和<em class="lp"> strip_accents </em>允许进一步清理原始文本，<em class="lp"> min_df </em>和<em class="lp"> max_df </em>允许我们限制哪些单词进入我们的词汇表。控制我们词汇的另一个重要方法是使用<em class="lp"> stop_words </em>参数，该参数允许删除诸如“is”、“at”和“which”之类的单词。</p><pre class="lr ls lt lu gt lx ly lz ma aw mb bi"><span id="0063" class="mc md je ly b gy me mf l mg mh">tfidf_vectorizer = TfidfVectorizer(strip_accents='unicode',<br/>    analyzer='word', token_pattern=r'\w{1,}', ngram_range=(1, 2),<br/>    max_features=10000)</span><span id="eae4" class="mc md je ly b gy mi mf l mg mh">train_features = tfidf_vectorizer.fit_transform(train_text)<br/>test_features = tfidf_vectorizer.fit_transform(test_text)</span></pre><p id="19b1" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated"><em class="lp"> max_features </em>参数允许将我们的词汇表限制为最频繁出现的特性；它假设最常用的术语是最重要的。我们的另一个选择是使用sublinear参数，它返回1+log(TF ),而不仅仅是TF。这可以用在这样的情况下，即有理由假设一个比另一个令牌多n倍出现的令牌不是重要n倍，而是大约重要log(n)倍。最后，默认情况下应用IDF权重。</p><p id="d787" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">现在，有了这些特性，我们可以预测测试集中注释的类别标签。这是一个多标签问题，因此标签并不相互排斥。我们将在sklearn中使用logit来获得循环中每个类的预测。我们将使用三重交叉验证来检查ROCAUC分数(本次挑战的评估指标)不会大幅波动。</p><pre class="lr ls lt lu gt lx ly lz ma aw mb bi"><span id="5384" class="mc md je ly b gy me mf l mg mh">pred = pd.DataFrame([])<br/>labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']</span><span id="5920" class="mc md je ly b gy mi mf l mg mh">for label in labels:    <br/>    target = train[label]<br/>    classifier = LogisticRegression(solver = 'sag') <br/>    cv_scores = cross_val_score(classifier, train_features,<br/>                     train_target, cv=3, scoring = 'roc_auc')<br/>    mean_cv = np.mean(cv_scores)</span><span id="afa4" class="mc md je ly b gy mi mf l mg mh">    print('CV score for label {} is {}'.format(label,mean_cv))<br/>    print('\n')</span><span id="f7ab" class="mc md je ly b gy mi mf l mg mh">    classifier.fit(train_features, train_target)<br/>    pred[label]=classifier.predict_proba(test_features)[:, 1]</span></pre><p id="3dd7" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">虽然这是一个非常基本的模型，还有许多参数优化有待执行，但它做得相当好——交叉验证得分约为0.97。从某种意义上来说，一个评论是否包含侮辱或有毒或可被视为身份仇恨，实际上在很大程度上是由话语本身所捕捉的。我们不需要钻研注释的语法或以更复杂的方式解析它来确定给出哪个标签，所以TF-IDF特征提取非常适合这里。</p><h1 id="fa4d" class="mj md je bd mk ml mm mn mo mp mq mr ms kk mt kl mu kn mv ko mw kq mx kr my mz bi translated">接下来呢？</h1><p id="086e" class="pw-post-body-paragraph kt ku je kv b kw na kf ky kz nb ki lb lc nc le lf lg nd li lj lk ne lm ln lo im bi translated">这里的分析可以从改进的词汇中受益。人们对侮辱和谩骂有着非凡的创造力，我们需要更好的方式来看待同一侮辱或词语的各种形式。也许几个小时的正则表达式工作可以帮助大大提高分数。</p><p id="c52a" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">并不是所有IDF分值大的单词都在区分类别标签。我们可以使用一些特征选择的方法来降低我们正在处理的向量的维数，并使用其他算法来进行预测。在后面的帖子中，我们将考虑一种称为双正态比例(BNS)的特征选择方法，该方法将权重添加到术语频率，类似于IDF权重，但考虑了文档的实际类别标签，以确定哪个特征对预测有影响。</p><p id="d559" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">其他特征可以附加到TF-IDF矩阵之外。粗略地看一下评论，看起来被归类为有毒的评论往往有更多的标点符号。像这样的元特征可以从数据中收集。</p><p id="4037" class="pw-post-body-paragraph kt ku je kv b kw kx kf ky kz la ki lb lc ld le lf lg lh li lj lk ll lm ln lo im bi translated">在任何情况下，为了保持理智和功能，不要涉入太多的有毒评论！</p></div></div>    
</body>
</html>