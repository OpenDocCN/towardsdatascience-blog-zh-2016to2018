<html>
<head>
<title>Understanding Batch Normalization with Examples in Numpy and Tensorflow with Interactive Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用交互代码的Numpy和Tensorflow中的示例了解批处理规范化</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-batch-normalization-with-examples-in-numpy-and-tensorflow-with-interactive-code-7f59bb126642?source=collection_archive---------1-----------------------#2018-03-27">https://towardsdatascience.com/understanding-batch-normalization-with-examples-in-numpy-and-tensorflow-with-interactive-code-7f59bb126642?source=collection_archive---------1-----------------------#2018-03-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/9566f36accc58de829ed30486149e4b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:938/1*XDDcoYNNTTvVJqnb-YrnnQ.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Gif from <a class="ae jy" href="https://imgur.com/gallery/j6JLpVA" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="88df" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">所以今天我就来探讨一下批量规格化(<a class="ae jy" href="https://arxiv.org/abs/1502.03167" rel="noopener ugc nofollow" target="_blank"> <em class="kx">批量规格化:通过减少内部协变Shift</em></a><em class="kx">by</em><a class="ae jy" href="https://arxiv.org/find/cs/1/au:+Ioffe_S/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank"><em class="kx">Sergey io FFE</em></a><em class="kx">，以及</em><a class="ae jy" href="https://arxiv.org/find/cs/1/au:+Szegedy_C/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank"><em class="kx">Christian Szegedy</em></a>)。然而，为了加强我对数据预处理的理解，我将讨论3种情况，</p><p id="e42d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">案例1 </strong> — <a class="ae jy" href="http://www.dataminingblog.com/standardization-vs-normalization/" rel="noopener ugc nofollow" target="_blank">归一化</a>:全数据(Numpy) <br/> <strong class="kb ir">案例2 </strong> — <a class="ae jy" href="http://www.dataminingblog.com/standardization-vs-normalization/" rel="noopener ugc nofollow" target="_blank">标准化</a>:全数据(Numpy) <br/> <strong class="kb ir">案例3 </strong> — <a class="ae jy" href="https://arxiv.org/abs/1502.03167" rel="noopener ugc nofollow" target="_blank">批量归一化</a>:小批量(Numpy / Tensorflow)</p><p id="4dff" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> **注** </strong>本帖不涉及反向传播！</p></div><div class="ab cl ky kz hu la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ij ik il im in"><p id="a836" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">实验设置</strong></p><div class="lf lg lh li gt ab cb"><figure class="lj jr lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/bfdab1da0c25c3bdefc3fee32dff9f7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*v9Qdu7kEM7ZrbC-rFnvzIg.png"/></div></figure><figure class="lj jr lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/5d2413a43a76314c91d67bd5e300f6ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*t6hXXvoqeJe4hhh8wH5dfQ.png"/></div></figure></div><p id="176d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这个实验的设置非常简单。为了模拟真实世界的用例，让我们从随机正态分布创建一个32*32的图像，并添加一些噪声。以上是我们的形象看起来像。</p><div class="lf lg lh li gt ab cb"><figure class="lj jr lt ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/1632ec3535a75dbb8dae9cf12be91482.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*4TK0h4_AINYymXWbFGP2Fw.png"/></div></figure><figure class="lj jr lu ll lm ln lo paragraph-image"><img src="../Images/2ad9cf977ce1e8105728bd7835d130f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*fJiU3WouiU_3mGstSs0Zyg.png"/></figure></div><p id="cdb6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">红框</strong> →(图像数量，图像宽度，图像高度，通道数量)现在我们将使用32*32灰度图像。<br/> <strong class="kb ir">左图</strong> →我们图像数据的直方图</p><p id="2d1c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">正如你在上面看到的，我们的图像平均值为26，方差为306。在左边，我们可以看到图像数据的直方图。</p></div><div class="ab cl ky kz hu la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ij ik il im in"><p id="141a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">情况1:归一化—全部数据</strong></p><div class="lf lg lh li gt ab cb"><figure class="lj jr lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/2bda1105175581ab304be3ed9115b7cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*FxUb57f-MnTsXKe3hK_cbg.png"/></div></figure><figure class="lj jr lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/8ccabcc796acdb3b0d2d315028eb1ee3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*AnoNwYUac9Xk0-Kj8_1Xmg.png"/></div></figure></div><p id="d5fb" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于我们的第一个例子，让我们对整个数据集进行归一化。视觉上我们看不出有什么不同。</p><div class="lf lg lh li gt ab cb"><figure class="lj jr lv ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/346d52fe67384ae62cb95d3d7a20411b.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*Hnzh1LSq-wS41d7fKfyuaw.png"/></div></figure><figure class="lj jr lw ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/d51438214f3d32ce08b3d002a3183d3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*awI18jG3_emJ98Tz5mztuw.png"/></div></figure></div><p id="4799" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">然而，一旦我们绘制直方图或查看平均值和标准差，我们可以清楚地看到我们的数据在0和1的范围内。</p></div><div class="ab cl ky kz hu la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ij ik il im in"><p id="dffc" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">案例2:标准化—全部数据</strong></p><div class="lf lg lh li gt ab cb"><figure class="lj jr lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/4edf23ffc387212884955f753118b4cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*Rh9FAXH_EtaJwaKqVh4oEA.png"/></div></figure><figure class="lj jr lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/a63a73e833d39bb3bbfdaca484be7b67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*p1RDofSFrSZcpa8Y6z1Y8A.png"/></div></figure></div><p id="1294" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同样，视觉上我看不出彼此有什么太大的不同。</p><div class="lf lg lh li gt ab cb"><figure class="lj jr lx ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/35076f0afb60d3f0719c8f0abad37f09.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*JevHVRMixsivWcEulq5VPQ.png"/></div></figure><figure class="lj jr ly ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/3a7e90ddd06ccf0923241f5469fc0bd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*huExjJIhG1mq6zRPK6d5xQ.png"/></div></figure></div><p id="eb10" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">然而，当我们看到直方图的轴时，我们可以清楚地看到，我们的数据的平均值已经移动到0(几乎)，方差为1。</p></div><div class="ab cl ky kz hu la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ij ik il im in"><p id="54a4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">标准化/规范化方程</strong></p><div class="lf lg lh li gt ab cb"><figure class="lj jr lz ll lm ln lo paragraph-image"><img src="../Images/29971c1cdb8431590b44bfb31e84fb71.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*uvvU4lzfwWpVZXEyTltnow.png"/></figure><figure class="lj jr ma ll lm ln lo paragraph-image"><img src="../Images/d4293675d35563420626bf494b93eab6.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*UY43iz5Uesa1m9ItIrxYCg.png"/><figcaption class="ju jv gj gh gi jw jx bd b be z dk mb di mc md">Image from this <a class="ae jy" href="http://www.dataminingblog.com/standardization-vs-normalization/" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure></div><p id="4aa3" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">左→ </strong>标准化方程<br/> <strong class="kb ir">右</strong> →标准化方程</p><p id="db15" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">以防万一，如果有人想知道，让我们回顾一下标准化和规范化两种情况下的等式。请注意<strong class="kb ir"> μ </strong>是平均值，<strong class="kb ir"> σ </strong>是标准差。</p></div><div class="ab cl ky kz hu la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ij ik il im in"><p id="6fb9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">批量归一化方程</strong></p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi me"><img src="../Images/8ae385950ad1076e73e4904c44c0a773.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wh5KvzofrPoaod0RpkQgQA.png"/></div></div></figure><p id="7eb0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">红框→ </strong>标准化方程<br/> <strong class="kb ir">蓝线→ </strong>将要学习的参数</p><p id="35e0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">现在我们已经讨论了标准化和规范化，我们可以看到，批量标准化的等式与规范化的过程完全相同。唯一的区别是伽玛和贝塔项，用蓝色下划线标出。我们可以将这些项想象成权重，我们将从地面真实数据中计算误差，并使用反向传播来学习这些参数。</p><p id="b547" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><em class="kx">但是有一点我希望注意！如果我们把gamma(谢谢</em> <a class="ae jy" href="https://medium.com/@clementlfang?source=post_info_responses---------1----------------" rel="noopener"> <em class="kx">洛阳方</em> </a> <em class="kx">纠正我</em> ) <em class="kx">设为1，beta设为0整个过程只是标准化而已。对于Tensorflow的实现，我们将滥用该属性。</em></p></div><div class="ab cl ky kz hu la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ij ik il im in"><p id="3093" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">案例三:批量归一化——纯实现</strong></p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi mf"><img src="../Images/f5c63197d87810662097185391d1677a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SQJUUQ6dKVAh14CFubRiLg.png"/></div></div></figure><p id="49d8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">红线</strong> →小批量，从我们的图像数据<br/> <strong class="kb ir">中取出前10张图像，蓝框</strong> →数据标准化</p><div class="lf lg lh li gt ab cb"><figure class="lj jr lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/b4b4aa87203848bce298a4da624625f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*6GsJ5Q-fRfgK_bJDxuMU6w.png"/></div></figure><figure class="lj jr lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/6de63f74c57a0dd86dcbaa4c27592017.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*LtUxg28mT8tLDD45hFnYuQ.png"/></div></figure></div><p id="7759" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这里有一点需要注意，对于批量标准化，我们将从测试数据中提取前10幅图像，并应用批量标准化。</p><div class="lf lg lh li gt ab cb"><figure class="lj jr mg ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/27f36d07ae0a223ade43a695323eafad.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*xyHd9VFFyirGRD5Ez3Hleg.png"/></div></figure><figure class="lj jr mh ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/4ac85fc1a6a892077f5b4c617d34633b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1402/format:webp/1*xEKh6m4Q76BaMk41mQoMgA.png"/></div></figure></div><p id="6369" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同样，我们可以看到均值在0左右，方差为1。现在让我们看看tensorflow的实现。</p></div><div class="ab cl ky kz hu la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ij ik il im in"><p id="ff6e" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">案例三:批量归一化—张量流</strong></p><figure class="lf lg lh li gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="gh gi mi"><img src="../Images/c90570c4c3595b6e2ff40a8f00b53b38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-VF0YXVZXleNJjBFobtf5w.png"/></div></div></figure><p id="2cea" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">红线</strong> → Mini Batch，来自我们图像数据<br/> <strong class="kb ir">的前10张图像蓝线→ </strong> Offset (Beta)为0，Scale (Gamma)为1</p><div class="lf lg lh li gt ab cb"><figure class="lj jr lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/6de63f74c57a0dd86dcbaa4c27592017.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*LtUxg28mT8tLDD45hFnYuQ.png"/></div></figure><figure class="lj jr lk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/b4b4aa87203848bce298a4da624625f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*6GsJ5Q-fRfgK_bJDxuMU6w.png"/></div></figure></div><p id="8515" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">还是那句话，视觉上，我们看不出任何区别。</p><div class="lf lg lh li gt ab cb"><figure class="lj jr mj ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/f1ff85701771e81937aefe6ed5271f92.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/1*xyHd9VFFyirGRD5Ez3Hleg.png"/></div></figure><figure class="lj jr mk ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/16dc546ae435d1180e5e929f7684bd54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mpme6YXMp7s3jxSNOol6QA.png"/></div></figure></div><p id="8c7a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">但是，如果我们看一下数据的平均值和方差，我们可以看到这与应用标准化完全相同。</p></div><div class="ab cl ky kz hu la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ij ik il im in"><p id="ccc8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">交互代码(谷歌Collab/ Replit/微软Azure笔记本)</strong></p><div class="lf lg lh li gt ab cb"><figure class="lj jr ml ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/c2428b56397a2f9f634e54fe8f970372.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/1*dTM2zq8YLPvceF9rVApSfQ.png"/></div></figure><figure class="lj jr mm ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/ff1739aa5c08009843266871f0c1e72d.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*nWQt9z2EHbQiaiYa-75KdQ.png"/></div></figure><figure class="lj jr mn ll lm ln lo paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><img src="../Images/f431553b346030a79b1bdb05fbd237c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*9-LZ1C0y_DJM8Ufi_ME4Bw.png"/></div></figure></div><p id="a1a1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">对于谷歌Colab，你需要一个谷歌帐户来查看代码，而且你不能在谷歌Colab中运行只读脚本，所以在你的操场上做一个副本。最后，我永远不会请求允许访问你在Google Drive上的文件，仅供参考。编码快乐！</p><p id="cb6f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">要访问Google Colab上的代码，<a class="ae jy" href="https://colab.research.google.com/drive/19ECWYHC72rSBuF9fQCGCuu6OAgZ1HBWu" rel="noopener ugc nofollow" target="_blank">请点击此处</a>。<br/>要访问Repl it上的代码，<a class="ae jy" href="https://repl.it/@Jae_DukDuk/33-Batch-Norm" rel="noopener ugc nofollow" target="_blank">请点击这里</a>。<br/>要访问Microsoft Azure笔记本上的代码，<a class="ae jy" href="https://selfcar-jaedukseo.notebooks.azure.com/nb/notebooks/33%20Batch%20Norm.ipynb" rel="noopener ugc nofollow" target="_blank">请单击此处</a>。</p></div><div class="ab cl ky kz hu la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ij ik il im in"><p id="8b7d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">遗言</strong></p><p id="5a84" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">最近Face book AI研究组发布了群组规范化。(<a class="ae jy" href="https://arxiv.org/pdf/1803.08494.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="kx">分组规格化</em></a><em class="kx">n by</em><a class="ae jy" href="https://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank"><em class="kx">吴雨欣</em> </a> <em class="kx">，以及</em> <a class="ae jy" href="https://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank"> <em class="kx">明凯何</em> </a>)我会尽量涵盖这一点。</p><p id="14c9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到jae.duk.seo@gmail.com给我，如果你想看我所有写作的列表，请在这里查看我的网站。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的twitter <a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，并访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>了解更多内容。如果你感兴趣，我还在这里做了解耦神经网络<a class="ae jy" href="https://becominghuman.ai/only-numpy-implementing-and-comparing-combination-of-google-brains-decoupled-neural-interfaces-6712e758c1af" rel="noopener ugc nofollow" target="_blank">的比较。</a></p></div><div class="ab cl ky kz hu la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ij ik il im in"><p id="138a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="85ed" class="mo mp iq kb b kc kd kg kh kk mq ko mr ks ms kw mt mu mv mw bi translated">CS231n冬季:第五讲:神经网络第二部分。(2018).YouTube。检索于2018年3月19日，来自<a class="ae jy" href="https://www.youtube.com/watch?v=gYpoJMlgyXA&amp;feature=youtu.be&amp;list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC&amp;t=3078" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=gYpoJMlgyXA&amp;feature = youtu . be&amp;list = plkt 2 usq 6 rbvctenobvg 1 tpcc 7 aoqi 31 ALC&amp;t = 3078</a></li><li id="eee8" class="mo mp iq kb b kc mx kg my kk mz ko na ks nb kw mt mu mv mw bi translated">thorey，C. (2016年)。流过批量归一化的渐变是什么样子的？。cthorey . github . io . 2018年3月19日检索，来自<a class="ae jy" href="http://cthorey.github.io/backpropagation/" rel="noopener ugc nofollow" target="_blank">http://cthorey.github.io/backpropagation/</a></li><li id="71b6" class="mo mp iq kb b kc mx kg my kk mz ko na ks nb kw mt mu mv mw bi translated">推导批量范数反投影方程。(2018).chrisyeh 96 . github . io . 2018年3月19日检索，来自<a class="ae jy" href="https://chrisyeh96.github.io/2017/08/28/deriving-batchnorm-backprop.html" rel="noopener ugc nofollow" target="_blank">https://chrisyeh 96 . github . io/2017/08/28/derivating-batch norm-back prop . html</a></li><li id="50ad" class="mo mp iq kb b kc mx kg my kk mz ko na ks nb kw mt mu mv mw bi translated">推导批次标准化的后向传递的梯度。(2018).kevinzakka . github . io . 2018年3月19日检索，来自<a class="ae jy" href="https://kevinzakka.github.io/2016/09/14/batch_normalization/" rel="noopener ugc nofollow" target="_blank">https://kevinzakka . github . io/2016/09/14/batch _ normalization/</a></li><li id="6c92" class="mo mp iq kb b kc mx kg my kk mz ko na ks nb kw mt mu mv mw bi translated">克拉泽特，F. (2018)。了解反向传递批处理规范化层。krat zert . github . io . 2018年3月19日检索，来自<a class="ae jy" href="https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html" rel="noopener ugc nofollow" target="_blank">https://krat zert . github . io/2016/02/12/understanding-the gradient-flow-through-the-batch-normalization-layer . html</a></li><li id="75b9" class="mo mp iq kb b kc mx kg my kk mz ko na ks nb kw mt mu mv mw bi translated">(2018).Arxiv.org。检索于2018年3月19日，来自<a class="ae jy" href="https://arxiv.org/pdf/1502.03167.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1502.03167.pdf</a></li><li id="2921" class="mo mp iq kb b kc mx kg my kk mz ko na ks nb kw mt mu mv mw bi translated">NumPy . histogram—NumPy 1.13版手册。(2018).Docs.scipy.org。检索于2018年3月19日，来自<a class="ae jy" href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.histogram.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/numpy-1 . 13 . 0/reference/generated/numpy . histogram . html</a></li><li id="b21c" class="mo mp iq kb b kc mx kg my kk mz ko na ks nb kw mt mu mv mw bi translated">NumPy . random . Weibull—NumPy v 1.13手册。(2018).Docs.scipy.org。检索于2018年3月19日，来自<a class="ae jy" href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.random.weibull.html#numpy.random.weibull" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/numpy-1 . 13 . 0/reference/generated/numpy . random . Weibull . html # numpy . random . Weibull</a></li><li id="21ea" class="mo mp iq kb b kc mx kg my kk mz ko na ks nb kw mt mu mv mw bi translated">numpy.var — NumPy v1.14手册。(2018).Docs.scipy.org。检索于2018年3月26日，来自<a class="ae jy" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.var.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/numpy/reference/generated/numpy . var . html</a></li><li id="abb7" class="mo mp iq kb b kc mx kg my kk mz ko na ks nb kw mt mu mv mw bi translated">数据？，H. (2018)。如何用Python中的Matplotlib绘制一个带有数据列表的直方图？。Stackoverflow.com。检索于2018年3月26日，来自<a class="ae jy" href="https://stackoverflow.com/questions/33203645/how-to-plot-a-histogram-using-matplotlib-in-python-with-a-list-of-data" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/33203645/how-to-plot-a-histogram-using-matplotlib-in-python-with-a-list-of-data</a></li><li id="f0a3" class="mo mp iq kb b kc mx kg my kk mz ko na ks nb kw mt mu mv mw bi translated">numpy.random.randn — NumPy v1.14手册。(2018).Docs.scipy.org。检索于2018年3月27日，来自<a class="ae jy" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randn.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/numpy/reference/generated/numpy . random . randn . html</a></li><li id="0370" class="mo mp iq kb b kc mx kg my kk mz ko na ks nb kw mt mu mv mw bi translated">吴，杨，何，王(2018)。群体规范化。Arxiv.org。检索于2018年3月27日，来自https://arxiv.org/abs/1803.08494<a class="ae jy" href="https://arxiv.org/abs/1803.08494" rel="noopener ugc nofollow" target="_blank"/></li><li id="85b1" class="mo mp iq kb b kc mx kg my kk mz ko na ks nb kw mt mu mv mw bi translated">标准化与规范化|数据挖掘博客—【www.dataminingblog.com T4】。(2007).Dataminingblog.com。检索于2018年3月27日，来自<a class="ae jy" href="http://www.dataminingblog.com/standardization-vs-normalization/" rel="noopener ugc nofollow" target="_blank">http://www . dataminingblog . com/standardization-vs-normalization/</a></li><li id="3cfd" class="mo mp iq kb b kc mx kg my kk mz ko na ks nb kw mt mu mv mw bi translated">约夫和塞格迪(2015年)。批量标准化:通过减少内部协变量转移加速深度网络训练。Arxiv.org。检索于2018年3月27日，来自<a class="ae jy" href="https://arxiv.org/abs/1502.03167" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1502.03167</a></li><li id="8d1d" class="mo mp iq kb b kc mx kg my kk mz ko na ks nb kw mt mu mv mw bi translated">正态分布。(2018).Mathsisfun.com。检索于2018年3月27日，来自<a class="ae jy" href="https://www.mathsisfun.com/data/standard-normal-distribution.html" rel="noopener ugc nofollow" target="_blank">https://www . mathsisfun . com/data/standard-normal-distribution . html</a></li></ol></div></div>    
</body>
</html>