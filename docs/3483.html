<html>
<head>
<title>From brain waves to robot movements with deep learning: an introduction.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从脑电波到具有深度学习的机器人运动:导论。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/from-brain-waves-to-arm-movements-with-deep-learning-an-introduction-3c2a8b535ece?source=collection_archive---------5-----------------------#2018-05-16">https://towardsdatascience.com/from-brain-waves-to-arm-movements-with-deep-learning-an-introduction-3c2a8b535ece?source=collection_archive---------5-----------------------#2018-05-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c74a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用神经网络可视化和解码大脑活动。</h2></div><p id="c7d8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以在<a class="ae lb" href="https://colab.research.google.com/drive/1lDfmXMo7_mcVBo9EAtgLNIgeJV50GTce#scrollTo=AFoTOqC-4Rjl" rel="noopener ugc nofollow" target="_blank">这个在线合作笔记本</a>中找到这篇文章的所有代码，你可以直接在你的浏览器上运行它。这里是<a class="ae lb" href="https://github.com/normandipalo/eeg-to-action" rel="noopener ugc nofollow" target="_blank"> GitHub 回购</a>。</p><p id="5d7a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在推特上关注我的工作更新和更多:【https://twitter.com/normandipalo T4】</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi lc"><img src="../Images/a518ac9af6e1bee77074e9710655698c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dcahsOdbeOLYlDZRA28DMA.png"/></div></div></figure><p id="0bb6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">神经系统是一个极其复杂的结构。在你的全身，超过十万公里长的神经连接着你的脊髓和大脑。这个“网格”传输控制每个动作的电脉冲。每一个命令都来自你的大脑，一个更神奇的神经元结构，它通过电激活信号进行交流。理解和解释脑电模式是神经科学家和神经生物学家最大的梦想之一，但事实证明这是一项极具挑战性的任务。</p><p id="904f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一种记录大脑活动的非侵入性方法是<strong class="kh ir">脑电图(EEG) </strong>。这是一种允许使用放置在患者头皮上的电极来记录脑电压波动的技术。通常，大约 30 个这样的电极被放置在头皮周围，允许记录脑电波的整体活动。总之，<a class="ae lb" href="https://www.kaggle.com/c/grasp-and-lift-eeg-detection" rel="noopener ugc nofollow" target="_blank">大脑活动和 EEG 信号之间的关系是复杂的，除了特定的实验室测试之外，对其了解甚少</a>。因此，一个巨大的挑战是学习如何“解码”，从某种意义上说，这些脑电图扫描，可以允许控制机器人假肢和其他设备使用非侵入式<strong class="kh ir">脑机接口(BCI) </strong>。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi lo"><img src="../Images/00ec7b57b3acb95af8bc04ec88e5760b.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*l_v1C6Fte2qgd0UGThLwmA.png"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk">Example of brain waves recorded with EEG. CC BY-SA 2.0, <a class="ae lb" href="https://commons.wikimedia.org/w/index.php?curid=845554" rel="noopener ugc nofollow" target="_blank">https://commons.wikimedia.org/w/index.php?curid=845554</a></figcaption></figure><p id="4c8b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作为强数据驱动的学科，<strong class="kh ir">深度学习</strong>最近在相关模式识别任务中的突破，创造了一种使用<strong class="kh ir">神经网络</strong>分析这些电信号的新方法。在这篇文章中，我们将看到这个主题的介绍:我们将阅读由<a class="ae lb" href="https://www.kaggle.com/c/grasp-and-lift-eeg-detection" rel="noopener ugc nofollow" target="_blank"> Kaggle 竞赛</a>提供的脑电图数据，该竞赛旨在检测哪些脑电图模式对应于特定的手臂和手势，如抓住或举起物体。在用不同的方式对数据进行预处理之后，我们将设计一个神经网络来执行这种分类。我也将展示一些大脑活动的数据可视化，以给出我们正在处理的数据的一个总体概念。该研究领域的最终目标是开发负担得起且有用的<strong class="kh ir">假肢装置</strong>，通过用大脑控制假肢，帮助截肢者重新获得轻松完成基本任务的能力。类似的技术也可以应用于读取肌肉电激活，从而通过分析激活的肌肉来解码一个人试图执行的运动类型。</p><p id="8bb3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">你可以在<a class="ae lb" href="https://colab.research.google.com/drive/1lDfmXMo7_mcVBo9EAtgLNIgeJV50GTce#scrollTo=AFoTOqC-4Rjl" rel="noopener ugc nofollow" target="_blank">这个在线合作笔记本</a>中找到这篇文章的所有代码，你可以直接在你的浏览器上运行它。下面是<a class="ae lb" href="https://github.com/normandipalo/eeg-to-action" rel="noopener ugc nofollow" target="_blank"> GitHub 回购</a>。</p><h1 id="2bdf" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">数据简介</h1><p id="ae65" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">如果你有一个 Kaggle 帐户<a class="ae lb" href="https://www.kaggle.com/c/grasp-and-lift-eeg-detection" rel="noopener ugc nofollow" target="_blank">你可以在这里</a>免费下载数据。正如您将看到的，该数据仅由几个<em class="mq">组成。csv </em>文件。这些文件分别是:</p><ul class=""><li id="8936" class="mr ms iq kh b ki kj kl km ko mt ks mu kw mv la mw mx my mz bi translated">用作模型输入的 EEG 数据，由放置在患者头皮上的 32 个电极记录。数据以 500 赫兹的频率记录。</li><li id="f89d" class="mr ms iq kh b ki na kl nb ko nc ks nd kw ne la mw mx my mz bi translated">测试人员试图实现的运动的逐帧标签，在 6 个可能的标签中。</li></ul><p id="4770" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些数据是通过记录不同人类测试者执行简单动作(如抓取和举起物体)时的脑电图来收集的。因此，数据集被分成不同的剧集，但也有不同的主题。我们将在稍后的准确度预测中看到，<strong class="kh ir">脑电波可能是非常个人化的</strong>，因为一个模型可以非常准确地预测同一个人在看不见的情节中的意图，但是如果训练不够多样，在对新测试人员做同样的事情时可能会有困难。</p><p id="a86f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，目标是创建一个神经网络，该网络将 EEG 读数作为输入，并输出测试者试图实现的这 6 个可能动作的概率分布。由于“无动作”不是一个可能的类，我们可以将其添加为一个类，或者将所有可能的输出设置为 0 到 1 之间的值，并使用阈值来决定是否检测到该动作。如果每个动作都低于阈值，我们就认为它没有动作。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/6e4e2e52a506374d6d72f285e26d69f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*Y5VXqeQtRD0lsFCazf8Njw.jpeg"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk">Position of electrodes, source: <a class="ae lb" href="https://www.kaggle.com/c/grasp-and-lift-eeg-detection/data" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/grasp-and-lift-eeg-detection/data</a></figcaption></figure><p id="895e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我制作了这些电极活动的动画数据可视化。由于采样频率相当高(500 Hz)，我使用了一个简单的 3 步低通滤波器<strong class="kh ir">来平滑数据，我用前 100 帧创建了一个动画，大约 1/5 秒。</strong></p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/78b21503d8c036a64bbe2c2894474660.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/1*NheLPLB5JdUNyjrH6TA1og.gif"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk">Activations of the 32 electrodes in the first 1/5 of second.</figcaption></figure><p id="23ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还可以将时间数据可视化为 2D 热图，其中纵轴是时间(从顶部开始向下)，横轴表示 32 个电极。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/c8d0e3e853c61b3d244a78dbc89e4170.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*kOXssRWPirXIwpcb8t1Vaw.png"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk">EEG temporal heatmap. (time starts from top and goes down)</figcaption></figure><p id="c89a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这也非常有用，因为正如我们将看到的，它将允许我们使用<strong class="kh ir">时空卷积</strong>。</p><h1 id="f225" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">数据预处理</h1><p id="8fea" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">这些原始数据应该进行预处理，以适应学习阶段。例如，与所执行的动作的相对低的变化率相比，EEG 的非常高的采样频率会导致许多问题:数据变化非常快，但是动作实际上保持不变，因此波动几乎可以被认为是噪声。此外，时态模型会接收大量快速变化的数据，而分类输出从不改变。</p><p id="cb8b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第一个可能的步骤是用低通滤波器对数据进行<strong class="kh ir">滤波。即使简单的移动平均也是可行的:通过这种方式，我们减轻了数据的高频变化，同时保留了更有用的低频结构，因为我们将分类的运动具有非常低的变化频率(最多 1Hz)。之后，我们可以<strong class="kh ir">对数据</strong>进行二次采样，即我们可以每 10、100 等只保留一个数据点。这也有助于减少时间维度，降低数据的相关性，在某种意义上使其更加时间稀疏。</strong></p><p id="17ab" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以采用许多其他预处理技术，但是为了简单起见，我们可以在这里停下来，开始设计我们的神经网络。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/a894229da0cd8f95006b5d752de76816.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*7hriG1eVkwqI6hXcsPNHDA.gif"/></div></figure><h1 id="7141" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">神经网络设计和实验</h1><p id="a2da" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">处理时态数据时，我们首先想到的架构之一是<strong class="kh ir">递归神经网络。</strong>这些网络具有动态结构，因此内部状态允许它们对时间数据进行编码，因此它们也基于过去的输入来计算输出。我在 Keras 设计了一个<strong class="kh ir"> LSTM 网络，用时序结构给它输入训练数据。结果很好，但在这个特殊的例子中，我更感兴趣的是展示一个常用于图像的<strong class="kh ir">卷积神经网络</strong>如何能够很好地处理时态数据。</strong></p><p id="7b3f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如前所述，在某种意义上，我们实际上是在处理时空数据:上面显示的热图的垂直轴代表时间演变，而水平轴显示各种电极，并且接近的电极几乎总是在人类头皮上空间上接近。这意味着我们实际上可以用卷积提取有用特征:2D 核可以对时间和空间中的模式进行编码。想象一个<strong class="kh ir"> 3x3 卷积核</strong>:它能够在热图中描绘的矩阵上，通过对三个不同的时间步长(3 个核行)以及三个不同的电极(3 个核列)进行加权求和来提取特征。因此，具有许多内核的 CNN 可以<strong class="kh ir">发现电极的激活如何在有限的时间周期内相对于期望的运动而变化的特征</strong>。</p><p id="b227" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我在 Keras 中实现了一个简单的 CNN 来检查它在这个数据集上的性能。你可以在<a class="ae lb" href="https://colab.research.google.com/drive/1lDfmXMo7_mcVBo9EAtgLNIgeJV50GTce#scrollTo=AFoTOqC-4Rjl" rel="noopener ugc nofollow" target="_blank">这个在线合作笔记本</a>中找到这篇文章的所有代码，你可以直接在你的浏览器上运行它。下面是<a class="ae lb" href="https://github.com/normandipalo/eeg-to-action" rel="noopener ugc nofollow" target="_blank"> GitHub 回购</a>。</p><pre class="ld le lf lg gt nj nk nl nm aw nn bi"><span id="a16c" class="no lu iq nk b gy np nq l nr ns">import keras<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Dropout<br/>from keras.layers import Embedding<br/>from keras.layers import LSTM, CuDNNLSTM, BatchNormalization, Conv2D, Flatten, MaxPooling2D, Dropout<br/>from keras.optimizers import Adam</span><span id="0408" class="no lu iq nk b gy nt nq l nr ns">model = Sequential()<br/>#model.add(CuDNNLSTM(128, input_shape = (time_steps//subsample, 32)))<br/>model.add(Conv2D(filters = 64, kernel_size = (7,7), padding = "same", activation = "relu", input_shape = (time_steps//subsample, 32, 1)))<br/>model.add(BatchNormalization())<br/>#model.add(MaxPooling2D(pool_size = (3,3)))<br/>model.add(Conv2D(filters = 64, kernel_size = (5,5), padding = "same", activation = "relu", input_shape = (time_steps//subsample, 32, 1)))<br/>model.add(BatchNormalization())<br/>#model.add(MaxPooling2D(pool_size = (3,3)))<br/>model.add(Conv2D(filters = 64, kernel_size = (3,3), padding = "same", activation = "relu", input_shape = (time_steps//subsample, 32, 1)))<br/>model.add(BatchNormalization())<br/>#model.add(MaxPooling2D(pool_size = (3,3)))<br/>model.add(Flatten())<br/>#model.add(Dropout(0.2))<br/>model.add(Dense(32, activation = "relu"))<br/>model.add(BatchNormalization())<br/># model.add(Dropout(0.2))<br/>model.add(Dense(6, activation = "sigmoid"))</span><span id="01b1" class="no lu iq nk b gy nt nq l nr ns">adam = Adam(lr = 0.001)</span><span id="aedb" class="no lu iq nk b gy nt nq l nr ns">model.compile(optimizer = adam, loss = "categorical_crossentropy", metrics = ["accuracy"])</span><span id="1066" class="no lu iq nk b gy nt nq l nr ns">model.summary()</span></pre><p id="1c20" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了检查我们模型的性能，正如 Kaggle 竞赛中所建议的，我们检查了<strong class="kh ir"> AUC 分数</strong>。如果你不熟悉 AUC 是什么，我建议<a class="ae lb" href="https://datascience.stackexchange.com/questions/806/advantages-of-auc-vs-standard-accuracy" rel="noopener ugc nofollow" target="_blank">这个清晰直观的解释</a>。您可以在在线笔记本中自行查看，通过快速培训阶段，我们可以达到 0.85 左右的 AUC 分数。</p><p id="8e50" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">通过训练不同的神经网络架构以及预处理技术等，可以实现许多改进，但这种概念的介绍性证明显示了神经网络从这种数据中学习的显著能力。</p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/67a4e6a648f97d2888d944855f4c3801.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/1*qKQWngYH90EvzOQ-ka693w.gif"/></div></figure><h1 id="81ed" class="lt lu iq bd lv lw lx ly lz ma mb mc md jw me jx mf jz mg ka mh kc mi kd mj mk bi translated">结论</h1><p id="b073" class="pw-post-body-paragraph kf kg iq kh b ki ml jr kk kl mm ju kn ko mn kq kr ks mo ku kv kw mp ky kz la ij bi translated">在这篇文章中，我们介绍了脑电图的脑电信号，这是一种非侵入性和相对简单的记录用户头皮有用信号的方法。我们看到了一些数据的直观可视化，以及如何使用神经网络从中提取运动意图等特征。我相信，由于深度学习，更广泛的各种数据科学技术，平台和逐年增长的竞赛，这个领域(机器人假体，脑机接口)将有一个深刻的推动。</p><p id="ab2c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这些技术的影响将是巨大的。拥有可以以自然方式控制的低成本假体可以极大地改善数百万人的生活。</p><p id="8e3e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我建议你去看看<a class="ae lb" href="https://medium.com/symbionic-project" rel="noopener">symbion 项目</a>，这是一个最近开始的项目，一些有才华的人试图拼凑一个<strong class="kh ir">低成本、智能手臂假体</strong>，可以通过肌肉激活来控制，以真正实现这种设备的大众化。</p><p id="e9a7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在推特上关注我的工作更新和更多:<a class="ae lb" href="https://twitter.com/normandipalo" rel="noopener ugc nofollow" target="_blank">https://twitter.com/normandipalo</a></p><figure class="ld le lf lg gt lh gh gi paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="gh gi nv"><img src="../Images/61bc0c3e28e5fc7ac2d5218927d47721.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2evqMZXfZYO-ZY_njBzJrQ.png"/></div></div></figure></div></div>    
</body>
</html>