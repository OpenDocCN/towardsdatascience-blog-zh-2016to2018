# 人工智能入门终极指南

> 原文：<https://towardsdatascience.com/the-ultimate-guide-to-starting-ai-d506255d7ea?source=collection_archive---------3----------------------->

## 如何开始您的项目的逐步概述

![](img/a0e7a691c0fd94bcc05d61418cead0ea.png)

许多团队试图通过[在计算出期望的输出和目标之前钻研算法和数据来启动一个应用人工智能项目。](http://bit.ly/quaesita_first)不幸的是，这就像在纽约市的公寓里养了几年小狗，然后惊讶于它不能为你放羊。

> 你不能指望在没有你首先做出一些努力的情况下，让巫师在你的业务上洒下机器学习魔法，从而获得任何有用的东西。

相反，第一步是给*的主人*——也就是你！—形成一个清晰的愿景，你想从你的狗(或 [ML/AI](http://bit.ly/quaesita_ai) 系统)那里得到什么，以及你如何知道你已经成功地训练了它。

我的[上一篇文章](http://bit.ly/quaesita_first)讨论了 [**为什么**](http://bit.ly/quaesita_first) ，现在是时候深入**如何**为 [ML/AI](http://bit.ly/quaesita_ai) 做这第一步，及其所有血淋淋的小步骤。

这份参考指南篇幅很长，所以在两分钟的速成课程中，请随意使用大字体和大标题，或者直接阅读概要[清单版本](http://bit.ly/quaesita_realitycheck)。这是目录:

*   **搞清楚谁是负责人**
*   **确定用例**
*   做一些现实检查
*   **明智地制定绩效指标**
*   **设定测试标准，克服人为偏见**

**角色阵容:**决策者、伦理学家、ML/AI 工程师、分析师、定性专家、经济学家、心理学家、可靠性工程师、AI 研究员、领域专家、UX 专家、统计学家、AI 控制理论家。

![](img/b58cf98ae6597a68881d9e6606c9ae2d.png)

Make sure the right person is tasked with the first step in machine learning and AI. More info [here](http://bit.ly/quaesita_roles) and [here](http://bit.ly/quaesita_first).

# 弄清楚谁是负责人

我们将要处理的任务是项目负责人的责任。那是谁说了算。如果博士研究员被选中担任这个角色，应该是因为那个人的决策能力和对你的业务的深刻理解。如果你打算让他们扮演这个角色，然后事后再去猜测他们，那你就选错了人。我们称之为*决策者*的实体(可能是一个人或一个委员会)应该拥有最终发言权。明智地选出你仁慈的独裁者。

> 如果决策者是你打算事后批评的人，那你就做错了。

如果决策者不精通决策的艺术和科学，有一个解决办法:让他们与定性专家配对。但如果负责人不了解你的业务，你还不如现在就把这些现金冲走。

![](img/baa83a7b86288e6eba576b8bf5b8aaff.png)

# 识别用例

## 关注输出

关键是 [ML/AI](http://bit.ly/quaesita_ai) 不是魔法，也不能解决所有问题。这是一个[的东西标签](http://bit.ly/quaesita_simplest)，它取决于你[找出](http://bit.ly/quaesita_island)你需要什么标签。

[事物标签](http://bit.ly/quaesita_simplest)不仅仅意味着分类——“这是不是一只猫的照片？”—这是不够大的想法。我说的标签是指输出。可能是一个[类别、](http://bit.ly/quaesita_slkid)一个数字、一个句子、一个波形、一个[组 ID](http://bit.ly/quaesita_unsupervised) 、一个单一动作、一个操纵杆移动、一系列动作、关于某个事物是否异常的 Y/N…[如此多的可能性](http://bit.ly/quaesita_island)！

> 在你确定你需要他们之前，不要雇佣那个博士导师。首先关注输出。

如果你读了我最近写的关于算法如何工作的文章，你会注意到，这篇文章理所当然地认为，给几杯茶贴上卡西喜欢或不喜欢的标签是值得的。谁同意用那个愚蠢的用例浪费大家的时间？！它对业务有何帮助？这个分类器应该存在吗？假设它能工作，它值得建造吗？

这就是你现在正在做的工作，我的朋友。这是第一份工作。

> 仅仅因为你能做某事，并不意味着它是对任何人的时间的很好的利用。

想象一下你的 ML/AI 系统正在运行，问问你自己，你是否乐意投入公司的资源来制造它。没有吗？继续头脑风暴。最好在几个博士在你的应用上浪费生命之前发现没人需要你的应用。

这项任务可能会很难，因为有太多的选择，所以坐在舒适的沙发上冥想吧。如果你需要一些头脑风暴的帮助，试试我的[醉酒岛](http://bit.ly/quaesita_island)练习。

A [video](https://www.youtube.com/watch?v=ksA_AVl0rMY&list=PLRKtJ4IpxJpDxl0NTvNYQWKCYzHNuy2xG&index=17) with my trick for brainstorming AI use cases.

## 现在不是输入的时候

你们中的一些决策者对数据非常熟悉。你可以同时谈论输入和输出……你会明白其中的区别。我的建议可能会让你大吃一惊:抵制诱惑！先别说投入。说真的。我知道你可以，但是不要。这里有许多原因中的两个。

***原因一:错过机会***

这是显而易见的。你的一些利益相关者没有你流利，他们很容易混淆。在早期，你可能向他们推销你的想法，希望为你的项目获得资源，你真的不想让他们误解为什么你的系统值得拥有。不要混淆他们！保持专注。告诉他们它是做什么的，而不是怎么做的。

> 问问自己，“这是目的还是手段？”如果是手段的话，暂时不谈。

许多流利的人的问题是，你认为每个人都和你一样流利。一些科技领域的绝顶聪明的人不具备这种技能让我感到惊讶，所以我现在知道不要想当然。

对某些人来说，数据就是数据。都一样。(亲爱的读者，如果你不确定自己在这方面是否流利，真的要强迫自己放慢速度。不断问自己“这是目的还是手段？”确保你现在把注意力集中在末端。)利益相关者可能无法跟上你的论点，这意味着你的推销会失败，你会错过用人工智能让世界变得更美好的机会。

![](img/4e24aa16c01dd1922801d861eed2108c.png)

Some folks have trouble figuring out which variable is the input and which one is the output… it all looks like one big confusing lump to them and they need your focus to appreciate why the outputs are worth having.

***原因二:默契***

作为一名在工程师身边工作了很长时间的工程师，我注意到我们这类人喜欢抓住细节。去他妈的大局观吧，从每一个细节中剔除填料是如此有趣，尤其是当有人在某件事上犯了错误的时候！我们喜欢技术上的正确性。

![](img/e0ba39f8520950bcad4bdd83e947fc33.png)

I, for one, have to be on my guard against getting caught up in the technical correctness of minutiae. Joke: Technically correct is the best kind of correct. Tautologically correct is a kind of correct.

这是一出悲喜剧:当你花了 6 个小时和你的朋友争论变量 *x* (原始的，标准化的，还是规范化的？)是一个很好的输入，具有预测输出 *y* 的合适日志，你已经，咳咳，规范化了 *y* 值得追求的想法。你首先停止质疑工作的意义，并最终构建了不需要构建的东西。

## 这是关于拥挤的人群

让我们想象一下，自动给[茶](http://bit.ly/quaesita_tea)贴 Y/N 标签是你想要的用例。确保你不是在考虑只给一两个杯子贴标签。 [ML/AI](http://bit.ly/quaesita_ai) 对于自动化*许多*重复的决策是有意义的。这不是一次性的。

> ML/AI 不是一次性的，所以确保你的企业需要大量的标签。

你在想象给至少几千个贴上标签？当这东西是活的，你确定你不能只是查找答案而不是预测它们？很好。我们继续。

![](img/cab4994d8c0fd749a7b25cc1fac2b44d.png)

拿起笔，写下你会接受的标签(本练习中的二进制 Y/N 很容易写下来，但如果你需要创意，你可以选择让它们[更有异国情调](http://bit.ly/quaesita_island))。写下你如何知道其中一个答案是否正确。写下错误的样子。期待机器学习中的错误！如果你期待完美无缺，最好在失望击垮你的灵魂之前安静地后退。

## 你可能还没有准备好机器学习

还在苦苦寻找用例？考虑暂停 [ML/AI](http://bit.ly/quaesita_ai) ，支持[分析](http://bit.ly/quaesita_analysts)一段时间。分析的[目标](http://bit.ly/quaesita_datasci)是为决策者产生灵感。一旦你有了灵感，你可以回到 [ML/AI](http://bit.ly/quaesita_ai) 重新开始。[分析](http://bit.ly/quaesita_roles)(又名数据挖掘)对每个项目来说都是一个好主意，而 [ML/AI](http://bit.ly/quaesita_roles) 只适用于那些目标是使用数据来自动标记事物的项目。尽管基本的数学原理通常是相同的，但是过程是非常不同的。[数据挖掘](http://bit.ly/quaesita_roles)是关于[最大化发现速度](http://bit.ly/quaesita_analysts)，而 [ML/AI](http://bit.ly/quaesita_datasci) 是关于自动化的性能。在数据挖掘中，你的团队只会犯一个错误，而 ML/AI 有一个令人印象深刻的潜在错误列表。只有当你有一个值得麻烦的用例时，才注册那些令人头疼的问题。

## 是给谁的？想想你的用户！

你耀眼的发明是给谁看的？谁受益？这是一个咨询 UX(用户体验)专家和规划应用程序目标用户的好时机。

> 构思新技术通常从“是什么”开始，但在着手“如何”之前，先了解“是谁”是很重要的。

通过与 UX 设计师相处，我学到了一些东西，那就是我下意识地描述我的用户是谁……通常是相当天真的。我是否考虑过对间接受益者的可用性，对整个社会的可用性，对其他企业的可用性，对使用输出作为输入的机器系统的可用性，对从事调试的工程师的可用性等等？为了避免粗制滥造的 UX 设计，在你继续之前，请花点时间考虑一下你所有的用户类别。用户不仅仅指最明显意义上的客户或最终用户。

## 继续下去合乎道德吗？

如果你的想法并不是对每个人都有好处呢？在规划您的理想用例时，考虑那些可能因为您的系统的存在而受到伤害的人。我不仅仅是指你所在行业的竞争对手。你的应用会伤害到任何人吗？如果你的技术发展到数百万或数十亿，这一点尤其重要。

> 想想你的创造所影响的人类！谁受益，谁可能受损？

如果你关心以道德和负责任的方式开发技术，你有责任考虑你的创造可能影响的所有人。在建成后再去想它们*是不负责任的。现在是*的时间*！伦理学家可以帮你分担一些负担。如果你的项目有可能对人类福祉产生重大影响，让他们成为你的顾问是个好主意。与你的 UX 专家一起，他们对这个项目的参与将帮助你确保受你的创作影响的群体有发言权。*

# 做一些现实检查

一旦你能清楚地说出你想要的标签，是时候做一个快速的现实检查了:你有关于这个商业问题的数据吗？

无法访问数据意味着没有任何意义。不过，你或许可以在网上找到你需要的东西——免费获取数据的趋势正在上升(例如这里的)。

尽管如此，它仍然是相关的。你知道你不能用*我的* [Marmite](http://bit.ly/marmitebean) 消费模式(定义:大数据)来预测*你的*血糖水平。明明没用的数据不算。你还不需要分析数据(这将在项目的后期进行),但是你应该检查到时候你是否真的有东西可以分析。没有数据意味着没有 [ML/AI](http://bit.ly/quaesita_ai) 。

> 无法访问相关数据或没有计算机来处理这些数据？没有什么好的方式来说这个…

![](img/e45cb783b49a916995ce3b378e314c1d.png)

This is your dream of [ML/AI](http://bit.ly/quaesita_ai) if you have no data.

你还需要证明你有处理数据的计算能力。(听说过[我的雇主](http://bit.ly/gcp-hello)吗？他们有很多，而且他们喜欢分享 T21。只是说说而已。)

## 现实清单

请确保您对所有这些问题的回答都是肯定的。这些中的每一个都可能在以后得到自己的指南，敬请关注。这只是一个快速概述的问题，以确定一个不成功的人。

*   ***合适的任务:*** 你是否自动化了很多决策/标签？你不能每次都完美地找到答案。
*   ***合理期望:*** 你是否明白你的系统可能很优秀，但它不会完美无瑕？你能忍受偶尔的错误吗？
*   ***生产中可能:*** 不管那些决策/标签来自哪里，你能在生产中为它们服务吗？你能聚集工程资源以你预期的规模来做吗？当你和工程师们坐下来的时候，你会更详细地研究这个问题，但是现在，一丝理智检查就足够了。
*   ***要学习的数据:*** 是否存在潜在有用的输入？你能接近他们吗？(如果数据还不存在也没关系，但是你有一个很快就会得到它们的计划。)
*   ***足够多的例子:*** 当你和你的[统计学家或机器学习工程师](http://bit.ly/quaesita_roles)哥们一起喝饮料时，你不经意地提到了可用的例子数量以及你想要的输出类型，他们的表情是不是没有一丝不悦？(我会在以后的文章里教你如何自己培养这种直觉。)
*   ***计算机:*** 您有足够的处理能力来处理您的数据集吗？([云技术](http://bit.ly/gcloudpstart)使得这对于任何愿意考虑使用它们的人来说都是一个自动的肯定。)
*   ***团队:*** 你有信心组建一个拥有[必备技能](http://bit.ly/quaesita_roles)的团队吗？
*   ***地面真相:*** 除非你是在[无监督学习](http://bit.ly/quaesita_unsupervised)之后，你有权限输出吗？如果没有，你能付钱让人类通过执行任务为你制造它们吗？
*   ***日志健全性:*** 可以区分哪个输入与哪个输出，对吗？
*   **(学习榜样，需要好的榜样来学习。)**

## 集合你的队伍

一旦你清除了现实清单，是时候开始招聘了，你可以在阅读本指南其余部分的同时进行招聘。我对你正在寻找的角色的建议是[这里](http://bit.ly/quaesita_roles)。

![](img/249be5b19ed46f5e3825fdb13e230db9.png)

# 明智地制定绩效指标

## 拥有权衡

如果你是新手，接下来的部分可能会有点棘手。你负责决定每种结果的价值。得到 Y 的那杯恶心的茶是我们错过的那杯美味的两倍吗？3.4823 倍？由你决定！

挣扎？找一个喜欢数字的人，让他们帮你集思广益。[定性专家](http://bit.ly/quaesita_roles)接受过这方面的专门训练，但必要时你的标准计算器也能胜任。如果你想要最好的帮手，大声说出它的正式行话(*引出无差异曲线*)来召唤一个经济学家。

> 经济学家是人工智能项目令人惊讶的有用顾问。

既然你已经知道了如何在**一个**单个输出上权衡各种结果，是时候考虑一下你想如何一次获得几千个结果了。用平均是平均的选择，但你不必平均。再说一遍，决策者是这里的老板。正确的评分方法取决于什么适合您的企业。

## (可选)专家模式侧重于模拟

棘手、复杂的项目从*模拟*中受益匪浅。这就是专门生成虚假但可信数据的[分析师](http://bit.ly/quaesita_analysts)可以帮助你看到你在这篇文章中所做选择的潜在后果的地方。

> 彩排有助于开幕夜的顺利进行。

模拟给你一次彩排，帮助你在真正开始你的项目之前解决一些问题。像[分析](http://bit.ly/quaesita_analysts)一样，它减轻了决策者努力沉思和考虑一切的任务负担。

## 制作您的度量标准

有许多不同的方法来制定指标。在我们的茶的例子中，你可以选择非常简单的一个:**准确性**又名*“不要出错。”每一个错误都同样糟糕(0)，每一个正确的回答都同样好(1)，然后你取一个平均值(这是你一直渴望得到的——有人需要对人们发现平均值的吸引力设定一个[中心限制](http://bit.ly/clt_wiki))。*

![](img/5bca7160bf44b3c6be2dac759aaab5b7.png)

等等，也许当谈到好茶时，你有 FOMO，而且你很高兴一路上都有次品？这是一个不同的指标，叫做**召回**。或者也许你不想浪费时间，你需要确定当系统说美味时，它真的值得喝，但是你可以接受错过美味的茶。这是一个完全不同的指标，叫做**精度**。我们将在另一篇文章中放慢速度，深入探讨度量标准。现在，不要管它们叫什么，只要想出一个适合你业务的就行了。

需要帮助吗？你的经济学家已经迷路了吗？没问题！也许你有一个喜欢设计游戏的朋友？游戏极客们在不知不觉中已经为这个训练了一生！如果你不和那群人混在一起，你可以打电话给你的定性专家，因为他们的工作是帮助决策者澄清他们对这类事情的想法。

## 请求专家评审

在人类福祉受到严重威胁的应用中，寻求专家小组的咨询，以验证不可能以某种反常和有害的方式在您的指标上获得高分。

哪些专家？你听说过这样一个故事吗，一个决策者、一个伦理学家、一个人工智能控制理论家、一个统计学家、一个用户体验研究员、一个行为经济学家、一个领域专家和一个可靠性工程师走进一个酒吧……

当然，这对于良性的商业应用程序来说可能有些过头了，所以你的定性专家对这些学科的入门水平的熟悉已经涵盖了你，你的游戏设计师朋友的直觉也在利用类似的脉络。

## 你好，业务绩效指标！

当你完成后，你会听到天使的合唱。您已经创建了您的业务绩效指标！

![](img/e509299d9b6b7ee6994c2db57030f95c.png)

这和一个[损失函数](http://bit.ly/quaesita_emperor)不是一回事(后面会讲到那些)。当谈到指标时，可能性是无限的，这取决于决策者来找出什么是真正重要的。如果您对解决这个问题感到焦虑，我正在酝酿更多的文章来帮助您掌握度量开发。

## (行话触发警告)你的人工智能专家应该知道的事情

这里有一个微妙的东西，你可以跳过，直到我们在后面的帖子中深入探讨，但如果你知道什么是[损失函数](http://bit.ly/quaesita_emperor)，那么你就会意识到我们将有*两个*指标在发挥作用。如果这对你来说毫无意义，我们现在不必担心，你在这里的工作只是确保你的 ML/AI 专家阅读下一段。他们中的许多人在学校错过了这一课。 ***警告:*** 很多决策者会发现，它读起来就像一个行话——胡言乱语的噩梦——我很抱歉！—那就转发吧。

> 损失函数是为了优化，而不是为了测试。

“在应用 ML/AI 中，[损失函数](http://bit.ly/quaesita_emperor)用于优化，而非统计测试。[统计测试](http://bit.ly/quaesita_statistics)应该问，*“它的性能是否足以构建/发布？*在哪里*执行*应该由业务问题及其所有者定义。你不应该改变业务问题陈述来满足你的凸优化野心。为了方便起见，您可以使用标准损失函数进行优化，该函数与您的领导者的想象刚刚产生的函数方向相同(通过分析或模拟执行相关性检查),但请使用*测试他们的*函数。**您是否在所有评估中都使用了损失？别担心，这是一个常见的错误，可能与软件默认设置、大学课程格式以及人工智能中的决策者缺勤有关。”

**如果没有标准损失函数与性能指标适当相关，请提醒您的决策者，他们的要求非常困难，可能需要投资优化研究人员。

**持异议的 AI 专家，看[这个](http://bit.ly/quaesita_incomp)。尽管这与职能无关，但与决策者合作的一般理念是适用的。

# 设置测试标准

## 定义您感兴趣的人群

谈论你的系统“工作”是没有意义的，除非你指定你打算让它在哪个[实例](http://bit.ly/quaesita_slkid)上工作。所有美国夏季投入？全球所有输入？(这些不一样！)

在您继续之前，您需要定义您感兴趣的统计[群体](http://bit.ly/quaesita_popwrong)，您的系统在您给它开绿灯之前需要展示良好性能的[实例](http://bit.ly/quaesita_slkid)的广泛集合。我为你准备了一份由两部分组成的[指南](http://bit.ly/quaesita_savvy)，以防你需要复习一下。

## 承诺粉碎它！

现在，您已经准备好了性能指标和人口，在您可以开始工作之前，您还有一项工作要做。因为到达这里需要几个月的时间，你可怜的脚一定很疼。

这是最后一项任务:决定你愿意签字同意的最低表现，因为我要让你承诺，除非它足够好，否则你不会让这个系统替你标记东西。

![](img/36a4385ae126b128752be2f72db33863.png)

Setting a bar for testing the system is a responsibility the decision-maker should take very seriously. (Image: Maria Fernanda Murillo winning a high jump competition, credit: Diego Sinisterra)

“足够好”是什么意思？你应该设定多高的标准？由你决定，但是你现在必须做出承诺。

> 预先设定标准是你如何让自己(和我)免受可怕的机器学习和人工智能伤害的一部分。

这个标准不是一个指导星。你也可以告诉你的团队要达到的绩效水平。)，但这不是你将要测试的。测试最低限度。

## 你对物种有偏见

你为什么在组建这个项目的团队之前，现在就提出这个截止日期？事实证明，作为人类物种的一员，我们受到一些可爱的认知偏见的困扰(不要说*沉没成本*或*禀赋效应*或*确认偏见*除非你希望那个经济学家再次凭空出现，这次是带着一个心理学家),这些偏见可以归结为:当人类在某件事情上投入时间和精力时，我们会爱上我们所做的事情……即使它是一堆有毒的垃圾。然后我们发现自己在讨价还价:*“Awww 但是性能也没那么差。我为 12%的准确率感到自豪。或许我们可以发射它？为什么我不针对 10%进行测试？看到了吗？它过去了。真是*[](http://bit.ly/quaesita_statistics)**够好了”**

*如果你想再跟我在这个悲伤的话题上纠缠 6 分钟，我有什么资格阻止你？*

> *我们人类爱上了自己倾注心血的东西……哪怕是一堆有毒的垃圾。*

*趁我们还清醒(！)在我们投入大量精力之前，我们会冷静、认真地审视一下业务问题，然后说:*“如果它不满足* ***这个最低*** *要求，我*保证*它会死掉。”**

*![](img/3d115531efa9622699d3c0aaf77d2909.png)*

## *比人类好？*

*我希望你现在能明白，为什么当人们问我“人工智能在某些方面比人类强吗？”时，我不得不忍俊不禁*

> *比人类好？同义反复是同义反复。*

*如果它的制造者要求它比人类更好，并且做了适当的测试，那么如果它不比人类更好，他们就碾碎它。如果存在，那么是的。除非他们不要求它比人类更好，在这种情况下，它可能不是。为什么有人问*我*？询问那些决策者他们是如何建立标准和测试的。(说到[种群](http://bit.ly/quaesita_incomp)，*它应该比哪个*人类强？那个志愿者吗？)*

*![](img/41f43a2d1c207c10f0d8b156440bf8eb.png)*

*此外，我们不要太在意机器在某些方面是否比我们更好。我的电脑总是比我更擅长…做乘法。这一点也不困扰我。我的水桶比我更会盛水。如果一个工具不能减少你的努力或者增加你所能达到的成就，那它还有什么意义呢？*

*而是关注它是否好到有用。*

## *不要要求太高*

*总是要求比人类更好的表现可能会让你失去利润。这有点像说你只会雇一个奥运金牌选手给你砌砖。也许一名奥运选手比你的普通人乔更强壮，但是如此严格的招聘标准可能会让你没有工人。把你的标准降低到对商业有益的程度，但不要更低。经济学家可能会说，将测试标准设定在最低水平是与激励相容的，T21。(如果你刚从商学院毕业，想对机制设计感兴趣，我们实际上正在为我们的假设检验程序建立一个 [BDM 拍卖](http://bit.ly/wiki_bdm)。)*

> *不要因为测试门槛过高而错过有利可图的解决方案。*

*有时自动化生产的产品单位质量比手工生产的低，但是机器的规模和速度使它在商业上是值得的。为了*你的*事业值得吗？嘿，你说了算，不是我。祝你好运！*

*有关该长文本的简短总结，请参见[清单版本](http://bit.ly/quaesita_realitycheck)。*

*![](img/796d9ae7e7b9949f1ae53aea6899207f.png)*

*这就是 [ML/AI](http://bit.ly/quaesita_ai) 完成的第一步！第二步涉及数据和硬件(以及工程师！)所以你可能想[温习一些词汇](http://bit.ly/quaesita_slkid)以期待即将到来的景点。*

*如果你觉得本指南中的任何想法都有价值，请告诉你网络中最有可能发现自己处于决策角色的人。让我们为一个光明的人工智能未来建立一批有技能和负责任的人工智能领导者！*

# *感谢阅读！YouTube 课程怎么样？*

*如果你在这里玩得开心，并且你正在寻找一个为初学者和专家设计的有趣的应用人工智能课程，这里有一个我为你制作的娱乐课程:*

*Enjoy the entire course playlist here: [bit.ly/machinefriend](http://bit.ly/machinefriend)*

# *喜欢作者？与凯西·科兹尔科夫联系*

*让我们做朋友吧！你可以在 [Twitter](https://twitter.com/quaesita) 、 [YouTube](https://www.youtube.com/channel/UCbOX--VOebPe-MMRkatFRxw) 、 [Substack](http://decision.substack.com) 和 [LinkedIn](https://www.linkedin.com/in/kozyrkov/) 上找到我。有兴趣让我在你的活动上发言吗？使用[表格](http://bit.ly/makecassietalk)取得联系。*