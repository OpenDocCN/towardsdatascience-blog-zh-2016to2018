<html>
<head>
<title>Upgrade your Image Classifier with Balanced data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用平衡数据升级您的图像分类器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/upgrade-your-image-classifier-with-balanced-data-ddea93859c0f?source=collection_archive---------6-----------------------#2018-12-23">https://towardsdatascience.com/upgrade-your-image-classifier-with-balanced-data-ddea93859c0f?source=collection_archive---------6-----------------------#2018-12-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="1e70" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">预处理和分层如何对图像分类器的性能产生奇迹</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f5f13088491dd498b56a4eded95e1aef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_kVRzmLhSNjqvZNL.jpg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">FER</figcaption></figure><p id="2b97" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">本文将带您了解数据管理技术，以完善图像分类器的机器学习模型，特别是面部情感识别。包含源代码的 R notebook 可以在 GitHub 链接<a class="ae lr" href="https://github.com/nishnab/Machine-Learning-and-Data-Visualization-Projects" rel="noopener ugc nofollow" target="_blank">这里</a>找到</p><p id="7386" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这个项目中，“面部情感识别”数据集，来自 Kaggle 竞赛<a class="ae lr" href="https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data" rel="noopener ugc nofollow" target="_blank"> <strong class="kx ir">表征学习中的挑战:面部表情识别挑战</strong> </a> <strong class="kx ir"> </strong>被使用。该数据由 27000 幅训练图像(48×48 像素的面部几乎居中，使得所有面部在图像中的相等空间上延伸)和包含 9000 幅图像的测试集组成。这是一个分类任务，将每张图片分为七类(0 =愤怒，1 =厌恶，2 =恐惧，3 =快乐，4 =悲伤，5 =惊讶，6 =中性)。</p><p id="0f49" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我尝试了几种算法，包括最近邻、贝叶斯分类器、决策树和神经网络，为这项任务建立机器学习模型。但是，他们中没有一个人的回报率超过 30%。这让我想知道哪里出了问题，以及如何以不同的方式完成这项任务。最近我看到了一篇<a class="ae lr" href="https://medium.com/neuralspace/kaggle-1-winning-approach-for-image-classification-challenge-9c1188157a86" rel="noopener">文章</a>，作者是<a class="ae lr" href="https://www.kaggle.com/c/plant-seedlings-classification" rel="noopener ugc nofollow" target="_blank">植物幼苗分类挑战赛</a>的一位顶级选手，文章建议读者在对图像进行分类之前，先处理不平衡的分类问题。</p><p id="25f4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这篇文章中，我将解释如何使用干净平衡的数据和可视化，用决策树算法构建一个更好的图像分类器。</p><p id="7b57" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">第一步:浏览数据</strong></p><p id="2c1a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在可视化数据集中每个类的分布时，我们知道数据集是严重不平衡的。</p><blockquote class="ls"><p id="d6a0" class="lt lu iq bd lv lw lx ly lz ma mb lq dk translated">如果类不是近似相等的，则数据集被描述为不平衡的。[1]</p></blockquote><figure class="md me mf mg mh kk gh gi paragraph-image"><div class="gh gi mc"><img src="../Images/508142fff4c832e4c1107e78588238ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/1*dM1Voee-zAbrGxBnm4nEJQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Distribution of classes</figcaption></figure><p id="c2b8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">有超过 7000 张“快乐”的图片，而“厌恶”的图片不到 500 张。这将导致有偏差的分类器将大多数图像预测为多数类。</p><blockquote class="ls"><p id="6e75" class="lt lu iq bd lv lw lx ly lz ma mb lq dk translated">决策树和逻辑回归等流行算法偏向于数据集中的大多数类[2]</p></blockquote><p id="d036" class="pw-post-body-paragraph kv kw iq kx b ky mi jr la lb mj ju ld le mk lg lh li ml lk ll lm mm lo lp lq ij bi translated">为了理解算法的复杂性，我应用了技术<a class="ae lr" href="https://lvdmaaten.github.io/tsne/" rel="noopener ugc nofollow" target="_blank">t-分布式随机邻居嵌入</a> (t-SNE)，这被认为是可视化高维数据的最佳方法。</p><blockquote class="ls"><p id="b82b" class="lt lu iq bd lv lw lx ly lz ma mb lq dk translated">t-SNE 是一种用于相似性数据可视化的技术，能够保留数据的局部结构，同时也揭示一些重要的全局结构，例如多尺度的聚类[3]</p><p id="529e" class="lt lu iq bd lv lw lx ly lz ma mb lq dk translated">t-SNE 通过在二维或三维地图中给出每个数据点的位置来可视化高维数据[3]</p></blockquote><p id="c74f" class="pw-post-body-paragraph kv kw iq kx b ky mi jr la lb mj ju ld le mk lg lh li ml lk ll lm mm lo lp lq ij bi translated">原始数据集的 tSNE 可视化向我们展示了数据的类结构。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mn"><img src="../Images/fd735312923ec209a61cac6253fdd603.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bMJAE3_1VPTbubg2H7e3RQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">t-SNE Original Dataset</figcaption></figure><p id="1d22" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">第二步:分区</strong></p><p id="76da" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">下一步是将训练数据集划分为训练集和验证集。验证集将用于调整，最终模型将使用测试数据集进行评估</p><p id="2dea" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">第三步:创建基准分类器</strong></p><blockquote class="ls"><p id="f69b" class="lt lu iq bd lv lw lx ly lz ma mb lq dk translated">该基准为评估和比较从示例中学习的算法提供了基础。[4]</p></blockquote><p id="c749" class="pw-post-body-paragraph kv kw iq kx b ky mi jr la lb mj ju ld le mk lg lh li ml lk ll lm mm lo lp lq ij bi translated">如果我们在这个阶段创建一个基准分类器，性能将低于 27 %。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mo"><img src="../Images/bc2bf9e8c1002eca473ae0d3e3ec07e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9MidT7ZNNkR2gJGW3_0kYQ.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Benchmark Classifier Results</figcaption></figure><p id="3fa3" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">第四步:数据预处理</strong></p><p id="4c48" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在可视化一个随机实例时，很明显图像是水平对齐的，并且还存在一些噪声作为背景。</p><blockquote class="ls"><p id="da01" class="lt lu iq bd lv lw lx ly lz ma mb lq dk translated">预处理方法对从非受控环境中获取的图像进行归一化。[5]</p></blockquote><p id="87a9" class="pw-post-body-paragraph kv kw iq kx b ky mi jr la lb mj ju ld le mk lg lh li ml lk ll lm mm lo lp lq ij bi translated">因此，所有的图像首先旋转和裁剪，如下图所示。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/6475bce36c204ff0187bb6eba8af3ce2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*olVWPGdnaOVwA33LH7ljdQ.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Fig: Sample Image (i) Original (ii) Rotated (iii) Cropped</figcaption></figure><p id="0f8a" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">然后将实例居中并缩放到范围{0.8，1.2}。变换前后每个像素中的值分布可以绘制为。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/0e1d7ecdfcf58c11a82677984e78fffd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dKqulTOiIT0hDKXZMiMTgQ.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Distribution of values in each pixel</figcaption></figure><p id="56d5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">步骤 5:特征提取</strong></p><p id="206d" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">这是一个拥有 2304 个特征的高维数据集。为了降低维数，我们可以使用最广泛使用的技术 PCA。</p><blockquote class="ls"><p id="b455" class="lt lu iq bd lv lw lx ly lz ma mb lq dk translated">主成分分析(PCA)是一种统计过程，它使用正交变换将一组可能相关的变量(每个变量取不同数值的实体)的观察值转换为一组称为主成分的线性不相关变量的值。[6]</p></blockquote><figure class="md me mf mg mh kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/b18d39c8e6dbfdeb91c6d260cd8ae5ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qySxsum9BM43qa-gt25Jrw.jpeg"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">PCA Output</figcaption></figure><p id="d32f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">从主成分分析总结中可以清楚地看出，前 25 个主成分拥有超过 80%的数据。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/c2ad7427b71227d545f13f8ad4b4376f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ADV2JiD5kHZd6_Dice8t5A.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">PCA Summary</figcaption></figure><p id="d956" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">主成分分析后的 tSNE 可视化明显更好，但大多数类别的映射有点接近，没有清晰地分类。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mt"><img src="../Images/7083a7c02c62880280aa1c0b7f5a0254.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VI5noR0nEaD6pvEHPpD5fg.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">t-SNE PC 1–25</figcaption></figure><p id="2441" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">相同的预处理步骤和来自 PCA 的正交旋转被应用于验证数据和测试数据</p><p id="4eac" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">第五步:分层</strong></p><p id="3145" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在这一步中，我们将处理训练数据中的不平衡类问题。</p><blockquote class="ls"><p id="af9a" class="lt lu iq bd lv lw lx ly lz ma mb lq dk translated">SMOTE 是一种过采样方法，其中少数类通过创建“合成”样本进行过采样，而不是通过替换进行过采样[1]</p></blockquote><p id="8dd7" class="pw-post-body-paragraph kv kw iq kx b ky mi jr la lb mj ju ld le mk lg lh li ml lk ll lm mm lo lp lq ij bi translated">少数类的合成过采样(SMOTE)和多数类的随机欠采样的组合将给出良好平衡的训练数据，该训练数据然后可用于构建执行得更好的分类器。从下面新列车数据的 tSNE 可视化中可以明显看出这一点</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mu"><img src="../Images/9b338bd383593460975b5fb406acd29d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MCNsKy3FVPaJJQMiEMhAEg.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">t-SNE Balanced Data</figcaption></figure><p id="e3ea" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">第六步:分类</strong></p><p id="2155" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我们使用准备好的训练数据建立分类器。从模型的混淆矩阵中，我们可以看到整体的准确率有所提高，接近 60 %。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/80f1d0b40885f81b16cb33261790c565.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*c-w3Q5kpXnrcsPA_qjuTpg.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Confusion matrix — Classifier trained using the processed data</figcaption></figure><p id="9dd6" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">第七步:超参数调整</strong></p><p id="6e7f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">通过调整复杂性参数(cp ),我们可以减少相对误差，如下图所示</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mw"><img src="../Images/100a7da96c42721ea863166482247ca5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NhJE9V9dX6MVxCJjYisAqA.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Variation in Relative error with complexity parameter</figcaption></figure><p id="c5c4" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">第八步:建造最终模型</strong></p><p id="7f34" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">最后一步是用调整后的参数(具有最小 Xval 相对误差的 cp 值)构建最终模型，并使用测试数据对其进行评估。</p><p id="9863" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">混淆矩阵统计表明，分类器的性能有了显著提高，总体准确率超过 90 %。灵敏度、特异性等其他性能指标也更好。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/9247bee937a3383090c27cd8ba810356.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*ySC2N6xSF8f7LVFIM8UNmg.png"/></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Confusion Matrix — Final model</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi my"><img src="../Images/412d5b021ef13aec1469ff7b7ffc1920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*99-8FXAnfZj_HLR5rlvJeg.png"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Other Performance metrics comparison for various classes</figcaption></figure><p id="49c0" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">结论</strong></p><p id="5090" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">预处理、降维和平衡数据集显著提高了决策树分类器的性能，从 27%提高到 91%。使用 tSNE 可视化高维数据可以让您更好地了解类的分布，这对于预处理可用于构建更好的分类器的数据非常有帮助。</p><p id="da8c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated"><strong class="kx ir">参考文献</strong></p><p id="01ca" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[1] N. Chawla，k .鲍耶，L. Hall 和 W. Kegelmeyer，<a class="ae lr" href="https://arxiv.org/pdf/1106.1813" rel="noopener ugc nofollow" target="_blank"> SMOTE:合成少数过采样技术</a> (2002)，《人工智能研究杂志》，第 16 期，第 321–357 页。</p><p id="b3b8" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[2]客博，<a class="ae lr" href="https://www.analyticsvidhya.com/blog/2017/03/imbalanced-classification-problem" rel="noopener ugc nofollow" target="_blank">如何处理机器学习中的不平衡分类问题</a> (2017)，【博客】Analytics Vidhya</p><p id="d6c5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[3] L. van der Maaten 和 G.Hinton，<a class="ae lr" href="http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf" rel="noopener ugc nofollow" target="_blank">使用 t-SNE 可视化数据</a> (2008)，《机器学习研究杂志》，第 9 期，第 2579-2605 页。</p><p id="470e" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[4] Z. ZHENG，<a class="ae lr" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.55.6219&amp;rep=rep1&amp;type=pdf" rel="noopener ugc nofollow" target="_blank">分类器学习的基准</a> (1993)，澳大利亚人工智能联合会议。世界科学，第 281-286 页。</p><p id="13fb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[5] M.G. Sumithra 和 P. Rajeswari，<a class="ae lr" href="http://www.aetsjournal.com/journal_issues/A_Survey:_Pre_Processing_techniques_for_Facial_Expression_Recognition.pdf" rel="noopener ugc nofollow" target="_blank">A Survey:Pre Processing techniques for face Expression Recognition</a>(2015)，《信息与通信工程应用国际期刊》第 1 卷:第 1 期:2015 年 1 月，第 47–51 页，第 1(1)卷，第 47–51 页。</p><p id="e8f5" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">[6]En.wikipedia.org，<a class="ae lr" href="https://en.wikipedia.org/wiki/Principal_component_analysis" rel="noopener ugc nofollow" target="_blank">主成分分析</a> (2018)，【在线】维基百科</p></div></div>    
</body>
</html>