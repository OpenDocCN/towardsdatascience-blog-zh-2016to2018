<html>
<head>
<title>Multimodal Image-to-Image Translation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多模态图像到图像翻译</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/multimodal-image-to-image-translation-c1ffaa5d5928?source=collection_archive---------3-----------------------#2018-04-13">https://towardsdatascience.com/multimodal-image-to-image-translation-c1ffaa5d5928?source=collection_archive---------3-----------------------#2018-04-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="1bc0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这篇博客中，我将解释图像到图像的翻译，这就是通常所说的<a class="ae kl" href="https://github.com/prakashpandey9/BicycleGAN" rel="noopener ugc nofollow" target="_blank">bicle gan</a>。图像到图像转换的任务可以被认为是每个像素的回归或分类。但是可以用来解决这个问题的更有趣的方法是生成对抗网络。通过使用 GANs 获得的结果更健壮并且在感知上更真实。</p><p id="04b1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在论文“<a class="ae kl" href="https://arxiv.org/pdf/1711.11586.pdf" rel="noopener ugc nofollow" target="_blank">走向多模态图像到图像翻译</a>”中，目的是在给定输入图像的情况下生成输出图像的分布。基本上，它是使用条件生成对抗网络的图像到图像翻译模型的扩展。在 pix2pix 之前，许多人试图使用 GAN 无条件地解决这个问题，并且使用 L2 回归以输入为条件输出。除了变分自动编码器之外，我已经在我以前的<a class="ae kl" rel="noopener" target="_blank" href="/deep-generative-models-25ab2821afd3">博客</a>中解释了条件 GAN。</p><p id="e72d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在模型的第一部分，我们使用了一个条件变分自动编码器 GAN。想法是使用编码器网络学习目标图像的低维潜在表示，即，已经生成所有目标图像的概率分布，并且我们尝试该分布接近正态分布，以便在推断时间期间容易采样。接下来，我们使用一个生成器，使用编码表示 z 将输入图像映射到输出图像。</p><p id="8d27" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在图像的第二部分，我们使用了条件隐回归子 GAN。在这种情况下，从正态分布 N(z)中采样 z，除了输入图像 A 之外，该正态分布 N(z)还被馈送到生成器以获得输出图像。这个输出图像然后被馈送到编码器网络以输出 z ’,我们试图使它接近 N(z)。经过这两步，我们计算损失函数。最终损失函数如下所示:</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi km"><img src="../Images/b6b44b65cba243c4d300764fb2a656ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/0*PbDSk4R_INGyfWx4."/></div></figure><p id="a9f2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中 G、D 和 E 代表发生器、鉴别器和编码器。</p><p id="7ce3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在该模型中，从潜在向量(z)到输出图像以及输出图像到潜在向量的映射是双射的。整体架构由两个循环组成，B-&gt; z-&gt; B’和 z-&gt; B’--&gt; z’，因此得名 BicycleGAN。该图清楚地总结了该架构。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ku"><img src="../Images/baad1afa21301376e71fc54ae4b1e6bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-bbvJOhldK3pOwYc."/></div></div></figure><h1 id="cf11" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">要点:-</h1><ul class=""><li id="ef31" class="lx ly iq jp b jq lz ju ma jy mb kc mc kg md kk me mf mg mh bi translated">我们有 3 个不同的网络:a)鉴别器，b)编码器，和 c)发生器。</li><li id="eabd" class="lx ly iq jp b jq mi ju mj jy mk kc ml kg mm kk me mf mg mh bi translated">cVAE-GAN(条件变分自动编码器-生成对抗网络)被用于将地面真实输出图像 B 编码为潜在向量 z，然后潜在向量 z 被用于重构输出图像 B’，即，B-&gt; z-&gt; B’。</li><li id="b48d" class="lx ly iq jp b jq mi ju mj jy mk kc ml kg mm kk me mf mg mh bi translated">对于逆映射(z-&gt; B’--&gt; z’)，我们使用 LR-GAN(潜在回归生成对抗网络)，其中使用生成器从输入图像 A 和 z 生成 B’</li><li id="30dd" class="lx ly iq jp b jq mi ju mj jy mk kc ml kg mm kk me mf mg mh bi translated">结合这两个模型，我们得到了自行车根。</li><li id="3506" class="lx ly iq jp b jq mi ju mj jy mk kc ml kg mm kk me mf mg mh bi translated">发生器的架构与 U-net 相同，其中存在具有对称跳跃连接的编码器和解码器网络。</li><li id="1d27" class="lx ly iq jp b jq mi ju mj jy mk kc ml kg mm kk me mf mg mh bi translated">对于编码器，我们使用几个残差块对输入图像进行有效编码。</li><li id="0c93" class="lx ly iq jp b jq mi ju mj jy mk kc ml kg mm kk me mf mg mh bi translated">使用批次大小为 1 的批次规范化，使用 Adam optimizer 来训练该模型。</li><li id="2323" class="lx ly iq jp b jq mi ju mj jy mk kc ml kg mm kk me mf mg mh bi translated">泄漏 ReLU 激活功能用于所有类型的网络。</li></ul><h1 id="880e" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">履行</h1><p id="c1f4" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mn ka kb kc mo ke kf kg mp ki kj kk ij bi translated">我在 TensorFlow 中实现了 BicycleGAN，你可以在我的 GitHub 个人资料中找到它。</p><div class="mq mr gp gr ms mt"><a href="https://github.com/prakashpandey9/BicycleGAN" rel="noopener  ugc nofollow" target="_blank"><div class="mu ab fo"><div class="mv ab mw cl cj mx"><h2 class="bd ir gy z fp my fr fs mz fu fw ip bi translated">prakashpendey 9/自行车</h2><div class="na l"><h3 class="bd b gy z fp my fr fs mz fu fw dk translated">NIPS 论文“多模态图像到图像翻译”的 BicycleGAN - Tensorflow 实现</h3></div><div class="nb l"><p class="bd b dl z fp my fr fs mz fu fw dk translated">github.com</p></div></div><div class="nc l"><div class="nd l ne nf ng nc nh ks mt"/></div></div></a></div><h1 id="27c8" class="kz la iq bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">参考</h1><p id="9f3e" class="pw-post-body-paragraph jn jo iq jp b jq lz js jt ju ma jw jx jy mn ka kb kc mo ke kf kg mp ki kj kk ij bi translated"><a class="ae kl" href="https://arxiv.org/pdf/1711.11586.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1711.11586.pdf</a></p></div></div>    
</body>
</html>