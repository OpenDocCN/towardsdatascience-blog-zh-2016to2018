<html>
<head>
<title>Speed Up your Algorithms Part 2— Numba</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">加速您的算法第 2 部分— Numba</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/speed-up-your-algorithms-part-2-numba-293e554c5cc1?source=collection_archive---------4-----------------------#2018-10-12">https://towardsdatascience.com/speed-up-your-algorithms-part-2-numba-293e554c5cc1?source=collection_archive---------4-----------------------#2018-10-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="19cb" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用 Numba 获得 C++/Fortran 般的速度</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/07c536e22c25956c72e05de09961c7ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*S9e58pstVLokmajz"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">“brown snake” by <a class="ae kv" href="https://unsplash.com/@joseph3088?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Duncan Sanchez</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="f9a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这是我写的系列文章中的第三篇。所有帖子都在这里:</p><ol class=""><li id="20d0" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/speed-up-your-algorithms-part-1-pytorch-56d8a4ae7051">加速您的算法第 1 部分— PyTorch </a></li><li id="b935" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/speed-up-your-algorithms-part-2-numba-293e554c5cc1">加速你的算法第二部分——Numba</a></li><li id="3ca5" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" rel="noopener" target="_blank" href="/speed-up-your-algorithms-part-3-parallelization-4d95c0888748">加速您的算法第三部分——并行化</a></li><li id="0afc" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">加速你的算法第 4 部分— Dask </li></ol><p id="083c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">而这些与<strong class="ky ir"> <em class="mg">相配套的 Jupyter 笔记本</em> </strong>可在此处获得:</p><p id="c6ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[<a class="ae kv" href="https://github.com/PuneetGrov3r/MediumPosts/tree/master/SpeedUpYourAlgorithms" rel="noopener ugc nofollow" target="_blank">Github-speedupyourlightms</a>和<strong class="ky ir">[</strong><a class="ae kv" href="https://www.kaggle.com/puneetgrover/kernels" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">ka ggle</strong></a><strong class="ky ir">]</strong></p><h1 id="6474" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">索引</h1><ol class=""><li id="88bd" class="ls lt iq ky b kz mz lc na lf nb lj nc ln nd lr lx ly lz ma bi translated">介绍</li><li id="6027" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">为什么是 Numba？</li><li id="2891" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">Numba 是如何工作的？</li><li id="f9c3" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">使用基本的 numba 功能(就@jit 吧！)</li><li id="4546" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">@矢量化包装器</li><li id="f1f6" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">在 GPU 上运行您的函数</li><li id="950e" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">进一步阅读</li><li id="db56" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">参考</li></ol><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="98f4" class="nj mi iq nf b gy nk nl l nm nn"><strong class="nf ir"><em class="mg">NOTE:<br/></em></strong>This post goes with <strong class="nf ir"><em class="mg">Jupyter Notebook</em></strong> available in my Repo on Github:[<a class="ae kv" href="https://nbviewer.jupyter.org/github/PuneetGrov3r/MediumPosts/blob/master/SpeedUpYourAlgorithms/2%29%20Numba.ipynb" rel="noopener ugc nofollow" target="_blank">SpeedUpYourAlgorithms-Numba</a>]</span></pre><h1 id="4d7e" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">1.介绍</h1><p id="bef5" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf no lh li lj np ll lm ln nq lp lq lr ij bi nr translated"><span class="l ns nt nu bm nv nw nx ny nz di"> N </span> umba 是一个<em class="mg">即时</em>的 python 编译器，也就是说，每当你调用一个 python 函数时，你的全部或部分代码都会被转换成机器码“<em class="mg">即时</em>”执行，然后它就会以你的本机机器码速度运行！它由 Anaconda 公司赞助，并得到了许多其他组织的支持。</p><p id="bc45" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有了 Numba，你可以加速所有计算密集型的 python 函数(比如循环)。它还支持<a class="ae kv" href="https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html" rel="noopener ugc nofollow" target="_blank"> numpy 库</a>！因此，您也可以在计算中使用 numpy，并加快整体计算速度，因为 python 中的循环非常慢。你也可以使用 python 标准库的数学库的许多功能，比如 sqrt 等。有关所有兼容功能的完整列表，请查看此处的<a class="ae kv" href="http://numba.pydata.org/numba-doc/0.17.0/reference/pysupported.html" rel="noopener ugc nofollow" target="_blank"/>。</p><h1 id="70a0" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">2.为什么是 Numba？</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oa"><img src="../Images/bbbb526d39c857accb331a1801614a94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7wHgolEzegBX41BW0cxVYQ.jpeg"/></div></div></figure><p id="d913" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[ <a class="ae kv" href="http://rebloggy.com/post/snake-crown-zeus-ball-python-python-i-cant-believe-he-let-me-do-this-snakes-in-h/30972529459" rel="noopener ugc nofollow" target="_blank">来源</a> ]</p><p id="36a3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi nr translated">S  o，为什么 numba？当有很多其他的编译器像<a class="ae kv" href="http://cython.org/" rel="noopener ugc nofollow" target="_blank"> cython </a>，或者任何其他类似的编译器或者类似<a class="ae kv" href="http://doc.pypy.org/en/latest/faq.html#what-is-pypy" rel="noopener ugc nofollow" target="_blank"> pypy </a>的时候。</p><p id="c310" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">原因很简单，在这里你不必离开用 python 写代码的舒适区。是的，你没看错，你根本不需要为基本的加速而改变你的代码，这可以和你从类似的带有类型定义的 cython 代码中得到的加速相媲美。这不是很好吗？</p><p id="94e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你只需要添加一个熟悉的 python 功能，一个围绕你的函数的装饰器(包装器)。一个用于类的<a class="ae kv" href="https://numba.pydata.org/numba-doc/dev/user/jitclass.html" rel="noopener ugc nofollow" target="_blank">包装器也正在开发中。</a></p><p id="02f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以，你只需要添加一个装饰就可以了。例如:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="9aa5" class="nj mi iq nf b gy nk nl l nm nn">from numba import jit</span><span id="246d" class="nj mi iq nf b gy ob nl l nm nn">@jit<br/>def function(x):<br/>    # your loop or numerically intensive computations<br/>    return x</span></pre><p id="47c9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它看起来仍然像一个纯 python 代码，不是吗？</p><h1 id="b309" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">3.numba 是如何工作的？</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oc"><img src="../Images/0ac8cf712b713cecdeae7ca93ee02ee3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bJ6XIUE05phjWZgz"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">“question mark neon signage” by <a class="ae kv" href="https://unsplash.com/@emilymorter?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Emily Morter</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="4869" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi nr translated"><span class="l ns nt nu bm nv nw nx ny nz di"> N </span> umba 使用<a class="ae kv" href="http://llvm.org/" rel="noopener ugc nofollow" target="_blank"> LLVM 编译器基础设施</a>从纯 Python 代码生成优化的机器码。使用 numba 运行代码的速度与 C、C++或 Fortran 中的类似代码相当。</p><p id="8d09" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">下面是代码的编译方式:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi od"><img src="../Images/285a549596a5888f29e53b154732de13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9n6WpEXjuD2lBSlX2_pU0g.png"/></div></div></figure><p id="9fce" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[ <a class="ae kv" href="https://github.com/ContinuumIO/gtc2017-numba/blob/master/1%20-%20Numba%20Basics.ipynb" rel="noopener ugc nofollow" target="_blank">来源</a></p><p id="d35d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先，Python 函数被获取、优化并转换成 Numba 的中间表示，然后在类似 Numpy 的类型推理(因此 python float 是 float64)的类型推理之后，它被转换成 LLVM 可解释代码。然后，这些代码被送入 LLVM 的实时编译器，以给出机器码。</p><p id="0755" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您可以根据自己的喜好，在 CPU(默认)或<a class="ae kv" href="http://numba.pydata.org/numba-doc/latest/cuda/index.html" rel="noopener ugc nofollow" target="_blank"> GPU </a>上运行时或导入时<a class="ae kv" href="http://numba.pydata.org/numba-doc/latest/user/jit.html#jit" rel="noopener ugc nofollow" target="_blank">生成</a>代码。</p><h1 id="6fa9" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">4.使用基本的 numba 功能(就@jit 吧！)</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/f607f06b87590f33f1b1cd9c62ae1771.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4IukKwm5RO0PWjmZ"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">Photo by <a class="ae kv" href="https://unsplash.com/@charlesetoroma?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Charles Etoroma</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><blockquote class="of og oh"><p id="dedf" class="kw kx mg ky b kz la jr lb lc ld ju le oi lg lh li oj lk ll lm ok lo lp lq lr ij bi translated"><em class="iq">小菜一碟！</em></p></blockquote><p id="114a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi nr translated">或者最佳性能 numba 建议在你的 jit 包装器中使用<code class="fe ol om on nf b">nopython = True</code>参数，这样它就不会用到 Python 解释器。或者你也可以使用<code class="fe ol om on nf b">@njit</code>。如果你的<code class="fe ol om on nf b">nopython = True</code>包装器因错误而失败，你可以使用简单的<code class="fe ol om on nf b">@jit</code>包装器，它将编译你的部分代码，循环它可以编译，并把它们变成函数，编译成机器码，把剩下的交给 python 解释器。<br/>所以，你只需要做:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="e293" class="nj mi iq nf b gy nk nl l nm nn">from numba import njit, jit</span><span id="59cb" class="nj mi iq nf b gy ob nl l nm nn">@njit      # or @jit(nopython=True)<br/>def function(a, b):<br/>    # your loop or numerically intensive computations<br/>    return result</span></pre><p id="8b1a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当使用<code class="fe ol om on nf b">@jit</code>时，确保你的代码有 numba 可以编译的东西，比如一个计算密集型的循环，可能有它支持的库(numpy)和函数。否则，它将无法编译任何内容。</p><p id="ba3b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最重要的是，numba 还会在函数首次作为机器码使用后对其进行缓存。所以在第一次之后，它会更快，因为它不需要再次编译代码，因为你使用的参数类型与你之前使用的相同。</p><p id="3542" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您的代码是<a class="ae kv" href="http://numba.pydata.org/numba-doc/latest/user/parallel.html#numba-parallel" rel="noopener ugc nofollow" target="_blank">可并行化的</a>，您也可以将<code class="fe ol om on nf b">parallel = True</code>作为参数传递，但是它必须与<code class="fe ol om on nf b">nopython = True</code>一起使用。目前，它只在 CPU 上工作。</p><p id="796d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你也可以指定你希望你的函数拥有的函数签名，但是它不会为你给它的任何其他类型的参数进行编译。例如:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="6587" class="nj mi iq nf b gy nk nl l nm nn">from numba import jit, int32</span><span id="4d4e" class="nj mi iq nf b gy ob nl l nm nn">@jit(int32(int32, int32))<br/>def function(a, b):<br/>    # your loop or numerically intensive computations<br/>    return result</span><span id="5af8" class="nj mi iq nf b gy ob nl l nm nn"><strong class="nf ir">#</strong> or if you haven't imported type names<br/><strong class="nf ir">#</strong> you can pass them as string</span><span id="4502" class="nj mi iq nf b gy ob nl l nm nn">@jit('int32(int32, int32)')<br/>def function(a, b):<br/>    # your loop or numerically intensive computations<br/>    return result</span></pre><p id="5da1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在你的函数将只接受两个 int32 并返回一个 int32。这样，你可以更好地控制你的功能。如果你愿意，你甚至可以传递多个功能签名。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/ea81c873b0ac3569cb3cf2db0290414a.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*aU6HSr8OGNilxhTR2A25XQ.png"/></div></figure><p id="f5fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您也可以使用 numba 提供的其他包装器:</p><ol class=""><li id="a125" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated"><a class="ae kv" href="http://numba.pydata.org/numba-doc/latest/user/vectorize.html" rel="noopener ugc nofollow" target="_blank">@矢量化</a>:允许标量参数用作 numpy <code class="fe ol om on nf b">ufunc</code> s，</li><li id="1b2d" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="http://numba.pydata.org/numba-doc/latest/user/vectorize.html#guvectorize" rel="noopener ugc nofollow" target="_blank">@ gu 矢量化</a>:产生 NumPy 个广义<code class="fe ol om on nf b">ufunc</code> s，</li><li id="3486" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="http://numba.pydata.org/numba-doc/latest/user/stencil.html#numba-stencil" rel="noopener ugc nofollow" target="_blank"> @stencil </a>:声明一个函数作为类模板操作的内核，</li><li id="64b3" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="http://numba.pydata.org/numba-doc/latest/user/jitclass.html#jitclass" rel="noopener ugc nofollow" target="_blank"> @jitclass </a>:对于 jit 感知类，</li><li id="a534" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="http://numba.pydata.org/numba-doc/latest/user/cfunc.html#cfunc" rel="noopener ugc nofollow" target="_blank"> @cfunc </a>:声明一个函数作为本机回调使用(从 C/C++等调用)，</li><li id="e3b0" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="http://numba.pydata.org/numba-doc/latest/extending/high-level.html#high-level-extending" rel="noopener ugc nofollow" target="_blank"> @overload </a>:注册自己的函数实现，用于 nopython 模式，例如<code class="fe ol om on nf b">@overload(scipy.special.j0)</code>。</li></ol><p id="f845" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Numba 还有提前<strong class="ky ir"/>(<a class="ae kv" href="https://numba.pydata.org/numba-doc/dev/user/pycc.html" rel="noopener ugc nofollow" target="_blank">AOT</a>)编译，产生一个不依赖 Numba 的编译后的扩展模块。但是:</p><ol class=""><li id="4027" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">它只允许常规函数(非 ufuncs)，</li><li id="4d74" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">您必须指定一个函数签名。您只能指定一个，因为许多指定在不同的名称下。</li></ol><p id="b1eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它还为您的 CPU 架构家族生成通用代码。</p><h1 id="14c4" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">5.@矢量化包装器</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi op"><img src="../Images/c901478cb8dc25e7e7117625135aac2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*E9-BCxGFbXYIegax"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">“gray solar panel lot” by <a class="ae kv" href="https://unsplash.com/@publicpowerorg?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">American Public Power Association</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="e423" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi nr translated"><span class="l ns nt nu bm nv nw nx ny nz di">通过</span>使用@vectorize wrapper，你可以将只在标量上操作的函数转换为数组，例如，如果你正在使用只在标量上工作的 python 的<code class="fe ol om on nf b">math</code>库。这提供了类似于 numpy 数组操作(ufuncs)的速度。例如:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="9592" class="nj mi iq nf b gy nk nl l nm nn">@vectorize<br/>def func(a, b):<br/>    # Some operation on scalars<br/>    return result</span></pre><p id="4fc1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">您还可以将<code class="fe ol om on nf b">target</code>参数传递给这个包装器，对于并行化代码，它的值可以等于<code class="fe ol om on nf b">parallel</code>，对于在 cuda/GPU 上运行代码，它的值可以等于<code class="fe ol om on nf b">cuda</code>。</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="31f2" class="nj mi iq nf b gy nk nl l nm nn">@vectorize(target="parallel")<br/>def func(a, b):<br/>    # Some operation on scalars<br/>    return result</span></pre><p id="23eb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您的代码计算量足够大或者数组足够大，使用<code class="fe ol om on nf b">target = “parallel”</code>或<code class="fe ol om on nf b">“cuda”</code>进行矢量化通常会比 numpy 实现运行得更快。如果不是这样，那么它会带来创建线程和为不同线程拆分元素的时间开销，这可能比整个进程的实际计算时间要长。因此，工作应该足够繁重以获得加速。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/c938d370f6b605853d8ecdcd4d465dc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*B-pN5BguZzGeoFX706QTAA.png"/></div></figure></div><div class="ab cl or os hu ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="ij ik il im in"><p id="b060" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个伟大的视频有一个例子，加速纳维尔斯托克斯方程计算流体力学与 Numba:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oy oz l"/></div></figure></div><div class="ab cl or os hu ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="ij ik il im in"><h1 id="eb4a" class="mh mi iq bd mj mk pa mm mn mo pb mq mr jw pc jx mt jz pd ka mv kc pe kd mx my bi translated">6.在 GPU 上运行您的函数</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oe"><img src="../Images/37b74be96f3a853db482c033a10ab7a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EpVwxeU9OQgi2pb4"/></div></div><figcaption class="kr ks gj gh gi kt ku bd b be z dk">“time-lapsed of street lights” by <a class="ae kv" href="https://unsplash.com/@marcsm?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Marc Sendra martorell</a> on <a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="dbd9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你也可以通过@jit 这样的包装器在 cuda/GPU 上运行函数。为此，您必须从<code class="fe ol om on nf b">numba</code>库中导入<code class="fe ol om on nf b">cuda</code>。但是在 GPU 上运行你的代码不会像以前那么容易了。在 GPU 上数百甚至数千个线程上运行函数需要进行一些初始计算。您必须声明和管理网格、块和线程的层次结构。也没那么难。</p><p id="680d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">要在 GPU 上执行一个函数，你必须定义一个叫做<code class="fe ol om on nf b"><strong class="ky ir">kernel function</strong></code>或<code class="fe ol om on nf b"><strong class="ky ir">device function</strong></code>的东西。首先让我们看一个<code class="fe ol om on nf b"><strong class="ky ir">kernel function</strong></code>。</p><p id="d692" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">关于内核函数，需要记住以下几点:</p><p id="72c5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">a)内核在被调用时显式声明它们的线程层次，即块数和每个块的线程数。您可以编译一次内核，然后使用不同的块和网格大小多次调用它。</p><p id="9802" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">b)内核不能返回值。所以，要么你必须对原始数组进行修改，要么传递另一个数组来存储结果。为了计算标量，您必须传递一个 1 元素数组。</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="2a2f" class="nj mi iq nf b gy nk nl l nm nn"># Defining a kernel function<br/>from numba import cuda</span><span id="88b8" class="nj mi iq nf b gy ob nl l nm nn">@cuda.jit<br/>def func(a, result):<br/>    # Some cuda related computation, then<br/>    # your computationally intensive code.<br/>    # (Your answer is stored in 'result')</span></pre><p id="89e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">所以为了启动一个内核，你必须传递两个东西:</p><ol class=""><li id="af00" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">每个块的线程数，</li><li id="3f39" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">块数。</li></ol><p id="2229" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">例如:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="8b2b" class="nj mi iq nf b gy nk nl l nm nn">threadsperblock = 32<br/>blockspergrid = (array.size + (threadsperblock - 1)) // threadsperblock<br/>func[blockspergrid, threadsperblock](array)</span></pre><p id="4f67" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每个线程中的内核函数必须知道它在哪个线程中，知道它负责数组的哪些元素。Numba 使获取这些元素的位置变得很容易，只需一次调用。</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="324e" class="nj mi iq nf b gy nk nl l nm nn">@cuda.jit<br/>def func(a, result):<br/>    pos = cuda.grid(1)  # For 1D array<br/>    # x, y = cuda.grid(2) # For 2D array<br/>    if pos &lt; a.shape[0]:<br/>        result[pos] = a[pos] * (some computation)</span></pre><p id="23ad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了节省将 numpy 数组复制到特定设备，然后再将结果存储到 numpy 数组中所浪费的时间，Numba 提供了一些<a class="ae kv" href="https://numba.pydata.org/numba-doc/dev/cuda/memory.html" rel="noopener ugc nofollow" target="_blank">函数</a>来声明和发送数组到特定设备，如:<code class="fe ol om on nf b">numba.cuda.device_array</code>、<code class="fe ol om on nf b">numba.cuda.device_array_like</code>、<code class="fe ol om on nf b">numba.cuda.to_device</code>等。为了节省不必要的拷贝到 cpu 的时间(除非必要)。</p><p id="8ee6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一方面，<code class="fe ol om on nf b"><strong class="ky ir">device function</strong></code>只能从设备内部调用(通过内核或另一个设备函数)。有利的一点是，你可以从一个<code class="fe ol om on nf b"><strong class="ky ir">device function</strong></code>返回值。因此，您可以使用函数的返回值来计算<code class="fe ol om on nf b">kernel function</code>或<code class="fe ol om on nf b">device function</code>中的内容。</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="eefa" class="nj mi iq nf b gy nk nl l nm nn">from numba import cuda</span><span id="8017" class="nj mi iq nf b gy ob nl l nm nn">@cuda.jit(device=True)<br/>def device_function(a, b):<br/>    return a + b</span></pre><p id="d977" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你也应该看看 Numba 的 cuda 库支持的功能。</p><p id="2bf9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Numba 在其 cuda 库中还实现了<a class="ae kv" href="https://numba.pydata.org/numba-doc/dev/cuda/intrinsics.html" rel="noopener ugc nofollow" target="_blank">原子操作</a>、<a class="ae kv" href="https://numba.pydata.org/numba-doc/dev/cuda/random.html" rel="noopener ugc nofollow" target="_blank">随机数生成器</a>、<a class="ae kv" href="https://numba.pydata.org/numba-doc/dev/cuda/memory.html#cuda-shared-memory" rel="noopener ugc nofollow" target="_blank">共享内存实现</a>(以加速数据访问)等。</p></div><div class="ab cl or os hu ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="ij ik il im in"><p id="357b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">ctypes/cffi/cython 互操作性:</p><ul class=""><li id="db35" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr pf ly lz ma bi translated">cffi—nopython 模式支持调用<a class="ae kv" href="http://numba.pydata.org/numba-doc/latest/reference/pysupported.html#cffi-support" rel="noopener ugc nofollow" target="_blank"> CFFI </a>函数。</li><li id="105e" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr pf ly lz ma bi translated">ctypes——在 nopython 模式下支持调用<a class="ae kv" href="http://numba.pydata.org/numba-doc/latest/reference/pysupported.html#ctypes-support" rel="noopener ugc nofollow" target="_blank"> ctypes </a>包装函数…</li><li id="0bfb" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr pf ly lz ma bi translated">Cython 导出函数<a class="ae kv" href="http://numba.pydata.org/numba-doc/latest/extending/high-level.html#cython-support" rel="noopener ugc nofollow" target="_blank">可调用</a>。</li></ul></div><div class="ab cl or os hu ot" role="separator"><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow ox"/><span class="ou bw bk ov ow"/></div><div class="ij ik il im in"><h1 id="7fbc" class="mh mi iq bd mj mk pa mm mn mo pb mq mr jw pc jx mt jz pd ka mv kc pe kd mx my bi translated">7.进一步阅读</h1><ol class=""><li id="674d" class="ls lt iq ky b kz mz lc na lf nb lj nc ln nd lr lx ly lz ma bi translated"><a class="ae kv" href="https://nbviewer.jupyter.org/github/ContinuumIO/gtc2017-numba/tree/master/" rel="noopener ugc nofollow" target="_blank">https://nb viewer . jupyter . org/github/continuum io/GTC 2017-numba/tree/master/</a></li><li id="43ec" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://devblogs.nvidia.com/seven-things-numba/" rel="noopener ugc nofollow" target="_blank">https://devblogs.nvidia.com/seven-things-numba/</a></li><li id="6e95" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://devblogs.nvidia.com/numba-python-cuda-acceleration/" rel="noopener ugc nofollow" target="_blank">https://devblogs.nvidia.com/numba-python-cuda-acceleration/</a></li><li id="20e7" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://jakevdp.github.io/blog/2015/02/24/optimizing-python-with-numpy-and-numba/" rel="noopener ugc nofollow" target="_blank">https://jakevdp . github . io/blog/2015/02/24/optimizing-python-with-numpy-and-numba/</a></li><li id="8cad" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://www.youtube.com/watch?v=1AwG0T4gaO0" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=1AwG0T4gaO0</a></li></ol><h1 id="9711" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">8.参考</h1><ol class=""><li id="a2b1" class="ls lt iq ky b kz mz lc na lf nb lj nc ln nd lr lx ly lz ma bi translated"><a class="ae kv" href="http://numba.pydata.org/numba-doc/latest/user/index.html" rel="noopener ugc nofollow" target="_blank">http://numba.pydata.org/numba-doc/latest/user/index.html</a></li><li id="7d97" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="https://github.com/ContinuumIO/gtc2018-numba" rel="noopener ugc nofollow" target="_blank">https://github.com/ContinuumIO/gtc2018-numba</a></li><li id="4382" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated"><a class="ae kv" href="http://stephanhoyer.com/2015/04/09/numba-vs-cython-how-to-choose/" rel="noopener ugc nofollow" target="_blank">http://Stephan hoyer . com/2015/04/09/numba-vs-cy thon-how-to-choose/</a></li></ol><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="0f56" class="nj mi iq nf b gy nk nl l nm nn">Suggestions and reviews are welcome.<br/>Thank you for reading!</span></pre><p id="d701" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">签名:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi pg"><img src="../Images/ca01c1d315400c09978fb5e62da01d87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*N7tbEUmEr0wEqsdlZNQ5iA.png"/></div></div></figure></div></div>    
</body>
</html>