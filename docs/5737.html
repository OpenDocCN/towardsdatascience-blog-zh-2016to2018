<html>
<head>
<title>Getting Started with Apache Kafka and Apache Flume (Import data to HDFS)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Kafka 和 Apache Flume 入门(将数据导入 HDFS)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/apache-kafka-and-flume-installation-guide-import-data-from-kafka-to-hdfs-c908b0df034c?source=collection_archive---------5-----------------------#2018-11-06">https://towardsdatascience.com/apache-kafka-and-flume-installation-guide-import-data-from-kafka-to-hdfs-c908b0df034c?source=collection_archive---------5-----------------------#2018-11-06</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/1de63faf322d4ce79040355ae62d3b8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8GbrXbHdH5uPGMb5epWhrg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Image Source: www.kafka.apache.org</figcaption></figure><p id="bf35" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">本文包含 Apache Kafka 安装、创建 Kafka 主题、发布和订阅主题消息的完整指南。此外，它还包含 Apache Flume 安装指南以及如何使用 Apache Flume 将 Kafka 主题消息导入 HDFS。</p><h1 id="c91a" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">1.总说明</h1><ul class=""><li id="2636" class="ly lz iq ke b kf ma kj mb kn mc kr md kv me kz mf mg mh mi bi translated">Hadoop 版本:3.1.0</li><li id="4090" class="ly lz iq ke b kf mj kj mk kn ml kr mm kv mn kz mf mg mh mi bi translated">阿帕奇卡夫卡版本:1.1.1</li><li id="e46b" class="ly lz iq ke b kf mj kj mk kn ml kr mm kv mn kz mf mg mh mi bi translated">Apache Flume 版本:1.8.0</li><li id="654d" class="ly lz iq ke b kf mj kj mk kn ml kr mm kv mn kz mf mg mh mi bi translated">操作系统:Ubuntu 16.04</li><li id="8275" class="ly lz iq ke b kf mj kj mk kn ml kr mm kv mn kz mf mg mh mi bi translated">Java 版本:Java 8</li></ul><h1 id="0f62" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">2.先决条件</h1><h1 id="dfe5" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">2.1.安装 Java</h1><p id="fbcf" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">阿帕奇卡夫卡需要 Java。要确保安装了 Java，首先更新操作系统，然后尝试安装它:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="7395" class="na lb iq mw b gy nb nc l nd ne">sudo apt-get update</span><span id="c78b" class="na lb iq mw b gy nf nc l nd ne">sudo apt-get upgrade</span><span id="6b15" class="na lb iq mw b gy nf nc l nd ne">sudo add-apt-repository -y ppa:webupd8team/java</span><span id="e224" class="na lb iq mw b gy nf nc l nd ne">sudo apt-get install oracle-java8-installer</span></pre><h1 id="717e" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">2.2.安装动物园管理员</h1><p id="0ecb" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">Apache Kafka 需要安装 Zookeeper 服务，因为它使用它来维护节点心跳、配置和选举领导者。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="338d" class="na lb iq mw b gy nb nc l nd ne">sudo apt-get install zookeeperd</span></pre><p id="9d89" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">默认情况下，zookeeper 使用端口 2181，安装后会自动运行。使用 telnet 命令检查 Zookeeper 是否正在运行:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="65aa" class="na lb iq mw b gy nb nc l nd ne">telnet localhost 2181</span></pre><p id="0baa" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">当 telnet 提示符打开时，写下“你还好吗”命令:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="9bd3" class="na lb iq mw b gy nb nc l nd ne">ruok</span></pre><p id="357e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果一切正常，它将返回<em class="ng"> imok </em>消息。</p><h1 id="81ad" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">2.3.创建具有 sudo 权限的非超级用户帐户</h1><p id="721d" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">因为 Kafka 是一个网络应用程序，它可能使用多个节点，所以最好创建一个具有 sudo 权限的服务用户。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="b8ec" class="na lb iq mw b gy nb nc l nd ne">sudo adduser — system — no-create-home — disabled-password — disabled-login kafkauser</span></pre><h1 id="96d9" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">3.安装和配置 Kafka 服务器</h1><h1 id="7b1e" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">3.1.下载卡夫卡</h1><p id="0e28" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">首先，我们需要下载 Kafka 二进制包。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="11a6" class="na lb iq mw b gy nb nc l nd ne">wget <a class="ae nh" href="http://www-eu.apache.org/dist/kafka/1.1.1/kafka_2.11-1.1.1.tgz" rel="noopener ugc nofollow" target="_blank">http://www-eu.apache.org/dist/kafka/1.1.1/kafka_2.11-1.1.1.tgz</a></span></pre><p id="b1ab" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在，我们需要提取 tgz 包。我们选择将 Kafka 安装在/opt/kafka 目录中:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="9168" class="na lb iq mw b gy nb nc l nd ne">sudo tar xvf kafka_2.11–1.1.1.tgz -–directory /opt/kafka -–strip 1</span></pre><p id="1cdb" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">Kafka 将它的日志存储在磁盘上的/tmp 目录下，最好创建一个新的目录来存储日志</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="9f75" class="na lb iq mw b gy nb nc l nd ne">sudo mkdir /var/lib/kafka</span><span id="eb10" class="na lb iq mw b gy nf nc l nd ne">sudo mkdir /var/lib/kafka/data</span></pre><h1 id="4fff" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">3.2.配置 Kafka</h1><p id="61b2" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">现在，我们需要编辑 Kafka 服务器配置文件。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="5b07" class="na lb iq mw b gy nb nc l nd ne">sudo gedit /opt/kafka/config/server.properties</span></pre><p id="13b6" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">默认情况下，Kafka 不允许我们删除主题。为了能够删除主题，找到并更改该行(如果没有找到，就添加它)。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="1a8d" class="na lb iq mw b gy nb nc l nd ne">delete.topic.enable = true</span></pre><p id="b780" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在，我们需要更改日志目录:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="7ee3" class="na lb iq mw b gy nb nc l nd ne">log.dirs=/var/lib/kafka/data</span></pre><p id="f0ec" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">此外，我们可以调整日志删除的时间间隔(Kafka 在特定时间后或根据磁盘大小删除日志):</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="0a03" class="na lb iq mw b gy nb nc l nd ne">log.retention.hours=168 # according to time</span><span id="2eb9" class="na lb iq mw b gy nf nc l nd ne">log.retention.bytes=104857600 # according to disk size</span></pre><h1 id="400b" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">3.3.更改目录权限</h1><p id="af43" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">我们需要在日志目录和 kafka 安装目录上授予 kafkauser 访问权限:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="870d" class="na lb iq mw b gy nb nc l nd ne">sudo chown –R kafkauser:nogroup /opt/kafka</span><span id="1474" class="na lb iq mw b gy nf nc l nd ne">sudo chown –R kafkauser:nogroup /var/lib/kafka</span></pre><h1 id="3aa9" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">3.4.开始卡夫卡</h1><p id="d6bc" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">要启动 Apache Kafka 服务，可以使用以下命令:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="d480" class="na lb iq mw b gy nb nc l nd ne">sudo /opt/kafka/bin/kafka-server-start.sh /opt/kafka/ config/server.properties</span></pre><p id="2b28" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果服务器已经成功启动，您应该会看到以下输出:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="cf4f" class="na lb iq mw b gy nb nc l nd ne">[2018–07–23 21:43:48,279] WARN No meta.properties file under dir /var/lib/kafka/data/meta.properties (kafka.server.BrokerMetadataCheckpoint)</span><span id="9583" class="na lb iq mw b gy nf nc l nd ne">[2018–07–23 21:43:48,516] INFO Kafka version : 0.10.0.1 (org.apache.kafka.common.utils.AppInfoParser)</span><span id="4d1f" class="na lb iq mw b gy nf nc l nd ne">[2018–07–23 21:43:48,525] INFO Kafka commitId : a7a17cdec9eaa6c5 (org.apache.kafka.common.utils.AppInfoParser)</span><span id="1b5f" class="na lb iq mw b gy nf nc l nd ne">[2018–07–23 21:43:48,527] INFO [Kafka Server 0], started (kafka.server.KafkaServer)</span><span id="4ebf" class="na lb iq mw b gy nf nc l nd ne">[2018–07–23 21:43:48,555] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)</span></pre><p id="de33" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">要将 Kafka 作为后台进程启动，可以使用 nohup 命令</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="6f72" class="na lb iq mw b gy nb nc l nd ne">sudo nohup /opt/kafka/bin/kafka-server-start.sh /opt/kafka/ config/server.properties /var/lib/kafka/data/kafka.log 2&gt;&amp;1 &amp;</span></pre><p id="55b7" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在，您有一个 Kafka 服务器正在运行并监听端口 9092。</p><h1 id="ac2a" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">3.5.启动时将 Kafka 作为服务启动</h1><p id="f60b" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">首先，我们需要在/etc/systemd/system 中创建一个服务单元文件</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="01bb" class="na lb iq mw b gy nb nc l nd ne">sudo gedit /etc/systemd/system/kafka.service</span></pre><p id="792a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir">卡夫卡.服务</strong></p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="31f7" class="na lb iq mw b gy nb nc l nd ne">[Unit]</span><span id="9024" class="na lb iq mw b gy nf nc l nd ne">Description=High-available, distributed message broker</span><span id="4628" class="na lb iq mw b gy nf nc l nd ne">After=network.target</span><span id="4385" class="na lb iq mw b gy nf nc l nd ne">[Service]</span><span id="f6fd" class="na lb iq mw b gy nf nc l nd ne">User=kafka</span><span id="3f6c" class="na lb iq mw b gy nf nc l nd ne">ExecStart=/opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties</span><span id="b0bf" class="na lb iq mw b gy nf nc l nd ne">[Install]</span><span id="f8a9" class="na lb iq mw b gy nf nc l nd ne">WantedBy=multi-user.target</span></pre><p id="0519" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">此外，使用可以将日志转发到另一个文件，这样您系统日志就不会被占用</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="06e5" class="na lb iq mw b gy nb nc l nd ne">ExecStart=/opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties &gt; /opt/kafka/server.log</span></pre><p id="36a1" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">要启动创建的服务，请使用以下命令:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="8b09" class="na lb iq mw b gy nb nc l nd ne">sudo systemctl start kafka.service</span></pre><p id="68c0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在操作系统启动时自动启动服务</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="7442" class="na lb iq mw b gy nb nc l nd ne">sudo systemctl enable kafka.service</span></pre><p id="f28c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">您可以使用以下命令检查您的服务状态:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="78d4" class="na lb iq mw b gy nb nc l nd ne">sudo systemctl status kafka.service</span></pre><h1 id="b167" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">3.6.使用卡夫卡主题</h1><h1 id="a553" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">3.6.1.创造一个卡夫卡主题</h1><p id="d00e" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">要创建 Kafka 主题，我们必须使用 kafka-topics.sh 脚本文件，并且我们需要指定 zookeeper 地址、复制因子、分区因子和主题名称:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="bbd4" class="na lb iq mw b gy nb nc l nd ne">/opt/kafka/bin/kafka-topics.sh — create — zookeeper localhost:2181 — replication-factor 1 — partitions 1 — topic testKafka</span></pre><h1 id="c93d" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">3.6.2.列出可用主题</h1><p id="eb03" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">要列出所有主题，请使用以下命令:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="5a5f" class="na lb iq mw b gy nb nc l nd ne">/opt/kafka/bin/kafka-topics.sh — list — zookeeper localhost:2181</span></pre><h1 id="f603" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">3.6.3.发布和订阅消息</h1><p id="964a" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">要将消息发布到主题中，我们必须使用 kafka-console-producer.sh 脚本，并且我们必须指定 kafka 服务器地址和主题名称:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="32a3" class="na lb iq mw b gy nb nc l nd ne">/opt/kafka/bin/kafka-console-producer.sh — broker-list localhost:9092 — topic testKafka</span></pre><p id="643a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">然后，我们需要打开另一个终端，并使用 kafka-console-consumer.sh 脚本创建一个订户。我们需要传递 Kafka 服务器地址和主题名称</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="6d98" class="na lb iq mw b gy nb nc l nd ne">/opt/kafka/bin/kafka-console-consumer.sh — bootstrap-server localhost:9092 — topic test — from-beginning</span></pre><p id="5bea" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在第一个终端(生产者)中，输入任意消息(例如:Hello！！)它必须出现在第二个终端中。</p><h1 id="2041" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">3.6.4.将文本文件导入 Kafka 主题</h1><p id="5a41" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">要在 Kafka 主题中打开一个文本文件，您需要使用带有管道的 cat 命令:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="352e" class="na lb iq mw b gy nb nc l nd ne">cat filename.txt | /opt/kafka/bin/kafka-console-producer.sh — broker-list localhost:9092 — topic testKafka</span></pre><h1 id="58ce" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">3.7.Kafka 多节点集群</h1><p id="b852" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">此外，我们可以在多个节点上运行它，以实现数据冗余和意外故障转移。假设我们有 3 个节点:</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/6f3c5fdd41dc934936bcfc0df4232714.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*1rZnda3DFw6zElMXCiuz4w.png"/></div></figure><p id="0355" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">我们需要遵循我们之前提到的相同步骤，并添加一些内容:</p><p id="686c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">1.在/opt/Kafka/config/server . properties 中:</p><p id="fbf0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">a.每个节点必须有一个唯一的 broker.id 属性</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="7761" class="na lb iq mw b gy nb nc l nd ne">for node-2 broker.id=1</span><span id="d0e9" class="na lb iq mw b gy nf nc l nd ne">for node-3 broker.id=2</span></pre><p id="c66c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">b.更改 zookeeper.connect 的值，使其列出所有带有端口的 zookeeper 主机</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="d951" class="na lb iq mw b gy nb nc l nd ne">zookeeper.connect=10.0.1.1:2181,10.0.1.2:2181,10.0.1.3:2181</span></pre><p id="3d8b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">2.我们必须改变动物园管理员的设置。使用编辑器 sudo gedit/etc/zookeeper/conf/zoo . CFG 打开<strong class="ke ir"> zoo.cfg </strong>文件，并添加以下几行:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="d495" class="na lb iq mw b gy nb nc l nd ne">server.0=10.0.1.1:2888:3888</span><span id="6dfa" class="na lb iq mw b gy nf nc l nd ne">server.1=10.0.1.2:2888:3888</span><span id="4b72" class="na lb iq mw b gy nf nc l nd ne">server.2=10.0.1.3:2888:3888</span></pre><p id="0cf6" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">3.重新启动 Zookeeper 服务</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="2040" class="na lb iq mw b gy nb nc l nd ne">sudo systemctl restart zookeeper.service</span></pre><h1 id="a09f" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">4.安装和配置 Apache Flume</h1><p id="6fde" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">要从 Kafka 主题中读取消息并存储到 HDFS 中，我们需要安装 Apache Flume。该应用程序用于将非结构化和半结构化数据存储到 HDFS 中。</p><h1 id="41d2" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">4.1.下载水槽</h1><p id="4bfe" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">首先，我们需要下载 apache flume 二进制包</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="e1a6" class="na lb iq mw b gy nb nc l nd ne">wget “http://www-eu.apache.org/dist/flume/1.8.0/apache_flume-1.8.0-bin.tar.gz"</span></pre><p id="6c20" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在我们需要提取。gz 包。我们选择将 Kafka 安装在/opt/kafka 目录中:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="0b4f" class="na lb iq mw b gy nb nc l nd ne">sudo tar -xvf apache_flume-1.8.0-bin.tar.gz –-directory /opt/flume –-strip 1</span></pre><h1 id="b48b" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">4.2.配置水槽</h1><p id="8aa1" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">您需要编辑<strong class="ke ir">“/etc/profile”</strong>、<strong class="ke ir"> ~/。bashrc" </strong>文件并添加以下几行</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="cf38" class="na lb iq mw b gy nb nc l nd ne">export FLUME_HOME= /opt/flume</span><span id="ad94" class="na lb iq mw b gy nf nc l nd ne">export PATH=$PATH:$FLUME_HOME/bin/</span></pre><p id="6309" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">要应用这些更改，请使用 source ~/。巴沙尔司令部。</p><p id="2d6f" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">完成后，flume 代理会自动启动。要确保 flume 安装成功，您可以运行以下命令:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="a247" class="na lb iq mw b gy nb nc l nd ne">flume-ng –help</span></pre><p id="0999" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">要将数据导入 HDFS，首先我们需要在您的主目录中创建一个日志文件。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="ac47" class="na lb iq mw b gy nb nc l nd ne">gedit ~/access.log</span></pre><p id="b1ae" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">写入任何数据并保存。</p><p id="91e8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在/opt/flume/conf 中创建一个文件<strong class="ke ir"> "flume.conf" </strong>文件，并将以下数据写入其中:</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="1695" class="na lb iq mw b gy nb nc l nd ne">flume1.sources = kafka-source-1</span><span id="f3c9" class="na lb iq mw b gy nf nc l nd ne">flume1.channels = hdfs-channel-1</span><span id="69b7" class="na lb iq mw b gy nf nc l nd ne">flume1.sinks = hdfs-sink-1</span><span id="b8fe" class="na lb iq mw b gy nf nc l nd ne">flume1.sources.kafka-source-1.type = org.apache.flume.source.kafka.KafkaSource</span><span id="51d6" class="na lb iq mw b gy nf nc l nd ne">flume1.sources.kafka-source-1.zookeeperConnect = localhost:2181</span><span id="5505" class="na lb iq mw b gy nf nc l nd ne">flume1.sources.kafka-source-1.topic = testKafka</span><span id="1cc4" class="na lb iq mw b gy nf nc l nd ne">flume1.sources.kafka-source-1.batchSize = 100</span><span id="a946" class="na lb iq mw b gy nf nc l nd ne">flume1.sources.kafka-source-1.channels = hdfs-channel-1</span><span id="87b3" class="na lb iq mw b gy nf nc l nd ne">flume1.channels.hdfs-channel-1.type = memory</span><span id="abcc" class="na lb iq mw b gy nf nc l nd ne">flume1.sinks.hdfs-sink-1.channel = hdfs-channel-1</span><span id="6859" class="na lb iq mw b gy nf nc l nd ne">flume1.sinks.hdfs-sink-1.type = hdfs</span><span id="3b41" class="na lb iq mw b gy nf nc l nd ne">flume1.sinks.hdfs-sink-1.hdfs.writeFormat = Text</span><span id="9586" class="na lb iq mw b gy nf nc l nd ne">flume1.sinks.hdfs-sink-1.hdfs.fileType = DataStream</span><span id="76dd" class="na lb iq mw b gy nf nc l nd ne">flume1.sinks.hdfs-sink-1.hdfs.filePrefix = test-events</span><span id="55fd" class="na lb iq mw b gy nf nc l nd ne">flume1.sinks.hdfs-sink-1.hdfs.useLocalTimeStamp = true</span><span id="79bd" class="na lb iq mw b gy nf nc l nd ne">flume1.sinks.hdfs-sink-1.hdfs.path = /data/kafka/%{topic}/%y-%m-%d</span><span id="b5c7" class="na lb iq mw b gy nf nc l nd ne">flume1.sinks.hdfs-sink-1.hdfs.rollCount=100</span><span id="f9fd" class="na lb iq mw b gy nf nc l nd ne">flume1.sinks.hdfs-sink-1.hdfs.rollSize=0</span><span id="4475" class="na lb iq mw b gy nf nc l nd ne">flume1.channels.hdfs-channel-1.capacity = 10000</span><span id="079f" class="na lb iq mw b gy nf nc l nd ne">flume1.channels.hdfs-channel-1.transactionCapacity = 1000</span></pre><p id="ddc7" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">请注意，flume1 是 flume 代理名称。</p><p id="fd1a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">下面，一些参数描述:</p><figure class="mr ms mt mu gt jr gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/b7bee694a10806e8ec33de864944794a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*-aJiVVWzCHW6xvvLEhCqDw.png"/></div></figure><p id="fc12" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">现在，您需要运行 flume 代理从 Kafka 主题中读取数据，并将其写入 HDFS。</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="9db6" class="na lb iq mw b gy nb nc l nd ne">flume-ng agent -n flume1 -c conf -f flume.conf — Dflume.root.logger=INFO,console</span></pre><p id="f624" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><em class="ng">注意:代理名称由-n FileAgent 指定，并且必须与-f conf/flume.conf </em>中给出的代理名称相匹配</p><p id="33ab" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">数据现在将通过以下路径转储到 HDFS 位置</p><pre class="mr ms mt mu gt mv mw mx my aw mz bi"><span id="01a8" class="na lb iq mw b gy nb nc l nd ne">/tmp/kafka/%{topic}/%y-%m-%d</span></pre><p id="7b82" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><em class="ng"> %{topic} &gt; &gt;卡夫卡题目名称</em></p><p id="9c4e" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><em class="ng"> %y-%m-%d &gt;</em></p><h1 id="5069" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">5.参考</h1><p id="aa02" class="pw-post-body-paragraph kc kd iq ke b kf ma kh ki kj mb kl km kn mo kp kq kr mp kt ku kv mq kx ky kz ij bi translated">[1]“阿帕奇卡夫卡官方文档”，阿帕奇，[在线]。可用:<a class="ae nh" href="http://kafka.apache.org." rel="noopener ugc nofollow" target="_blank">http://kafka.apache.org。</a>【访问日期 2018 年 07 月 15 日】。</p><p id="0a69" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[2]“Apache Flume 官方文档”，Apache，[在线]。可用:<a class="ae nh" href="http://flume.apache.org." rel="noopener ugc nofollow" target="_blank">http://flume.apache.org。</a>【访问时间 2018 年 07 月 20 日】。</p><p id="97cb" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[3] Sarad，“如何在 Ubuntu 16.04 上安装 Kafka”，Hevo，2017 年 8 月 20 日。【在线】。可用:【https://hevodata.com/blog/how-to-install-kafka-on-ubuntu. T2】【2018 年 06 月 30 日获取】。</p><p id="de5a" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[4]“15 分钟内完成 Kafka 设置”，ETL-Tools，[在线]。可用:<a class="ae nh" href="http://etl-tools.info/en/examples/kafka-setup-in-15-minutes.htm." rel="noopener ugc nofollow" target="_blank">http://ETL-tools . info/en/examples/Kafka-setup-in-15-minutes . htm .</a>【25 07 2018 访问】。</p><p id="4a97" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[5] hitjethva，“在 Ubuntu 16.04 上安装和配置 Apache Kafka”，DevOps，2016 年 10 月 3 日。【在线】。可用:<a class="ae nh" href="https://devops.profitbricks.com/tutorials/install-and-configure-apache-kafka-on-ubuntu-1604-1/." rel="noopener ugc nofollow" target="_blank">https://devo PS . profit bricks . com/tutorials/install-and-configure-Apache-Kafka-on-Ubuntu-1604-1/。</a>【访问时间 2018 年 07 月 15 日】。</p><p id="f82d" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[6] M. Litwintschik，“Hadoop 3 单节点安装指南”，2018 年 3 月 19 日。【在线】。可用:<a class="ae nh" href="http://www.tech.marksblogg.com/hadoop-3-single-node-install-guide.html." rel="noopener ugc nofollow" target="_blank">http://www . tech . marksblogg . com/Hadoop-3-single-node-install-guide . html</a>【2018 年 10 月 06 日访问】。</p><p id="ce87" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[7]“栈溢出问答”，栈溢出，[在线]。可用:<a class="ae nh" href="https://www.Stackoverflow.com." rel="noopener ugc nofollow" target="_blank">https://www.Stackoverflow.com。</a></p><p id="dcc4" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[8] Gwen Shapira 和 Jeff Holoman，“Flafka: Apache Flume 遇到 Apache Kafka 进行事件处理”，Cloudera，2014 年 11 月 6 日。【在线】。可用:<a class="ae nh" href="http://blog.cloudera.com/blog/2014/11/flafka-apache-flume-meets-apache-kafka-for-event-processing/." rel="noopener ugc nofollow" target="_blank">http://blog . cloud era . com/blog/2014/11/flafka-Apache-flume-meets-Apache-Kafka-for-event-processing/。</a>【访问日期 2018 年 06 月 15 日】。</p><p id="bcfd" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">[9] S. Team，“Apache Flume 安装教程—初学者指南”，Data Flair，2016 年 8 月 22 日。【在线】。可用:<a class="ae nh" href="https://data-flair.training/blogs/apache-flume-installation-tutorial." rel="noopener ugc nofollow" target="_blank">https://data-flair . training/blogs/Apache-flume-installation-tutorial。</a>【访问日期 2018 年 06 月 20 日】。</p></div></div>    
</body>
</html>