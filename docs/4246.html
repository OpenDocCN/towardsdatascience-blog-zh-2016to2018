<html>
<head>
<title>Training a Random Forest to Identify Malignant Breast Cancer Tumors</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">训练随机森林以识别恶性乳腺癌肿瘤</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-a-random-forest-to-identify-malignant-breast-cancer-tumors-49e8a69fc964?source=collection_archive---------5-----------------------#2018-08-01">https://towardsdatascience.com/training-a-random-forest-to-identify-malignant-breast-cancer-tumors-49e8a69fc964?source=collection_archive---------5-----------------------#2018-08-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/b7bcde316911dd3d1af206cf3f94fa49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*cV-gENgCXftOAwJKf_nQrQ.jpeg"/></div></div></figure><div class=""/><p id="746f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在 Sklearn Python 库中，有一组可以导入的示例数据集。在这些数据集中，有一个二元分类乳腺癌数据集，是从威斯康星州的观察中提取的。我选择为一个个人项目研究这个数据集，因为它提出了一个我认为有影响力和有趣的主题(也是练习我在数据科学方面的技能的好方法)——<strong class="ka jc">我的目标是训练一个分类模型来识别恶性乳腺癌肿瘤，准确率为&gt; 95% </strong>。数据集可以按如下方式导入:</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi kw"><img src="../Images/1987d2796ad889fd66ad430988e9def1.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/1*zvj7pWIpt-bOKuooCNTZVg.png"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Importing the Data Set</figcaption></figure></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="f3a4" class="lm ln jb bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">构建用于比较的基线模型</h1><p id="8d9d" class="pw-post-body-paragraph jy jz jb ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">在对数据集进行任何分析之前，<strong class="ka jc">通常最好建立一个基线分类模型，该模型可以用作基准</strong>来决定机器学习模型是否有效。为了建立这个基线模型，我观察了数据集中“恶性”(标记为 1)和“良性”(标记为 0)观察值的分布。根据这些分类类别中哪一个更有可能(或发生率更高)，我预测每个观察结果都属于更有可能的类别。下图显示了两个目标类别的分布情况:</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/3c1249b823dcf9282b4119471c9748aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*uFfGOFBCoeTqA9hQRFggJQ.png"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Distribution of the Output Variable</figcaption></figure><p id="3eaa" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从该图可以看出，大约有 350 个“恶性”观察值和大约 220 个“良性”观察值。因此，如果每个观察结果都被预测为恶性，就会创建一个大约 61%准确的模型<strong class="ka jc"/>——这个简单的模型将被用作未来比较的基准。</p></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="5d7d" class="lm ln jb bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">数据清理和预处理</h1><p id="3aba" class="pw-post-body-paragraph jy jz jb ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">在定义了简单的基线模型之后，我执行了一些快速的数据清理和观察，例如<strong class="ka jc">检查空值</strong>，<strong class="ka jc">查看数据集中每个特性的数据类型</strong>，以及<strong class="ka jc">查看集合中观察值的总数</strong>。在这种情况下，因为数据来自 Sklearn python 库中维护的示例集，所以不需要做太多的数据清理工作。如果数据集存储在 pandas 数据框中，可以使用以下命令检查每一列中 null 值的总数:</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/eea629eb7879471e2de07736361548ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:876/format:webp/1*2LCJRrbSB4Md5HzDBoCNjg.png"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Checking for Null Values with Pandas</figcaption></figure><p id="51ab" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这种情况下，<strong class="ka jc">在数据集</strong>中不存在空值，因此不需要替换/清除数据中的空值。此外，当检查每一列的数据类型时(使用熊猫数据框的<strong class="ka jc">“dtypes”</strong>属性)，发现所有数据都是类型<strong class="ka jc">“float 64”</strong>。因此，因为所有的特征都已经是数字的，所以不必进行数据清理来创建可以直接输入到机器学习模型中的特征。这个预处理阶段唯一有趣的发现是数据集只包含 569 个观察值。这是用于训练机器学习模型的非常少量的数据，并且可能在未来产生问题(即，模型的过度拟合或缺乏准确性)，因此在选择使用随机森林对数据进行分类时，这一点得到了充分的考虑(随机森林对过度拟合有很强的抵抗力，在此<a class="ae mr" href="https://www.kdnuggets.com/2017/10/random-forests-explained.html" rel="noopener ugc nofollow" target="_blank">阅读更多关于它们的信息</a>)。</p></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="3410" class="lm ln jb bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated"><strong class="ak">探索性数据分析(EDA) </strong></h1><p id="6cf9" class="pw-post-body-paragraph jy jz jb ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">为了更好地理解数据集以及哪些特征可能对机器学习模型有用，进行了简单的数据分析和可视化。对数据集进行的第一个查询是可视化数据集中所有不同特征的相关性矩阵(在熊猫数据帧上使用<strong class="ka jc">“corr”</strong>方法计算相关性)。该关联图<strong class="ka jc">揭示了哪些特征为问题提供了新信息，哪些特征与集合中的其他特征</strong>相似。相关矩阵被绘制为热图，这使得数据集中各要素之间的相关性变得易于查看。看起来如下:</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ms"><img src="../Images/c7d840f7043555a622daa6e00928a534.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UX4k8lSdBaKCDtsSlW7v8w.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Correlation Heat Map for the Breast Cancer Data Set</figcaption></figure><p id="f78f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这种情况下，具有白色的特征对彼此高度相关，因此呈现出与问题相似的信息。例如，特征对(0，2)、(0，3)和(2，3)都高度相关。后来，当为机器学习模型选择特征时，考虑了这种高相关性，并且消除了与其他特征具有非常高相关性(&gt; 98%)的特征。</p><p id="2bd8" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">除了可视化相关性，还对数据集中的每个特征进行了单变量分析和可视化。更具体地说，创建了特征值及其相关分类的散点图和每个目标类别的平均特征量图。单独查看每个特征的分布会使<strong class="ka jc">更好地理解每个目标类别</strong>之间哪些特征具有明显/可见的差异，从而揭示哪些特征在创建分类模型时会有用。这些可视化的一些结果如下:</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mt"><img src="../Images/0aed2110dc87ac8857106ae9585a77f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z3ZYLeK_iBeVbCMVEp60Qw.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Univariate Visualization Ex. 1</figcaption></figure><p id="e234" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这种情况下，特征 5 显示了两个目标分类类别之间值的<strong class="ka jc">明显差异，其中分类为“良性”(0)的观察值似乎比分类为“恶性”(1)的观察值更高。因此，该可视化暗示特征 5 可能是包括在最终分类模型中的有用特征。</strong></p><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mu"><img src="../Images/fba26b0efa8fa4c2754c585e63e20da3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZM-c1JJ9QSnuStxAN2D2Jg.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Univariate Visualization Ex. 2</figcaption></figure><p id="8be3" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在上面的可视化中，特征 7 似乎在两个目标类别之间具有<strong class="ka jc">相似的特征——散点图上 1 和 0 大致相似的位置以及相似的平均特征值。因此，这种可视化暗示了特征 7 在确定准确分类时对我们的模型可能不是那么有用。</strong></p><p id="74f9" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">当决定在训练机器学习模型中使用哪个特征时，在两个目标分类类别之间表现出显著特征差异的特征被保留，而没有表现出这种差异的特征被去除。一旦排除了这些特性，就创建了一个聚合可视化(使用 seaborn python 库中的<strong class="ka jc"> "pairplot" </strong>方法)来查看集合中最有趣的特性的整体属性。结果如下:</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/b0f920d593374e2f40c8dd001e9363f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JcknwVhXsiXfFr5s4WnWdA.png"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Pair Plot of Selected Features</figcaption></figure><p id="05f7" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">上面的图由每个观察值的分类值着色。对于配对图中的每个特征，可以注意到，在大多数情况下，可以注意到两个目标分类类别之间的值的差异。</p></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="9d31" class="lm ln jb bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated"><strong class="ak">特征工程/选择</strong></h1><p id="b373" class="pw-post-body-paragraph jy jz jb ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">在数据集上执行简单的 EDA 之后，哪些特征将对机器学习模型有用变得非常清楚。因此，在选择/创建特征时没有做太多额外的工作。尝试用于自动特征选择的一些方法包括:</p><ul class=""><li id="5e91" class="mw mx jb ka b kb kc kf kg kj my kn mz kr na kv nb nc nd ne bi translated">使用 Sklearn 创建多项式和交互式特征。</li><li id="6ca2" class="mw mx jb ka b kb nf kf ng kj nh kn ni kr nj kv nb nc nd ne bi translated">运行简单的随机森林，并根据要素对模型的重要性选择要素。</li><li id="9ce1" class="mw mx jb ka b kb nf kf ng kj nh kn ni kr nj kv nb nc nd ne bi translated">消除与集合中其他特征高度相关的特征。</li></ul><p id="fbe9" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">创建多项式要素并没有提高随机森林模型的性能(精度实际上降低了)。然而，<strong class="ka jc">使用随机森林的“feature_importances_”属性</strong>过滤特征非常有用，并最终提高了最终模型的准确性。为了创建这样的过滤器，在现有特征集(不包括多项式特征)上训练默认随机森林，并且通过参考训练的随机森林的“feature_importances_”属性来确定每个特征的重要性。为重要性低的特征设置阈值<strong class="ka jc">，重要性低于重要性阈值的所有特征都从数据集中删除</strong>。测试了几个重要性阈值，以确定哪一个性能最好，结果如下:</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/85a0bbd949086aa1326948e33c5a66a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*Vek1j2eOWO7AnCAK6DbOzQ.png"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Feature Filtering on Different Importance Thresholds</figcaption></figure><p id="6814" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从上面的报告中可以看出，最佳过滤阈值是 0.008，准确率为 95.5%(高于我最初的目标！).在特征工程的最后一步之后，工作开始建立最终模型。</p></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="2c54" class="lm ln jb bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">构建随机森林模型</h1><p id="851c" class="pw-post-body-paragraph jy jz jb ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">对于这个实验，使用 Sklearn 随机森林分类器对数据进行分类。可以使用以下代码导入该模型并使其适合一组观察值:</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/2ee1c40bdb4a990c086d9c75260606dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*uPrVuksIDaO6XPVqIKh15Q.png"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Example of Constructing a Random Forest Classifier</figcaption></figure><p id="b3a1" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">上面的代码从 Sklearn 库中导入随机森林，用 50 棵树的大小实例化它(<strong class="ka jc"> n_estimators </strong>是将被构造来形成随机森林对象的决策树的数量)，并使随机森林适合一组测试数据。在这个实验中，使用 Sklearn.model_selection 中的<strong class="ka jc"> "train_test_split" </strong>方法将数据分成训练集和测试集，该方法根据所需的比率将数据分成训练组和测试组。当随机森林使用分区的训练和测试数据进行训练时，结果如下:</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/617afd8fbf84ca4cd0dbf8f196106b05.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*Z5vWwLtIASAuGnsdsn-TLg.png"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Random Forest Accuracy</figcaption></figure><p id="ae41" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从上面可以看出，50 棵决策树的随机森林在数据集上获得了 95.77% 的<strong class="ka jc">准确率！这超过了该实验最初设定的 95%的准确率目标。然而，在实验结束之前，对随机森林的不同数量的估计量进行了测试，以查看模型是否可以变得更加精确。此外，最高性能随机森林的<strong class="ka jc">精度和召回</strong>被观察以获得关于模型的整体质量的另一个度量。</strong></p></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="c720" class="lm ln jb bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">测试不同的随机森林大小</h1><p id="4410" class="pw-post-body-paragraph jy jz jb ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">选择了 25、50、75、100、125 和 150 的随机森林大小，并测试了每个模型的准确性，以确定哪种大小的随机森林最有效。结果如下:</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/507413277b130da5dff763e22086cb96.png" data-original-src="https://miro.medium.com/v2/resize:fit:486/format:webp/1*ghkS9wWl6DYIVg_8Up93jA.png"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Accuracy with Different Forest Sizes</figcaption></figure><p id="ce1c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在上面的报告中，可以看到最准确的森林大小是 125，准确率为 96.7%！这样的准确率远远高于 95%的最初目标，因此<strong class="ka jc">该模型被选为表现最好的</strong>，然后观察该模型的精确度和召回率以评估其整体质量。</p></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="88d4" class="lm ln jb bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">精确度和召回率</h1><p id="56f1" class="pw-post-body-paragraph jy jz jb ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">因为原始数据集有些不平衡(目标分类类别不是均匀分布的)，<strong class="ka jc">除了准确性</strong>之外，对我的模型的质量进行度量是一种很好的做法——具有不平衡目标变量分布的模型可能会获得较高的准确性，但实际上并没有很好地拟合数据。因此，决定观察每个目标分类类别的模型的<strong class="ka jc">精度</strong>和<strong class="ka jc">召回</strong>。如果你对这些术语不熟悉，我推荐你阅读<a class="ae mr" href="http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html" rel="noopener ugc nofollow" target="_blank">这篇文章</a>来更好地理解它们。与准确度一样，精确度和召回率也是评估机器学习模型有效性的一个指标。使用以下代码可以观察随机森林模型的精度和召回率:</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/aa227465bebc3ba3592d4f1aea2bdbcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*aes-h9f7tlXkPjyJ0S4Exw.png"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Code for Finding Precision and Recall</figcaption></figure><p id="547c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用上述代码，评估了 125 估计量随机森林模型的精度和召回率，以获得以下结果:</p><figure class="kx ky kz la gt is gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/9c07c5c857ef9364c3571893ba6b2520.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*2iqjLIWBZnruarJ0cDdZzQ.png"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Precision/Recall Score</figcaption></figure><p id="a664" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该模型平均获得了<strong class="ka jc"> 99%的精确度和</strong>99%的召回率，这是一个非常好的分数(1.0 是这两个分数的最高分)。观察到这一指标后，很明显随机森林分类模型与数据吻合得很好，准确率超过 96%，精确度/召回分数为 99% 。</p></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="57d6" class="lm ln jb bd lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj bi translated">结论</h1><p id="c910" class="pw-post-body-paragraph jy jz jb ka b kb mk kd ke kf ml kh ki kj mm kl km kn mn kp kq kr mo kt ku kv ij bi translated">在这篇文章中，我使用 Sklearn 乳腺癌数据集建立了一个随机森林分类模型，将乳腺癌肿瘤分为“恶性”或“良性”。我最初的目标是获得一个至少 95%准确的模型。在对简单的 EDA 进行预成型以确定数据集中最重要的特征，分析各种选定特征的特征重要性，并测试不同大小的随机森林后，我得到了一个最终的模型，其准确率为<strong class="ka jc"> 96.7% </strong>！</p><p id="7276" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你想看看这个项目的源代码，你可以看看为它创建的<a class="ae mr" href="https://github.com/wolfecameron/MachineLearning/blob/master/breast_cancer_classification.py" rel="noopener ugc nofollow" target="_blank"> <em class="no"> GitHub 库</em> </a>！如果你有任何问题或者想关注我未来的帖子，请随时评论这篇帖子或者通过<a class="ae mr" href="https://www.linkedin.com/in/cameron-wolfe-9b2511144/" rel="noopener ugc nofollow" target="_blank"> <em class="no"> LinkedIn </em> </a>与我联系。<strong class="ka jc"> <em class="no">非常感谢您的阅读！</em>T11】</strong></p></div></div>    
</body>
</html>