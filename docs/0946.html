<html>
<head>
<title>Summary of — SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SegNet概述:一种用于图像分割的深度卷积编解码器架构</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/summary-of-segnet-a-deep-convolutional-encoder-decoder-architecture-for-image-segmentation-75b2805d86f5?source=collection_archive---------1-----------------------#2017-07-12">https://towardsdatascience.com/summary-of-segnet-a-deep-convolutional-encoder-decoder-architecture-for-image-segmentation-75b2805d86f5?source=collection_archive---------1-----------------------#2017-07-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="7239" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">论文发表者:Vijay Badrinarayanan、Alex Kendall、Roberto Cipolla在CVPR第15届年会上发表</em></p><div class="km kn ko kp gt ab cb"><figure class="kq kr ks kt ku kv kw paragraph-image"><img src="../Images/aee7d9402d08cefbecfba8d301c3822c.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/0*kGCVloqCq5-4vJJV.gif"/></figure><figure class="kq kr ks kt ku kv kw paragraph-image"><img src="../Images/0c3cd35375970eb5df427d288bbdd302.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/0*rneNsJQbl5ipVNeL.gif"/></figure></div><div class="ab cb"><figure class="kq kr ks kt ku kv kw paragraph-image"><img src="../Images/b0741380b3f7cb59a070257ab66a6177.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/0*6Af__v2koUPyuUOe.gif"/></figure><figure class="kq kr ks kt ku kv kw paragraph-image"><img src="../Images/a70e2b0db952ea4cb32d06c8c1500fa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/0*NXN7P4T2NX8fS_Q1.gif"/></figure></div><div class="ab cb"><figure class="kq kr ks kt ku kv kw paragraph-image"><img src="../Images/8b289b5582adfe56e9edbf37ef8def0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/0*Ml_MwepObqe8oBQ2.gif"/></figure><figure class="kq kr ks kt ku kv kw paragraph-image"><img src="../Images/93fb7057920c703dcccf40493bd3d552.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/0*EfGm46B7NV6Eyyf5.gif"/><figcaption class="kz la gj gh gi lb lc bd b be z dk ld di le lf">Some videos I used to play around with SegNet</figcaption></figure></div><p id="d91c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">欲了解更多关于复制这一点的信息，请访问我的回购</em> <a class="ae lg" href="https://github.com/saytosid/segnet_docker_cs671" rel="noopener ugc nofollow" target="_blank"> <em class="kl">这里</em> </a></p><h1 id="e1b5" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">TLDR:</h1><ul class=""><li id="50ef" class="mf mg iq jp b jq mh ju mi jy mj kc mk kg ml kk mm mn mo mp bi translated">使用一种新颖的技术来对编码器输出进行上采样，该技术涉及存储池层中使用的最大池索引。这提供了相当好的性能和空间效率</li><li id="95ce" class="mf mg iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated">仅具有前向连接和不可训练层的VGG16用作编码器。这导致参数非常少。</li></ul><h1 id="762c" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">问题</h1><ul class=""><li id="ae43" class="mf mg iq jp b jq mh ju mi jy mj kc mk kg ml kk mm mn mo mp bi translated">语义逐像素标记，即将图像的每个像素标记为属于图像中所示的某个类别(树、道路、天空等)。</li></ul><figure class="km kn ko kp gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi mv"><img src="../Images/4ce7821d86dc649878e4dabf9652c8ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*v_KWTZcaAw-DRxmv.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Fig 1: Segmentation of a road scene imagess</figcaption></figure><p id="d3a8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一些应用包括自动驾驶、场景理解等。直接采用分类网络进行逐像素分割会产生较差的结果，这主要是因为<em class="kl">最大池</em>和<em class="kl">子采样</em>会降低特征图分辨率，从而降低输出分辨率。即使外推至原始分辨率，也会产生有损图像。</p><h1 id="0401" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">SegNet —挑战</h1><ul class=""><li id="a3c6" class="mf mg iq jp b jq mh ju mi jy mj kc mk kg ml kk mm mn mo mp bi translated">在道路场景数据集上训练，因此，类表示宏观对象，因此期望分割是平滑的</li><li id="b134" class="mf mg iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated">边界信息对于像道路标记和其他小物体这样的物体是至关重要的。(<em class="kl">边界划定</em></li><li id="c9d6" class="mf mg iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated">主要用例将是嵌入式系统，因此它必须<em class="kl">计算高效</em></li></ul><h1 id="e2ff" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">SegNet-架构</h1><p id="6592" class="pw-post-body-paragraph jn jo iq jp b jq mh js jt ju mi jw jx jy na ka kb kc nb ke kf kg nc ki kj kk ij bi translated">编码器-解码器对用于为不同分辨率的分类创建特征图。</p><figure class="km kn ko kp gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi nd"><img src="../Images/1e8532c8d4902061a10b3a75a0588fe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AM6HnBSBXv4cFk3N.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Fig 2: Nut-shell architecture</figcaption></figure><h1 id="150b" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">编码器</h1><ul class=""><li id="147f" class="mf mg iq jp b jq mh ju mi jy mj kc mk kg ml kk mm mn mo mp bi translated">13个VGG16 Conv层</li><li id="537f" class="mf mg iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated">没有完全连接，这将参数从134米减少到14.7米</li><li id="70a3" class="mf mg iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated">良好的初始权重是可用的，因此这些层是不可训练的</li></ul><figure class="km kn ko kp gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi ne"><img src="../Images/4d297ed0cd326b77b4da82df2f6d6014.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*22ydRfyjbwthN9ar.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Fig 3: Encoder architecture</figcaption></figure><p id="af60" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">每个编码器如图3所示。新颖性在于二次采样阶段，最大池用于实现图像中小空间位移的平移不变性，将其与二次采样相结合，导致每个像素管理一个<em class="kl">更大的输入图像上下文</em>(空间窗口)。这些方法实现了更好的分类精度，但是减小了特征图的大小，这导致了具有模糊边界的有损图像表示，这对于分割目的来说是不理想的。希望输出图像分辨率与输入图像相同，为了实现这一点，SegNet在其解码器中进行上采样，为此它需要存储一些信息。在子采样之前，需要<em class="kl">捕获并存储</em>编码器特征图中的边界信息。为了有效地利用该空间，SegNet只存储<em class="kl">最大汇集索引</em>，即每个汇集窗口中最大特征值的位置是为每个编码器映射存储的。2x2的每个窗口只需要2位，精度略有损失，但是<em class="kl">折衷</em>。</p><p id="bd1e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">优势</strong></p><ul class=""><li id="ea42" class="mf mg iq jp b jq jr ju jv jy nf kc ng kg nh kk mm mn mo mp bi translated">改进的边界划分</li><li id="98cc" class="mf mg iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated">参数数量较少</li></ul><figure class="km kn ko kp gt kr gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/4d5797d7b67e5595f1dd4c9b521a9a01.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/format:webp/0*zVNqdSU6E7T2AxSp.png"/></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Fig 4: Upsamplig in SegNet</figcaption></figure><p id="6eb2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种形式的上采样可以结合到任何编码器-解码器架构中</p><h1 id="7226" class="lh li iq bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me bi translated">解码器</h1><ul class=""><li id="c658" class="mf mg iq jp b jq mh ju mi jy mj kc mk kg ml kk mm mn mo mp bi translated">对于13个编码器中的每一个，都有一个相应的解码器，该解码器使用存储的<em class="kl">最大池索引</em>对特征图进行上采样</li><li id="a311" class="mf mg iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated">生成更高分辨率的稀疏特征地图</li><li id="dc17" class="mf mg iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated">稀疏地图通过<em class="kl">可训练滤波器组</em>生成密集特征地图</li><li id="70a9" class="mf mg iq jp b jq mq ju mr jy ms kc mt kg mu kk mm mn mo mp bi translated">最后一个解码器连接到对每个像素进行分类的<em class="kl"> softmax分类器</em></li></ul><p id="7abb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">SegNet论文将其技术与其他几种解码器进行了比较，如图5所示。</p><figure class="km kn ko kp gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="gh gi nj"><img src="../Images/5144ec0c53b06fba6689ab8f6f8e0b70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*T-4YCT9d-06JOUNE.png"/></div></div><figcaption class="kz la gj gh gi lb lc bd b be z dk">Fig 5: Several decoders compared</figcaption></figure></div><div class="ab cl nk nl hu nm" role="separator"><span class="nn bw bk no np nq"/><span class="nn bw bk no np nq"/><span class="nn bw bk no np"/></div><div class="ij ik il im in"><p id="338f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kl">最初发布于</em><a class="ae lg" href="http://saytosid.github.io/segnet" rel="noopener ugc nofollow" target="_blank"><em class="kl">say tosid . github . io</em></a><em class="kl">。</em></p></div></div>    
</body>
</html>