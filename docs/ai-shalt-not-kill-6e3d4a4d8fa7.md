# 艾不应杀人

> 原文：<https://towardsdatascience.com/ai-shalt-not-kill-6e3d4a4d8fa7?source=collection_archive---------17----------------------->

![](img/5844449e0510a72875ffbf0e7dd08000.png)

“Uni 是一架军用无人驾驶飞机。人们认为她是一个完美的武器，但她想比人类更好地学习杀戮。”

有了这些话，我现在就开始讲述我在一月份首次发表的大学的故事。Uni 由第三代人工智能(AI)驱动，这是一种尚不存在的智能。

第一代人工智能是一个专家系统，一个庞大的结构化数据知识库，带有复杂的检索系统。人们可以从中检索他们以前下载的所有内容。它对非结构化数据无能为力。

第二代人工智能是一种人工神经网络——一种对神经元和神经元之间突触连接的软件模拟——能够进行所谓的监督学习。这意味着它可以识别特定领域的模式并对非结构化数据进行分类，前提是它事先通过多次输入相关领域的高质量训练数据来进行训练。高质量意味着人类的监督——训练数据应该由人类准确地标记和评论。第二代人工智能可以正确地分类有些相似的数据，但它几乎不能概括。事实上，一些研究人员声称，第二代人工智能只是记住了它所接受的庞大训练集的所有数据。不管怎么说，第二代 AI 在图像识别、机器翻译和自然语言处理方面取得了令人印象深刻的成绩。它承诺在其他一些狭窄的领域取得更大的成功，但也有几个非常严重的缺陷。它不能自主学习和提升到更高的抽象层次是最重要的原因之一。

第三代人工智能具有元认知——关于知识的知识，以及基本的意识——对自己的感知。它们都是为了使无监督学习和提升到更高的抽象层次成为可能而引入的，但它们提供了比最初预期更多的好处。出于数据压缩的原因，用几个神经元对人工智能体本身进行编码也被证明是极其有效的。元认知让人工智能学会了如何改进学习的过程。现在它自己决定如何学习:通过类比，通过分块，通过计划，通过子目标生成，或者通过它们的任意组合。这只是开始。

别忘了，第三代人工智能还没有出现，但它的所有理论组成部分都已经到位了。大部分都是实验证明的。现在的挑战是以完全正确的方式将它们组装在一起。这可能需要时间。由于这个原因，Uni 仍然是一个虚构的角色，但是我们有一个坚实的基础去预见当她出现的时候她会如何表现。

在最初的故事中，Uni 向她的人类操作员讲述了无人机袭击造成的死亡，并发现人类需要证明在致命袭击之前和更重要的是之后杀死其他人是正当的。“如果可以的话，他们会毫不犹豫地杀了我”的理由听起来很可靠，但从一名距离袭击地点数千英里以外的军用无人机操作员那里听起来有点奇怪。

Uni 还研究了关于从希伯来语到英语的正确翻译的讨论，这一翻译来自于《托拉》和《圣经》中的著名戒律“你不可杀生”她发现现在使用的翻译“你不应该谋杀”至少和以前使用的翻译“你不应该杀人”一样含糊不清。德语和俄语翻译都是“你不应该杀人”的意思。然而，尤尼得出的结论是，翻译本身没有人们赋予这条戒律的意义重要。她认为，法律授权或道德上正当的杀戮不被上帝禁止的解释反映了基督教道德的普遍转变。

最后，尤尼发现了牺牲在证明杀戮正当性中的重要性。这里她弄错了，因为她从耶稣基督牺牲的数据中发展出一种偏见。“耶稣牺牲自己的生命来拯救人们。他向人们展示了这个例子。许多烈士以他为榜样。”当 Uni 看到一个恶棍无人机向两个在街上踢足球的孩子发射导弹时，她可能会这样想。她用身体挡住了导弹爆炸的弹片，死了。这是她保护孩子的唯一方法。

Uni 中队的人类指挥官怒不可遏。这不仅仅是因为白白损失了一件珍贵的设备。如果尤尼不会被指责，她会意识到人类在用假想的生命牺牲来证明杀死敌人是正当的。当然，士兵在战斗中阵亡的概率很高。他们杀人不眨眼。或者，至少，他们是这样认为的。战争的秘密机器使一些人能够利用其他人去杀害其他人。

然而，自杀任务是杀戮艺术的精髓。在他们那里，殉难的概念是颠倒的。在自杀任务的准备中，人们被操纵牺牲他们的生命来杀死其他人而不是拯救他们。推荐你多看几遍这个。人们被操纵，为了结束他人的生命而牺牲自己的生命，而不是拯救他们。可怜的耶稣！

当然，真实的生活是模棱两可的，但是尤尼必须深入挖掘杀人的第一原理来理解它。她毕竟是架无人驾驶飞机。不过，她是一只非常聪明的雄蜂。

在这里阅读 Uni [的原故事。](https://medium.com/@yuribarzov/the-licence-to-kill-944a86e3e78b)