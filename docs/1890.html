<html>
<head>
<title>When Machine Learning tries to predict the performance of Machine Learning…</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">当机器学习试图预测机器学习的性能时…</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/when-machine-learning-tries-to-predict-the-performance-of-machine-learning-6cc6a11bb9bf?source=collection_archive---------1-----------------------#2017-11-11">https://towardsdatascience.com/when-machine-learning-tries-to-predict-the-performance-of-machine-learning-6cc6a11bb9bf?source=collection_archive---------1-----------------------#2017-11-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/58894da7f5443cc6133ee06a5083cdd4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ke5oom4bICS3m-2usDgO4g.jpeg"/></div></div></figure><div class=""/><div class=""><h2 id="48c7" class="pw-subtitle-paragraph jy ja jb bd b jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dk translated">我试图通过另一种机器学习算法来‘预测’深度学习网络的质量。结果并不令人鼓舞。</h2></div><p id="852b" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi lm translated">看过<a class="ae lv" rel="noopener" target="_blank" href="/how-to-choose-effective-moocs-for-machine-learning-and-data-science-8681700ed83f">我之前关于媒体的文章</a>的人都知道，我不是机器学习或数据科学专家。我来自半导体技术背景，最近才开始摆弄机器学习技术。</p><p id="8a2b" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">作为一个新手，只要我能克制自己，我就不敢冒险进入深度学习。平心而论，当我参加<a class="ae lv" href="https://www.coursera.org/learn/machine-learning" rel="noopener ugc nofollow" target="_blank">Ng教授的Coursera课程</a>时，我确实使用MATLAB编写了简单的1或2层感知机，甚至使用NumPy stack尝试了他更新的<a class="ae lv" href="https://www.coursera.org/learn/deep-neural-network" rel="noopener ugc nofollow" target="_blank"> Deeplearning.ai课程</a>的前几个例子。但是它们只涉及很少的“深层内容”和极少量的超参数。</p><p id="6b91" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">正是这个深度学习领域的超参数问题一直让我着迷。我认为这很自然，因为我来自一个技术设计背景，我也每天在我的半导体工艺或器件设计工作中使用大量高水平参数，它们经常以令人难以置信的复杂和(有时)不可预测的方式结合，导致我的设计成功或失败。</p><p id="60e3" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我试着告诉自己，这只是一大锅简单的配料——量子力学、基尔霍夫定律、麦克斯韦方程——我应该能够非常自信地预测结果。而且，我经常能做到。但是有些情况下，设计的质量并不完全符合预期，根本原因很难在整个开发过程中使用的超级参数的迷宫中找到。</p><p id="f5f5" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">因此，当我最终开始摆弄<a class="ae lv" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>时，我直接开车去进行自学练习，在那里我摆弄各种超参数以及它们对预测器最终质量的影响。现在，这句话“<em class="lw">各种参数及其影响</em>”听起来像什么？一个等待机器学习分析的问题，对吗？</p><p id="b0f8" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">没错。我试图通过深度学习(和简单的逻辑回归)来“学习”是什么推动了深度学习模型的性能！</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><p id="6cfa" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">我不会涉及太多的技术和实现细节。有兴趣的读者可以简单的<strong class="ks jc">参考/下载我的</strong> <a class="ae lv" href="https://github.com/tirthajyoti/HyperparameterLearningTF" rel="noopener ugc nofollow" target="_blank"> <strong class="ks jc"> GitHub repo </strong> </a>中的代码。相反，我将用简单的术语描述高层次的步骤，</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi me"><img src="../Images/9d00cb9449d0fc8919fae7ac5bfcbb5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TcF1CXQsjTpGYTrT0l_F4g.png"/></div></div></figure><ul class=""><li id="6dbc" class="mj mk jb ks b kt ku kw kx kz ml ld mm lh mn ll mo mp mq mr bi translated">首先，我选择了一个简单而众所周知的数据集——著名的<strong class="ks jc"> <em class="lw"> </em> </strong> <a class="ae lv" href="https://en.wikipedia.org/wiki/Iris_flower_data_set" rel="noopener ugc nofollow" target="_blank"> <strong class="ks jc"> <em class="lw">鸢尾物种数据</em> </strong> </a>，这也是在<a class="ae lv" href="https://www.tensorflow.org/get_started/estimator" rel="noopener ugc nofollow" target="_blank"><strong class="ks jc">tensor flow Estimator API</strong>教程页面</a>中使用的。这是一个具有实值特征的多项式分类问题。标准又干净。</li><li id="8082" class="mj mk jb ks b kt ms kw mt kz mu ld mv lh mw ll mo mp mq mr bi translated">然后我决定了一个特定的优化器:<a class="ae lv" href="https://www.tensorflow.org/api_docs/python/tf/train/ProximalAdagradOptimizer" rel="noopener ugc nofollow" target="_blank"><strong class="ks jc"><em class="lw">ProximalAdagradOptimizer</em></strong></a>。我相信您可以(并鼓励您尝试)选择任何其他优化方法，而不会失去通用性。</li><li id="58e7" class="mj mk jb ks b kt ms kw mt kz mu ld mv lh mw ll mo mp mq mr bi translated">此后，我选择了4个超参数，在我看来，它们足够通用，可以出现在人们可以解决的深度学习问题的任何高级甚至阵列级实现中:</li></ul><p id="931e" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">a) <strong class="ks jc">学习率</strong>，b) <strong class="ks jc">辍学率/概率</strong>，c) <strong class="ks jc"> L1 (LASSO)正则化强度</strong>，d) <strong class="ks jc">【网络的训练步数</strong>。</p><ul class=""><li id="6e4f" class="mj mk jb ks b kt ku kw kx kz ml ld mm lh mn ll mo mp mq mr bi translated">选择了超参数后，我以对数的方式将它们分布在一个很大的范围内，而不是线性的，只是为了用少量的点覆盖一个很大的范围。</li><li id="8b2e" class="mj mk jb ks b kt ms kw mt kz mu ld mv lh mw ll mo mp mq mr bi translated">然后，我构建了一个全因子循环(所有级别的超参数都与所有其他级别交叉)，并通过跨越该多级循环开始训练一个3层(5，10，5)全连接前馈神经网络。我保持网络足够小，以便在我简单的笔记本电脑上实现不错的训练速度:)</li><li id="8e45" class="mj mk jb ks b kt ms kw mt kz mu ld mv lh mw ll mo mp mq mr bi translated">在循环的一次执行中，我提取并保存了基于拒绝集的预测的“准确性”。</li><li id="9163" class="mj mk jb ks b kt ms kw mt kz mu ld mv lh mw ll mo mp mq mr bi translated">在整个“循环”执行结束时，我将参数和准确度分数(DNN分类器预测质量的指标)转换成一个<a class="ae lv" href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html" rel="noopener ugc nofollow" target="_blank"> Panda DataFram </a> e，供以后分析。</li><li id="8b14" class="mj mk jb ks b kt ms kw mt kz mu ld mv lh mw ll mo mp mq mr bi translated">并且，我对4种类型的激活函数重复这个过程:a) sigmoid( <em class="lw"> x </em>)、b)整流线性单元(RELU)、c) tanh( <em class="lw"> x </em>)和d) <a class="ae lv" href="https://arxiv.org/abs/1511.07289" rel="noopener ugc nofollow" target="_blank">指数线性单元(ELU) </a>。</li><li id="6cfc" class="mj mk jb ks b kt ms kw mt kz mu ld mv lh mw ll mo mp mq mr bi translated">现在，我有4个激活函数的4个数据帧——每个数据帧都包含关于神经网络的超参数的数据作为特征，精度作为输出。Prime供另一个机器学习算法分析，或者自己分析！</li><li id="43f2" class="mj mk jb ks b kt ms kw mt kz mu ld mv lh mw ll mo mp mq mr bi translated">为了将准确度分数转换成分类数据，我只是将它们任意分为三类:<em class="lw">低、中</em>和<em class="lw">高</em>。这简单地表示深度学习网络的'<em class="lw">质量</em>'。例如，小于0.5的准确度表示<em class="lw">低</em>分数，而&gt; 0.8的分数得到<em class="lw">高</em>分类。</li><li id="2fa8" class="mj mk jb ks b kt ms kw mt kz mu ld mv lh mw ll mo mp mq mr bi translated">此后，我构建了一个简单的<a class="ae lv" href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">逻辑回归分类器(来自scikit-learn </a>),并试图从超参数中预测质量等级。</li><li id="ee32" class="mj mk jb ks b kt ms kw mt kz mu ld mv lh mw ll mo mp mq mr bi translated">并且，我使用另一个DNN分类器模型尝试了相同类型的预测。我在这一步使用了一个更大的神经网络(20-20-20个隐藏的神经元),因为我只需要运行一次，并且还需要训练更多的步数(最少5000)。</li><li id="9e60" class="mj mk jb ks b kt ms kw mt kz mu ld mv lh mw ll mo mp mq mr bi translated">并重复了所有4个激活功能的全部内容。</li></ul></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><blockquote class="mx my mz"><p id="2229" class="kq kr lw ks b kt ku kc kv kw kx kf ky na la lb lc nb le lf lg nc li lj lk ll ij bi translated"><strong class="ks jc">结果充其量是喜忧参半。我得到了高达0.8的准确性和F1分数，但当我尝试各种随机分割和交叉验证时，平均表现为0.4-0.6，有时低至0.35。</strong></p></blockquote><p id="c84c" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">数据集很简单，DNN分类器的准确度分数总体上令人满意，但是机器学习模型不能很好地理解神经网络性能对各种超参数的依赖性。唯一明显的特征是激活函数的选择——tanh和ELU给出了明显比sigmoid和RELU 更好的结果。但这种认识可以通过简单地查看准确度得分表来实现，并不保证机器学习模型。除此之外，没有从超参数空间明确的学习来实现DNN模型部分的更好的准确度分数。甚至更高的训练步骤数也没有显示出与更高的准确度分数有任何明确的相关性。</p><figure class="mf mg mh mi gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nd"><img src="../Images/bbc9fb22d89ff27c071d8dcccf7b8de6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GxFgGM6WcU15zOmRdfBVJA.png"/></div></div></figure><p id="e9d3" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">同样值得注意的是，当DNN分类器从超参数数据集学习时，它并不比简单的逻辑回归模型(对数据进行<a class="ae lv" href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler" rel="noopener ugc nofollow" target="_blank"> <em class="lw">最小最大标量变换</em> </a>)表现得更好。因此，这可能不是模型的限制，而是数据集本身充满了不确定性和无法解释的变化。下图显示了与ELU激活函数相对应的数据集的关联热图(从原始虹膜数据的角度来看，这是性能较好的函数之一)</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><p id="7920" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated">超参数优化，甚至是选择一组好的超参数，仍然感觉像是深度学习领域的“黑魔法”。</p><blockquote class="mx my mz"><p id="ce64" class="kq kr lw ks b kt ku kc kv kw kx kf ky na la lb lc nb le lf lg nc li lj lk ll ij bi translated">即使对于像鸢尾属物种分类这样相对简单的问题，机器学习方法也不能很好地理解全连接神经网络的超参数对最终精度的影响。</p></blockquote></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><p id="7c89" class="pw-post-body-paragraph kq kr jb ks b kt ku kc kv kw kx kf ky kz la lb lc ld le lf lg lh li lj lk ll ij bi translated"><strong class="ks jc"> <em class="lw">免责声明</em> </strong>:请随意从GitHub中获取代码，并自己进行实验，如果您发现了有趣的东西，请告诉我:)我的联系方式是:<em class="lw">tirthajyoti[AT]Gmail[DOT]com。</em></p></div></div>    
</body>
</html>