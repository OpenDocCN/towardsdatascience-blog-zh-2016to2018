<html>
<head>
<title>Machine Learning Basics — Part 4 — Anomaly Detection, Recommender Systems and Scaling</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习基础—第 4 部分—异常检测、推荐系统和扩展</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/machine-learning-basics-part-4-anomaly-detection-recommender-systems-and-scaling-b8bbf0413aa9?source=collection_archive---------1-----------------------#2018-03-16">https://towardsdatascience.com/machine-learning-basics-part-4-anomaly-detection-recommender-systems-and-scaling-b8bbf0413aa9?source=collection_archive---------1-----------------------#2018-03-16</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/6e3ba99e4432ccc96d6dc11e9434bf25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7RYTZ6RG3MYWST0w."/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by Fahrul Azmi on Unsplash — <a class="ae kf" href="https://unsplash.com/photos/vR-Nb0bncOY" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/vR-Nb0bncOY</a></figcaption></figure><p id="db5e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，我重温了 Andre Ng 在 Coursera 上的《神奇的<a class="ae kf" href="https://www.coursera.org/learn/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习课程》中的学习材料，并对这些概念做了一个概述。这篇文章的目的不是作为一个教程，而是更新基本思想。</a></p><p id="9286" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除非另有明确说明，否则所有引用都是指本课程的材料。</p><h1 id="4e51" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">目录</h1><ul class=""><li id="9379" class="mc md it ki b kj me kn mf kr mg kv mh kz mi ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#anomaly-detection" rel="noopener ugc nofollow" target="_blank">异常检测</a></li><li id="bffb" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#develop-a-anomaly-detection-system" rel="noopener ugc nofollow" target="_blank">-开发异常检测系统</a></li><li id="e86c" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#practical-tips-and-difference-to-a-supervised-learning-system" rel="noopener ugc nofollow" target="_blank">-实用技巧和监督学习系统的区别</a></li><li id="a0c6" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#multivariat-gaussian-distribution" rel="noopener ugc nofollow" target="_blank">-多元高斯分布</a></li><li id="bcb8" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#recommender-systems" rel="noopener ugc nofollow" target="_blank">推荐系统</a></li><li id="683b" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#feature-learning-with-collaborative-filtering" rel="noopener ugc nofollow" target="_blank">-使用协同过滤的特征学习</a></li><li id="afc1" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#further-usage" rel="noopener ugc nofollow" target="_blank">-进一步用法</a></li><li id="0b7a" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#scaling-machine-learning-systems" rel="noopener ugc nofollow" target="_blank">扩展机器学习系统</a></li><li id="d306" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#stochastic-gradient-descent" rel="noopener ugc nofollow" target="_blank">-随机梯度下降</a></li><li id="86e8" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#mini-batch-gradient-descent" rel="noopener ugc nofollow" target="_blank">-小批量梯度下降</a></li><li id="0565" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#test-for-convergence" rel="noopener ugc nofollow" target="_blank">-收敛测试</a></li><li id="4fab" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#online-learning" rel="noopener ugc nofollow" target="_blank">-在线学习</a></li><li id="64b4" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#map-reduce-and-data-parallelism" rel="noopener ugc nofollow" target="_blank"> -Map-reduce 和数据并行</a></li><li id="93fc" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#tricks-for-use-on-applications" rel="noopener ugc nofollow" target="_blank">在应用程序上使用的技巧</a></li><li id="c908" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#create-a-pipeline-for-your-problem" rel="noopener ugc nofollow" target="_blank">-为你的问题创建一个管道</a></li><li id="a8a1" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#getting-more-data" rel="noopener ugc nofollow" target="_blank">-获取更多数据</a></li><li id="9f56" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/DDCreationStudios/Writing/blob/master/2018/articles/MLIntroP4.md#ceiling-analysis" rel="noopener ugc nofollow" target="_blank">-上限分析</a></li></ul><h1 id="85e4" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">异常检测</h1><p id="f7d0" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">异常检测针对该范围内其他示例的行为测试一个新示例。这种想法通常用于欺诈检测、机器制造或监控。如果目标是检测某些异常值，它总是有用的。</p><p id="2b5a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用高斯分布算法意味着示例 x 分布有均值μ和方差适马平方。</p><p id="e89b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">μ和适马平方的公式为:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mv"><img src="../Images/57feff7933b3ac30d893000124fcd284.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0SlcKVECTmtYIihg.png"/></div></div></figure><p id="c3fd" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">计算概率的公式是:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi na"><img src="../Images/f77e42f4ed5fd049c8d2f6da57886fcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5ya1BHHxXNQfmxXO.png"/></div></div></figure><p id="d066" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">构建算法的步骤如下</p><ol class=""><li id="2f14" class="mc md it ki b kj kk kn ko kr nb kv nc kz nd ld ne mk ml mm bi translated">选择可能代表异常示例的特征 x</li><li id="122d" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld ne mk ml mm bi translated">计算参数μ和适马</li><li id="b540" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld ne mk ml mm bi translated">计算 x 的概率 p</li><li id="baa0" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld ne mk ml mm bi translated">根据您设定的概率边界ε进行测试</li></ol><h1 id="6cfc" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">开发一个异常检测系统</h1><p id="739a" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">当实现该算法时，引入实数评估度量是很重要的。</p><p id="619d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">与往常一样，建议将数据集分为训练集、交叉验证集和测试集(60–20–20)。</p><p id="4ba2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">建立该系统的步骤如下:</p><ol class=""><li id="bded" class="mc md it ki b kj kk kn ko kr nb kv nc kz nd ld ne mk ml mm bi translated">在训练集上拟合模型 p(x)</li><li id="972a" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld ne mk ml mm bi translated">根据交叉验证和测试集的结果概率预测 y</li><li id="7b9d" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld ne mk ml mm bi translated">使用列联表(真阳性、假阳性等)、精确度/召回方法或 F1 分数评估结果</li><li id="7c7a" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld ne mk ml mm bi translated">改变ε的值(如有必要)</li></ol><h1 id="1843" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">监督学习系统的实用技巧和区别</h1><p id="3b49" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">在以下情况下，应使用异常检测系统</p><ul class=""><li id="f05c" class="mc md it ki b kj kk kn ko kr nb kv nc kz nd ld mj mk ml mm bi translated">有大量的反面例子，但也有少量正面例子</li><li id="e2dc" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated">异常本身不能被分类，并且在将来的例子中可能变化</li><li id="5b1a" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated">例如，欺诈检测、监控机器等。</li></ul><p id="fa3e" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果分类可以很容易地完成，即有大量的正面和负面的例子，未来的例子将是相似的，建议使用监督学习算法。(例如垃圾邮件、癌症分类)</p><p id="958f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了分析误差，有必要绘制特征图，看看它们是否表现为高斯分布。如果没有，可以添加常数(如 log(x))，以尽量使其看起来像高斯分布。</p><p id="1166" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">使用异常检测系统的基本假设是异常实例少，正常实例多。如果不满足这一点，则应检查错误分类的示例的行为是否允许提出新的特征。</p><h1 id="c9d2" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">多元高斯分布</h1><p id="bed8" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">在某些情况下，正态高斯分布不足以准确标记异常。多元高斯分布会立即计算 x 的概率模型，而不是单独为每个要素建立概率模型。它使用协方差矩阵，而不是适马平方。</p><p id="8025" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该公式如下所示:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nf"><img src="../Images/2605fa6a321e712361c1f0c2bc9ab07d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NN1dW3gmnd0gY2Dw.png"/></div></div></figure><p id="0037" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">鉴于:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ng"><img src="../Images/c048396cdbd976c00d76e3dc6247b39f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bJFS1XwWiHQGQwRI.png"/></div></div></figure><p id="5eec" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当样本数远大于特征数时，多元高斯模型是值得考虑的。它捕捉特征之间的相关性，但是计算量很大。当很明显什么特征组合可以捕获异常时，建议首先使用原始高斯模型实现这些特征组合。</p><h1 id="e903" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">推荐系统</h1><p id="1705" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">推荐系统是在现实生活中应用机器学习算法的最常见和最成功的实例之一。</p><p id="7e8c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设你有一个基于内容的推荐系统。首先，一个问题必须被公式化。这可能类似于预测某个用户对某个产品的评价。</p><p id="db2c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">给定电影的评级，为了学习某个用户的参数θ，优化算法可以看起来像这样:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nh"><img src="../Images/0fac61c07f4af3794d3356069ab127e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HdaM9Qk3dmpHUxqH.png"/></div></div></figure><ul class=""><li id="8b0e" class="mc md it ki b kj kk kn ko kr nb kv nc kz nd ld mj mk ml mm bi translated">参数θ表示某个用户的向量</li><li id="1221" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated">特征 x 表示电影的向量</li><li id="12b2" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated">y 表示某个用户对某部电影的评价</li><li id="6740" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated">n 表示用户的数量</li></ul><p id="a132" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这是为不同用户(θj)总结的具有正则化的平方误差的基本成本函数。</p><p id="9116" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">并且使用梯度下降(将学习率α乘以关于优化目标的参数的偏导数)来逐渐最小化结果。注意，k = 0 时的θ0 不应被正则化(如线性回归中所解释的)。</p><h1 id="2b58" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">基于协同过滤的特征学习</h1><p id="6a81" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">给定特定电影的每个用户的参数θ，电影的特征向量可以用优化算法来估计:</p><p id="1b08" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">解决首先计算哪个向量(电影的特征向量或用户的参数向量)的问题的一种方法是猜测用户的参数向量，然后使用该估计来定义电影的(更好的)特征向量。</p><p id="1c03" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种实现被称为协同过滤，因为对于用户的每个评级，该算法能够定义更好的电影特征向量，并改善所有用户的输出。</p><p id="66a6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">为了同时使用协同过滤(同时更新θ和 x)，可以使用以下公式:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ni"><img src="../Images/9f7e7fc49dac4d22423fecacfb81cc07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GifY9v1A7IprUrqv.png"/></div></div></figure><p id="3b86" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这导致以下梯度下降实现:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nj"><img src="../Images/74c99dbe84bde1f27f51a318729d748a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4Yy8dpHOsj-3BSAV.png"/></div></div></figure><p id="cdb6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">要实现这个公式，您必须</p><ol class=""><li id="a637" class="mc md it ki b kj kk kn ko kr nb kv nc kz nd ld ne mk ml mm bi translated">用小的随机值初始化所有的θ和 x</li><li id="c346" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld ne mk ml mm bi translated">使用提供的梯度下降公式最小化成本函数</li><li id="a478" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld ne mk ml mm bi translated">用参数θ和学习到的特征 x 预测用户的电影评级。</li></ol><h1 id="6085" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">进一步使用</h1><p id="9551" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">在实现协同过滤系统之后，另一个步骤可以是推荐相关的电影/产品。</p><p id="a370" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这很容易做到，因为我们已经计算了特征向量 x。现在要找到相关的电影/产品，我们只需找到距离最小的，比如:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/bfd4fc775a25a3297983b4dde4d3e245.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/0*rW1OlD5bIdQ_05Vx.png"/></div></figure><p id="49d2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请注意，如果您的用户或电影/产品根本没有评级，您应该在实现学习算法之前执行均值归一化。要实现这一点，首先应该从结果矩阵中减去平均值，然后在预测评级时重新相加。但是你应该经常问自己，向一个完全不确定的单位推荐某样东西是否有意义。</p><h1 id="55d8" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">扩展机器学习系统</h1><p id="0fe8" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">当一个案例有非常多的例子时(大约 1 亿个)，总是问自己是否有可能在保留结果的情况下减少数据集。</p><p id="6bf5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一种方法是绘制 m 值范围的学习曲线，并验证当 m 小时算法具有高方差。当 th 算法已经具有高偏差时，增加数据集没有帮助。</p><h1 id="b7b1" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">随机梯度下降</h1><p id="3b9a" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">在大的训练集上，梯度下降变得非常计算昂贵。解决这个问题的一个方法是使用随机梯度下降。</p><p id="4a34" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">不是一次迭代所有训练示例，而是随机打乱数据集，并对单个示例执行梯度下降，如下所示:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nl"><img src="../Images/be9666545a2ecbf95702234d6832b10a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7lC8-Mu82KAuL6XK.png"/></div></div></figure><p id="0ea8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这允许改进每个单个示例的参数，因此比一次改进所有示例的参数花费更少的时间。(代价是它可能根本不会收敛，但对于大多数实际用例来说，最终会足够接近)。</p><h1 id="1b00" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">小批量梯度下降</h1><p id="c733" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">作为在每次梯度下降迭代中遍历所有示例或仅遍历 1 个示例的中间方式，小批量允许在每次迭代中设置一定数量 b 的示例。调整后的循环可能如下所示:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nm"><img src="../Images/288a62f3a4ae8deeba0678387737a989.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QXXbkQpEOR6IyyPb.png"/></div></div></figure><h1 id="60e4" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">收敛性测试</h1><p id="9911" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">为了测试小批量或随机梯度下降是否收敛，可以绘制并检查成本函数。</p><p id="0bf3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于小批量梯度下降，迭代次数的成本函数可以直接绘制，而对于随机梯度下降，成本函数(在某个例子上)必须根据多个例子的平均值绘制。</p><p id="6eb4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果算法未能收敛，尝试缓慢降低学习速率α。</p><h1 id="aeb5" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">在线学习</h1><p id="714b" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">在网上学习的观念中，数据被认为是无穷无尽和免费的。例如在网站上获取用户数据流。在这种情况下，每次可以对一个示例执行梯度下降，次数不限。随着每个输入的例子，算法被改进，并且这样算法也可以根据用户偏好的改变而适应。</p><h1 id="a1bd" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">映射减少和数据并行</h1><p id="cbb4" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">另一种处理大型数据集的方法是使用批量梯度下降，但将其分成不同的子集，允许多台机器处理自己的数据集。之后，可以简单地将结果相加，以符合原始公式(基本上使用函数和)。</p><h1 id="47c5" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">在应用程序上使用的技巧</h1><h1 id="6239" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">为你的问题创建一个管道</h1><p id="c49e" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">例如</p><ul class=""><li id="7639" class="mc md it ki b kj kk kn ko kr nb kv nc kz nd ld mj mk ml mm bi translated">检测文本</li><li id="823d" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated">分段字符</li><li id="6679" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated">分类字符</li></ul><h1 id="2dc3" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">获取更多数据</h1><ul class=""><li id="0cc2" class="mc md it ki b kj me kn mf kr mg kv mh kz mi ld mj mk ml mm bi translated">尝试通过在你已有的数据集上添加变形来创建额外的数据(人工数据合成)</li><li id="1bdc" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated">尝试自己收集/标记数据</li><li id="ee18" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated">人群来源数据</li></ul><h1 id="a763" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">上限分析</h1><p id="0743" class="pw-post-body-paragraph kg kh it ki b kj me kl km kn mf kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">通过比较准确度的提高，分析管道中哪些部分值得花费时间进行改进。</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="ff21" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">第四部分到此结束。多么不可思议的课程！:)</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="bd59" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢阅读我的文章！欢迎留下任何反馈！</p></div><div class="ab cl nn no hx np" role="separator"><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns nt"/><span class="nq bw bk nr ns"/></div><div class="im in io ip iq"><p id="794b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">丹尼尔是一名商业法的法学硕士学生，在维也纳担任软件工程师和技术相关活动的组织者。他目前的个人学习努力集中在机器学习上。</p><p id="7a3c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">连接到:</p><ul class=""><li id="56f8" class="mc md it ki b kj kk kn ko kr nb kv nc kz nd ld mj mk ml mm bi translated"><a class="ae kf" href="https://www.linkedin.com/in/createdd" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a></li><li id="bd79" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://github.com/Createdd" rel="noopener ugc nofollow" target="_blank"> Github </a></li><li id="6082" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://medium.com/@ddcreationstudi" rel="noopener">中等</a></li><li id="00f6" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://twitter.com/DDCreationStudi" rel="noopener ugc nofollow" target="_blank">推特</a></li><li id="c065" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://steemit.com/@createdd" rel="noopener ugc nofollow" target="_blank">钢模</a></li><li id="ed95" class="mc md it ki b kj mn kn mo kr mp kv mq kz mr ld mj mk ml mm bi translated"><a class="ae kf" href="https://hashnode.com/@DDCreationStudio" rel="noopener ugc nofollow" target="_blank">哈希节点</a></li></ul><figure class="mw mx my mz gt ju gh gi paragraph-image"><a href="https://www.buymeacoffee.com/createdd"><div class="gh gi nu"><img src="../Images/83466a0fecfad25d83533bd8e919086d.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*mW8ks3kpW9KQewTN8fe25w.png"/></div></a><figcaption class="kb kc gj gh gi kd ke bd b be z dk">You can support me on <a class="ae kf" href="https://www.buymeacoffee.com/createdd" rel="noopener ugc nofollow" target="_blank">https://www.buymeacoffee.com/createdd</a></figcaption></figure></div></div>    
</body>
</html>