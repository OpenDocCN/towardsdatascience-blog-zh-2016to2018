<html>
<head>
<title>Instance Embedding: Segmentation Without Proposals</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实例嵌入:没有建议的分段</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/instance-embedding-instance-segmentation-without-proposals-31946a7c53e1?source=collection_archive---------3-----------------------#2018-04-01">https://towardsdatascience.com/instance-embedding-instance-segmentation-without-proposals-31946a7c53e1?source=collection_archive---------3-----------------------#2018-04-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/c1c980675a8f3407645f79c94a394040.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*73E15g6xOD8leNHppZZycw.png"/></div></div></figure><div class=""/><p id="dcc8" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这篇文章中，我将回顾实例分割领域的 3 篇论文。它们不同于主流的基于提议的基于 fast-RCNN 的方法，如<a class="ae kw" href="https://arxiv.org/abs/1703.06870" rel="noopener ugc nofollow" target="_blank"> Mask-RCNN </a>或<a class="ae kw" href="https://arxiv.org/abs/1712.04837" rel="noopener ugc nofollow" target="_blank"> MaskLab </a>和最新的<a class="ae kw" href="https://arxiv.org/abs/1803.01534" rel="noopener ugc nofollow" target="_blank"> PANet </a>，在多个数据集上实现了最先进的结果(<a class="ae kw" href="https://www.cityscapes-dataset.com/" rel="noopener ugc nofollow" target="_blank"> CityScapes </a>、<a class="ae kw" href="http://cocodataset.org/" rel="noopener ugc nofollow" target="_blank"> COCO </a>、<a class="ae kw" href="https://www.mapillary.com/dataset/vistas" rel="noopener ugc nofollow" target="_blank"> MVD </a>)。参见此处的 Mask-RCNN <a class="ae kw" href="http://kaiminghe.com/iccv17tutorial/maskrcnn_iccv2017_tutorial_kaiminghe.pdf" rel="noopener ugc nofollow" target="_blank">教程。</a></p><p id="0e99" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在基于提议的实例分段架构中有三个基本缺陷。首先，两个对象可能共享同一个边界框，或者非常相似的框。在这种情况下，遮罩头部无法判断要在盒子中选取哪个对象。对于其边界框中填充率较低的线状对象(如自行车和椅子)，这是一个严重的问题。其次，架构中没有任何东西阻止两个实例共享一个像素。第三，实例的数量受限于网络处理的提案数量(通常为数百)。</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi kx"><img src="../Images/5a8dacfc1afa0748d6a2b519f1fe07c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hKOJOX99Mxg_O3Yr."/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk">architecture for Mask-RCNN, <a class="ae kw" href="https://www.slideshare.net/IldooKim/deep-object-detectors-1-20166" rel="noopener ugc nofollow" target="_blank">https://www.slideshare.net/IldooKim/deep-object-detectors-1-20166</a></figcaption></figure><p id="1e6a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此外，该架构非常复杂，很难调整和“调试”。在目标检测中，这个问题的前兆，已经成功地使用了更简单的单级架构，例如<a class="ae kw" href="https://arxiv.org/abs/1708.02002" rel="noopener ugc nofollow" target="_blank"> RetinaNet </a>。</p><p id="c301" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">使用实例嵌入，每个对象都被分配一个 n 维空间中的“颜色”。网络处理图像并产生与输入图像相同大小的密集输出。网络输出中的每个像素是嵌入空间中的一个点。属于同一对象的像素在嵌入空间中是靠近的，而属于不同对象的像素在嵌入空间中是远离的。解析图像嵌入空间涉及某种聚类算法。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><h1 id="5d38" class="ln lo jb bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">论文 1:具有区别损失函数的语义实例分割</h1><p id="3db9" class="pw-post-body-paragraph jy jz jb ka b kb ml kd ke kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv ij bi translated"><a class="ae kw" href="https://arxiv.org/find/cs/1/au:+Brabandere_B/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank">伯特·德·布拉班德雷</a>，<a class="ae kw" href="https://arxiv.org/find/cs/1/au:+Neven_D/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank">戴维·内文</a>，<a class="ae kw" href="https://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank">吕克·范古尔</a><a class="ae kw" href="https://arxiv.org/abs/1708.02551" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1708.02551</a><br/>T9】https://github.com/DavyNeven/fastSceneUnderstanding</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/7c6cde02a7186eb58d06cd32d447f49b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/0*PYT_oRjBL-4tGm0B."/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk">visualizing the contrastive loss.</figcaption></figure><p id="ed7e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">损失。</strong>本文使用由三部分组成的对比损失函数:</p><p id="0fc5" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">(1)拉力。惩罚相同实例的所有元素与其平均值的距离。也就是说，获取一个实例的所有像素并计算它们的平均值。拉力会将同一实例的所有像素嵌入吸引到同一点。简而言之，减少每个实例嵌入的差异。</p><p id="1d61" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">(2)一个推力。取所有的中心点(在嵌入空间中，而不是空间中心)并将它们推得更远。</p><p id="fea4" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">(3)正规化。中心不应该离原点太远。</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/cbbe71ed4c4bc3b00604213e381f089a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*n7d5zeLPcxRq_2NpQ1X90g.png"/></div></figure><p id="c6d0" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">α和β的值为 1，γ设置为 0.001。两个增量都是拉力和推力的阈值。</p><p id="4308" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">解析</strong>。在获得语义分割图(汽车、狗、计算机……)之后，我们将每个类别掩码细分为实例。这是通过在语义掩码中选取一个随机未分配的点，并迭代应用均值漂移算法来找到实例的均值点来实现的。</p><p id="097a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">均值的第一个假设是最初选取的随机像素的嵌入。然后，围绕该点(在嵌入空间中)扩展一组点，然后再次计算它们的平均值，并且重复该过程，直到平均值的变化不显著。根据我的经验，算法收敛不超过 10 次迭代。大多数时候 3-4 次迭代就足够了。</p><p id="e1ca" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">用于在嵌入空间中扩展实例遮罩的半径与拉取阈值相同。理论上，如果测试误差为 0，并且中心之间的最小距离至少是方差分量的拉阈值的两倍，则我们可以使用这些阈值来解析图像。距离不大于拉动阈值的所有点应属于同一个实例。因为测试误差几乎从不为 0，所以使用均值漂移算法来寻找嵌入的高密度部分的中心。</p><figure class="ky kz la lb gt is"><div class="bz fp l di"><div class="ms mt l"/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk">a nice visualization of this tracking process in a two dimensional embedding space where the mode of the set, the peak of the density, is finally found.</figcaption></figure><p id="f9f9" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">错误来源</strong></p><figure class="ky kz la lb gt is gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/9c93fd78c556b5d26fd3101006700fb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*eAgv5h2BhHwWumPP0bzgzQ.png"/></div></figure><p id="c67a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这些结果显示了 Cityscapes 数据集上大多数错误的来源。如果语义分段没有被断定，而是使用了基础事实，则 AP50 结果从 40.2 跳到 58.5。如果也使用实际的中心，而不是使用均值漂移来估计，则得分几乎增加了 20 分，达到 77.8 分。使用<a class="ae kw" href="https://arxiv.org/abs/1803.01534" rel="noopener ugc nofollow" target="_blank">面板</a>(参见<a class="ae kw" href="https://www.cityscapes-dataset.com/benchmarks/." rel="noopener ugc nofollow" target="_blank">仪表板</a>)在 COCO 上不进行预训练的当前技术水平结果是 57.1。与使用语义分段基本原理相同。我们了解到嵌入本身可能非常好。</p><h1 id="7a39" class="ln lo jb bd lp lq mv ls lt lu mw lw lx ly mx ma mb mc my me mf mg mz mi mj mk bi translated">嵌入示例</h1><p id="07ab" class="pw-post-body-paragraph jy jz jb ka b kb ml kd ke kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv ij bi translated">下面是一个由一个训练有素的网络嵌入生成的实例。它用于解决目前正在 Kaggle 上运行的<a class="ae kw" href="https://www.kaggle.com/c/data-science-bowl-2018" rel="noopener ugc nofollow" target="_blank">数据科学碗 2018 </a>提出的问题。目的是在医学图像中找到细胞核。</p><p id="5347" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">左上角的图像是原始图像。中上部图像是语义分割(这里只有两类，背景和前景)。其余的图像是 64 个嵌入空间的前 7 个通道。从嵌入可以明显看出，网络学习了在空间上区分细胞核的通道。对角线或水平编码的例子。一些编码从图像中心的距离。但是，在实例内部，颜色是同质的。这让我们对网络如何学习分割实例有了一些了解。</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi na"><img src="../Images/6abf7d418657c43ae75d91692d846215.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2U0aA1GvO-m3Rw8Y."/></div></div></figure><h1 id="bd39" class="ln lo jb bd lp lq mv ls lt lu mw lw lx ly mx ma mb mc my me mf mg mz mi mj mk bi translated">论文 2:通过深度度量学习的语义实例分割</h1><p id="69d9" class="pw-post-body-paragraph jy jz jb ka b kb ml kd ke kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv ij bi translated"><a class="ae kw" href="https://arxiv.org/find/cs/1/au:+Fathi_A/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank">阿里雷扎·法蒂</a>，<a class="ae kw" href="https://arxiv.org/find/cs/1/au:+Wojna_Z/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank">兹比格涅夫·沃伊纳</a>，<a class="ae kw" href="https://arxiv.org/find/cs/1/au:+Rathod_V/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank">维韦克·拉特霍德</a>，<a class="ae kw" href="https://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank">王鹏</a>，<a class="ae kw" href="https://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank">玄武铉</a>，<a class="ae kw" href="https://arxiv.org/find/cs/1/au:+Guadarrama_S/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank">塞尔吉奥·瓜达拉马</a>，<a class="ae kw" href="https://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank">凯文·p·墨菲</a><br/>【https://arxiv.org/abs/1703.10277</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nb"><img src="../Images/55b79cbc722f2bb6e27592efb1d06293.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*g9KUrM-IFijKywX-."/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk">Network architecture proposed in Semantic Instance Segmentation via Deep Metric Learning</figcaption></figure><p id="1fa3" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">本文的主要贡献是为每个像素学习种子分数。分数告诉我们该像素是否是扩展遮罩的良好候选。在之前的论文中，种子是随机选择的，然后使用均值漂移算法来细化中心。这里只做了一次扩展。</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nc"><img src="../Images/4dbf3fbb772ee654bab297745adf1174.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/0*S382qDDi2S8nFUVd."/></div></div><figcaption class="lc ld gj gh gi le lf bd b be z dk">seedeness score per pixel. taken as the maximum over all classes and bandwidths.</figcaption></figure><p id="ded6" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">该论文提出为每个像素学习几个可能种子。我们为每个半径(在嵌入空间中)和类学习一个种子。因此，如果我们有 C 类，我们学习 T 带宽(半径),我们有 CxT 种子“建议”每像素。对于每个像素，只考虑得分最高的建议。</p><p id="1d15" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">嵌入损失。</strong>本文对像素对的嵌入进行惩罚。我们考虑具有相同实例的对和来自不同实例的对。</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/2ae30ea775a5914c63109541b599f7e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/0*C0JEC4d2sHPRMPIb."/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk">a logistic distance function in embedding space</figcaption></figure><p id="cf14" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">本文使用一种改进的逻辑函数，将嵌入空间中的欧氏距离变换到[0，1]域。嵌入空间中接近的对将被函数赋予接近 1 的值，而距离远的对将接近 0。</p><p id="ab5c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">自然地，logloss 被用作损失函数。实例大小可能会有所不同，因此，为了减轻这种不平衡问题，根据实例的大小对它们进行加权。</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/69f3d49913fee48d61b0eaaba732457b.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*aklQ2hqQpbJ9u-S-p95rzw.png"/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk">logloss over logistic distance between pairs of pixels</figcaption></figure><p id="62e2" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">落英。</strong>对于每个像素，模型学习几个种子性分数。带宽(嵌入空间的半径)和类别的每个组合得一分。由于种子分数接近但不同于语义分割，因此每次评估嵌入时都要确定每一个的基础事实。围绕像素的嵌入扩展掩码，并且如果具有基本事实实例的 IoU 超过某个阈值，则该像素被认为是该实例的类的种子。这个损失将会惩罚这个职业的低种子分数。</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/dc8469e1816a0efcee8842770deb4b4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/0*26PsDHQzweWbcccn."/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk">seediness loss</figcaption></figure><p id="a9e2" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">每批图像中只有 10 个左右的种子被评估，随机挑选。学习几个这样的模型，一个用于一个带宽。带宽越宽，物体越大。在某种程度上，获得最高分数的带宽是模型传达其对实例大小的估计的方式(相对于嵌入空间中的距离)。</p><p id="cc50" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">训练程序。</strong>本文使用在 COCO 数据集上预处理的 ResNet-101 主干。训练从没有分类/种子预测开始，即λ=0，并且随着嵌入更加稳定而进展到 0.2。</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/ea6c19d91553f6588eaaba1372d63a7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:426/format:webp/1*25y46E_ezGr94BlNK6yU9A.png"/></div></figure><p id="41ee" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">以不同的比例(0.25，0.5，1，2)评估主链，并将连接的结果输入种子和包埋头。</p><p id="5201" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">解析</strong>。这个过程非常简单，因为种子学会了。提出了一种为图像选择最佳种子集的方法。它一方面优化了高种子分数，另一方面优化了嵌入空间的多样性。</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/a2f37b0414e03c04444bb7b0f9834c38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/0*1hPGRNNFwr0d5WYG."/></div></figure><p id="db6a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">迭代地选择种子，每个新的种子被选择为在嵌入空间中远离先前选择的种子。选择的第一个种子是图像中种子性得分最高的像素。第二个将是一方面具有高种子性分数，另一方面在嵌入空间中不接近的种子。使用参数α来控制这两个要求之间的平衡。α是一个需要调整的参数，该参数的测试范围在 0.1 到 0.6 之间。与 NMS 不同，嵌入空间的多样性受到鼓励，而不是空间多样性。</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/12b1b48092ea39d0aebb82f0e802b6de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/0*-ZNb-CVraFaUCFE_."/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk">some results from Semantic Instance Segmentation via Deep Metric Learning</figcaption></figure><h1 id="5044" class="ln lo jb bd lp lq mv ls lt lu mw lw lx ly mx ma mb mc my me mf mg mz mi mj mk bi translated">论文 3:用于实例分组的递归像素嵌入</h1><p id="aba0" class="pw-post-body-paragraph jy jz jb ka b kb ml kd ke kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv ij bi translated"><a class="ae kw" href="https://arxiv.org/find/cs/1/au:+Kong_S/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank">舒孔</a>，<a class="ae kw" href="https://arxiv.org/find/cs/1/au:+Fowlkes_C/0/1/0/all/0/1" rel="noopener ugc nofollow" target="_blank">查尔斯·福尔克斯</a><br/>T5】https://arxiv.org/abs/1712.08273<br/><a class="ae kw" href="https://github.com/aimerykong/Recurrent-Pixel-Embedding-for-Instance-Grouping" rel="noopener ugc nofollow" target="_blank">https://github . com/aimerykong/Recurrent-Pixel-Embedding-for-Instance-Grouping</a></p><figure class="ky kz la lb gt is gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/1e14fbbbcc9dfb8fe013e59882524718.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/0*RFwW286zQuYOeCPp."/></div></figure><p id="9384" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">本文提出在 n-球面上进行嵌入，并使用余弦距离来测量像素的邻近性。然而，本文的主要贡献是基于高斯模糊均值漂移(GBMS)算法的改进版本的递归分组模型。</p><p id="1a2c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">GBMS 是一种迭代算法，类似于第一篇论文中用于查找实例中心的简单均值漂移算法。在这个版本中，所有的像素都被认为是潜在的种子。所有像素在每次迭代时都相对于它们周围的密度进行更新。朝着一个“重心”移动，好像图像的嵌入空间是一个产生行星的星云。点与点之间的距离越远，它们之间的相互影响就越小。从下面的算法可以清楚地看出，距离是由高斯的带宽控制的，这是它的标准偏差。</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/a696e44f3458e0224c97b297e5fd3316.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/0*NBDyeIcrSvhvqx42."/></div></figure><p id="ca2d" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对于 GBMS 来说，有三次收敛保证，所以在应用几次变换后，我们最终应该得到非常密集的，几乎像点一样的簇。想了解更多关于 GBMS 的信息，请看这里。</p><p id="52c7" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了将该算法结合到网络中，已经使用矩阵上的运算来表示该算法。</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/1c26cfac55c2738a45ff3d758275b812.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/0*3z21-wzUPCuRZ9kc."/></div></figure><p id="0c8c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">简单地应用上述算法是没有意义的，因为嵌入是在球体上，并且它们的接近度是使用余弦变换来测量的。描述所有点之间距离的相似性矩阵使用以下变换来计算:</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/fdd0a189d0da94ae8acc79b74e7da288.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/0*sIDr2K3mkoiqLeNR."/></div></figure><p id="66e0" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">测量球体上的距离，而不是使用 L2 规范。此外，在应用 GBMS 步骤后，需要对生成的嵌入进行归一化，以便它们位于单位球面上。</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nn"><img src="../Images/b6202d1bd50e9b348026daf897f6b189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hs7RhCoBikkGdSzw."/></div></div></figure><p id="4ecb" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">训练。</strong>使用成对像素损失，类似于之前的论文，对不同对所需的距离设置阈值(alpha)。使用范围为[0，1]而不是[-1，-1]的校准余弦距离来评估每一对。</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div class="gh gi no"><img src="../Images/9fcb81ee59a0f82658315ccb2438e44c.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*slRREbiolW6BFjeNNGGGpw.png"/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk">calibrated cosine distance</figcaption></figure><p id="9f0a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">损失通过递归分组模型的每个应用反向传播。应用的后期阶段只会出现非常困难的情况。例如，作者将这一特性与在 fast-RCNN 训练中使用的硬负挖掘进行了比较。</p><figure class="ky kz la lb gt is gh gi paragraph-image"><div class="gh gi np"><img src="../Images/2f1da874c430bf382670b52ac59cac3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/0*optGvm68SkyMuzbW."/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk">loss used in Recurrent Pixel Embedding for Instance Grouping</figcaption></figure><p id="2965" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">作者在论文中使用 0.5 作为α值。请注意，实例的大小用于重新平衡大小实例之间的损失。</p><p id="6642" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">解析。</strong>在分组模块的几次应用之后，簇应该非常密集，随机选取值应该产生足够好的种子。</p><p id="5449" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">出于实际目的，在 GBMS 步骤中仅使用一些像素是有意义的，因为计算相似性矩阵可能被证明是极其昂贵的。所取的像素数量是速度/精度的折衷考虑。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><h1 id="99b0" class="ln lo jb bd lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk bi translated">其他方法</h1><p id="5155" class="pw-post-body-paragraph jy jz jb ka b kb ml kd ke kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv ij bi translated">实例嵌入不是基于建议的网络的唯一替代方案。以下是一些使用其他方法解决实例分割问题的论文</p><ul class=""><li id="eb91" class="nq nr jb ka b kb kc kf kg kj ns kn nt kr nu kv nv nw nx ny bi translated">【https://arxiv.org/abs/1605.09410】端到端实例分割与递归关注 <br/> <a class="ae kw" href="https://arxiv.org/abs/1605.09410" rel="noopener ugc nofollow" target="_blank"/></li><li id="0be3" class="nq nr jb ka b kb nz kf oa kj ob kn oc kr od kv nv nw nx ny bi translated"><strong class="ka jc">深分水岭变换为例分割</strong><br/><a class="ae kw" href="https://arxiv.org/abs/1611.08303" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1611.08303</a></li><li id="ee1e" class="nq nr jb ka b kb nz kf oa kj ob kn oc kr od kv nv nw nx ny bi translated"><strong class="ka jc">关联嵌入:用于联合检测和分组的端到端学习</strong><br/><a class="ae kw" href="http://ttic.uchicago.edu/~mmaire/papers/pdf/affinity_cnn_cvpr2016.pdf" rel="noopener ugc nofollow" target="_blank">http://ttic . uchicago . edu/~ mmaire/papers/pdf/affinity _ CNN _ cvpr 2016 . pdf</a></li><li id="948f" class="nq nr jb ka b kb nz kf oa kj ob kn oc kr od kv nv nw nx ny bi translated"><strong class="ka jc">序贯分组网络实例分割</strong><br/><a class="ae kw" href="https://www.cs.toronto.edu/~urtasun/publications/liu_etal_iccv17.pdf" rel="noopener ugc nofollow" target="_blank">https://www . cs . Toronto . edu/~ urta sun/publications/Liu _ et al _ iccv 17 . pdf</a></li></ul><h1 id="7a17" class="ln lo jb bd lp lq mv ls lt lu mw lw lx ly mx ma mb mc my me mf mg mz mi mj mk bi translated">摘要</h1><p id="0beb" class="pw-post-body-paragraph jy jz jb ka b kb ml kd ke kf mm kh ki kj mn kl km kn mo kp kq kr mp kt ku kv ij bi translated">与基于建议书的解决方案相比，这些论文的结果没有竞争力。我们已经回顾了 3 篇论文，它们对丢失和解析提出了不同的解决方法。</p><p id="0f5c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">(1) <strong class="ka jc">使用区别损失函数的语义实例分割</strong> <br/>使用了非成对损失函数。使用图像中的所有像素产生丰富得多的渐变。</p><p id="f5dd" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">(2) <strong class="ka jc">通过深度度量学习的语义实例分割</strong> <br/>引入了种子模型，帮助我们分类并同时挑选最佳种子，优化速度。</p><p id="9d1c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">(3) <strong class="ka jc">循环像素嵌入例如分组</strong> <br/> GBMS，均值偏移的一种变体，在训练和解析中被用于网络内部。产生非常密集的集群。</p><p id="fbe0" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这些方法可能被结合和改进以产生更好的结果。它们比基于提议的方法更简单，可能更快，同时避免了本文介绍中提到的基本缺陷。</p></div><div class="ab cl lg lh hu li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ij ik il im in"><p id="d939" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">联系人:</strong>me@barvinograd.com</p><p id="7b31" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">幻灯片:</strong>T10】https://goo.gl/iTC9aS</p><figure class="ky kz la lb gt is"><div class="bz fp l di"><div class="oe mt l"/></div><figcaption class="lc ld gj gh gi le lf bd b be z dk">results from “Semantic Instance Segmentation with a Discriminative Loss Function” on the CityScapes dataset</figcaption></figure></div></div>    
</body>
</html>