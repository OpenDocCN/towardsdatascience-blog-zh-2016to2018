<html>
<head>
<title>My experience participating in Kaggle Data Science Bowl 2017 (Lung Cancer Detection)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我参加Kaggle数据科学碗2017(肺癌检测)的经历</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/my-experience-participating-in-kaggle-data-science-bowl-2017-lung-cancer-detection-4705032052ec?source=collection_archive---------4-----------------------#2017-04-24">https://towardsdatascience.com/my-experience-participating-in-kaggle-data-science-bowl-2017-lung-cancer-detection-4705032052ec?source=collection_archive---------4-----------------------#2017-04-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jn jo jp jq"><div class="bz fp l di"><div class="jr js l"/></div><figcaption class="jt ju gj gh gi jv jw bd b be z dk">3D reconstruction in all three axes</figcaption></figure><h1 id="c3a1" class="jx jy iq bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated"><strong class="ak">简介</strong></h1><p id="5f76" class="pw-post-body-paragraph kv kw iq kx b ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我参加了Kaggle一年一度的<a class="ae lt" href="https://www.kaggle.com/c/data-science-bowl-2017" rel="noopener ugc nofollow" target="_blank">数据科学碗(DSB) 2017 </a>，很想和大家分享我激动人心的经历。首先，我想强调一下我对这场比赛的技术方法。这是我们面临的问题:我们必须从高风险患者的低剂量ct扫描中检测肺癌。本质上，我们需要预测患者在接受扫描后的一年内是否会被诊断为肺癌。</p><p id="422e" class="pw-post-body-paragraph kv kw iq kx b ky lu la lb lc lv le lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">我认为竞争尤其具有挑战性，因为与一个患者(单个训练样本)相关的数据量非常大。因此，这使得很难将3D CT扫描数据输入到任何深度学习算法中。由于最近的流行，我真的想应用最新的深度学习技术。然而，我很快意识到，我们只是没有足够的数据来从头训练大型深度学习模型。所以，唯一能让我训练深度学习模型的方法就是把这个问题进一步分解成更小的子问题。</p><h1 id="60e8" class="jx jy iq bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">肺分割</h1><p id="1dfc" class="pw-post-body-paragraph kv kw iq kx b ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">所以首先要做的是。我想用传统的图像处理算法从CT扫描中剔除肺部。使用阈值和聚类，我想检测肺部的3D结节。发现肺部的恶性结节是至关重要的，因为这是放射科医生为患者检测肺癌的主要指标。按照这些Kaggle内核中的代码(<a class="ae lt" href="https://www.kaggle.com/gzuidhof/data-science-bowl-2017/full-preprocessing-tutorial" rel="noopener ugc nofollow" target="_blank">圭多·祖德霍夫</a>和<a class="ae lt" href="https://www.kaggle.com/arnavkj95/data-science-bowl-2017/candidate-generation-and-luna16-preprocessing" rel="noopener ugc nofollow" target="_blank">阿纳夫·贾恩</a>)，我很快就能够预处理并从CT扫描中分割出肺部。看看下面的图片。</p><figure class="ma mb mc md gt jq gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi lz"><img src="../Images/db16f1d6eac0e31ee665221d8d4ed82c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MCYrl690D2kW7ek8DdD5Og.png"/></div></div><figcaption class="jt ju gj gh gi jv jw bd b be z dk">Segmented lung and its internal structure</figcaption></figure><p id="8db1" class="pw-post-body-paragraph kv kw iq kx b ky lu la lb lc lv le lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">在进一步分析数据后，我意识到使用简单的阈值来检测结节并将其用于特征提取是不够的。在我们从这些候选结节中提取特征之前，我需要一种方法来减少假阳性。</p><h1 id="3832" class="jx jy iq bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">使用LUNA数据的结节检测</h1><p id="5767" class="pw-post-body-paragraph kv kw iq kx b ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">这个竞赛允许我们使用外部数据，只要这些数据是免费提供给公众的。因此，我决定探索在Kaggle论坛上提到的<a class="ae lt" href="https://luna16.grand-challenge.org/" rel="noopener ugc nofollow" target="_blank"><strong class="kx ir">LU</strong>ng<strong class="kx ir">N</strong>ode<strong class="kx ir">A</strong>analysis(LUNA)Grand Challenge</a>数据集。该数据集提供了由多名放射科医师注释的CT扫描中的结节位置。了解结节的位置使我能够建立一个可以检测图像中结节的模型。为了简单起见，我决定建立一个2D卷积神经网络(CNN)来预测图像是否包含结节。我遵循了与这里的<a class="ae lt" href="https://github.com/swethasubramanian/LungCancerDetection" rel="noopener ugc nofollow" target="_blank">Sweta subra manian</a>记录的完全相同的方法。</p><figure class="ma mb mc md gt jq gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi mk"><img src="../Images/fcf3009d4c03ef13b795f23f669b0179.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QMB8_7bg2VgkAVusFPCEqQ.png"/></div></div><figcaption class="jt ju gj gh gi jv jw bd b be z dk">CNN architecture of the nodule detector</figcaption></figure><p id="d691" class="pw-post-body-paragraph kv kw iq kx b ky lu la lb lc lv le lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">该CNN模型的输入是64×64灰度图像，它生成包含结节的图像的概率。使用这个CNN模型，我能够在LUNA验证数据集上实现85.38%的精确度和78.72%的召回率。以下是一些从LUNA CT扫描数据中截取的样本图像。</p><figure class="ma mb mc md gt jq gh gi paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="gh gi ml"><img src="../Images/852e995b8c924e4951ab9e42119ff0da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CiBR9E0U71LmO8mWWdPr3w.png"/></div></div><figcaption class="jt ju gj gh gi jv jw bd b be z dk">True Positive (Top) and False Positive (Bottom) sample images of the LUNA validation set</figcaption></figure><h1 id="5271" class="jx jy iq bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated"><strong class="ak">最终XGBoost模型</strong></h1><p id="8876" class="pw-post-body-paragraph kv kw iq kx b ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">我从初始分割方法中生成的每个候选结节，我能够从其中心裁剪出一个2D补丁。</p><p id="db67" class="pw-post-body-paragraph kv kw iq kx b ky lu la lb lc lv le lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">通过将训练好的CNN模型应用于这个2D斑块，我能够排除没有产生高概率的候选结节。所有剩余的结节用于生成特征。最终的功能集包括:</p><ul class=""><li id="fea0" class="mm mn iq kx b ky lu lc lv lg mo lk mp lo mq ls mr ms mt mu bi translated">结节面积、直径、像素密度和结节数量</li><li id="c4ee" class="mm mn iq kx b ky mv lc mw lg mx lk my lo mz ls mr ms mt mu bi translated">来自已训练CNN模型的最后全连接层的聚集特征</li><li id="7880" class="mm mn iq kx b ky mv lc mw lg mx lk my lo mz ls mr ms mt mu bi translated">预训练ResNet模型的最后一个全连接层的聚合特征(此处描述的迁移学习方法<a class="ae lt" href="https://www.kaggle.com/drn01z3/data-science-bowl-2017/mxnet-xgboost-baseline-lb-0-57" rel="noopener ugc nofollow" target="_blank"/>)</li><li id="e1f1" class="mm mn iq kx b ky mv lc mw lg mx lk my lo mz ls mr ms mt mu bi translated">与CT扫描相关的简单特征(即分辨率、切片数量、切片厚度)</li></ul><p id="367a" class="pw-post-body-paragraph kv kw iq kx b ky lu la lb lc lv le lf lg lw li lj lk lx lm ln lo ly lq lr ls ij bi translated">利用这些特性，我能够建立一个XGBoost模型，预测患者被诊断为肺癌的概率。使用我的最佳模型，我在stage2私人排行榜上获得了0.59715的对数亏损分数。作为参考，我想强调的是，获胜团队的对数损失分数为0.39975(分数越低越好)。</p><h1 id="79cb" class="jx jy iq bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">结束语</h1><p id="4074" class="pw-post-body-paragraph kv kw iq kx b ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls ij bi translated">有几个方法我真的很想尝试，但是由于时间限制，没有时间去实现。具体来说，在使用2D CNN看到有希望的结果后，训练3D CNN来检测结节将是我的下一个方法。看起来许多获奖的解决方案成功地利用3D CNN利用LUNA数据检测结节。我对结果很满意，因为我能投入比赛的时间有限。总的来说，我试图尽可能地利用现有的工作，以便我可以专注于挖掘更高层次的功能。这是一种在短时间内学习最新机器学习技术和工具的极好方式。源代码和python笔记请参考获取我的<a class="ae lt" href="https://github.com/ashish217/kaggle/tree/master/data_science_bowl3" rel="noopener ugc nofollow" target="_blank"> GitHub页面</a>。</p></div></div>    
</body>
</html>