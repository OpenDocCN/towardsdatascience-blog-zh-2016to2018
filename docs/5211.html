<html>
<head>
<title>Watermarking in Spark Structured Streaming</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark 结构化流中的水印技术</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/watermarking-in-spark-structured-streaming-9e164f373e9?source=collection_archive---------4-----------------------#2018-10-04">https://towardsdatascience.com/watermarking-in-spark-structured-streaming-9e164f373e9?source=collection_archive---------4-----------------------#2018-10-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="4082" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">处理迟到事件是<em class="kl">流处理引擎</em>的一个关键功能。这个问题的一个解决方案是<em class="kl">水印</em>的概念。并且从<a class="ae km" href="https://spark.apache.org/releases/spark-release-2-1-0.html" rel="noopener ugc nofollow" target="_blank"> Spark 2.1 </a>开始支持结构化流 API。</p></div><div class="ab cl kn ko hu kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="ij ik il im in"><h1 id="4564" class="ku kv iq bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">什么是水印？</h1><p id="a7b0" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated"><em class="kl">水印</em>是帮助<em class="kl">流处理引擎</em>处理<em class="kl">延迟</em>的有用方法。基本上，一个<strong class="jp ir">水印</strong>是一个<strong class="jp ir">阈值</strong>，用于指定系统等待<strong class="jp ir">延迟事件</strong>多长时间。如果到达的事件位于水印内，它被用来更新查询。否则，如果它比水印旧，它将被丢弃，并且不会被<em class="kl">流媒体引擎</em>进一步处理。</p><figure class="ly lz ma mb gt mc gh gi paragraph-image"><div class="gh gi lx"><img src="../Images/55804350d5f878f543fc491f31830362.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*KRnZWCvffMXNKHO4Et_I-Q.jpeg"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk">Flooding watermarks</figcaption></figure><h1 id="ecc2" class="ku kv iq bd kw kx mj kz la lb mk ld le lf ml lh li lj mm ll lm ln mn lp lq lr bi translated">但是，我为什么要在乎呢？</h1><p id="01ef" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">在分布式和网络化系统中，总有可能发生中断——节点故障、传感器失去连接等等。因此，不能保证数据会按照创建的顺序到达<em class="kl">流处理引擎</em>。为了<em class="kl">容错</em>，因此有必要处理此类<em class="kl">无序</em>数据。</p><p id="3d46" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了解决这个问题，必须保留聚合的状态。如果发生延迟事件，可以重新处理查询。但是这意味着所有聚集的状态必须无限期地保持，这导致内存使用也无限期地增长。这在现实世界中是不实际的，除非系统有无限的资源(例如无限制的预算)。因此<em class="kl">水印</em>对于<strong class="jp ir">通过设计约束系统</strong>并防止其在运行时爆炸是一个有用的概念。</p><h1 id="d936" class="ku kv iq bd kw kx mj kz la lb mk ld le lf ml lh li lj mm ll lm ln mn lp lq lr bi translated">怎么用？</h1><p id="f841" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated">自从<a class="ae km" href="https://spark.apache.org/releases/spark-release-2-1-0.html" rel="noopener ugc nofollow" target="_blank"> Spark 2.1 </a>，<em class="kl">水印</em>被引入结构化流 API。您可以通过简单地将<code class="fe mo mp mq mr b"><strong class="jp ir">withWatermark</strong></code><strong class="jp ir">-操作符</strong>添加到查询中来启用它:</p><p id="c5c8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><code class="fe mo mp mq mr b">withWatermark(eventTime: String, delayThreshold: String): Dataset[T]</code></p><p id="7b76" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它使用<strong class="jp ir">两个参数</strong>，a)一个<strong class="jp ir">事件时间列</strong>(必须与聚合正在处理的相同)和 b)一个<strong class="jp ir">阈值</strong>来指定延迟数据应该被处理多长时间(以事件时间为单位)。然后，Spark 将维持一个集合的状态，直到<code class="fe mo mp mq mr b">max eventTime — delayThreshold &gt; T</code>，其中<code class="fe mo mp mq mr b">max eventTime</code>是引擎看到的最新事件时间，<code class="fe mo mp mq mr b">T</code>是窗口的开始时间。如果延迟数据在此阈值范围内，查询最终会得到更新(下图中的<em class="kl">右侧</em>图像)。否则，它将被丢弃，不会触发重新处理(下图中的<em class="kl">左图</em>)。</p><div class="ly lz ma mb gt ab cb"><figure class="ms mc mt mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><img src="../Images/a7f14f0201fcc56f2fd988a780e71e3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*7rIBWTxHL9oLD5LoEauD0w.png"/></div></figure><figure class="ms mc mt mu mv mw mx paragraph-image"><div role="button" tabindex="0" class="my mz di na bf nb"><img src="../Images/b44cdb56d840c4412a91c0e34f603665.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*wK6UDg1j92fw_er9M4FRIQ.png"/></div><figcaption class="mf mg gj gh gi mh mi bd b be z dk nc di nd ne">Late donkey in structured word count: event dropped (left), event within watermark updates Window 2 (right).</figcaption></figure></div><p id="4d78" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">值得一提的是，查询的<strong class="jp ir">输出模式</strong>必须设置为<code class="fe mo mp mq mr b">"append"</code>(默认设置)或<code class="fe mo mp mq mr b">"update”</code>。<code class="fe mo mp mq mr b">Complete</code>-根据设计，模式不能与<em class="kl">水印</em>一起使用，因为它要求保存所有数据，以便将整个结果表输出到接收器。</p><p id="7432" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一个快速演示，如何在一个简单的<em class="kl"> Spark 结构化流</em>应用程序中使用这个概念，可以在这里找到<a class="ae km" href="https://github.com/datadonK23/SparkStructuredStreamingEx/blob/master/src/main/scala/StructuredWatermarkingWC.scala" rel="noopener ugc nofollow" target="_blank"><strong class="jp ir"/></a>——这是一个<strong class="jp ir">字数</strong>(有一些小的 NLP 增强)<strong class="jp ir">还有什么:D </strong></p></div><div class="ab cl kn ko hu kp" role="separator"><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks kt"/><span class="kq bw bk kr ks"/></div><div class="ij ik il im in"><h2 id="227a" class="nf kv iq bd kw ng nh dn la ni nj dp le jy nk nl li kc nm nn lm kg no np lq nq bi translated">参考</h2><p id="1787" class="pw-post-body-paragraph jn jo iq jp b jq ls js jt ju lt jw jx jy lu ka kb kc lv ke kf kg lw ki kj kk ij bi translated"><a class="ae km" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank">结构化流媒体编程指南</a>、<a class="ae km" href="https://jaceklaskowski.gitbooks.io/spark-structured-streaming/spark-sql-streaming-Dataset-withWatermark.html" rel="noopener ugc nofollow" target="_blank"> Spark 结构化流媒体书籍</a>作者<a class="nr ns ep" href="https://medium.com/u/df186e1cd0c2?source=post_page-----9e164f373e9--------------------------------" rel="noopener" target="_blank">亚采克·拉斯科夫斯基</a>、<a class="ae km" href="https://databricks.com/blog/2017/05/08/event-time-aggregation-watermarking-apache-sparks-structured-streaming.html" rel="noopener ugc nofollow" target="_blank"> databricks </a>博客、<a class="ae km" href="http://blog.madhukaraphatak.com/introduction-to-spark-structured-streaming-part-12/" rel="noopener ugc nofollow" target="_blank"> post </a>作者<a class="nr ns ep" href="https://medium.com/u/6e43969d2f6e?source=post_page-----9e164f373e9--------------------------------" rel="noopener" target="_blank">马杜</a>、<a class="ae km" href="https://vishnuviswanath.com/spark_structured_streaming.html#watermark" rel="noopener ugc nofollow" target="_blank"> post </a>作者<a class="nr ns ep" href="https://medium.com/u/81a1d7913fbb?source=post_page-----9e164f373e9--------------------------------" rel="noopener" target="_blank"> vishnu viswanath </a>、waitingforcode 上的<a class="ae km" href="http://www.waitingforcode.com/apache-spark-structured-streaming/apache-spark-structured-streaming-watermarks/read" rel="noopener ugc nofollow" target="_blank"> post </a>、<a class="ae km" href="https://blog.knoldus.com/exploring-spark-structured-streaming/" rel="noopener ugc nofollow" target="_blank"> Knoldus </a>博客、<a class="ae km" href="https://softwaremill.com/windowing-in-big-data-streams-spark-flink-kafka-akka/" rel="noopener ugc nofollow" target="_blank"> SoftwareMill 【T21</a></p></div></div>    
</body>
</html>