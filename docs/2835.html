<html>
<head>
<title>Understanding 2D Dilated Convolution Operation with Examples in Numpy and Tensorflow with Interactive Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用交互代码理解 Numpy 和 Tensorflow 中的 2D 展开卷积运算</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/understanding-2d-dilated-convolution-operation-with-examples-in-numpy-and-tensorflow-with-d376b3972b25?source=collection_archive---------1-----------------------#2018-03-12">https://towardsdatascience.com/understanding-2d-dilated-convolution-operation-with-examples-in-numpy-and-tensorflow-with-d376b3972b25?source=collection_archive---------1-----------------------#2018-03-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/b43c2d385fb418eb25ef161c2901da1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9tf4VAJcUMlVjI3Y66X6rQ.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Image from <a class="ae kc" href="https://pixabay.com/en/create-symbols-sacred-geometry-3014605/" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure><p id="3d75" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以从这篇论文来看。<a class="ae kc" href="https://arxiv.org/abs/1511.07122" rel="noopener ugc nofollow" target="_blank">用膨胀卷积进行多尺度上下文聚合</a>，我被介绍到膨胀卷积运算。而且说实话只是用修改过的核，准确的说是更宽的核进行卷积运算。然而，为了充分理解一些事情，我需要实施它，因此有了这个帖子。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="9932" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">卷积 vs 扩张卷积(理论)</strong></p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi li"><img src="../Images/610f561054580970235c3237c2fbb434.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zhd8ItyO2vwBS0XfmkFMkg.png"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Image from <a class="ae kc" href="https://arxiv.org/abs/1511.07122" rel="noopener ugc nofollow" target="_blank">paper</a></figcaption></figure><p id="d8bd" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">红线→ </strong>“熟悉的”离散卷积(在我们的例子中是正常的 2D 卷积)运算和扩张卷积之间的关系</p><p id="922f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir"> <em class="ln">我们熟悉的离散卷积就是 1-膨胀卷积</em> </strong>。因此，仅仅从这个陈述中，我们已经可以看出，当 1 的值增加到 2 时，这不是我们都喜欢的“熟悉的”卷积运算。而这一点，可以通过图片看得很清楚。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lo"><img src="../Images/1c99106246d0bde53ff674bdfc608709.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*764GG_1uRUb8j6xvZOpoLg.png"/></div></div></figure><p id="c75d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">蓝色书写→ </strong>膨胀因子为 1、2、4。(或 1-扩张卷积、2-扩张卷积和 4-扩张卷积)</p><p id="aa87" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">那么这些扩张因子是什么呢？这可以用另一个图像来解释。(其实是同一个图像 lol)</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lo"><img src="../Images/e847cf62c1aa167c49710f051a235352.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ssV3Bqv-9JxhuuYuVsZogA.png"/></div></div></figure><p id="a486" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">蓝色数字</strong> →应用于内核的膨胀因子</p><p id="53a0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所以上图并不是膨胀卷积的最佳表现，但你可以大致了解这个膨胀因子是什么。并且随着膨胀因子的增加，原始核元素之间的空间变得越来越宽。现在让我们来看例子。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="5df9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">实验设置</strong></p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lp"><img src="../Images/0ffcd796f434e63c7d80e9f026a24eef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*28o7fCEykwZAlhfEnL5mAA.png"/></div></div></figure><p id="f38e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">红框</strong> →原矩阵<br/> <strong class="kf ir">蓝框</strong> →我们要用的内核</p><p id="1997" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">因此，我们将使用蓝框核对红框矩阵执行多重卷积运算。但是，有三点需要注意。</p><ol class=""><li id="86c3" class="lq lr iq kf b kg kh kk kl ko ls ks lt kw lu la lv lw lx ly bi translated">在 Tensorflow 中有两种方法来执行扩张卷积，或者通过基本的<a class="ae kc" href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_backprop_filter" rel="noopener ugc nofollow" target="_blank"> tf.nn.conv2d() </a>(通过设置扩张的)或者通过<a class="ae kc" href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d" rel="noopener ugc nofollow" target="_blank"> tf.nn.atrous_conv2d() </a></li><li id="e7d7" class="lq lr iq kf b kg lz kk ma ko mb ks mc kw md la lv lw lx ly bi translated">然而，似乎这两个操作都没有翻转内核。所以他们正在执行互相关(如果我错了请纠正我)，所以我们将手动翻转内核，如下所示。(红线)</li></ol><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi me"><img src="../Images/8150a879f63661bc786bdb7b777dea45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RG-JznLvcPpTHr5QRZpi4w.png"/></div></div></figure><p id="6a60" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">3.如上所述，<strong class="kf ir">所有的</strong> Tensorflow 操作将使用原始(3*3)内核，同时改变膨胀因子，而对于 Numpy，我们将<strong class="kf ir">为每个膨胀率生成</strong>特定内核。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="5c4e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">例 1-扩张因子 1 </strong></p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mf"><img src="../Images/f2817348fa8bfea048c98a71e1b18986.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sluyY07iDGFISH6mXs485A.png"/></div></div></figure><p id="bb49" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们已经知道，如果我们将膨胀因子设置为 1，它就像我们学会的卷积运算一样。所以这个例子没有什么特别的。现在让我们看一下代码。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mg"><img src="../Images/58f7679b557e51a224511204a6f8216d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jurmVstcbgQQ6G6cDzE3Gw.png"/></div></div></figure><p id="edb3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">红线</strong> →注意我们正在对 Numpy <br/> <strong class="kf ir">进行“熟悉的”卷积运算，黄线</strong> →张量流的膨胀因子</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="a66c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">示例 2 -扩张因子 2 </strong></p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mh"><img src="../Images/e1dcb61ccb631f2144f846d720289496.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HrJkh0acWisXIipf3YhLqg.png"/></div></div></figure><p id="8182" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">红框</strong> →为 Numpy 生成膨胀因子为 2 的内核</p><p id="7aa3" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，由于膨胀因子已经增加到 2，我们将为 Numpy 生成一个新内核。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mi"><img src="../Images/302410ea12693c7155678ffdced5ea34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MV7aS5L-fuj5Zb01bnpR_Q.png"/></div></div></figure><p id="43f7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">红线</strong> →注意我们正在对 Numpy <br/> <strong class="kf ir">黄线</strong> →张量流的膨胀因子进行“熟悉的”卷积运算</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="a9df" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">示例 3 —扩张因子 3 </strong></p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mj"><img src="../Images/06ec2836e90b1123dae7b0f0475a254e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7fabMfbKVtzpJS8tZ27lOg.png"/></div></div></figure><p id="cb6b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">红框</strong> →为 Numpy 生成膨胀系数为 3 的内核</p><p id="6351" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，由于膨胀因子已经增加到 3，我们将为 Numpy 生成一个新内核。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mk"><img src="../Images/dda3a22f79aff76efa328570396bbed9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b0o1RTc3AvW-qSkJ4jo_EA.png"/></div></div></figure><p id="3abf" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">红线</strong> →注意我们正在对 Numpy <br/> <strong class="kf ir">进行“熟悉的”卷积运算，黄线</strong> →张量流的膨胀因子</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="1f13" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">例 4—扩张因子 4 </strong></p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ml"><img src="../Images/95aaaaf1abebf91efbe44fa17e62726f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GUfHz47W8CDrcqTFEAYEbQ.png"/></div></div></figure><p id="183c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">红框</strong> →为 Numpy 生成膨胀系数为 4 的内核</p><p id="0e75" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">现在，由于膨胀因子已经增加到 4，我们将为 Numpy 生成一个新内核。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mm"><img src="../Images/be9c565b36c6224a6e143329a4d0b452.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kdKcxoZDla3zAxUK_JbdOQ.png"/></div></div></figure><p id="75b4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">红线</strong> →注意我们正在对 Numpy <br/> <strong class="kf ir">黄线</strong> →张量流的膨胀因子进行“熟悉的”卷积运算</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="6f8b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">交互代码</strong></p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mn"><img src="../Images/f41e62acd6658e6d740d786f6413853d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bKfnaM_csgRN_a4rYMeAHw.png"/></div></div></figure><p id="175b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ln">我为了交互代码搬到了 Google Colab！所以你需要一个谷歌帐户来查看代码，你也不能在谷歌实验室运行只读脚本，所以在你的操场上做一个副本。最后，我永远不会请求允许访问你在 Google Drive 上的文件，仅供参考。编码快乐！</em></p><p id="708b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">**注意**安装在 Google Collab 上的 Tensorflow 版本似乎不支持膨胀因子大于 2 的膨胀卷积，(仅适用于 tf.nn.conv2d())它会给出以下错误。所以我已经把 tf.nn.cond2d()注释掉了。</p><figure class="lj lk ll lm gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mo"><img src="../Images/5f822b91979a254fdd8c8f04dcbc475a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g5DZ9Je1xAQmmhY68CXTPQ.png"/></div></div></figure><p id="b6df" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">要访问代码，<a class="ae kc" href="https://colab.research.google.com/drive/11v7HffmCyiww94Ftiz8mvKP_W-oUhnUF" rel="noopener ugc nofollow" target="_blank">请点击此处</a>。</p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="5a77" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">最后的话</strong></p><p id="86ee" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个惊人的事实是:对扩张卷积运算进行反向传播只是<a class="ae kc" href="https://medium.com/swlh/only-numpy-understanding-back-propagation-for-transpose-convolution-in-multi-layer-cnn-with-c0a07d191981" rel="noopener">转置卷积运算</a>。</p><p id="d72e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 给我，如果你想看我所有写作的列表，请点击这里查看我的网站。</p><p id="ccc9" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">同时，在我的推特<a class="ae kc" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，访问<a class="ae kc" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或者我的<a class="ae kc" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。如果你感兴趣，我还在这里做了解耦神经网络<a class="ae kc" href="https://becominghuman.ai/only-numpy-implementing-and-comparing-combination-of-google-brains-decoupled-neural-interfaces-6712e758c1af" rel="noopener ugc nofollow" target="_blank">的比较。</a></p></div><div class="ab cl lb lc hu ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="ij ik il im in"><p id="ab72" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kf ir">参考</strong></p><ol class=""><li id="602d" class="lq lr iq kf b kg kh kk kl ko ls ks lt kw lu la lv lw lx ly bi translated">膨胀卷积和克罗内克因子卷积。(2016).推论。检索于 2018 年 3 月 12 日，来自<a class="ae kc" href="http://www.inference.vc/dilated-convolutions-and-kronecker-factorisation/" rel="noopener ugc nofollow" target="_blank">http://www . inference . VC/expanded-convolutions-and-kronecker-factorisation/</a></li><li id="c65e" class="lq lr iq kf b kg lz kk ma ko mb ks mc kw md la lv lw lx ly bi translated">卷积运算教程—no 1 . 0 . 0 文档。(2018).Deeplearning.net。检索于 2018 年 3 月 12 日，来自<a class="ae kc" href="http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html" rel="noopener ugc nofollow" target="_blank">http://deep learning . net/software/the ano/tutorial/conv _ 算术. html </a></li><li id="ca09" class="lq lr iq kf b kg lz kk ma ko mb ks mc kw md la lv lw lx ly bi translated">tf.nn.atrous_conv2d | TensorFlow。(2018).张量流。检索于 2018 年 3 月 12 日，来自<a class="ae kc" href="https://www.tensorflow.org/api_docs/python/tf/nn/atrous_conv2d" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/nn/atrous _ conv 2d</a></li><li id="5430" class="lq lr iq kf b kg lz kk ma ko mb ks mc kw md la lv lw lx ly bi translated">SciPy . signal . convolved 2d—SciPy v 1 . 0 . 0 参考指南。(2018).Docs.scipy.org。检索于 2018 年 3 月 12 日，来自<a class="ae kc" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html" rel="noopener ugc nofollow" target="_blank">https://docs . scipy . org/doc/scipy/reference/generated/scipy . signal . convolved . html</a></li><li id="f3a2" class="lq lr iq kf b kg lz kk ma ko mb ks mc kw md la lv lw lx ly bi translated">数组，I. (2018)。NumPy 数组的就地类型转换。Stackoverflow.com。检索于 2018 年 3 月 12 日，来自<a class="ae kc" href="https://stackoverflow.com/questions/4389517/in-place-type-conversion-of-a-numpy-array" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/4389517/in-place-type-conversion-of-a-numpy-array</a></li><li id="548b" class="lq lr iq kf b kg lz kk ma ko mb ks mc kw md la lv lw lx ly bi translated">TF . nn . conv 2d _ back prop _ filter | tensor flow。(2018).张量流。检索于 2018 年 3 月 12 日，来自<a class="ae kc" href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_backprop_filter" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/nn/conv2d _ back prop _ filter</a></li><li id="63a5" class="lq lr iq kf b kg lz kk ma ko mb ks mc kw md la lv lw lx ly bi translated">tf.nn.conv2d | TensorFlow。(2018).张量流。检索于 2018 年 3 月 12 日，来自<a class="ae kc" href="https://www.tensorflow.org/api_docs/python/tf/nn/conv2d" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/api_docs/python/tf/nn/conv2d</a></li><li id="6caf" class="lq lr iq kf b kg lz kk ma ko mb ks mc kw md la lv lw lx ly bi translated">“扩张卷积和卷积+步幅有什么区别？——Quora”。2018.Quora.Com。2018 年 3 月 12 日访问。<a class="ae kc" href="https://www.quora.com/What-is-the-difference-between-dilated-convolution-and-convolution+stride" rel="noopener ugc nofollow" target="_blank">https://www . quora . com/What-is-difference-of-expanded-convolution-and-convolution+stride</a>。</li><li id="bba3" class="lq lr iq kf b kg lz kk ma ko mb ks mc kw md la lv lw lx ly bi translated">于，冯，科尔敦，伏(2015)。基于扩张卷积的多尺度上下文聚合。<em class="ln"> arXiv 预印本 arXiv:1511.07122 </em>。</li><li id="60d1" class="lq lr iq kf b kg lz kk ma ko mb ks mc kw md la lv lw lx ly bi translated">理解多层 CNN 转置卷积的反向传播。(2018).中等。检索于 2018 年 3 月 12 日，来自<a class="ae kc" href="https://medium.com/swlh/only-numpy-understanding-back-propagation-for-transpose-convolution-in-multi-layer-cnn-with-c0a07d191981" rel="noopener">https://medium . com/swlh/only-numpy-understanding-back-propagation-for-transpose-convolution-in-multi-layer-CNN-with-c0a 07d 191981</a></li></ol></div></div>    
</body>
</html>