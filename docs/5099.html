<html>
<head>
<title>Review: Inception-v4 — Evolved From GoogLeNet, Merged with ResNet Idea (Image Classification)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回顾:Inception-v4——从 GoogLeNet 发展而来，与 ResNet Idea(图像分类)合并</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification-5e8c339d18bc?source=collection_archive---------5-----------------------#2018-09-27">https://towardsdatascience.com/review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification-5e8c339d18bc?source=collection_archive---------5-----------------------#2018-09-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="8be4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi kl translated"><span class="l km kn ko bm kp kq kr ks kt di">在</span>这个故事中，谷歌的<strong class="jp ir">Inception-v4【1】被评论。从 GoogLeNet / Inception-v1 演化而来的 Inception-v4，比 Inception-v3 有一个<strong class="jp ir">更统一的简化架构和更多的 Inception 模块。</strong></strong></p><p id="484c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从下图中，我们可以看到从 v1 到 v4 的<strong class="jp ir"> top-1 精度。而且<strong class="jp ir"> Inception-v4 比 ResNet </strong>好。</strong></p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ku"><img src="../Images/75fc4f59b3df6d43b72d836b3fc4fcf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*A0JzlOwTokGwhcBhT89tDQ.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">Top-1 Accuracy against Number of Operations (Size is the number of parameters)</strong></figcaption></figure><p id="c2d0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">有剩余连接的初始网络，</strong>微软 ResNet 提出的一个想法，<strong class="jp ir">优于同样昂贵的没有剩余连接的初始网络。</strong></p><p id="9e2d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">利用 1 个初始 v4 和 3 个残差网络的集成，在 ILSVRC 分类任务中可以实现 3.08%的误差</strong>。这是一篇<strong class="jp ir"> 2017 AAAI </strong>的论文，在我写这篇文章的时候有超过<strong class="jp ir"> 1000 次引用</strong>。(<a class="ll lm ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----5e8c339d18bc--------------------------------" rel="noopener" target="_blank">曾植和</a> @中)</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="a38a" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">涵盖哪些内容</h1><ol class=""><li id="7383" class="ms mt iq jp b jq mu ju mv jy mw kc mx kg my kk mz na nb nc bi translated"><strong class="jp ir">从 Inception-v1 到 Inception-v3 的简要概述</strong></li><li id="629d" class="ms mt iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><strong class="jp ir">盗梦空间-v4 </strong></li><li id="1681" class="ms mt iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><strong class="jp ir">盗梦空间-ResNet-v1 </strong></li><li id="78ef" class="ms mt iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><strong class="jp ir">盗梦空间-ResNet-v2 </strong></li><li id="1d00" class="ms mt iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><strong class="jp ir">与最先进方法的比较</strong></li></ol></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="e017" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">1.从初始版本 1 到初始版本 3 的简要概述</h1><p id="87e7" class="pw-post-body-paragraph jn jo iq jp b jq mu js jt ju mv jw jx jy ni ka kb kc nj ke kf kg nk ki kj kk ij bi translated">在开始谈论 Inception-v4 之前，让我们先回顾一下从 v1 到 v3。</p><h2 id="6784" class="nl lv iq bd lw nm nn dn ma no np dp me jy nq nr mi kc ns nt mm kg nu nv mq nw bi translated">1.1.Inception-v1/Google net[2]:Inception 模块</h2><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi nx"><img src="../Images/1f943a27589007aa5a68fa3a71a3c8fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2q5Yhan-4DQcwy9Hi2gX3g.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">Inception Module (Left), Inception Module with Dimensionality Reduction (Right)</strong></figcaption></figure><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ny"><img src="../Images/6936f15c0a8bfc9ed2155e86fc7bdd47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rXcdL9OV5YKlYyks9XK-wA.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">Overall Architecture</strong></figcaption></figure><p id="056c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> Inception 模块</strong>在 Inception-v1 / GoogLeNet 中首次引入。<strong class="jp ir">输入同时通过 1×1、3×3 和 5×5 conv 以及最大池</strong>并连接在一起作为输出。因此，我们不需要考虑每一层应该使用哪种过滤器尺寸。</p><p id="99c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(<a class="ae nz" href="https://medium.com/coinmonks/paper-review-of-googlenet-inception-v1-winner-of-ilsvlc-2014-image-classification-c2b3565a64e7" rel="noopener">我对《盗梦空间》的详细回顾-v1 / GoogLeNet </a>)</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h2 id="40d5" class="nl lv iq bd lw nm nn dn ma no np dp me jy nq nr mi kc ns nt mm kg nu nv mq nw bi translated">1.2.Inception-v2 / BN-Inception [3]:批量规范化</h2><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi oa"><img src="../Images/a2921864addd556875025429f4f3e90c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*09GjUZS_EYh9KBxxJQCmDw.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">Batch Normalization (BN)</strong></figcaption></figure><p id="55d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">批量规范化(BN) </strong>在 Inception-v2 / BN-Inception 中引入。ReLU 被用作激活函数来解决饱和问题和由此产生的消失梯度。但是这也使得输出更加不规则。随着时间的推移，X 的分布保持固定是有利的，因为当网络变得更深时，小的变化将被放大。可以使用更高的学习率。</p><p id="2f58" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">此外，<strong class="jp ir"> 5×5 conv 被两个 3×3 conv</strong>取代，用于在保持感受野大小的同时降低参数。</p><p id="b4bc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(<a class="ae nz" href="https://medium.com/@sh.tsang/review-batch-normalization-inception-v2-bn-inception-the-2nd-to-surpass-human-level-18e2d0f56651" rel="noopener">我对 Inception-v2 / BN-Inception 的详细回顾</a>)</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h2 id="1bd4" class="nl lv iq bd lw nm nn dn ma no np dp me jy nq nr mi kc ns nt mm kg nu nv mq nw bi translated"><strong class="ak"> 1.3。Inception-v3 [4]:因式分解</strong></h2><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ob"><img src="../Images/b27ecdd41c519ac8ec687570c81ca325.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kCif48yAZikiDEEsGv4ZsQ.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">3×3 conv becomes 1×3 and 3×1 convs (Left), 7×7 conv becomes 1×7 and 7×1 convs (Right)</strong></figcaption></figure><p id="e39e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">如上图卷积层引入因子分解</strong>进一步降维，减少过拟合问题。例如:</p><p id="d15c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过使用<strong class="jp ir"> 3×3 滤波器</strong>，参数数量= <strong class="jp ir"> 3×3=9 <br/> </strong>通过使用<strong class="jp ir"> 3×1 和 1×3 滤波器</strong>，参数数量= <strong class="jp ir"> 3×1+1×3=6 <br/>参数数量减少 33% </strong></p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="ab gu cl oc"><img src="../Images/f35fe2bb075dbbb13c59ce54c6c5601b.png" data-original-src="https://miro.medium.com/v2/format:webp/1*_Z-bkIqq41WHaX4VqcVwNg.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">Conventional downsizing (Top Left), Efficient Grid Size Reduction (Bottom Left), Detailed Architecture of Efficient Grid Size Reduction (Right)</strong></figcaption></figure><p id="d964" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">并且还引入了高效的<strong class="jp ir">网格尺寸缩减模块</strong>，其<strong class="jp ir">更便宜并且仍然是高效的网络</strong>。通过有效的网格尺寸缩减，例如图中所示，<strong class="jp ir"> 320 个特征图</strong>由<strong class="jp ir"> conv 以步长 2 </strong>完成。<strong class="jp ir">通过<strong class="jp ir">最大汇集</strong>得到 320 张特征地图</strong>。并且这 2 组特征图被<strong class="jp ir">连接成 640 个特征图</strong>并且进入下一级的初始模块。</p><p id="2725" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(<a class="ae nz" href="https://medium.com/@sh.tsang/review-inception-v3-1st-runner-up-image-classification-in-ilsvrc-2015-17915421f77c" rel="noopener">我对 Inception-v3 的详细回顾</a>)</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="7533" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">2.盗梦空间-第 4 版</h1><p id="d0af" class="pw-post-body-paragraph jn jo iq jp b jq mu js jt ju mv jw jx jy ni ka kb kc nj ke kf kg nk ki kj kk ij bi translated">比 inception-v3 更统一的简化架构和更多的 Inception 模块，介绍如下:</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi od"><img src="../Images/c7878015d2571bba4a6696efc72106f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HJ3CNNGz6v76H38s7-OTSA.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">Inception-v4: Whole Network Schema (Leftmost), Stem (2nd Left), Inception-A (Middle), Inception-B (2nd Right), Inception-C (Rightmost)</strong></figcaption></figure><p id="312d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是一个没有任何剩余连接的<strong class="jp ir">纯初始变体</strong>。它可以在不分割副本的情况下进行训练，使用<strong class="jp ir">内存优化来反向传播</strong>。</p><p id="dbb2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们可以看到<strong class="jp ir">使用了从 Inception-v1 到 Inception-v3 的技术</strong>。(也使用了批量标准化，但未在图中显示。)</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="2401" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated"><strong class="ak"> 3。盗梦空间-ResNet-v1 </strong></h1><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi oe"><img src="../Images/016e96aa2b06b1cfcbb911835f8facdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LjImFrHzbu2mG8RezRO_JA.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">Inception-ResNet-v1: Whole Network Schema (Leftmost), Stem (2nd Left), Inception-A (Middle), Inception-B (2nd Right), Inception-C (Rightmost)</strong></figcaption></figure><p id="26ea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通过使用上述版本的 Inception-A、Inception-B 和 Inception-C，我们可以拥有 Inception-ResNet-v1。我们可以看到每个模块的左侧都有一个<strong class="jp ir">快捷连接。这种快捷的连接已经被一种证明，它可以帮助在 ResNet [5]中走得更深。</strong></p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi of"><img src="../Images/02e9621acf9d7ddddf1f7e816a8c0b12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*0cRib0KY0iyGBtbbVozPsw.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">Inception-Resnet-v1 and Inception-v3</strong></figcaption></figure><p id="4ccb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它的<strong class="jp ir">大约相当于《盗梦空间-v3》的计算成本。Inception-Resnet-v1 的训练速度要快得多</strong>，但最终精度比 Inception-v3 稍差。</p><p id="cbd4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，加在一起后使用的 ReLU 使得 Inception network 无法进一步深入。<strong class="jp ir">在论文中，作者还提到，如果过滤器的数量超过 1000，残差变体开始表现出不稳定性，并且网络在训练期间早期就“死亡”。</strong></p><p id="a288" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">为了稳定训练</strong>，在将残差添加到先前的层激活之前缩小残差。一般来说，<strong class="jp ir">在添加</strong>到累积层激活之前，在 0.1 和 0.3 之间选择一些缩放因子来缩放残差</p><p id="2752" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">(也许，如果 ReLU 被用作预激活单元，就像在使用身份映射的改进 ResNet 中提到的[6]，它可能会更深入。)</strong>(如有兴趣，请访问<a class="ae nz" rel="noopener" target="_blank" href="/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e">我对预激活 ResNet 的评论。</a>)</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="facc" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">4.盗梦空间-ResNet-v2</h1><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi og"><img src="../Images/1c17fbfa168c4f39b9d5ebbeba863157.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ohZ1Bb8Ny2U2EivnwYgTmA.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">Inception-ResNet-v2: Inception-A (Leftmost), Inception-B (Middle), Inception-C (Rightmost)</strong></figcaption></figure><p id="0968" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有了<strong class="jp ir">全网模式使用 Inception-ResNet-v1 中的那个，Stem 使用 Inception-v4 </strong>中的那个，以及以上版本的 Inception-A、Inception-B、Inception-C，我们就可以有 Inception-ResNet-v2 了。同样，在每个模块的左侧有一个<strong class="jp ir">快捷连接。</strong></p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/fa6ed8dd5e5ccd938f619a51d7084ed9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*-TsQoXkufqLAKeIMLJsbDQ.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">Inception-Resnet-v2 and Inception-v4</strong></figcaption></figure><p id="90e7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它的计算成本大约相当于《盗梦空间 4》的计算成本。与 Inception-v4 相比，Inception-ResNet-v2 的训练速度要快得多，并且达到了略好的最终精度。</p><p id="bd3b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">然而，同样地，如果 ReLU 被用作预激活单位，它可能会更深入。(如果感兴趣，请访问<a class="ae nz" rel="noopener" target="_blank" href="/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e">我对改进的 ResNet 的评论。</a>)</p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="3ffa" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">5.<strong class="ak">与最先进方法的比较</strong></h1><p id="b922" class="pw-post-body-paragraph jn jo iq jp b jq mu js jt ju mv jw jx jy ni ka kb kc nj ke kf kg nk ki kj kk ij bi translated"><strong class="jp ir">多裁剪:</strong>是将输入图像裁剪成多个子图像，输入网络进行分类，以提高精度。从 AlexNet，VGGNet 等开始使用。</p><p id="9318" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">具体来说，AlexNet 使用了 10 种作物，GoogLeNet 使用了 144 种作物。</p><p id="a9a2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">多模型</strong>:就是将多个训练好的模型集成在一起，得到更准确的预测，就像 boosting 一样。从 LeNet，AlexNet 等开始使用。</p><p id="24fb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">(如果有兴趣，请访问我的<a class="ae nz" href="https://medium.com/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160" rel="noopener"> AlexNet </a>和<a class="ae nz" href="https://medium.com/coinmonks/paper-review-of-googlenet-inception-v1-winner-of-ilsvlc-2014-image-classification-c2b3565a64e7" rel="noopener"> GoogLeNet </a>评论。)</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi oi"><img src="../Images/ed14e79369a71ca38deb89f26149a0a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lJh68Lj43CALyLFgqti4KQ.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">Single-Crop Single-Model Results</strong></figcaption></figure><p id="31ba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<strong class="jp ir">单作物单模型的情况下，Inception-v4 和 Inception-ResNet-v2 的性能最好</strong>，结果相似。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ob"><img src="../Images/05d0bd3595fae694a60c1d9b45b2a6e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kxoJaXsmrVFxP0BtEsi1PA.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">10/12-Crop Single-Model Results</strong></figcaption></figure><p id="9b6c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用<strong class="jp ir"> 10/12-Crop 单模型，Inception-v4 和 Inception-ResNet-v2 同样具有最佳性能</strong>，结果相似。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div class="gh gi oj"><img src="../Images/e475ae3cd3bd4b21daa5e74efb921906.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*phstFNaxEyGsbYMSP9jZ4w.png"/></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">144-Crop Single-Model Results</strong></figcaption></figure><p id="afed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">使用<strong class="jp ir"> 144-Crop 单模型，Inception-v4 和 Inception-ResNet-v2 同样具有最佳性能</strong>，结果相似。</p><figure class="kv kw kx ky gt kz gh gi paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="gh gi ok"><img src="../Images/6f86e88d3d0e048f4747e51f82b2541d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LZchNvQivEusNv1gbVl8nQ.png"/></div></div><figcaption class="lg lh gj gh gi li lj bd b be z dk"><strong class="bd lk">144-Crop N-Model Results</strong></figcaption></figure><p id="2ae3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">用<strong class="jp ir"> 144-Crop N-Model，Inception-v4(+Residual)，即 1 个纯 Inception-v4 和 3 个 Inception-ResNet-v2 模型(N=4)，性能最好。</strong></p><p id="e66c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">获得 3.1%的前 5 名错误率</strong>。与 ResNet  (3.57%的错误率，2015 年 ILSVRC 的冠军)<strong class="jp ir">和 Inception-v3 </strong> (3.58%的错误率，2015 年 ILSVRC 的亚军)相比，这已经是一个<strong class="jp ir">很大的相对进步。</strong></p></div><div class="ab cl ln lo hu lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ij ik il im in"><h1 id="ea61" class="lu lv iq bd lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr bi translated">参考</h1><ol class=""><li id="6d7b" class="ms mt iq jp b jq mu ju mv jy mw kc mx kg my kk mz na nb nc bi translated">【2017 AAAI】【Inception-v4】<br/><a class="ae nz" href="https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14806/14311" rel="noopener ugc nofollow" target="_blank">Inception-v4、Inception-ResNet 以及剩余连接对学习的影响</a></li><li id="afeb" class="ms mt iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated">【2015 CVPR】【谷歌网/盗梦空间-v1】<br/><a class="ae nz" href="https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf" rel="noopener ugc nofollow" target="_blank">随着回旋越走越深</a></li><li id="36c5" class="ms mt iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated">【2015 ICML】【BN-Inception/Inception-v2】<br/><a class="ae nz" href="http://proceedings.mlr.press/v37/ioffe15.pdf" rel="noopener ugc nofollow" target="_blank">批量归一化:通过减少内部协变量移位加速深度网络训练</a></li><li id="3613" class="ms mt iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated">【2016 CVPR】【盗梦空间-v3】<br/><a class="ae nz" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank">重新思考计算机视觉的盗梦空间架构</a></li><li id="e0a8" class="ms mt iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated">【2016 CVPR】【ResNet】<br/><a class="ae nz" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf" rel="noopener ugc nofollow" target="_blank">用于图像识别的深度残差学习</a></li><li id="e44f" class="ms mt iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated">【2016 ECCV】【带有身份映射的 ResNet】<br/><a class="ae nz" href="https://arxiv.org/abs/1603.05027" rel="noopener ugc nofollow" target="_blank">深度剩余网络中的身份映射</a></li></ol><h1 id="6c3e" class="lu lv iq bd lw lx ol lz ma mb om md me mf on mh mi mj oo ml mm mn op mp mq mr bi translated">我的评论</h1><ol class=""><li id="4c7d" class="ms mt iq jp b jq mu ju mv jy mw kc mx kg my kk mz na nb nc bi translated"><a class="ae nz" href="https://medium.com/@sh.tsang/review-inception-v3-1st-runner-up-image-classification-in-ilsvrc-2015-17915421f77c" rel="noopener">回顾:Inception-v3–ILSVRC 2015 亚军(图像分类)</a></li><li id="11c6" class="ms mt iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><a class="ae nz" href="https://medium.com/@sh.tsang/review-batch-normalization-inception-v2-bn-inception-the-2nd-to-surpass-human-level-18e2d0f56651" rel="noopener">回顾:批量归一化(Inception-v2/BN-Inception)——ILSVRC 2015 中第二个超越人类水平的性能(图像分类)</a></li><li id="4d8d" class="ms mt iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><a class="ae nz" href="https://medium.com/coinmonks/paper-review-of-googlenet-inception-v1-winner-of-ilsvlc-2014-image-classification-c2b3565a64e7" rel="noopener">回顾:Google net(Inception v1)——ILSVRC 2014(图像分类)获奖者</a></li><li id="93fd" class="ms mt iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><a class="ae nz" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8">回顾:ResNet—ils vrc 2015(图像分类、定位、检测)获奖者</a></li><li id="a454" class="ms mt iq jp b jq nd ju ne jy nf kc ng kg nh kk mz na nb nc bi translated"><a class="ae nz" rel="noopener" target="_blank" href="/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e">回顾:带有身份映射的 ResNet 已达到 1000 多个图层(图像分类)</a></li></ol></div></div>    
</body>
</html>