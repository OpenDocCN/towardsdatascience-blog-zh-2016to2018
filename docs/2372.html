<html>
<head>
<title>What is wrong with Convolutional neural networks ?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络有什么问题？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-is-wrong-with-convolutional-neural-networks-75c2ba8fbd6f?source=collection_archive---------4-----------------------#2018-01-17">https://towardsdatascience.com/what-is-wrong-with-convolutional-neural-networks-75c2ba8fbd6f?source=collection_archive---------4-----------------------#2018-01-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><h1 id="cf7a" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</h1><p id="cb1a" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">当然，卷积神经网络(CNN)是一种迷人而强大的工具，也许这是深度学习这些天如此受欢迎的原因之一，自从 Alex Krizhevsky，Ilya Sutskever 和 Geoffrey Hinton 在 2012 年发表了“用深度卷积网络进行图像网络分类”以来，CNN 一直是计算机视觉中在许多任务中实现超人性能的制胜法宝，但 CNN 是完美无瑕的吗？那是我们能做的最好的吗？我想从标题中你可以看出答案是否定的。</p><p id="c024" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">2014 年 12 月 4 日，Geoffrey Hinton 在麻省理工学院做了一个关于他的名为“胶囊网络”的项目的演讲，他讨论了 CNN 的问题，以及为什么合用是非常糟糕的，以及它工作得如此好的事实是一场灾难</p><blockquote class="lo lp lq"><p id="8652" class="kl km lr kn b ko lj kq kr ks lk ku kv ls ll ky kz lt lm lc ld lu ln lg lh li ij bi translated">如果你熟悉 CNN，你可以跳到<strong class="kn ir">怎么了？</strong></p></blockquote><h1 id="6578" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">卷积层</h1><p id="f28f" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">卷积层具有一组矩阵，这些矩阵在称为卷积的过程中与前一层输出相乘，以检测一些特征。这些特征可以是基本特征(例如边缘、颜色等级或图案)或复杂特征(例如形状、鼻子或嘴)。因此，这些矩阵称为过滤器或内核</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div class="gh gi lv"><img src="../Images/289f2deaca9bc4dac099606d40f6432a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/1*GcI7G-JLAQiEoCON7xFbhg.gif"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk"><a class="ae mh" href="https://www.cc.gatech.edu/~san37/post/dlhc-cnn/" rel="noopener ugc nofollow" target="_blank">(source)</a></figcaption></figure><h1 id="8d64" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">池层</h1><p id="e7f4" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">有多种类型的池层(最大池、平均池……)，目前最常见的是最大池，因为它给出了交易方差，虽然很差，但对某些任务来说已经足够好了，并且它降低了网络的维数，非常便宜(没有参数)<br/>最大池层实际上非常简单，你预定义一个过滤器(一个窗口)并在输入中交换该窗口，取窗口中包含的最大值作为输出</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mi"><img src="../Images/43c9d1def28f9c877534635172a57cd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GksqN5XY8HPpIddm5wzm7A.jpeg"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">max pooling with filter size 2*2 <a class="ae mh" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">(source)</a></figcaption></figure><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi mn"><img src="../Images/74bafff5adb120fe19072e3482f74265.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*lbUtgiANqLoO1GFSc9pHTg.gif"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk"><a class="ae mh" href="https://www.cc.gatech.edu/~san37/post/dlhc-cnn/" rel="noopener ugc nofollow" target="_blank">(source)</a></figcaption></figure><h1 id="a50f" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">怎么了？</h1><h2 id="6d73" class="mo jo iq bd jp mp mq dn jt mr ms dp jx kw mt mu kb la mv mw kf le mx my kj mz bi translated">1- <strong class="ak">反向传播</strong></h2><p id="79c1" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">反向传播算法是一种在对一批数据进行预处理后，寻找每个权重在误差中的贡献的方法，大多数好的优化算法(SGD，ADAM …)都使用反向传播算法来寻找梯度</p><p id="9241" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">反向传播在过去几年做得很好，但不是一种有效的学习方式，因为它需要庞大的数据集<br/>我相信我们可以做得更好</p><h2 id="1884" class="mo jo iq bd jp mp mq dn jt mr ms dp jx kw mt mu kb la mv mw kf le mx my kj mz bi translated">2-平移不变性</h2><p id="451f" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">当我们说平移不变性时，我们的意思是，方向或位置稍有变化的同一物体可能不会激发本应识别该物体的神经元</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi na"><img src="../Images/2df7c13f734cef6f16e9cdc0ff57bcb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6kN_h3jQl62I9d8vz33TYQ.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk"><a class="ae mh" href="https://www.cc.gatech.edu/~san37/post/dlhc-cnn/" rel="noopener ugc nofollow" target="_blank">(source)</a></figcaption></figure><p id="3d8c" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">如上图所示，如果我们假设有一个用来检测猫的神经元，它的值会随着猫的位置和旋转的变化而变化，数据增强部分解决了这个问题，但并没有完全解决它</p><h2 id="54f7" class="mo jo iq bd jp mp mq dn jt mr ms dp jx kw mt mu kb la mv mw kf le mx my kj mz bi translated">3-池层</h2><p id="7b77" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">合并图层是一个很大的错误，因为它丢失了很多有价值的信息，而且它忽略了部分和整体之间的关系，如果我们谈论的是人脸检测器，那么我们必须结合一些特征(嘴、两只眼睛、椭圆形脸和鼻子)来说这是一张脸<br/> CNN 会说如果这 5 个特征以很高的概率出现，这将是一张脸</p><figure class="lw lx ly lz gt ma gh gi paragraph-image"><div role="button" tabindex="0" class="mj mk di ml bf mm"><div class="gh gi nb"><img src="../Images/6cb662643f5fff6ef4068f55bae718c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wsf4tsOH77T1lpylPUIhbA.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk"><a class="ae mh" href="https://medium.com/ai%C2%B3-theory-practice-business/understanding-hintons-capsule-networks-part-i-intuition-b4b559d1159b" rel="noopener">(source)</a></figcaption></figure><p id="8625" class="pw-post-body-paragraph kl km iq kn b ko lj kq kr ks lk ku kv kw ll ky kz la lm lc ld le ln lg lh li ij bi translated">所以两个图像的输出可能是相似的，这并不好</p><h1 id="2885" class="jn jo iq bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结论</h1><p id="1a64" class="pw-post-body-paragraph kl km iq kn b ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li ij bi translated">CNN 很棒，但它有两个非常危险的缺陷:平移不变性和池层，幸运的是，我们可以通过数据增强来减少危险，但有些事情正在发生(胶囊网络),我们必须准备好迎接变化</p><h2 id="316a" class="mo jo iq bd jp mp mq dn jt mr ms dp jx kw mt mu kb la mv mw kf le mx my kj mz bi translated">来源</h2><div class="nc nd gp gr ne nf"><a href="http://cs231n.github.io/" rel="noopener  ugc nofollow" target="_blank"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd ir gy z fp nk fr fs nl fu fw ip bi translated">用于视觉识别的 CS231n 卷积神经网络</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">斯坦福 CS231n 课程材料和笔记:视觉识别的卷积神经网络。</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">cs231n.github.io</p></div></div></div></a></div><div class="nc nd gp gr ne nf"><a href="https://medium.com/ai%C2%B3-theory-practice-business/understanding-hintons-capsule-networks-part-i-intuition-b4b559d1159b" rel="noopener follow" target="_blank"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd ir gy z fp nk fr fs nl fu fw ip bi translated">理解辛顿的胶囊网络。第一部分:直觉。</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">理解 Hinton 的胶囊网络系列的一部分:</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">medium.com</p></div></div><div class="no l"><div class="np l nq nr ns no nt mb nf"/></div></div></a></div><div class="nc nd gp gr ne nf"><a href="https://www.cc.gatech.edu/~san37/post/dlhc-cnn/" rel="noopener  ugc nofollow" target="_blank"><div class="ng ab fo"><div class="nh ab ni cl cj nj"><h2 class="bd ir gy z fp nk fr fs nl fu fw ip bi translated">卷积神经网络</h2><div class="nm l"><h3 class="bd b gy z fp nk fr fs nl fu fw dk translated">这是 CSE6250 大数据分析中医疗保健深度学习实验室系列的初步版本…</h3></div><div class="nn l"><p class="bd b dl z fp nk fr fs nl fu fw dk translated">www.cc.gatech.edu</p></div></div><div class="no l"><div class="nu l nq nr ns no nt mb nf"/></div></div></a></div><figure class="lw lx ly lz gt ma"><div class="bz fp l di"><div class="nv nw l"/></div></figure></div></div>    
</body>
</html>