<html>
<head>
<title>Keep It Simple Stupid: Lesson in Model Selection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">保持简单愚蠢:模型选择的教训</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/keep-it-simple-stupid-lesson-in-model-selection-5fd1193009d?source=collection_archive---------5-----------------------#2017-08-16">https://towardsdatascience.com/keep-it-simple-stupid-lesson-in-model-selection-5fd1193009d?source=collection_archive---------5-----------------------#2017-08-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="53d3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我在大会上接受了一个项目，在那里我得到了乳房肿瘤的物理数据，并被要求预测肿瘤是恶性还是良性。在这次作业中，我被特别要求比较两种不同的建模技术，并解释为什么我选择了一种而不是另一种。我开始使用的两种技术是逻辑回归和随机森林。在这种情况下，逻辑回归是最终的赢家，因为随机森林最终没有提供任何更多的预测能力，并且向模拟客户端解释推论会更加困难。</p><p id="6904" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">模型创建</strong></p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi kl"><img src="../Images/a2a9f366f56302607a2abe51a5d77dbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*oO7FXIGLxa1yl0cUFIX3Ng.png"/></div></figure><p id="fae5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在对数据进行缩放后，我创建了一个热图，它显示了我在逻辑回归的特征选择上几乎没有回旋的余地。几乎所有的东西都是高度相关的，除了几个变量，使用大多数变量会弄乱结果。我最终选择了三个变量(半径平均值、凹度最差和对称性最差)，并添加了一个交互项。结果如下:</p><p id="32f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kt">物流培训设置结果</em> </strong></p><p id="ac6c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">准确率:</strong> 96%</p><p id="9d68" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">灵敏度:</strong> 94%</p><p id="bf4f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">特异性:</strong> 97%</p><p id="9ab2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kt">逻辑测试集结果</em> </strong></p><p id="aa2d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">准确率:</strong> 94%</p><p id="b345" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">灵敏度:</strong> 89%</p><p id="008e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">特异性:</strong> 97%</p><p id="3a8b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我对这些结果非常满意，但是需要根据作业尝试另一个模型。随机森林是我经常使用的算法，我不必担心变量之间的独立性，所以我尝试了一下。训练集的结果稍好，但测试集的结果与逻辑回归的结果相匹配:</p><p id="1207" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kt">随机森林训练设置结果</em> </strong></p><p id="1d9b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">准确率:</strong> 98%</p><p id="9dfe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">灵敏度:</strong> 95%</p><p id="b5ee" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">特异性:</strong> 99%</p><p id="05f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="kt">随机森林测试集结果</em> </strong></p><p id="6be5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">准确率:</strong> 94%</p><p id="70d7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">灵敏度:</strong> 89%</p><p id="8ac9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">特异性:</strong> 96%</p><p id="3485" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">型号选择</strong></p><p id="d80d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这种情况下，逻辑回归是明显的赢家，因为它在以下方面更简单:</p><p id="35d1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 1。</strong> <strong class="jp ir">逻辑回归是一种更简单的算法</strong></p><p id="c55b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">大多数对数据科学了解有限的人都知道，线性回归就是在数据集上画一条线。那么，解释逻辑回归是相同的事情，除了目标被0和1限制，结果是记录是您试图预测的目标类的概率，这并不是一个飞跃。</p><p id="0fbe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这与随机森林相反，随机森林是一种集合方法。我认为大多数人能够理解单一决策树的概念。但是解释为什么你要创建多棵树来防止过度拟合，以及它们是如何组合的就有点困难了。在这两种算法中，我更愿意向客户解释逻辑回归。</p><p id="0ba8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> 2。</strong> <strong class="jp ir">逻辑回归提供了更简单的推论</strong></p><p id="1e57" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">就像线性回归一样，你可以从逻辑回归中得到系数。我们可以看到，凹度的增加导致肿瘤恶性的可能性更高。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kv kw di kx bf ky"><div class="gh gi ku"><img src="../Images/d7163b26e2ac220c439807e53794b322.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*isAsVOpQSxM2PmrzpZUZoA.png"/></div></div></figure><p id="0deb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="kt">注意:我知道半径平均值和交互作用项并不显著，但是去掉它们会影响逻辑回归的预测能力。</em></p><p id="1df5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这与随机森林不同，在随机森林中，您只能提取重要的特征。你不能说它们是如何与目标相关联的，因为一棵树上的变量分裂可能与另一棵树上的分裂相矛盾。</p><p id="4f1a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在如今神经网络和其他复杂算法大行其道的世界里，保持简单愚蠢是需要记住的重要一课。虽然它们可能很强大，但如果用更简单的方法也能达到同样的效果，你可能会得到额外的好处，能够更容易地向客户解释它和它的结果。</p><p id="39c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你想看与这个项目相关的jupyter笔记本，请查看我的<a class="ae kz" href="https://brendanbailey.github.io/Blog/GABreast_Cancer/GA_Breast_Cancer_Project.html" rel="noopener ugc nofollow" target="_blank">作品集页面</a>。</p></div></div>    
</body>
</html>