<html>
<head>
<title>Collaborative Filtering and Embeddings — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">协作过滤和嵌入—第 1 部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/collaborative-filtering-and-embeddings-part-1-63b00b9739ce?source=collection_archive---------1-----------------------#2017-12-28">https://towardsdatascience.com/collaborative-filtering-and-embeddings-part-1-63b00b9739ce?source=collection_archive---------1-----------------------#2017-12-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/4375e9dafe0cabced41686c74f9215fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2z30zhIwjK7R4sRTavEG_A.png"/></div></div></figure><p id="8544" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">推荐系统就在我们身边。从网飞、亚马逊到 even Medium，每个人都在试图理解我们的口味，这样他们就能促使我们持续参与。你会惊讶于这背后的工作量。让我们试着理解开发推荐系统的一种方法的机制。</p><h1 id="1320" class="kz la it bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">介绍</h1><p id="4c11" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">在这一系列文章中，我将解释协作过滤，这是开发自动推荐系统的一种非常常见的技术(尽管用例不限于推荐)。然而，使这个讨论有趣的是我们如何在实现这个技术的同时理解一个更一般的<strong class="kd iu">嵌入</strong>的概念。如果你没有听说过这个术语，不用担心，在这篇文章结束时你会有一个好主意。</p><h2 id="674e" class="mc la it bd lb md me dn lf mf mg dp lj km mh mi ln kq mj mk lr ku ml mm lv mn bi translated"><strong class="ak">第一部分:</strong></h2><ul class=""><li id="216a" class="mo mp it kd b ke lx ki ly km mq kq mr ku ms ky mt mu mv mw bi translated">协同过滤背后的基本思想</li><li id="80bd" class="mo mp it kd b ke mx ki my km mz kq na ku nb ky mt mu mv mw bi translated">一个在 excel 中实现协同过滤的简单算法(是的你没看错！！)</li><li id="d303" class="mo mp it kd b ke mx ki my km mz kq na ku nb ky mt mu mv mw bi translated">理解嵌入和偏差的概念</li></ul><h2 id="8f97" class="mc la it bd lb md me dn lf mf mg dp lj km mh mi ln kq mj mk lr ku ml mm lv mn bi translated">第二部分:</h2><ul class=""><li id="4f15" class="mo mp it kd b ke lx ki ly km mq kq mr ku ms ky mt mu mv mw bi translated">利用<a class="ae nc" href="https://github.com/fastai/fastai/tree/master/fastai" rel="noopener ugc nofollow" target="_blank"> <strong class="kd iu"> fastai </strong> </a>库实现协同过滤</li><li id="af35" class="mo mp it kd b ke mx ki my km mz kq na ku nb ky mt mu mv mw bi translated">解释和可视化嵌入</li></ul><p id="9ceb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae nc" rel="noopener" target="_blank" href="/collaborative-filtering-and-embeddings-part-2-919da17ecefb"> <strong class="kd iu">协同过滤和嵌入—第二部分</strong> </a></p><p id="4395" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">这篇文章中提出的大多数想法都来自于<strong class="kd iu">杰瑞米·霍华德</strong>作为<a class="ae nc" href="https://www.usfca.edu/data-institute" rel="noopener ugc nofollow" target="_blank">T21</a><strong class="kd iu">数据研究所的一部分进行的<a class="ae nc" href="http://course.fast.ai/" rel="noopener ugc nofollow" target="_blank"> <strong class="kd iu">深度学习 MOOC </strong> </a> - <strong class="kd iu"> v2 </strong>。这篇文章只是我尝试分享我在这个课程中学到的一些惊人的东西。</strong></p><p id="cbf0" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">现在，事不宜迟，让我们开始吧…</p><h1 id="09b7" class="kz la it bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">什么是协同过滤？</h1><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/0457b53449ab921b7161c5b3b694b2ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/1*hQAQ8s0-mHefYH83uDanGA.gif"/></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk">Figure 1: Collaborative filtering [1]</figcaption></figure><p id="2958" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在<strong class="kd iu">推荐系统</strong>的上下文中，协同过滤是一种通过分析与所述用户相似的用户的喜好来预测用户兴趣的方法。通过<strong class="kd iu">协作多个观点</strong>来过滤模式的想法是它被称为协作过滤的原因。</p><blockquote class="nm nn no"><p id="8737" class="kb kc np kd b ke kf kg kh ki kj kk kl nq kn ko kp nr kr ks kt ns kv kw kx ky im bi translated">协同过滤方法的基本假设是，如果一个人<em class="it"> A </em>在一个问题上与一个人<em class="it"> B </em>有相同的观点，那么 A 在另一个问题上比随机选择的人更有可能有 B 的观点</p><p id="1e2a" class="kb kc np kd b ke kf kg kh ki kj kk kl nq kn ko kp nr kr ks kt ns kv kw kx ky im bi translated">——维基百科[2]</p></blockquote><p id="6086" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">协同过滤是一个通用的概念，有几种算法来实现它。查看这篇比较不同算法性能的文章。</p><div class="nt nu gp gr nv nw"><a href="https://medium.com/@pgrover3/various-implementations-of-collaborative-filtering-100385c6dfe0" rel="noopener follow" target="_blank"><div class="nx ab fo"><div class="ny ab nz cl cj oa"><h2 class="bd iu gy z fp ob fr fs oc fu fw is bi translated">协同过滤的各种实现</h2><div class="od l"><h3 class="bd b gy z fp ob fr fs oc fu fw dk translated">利用协同过滤构建推荐系统的不同方法比较</h3></div><div class="oe l"><p class="bd b dl z fp ob fr fs oc fu fw dk translated">medium.com</p></div></div><div class="of l"><div class="og l oh oi oj of ok jz nw"/></div></div></a></div><p id="9cf1" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">一种这样的算法是<strong class="kd iu">概率矩阵分解。</strong>不要被名字吓到。我们将使用 excel 中的虚拟示例来理解这一点。</p><h1 id="c055" class="kz la it bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">Excel 中的协同过滤</h1><h2 id="4542" class="mc la it bd lb md me dn lf mf mg dp lj km mh mi ln kq mj mk lr ku ml mm lv mn bi translated">方案</h2><p id="fe75" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">如图 2 所示，我们有不同用户对不同电影的评分数据，评分范围为 0-5。空白单元格表示用户尚未对电影进行评级。我们的目标是尽可能地模拟这个系统。</p><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ol"><img src="../Images/1cea085ecde4d373c1092bbb98786fbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*by02yLSCV8kcjd3BdhY4Tg.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk">Figure 2: Original ratings</figcaption></figure><h2 id="bb1f" class="mc la it bd lb md me dn lf mf mg dp lj km mh mi ln kq mj mk lr ku ml mm lv mn bi translated">模型</h2><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi om"><img src="../Images/20d94affc9f9c516b804591480f2bd14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3f1x1X5POBvjqVksN3oV0A.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk">Figure 3</figcaption></figure><p id="28ee" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">在图 3 中，您可以看到完整的框架。让我们试着去理解用户-电影<strong class="kd iu">(乔恩-阿甘)的特定组合在这里发生了什么。</strong></p><p id="4c17" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">本质上，这个模型就是这个等式:</p><p id="56ca" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> <em class="np">模型预测的评分(黄色单元格中的 3.25)= 2 个绿色矢量(嵌入矢量)的点积+ 0.14(电影偏差)+ 0.87(用户偏差)</em> </strong></p><p id="aa8d" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">类似地，我们将预测每个用户-电影组合的评分，除了那些在实际数据中不存在<strong class="kd iu">用户-电影评分的组合。基于此，我们将通过比较预测评级和实际评级来计算损失(<strong class="kd iu"> RMSE(均方根误差)</strong>(在我们的例子中:底部的红色单元格)。</strong></p><p id="ad71" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">很明显，我们的预测是基于这些<strong class="kd iu"> 2 个嵌入矩阵和 2 个偏差矩阵</strong>。但是里面的数字呢，它们看起来是随机的，实际上是随机初始化的。那么，什么样的正确数字会让我们的预测接近实际的收视率呢？</p><p id="acc9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">是的，你猜对了。<strong class="kd iu">我们将通过使用某种优化算法</strong>使损失最小化来学习这些数字。事实上，这可以在 excel 中完成！！</p><h2 id="7421" class="mc la it bd lb md me dn lf mf mg dp lj km mh mi ln kq mj mk lr ku ml mm lv mn bi translated">梯度下降</h2><p id="7755" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">转到<strong class="kd iu">数据→解算器</strong>，您将看到以下窗口。在<strong class="kd iu">设置目标</strong>中选择<strong class="kd iu">损失单元</strong>，在<strong class="kd iu">可变单元</strong>中选择<strong class="kd iu">嵌入和偏置矩阵范围</strong>。点击求解，求解器将通过最小化损失开始学习嵌入和偏差矩阵中的正确值。</p><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div class="gh gi on"><img src="../Images/9a4a2584404b106d1b979a3161345ca6.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*7JVLEDVk9eKbmVul2wGmCg.png"/></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk">Figure 4</figcaption></figure><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oo"><img src="../Images/27d79525ccce5cbd9d3f185ef41f46bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KubfsXeh5t7tqNRkSD3qsA.png"/></div></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk">Figure 5 : Predicted ratings using collaborative filtering</figcaption></figure><p id="4fc4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">我们可以在图 5 中看到，求解器已经学习了嵌入和偏差矩阵中的值。我们的损失从<strong class="kd iu"> 26.04 </strong>减少到<strong class="kd iu"> 4.58 </strong>。我们从模型中得到的预测似乎也接近实际的收视率。所以现在我们有了一个看起来运行良好的模型。但是我们仍然不知道它为什么有效。基本上这个算法背后有 3 个关键的想法。</p></div><div class="ab cl op oq hx or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="im in io ip iq"><h1 id="947e" class="kz la it bd lb lc ow le lf lg ox li lj lk oy lm ln lo oz lq lr ls pa lu lv lw bi translated">嵌入</h1><blockquote class="nm nn no"><p id="623d" class="kb kc np kd b ke kf kg kh ki kj kk kl nq kn ko kp nr kr ks kt ns kv kw kx ky im bi translated">关键思想#1:找到每个用户和每部电影作为嵌入的正确表示</p></blockquote><p id="5ad4" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">是时候解决房间里的大象了。我们来看一个具体的例子。这里，<strong class="kd iu">乔恩</strong>和<strong class="kd iu">阿甘</strong>由<strong class="kd iu">向量</strong>(求解器已经学习的一串 5 个数字)表示。这些向量被称为<strong class="kd iu">嵌入</strong>。本质上在一个<strong class="kd iu"> 5 维</strong>向量空间中，乔恩和阿甘由这两个嵌入向量表示。</p><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/db87adf2068f9a677acafceda6ff2a07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*x2AVbLPJrKGIYIn19kPu3w.png"/></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk">Embedding : Jon</figcaption></figure><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div class="gh gi pb"><img src="../Images/4ee9e53fd180b9ec41d64be8394b7104.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*pArm7XQjvz0nIEQXg5zltw.png"/></div><figcaption class="ni nj gj gh gi nk nl bd b be z dk">Embedding : Forrest Gump</figcaption></figure><blockquote class="nm nn no"><p id="664d" class="kb kc np kd b ke kf kg kh ki kj kk kl nq kn ko kp nr kr ks kt ns kv kw kx ky im bi translated">嵌入是特定实体的多维向量表示</p></blockquote><p id="d908" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">这种将实体表示为高维向量的方式是关键。这种表示可以捕捉不同实体之间的复杂关系。</strong></p><h2 id="a3b3" class="mc la it bd lb md me dn lf mf mg dp lj km mh mi ln kq mj mk lr ku ml mm lv mn bi translated">为什么是 5？</h2><p id="7055" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">嵌入向量的维数没有特定的规则，更多的是关于实验。维度应该足以捕捉实体的复杂性。一维或二维向量可能无法捕捉 Jon 的复杂性。但也不应该过高。我们的乔恩和阿甘没那么复杂。</p><h2 id="430d" class="mc la it bd lb md me dn lf mf mg dp lj km mh mi ln kq mj mk lr ku ml mm lv mn bi translated">嵌入向量中数字背后的直觉</h2><p id="85f5" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">您可以将这些数字视为捕捉它所代表的实体的不同特征。比如乔恩<strong class="kd iu"> (1.34) </strong>中的第一个数字，可能代表他有多喜欢<strong class="kd iu">奇幻小说</strong>。而《阿甘正传》中的第一个数字<strong class="kd iu"> (-1.72) </strong>告诉了我们在多大程度上可以把阿甘当做<strong class="kd iu">幻想</strong>(由于数字是负数，所以非常少)。</p><p id="88e2" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">注意:从理论上讲，这是一个思考嵌入向量中的数字的好方法，但是我们永远不能真正说出每个数字实际上在捕捉什么。我们可以做一个有根据的猜测。</p><h1 id="2366" class="kz la it bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">嵌入空间的封闭性</h1><blockquote class="nm nn no"><p id="1893" class="kb kc np kd b ke kf kg kh ki kj kk kl nq kn ko kp nr kr ks kt ns kv kw kx ky im bi translated">关键思想#2:如果一部电影和一个用户在一个向量空间中很接近，那么用户很可能会给这部电影很高的评价</p></blockquote><p id="11fb" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">捕捉接近度有不同的方法:<strong class="kd iu">点积，欧氏距离，余弦相似度</strong>。在我们的例子中，我们使用了<strong class="kd iu">点积</strong>。</p><h1 id="a1c6" class="kz la it bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">偏见的作用</h1><blockquote class="nm nn no"><p id="488e" class="kb kc np kd b ke kf kg kh ki kj kk kl nq kn ko kp nr kr ks kt ns kv kw kx ky im bi translated">关键思想#3:实体有一个独立于它与其他实体的交互的固有性质</p></blockquote><p id="a631" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">简而言之，一些用户比其他人更挑剔。类似地，一些电影可以被普遍认为是好的，并且会被大多数用户评价很高。这些信息是通过偏见获得的。</p></div><div class="ab cl op oq hx or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="im in io ip iq"><h1 id="2bea" class="kz la it bd lb lc ow le lf lg ox li lj lk oy lm ln lo oz lq lr ls pa lu lv lw bi translated">该模型的建议</h1><p id="80f4" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">现在，我们有了一个训练有素的模型，它已经为每个用户和电影学习了正确的嵌入和偏好。考虑这样一种情况，我们必须向用户推荐一组电影中的一部电影(假设该组中的所有电影都没有被该用户看到)。</p><p id="d2ef" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">使用计算出的嵌入和偏差，我们可以预测用户将对该组中的每部电影给出的评级。所建议的电影将是具有最高预测等级的电影。</p><p id="1256" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu"> <em class="np">预测评分=嵌入向量点积(用户、电影)+用户偏差+电影偏差</em> </strong></p></div><div class="ab cl op oq hx or" role="separator"><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou ov"/><span class="os bw bk ot ou"/></div><div class="im in io ip iq"><p id="61e9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><strong class="kd iu">链接到 excel 文件:</strong><a class="ae nc" href="https://github.com/shik3519/collaborative-filtering/blob/master/collab_filter.xlsx" rel="noopener ugc nofollow" target="_blank">https://github . com/shik 3519/collaborative-filtering/blob/master/collab _ filter . xlsx</a>。受此文件启发→[3]</p><h1 id="a24c" class="kz la it bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">结束注释</h1><p id="151b" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">这篇文章中讨论的方法肯定不是实现协同过滤的最佳方式。使用神经网络有更好的执行算法，但是嵌入的核心思想是共同的。</p><p id="e857" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">看看这篇文章，它讨论了神经网络的实现以及其他很多东西。</p><div class="nt nu gp gr nv nw"><a href="https://medium.com/@pgrover3/various-implementations-of-collaborative-filtering-100385c6dfe0" rel="noopener follow" target="_blank"><div class="nx ab fo"><div class="ny ab nz cl cj oa"><h2 class="bd iu gy z fp ob fr fs oc fu fw is bi translated">协同过滤的各种实现</h2><div class="od l"><h3 class="bd b gy z fp ob fr fs oc fu fw dk translated">利用协同过滤构建推荐系统的不同方法比较</h3></div><div class="oe l"><p class="bd b dl z fp ob fr fs oc fu fw dk translated">medium.com</p></div></div><div class="of l"><div class="og l oh oi oj of ok jz nw"/></div></div></a></div><h1 id="35a3" class="kz la it bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">接下来</h1><p id="11bc" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">在<a class="ae nc" rel="noopener" target="_blank" href="/collaborative-filtering-and-embeddings-part-2-919da17ecefb">的下一篇文章</a>中，我将讨论我们如何使用由<a class="pc pd ep" href="https://medium.com/u/34ab754f8c5e?source=post_page-----63b00b9739ce--------------------------------" rel="noopener" target="_blank">杰瑞米·霍华德</a> <strong class="kd iu"> </strong>等人开发的名为<a class="ae nc" href="https://github.com/fastai/fastai/tree/master/fastai" rel="noopener ugc nofollow" target="_blank"> <strong class="kd iu"> fastai </strong> </a>的库来实现协同过滤。这个库构建在<a class="ae nc" href="http://pytorch.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="kd iu"> pytorch </strong> </a>之上，专注于更容易实现的<strong class="kd iu">机器学习和深度学习模型</strong>。</p><p id="a787" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">此外，我们将了解如何使用<a class="ae nc" href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding" rel="noopener ugc nofollow" target="_blank"><strong class="kd iu">【t-SNE】</strong></a><strong class="kd iu"/><a class="ae nc" href="https://plot.ly/" rel="noopener ugc nofollow" target="_blank"><strong class="kd iu"/></a><strong class="kd iu">和</strong><a class="ae nc" href="https://bokeh.pydata.org/en/latest/" rel="noopener ugc nofollow" target="_blank"><strong class="kd iu">Bokeh</strong></a><strong class="kd iu"/>(<em class="np">Python 交互式可视化库，面向现代 web 浏览器进行演示</em>)。下面是一个什么在商店的预告。</p><figure class="ne nf ng nh gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi pe"><img src="../Images/43b351edc8519c20f7fe3edc7bd019d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KUFC9WfU9IVC28c467KdqQ.png"/></div></div></figure><p id="43c9" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated"><a class="ae nc" rel="noopener" target="_blank" href="/collaborative-filtering-and-embeddings-part-2-919da17ecefb"> <strong class="kd iu">【协同过滤与嵌入—第二部分</strong> </a></p><h1 id="5d7d" class="kz la it bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">更多资源</h1><div class="nt nu gp gr nv nw"><a href="https://medium.com/@apiltamang/learning-entity-embeddings-in-one-breath-b35da807b596" rel="noopener follow" target="_blank"><div class="nx ab fo"><div class="ny ab nz cl cj oa"><h2 class="bd iu gy z fp ob fr fs oc fu fw is bi translated">一口气学习实体嵌入</h2><div class="od l"><h3 class="bd b gy z fp ob fr fs oc fu fw dk translated">也许不会，除非你经常打破屏住呼吸的世界纪录！从好的方面来看，实体…</h3></div><div class="oe l"><p class="bd b dl z fp ob fr fs oc fu fw dk translated">medium.com</p></div></div><div class="of l"><div class="pf l oh oi oj of ok jz nw"/></div></div></a></div><div class="nt nu gp gr nv nw"><a rel="noopener follow" target="_blank" href="/structured-deep-learning-b8ca4138b848"><div class="nx ab fo"><div class="ny ab nz cl cj oa"><h2 class="bd iu gy z fp ob fr fs oc fu fw is bi translated">结构化深度学习</h2><div class="od l"><h3 class="bd b gy z fp ob fr fs oc fu fw dk translated">快的</h3></div><div class="oe l"><p class="bd b dl z fp ob fr fs oc fu fw dk translated">towardsdatascience.com</p></div></div><div class="of l"><div class="pg l oh oi oj of ok jz nw"/></div></div></a></div><div class="nt nu gp gr nv nw"><a href="http://course.fast.ai/lessons/lesson4.html" rel="noopener  ugc nofollow" target="_blank"><div class="nx ab fo"><div class="ny ab nz cl cj oa"><h2 class="bd iu gy z fp ob fr fs oc fu fw is bi translated">面向程序员的深度学习——36 小时免费课程</h2><div class="od l"><h3 class="bd b gy z fp ob fr fs oc fu fw dk translated">fast.ai 面向编码员的实用深度学习 MOOC。学习 CNN，RNNs，计算机视觉，NLP，推荐系统…</h3></div><div class="oe l"><p class="bd b dl z fp ob fr fs oc fu fw dk translated">course.fast.ai</p></div></div><div class="of l"><div class="ph l oh oi oj of ok jz nw"/></div></div></a></div><h1 id="0130" class="kz la it bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">参考</h1><p id="3478" class="pw-post-body-paragraph kb kc it kd b ke lx kg kh ki ly kk kl km lz ko kp kq ma ks kt ku mb kw kx ky im bi translated">[1]<a class="ae nc" href="https://commons.wikimedia.org/wiki/File%3ACollaborative_filtering.gif" rel="noopener ugc nofollow" target="_blank">https://commons . wikimedia . org/wiki/File % 3a collaborative _ filtering . gif</a></p><p id="d708" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">[2]<a class="ae nc" href="https://en.wikipedia.org/wiki/Collaborative_filtering" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Collaborative_filtering</a></p><p id="eb9f" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">[3]<a class="ae nc" href="https://github.com/fastai/fastai/blob/master/courses/dl1/excel/collab_filter.xlsx" rel="noopener ugc nofollow" target="_blank">https://github . com/fastai/fastai/blob/master/courses/dl1/excel/collab _ filter . xlsx</a></p><p id="0033" class="pw-post-body-paragraph kb kc it kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">[4]<a class="ae nc" href="http://www.wired.co.uk/article/how-do-netflixs-algorithms-work-machine-learning-helps-to-predict-what-viewers-will-like" rel="noopener ugc nofollow" target="_blank">http://www . wired . co . uk/article/how-do-netflixs-algorithms-work-machine-learning-helps-to-predict-what-viewers-will-like</a></p></div></div>    
</body>
</html>