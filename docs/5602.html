<html>
<head>
<title>Scaling up with Distributed Tensorflow on Spark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Spark 上分布张量流的放大</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/scaling-up-with-distributed-tensorflow-on-spark-afc3655d8f95?source=collection_archive---------7-----------------------#2018-10-29">https://towardsdatascience.com/scaling-up-with-distributed-tensorflow-on-spark-afc3655d8f95?source=collection_archive---------7-----------------------#2018-10-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/98e835adac456ab74c518b877dbb07b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YECeOxlko9KoOJNw8RNm3A.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk"><a class="ae kc" href="https://unsplash.com/photos/ZiQkhI7417A" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/photos/ZiQkhI7417A</a></figcaption></figure><p id="ad23" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您可能在过去经历过，或者可能在某个时候会经历，内存不足是数据科学中一个非常常见的问题。</p><p id="eff2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于业务涉及面广，创建包含超过 10，000 个或更多要素的数据集并不罕见。我们可以选择用树算法来处理这样的数据集。然而，Deeplearning 可以更容易地自动设计功能，并将它们处理成你选择的模型。</p><p id="d4eb" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一个经常出现的问题是，在处理如此大量的数据时，如何在适当的数量内训练您最喜欢的模型。</p><p id="307c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">结合 Tensorflow 和 Spark 的分布式深度学习为这个问题提供了一套便捷的解决方案。</p><h1 id="f5db" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated"><strong class="ak"> <em class="lz"> 1。简而言之分布式深度学习</em> </strong></h1><p id="1ebb" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">分布式深度学习的关键成分包括中央<strong class="kf ir"> <em class="mf">参数服务器</em> </strong>和<strong class="kf ir"> <em class="mf">工人</em> </strong>。</p><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/e35b40d8fec4aa9c21b3c5064820b863.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*691Sexy23zPn0Mv_T6pgBQ.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Fig 1: Illustration of Distributed Deeplearning from<a class="ae kc" href="http://joerihermans.com/ramblings/distributed-deep-learning-part-1-an-introduction/" rel="noopener ugc nofollow" target="_blank"> Joeri Hermans’thesis</a></figcaption></figure><p id="408e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">每个 Worker 被分配一个数据集的分区，也称为<strong class="kf ir"> <em class="mf"> shard、</em> </strong>和一个<strong class="kf ir"> <em class="mf">局部模型副本</em> </strong>。<strong class="kf ir"> <em class="mf"> </em> </strong>在数据集的这一部分上，每个工人应用常规的深度学习优化，例如 mini-batch，并计算梯度。在计算梯度时，工人<strong class="kf ir"> <em class="mf">将其结果</em> </strong>提交给中央<strong class="kf ir"> <em class="mf">参数服务器</em> </strong>。</p><p id="ed31" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在接收到来自所有工作者的所有提交之后，梯度被平均并且模型被更新。接下来<strong class="kf ir"> <em class="mf">允许工人拉动</em> </strong>模型的新参数化。</p><p id="8294" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">从这个框架中，出现了许多令人兴奋的数学问题，例如想知道这个过程是否可以异步进行？这将避免让工人等待来自参数服务器的每个新的更新。这种技术的缺点是工人可能用过时的模型参数处理数据。我推荐阅读<a class="ae kc" href="http://joerihermans.com/ramblings/distributed-deep-learning-part-1-an-introduction/" rel="noopener ugc nofollow" target="_blank">游里·赫曼的论文</a>来了解更多关于这个话题的细节。</p><h1 id="9982" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">2.分布式张量流来了</h1><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/6f4785ce8898fd290b54ea041ee9b2e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*bGSjTA9dsHkyfZrJ7IbGUw.png"/></div></figure><p id="c310" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Tensorflow 使用数据流图来表示各个操作之间的计算依赖关系。分布式张量流允许我们在不同的进程中计算图的部分，因此在不同的服务器上。</p><p id="965e" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">图 2 示出了分布式张量流设置，即张量流集群。</p><p id="e7e0" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在该集群中，可以找到多个组件，如第一部分所述。</p><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/c3d5a008844e7988979aa3bc1d11487f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7LFD1Bb5wQTmbY6zP3-xsQ.png"/></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Fig 2. Illustration of a distributed Tensorflow set-up on Google Cloud Platform (<a class="ae kc" href="https://cloud.google.com/architecture/running-distributed-tensorflow-on-compute-engine" rel="noopener ugc nofollow" target="_blank">https://cloud.google.com/architecture/running-distributed-tensorflow-on-compute-engine</a>)</figcaption></figure><p id="e44b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Tensorflow 提供集装箱管理器 Kubernetes 作为服务不同工作的主要选项。容器可以通过 Tensorflow 的协议缓冲区<strong class="kf ir"> tf.train.Example </strong>从输入管道接收数据。</p><p id="684d" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">就我个人而言，我已经开始喜欢 Tensorflow 的 dara 格式和数据集类<strong class="kf ir"> tf.data.Dataset </strong>，并开始喜欢上它。遗憾的是，Tensorflow 的数据预处理库还处于起步阶段。如果你像我一样，喜欢在通过任何神经架构之前创建大量的功能，你会寻找另一个专门从事 ETL 的分布式计算框架，比如 Spark。</p><p id="d33f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">火花来了…</p><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/8e34dd2c2ec7b8a9b3700ae441a6250c.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*Pa7PO1v7bANI7C-eHMS_PQ.png"/></div></figure><h1 id="15a6" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">3.火花拯救我们！</h1><p id="ea4a" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">Spark 的优化能力在于使用弹性分布式数据集，即<strong class="kf ir"> rdd </strong>。</p><p id="abec" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Yahoo 提供了一个开源存储库，它为您管理 workers 和 parameters 服务器，同时为您提供来自 rdd 的流数据的可能性。</p><p id="d29c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为此，我们需要使用包装器<strong class="kf ir"> TFCluster </strong>定义一个集群，如图所示</p><figure class="mh mi mj mk gt jr"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="f08c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您计划传递一个 rdd 来训练或生成预测，您需要将 input_mode 设置为<strong class="kf ir"> TFCluster。输入模式。火花。</strong></p><p id="e4d1" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用以下代码应用训练或推理:</p><figure class="mh mi mj mk gt jr"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="191b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一切都很好，现在仍然有两个关键问题需要回答:</p><ul class=""><li id="1374" class="mq mr iq kf b kg kh kk kl ko ms ks mt kw mu la mv mw mx my bi translated">我们应该在哪里传递我们的计算图，包含我们的神经网络？</li><li id="5593" class="mq mr iq kf b kg mz kk na ko nb ks nc kw nd la mv mw mx my bi translated">您应该从哪里提取数据批次？</li></ul><p id="3954" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">所有这些都是在一个 map-function 中定义的，您需要将它作为一个参数传递。</p><p id="84dc" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">包含主要成分的示例如下所示:</p><figure class="mh mi mj mk gt jr"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="65a4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如本文第一部分所述，集群中有两种类型的作业，参数服务器和 worker。</p><p id="bb16" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如前所述，您需要您的参数服务器不断地监听来自作品的可能的<strong class="kf ir"> <em class="mf">提交</em> </strong>。这是使用<strong class="kf ir"><em class="mf">server . join()</em></strong>方法完成的。这个方法告诉 TensorFlow 阻塞并监听请求，直到服务器关闭。</p><p id="41ae" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在 worker 中，可以在由<strong class="kf ir">TF . device(TF . train . replica _ device _ set(…))处理的上下文管理器中定义自己喜欢的计算图。</strong></p><figure class="mh mi mj mk gt jr"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="7525" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这一行确保参数服务器知道您的工人正在计算任何<strong class="kf ir"> tf 的梯度。你可能已经定义了变量</strong>。因此，它将聚合这些梯度，并在每次提交后发回更新。</p><p id="426b" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果你像我一样懒惰，你可能也使用<strong class="kf ir">TF . train . monitored training session</strong>来处理回调，比如保存/恢复你的模型，并最终计算训练的摘要。</p><figure class="mh mi mj mk gt jr"><div class="bz fp l di"><div class="mo mp l"/></div></figure><p id="fbd6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">您需要确保不是所有的员工都在处理这些子任务。建议定义一个所谓的<strong class="kf ir">首席工人</strong>，例如任务指数为 0 的工人。</p><p id="778c" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">rdd 上的<strong class="kf ir">流用<strong class="kf ir"> ctx.get_data_feed(…) </strong>调用。Spark 和 Tensorflow 的组合不是 100%最佳的。您可以根据<strong class="kf ir">TF . train . monitored training session</strong>中定义的一些条件，基于步骤或指标，选择终止应用程序。然而，Spark 不能提前终止 RDD 操作，所以多余的分区仍然会被发送给执行器。<strong class="kf ir"> tf_feed.terminated() </strong>是为了表示这些多余的分区被忽略。</strong></p><h1 id="ffaf" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">4.结论</h1><p id="df0c" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">在这篇博客中，我们学习了如何将 Spark 和 Tensorflow 结合起来，将弹性分布式数据帧分布在不同的作品上。我们还理解了参数服务器如何在每次提交 workers 之后不断更新变量。</p><p id="f291" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们希望这个博客对你有用，因为它对我们来说是一次很好的学习经历！</p><h1 id="fc9d" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">关于作者</h1><figure class="mh mi mj mk gt jr gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/7620cd703e6da8bc3e47845da14b0e5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*1zPE3zWqG0oiE12QrZ0sOg.png"/></div></figure><p id="d35a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://www.linkedin.com/in/xin-pang/" rel="noopener ugc nofollow" target="_blank">庞欣</a>是一名高级数据科学家，专攻 Spark，目前在一家最大的物流跨国公司应用她的技能。</p><p id="7f8a" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><a class="ae kc" href="https://www.linkedin.com/in/benoit-descamps-phd/" rel="noopener ugc nofollow" target="_blank"> Benoit Descamps </a>是一名独立的人工智能顾问，对数学和软件工程充满热情。如果您对集成最新的机器学习解决方案有任何疑问，请直说！</p><h1 id="409c" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">更多精彩内容！</h1><p id="d75f" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">@ <a class="ae kc" href="https://medium.com/@pang.xin/spark-study-notes-core-concepts-visualized-5256c44e4090" rel="noopener"> Spark 研究笔记:核心概念可视化</a></p><p id="534f" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">@ <a class="ae kc" href="https://medium.com/machine-learning-rambling/tuning-hyperparameters-part-i-successivehalving-c6c602865619" rel="noopener">调整超参数(第一部分):成功减半</a></p><p id="4ca6" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">@<a class="ae kc" href="https://www.kdnuggets.com/2018/01/custom-optimizer-tensorflow.html" rel="noopener ugc nofollow" target="_blank">tensor flow 中的自定义优化器</a></p><p id="e9b5" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">@<a class="ae kc" href="https://medium.com/bigdatarepublic/regression-prediction-intervals-with-xgboost-428e0a018b" rel="noopener">XG boost 回归预测区间</a></p><h1 id="6b50" class="lb lc iq bd ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly bi translated">参考</h1><p id="e12b" class="pw-post-body-paragraph kd ke iq kf b kg ma ki kj kk mb km kn ko mc kq kr ks md ku kv kw me ky kz la ij bi translated">[1] <a class="ae kc" href="http://joerihermans.com/ramblings/distributed-deep-learning-part-1-an-introduction/" rel="noopener ugc nofollow" target="_blank">关于分布式深度学习的来龙去脉的有见地的技术讨论</a> <a class="ae kc" href="http://joerihermans.com/ramblings/distributed-deep-learning-part-1-an-introduction/" rel="noopener ugc nofollow" target="_blank"> n/ </a></p><p id="9cb4" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[2] <a class="ae kc" href="https://github.com/tmulc18/Distributed-TensorFlow-Guide" rel="noopener ugc nofollow" target="_blank">分布式张量流导</a></p><p id="5bd7" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[3] <a class="ae kc" href="http://amid.fish/distributed-tensorflow-a-gentle-introduction" rel="noopener ugc nofollow" target="_blank">分布式张量流简介</a></p><p id="fdf2" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[4] <a class="ae kc" href="http://TensorFlow Dev Summit 2017" rel="noopener ugc nofollow" target="_blank">分布式 Tenforflow @ Tensorflow 发展峰会(2017) </a></p><p id="b796" class="pw-post-body-paragraph kd ke iq kf b kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">[5] <a class="ae kc" href="https://github.com/yahoo/TensorFlowOnSpark" rel="noopener ugc nofollow" target="_blank">雅虎在 Spark 上的分布式张量流</a></p></div></div>    
</body>
</html>