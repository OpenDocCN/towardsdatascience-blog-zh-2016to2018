<html>
<head>
<title>Grid Search for model tuning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">模型调整的网格搜索</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/grid-search-for-model-tuning-3319b259367e?source=collection_archive---------0-----------------------#2018-12-29">https://towardsdatascience.com/grid-search-for-model-tuning-3319b259367e?source=collection_archive---------0-----------------------#2018-12-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/45e9f9207ad0e10f7fe27664afd2dedb.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/0*I0Uf79WuTauqKCMr.gif"/></div></figure><p id="0cd0" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">模型<strong class="jw ir"> <em class="ks">超参数</em> </strong>是模型外部的模型特征，其值无法从数据中估计。必须在学习过程开始之前设置超参数的值。比如支持向量机中的<em class="ks"> c </em>，k-最近邻中的<em class="ks"> k </em>，神经网络中的<em class="ks">隐层数</em>。</p><p id="68b2" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">相反，<strong class="jw ir"> <em class="ks">参数</em> </strong>是模型的内部特性，其值可以从数据中估计。例如，线性/逻辑回归的β系数或支持向量机中的支持向量。</p><blockquote class="kt ku kv"><p id="f924" class="ju jv ks jw b jx jy jz ka kb kc kd ke kw kg kh ki kx kk kl km ky ko kp kq kr ij bi translated">网格搜索用于寻找模型的最佳<em class="iq">超参数</em>，从而产生最“准确”的预测。</p></blockquote><p id="9c51" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">让我们通过在<a class="ae kz" href="https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)" rel="noopener ugc nofollow" target="_blank">乳腺癌数据集</a>上建立分类模型来看看网格搜索。</p><h2 id="a9d6" class="la lb iq bd lc ld le dn lf lg lh dp li kf lj lk ll kj lm ln lo kn lp lq lr ls bi translated">1.导入数据集并查看前 10 行。</h2><figure class="lt lu lv lw gt jr"><div class="bz fp l di"><div class="lx ly l"/></div></figure><p id="33ea" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">输出:</p><figure class="lt lu lv lw gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi lz"><img src="../Images/2617af54a623a0f8e7556a6361600da8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BOv1Lyof38x-XDiStnEuqw.png"/></div></div></figure><p id="57ec" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">数据集中的每一行都有两个可能的类别:良性(用 2 表示)和恶性(用 4 表示)。此外，该数据集中有 10 个属性(如上所示)将用于预测，除了作为 id 号的样本代码号。</p><h2 id="88d4" class="la lb iq bd lc ld le dn lf lg lh dp li kf lj lk ll kj lm ln lo kn lp lq lr ls bi translated">2.清理数据，并将类值重命名为 0/1，用于建模(其中 1 表示恶性病例)。还有，我们来观察一下班级的分布。</h2><figure class="lt lu lv lw gt jr"><div class="bz fp l di"><div class="lx ly l"/></div></figure><p id="9505" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">输出:</p><figure class="lt lu lv lw gt jr gh gi paragraph-image"><div class="gh gi me"><img src="../Images/6510b2ac1982f09981e9cc7c0dd32c2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/1*KCN_U0V3Joe-4D30egl9hQ.png"/></div></figure><p id="ac97" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">良性病例 444 例，恶性病例 239 例。</p><h2 id="d641" class="la lb iq bd lc ld le dn lf lg lh dp li kf lj lk ll kj lm ln lo kn lp lq lr ls bi translated">3.在构建分类模型之前，让我们构建一个虚拟分类器来确定“基线”性能。这就回答了这个问题——“如果只是猜测，这个模型的成功率会是多少？”我们使用的虚拟分类器将简单地预测多数类。</h2><figure class="lt lu lv lw gt jr"><div class="bz fp l di"><div class="lx ly l"/></div></figure><p id="ff8c" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">输出:</p><figure class="lt lu lv lw gt jr gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/6f5b07f9f7d236b0b7b13dce87c13c86.png" data-original-src="https://miro.medium.com/v2/resize:fit:228/format:webp/1*RT1Vo49y8TJnRG9OKOh4eQ.png"/></div></figure><figure class="lt lu lv lw gt jr gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/81822a4c7bb5306535d1852c4f61f27d.png" data-original-src="https://miro.medium.com/v2/resize:fit:304/format:webp/1*usB1eswDcyW4-M98qm41gg.png"/></div></figure><p id="7da9" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">从输出中，我们可以观察到测试数据集中有 68 个恶性和 103 个良性案例。然而，我们的分类器预测所有病例都是良性的(因为它是多数类)。</p><h2 id="2221" class="la lb iq bd lc ld le dn lf lg lh dp li kf lj lk ll kj lm ln lo kn lp lq lr ls bi translated">4.计算此模型的评估指标。</h2><figure class="lt lu lv lw gt jr"><div class="bz fp l di"><div class="lx ly l"/></div></figure><p id="7aec" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">输出:</p><figure class="lt lu lv lw gt jr gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/60cbbc562470299d6da26df42711ee68.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*2y_TJr60p8vOf7joHmYy-A.png"/></div></figure><figure class="lt lu lv lw gt jr gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/2e8446400c32a6b45234651fb64123c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:410/format:webp/1*XhCkzVs9cVM3fq2HrxNmdA.png"/></div></figure><p id="6ee9" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">模型的准确性为 60.2%，但这是准确性可能不是评估模型的最佳度量的情况。那么，让我们来看看其他评估指标。</p><figure class="lt lu lv lw gt jr gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/a9230f4c6cf5bdf87d37733f666cb3f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*zxYAjp_e2Fp7pFAv1tkBLw.png"/></div></figure><p id="7a34" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">上图是混淆矩阵，添加了标签和颜色以便更直观(生成该矩阵的代码可以在<a class="ae kz" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py" rel="noopener ugc nofollow" target="_blank">这里</a>找到)。总结一下混淆矩阵:真阳性(TP)= 0，真阴性(TN)= 103，假阳性(FP)= 0，假阴性(FN)= 68。评估指标的公式如下:</p><figure class="lt lu lv lw gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="gh gi mk"><img src="../Images/3f509676db7f402fc0e8914ed77f33f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fPk7uc0KflLMkv47oaB5Mg.png"/></div></div></figure><p id="9991" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">由于该模型没有对任何恶性病例进行正确分类，因此召回率和精确度指标为 0。</p><h2 id="8f0e" class="la lb iq bd lc ld le dn lf lg lh dp li kf lj lk ll kj lm ln lo kn lp lq lr ls bi translated">5.现在我们已经有了基线精度，让我们用默认参数建立一个逻辑回归模型并评估这个模型。</h2><figure class="lt lu lv lw gt jr"><div class="bz fp l di"><div class="lx ly l"/></div></figure><p id="cd0b" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">输出:</p><figure class="lt lu lv lw gt jr gh gi paragraph-image"><div class="gh gi ml"><img src="../Images/ff446850b16c4d26a231163b29540327.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*ycgXKS4VsiFbepDgoTE3aQ.png"/></div></figure><figure class="lt lu lv lw gt jr gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/e5ecb205afa83a817e662a16cc8ec208.png" data-original-src="https://miro.medium.com/v2/resize:fit:420/format:webp/1*4RiY-CFCpVZijaUyi2saRw.png"/></div></figure><p id="a0c1" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">通过用默认参数拟合逻辑回归模型，我们得到了一个“更好”的模型。准确率为 94.7%，同时精度更是惊人的 98.3%。现在，让我们再次看一下该模型结果的混淆矩阵:</p><figure class="lt lu lv lw gt jr gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/2d0a04983c8c73c5b652c9a5b9585b1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*dbBOgZ4hDiP296JaoBerFg.png"/></div></figure><p id="86e2" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">查看错误分类的实例，我们可以观察到<strong class="jw ir"> <em class="ks"> 8 个恶性病例被错误地分类为良性(假阴性)</em> </strong>。此外，只有一个良性病例被归类为恶性(假阳性)。</p><p id="d4c7" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">假阴性更严重，因为疾病被忽略了，这可能导致患者死亡。同时，假阳性会导致不必要的治疗——产生额外的费用。</p><p id="a5c7" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">让我们通过使用网格搜索来寻找最佳参数，从而尽量减少假阴性。网格搜索可用于改进任何特定的评估指标。</p><blockquote class="kt ku kv"><p id="2eb7" class="ju jv ks jw b jx jy jz ka kb kc kd ke kw kg kh ki kx kk kl km ky ko kp kq kr ij bi translated">我们需要关注的减少假阴性的指标是<strong class="jw ir">召回</strong>。</p></blockquote><h2 id="43ee" class="la lb iq bd lc ld le dn lf lg lh dp li kf lj lk ll kj lm ln lo kn lp lq lr ls bi translated">6.网格搜索最大化回忆</h2><figure class="lt lu lv lw gt jr"><div class="bz fp l di"><div class="lx ly l"/></div></figure><p id="76a6" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">输出:</p><figure class="lt lu lv lw gt jr gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/6299cbe2715d3afb8168484374fd2f6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*-73SS3zB51ixv8FvVgw6mA.png"/></div></figure><figure class="lt lu lv lw gt jr gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/7722689fa218bc199be97efcd8d1166e.png" data-original-src="https://miro.medium.com/v2/resize:fit:420/format:webp/1*eBL6uoCmwOUMEk-SHRAzSw.png"/></div></figure><p id="b472" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">我们调整的超参数是:</p><ol class=""><li id="f2b7" class="mp mq iq jw b jx jy kb kc kf mr kj ms kn mt kr mu mv mw mx bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/l1-and-l2-regularization-methods-ce25e7fc831c">惩罚</a> : l1 或 l2，指定惩罚中使用的标准。</li><li id="a8c5" class="mp mq iq jw b jx my kb mz kf na kj nb kn nc kr mu mv mw mx bi translated"><a class="ae kz" href="https://stackoverflow.com/questions/22851316/what-is-the-inverse-of-regularization-strength-in-logistic-regression-how-shoul" rel="noopener ugc nofollow" target="_blank"> C </a>:正则化强度的倒数——C 值越小，正则化越强。</li></ol><p id="8df9" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">此外，在网格搜索功能中，我们有一个评分参数，可以指定评估模型的指标(我们选择了 recall 作为指标)。从下面的混淆矩阵中，我们可以看到假阴性的数量减少了，然而，这是以假阳性增加为代价的。网格搜索后的召回率从 88.2%上升到 91.1%，而准确率从 98.3%下降到 87.3%。</p><figure class="lt lu lv lw gt jr gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/e0d0b62dcb244688fdf5fd35faad630d.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*JLIKCMC2HhAHhqHxNsi1Lg.png"/></div></figure><p id="5718" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">通过使用“f1”分数作为评估指标，您可以进一步调整模型，以在精确度和召回率之间取得平衡。查看这篇<a class="ae kz" rel="noopener" target="_blank" href="/beyond-accuracy-precision-and-recall-3da06bea9f6c">文章</a>，更好地理解评估指标。</p><p id="22a3" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">网格搜索为指定的每个超参数组合建立一个模型，并评估每个模型。一种更有效的超参数调整技术是随机搜索，其中超参数的随机组合用于寻找最佳解决方案。</p></div><div class="ab cl ne nf hu ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="ij ik il im in"><p id="3d93" class="pw-post-body-paragraph ju jv iq jw b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ij bi translated">连接 LinkedIn<a class="ae kz" href="https://www.linkedin.com/feed/" rel="noopener ugc nofollow" target="_blank">和 Github</a>查看完整的笔记本。</p><div class="nl nm gp gr nn no"><a href="https://github.com/rohanjoseph93/Python-for-data-science/blob/master/Grid%20Search%20-%20Breast%20Cancer.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="np ab fo"><div class="nq ab nr cl cj ns"><h2 class="bd ir gy z fp nt fr fs nu fu fw ip bi translated">rohanjoseph 93/用于数据科学的 Python</h2><div class="nv l"><h3 class="bd b gy z fp nt fr fs nu fu fw dk translated">用 Python 学习数据科学。通过创建帐户，为 rohanjoseph 93/Python-for-data-science 开发做出贡献…</h3></div><div class="nw l"><p class="bd b dl z fp nt fr fs nu fu fw dk translated">github.com</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc js no"/></div></div></a></div></div></div>    
</body>
</html>