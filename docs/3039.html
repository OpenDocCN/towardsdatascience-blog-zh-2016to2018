<html>
<head>
<title>Diabetes Prediction — Artificial Neural Network Experimentation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">糖尿病预测——人工神经网络实验</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/diabetes-prediction-artificial-neural-network-experimentation-f4267796443d?source=collection_archive---------5-----------------------#2018-04-02">https://towardsdatascience.com/diabetes-prediction-artificial-neural-network-experimentation-f4267796443d?source=collection_archive---------5-----------------------#2018-04-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="06d5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为一名数据科学专业人员，我们倾向于学习所有可用的技术来处理我们的数据，并从中推导出有意义的见解。在本文中，我描述了我用神经网络架构对数据进行探索性分析的实验。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/f47126f512da9377b1029284fc76dcf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j7LpJS4q5sW6On_OVPVQnA.jpeg"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Source : <a class="ae lb" href="http://legacymedsearch.com/medicine-going-digital-fda-racing-catch/" rel="noopener ugc nofollow" target="_blank">http://legacymedsearch.com/medicine-going-digital-fda-racing-catch/</a></figcaption></figure><p id="133c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里是到我的代码库的<a class="ae lb" href="https://github.com/bmonikraj/neural-network-sklearn" rel="noopener ugc nofollow" target="_blank"> github 链接</a>，我已经用它进行了探索性的数据分析，所有的架构设计都在本文中提到。我使用过 Python 3.6 以及 Pandas、Numpy 和 Keras(tensor flow 上的后端)模块。</p><div class="lc ld gp gr le lf"><a href="https://github.com/bmonikraj/neural-network-sklearn" rel="noopener  ugc nofollow" target="_blank"><div class="lg ab fo"><div class="lh ab li cl cj lj"><h2 class="bd ir gy z fp lk fr fs ll fu fw ip bi translated">bmonikraj/神经网络-sklearn</h2><div class="lm l"><h3 class="bd b gy z fp lk fr fs ll fu fw dk translated">神经网络-sklearn -神经网络在 pima 印度糖尿病数据集上的实现</h3></div><div class="ln l"><p class="bd b dl z fp lk fr fs ll fu fw dk translated">github.com</p></div></div><div class="lo l"><div class="lp l lq lr ls lo lt kv lf"/></div></div></a></div></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><p id="f41d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是我用于探索性数据分析的数据集的链接，来自<a class="ae lb" href="https://www.kaggle.com/uciml/pima-indians-diabetes-database/data" rel="noopener ugc nofollow" target="_blank"> Kaggle 网站</a>。链接中提到了列的数据描述和元数据。</p><pre class="km kn ko kp gt mb mc md me aw mf bi"><span id="c742" class="mg mh iq mc b gy mi mj l mk ml">Number of Observations : 768<br/>Number of Features : 8<br/>Input Neurons : 8<br/>Output Neurons : 2 (Diabetic and Non-diabetic)<br/>Test Data size : 20%<br/>Train Data size : 80%</span></pre><div class="lc ld gp gr le lf"><a href="https://www.kaggle.com/uciml/pima-indians-diabetes-database/data" rel="noopener  ugc nofollow" target="_blank"><div class="lg ab fo"><div class="lh ab li cl cj lj"><h2 class="bd ir gy z fp lk fr fs ll fu fw ip bi translated">皮马印第安人糖尿病数据库</h2><div class="lm l"><h3 class="bd b gy z fp lk fr fs ll fu fw dk translated">基于诊断方法预测糖尿病的发病</h3></div><div class="ln l"><p class="bd b dl z fp lk fr fs ll fu fw dk translated">www.kaggle.com</p></div></div><div class="lo l"><div class="mm l lq lr ls lo lt kv lf"/></div></div></a></div></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><p id="362a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我创建了<a class="ae lb" href="http://www.statisticssolutions.com/correlation-pearson-kendall-spearman/" rel="noopener ugc nofollow" target="_blank"> <strong class="jp ir">关联矩阵</strong> </a> <strong class="jp ir"> </strong>，并使用<em class="mn"> Seaborn </em>模块绘制了热图和 pairs 图(数据集的每两个特征之间的图),用于数据可视化。通过相互比较，关联图给出了关于特性依赖性的概念。相关性是任何数据集的<a class="ae lb" href="https://en.wikipedia.org/wiki/Bivariate_analysis" rel="noopener ugc nofollow" target="_blank">双变量分析</a>的一部分。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/62f7a98bc71dd5ba52fad4135d755814.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*cS7Mu9YNjAcGOSmtykoJxg.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Correlation Matrix</figcaption></figure><p id="5e41" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">下面是描述每个特征之间的二元图的配对图，也显示了每个特征的<a class="ae lb" href="http://asq.org/learn-about-quality/data-collection-analysis-tools/overview/histogram.html" rel="noopener ugc nofollow" target="_blank">直方图</a>。<em class="mn">单元格[i，i]显示直方图，其中 I 是第 I 行/列。</em></p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mp"><img src="../Images/622f945a2a3df6694bdb607073ac7980.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oaxTTbQv8EdXCxIFO380vw.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Pair Plot and Histogram of the dataset (Only X)</figcaption></figure><p id="32f4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从上面的直方图可以得出一个推论，很少有<strong class="jp ir">特征遵循标准或已知的分布，如高斯、瑞利等，这从图</strong>的形状可以明显看出。如果需要，这种假设在建立预测模型时会很方便，因为我们已经知道(或至少假设)了数据的分布及其数学公式。</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/e579a4705cc40168fb42a199a36dda96.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*Yl1WnnMwDQPlf-HwWOTnWA.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Correlation Matrix including the target (Outcome) value</figcaption></figure><p id="8c52" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">从上面的情节可以得出<em class="mn">(因为相关分数高)</em><em class="mn">【结果-葡萄糖】</em>对和<em class="mn">【结果-身体质量指数】</em>对是最相互依赖的。所以密谋与<a class="ae lb" href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient" rel="noopener ugc nofollow" target="_blank">培生<strong class="jp ir">联合密谋</strong>培生</a>会关注他们的行为。从下面可以看出，Outcome (Target)只有两种可能的结果。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mq"><img src="../Images/b8bd39d55e886ea0afa52d844f5a2ced.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*dGOpIn1K9ADOEK9LTUXETQ.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Outcome — Glucose (Pearson Correlation)</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mq"><img src="../Images/64174f1f3d86b4c78243d7a974fde47e.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/format:webp/1*cPZtagIus4LVIVJchYDHSg.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Outcome — BMI (Pearson Correlation)</figcaption></figure><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/4e67d7650edfa3a585b3208bb8f13733.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*b0GGqfJcgU7LmWNI9pp4jQ.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Glucose — BMI (Pearson Correlation)</figcaption></figure><p id="b6f2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">根据第一个皮尔逊相关图，显然<em class="mn">‘葡萄糖’</em>与结果高度相关，这使得<em class="mn">‘葡萄糖’</em>成为最重要的特征。</p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><p id="9500" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在这是最有趣的部分，实验神经网络的各种可能的架构。在深入这个问题之前，我想指出关于架构决策的几个关键点。</p><ol class=""><li id="512d" class="ms mt iq jp b jq jr ju jv jy mu kc mv kg mw kk mx my mz na bi translated">输入神经元数量=<em class="mn">中的特征数量 X </em></li><li id="1a31" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">输出神经元数量=目标中的类别数量</li><li id="8269" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">#隐藏层&gt; 0</li><li id="0506" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">隐藏层中的神经元数 1 ~ #隐藏层中的神经元数 2 ~ #隐藏层中的神经元数 3 …隐藏层中的神经元数量<em class="mn">(如果架构有 N 个隐藏层)</em></li><li id="8610" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">隐藏层中的神经元数量~ #输入神经元| #隐藏层中的神经元数量~ 2 X #输入神经元</li><li id="8179" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">权重必须随机初始化</li></ol></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><p id="4232" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><a class="ae lb" href="https://www.tutorialspoint.com/artificial_intelligence/artificial_intelligence_neural_networks.htm" rel="noopener ugc nofollow" target="_blank">人工神经网络</a>是最流行的机器学习算法之一，广泛应用于预测建模和构建分类器。目前，许多先进的神经网络模型，如卷积神经网络、深度学习模型，在计算机视觉、网络安全、人工智能、机器人应用、医疗保健和许多更先进的技术领域中很受欢迎。</p><p id="4723" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">驱使数据科学家使用人工神经网络的几个令人兴奋的事实是</p><ul class=""><li id="0e31" class="ms mt iq jp b jq jr ju jv jy mu kc mv kg mw kk ng my mz na bi translated">适应并训练自己处理复杂的非线性问题。</li><li id="4b32" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk ng my mz na bi translated">灵活应对各种问题集。</li><li id="5f14" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk ng my mz na bi translated">从根本上兼容实时学习(在线学习)。</li><li id="7bbd" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk ng my mz na bi translated">在大多数情况下，构建人工神经网络需要大量的数据和快速的 GPU 来进行计算</li></ul></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><blockquote class="nh ni nj"><p id="07cc" class="jn jo mn jp b jq jr js jt ju jv jw jx nk jz ka kb nl kd ke kf nm kh ki kj kk ij bi translated">在这个程序中，在使用的每个架构中，输出层都由'<a class="ae lb" href="https://en.wikipedia.org/wiki/Softmax_function" rel="noopener ugc nofollow" target="_blank"> softmax </a>'激活函数激活。中间层由'<a class="ae lb" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" rel="noopener ugc nofollow" target="_blank"> relu </a>激活功能激活。</p><p id="959e" class="jn jo mn jp b jq jr js jt ju jv jw jx nk jz ka kb nl kd ke kf nm kh ki kj kk ij bi translated">由于这是一个探索性的数据分析，所以所有的指标和图表都受制于这个特定的问题集。</p></blockquote><h2 id="d33b" class="mg mh iq bd nn no np dn nq nr ns dp nt jy nu nv nw kc nx ny nz kg oa ob oc od bi translated">单一隐藏层架构</h2><figure class="km kn ko kp gt kq gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/2a43f7a41e5df232d973e701ca820e25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qVgFO1ezNrTb6LYndRrUlg.png"/></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Single Layer Architecture — Accuracy vs Neurons in Hidden Layer</figcaption></figure><p id="47d2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们的问题中，对于隐藏层中任意数量的神经元(基于上图的强假设),应用单层架构产生了 64.28% 的饱和精度。</p><h2 id="9feb" class="mg mh iq bd nn no np dn nq nr ns dp nt jy nu nv nw kc nx ny nz kg oa ob oc od bi translated">两个隐藏层架构</h2><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi of"><img src="../Images/554bb6f6a1f23a4659430a5e078106e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cHp_SKCknqkU9dHAw8Tohw.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Two hidden layer architecture — X-axis : Neurons in first hidden layer, Y-axis: Nuerons in second hidden layer, Z-axis: Accuracy</figcaption></figure><p id="4090" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在两个隐藏层架构的情况下，观察到类似的行为，其中准确度总是饱和到<strong class="jp ir"> 64.28%。</strong></p><h2 id="145d" class="mg mh iq bd nn no np dn nq nr ns dp nt jy nu nv nw kc nx ny nz kg oa ob oc od bi translated">多重隐藏层架构</h2><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi of"><img src="../Images/a9f52bb37f9b07c8e2331c692d2d432a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aHZ61cvGm92Cnynp_-e5jA.png"/></div></div><figcaption class="kx ky gj gh gi kz la bd b be z dk">Performance of classifier based on increasing hidden layers</figcaption></figure></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><p id="6616" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">既然我们正在讨论用神经网络进行探索性数据分析，我想提出几个需要记住的要点</p><ul class=""><li id="dac1" class="ms mt iq jp b jq jr ju jv jy mu kc mv kg mw kk ng my mz na bi translated">激活函数的选择在很大程度上影响性能。基于实验、目标类型和我们正在处理的数据选择激活函数的明智决定很重要。</li><li id="161b" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk ng my mz na bi translated">隐藏层中神经元的数量应该与输入神经元的数量相似。如果神经元的数量足够多，这可能会提高性能，但也可能会增加复杂性。为此要保持一种折衷。</li><li id="6d5e" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk ng my mz na bi translated">使用带有反向传播的动量可以帮助收敛解，并实现全局最优。</li><li id="9ef2" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk ng my mz na bi translated">在决定隐藏层的架构时，尝试不同的架构会有所帮助，因为每个数据集在不同的架构下可能会有不同的表现。</li><li id="3559" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk ng my mz na bi translated">数据的大小很重要，所以尽量相应地选择数据大小。越大越好！</li><li id="26c0" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk ng my mz na bi translated">当网络从零开始构建时，网络权重的随机初始化是强制性的(没有像初始模型那样预先训练的权重)。</li></ul></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><p id="ca5b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在神经网络之后，我应用了一些其他算法来测试数据集和性能。结果是这样的</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi og"><img src="../Images/f02fb8954de12b190ba99437710aabdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F7O3_qYVTejpSYL2ZBIP1g.png"/></div></div></figure></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="66e0" class="oh mh iq bd nn oi oj ok nq ol om on nt oo op oq nw or os ot nz ou ov ow oc ox bi translated">关键要点</h1><p id="6f9f" class="pw-post-body-paragraph jn jo iq jp b jq oy js jt ju oz jw jx jy pa ka kb kc pb ke kf kg pc ki kj kk ij bi translated">在每一个现实世界的问题中，构建以解决方案为中心的模型的第一步是执行探索性的数据分析。这将为问题建立合适的模型，该模型可进一步用于调整性能和有效地解决问题。</p><p id="fd5f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">人工神经网络的探索性数据分析处理隐藏层和激活函数。先进的大数据问题、基于图像的问题和许多其他复杂问题现在都可以用卷积神经网络来解决<strong class="jp ir"> (CNN) </strong>。深度学习已经被广泛用于许多复杂的研究问题，因为它能够从大数据中获得洞察力，在许多情况下跳过数据特征提取的过程<em class="mn"> (CNN 可以直接对图像进行处理，无需任何特征提取)。计算机视觉应用中的 CNN 的另一个好处是保持图像的空间属性完整，这对于许多基于几何的计算和推理非常有用。</em></p></div><div class="ab cl lu lv hu lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ij ik il im in"><h1 id="d49f" class="oh mh iq bd nn oi oj ok nq ol om on nt oo op oq nw or os ot nz ou ov ow oc ox bi translated">参考</h1><ol class=""><li id="e249" class="ms mt iq jp b jq oy ju oz jy pd kc pe kg pf kk mx my mz na bi translated">探索性数据分析—<a class="ae lb" href="https://www.kaggle.com/etakla/exploring-the-dataset-bivariate-analysis" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/etakla/exploring-the-dataset-bivariable-Analysis</a></li><li id="67d0" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">https://keras.io/</li><li id="dc0c" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">熊猫—【https://pandas.pydata.org/ T2】</li><li id="acac" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">https://seaborn.pydata.org/<a class="ae lb" href="https://seaborn.pydata.org/" rel="noopener ugc nofollow" target="_blank"/></li><li id="1805" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">皮尔逊相关性—<a class="ae lb" href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Pearson _ Correlation _ coefficient</a></li><li id="1f35" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">人工神经网络—<a class="ae lb" href="https://www.tutorialspoint.com/artificial_intelligence/artificial_intelligence_neural_networks.htm" rel="noopener ugc nofollow" target="_blank">https://www . tutorialspoint . com/artificial _ intelligence/artificial _ intelligence _ Neural _ networks . htm</a></li></ol></div></div>    
</body>
</html>