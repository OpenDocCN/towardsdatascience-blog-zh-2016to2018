<html>
<head>
<title>How to Predict Severe Traffic Jams with Python and Recurrent Neural Networks?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用 Python 和递归神经网络预测严重堵车？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-predict-severe-traffic-jams-with-python-and-recurrent-neural-networks-e53b6d411e8d?source=collection_archive---------9-----------------------#2018-12-13">https://towardsdatascience.com/how-to-predict-severe-traffic-jams-with-python-and-recurrent-neural-networks-e53b6d411e8d?source=collection_archive---------9-----------------------#2018-12-13</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="3700" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">利用 Python 和 Keras 实现序列模型在交通事件 Waze 开放数据挖掘中的应用。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f6a499d7d2fcbb1e3c569fa8cf3ef752.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W-J6fn-uP-ac7HThmwrFLw.jpeg"/></div></div></figure><p id="a662" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在本教程中，我将向您展示如何使用 RNN 深度学习模型从事件报告的 Waze 交通开放数据中发现模式，并预测严重的交通堵塞是否会很快发生。干预是可以有效取出的。</p><h1 id="0179" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">竞争</h1><p id="3025" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">2018 年 12 月 1 日，我在德克萨斯州弗里斯科的 UNT 灵感公园参加了一场黑客马拉松编程比赛。黑客马拉松被称为“HackNTX”。</p><p id="3cc2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">黑客马拉松从早上 8 点开始，到晚上 9 点结束。参与者可以自由地吃零食和水果，在院子里散步，呼吸新鲜空气，晒晒太阳。此外，人们可以自由地交谈、讨论和组建团队(每个团队不超过 5 人)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/95fcd30d3a46565eaa7637a4c5905fc1.png" data-original-src="https://miro.medium.com/v2/format:webp/1*rGBTf6TNIsxLWxfP7INR5A.png"/></div></figure><p id="428f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">主持人向参赛者提供了各种开放数据集，以及一些预定义的演示问题。你可以选择自己的新问题，在竞赛中解决。</p><p id="c8e2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Waze 数据是提供的数据集之一。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/ab97bcbb6779d1ccebcc3762351dc97b.png" data-original-src="https://miro.medium.com/v2/format:webp/1*-asboDP8UJ-gZkr590rQmg.jpeg"/></div></figure><p id="66bc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在国内，我从来不用 Waze App 导航。对我来说是新的。</p><p id="83f4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我谷歌了一下，发现了 Waze 的特征。它不仅可以为用户提供普通的导航功能，还可以让用户报告交通事件，以便其他用户可以相应地调整他们的路线。</p><p id="10d8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对我来说，最重要的特点是，当你被困在交通堵塞时，你可以准确地知道前面发生了什么，如道路施工，或车祸。在这种情况下，你将能够有一个更好的估计，冷静下来。这对你的健康有好处。</p><p id="e9b2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从几年前开始，Waze 与政府合作，开始共享数据。对于政府来说，他们可以从即时的交通状况报告中受益，并及时对事件做出响应。对于 Waze 平台来说，它可以整合政府开放的数据，如道路规划，以改善其路由功能，让用户更快乐。</p><p id="e7f4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">HackNTX 的主办方提供的 Waze 数据是关于 DFW 地区从 11 月 1 日到 11 月 29 日的交通事件。</p><p id="7c63" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">原始数据为 TSV 格式，总大小约为 300 兆字节。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/42a870fa03b39e25a2dea2bef7c4ada1.png" data-original-src="https://miro.medium.com/v2/format:webp/1*-dTaqme-iv4DIbvSG42I7Q.jpeg"/></div></figure><p id="5448" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">每行代表一个事件报告，包含坐标和时间戳。</p><p id="bbce" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在探索性数据分析阶段，我根据数据进行了几次可视化。</p><p id="7d38" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">第一次听说 QGIS，软件很强大。谢谢杰西教我如何使用它！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/a82c76de08192e7652c2778247d56d63.png" data-original-src="https://miro.medium.com/v2/format:webp/1*9j554-0lMXn6-SzGVgPn2w.png"/></div></figure><p id="8732" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在上面的截图中，你可以看到每个点代表一个事件。他们人太多了！</p><p id="9306" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">由于我对 QGIS 不太熟悉，Jesse 在下午早些时候离开了比赛，我不得不回去使用 Python 进行详细的可视化。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/0c89c759b13434ed33a39352f4818e19.png" data-original-src="https://miro.medium.com/v2/format:webp/1*_smxAZ4KGaJpFdu5Exw1nA.png"/></div></figure><p id="5d4d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">上图是用 Python 的 Geopandas 包制作的。它显示了三种不同类型的交通事件，即交通堵塞(红色)、事故(黄色)和“路肩停车”(蓝色)。请注意，它们仅从数据集中的前 3000 行中提取。</p><p id="af9e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">正如你可能已经发现的，红点的数量(意味着交通堵塞)是巨大的。交通堵塞确实是一个大问题。</p><p id="40b7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我从数据中提取了所有独特的事件类型，得到了以下列表:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/214063908511e358e574133b4db8f9e5.png" data-original-src="https://miro.medium.com/v2/format:webp/1*1Vf6T9xRVT0_kWBoQAMUSQ.jpeg"/></div></figure><p id="fb6c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们可能知道，交通堵塞可以分为几个不同的级别。最严重的是“大塞车”和“大塞车”。</p><p id="f948" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我把这两类事件合并成一个集合 a .而其他事件可以看作是集合 b。</p><p id="a28f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对于集合 A 中的每个事件，我回溯 30 分钟，并将同一条路上报告的每个事件累积到一个序列中。总共有 987 个。然而，其中一些是空列表，意味着在严重堵塞之前没有任何报告，而且它发生得非常突然。对于这种堵车，没人能预测，所以我决定去掉，保留了 861 个非空序列。</p><p id="2946" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">类似地，我通过回溯来自集合 b 的事件随机提取了 861 个非空序列。注意这些序列<strong class="kw iu">没有</strong>导致严重的交通堵塞。</p><p id="d97d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们已经得到了作为输入数据的序列，我们将从集合 A 生成的序列标记为 1，而其他的标记为 0。</p><p id="167e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们的研究问题是，能不能用一个模型对这些序列数据进行分类？</p><p id="d97a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">结果证明是成功的。我们获得了一等奖！</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/59f2bacb24d40d2eb0a38d3cc24cb8ca.png" data-original-src="https://miro.medium.com/v2/format:webp/1*F5sVFwnTuTK-tC_QLXUSBg.jpeg"/></div></figure><p id="596b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们的团队，昵称为“守望饺子”，由来自武汉大学的访问博士生王春英和我组成，代表实验室。我们每个人都得到了 100 美元。看我们多开心啊！</p><p id="01dc" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">HackNTX 的网站很快就对黑客马拉松比赛进行了报道。这里是<a class="ae mo" href="https://www.hackntx.com/blog/2018/12/03/hackntx-2018-winners-and-wrap-up" rel="noopener ugc nofollow" target="_blank">环节</a>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/6cf33fc21e37e6bf001c04d373d7926a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Olwr2hspCtc60mfff6sW-g.jpeg"/></div></figure><p id="d3a8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">几天后，UNT 也向<a class="ae mo" href="https://informationscience.unt.edu/visiting-scholar-and-doctoral-student-take-first-place-win-hack-ntx-event" rel="noopener ugc nofollow" target="_blank">报告了这个消息</a>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/7adbc8669a3265f1f1aa1d635cd7f81c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*qQsgxmgWBXm4Ba5fY9wFCg.jpeg"/></div></figure><p id="f8c7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">对我来说，获得一等奖几乎完全是运气。然而，我认为该模型具有潜在的实用价值。</p><p id="40bd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在本文的后面部分，我将尝试向您展示如何使用 Python 和 Keras 实现 RNN 模型来对 Waze 事件序列进行分类。</p><h1 id="df71" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">环境</h1><p id="ec01" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">要做深度学习，你需要 GPU 或者 TPU，否则你的笔记本电脑会被折磨。我带着没有风扇的 Macbook 去参加比赛，我没有办法用它来训练深度神经网络。</p><p id="d0a5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我用了谷歌 Colab。这很酷，谷歌人很慷慨，为用户提供免费的 GPU 和 TPU。</p><p id="271e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">请先下载安装 Google Chrome，然后点击<a class="ae mo" href="https://chrome.google.com/webstore/detail/colaboratory/flckfnigdgnmmidlohfbfccgpakpeagd" rel="noopener ugc nofollow" target="_blank">这个链接</a>，安装一个名为 Colaboratory 的插件。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/2f28ac81dcd5510f941f3dc63216040b.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Cw-t1CF5I6rsTHxiRWP0AQ.png"/></div></figure><p id="76f5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你会在 Chrome 的扩展栏中看到它的黄色图标。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/9c49e15626294b046e138734f4d9471f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*PJOQwG2LX4PlhWoLi0-Kpg.jpeg"/></div></figure><p id="861e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我已经把这个教程的所有代码和数据上传到了<a class="ae mo" href="https://github.com/wshuyi/demo_traffic_jam_prediction" rel="noopener ugc nofollow" target="_blank">这个 github repo </a>上。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/9bf11cb87e03fee18cbafb17faaabe70.png" data-original-src="https://miro.medium.com/v2/format:webp/1*jWrm_Dtqk6qAlV8V5j3lfw.jpeg"/></div></figure><p id="923b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">请点击上面的链接，并点击<code class="fe mp mq mr ms b">demo.ipynb</code>。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/337ce8ae9c13ff305c570f9610f8749c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*N2AX2VaZEdxW-leGegzTvw.jpeg"/></div></figure><p id="6c44" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在你可以点击 Colaboratory 的图标，Chrome 会自动为你打开 Google Colab，将这个 ipynb 文件加载进去。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/6dbb16efd5ccd54b54144bbed353ce92.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Np2Prx_JJUMiCDNsFkQwSw.png"/></div></figure><p id="0b8f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">点击上面截图中我用红色圈出的“复制到驱动器”按钮，Google 会在你的 Google Drive 上为你创建一份 Jupyter 笔记本文件的副本。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/9e9222cc58bd87ecf472a03546663396.png" data-original-src="https://miro.medium.com/v2/format:webp/1*5k2K4TLIOfBW-4g7Bt4pjg.jpeg"/></div></figure><p id="1b8a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">进入“运行时”菜单，点击“更改运行时类型”。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/b91062b27ceb51b30f7d4cf445264ac8.png" data-original-src="https://miro.medium.com/v2/format:webp/1*-nqM1RpgWlf15_Hb1EXklA.jpeg"/></div></figure><p id="c6c5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">仔细检查选项是否设置如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/e8f8d21022584d4cd90703dd2e5a2952.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ZcMMiN9LLennwJI69aneAg.jpeg"/></div></figure><p id="d483" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">保存，然后就万事俱备了。</p><p id="4041" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">要运行一段代码，只需点击左侧的运行按钮。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/3911534ae3d2d11554469453da7cd13d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*jXAPbYOISiEFghyLcle3RQ.jpeg"/></div></figure><p id="53a6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们一步一步来，我会给你必要的解释。</p><h1 id="7f70" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">密码</h1><p id="ecb2" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">我们需要加载 Pandas 包来处理表格数据。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="9ceb" class="mx lr it ms b gy my mz l na nb">import pandas as pd</span></pre><p id="2d30" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将需要另一个包来加载预处理阶段保存的数据。它叫泡菜。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="5439" class="mx lr it ms b gy my mz l na nb">import pickle</span></pre><p id="4fb0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">它可以将单个或多个 Python 数据保存到外部文件中。当您将它加载回程序中时，它会将数据恢复为保存时的状态。在这种情况下，它比用 CSV 文件交换数据更容易、更高效。</p><p id="82d4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们克隆本教程的 github repo，并将数据放入 Google Colab workspace。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="da1e" class="mx lr it ms b gy my mz l na nb">!git clone <a class="ae mo" href="https://github.com/wshuyi/demo_traffic_jam_prediction.git" rel="noopener ugc nofollow" target="_blank">https://github.com/wshuyi/demo_traffic_jam_prediction.git</a></span></pre><p id="c10a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">数据没那么大，不一会就下载完了。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="d10f" class="mx lr it ms b gy my mz l na nb">Cloning into 'demo_traffic_jam_prediction'...<br/>remote: Enumerating objects: 6, done.[K<br/>remote: Counting objects: 100% (6/6), done.[K<br/>remote: Compressing objects: 100% (4/4), done.[K<br/>remote: Total 6 (delta 0), reused 3 (delta 0), pack-reused 0[K<br/>Unpacking objects: 100% (6/6), done.</span></pre><p id="cb41" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们告诉 Jupyter 笔记本数据文件夹的路径。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="34f6" class="mx lr it ms b gy my mz l na nb">from pathlib import Path<br/>data_dir = Path('demo_traffic_jam_prediction')</span></pre><p id="3714" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将打开数据文件并用 pickle 加载两个不同的数据变量。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="fc76" class="mx lr it ms b gy my mz l na nb">with open(data_dir / 'data.pickle', 'rb') as f:<br/>    [event_dict, df] = pickle.load(f)</span></pre><p id="cfb6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">首先，让我们看看名为<code class="fe mp mq mr ms b">event_dict</code>的事件字典:</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="1c34" class="mx lr it ms b gy my mz l na nb">event_dict</span></pre><p id="7d70" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下是所有的事件类型。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="ff31" class="mx lr it ms b gy my mz l na nb">{1: 'road closed due to construction',<br/> 2: 'traffic jam',<br/> 3: 'stopped car on the shoulder',<br/> 4: 'road closed',<br/> 5: 'other',<br/> 6: 'object on roadway',<br/> 7: 'major event',<br/> 8: 'pothole',<br/> 9: 'traffic heavier than normal',<br/> 10: 'road construction',<br/> 11: 'fog',<br/> 12: 'accident',<br/> 13: 'slowdown',<br/> 14: 'stopped car',<br/> 15: 'small traffic jam',<br/> 16: 'stopped traffic',<br/> 17: 'heavy traffic',<br/> 18: 'minor accident',<br/> 19: 'medium traffic jam',<br/> 20: 'malfunctioning traffic light',<br/> 21: 'missing sign on the shoulder',<br/> 22: 'animal on the shoulder',<br/> 23: 'animal struck',<br/> 24: 'large traffic jam',<br/> 25: 'hazard on the shoulder',<br/> 26: 'hazard on road',<br/> 27: 'ice on roadway',<br/> 28: 'weather hazard',<br/> 29: 'flooding',<br/> 30: 'road closed due to hazard',<br/> 31: 'hail',<br/> 32: 'huge traffic jam'}</span></pre><p id="2477" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后，让我们看看数据帧中的<code class="fe mp mq mr ms b">df</code>是什么。</p><p id="3b98" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是一张相当长的桌子。让我们只显示前 10 行。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="8215" class="mx lr it ms b gy my mz l na nb">df.head(10)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/a6842096924d44988ce222ef9b70fe68.png" data-original-src="https://miro.medium.com/v2/format:webp/1*QgzssUhGlz-pb9_nrxmDbA.png"/></div></figure><p id="8273" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在每一行中，都有一个相应的标签，显示数据序列之后是否有严重的交通堵塞事件。</p><p id="c69f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后我们会让熊猫给我们展示最后 10 排。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="8ec5" class="mx lr it ms b gy my mz l na nb">df.tail(10)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/8bd869a64a14b0bb4147e217d50499a5.png" data-original-src="https://miro.medium.com/v2/format:webp/1*ZZWeO4oiGSgVl-18KgqT-A.png"/></div></figure><p id="b9a6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们已经正确地加载了数据，我们将看到哪一行包含最长的序列。</p><p id="de67" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将使用来自 Pandas 的一个名为<code class="fe mp mq mr ms b">idxmax()</code>的函数，它将帮助我们获得最大值的索引。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="342a" class="mx lr it ms b gy my mz l na nb">max_len_event_id = df.events.apply(len).idxmax()<br/>max_len_event_id</span></pre><p id="0a2d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">结果如下:</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="880f" class="mx lr it ms b gy my mz l na nb">105</span></pre><p id="eda1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们深入了解这一行的顺序:</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="c28b" class="mx lr it ms b gy my mz l na nb">max_len_event = df.iloc[max_len_event_id]<br/>max_len_event.events</span></pre><p id="8d15" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">结果是一个相当长的列表。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="4539" class="mx lr it ms b gy my mz l na nb">['stopped car on the shoulder',<br/> 'heavy traffic',<br/> 'heavy traffic',<br/> 'heavy traffic',<br/> 'slowdown',<br/> 'stopped traffic',<br/> 'heavy traffic',<br/> 'heavy traffic',<br/> 'heavy traffic',<br/> 'heavy traffic',<br/> 'traffic heavier than normal',<br/> 'stopped car on the shoulder',<br/> 'traffic jam',<br/> 'heavy traffic',<br/> 'stopped traffic',<br/> 'stopped traffic',<br/> 'stopped traffic',<br/> 'heavy traffic',<br/> 'traffic jam',<br/> 'stopped car on the shoulder',<br/> 'stopped traffic',<br/> 'stopped traffic',<br/> 'stopped traffic',<br/> 'heavy traffic',<br/> 'traffic heavier than normal',<br/> 'traffic heavier than normal',<br/> 'traffic heavier than normal',<br/> 'traffic heavier than normal',<br/> 'heavy traffic',<br/> 'stopped traffic',<br/> 'traffic heavier than normal',<br/> 'pothole',<br/> 'stopped car on the shoulder',<br/> 'traffic jam',<br/> 'slowdown',<br/> 'stopped traffic',<br/> 'heavy traffic',<br/> 'traffic heavier than normal',<br/> 'traffic jam',<br/> 'traffic jam',<br/> 'stopped car on the shoulder',<br/> 'major event',<br/> 'traffic jam',<br/> 'traffic jam',<br/> 'stopped traffic',<br/> 'heavy traffic',<br/> 'traffic heavier than normal',<br/> 'stopped car on the shoulder',<br/> 'slowdown',<br/> 'heavy traffic',<br/> 'heavy traffic',<br/> 'stopped car on the shoulder',<br/> 'traffic jam',<br/> 'slowdown',<br/> 'slowdown',<br/> 'heavy traffic',<br/> 'stopped car on the shoulder',<br/> 'heavy traffic',<br/> 'minor accident',<br/> 'stopped car on the shoulder',<br/> 'heavy traffic',<br/> 'stopped car on the shoulder',<br/> 'heavy traffic',<br/> 'stopped traffic',<br/> 'heavy traffic',<br/> 'traffic heavier than normal',<br/> 'heavy traffic',<br/> 'stopped car on the shoulder',<br/> 'traffic heavier than normal',<br/> 'stopped traffic',<br/> 'heavy traffic',<br/> 'heavy traffic',<br/> 'heavy traffic',<br/> 'stopped car on the shoulder',<br/> 'slowdown',<br/> 'stopped traffic',<br/> 'heavy traffic',<br/> 'stopped car on the shoulder',<br/> 'traffic heavier than normal',<br/> 'heavy traffic',<br/> 'minor accident',<br/> 'major event',<br/> 'stopped car on the shoulder',<br/> 'stopped car on the shoulder']</span></pre><p id="416b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你仔细检查序列，你会注意到这条路上有严重交通堵塞的迹象。然而，你需要让机器获得“感觉”并自动对序列进行分类。</p><p id="c6b2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最长的序列有多长？</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="969b" class="mx lr it ms b gy my mz l na nb">maxlen = len(max_len_event.events)<br/>maxlen</span></pre><p id="f367" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面是答案:</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="0812" class="mx lr it ms b gy my mz l na nb">84</span></pre><p id="57d2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">哇！这是一个长长的事件列表！</p><p id="15a9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">电脑不擅长读取事件名称。让我们试着把名字转换成数字，这样计算机就能更好地处理这个问题。</p><p id="1738" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">为了有效地做到这一点，我们需要反转之前加载的字典。即尝试将“索引:事件类型”格式转换为“事件类型:索引”。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="bd08" class="mx lr it ms b gy my mz l na nb">reversed_dict = {}<br/>for k, v in event_dict.items():<br/>  reversed_dict[v] = k</span></pre><p id="8124" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们检查一下翻过来的字典。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="5cf9" class="mx lr it ms b gy my mz l na nb">reversed_dict</span></pre><p id="cb35" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是结果。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="efc3" class="mx lr it ms b gy my mz l na nb">{'accident': 12,<br/> 'animal on the shoulder': 22,<br/> 'animal struck': 23,<br/> 'flooding': 29,<br/> 'fog': 11,<br/> 'hail': 31,<br/> 'hazard on road': 26,<br/> 'hazard on the shoulder': 25,<br/> 'heavy traffic': 17,<br/> 'huge traffic jam': 32,<br/> 'ice on roadway': 27,<br/> 'large traffic jam': 24,<br/> 'major event': 7,<br/> 'malfunctioning traffic light': 20,<br/> 'medium traffic jam': 19,<br/> 'minor accident': 18,<br/> 'missing sign on the shoulder': 21,<br/> 'object on roadway': 6,<br/> 'other': 5,<br/> 'pothole': 8,<br/> 'road closed': 4,<br/> 'road closed due to construction': 1,<br/> 'road closed due to hazard': 30,<br/> 'road construction': 10,<br/> 'slowdown': 13,<br/> 'small traffic jam': 15,<br/> 'stopped car': 14,<br/> 'stopped car on the shoulder': 3,<br/> 'stopped traffic': 16,<br/> 'traffic heavier than normal': 9,<br/> 'traffic jam': 2,<br/> 'weather hazard': 28}</span></pre><p id="10b7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们成功了。</p><p id="bf90" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们需要构造一个函数，来转换事件列表，并返回给我们一个数字列表。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="2c66" class="mx lr it ms b gy my mz l na nb">def map_event_list_to_idxs(event_list):<br/>  list_idxs = []<br/>  for event in (event_list):<br/>    idx = reversed_dict[event]<br/>    list_idxs.append(idx)<br/>  return list_idxs</span></pre><p id="e942" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们试试最长列表中的函数。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="81c3" class="mx lr it ms b gy my mz l na nb">map_event_list_to_idxs(max_len_event.events)</span></pre><p id="1556" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">结果是:</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="059c" class="mx lr it ms b gy my mz l na nb">[3,<br/> 17,<br/> 17,<br/> 17,<br/> 13,<br/> 16,<br/> 17,<br/> 17,<br/> 17,<br/> 17,<br/> 9,<br/> 3,<br/> 2,<br/> 17,<br/> 16,<br/> 16,<br/> 16,<br/> 17,<br/> 2,<br/> 3,<br/> 16,<br/> 16,<br/> 16,<br/> 17,<br/> 9,<br/> 9,<br/> 9,<br/> 9,<br/> 17,<br/> 16,<br/> 9,<br/> 8,<br/> 3,<br/> 2,<br/> 13,<br/> 16,<br/> 17,<br/> 9,<br/> 2,<br/> 2,<br/> 3,<br/> 7,<br/> 2,<br/> 2,<br/> 16,<br/> 17,<br/> 9,<br/> 3,<br/> 13,<br/> 17,<br/> 17,<br/> 3,<br/> 2,<br/> 13,<br/> 13,<br/> 17,<br/> 3,<br/> 17,<br/> 18,<br/> 3,<br/> 17,<br/> 3,<br/> 17,<br/> 16,<br/> 17,<br/> 9,<br/> 17,<br/> 3,<br/> 9,<br/> 16,<br/> 17,<br/> 17,<br/> 17,<br/> 3,<br/> 13,<br/> 16,<br/> 17,<br/> 3,<br/> 9,<br/> 17,<br/> 18,<br/> 7,<br/> 3,<br/> 3]</span></pre><p id="a971" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在我们从 Keras 加载 numpy 和一些实用函数。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="5559" class="mx lr it ms b gy my mz l na nb">import numpy as np<br/>from keras.utils import to_categorical<br/>from keras.preprocessing.sequence import pad_sequences</span></pre><p id="30b0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们需要弄清楚我们有多少不同的事件类型。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="8958" class="mx lr it ms b gy my mz l na nb">len(event_dict)</span></pre><p id="d41d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">结果如下:</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="7976" class="mx lr it ms b gy my mz l na nb">32</span></pre><p id="a00a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们把所有的事件顺序转换成数字列表。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="48d6" class="mx lr it ms b gy my mz l na nb">df.events.apply(map_event_list_to_idxs)</span></pre><p id="327f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">结果是:</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="2c39" class="mx lr it ms b gy my mz l na nb">0      [9, 17, 18, 14, 13, 17, 3, 13, 16, 3, 17, 17, ...<br/>1                                             [2, 10, 3]<br/>2                                                    [2]<br/>3                                                    [2]<br/>4                               [2, 2, 2, 2, 2, 2, 2, 9]<br/>5                                             [3, 2, 17]<br/>6                                             [3, 2, 17]<br/>7                        [2, 15, 2, 17, 2, 2, 13, 17, 2]<br/>8                                  [17, 2, 2, 16, 17, 2]<br/>9                                  [17, 2, 2, 16, 17, 2]<br/>10     [17, 16, 17, 2, 17, 3, 17, 17, 16, 17, 16, 18,...<br/>11                                                  [17]<br/>12                                                  [17]<br/>13                                              [24, 24]<br/>14                                    [24, 2, 24, 24, 2]<br/>15                                    [24, 2, 24, 24, 2]<br/>16     [2, 10, 2, 2, 2, 18, 16, 16, 7, 2, 16, 2, 2, 9...<br/>17     [2, 10, 2, 2, 2, 18, 16, 16, 7, 2, 16, 2, 2, 9...<br/>18                               [24, 24, 24, 16, 2, 16]<br/>19                               [24, 24, 24, 16, 2, 16]<br/>20                                                [2, 2]<br/>21                                            [2, 16, 2]<br/>22                                            [2, 16, 2]<br/>23                                                [2, 2]<br/>24                                                [2, 2]<br/>25                                              [24, 24]<br/>26                                                [2, 2]<br/>27                                         [2, 2, 2, 17]<br/>28                                            [2, 19, 2]<br/>29                                                  [24]<br/>                             ...<br/>831                     [9, 9, 9, 2, 9, 9, 17, 2, 9, 17]<br/>832                                            [3, 3, 3]<br/>833                                 [2, 9, 2, 17, 17, 2]<br/>834       [3, 3, 17, 3, 13, 3, 3, 23, 9, 3, 3, 25, 3, 3]<br/>835      [3, 17, 9, 14, 9, 17, 14, 9, 2, 9, 3, 2, 2, 17]<br/>836                                                  [2]<br/>837         [17, 2, 16, 3, 9, 17, 17, 17, 13, 17, 9, 17]<br/>838    [13, 17, 17, 3, 3, 16, 17, 16, 17, 16, 3, 9, 1...<br/>839                                                  [2]<br/>840                                                  [3]<br/>841                                                  [2]<br/>842    [17, 17, 17, 3, 17, 23, 16, 17, 17, 3, 2, 13, ...<br/>843                                               [3, 3]<br/>844                                                  [2]<br/>845                     [2, 17, 2, 2, 2, 2, 2, 17, 2, 2]<br/>846                                   [7, 17, 3, 18, 17]<br/>847                                            [3, 3, 3]<br/>848    [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...<br/>849                                               [2, 2]<br/>850          [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 13, 3, 2]<br/>851                                            [2, 2, 2]<br/>852                                          [16, 2, 16]<br/>853                [3, 16, 5, 3, 17, 3, 16, 9, 3, 2, 17]<br/>854                                                 [16]<br/>855    [3, 3, 3, 3, 3, 3, 3, 3, 2, 13, 3, 6, 3, 6, 3,...<br/>856                    [17, 17, 17, 2, 3, 2, 2, 2, 2, 2]<br/>857                                               [2, 2]<br/>858                                  [2, 2, 9, 17, 2, 2]<br/>859                            [17, 3, 2, 2, 2, 2, 2, 2]<br/>860    [17, 3, 3, 17, 3, 17, 2, 3, 18, 14, 3, 3, 16, ...<br/>Name: events, Length: 1722, dtype: object</span></pre><p id="08e5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">作为人类，我们很难识别每个数字所代表的意义。但是，对于计算机来说，就容易多了。</p><p id="7ad5" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将结果列表命名为<code class="fe mp mq mr ms b">sequences</code>，显示前五行。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="6d92" class="mx lr it ms b gy my mz l na nb">sequences = df.events.apply(map_event_list_to_idxs).tolist()<br/>sequences[:5]</span></pre><p id="4cdf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">结果如下:</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="a6f5" class="mx lr it ms b gy my mz l na nb">[[9,<br/>  17,<br/>  18,<br/>  14,<br/>  13,<br/>  17,<br/>  3,<br/>  13,<br/>  16,<br/>  3,<br/>  17,<br/>  17,<br/>  16,<br/>  3,<br/>  16,<br/>  17,<br/>  9,<br/>  17,<br/>  2,<br/>  17,<br/>  2,<br/>  7,<br/>  16,<br/>  17,<br/>  17,<br/>  17,<br/>  17,<br/>  13,<br/>  5,<br/>  17,<br/>  9,<br/>  9,<br/>  16,<br/>  16,<br/>  3],<br/> [2, 10, 3],<br/> [2],<br/> [2],<br/> [2, 2, 2, 2, 2, 2, 2, 9]]</span></pre><p id="3e03" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">注意第一行比后面几行长得多。</p><p id="bc59" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，要对数据应用序列模型，我们需要确保所有输入序列共享相同的长度。因此，我们使用最长序列的长度作为最大长度，并从开始用 0 填充其他较短的序列。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="60d8" class="mx lr it ms b gy my mz l na nb">data = pad_sequences(sequences, maxlen=maxlen)<br/>data</span></pre><p id="2e6b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">以下是填充序列:</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="4b5c" class="mx lr it ms b gy my mz l na nb">array([[ 0,  0,  0, ..., 16, 16,  3],<br/>       [ 0,  0,  0, ...,  2, 10,  3],<br/>       [ 0,  0,  0, ...,  0,  0,  2],<br/>       ...,<br/>       [ 0,  0,  0, ..., 17,  2,  2],<br/>       [ 0,  0,  0, ...,  2,  2,  2],<br/>       [ 0,  0,  0, ...,  3,  3,  2]], dtype=int32)</span></pre><p id="70d6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">现在所有的序列都有相同的长度。</p><p id="dfed" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们需要获取标签列，并将其保存到一个名为<code class="fe mp mq mr ms b">labels</code>的变量中。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="b421" class="mx lr it ms b gy my mz l na nb">labels = np.array(df.label)</span></pre><p id="a0db" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因为我们需要使用几个随机函数，为了保持您的运行结果与我的相同，我们将随机种子值指定为 12。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="3ef9" class="mx lr it ms b gy my mz l na nb">np.random.seed(12)</span></pre><p id="ad7d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当您完成代码的第一次运行时，可以随意修改它。</p><p id="b28e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们把这些序列和它们相应的标签混在一起。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="4416" class="mx lr it ms b gy my mz l na nb">indices = np.arange(data.shape[0])<br/>np.random.shuffle(indices)<br/>data = data[indices]<br/>labels = labels[indices]</span></pre><p id="cc00" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">训练集将包含 80%的数据，而另外 20%将进入验证集。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="c655" class="mx lr it ms b gy my mz l na nb">training_samples = int(len(indices) * .8)<br/>validation_samples = len(indices) - training_samples</span></pre><p id="7c50" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下面的代码将数据与标签一起分为定型集和验证集。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="9a95" class="mx lr it ms b gy my mz l na nb">X_train = data[:training_samples]<br/>y_train = labels[:training_samples]<br/>X_valid = data[training_samples: training_samples + validation_samples]<br/>y_valid = labels[training_samples: training_samples + validation_samples]</span></pre><p id="6728" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们展示训练数据的内容:</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="cc41" class="mx lr it ms b gy my mz l na nb">X_train</span></pre><p id="e842" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是结果。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="339d" class="mx lr it ms b gy my mz l na nb">array([[ 0,  0,  0, ..., 15, 15,  3],<br/>       [ 0,  0,  0, ...,  0,  2,  2],<br/>       [ 0,  0,  0, ...,  0,  0, 16],<br/>       ...,<br/>       [ 0,  0,  0, ...,  2, 15, 16],<br/>       [ 0,  0,  0, ...,  2,  2,  2],<br/>       [ 0,  0,  0, ...,  0,  0,  2]], dtype=int32)</span></pre><p id="0f1b" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">请注意，当我们用 0 填充序列作为填充值时，现在我们有 33 个事件类型，而不是 32 个。</p><p id="9a98" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">因此事件类型的数量将被设置为 33。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="461f" class="mx lr it ms b gy my mz l na nb">num_events = len(event_dict) + 1</span></pre><p id="d309" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果我们简单地把数字放入分类模型，它会把每个数字看作一个连续的值。然而，事实并非如此。因此，我们将让数字通过一个嵌入层，并将每个数字(代表某种类型的事件)转换为一个向量。每个向量将包含 20 个标量。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="1421" class="mx lr it ms b gy my mz l na nb">embedding_dim = 20</span></pre><p id="a060" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">初始嵌入矩阵将随机生成。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="aaa5" class="mx lr it ms b gy my mz l na nb">embedding_matrix = np.random.rand(num_events, embedding_dim)</span></pre><p id="ffb9" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">最后，我们现在可以建立一个模型。</p><p id="e507" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们使用 Keras 中的顺序模型，一层一层地放置不同的层，就像我们玩乐高一样。</p><p id="a2ed" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">第一层是嵌入层，然后是 LSTM 层，最后一层是稠密层，其激活函数是 sigmoid，进行二值分类。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="7e04" class="mx lr it ms b gy my mz l na nb">from keras.models import Sequential<br/>from keras.layers import Embedding, Flatten, Dense, LSTM<br/><br/>units = 32<br/><br/>model = Sequential()<br/>model.add(Embedding(num_events, embedding_dim))<br/>model.add(LSTM(units))<br/>model.add(Dense(1, activation='sigmoid'))</span></pre><p id="1304" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如果你对 Keras 不熟悉，推荐你读一读 Keras 的创建者 Franç ois Chollet 的《用 Python 进行深度学习》。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/422689e376d99d6b7904113067003853.png" data-original-src="https://miro.medium.com/v2/format:webp/1*_HJAxpaR7q9IzECDaoN4xg.jpeg"/></div></figure><p id="c83e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下一步是处理嵌入层中的参数。目前，我们只是加载随机生成的初始嵌入矩阵，不会让训练过程改变嵌入层的权重。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="d82e" class="mx lr it ms b gy my mz l na nb">model.layers[0].set_weights([embedding_matrix])<br/>model.layers[0].trainable = False</span></pre><p id="dd4d" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后，我们训练模型，并将模型保存到 h5 文件中。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="9a4b" class="mx lr it ms b gy my mz l na nb">model.compile(optimizer='rmsprop',<br/>              loss='binary_crossentropy',<br/>              metrics=['acc'])<br/>history = model.fit(X_train, y_train,<br/>                    epochs=50,<br/>                    batch_size=32,<br/>                    validation_data=(X_valid, y_valid))<br/>model.save("mymodel_embedding_untrainable.h5")</span></pre><p id="c92a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">在 TPU 的大力支持下，训练速度相当快。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/b72a5abf0e98b67f52c7be65ec798e71.png" data-original-src="https://miro.medium.com/v2/format:webp/1*0iZfMld-wLSdsB5RqK8Ydw.png"/></div></figure><p id="fd66" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">模型训练完成后，让我们用 matplotlib 可视化精度和损耗的曲线。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="2f73" class="mx lr it ms b gy my mz l na nb">import matplotlib.pyplot as plt<br/><br/>acc = history.history['acc']<br/>val_acc = history.history['val_acc']<br/>loss = history.history['loss']<br/>val_loss = history.history['val_loss']<br/><br/>epochs = range(1, len(acc) + 1)<br/><br/>plt.plot(epochs, acc, 'bo', label='Training acc')<br/>plt.plot(epochs, val_acc, 'b', label='Validation acc')<br/>plt.title('Training and validation accuracy')<br/>plt.legend()<br/><br/>plt.figure()<br/><br/>plt.plot(epochs, loss, 'bo', label='Training loss')<br/>plt.plot(epochs, val_loss, 'b', label='Validation loss')<br/>plt.title('Training and validation loss')<br/>plt.legend()<br/><br/>plt.show()</span></pre><p id="2fed" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是精确度曲线。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/b0e679ac53aeedd566eca453f8c25e8e.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Wn2uKzWeMybpvjMM7R2lDw.png"/></div></figure><p id="7d9c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如你所见，还不错。如果我们使用虚拟模型来预测标签为 0 的所有内容(或所有内容为 1)，精确度将保持在 0.50。很明显，我们的模型捕捉到了一些模式，并且比虚拟模型表现得更好。</p><p id="05d6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是，它很不稳定。</p><p id="34de" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后让我们看看损失曲线。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/842f726eab809af9f9e82555a6a9cd5f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*f1re_xBbgeR_F7Et1fGICw.png"/></div></figure><p id="23fd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可能会发现，这并不好。当训练损失下降时，验证集的损失上升，并且没有明显的收敛趋势。</p><p id="b6e3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">更重要的是找出原因。</p><p id="1131" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">注意，我们使用了一个随机初始化的嵌入矩阵，它在训练阶段保持不变。这可能会给我们带来麻烦。</p><p id="de69" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下一步，我们可以做一个实验来训练和调整嵌入层。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="338c" class="mx lr it ms b gy my mz l na nb">from keras.models import Sequential<br/>from keras.layers import Embedding, Flatten, Dense, LSTM<br/><br/>units = 32<br/><br/>model = Sequential()<br/>model.add(Embedding(num_events, embedding_dim))<br/>model.add(LSTM(units))<br/>model.add(Dense(1, activation='sigmoid'))</span></pre><p id="26ba" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">代码中唯一不同的是，参数<code class="fe mp mq mr ms b">trainable</code>被设置为<code class="fe mp mq mr ms b">True</code>。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="2777" class="mx lr it ms b gy my mz l na nb">model.layers[0].set_weights([embedding_matrix])<br/>model.layers[0].trainable = True</span></pre><p id="4a3a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们编译这个模型，再运行一遍。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="c6b6" class="mx lr it ms b gy my mz l na nb">model.compile(optimizer='rmsprop',<br/>              loss='binary_crossentropy',<br/>              metrics=['acc'])<br/>history = model.fit(X_train, y_train,<br/>                    epochs=50,<br/>                    batch_size=32,<br/>                    validation_data=(X_valid, y_valid))<br/>model.save("mymodel_embedding_trainable.h5")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/15f734c9b83aca9df9a026e8d5eb2627.png" data-original-src="https://miro.medium.com/v2/format:webp/1*fFxVkUvbPWnmAAFTgNVCdw.png"/></div></figure><p id="c600" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们还绘制了精度曲线和损耗曲线。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="da82" class="mx lr it ms b gy my mz l na nb">import matplotlib.pyplot as plt<br/><br/>acc = history.history['acc']<br/>val_acc = history.history['val_acc']<br/>loss = history.history['loss']<br/>val_loss = history.history['val_loss']<br/><br/>epochs = range(1, len(acc) + 1)<br/><br/>plt.plot(epochs, acc, 'bo', label='Training acc')<br/>plt.plot(epochs, val_acc, 'b', label='Validation acc')<br/>plt.title('Training and validation accuracy')<br/>plt.legend()<br/><br/>plt.figure()<br/><br/>plt.plot(epochs, loss, 'bo', label='Training loss')<br/>plt.plot(epochs, val_loss, 'b', label='Validation loss')<br/>plt.title('Training and validation loss')<br/>plt.legend()<br/><br/>plt.show()</span></pre><p id="dd66" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">准确度曲线如下所示。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/72b1a42eda84023eb2d3c1d1a19c6a55.png" data-original-src="https://miro.medium.com/v2/format:webp/1*kRCucuU429etH6O0l50Kiw.png"/></div></figure><p id="1df2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">如你所见，情况有所好转。验证准确度曲线波动下降，验证准确度高于 0.75。</p><p id="4a53" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这种模式在某种程度上更有价值。</p><p id="c9e3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">但是，我们不应该这么快就下结论。如果你观察亏损曲线，你就不会这么乐观了。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/08509154eeff3376b664df457ae30510.png" data-original-src="https://miro.medium.com/v2/format:webp/1*RycT1u9xh0tGMSbWUXsoAA.png"/></div></figure><p id="301c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从中途开始，不同盘的损失趋势走向不同的方向。</p><p id="6d3e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">这是一种过度拟合的暗示。</p><p id="f139" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">过度拟合总是表明训练数据对于复杂模型来说是不够的。</p><p id="5fbf" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">你可以为训练增加更多的数据，或者降低复杂度。</p><p id="9418" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">第一种方法现在不太适用，因为我们只有 11 月份 29 天的数据集。</p><p id="9d11" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，要降低模型的复杂性，可以通过 Dropout 轻松实现。</p><p id="e5ce" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">当你使用 Dropout 时，模型会随机选取一定比例(你说了算)的神经元，在<strong class="kw iu">训练</strong>阶段将它们的权重设置为零，这样就可以将它们视为从网络中“移除”，复杂度变低了。</p><p id="7f10" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">注意在<strong class="kw iu">验证</strong>阶段，模型将使用所有神经元，没有任何遗漏。</p><p id="5605" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将添加两个与辍学相关的参数。为此，我们在定义 LSTM 层时使用<code class="fe mp mq mr ms b">dropout=0.2, recurrent_dropout=0.2</code>。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="47ec" class="mx lr it ms b gy my mz l na nb">from keras.models import Sequential<br/>from keras.layers import Embedding, Flatten, Dense, LSTM<br/><br/>units = 32<br/><br/>model = Sequential()<br/>model.add(Embedding(num_events, embedding_dim))<br/>model.add(LSTM(units, dropout=0.2, recurrent_dropout=0.2))<br/>model.add(Dense(1, activation='sigmoid'))</span></pre><p id="b3c7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我们将保持嵌入层的参数<code class="fe mp mq mr ms b">trainable</code>为<code class="fe mp mq mr ms b">True</code>。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="1101" class="mx lr it ms b gy my mz l na nb">model.layers[0].set_weights([embedding_matrix])<br/>model.layers[0].trainable = True</span></pre><p id="212f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">让我们再进行一次训练。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="2812" class="mx lr it ms b gy my mz l na nb">model.compile(optimizer='rmsprop',<br/>              loss='binary_crossentropy',<br/>              metrics=['acc'])<br/>history = model.fit(X_train, y_train,<br/>                    epochs=50,<br/>                    batch_size=32,<br/>                    validation_data=(X_valid, y_valid))<br/>model.save("mymodel_embedding_trainable_with_dropout.h5")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/6516f20a5552ba462b857ef09178614f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*7dcHqFpjsfQ5g041ZSr7-Q.png"/></div></figure><p id="5ba0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">可视化部分没有修改。</p><pre class="kj kk kl km gt mt ms mu mv aw mw bi"><span id="13af" class="mx lr it ms b gy my mz l na nb">import matplotlib.pyplot as plt<br/><br/>acc = history.history['acc']<br/>val_acc = history.history['val_acc']<br/>loss = history.history['loss']<br/>val_loss = history.history['val_loss']<br/><br/>epochs = range(1, len(acc) + 1)<br/><br/>plt.plot(epochs, acc, 'bo', label='Training acc')<br/>plt.plot(epochs, val_acc, 'b', label='Validation acc')<br/>plt.title('Training and validation accuracy')<br/>plt.legend()<br/><br/>plt.figure()<br/><br/>plt.plot(epochs, loss, 'bo', label='Training loss')<br/>plt.plot(epochs, val_loss, 'b', label='Validation loss')<br/>plt.title('Training and validation loss')<br/>plt.legend()<br/><br/>plt.show()</span></pre><p id="0336" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">从准确度曲线上，你可能看不到什么令人兴奋的东西。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/c504868e0d3f63b03c14484dea8f1e8b.png" data-original-src="https://miro.medium.com/v2/format:webp/1*J9KhbAEBKFlTzvvOmH_fkw.png"/></div></figure><p id="f9f1" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然而，当你观察损失曲线时，你会看到显著的改善。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="ab gu cl mn"><img src="../Images/bee3902936d15571287d0a0631a7a0e0.png" data-original-src="https://miro.medium.com/v2/format:webp/1*JwXWFUCzIRUai3ZfvQ9p4Q.png"/></div></figure><p id="2651" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">验证损失曲线更平滑，更接近训练损失的趋势。</p><p id="1b04" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">过度拟合的问题已经得到了解决，模型现在更加稳定，并且可以推广到看不见的数据。</p><p id="7070" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">然后，交通管理部门可以使用该模型，通过事件报告的 Waze 开放数据来预测严重交通堵塞的发生。模型精度的期望值约为 75%。</p><p id="de74" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">也许这样一来，由于这些预防措施，一些严重的交通堵塞就不会发生了。</p><h1 id="60d7" class="lq lr it bd ls lt lu lv lw lx ly lz ma jz mb ka mc kc md kd me kf mf kg mg mh bi translated">摘要</h1><p id="03fb" class="pw-post-body-paragraph ku kv it kw b kx mi ju kz la mj jx lc ld mk lf lg lh ml lj lk ll mm ln lo lp im bi translated">希望你能从这篇教程中得到以下几点。</p><ul class=""><li id="0266" class="nc nd it kw b kx ky la lb ld ne lh nf ll ng lp nh ni nj nk bi translated">序列模型，如 RNN 和 LSTM，不仅可以用于文本，也可以用于其他序列数据。</li><li id="d446" class="nc nd it kw b kx nl la nm ld nn lh no ll np lp nh ni nj nk bi translated">您可以在这类任务中使用嵌入层，即使它们没有预先训练的单词嵌入模型，如 word2vec、glove 或 fasttext。确保您设置了嵌入层的权重<strong class="kw iu">可训练</strong>。</li><li id="8a45" class="nc nd it kw b kx nl la nm ld nn lh no ll np lp nh ni nj nk bi translated">你可以尝试用几种不同的方法来克服过度拟合。辍学就是其中之一。在我们的情况下，它是有效的。</li></ul><p id="9812" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">希望您现在可以用顺序数据处理自己的分类任务。</p><p id="1f20" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">快乐深度学习！</p><p id="0288" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">我关于深度学习的其他教程:</p><ul class=""><li id="16e9" class="nc nd it kw b kx ky la lb ld ne lh nf ll ng lp nh ni nj nk bi translated"><a class="ae mo" href="https://medium.com/datadriveninvestor/deep-learning-with-python-and-fast-ai-part-1-image-classification-with-pre-trained-model-cd9364107872" rel="noopener">使用 Python 和 fast.ai 的深度学习，第 1 部分:使用预训练模型的图像分类</a></li><li id="42bd" class="nc nd it kw b kx nl la nm ld nn lh no ll np lp nh ni nj nk bi translated"><a class="ae mo" href="https://medium.com/datadriveninvestor/deep-learning-with-python-and-fast-ai-part-2-nlp-classification-with-transfer-learning-e7aaf7514e04" rel="noopener">使用 Python 和 fast.ai 的深度学习，第 2 部分:使用迁移学习的 NLP 分类</a></li><li id="7b57" class="nc nd it kw b kx nl la nm ld nn lh no ll np lp nh ni nj nk bi translated"><a class="ae mo" href="https://medium.com/datadriveninvestor/deep-learning-with-python-part-0-setup-fast-ai-1-0-on-google-cloud-c3d41aadbc8c" rel="noopener">Python 深度学习，第 0 部分:在 Google Cloud 上设置 fast . ai 1.0</a></li><li id="56cf" class="nc nd it kw b kx nl la nm ld nn lh no ll np lp nh ni nj nk bi translated"><a class="ae mo" href="https://medium.com/@wshuyi/how-to-accelerate-your-python-deep-learning-with-cloud-gpu-a976917037a" rel="noopener">如何用云 GPU 加速你的 Python 深度学习？</a></li></ul></div></div>    
</body>
</html>