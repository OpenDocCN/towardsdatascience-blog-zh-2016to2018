<html>
<head>
<title>Decision Trees in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的决策树</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052?source=collection_archive---------1-----------------------#2017-05-17">https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052?source=collection_archive---------1-----------------------#2017-05-17</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/d00810acdaab32515b22c12435aef811.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ff6FquwFWnrFeZJWfvsiag.jpeg"/></div></div></figure><div class=""/><p id="47d7" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">一棵树在现实生活中有很多类比，事实证明它影响了<strong class="ka jc">机器学习</strong>的广泛领域，既包括<strong class="ka jc">分类，也包括回归</strong>。在决策分析中，决策树可用于直观、明确地表示决策和决策制定。顾名思义，它使用树状决策模型。虽然在数据挖掘中它是一个常用的工具，用来导出一个策略以达到一个特定的目标，但它也广泛地用于机器学习，这将是本文的主要焦点。</p><h2 id="a7b7" class="kw kx jb bd ky kz la dn lb lc ld dp le kj lf lg lh kn li lj lk kr ll lm ln lo bi translated">一个算法如何用树来表示？</h2><p id="9916" class="pw-post-body-paragraph jy jz jb ka b kb lp kd ke kf lq kh ki kj lr kl km kn ls kp kq kr lt kt ku kv ij bi translated">为此，让我们考虑一个非常基本的例子，使用泰坦尼克号的数据集来预测一名乘客是否会幸存。以下模型使用数据集中的 3 个特征/属性/列，即性别、年龄和 sibsp(配偶或子女数量)。</p><figure class="lv lw lx ly gt is gh gi paragraph-image"><div class="gh gi lu"><img src="../Images/f81a43704ee63f24d347753fab51e66b.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*XMId5sJqPtm8-RIwVVz2tg.png"/></div><figcaption class="lz ma gj gh gi mb mc bd b be z dk">Image taken from wikipedia</figcaption></figure><p id="d15a" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="md">一棵决策树被倒过来画，它的根在顶部。</em>在左边的图片中，黑色的粗体文本代表一个条件/ <strong class="ka jc">内部节点</strong>，基于该条件树分裂成分支/ <strong class="ka jc">边</strong>。不再分裂的分支的末端是 decision/ <strong class="ka jc"> leaf </strong>，在本例中，乘客是死是活，分别用红色和绿色文本表示。</p><p id="f151" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">虽然，一个真正的数据集将有更多的功能，这只是一个更大的树的一个分支，但你不能忽视这种算法的简单性。<strong class="ka jc">特征的重要性是清楚的</strong>并且可以容易地查看关系。这种方法通常被称为从数据中学习决策树<strong class="ka jc">，上述树被称为分类树<strong class="ka jc">因为目标是将乘客分类为幸存或死亡。<strong class="ka jc">回归树</strong>以同样的方式表示，只是它们预测连续的值，比如房子的价格。一般来说，决策树算法被称为 CART 或分类和回归树。</strong></strong></p><p id="cc7f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">那么，后台到底是怎么回事呢？</strong>种一棵树包括决定<strong class="ka jc">选择哪些特征</strong>和<strong class="ka jc">使用什么条件</strong>进行分裂，以及知道何时停止。因为一棵树通常是任意生长的，所以你需要修剪它，让它看起来更漂亮。让我们从一种常用的分割技术开始。</p><h2 id="9f33" class="kw kx jb bd ky kz la dn lb lc ld dp le kj lf lg lh kn li lj lk kr ll lm ln lo bi translated"><strong class="ak">递归二进制分裂</strong></h2><figure class="lv lw lx ly gt is gh gi paragraph-image"><div class="gh gi me"><img src="../Images/da55e6a4918d808a01ef066626cfb1a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*CjV-yiPk8PEJNiTG2VxAvA.png"/></div></figure><p id="d983" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="md">在该程序中，考虑了所有特征，并使用成本函数尝试和测试了不同的分割点。选择具有最佳成本(或最低成本)的分割。</em></p><p id="f4e0" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">考虑从 titanic 数据集学习的树的早期例子。在第一次分裂或根中，考虑所有属性/特征，并且基于该分裂将训练数据分成组。我们有 3 个特征，所以将有 3 个候选分裂。现在我们将<strong class="ka jc"> <em class="md">计算出</em> </strong> <a class="ae mf" href="https://medium.com/towards-data-science/balancing-bias-and-variance-to-control-errors-in-machine-learning-16ced95724db" rel="noopener"> <strong class="ka jc"> <em class="md">准确度</em> </strong> </a> <strong class="ka jc"> <em class="md">每拆分一次将花费我们多少，使用函数</em> </strong>。<strong class="ka jc"> <em class="md">选择成本最低的拆分</em> </strong>，在我们的例子中是乘客的性别。该<strong class="ka jc"> <em class="md">算法本质上是递归的</em> </strong>，因为形成的组可以使用相同的策略细分。由于这个过程，这个算法也被称为<strong class="ka jc">贪婪算法</strong>，因为我们有降低成本的过度欲望。<strong class="ka jc">这使得根节点成为最佳预测器/分类器。</strong></p><h2 id="22e7" class="kw kx jb bd ky kz la dn lb lc ld dp le kj lf lg lh kn li lj lk kr ll lm ln lo bi translated">拆分的成本</h2><p id="f68e" class="pw-post-body-paragraph jy jz jb ka b kb lp kd ke kf lq kh ki kj lr kl km kn ls kp kq kr lt kt ku kv ij bi translated">让我们仔细看看用于分类和回归的<strong class="ka jc">成本函数</strong>。在这两种情况下，成本函数试图<strong class="ka jc">找到最相似的分支，或者具有相似响应的组的分支</strong>。这使得我们可以更确定一个测试数据的输入会遵循一定的路径。</p><blockquote class="mg"><p id="e189" class="mh mi jb bd mj mk ml mm mn mo mp kv dk translated">回归:总和(y-预测)</p></blockquote><p id="716a" class="pw-post-body-paragraph jy jz jb ka b kb mq kd ke kf mr kh ki kj ms kl km kn mt kp kq kr mu kt ku kv ij bi translated">比方说，我们正在预测房价。现在，决策树将通过考虑训练数据中的每个特征来开始分裂。特定组的训练数据输入的响应的平均值被认为是对该组的预测。上述函数应用于所有数据点，并计算所有候选分割的成本。<em class="md">再次选择最低成本的分割</em>。另一个成本函数涉及标准偏差的减少，更多信息可在<a class="ae mf" href="http://www.saedsayad.com/decision_tree_reg.htm" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><blockquote class="mg"><p id="aeba" class="mh mi jb bd mj mk ml mm mn mo mp kv dk translated">分类:G =总和(PK *(1-PK))</p></blockquote><p id="b762" class="pw-post-body-paragraph jy jz jb ka b kb mq kd ke kf mr kh ki kj ms kl km kn mt kp kq kr mu kt ku kv ij bi translated">基尼系数通过分裂产生的群体中反应类别的混合程度，给出了分裂有多好的概念。这里，pk 是特定组中同类输入的比例。当一个组包含来自同一类的所有输入时，出现完美的类纯度，在这种情况下，pk 为 1 或 0，G = 0，其中一个组中具有 50-50 个类的节点具有最差的纯度，因此对于二进制分类，它将具有 pk = 0.5 和 G = 0.5。</p><h2 id="0716" class="kw kx jb bd ky kz la dn lb lc ld dp le kj lf lg lh kn li lj lk kr ll lm ln lo bi translated">什么时候停止分裂？</h2><p id="079c" class="pw-post-body-paragraph jy jz jb ka b kb lp kd ke kf lq kh ki kj lr kl km kn ls kp kq kr lt kt ku kv ij bi translated">你可能会问<strong class="ka jc"> <em class="md">什么时候停止种一棵树？</em> </strong>作为一个问题通常有一个大的特征集，它导致大量的分裂，进而产生一棵巨大的树。这样的树<em class="md">很复杂，会导致过度拟合。</em>所以，我们需要知道什么时候停止？一种方法是<strong class="ka jc">设置在每片叶子上使用的最小数量的训练输入。</strong>例如，我们可以使用最少 10 名乘客来做出决定(死亡或幸存)，并忽略任何少于 10 名乘客的叶子。另一种方法是设置模型的最大深度。<strong class="ka jc">最大深度是指从根到叶子的最长路径的长度。</strong></p><h2 id="c890" class="kw kx jb bd ky kz la dn lb lc ld dp le kj lf lg lh kn li lj lk kr ll lm ln lo bi translated">修剪</h2><p id="4770" class="pw-post-body-paragraph jy jz jb ka b kb lp kd ke kf lq kh ki kj lr kl km kn ls kp kq kr lt kt ku kv ij bi translated">一棵树的性能可以通过<strong class="ka jc"> <em class="md">修剪</em> </strong>进一步提升。<em class="md">它包括</em> <strong class="ka jc"> <em class="md">去除利用低重要性特征的分支</em> </strong>。这样，我们降低了树的复杂性，从而通过减少过度拟合来提高其预测能力。</p><p id="63ec" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">修剪可以从根部开始，也可以从叶子开始。最简单的修剪方法是从叶子开始，删除叶子中最受欢迎的类的每个节点，如果这种改变不会降低精确度，则保留这种改变。它也被称为<strong class="ka jc">减少错误修剪</strong>。可以使用更复杂的修剪方法，例如<strong class="ka jc">成本复杂性修剪</strong>，其中使用学习参数(α)来衡量是否可以基于子树的大小移除节点。这也被称为<strong class="ka jc">最弱链接修剪。</strong></p><h2 id="b3cf" class="kw kx jb bd ky kz la dn lb lc ld dp le kj lf lg lh kn li lj lk kr ll lm ln lo bi translated">手推车的优势</h2><ul class=""><li id="03dd" class="mv mw jb ka b kb lp kf lq kj mx kn my kr mz kv na nb nc nd bi translated">易于理解、解释和形象化。</li><li id="3dce" class="mv mw jb ka b kb ne kf nf kj ng kn nh kr ni kv na nb nc nd bi translated">决策树<em class="md">隐含地执行变量筛选或特征选择。</em></li><li id="90ee" class="mv mw jb ka b kb ne kf nf kj ng kn nh kr ni kv na nb nc nd bi translated"><em class="md">能处理数字和分类数据吗</em>。也可以<em class="md">处理多输出问题。</em></li><li id="a6e2" class="mv mw jb ka b kb ne kf nf kj ng kn nh kr ni kv na nb nc nd bi translated">决策树需要用户相对较少的努力来准备数据。</li><li id="a36b" class="mv mw jb ka b kb ne kf nf kj ng kn nh kr ni kv na nb nc nd bi translated"><em class="md">参数之间的非线性关系不影响采油树性能。</em></li></ul><h2 id="c608" class="kw kx jb bd ky kz la dn lb lc ld dp le kj lf lg lh kn li lj lk kr ll lm ln lo bi translated"><strong class="ak">推车的缺点</strong></h2><ul class=""><li id="e7ed" class="mv mw jb ka b kb lp kf lq kj mx kn my kr mz kv na nb nc nd bi translated">决策树学习者<em class="md">可以创建不能很好概括数据的过于复杂的树</em>。这叫做<em class="md">过拟合</em>。</li><li id="5800" class="mv mw jb ka b kb ne kf nf kj ng kn nh kr ni kv na nb nc nd bi translated">决策树可能不稳定，因为数据的微小变化可能导致生成完全不同的树。这就是所谓的<a class="ae mf" href="https://medium.com/towards-data-science/balancing-bias-and-variance-to-control-errors-in-machine-learning-16ced95724db" rel="noopener"> <em class="md">方差</em> </a>，需要通过 <em class="md">套袋、</em> <a class="ae mf" rel="noopener" target="_blank" href="/boosting-the-accuracy-of-your-machine-learning-models-f878d6a2d185"> <strong class="ka jc"> <em class="md">升压</em> </strong> </a>等方法降低<em class="md">。</em></li><li id="bb1e" class="mv mw jb ka b kb ne kf nf kj ng kn nh kr ni kv na nb nc nd bi translated">贪婪算法不能保证返回全局最优的决策树。这可以通过训练多个树来减轻，其中特征和样本通过替换被随机采样。</li><li id="1876" class="mv mw jb ka b kb ne kf nf kj ng kn nh kr ni kv na nb nc nd bi translated">决策树学习者创建<em class="md"> </em> <a class="ae mf" href="https://medium.com/towards-data-science/balancing-bias-and-variance-to-control-errors-in-machine-learning-16ced95724db" rel="noopener"> <em class="md">偏向</em> </a> <em class="md">的树如果某些职业支配</em>。因此，建议在拟合决策树之前平衡数据集。</li></ul><p id="66fe" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这都是基本的，让你和决策树学习一样。使用<strong class="ka jc">提升</strong> 的<a class="ae mf" rel="noopener" target="_blank" href="/boosting-the-accuracy-of-your-machine-learning-models-f878d6a2d185">技术对决策树学习进行了改进。实现这些算法的一个流行库是</a><a class="ae mf" href="https://becominghuman.ai/implementing-decision-trees-using-scikit-learn-5057b27221ec" rel="noopener ugc nofollow" target="_blank"> <strong class="ka jc"> Scikit-Learn </strong> </a>。它有一个很棒的 api，只需几行 python 代码就能让你的模型运行起来。</p></div><div class="ab cl nj nk hu nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="ij ik il im in"><p id="e979" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你喜欢这篇文章，一定要点击下面的❤推荐它，如果你有任何问题，<strong class="ka jc">留下评论</strong>，我会尽力回答。</p><p id="7050" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了更加了解机器学习的世界，<strong class="ka jc">跟我来</strong>。这是最好的办法，等我多写点这样的文章就知道了。</p><p id="ddff" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">也可以在<a class="ae mf" href="https://twitter.com/Prashant_1722" rel="noopener ugc nofollow" target="_blank"> <strong class="ka jc">推特</strong> </a>，<a class="ae mf" href="mailto:pr.span24@gmail.com" rel="noopener ugc nofollow" target="_blank"> <strong class="ka jc">直接发邮件给我</strong> </a>或者<a class="ae mf" href="https://www.linkedin.com/in/prashantgupta17/" rel="noopener ugc nofollow" target="_blank"> <strong class="ka jc">在 linkedin </strong> </a>上找我。我很乐意收到你的来信。</p><p id="17f7" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">乡亲们，祝你们有美好的一天:)</p></div></div>    
</body>
</html>