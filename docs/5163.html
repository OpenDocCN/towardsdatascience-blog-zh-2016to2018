<html>
<head>
<title>Classification on a large and noisy dataset with R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于 R 的大规模噪声数据集的分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/classification-on-a-large-and-noisy-dataset-with-r-c10cf14cbae6?source=collection_archive---------6-----------------------#2018-10-01">https://towardsdatascience.com/classification-on-a-large-and-noisy-dataset-with-r-c10cf14cbae6?source=collection_archive---------6-----------------------#2018-10-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><p id="b485" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">几天前，我写了一篇文章，描述了一个全面的监督学习工作流程，使用 caret 和 caretEnsemble 包进行多种建模。当时我提到我使用的是一种简单的<em class="kp">T4，在某种意义上，它是全数字的，完全填充的(没有一个缺失值)，没有分类特征，没有类别不平衡(当然，因为这是一个回归问题)，并且它是一个相当小的数据集，只有 8 个预测值。</em></p><p id="5a65" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这感觉就像是作弊，但它确实帮助了我写的第一篇文章，也帮助我顺利地完成了整个工作流程，并最终使用<code class="fe kq kr ks kt b">caretEnsemble.</code>做了一些多重建模</p><p id="d3fb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">所以现在我决定把这个从<em class="kp">简单</em>难度提升到<em class="kp">普通</em>难度。</p><p id="732d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这种意义上，我在我打算使用的<a class="ae ko" href="https://archive.ics.uci.edu/ml/index.php" rel="noopener ugc nofollow" target="_blank"> UCI 机器学习库</a>中遇到了<a class="ae ko" href="https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks" rel="noopener ugc nofollow" target="_blank">这个数据集</a>。</p><p id="13d5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们在这个数据集上遇到的新困难是什么？我来总结一下:</p><ol class=""><li id="a1f8" class="ku kv it js b jt ju jx jy kb kw kf kx kj ky kn kz la lb lc bi translated">目标变量是分类二项式的，具有非常高的类别不平衡</li><li id="e8e1" class="ku kv it js b jt ld jx le kb lf kf lg kj lh kn kz la lb lc bi translated">数据集的大小相当大。训练集是 60，000 x 171，测试集是 16，000 x 171</li><li id="7259" class="ku kv it js b jt ld jx le kb lf kf lg kj lh kn kz la lb lc bi translated">巨大的价值缺失问题</li><li id="5e41" class="ku kv it js b jt ld jx le kb lf kf lg kj lh kn kz la lb lc bi translated">异常值和多重共线性的潜在存在</li><li id="afd9" class="ku kv it js b jt ld jx le kb lf kf lg kj lh kn kz la lb lc bi translated">第一类错误和第二类错误都有特定的成本，这就要求我们尽量减少第二类错误。</li></ol><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi li"><img src="../Images/93d10db493570a2bc1f8bc94a497388d.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*McCPAzyK4nk73-Tn5JITcA.jpeg"/></div></figure><p id="d2c8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是存储库所有者对数据集和任务的描述:</p><p id="ccf0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="kp">“数据集包含从日常使用的重型斯堪尼亚卡车上收集的数据。重点介绍的系统是空气压力系统(APS ),它产生压缩空气，用于卡车的各种功能，如制动和换档。数据集的正类包括 APS 系统特定组件的组件故障。负类包括与 APS 无关的部件出现故障的卡车。这些数据由专家选择的所有可用数据的子集组成。</em></p><p id="b522" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="kp">出于专有原因，数据的属性名称已被匿名化。它由单个数字计数器和直方图组成，直方图由不同条件的仓组成。(…)总共有 171 个属性，其中 7 个是直方图变量。缺失值用“na”表示。</em></p><p id="9134" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="kp"> —挑战指标</em></p><p id="a51c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="kp">失误分类的成本度量:</em></p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi lq"><img src="../Images/6dcfe058b06f4d7763c45335da5e9b0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*Fn7IlpHOZSDlL6FZe0eaPg.png"/></div></figure><p id="e326" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><em class="kp">在这种情况下，成本 _1 指的是需要由一名机械师在车间进行不必要检查的成本，而成本 _2 指的是遗漏一辆故障卡车的成本，这可能会导致故障。</em></p><p id="c2df" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated"><code class="fe kq kr ks kt b"><em class="kp">Total_cost = Cost_1 * No_Instances + Cost_2 * No_Instances</em></code></p><p id="5ec9" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们会试试看！</p><h2 id="92b5" class="lr ls it bd lt lu lv dn lw lx ly dp lz kb ma mb mc kf md me mf kj mg mh mi mj bi translated">环境</h2><blockquote class="mk ml mm"><p id="1891" class="jq jr kp js b jt ju jv jw jx jy jz ka mn kc kd ke mo kg kh ki mp kk kl km kn im bi translated">1.1)我们试图预测什么？</p></blockquote><p id="6bb3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们需要预测系统故障的类型。它可以是<em class="kp"> APS </em>的故障组件，也可以是与<em class="kp"> APS </em>无关的故障组件。这一点非常重要，因为我们的预测误差会导致公司不必要的支出。具体来说，我们希望避免<em class="kp">类型 2 错误(错过故障卡车的成本，这可能会导致故障)</em>。</p><blockquote class="mk ml mm"><p id="9dc0" class="jq jr kp js b jt ju jv jw jx jy jz ka mn kc kd ke mo kg kh ki mp kk kl km kn im bi translated">2.2)这是什么类型的问题？监督学习还是非监督学习？分类还是回归？二元还是多类？单变量还是多变量？</p></blockquote><p id="c1aa" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这是一个具有多个特征的二元分类问题。</p><blockquote class="mk ml mm"><p id="689d" class="jq jr kp js b jt ju jv jw jx jy jz ka mn kc kd ke mo kg kh ki mp kk kl km kn im bi translated">2.3)我们有什么类型的数据？</p></blockquote><p id="9fd3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们有两个<em class="kp"> csv </em>文件，一个用于培训，一个用于测试。在实际数据开始之前，两者都显示了 20 个不重要的文本行，我们必须在导入数据框时跳过这些行。列名有一行，缺少的值用“na”表示，因此我们将确保在<em class="kp">读取</em>CSV 时包含这些值。</p><p id="8e25" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">2.4)导入数据集</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="faf5" class="lr ls it kt b gy mu mv l mw mx">training_data &lt;- read.csv("aps_failure_traning_set.csv",<br/>                          skip = 20, <br/>                          na.strings = "na")</span><span id="090c" class="lr ls it kt b gy my mv l mw mx">test_data &lt;- read.csv("aps_failure_test_set.csv",<br/>                      skip = 20, <br/>                      na.strings = "na")</span></pre><p id="be50" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们检查两个数据集的维度:</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="6abc" class="lr ls it kt b gy mu mv l mw mx">dim(training_data)<br/>dim(test_data)</span><span id="22d1" class="lr ls it kt b gy my mv l mw mx">[1] 60000   171<br/>[1] 16000   171</span></pre><blockquote class="mk ml mm"><p id="9c2e" class="jq jr kp js b jt ju jv jw jx jy jz ka mn kc kd ke mo kg kh ki mp kk kl km kn im bi translated">2.5)激活项目期间要使用的包</p></blockquote><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="fc97" class="lr ls it kt b gy mu mv l mw mx">library(dplyr)<br/>library(caret)<br/>library(caretEnsemble)<br/>library(mice)<br/>library(doParallel)<br/>library(car)</span></pre><h2 id="87a9" class="lr ls it bd lt lu lv dn lw lx ly dp lz kb ma mb mc kf md me mf kj mg mh mi mj bi translated">探索性数据分析</h2><blockquote class="mk ml mm"><p id="1fca" class="jq jr kp js b jt ju jv jw jx jy jz ka mn kc kd ke mo kg kh ki mp kk kl km kn im bi translated">2.1)查看数据(str 或 dplyr 的一瞥)。第一眼。有什么奇怪的吗？</p></blockquote><p id="b440" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">导入集合时指定<code class="fe kq kr ks kt b">na.strings=”na"</code>允许 R 将每个特性识别为数字。如果我们不这样做，每列中出现的<em class="kp"> na </em>会自动导致它们被归类为<em class="kp">字符</em>类型。</p><p id="9014" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">使用下面的代码，我们可以看到除了我们的响应变量<code class="fe kq kr ks kt b">class</code>，所有其他的特性都是数字的。</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="64f1" class="lr ls it kt b gy mu mv l mw mx">glimpse(training_data)</span><span id="6c0c" class="lr ls it kt b gy my mv l mw mx">glimpse(test_data)</span></pre><blockquote class="mk ml mm"><p id="f232" class="jq jr kp js b jt ju jv jw jx jy jz ka mn kc kd ke mo kg kh ki mp kk kl km kn im bi translated">2.2)它是一个“整洁”的数据集吗？需要“聚集”还是“分散”呢？它是以一种我们可以合作的方式呈现的吗？</p></blockquote><p id="a4ad" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">很整洁。每行是一个观察值，每列是一个特征。</p><blockquote class="mk ml mm"><p id="2ad3" class="jq jr kp js b jt ju jv jw jx jy jz ka mn kc kd ke mo kg kh ki mp kk kl km kn im bi translated">2.3)行名和列名可以吗？我们应该改变他们吗？</p></blockquote><p id="0135" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我看不出有什么理由要改变它们。</p><blockquote class="mk ml mm"><p id="f7de" class="jq jr kp js b jt ju jv jw jx jy jz ka mn kc kd ke mo kg kh ki mp kk kl km kn im bi translated">2.4)检查数据类型。他们还好吗？如果没有，转换</p></blockquote><p id="4c59" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们已经评估过数据类型是可以的。在这里，您还需要检查响应变量是否属于 factor 类型，以及预期的两个级别。</p><blockquote class="mk ml mm"><p id="0c6c" class="jq jr kp js b jt ju jv jw jx jy jz ka mn kc kd ke mo kg kh ki mp kk kl km kn im bi translated">2.5)我们的响应/目标变量是什么？阶层失衡？研究一下</p></blockquote><p id="c212" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们的目标变量是<code class="fe kq kr ks kt b">class</code>，有两个级别:<em class="kp"> neg </em>和<em class="kp"> pos </em>。积极类包括 APS 系统特定组件的组件故障。负类包括与 APS 无关的部件出现故障的卡车。</p><p id="6932" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">每组有多少个<em class="kp">阴性</em>和<em class="kp">阳性</em>？</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="c776" class="lr ls it kt b gy mu mv l mw mx">summary(training_data$class)<br/>summary(test_data$class)</span><span id="6501" class="lr ls it kt b gy my mv l mw mx"><strong class="kt iu">  neg   pos <br/>59000  1000 <br/>  neg   pos <br/>15625   375</strong></span></pre><p id="7298" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们检查一下比例:</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="5efa" class="lr ls it kt b gy mu mv l mw mx">options(digits = 2)</span><span id="8b41" class="lr ls it kt b gy my mv l mw mx">prop.table(table(training_data$class))<br/>prop.table(table(test_data$class))</span><span id="e873" class="lr ls it kt b gy my mv l mw mx"><strong class="kt iu">neg   pos <br/>0.983 0.017</strong></span><span id="6e25" class="lr ls it kt b gy my mv l mw mx"><strong class="kt iu">neg   pos <br/>0.977 0.023</strong></span></pre><p id="2490" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">好吧，看起来这里有个问题。阶级完全不平衡。</p><p id="de60" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可能会想出一个无用的模型，将每个观察结果分类为<em class="kp">阴性</em>并获得 97.7%的准确性，所以让我们小心我们的准确性分数解释。</p><p id="2188" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">稍后我们会看到我们如何处理阶级不平衡。</p><blockquote class="mk ml mm"><p id="651d" class="jq jr kp js b jt ju jv jw jx jy jz ka mn kc kd ke mo kg kh ki mp kk kl km kn im bi translated">2.6)其余功能。汇总统计数据。了解您的数据</p></blockquote><p id="8982" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们正在处理 171 个特征，所以在整个数据集上调用<code class="fe kq kr ks kt b">summary()</code>在视觉解释方面不会有太大帮助。相反，我们将使用<code class="fe kq kr ks kt b">summary()</code>函数创建一个数据框。这将使我们能够计算一些新的统计数据，特别是与缺失值相关的统计数据，正如您将看到的，这是该数据的另一个大问题。</p><p id="11b6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">利用这个汇总数据框架，我们还将计算所有数据的平均四分位数。这也将允许我们了解更多关于特征的分布和丢失值的平均数。</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="7a0c" class="lr ls it kt b gy mu mv l mw mx">options(scipen = 999)</span><span id="bfaa" class="lr ls it kt b gy my mv l mw mx"><strong class="kt iu">summary_df </strong>&lt;- do.call(cbind, lapply(training_data[, <br/>                      2:ncol(training_data)], summary))<br/><strong class="kt iu">summary_df_t </strong>&lt;- as.data.frame(round(t(summary_df),0))</span><span id="2eed" class="lr ls it kt b gy my mv l mw mx"><strong class="kt iu">names</strong>(summary_df_t)[7] &lt;- paste("Missing_values")</span><span id="0fe4" class="lr ls it kt b gy my mv l mw mx">summary_df_t_2 &lt;- summary_df_t %&gt;% <br/>                      mutate(obs = nrow(training_data),<br/>                             Missing_prop = Missing_values / obs)</span><span id="d817" class="lr ls it kt b gy my mv l mw mx">print(summary_df_t_2)</span></pre><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mz"><img src="../Images/ed28aa38b8f021a4d8454c0ea7f8062d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5LSps5ZXmY-Sn1uk8APbQg.png"/></div></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">Each row is a feature. In this case we are just looking at the first 10 features</figcaption></figure><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="2ab8" class="lr ls it kt b gy mu mv l mw mx">summary_df_t_2 %&gt;% summarise(Min = mean(Min.),<br/>                             first_Q = mean(`1st Qu.`),<br/>                             Median = median(Median),<br/>                             Mean = mean(Mean),<br/>                             third_Q = mean(`3rd Qu.`),<br/>                             Max = max(Max.),<br/>                             mean_MV = mean(Missing_values),<br/>                             obs = mean(obs),<br/>                             mean_MV_perc = mean_MV / obs)</span></pre><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mz"><img src="../Images/ea3bf7f60c8047aeec70ce83c65b53df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HjShsSUIN7T3UafIrtYFLg.png"/></div></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">Summary of all features using the mean of each column</figcaption></figure><p id="44e0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们可以看到，在 60，000 个样本中，每个特征的平均缺失值数为 5，000。这意味着每列平均有 8.3%的缺失值。太多了！</p><p id="92c4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们对我们的测试集进行同样的检查:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi ni"><img src="../Images/691a88e1d4b81151ea8bf81a66183a0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N-5d4xm9Pe0FpEV1knmJuA.png"/></div></div></figure><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nj"><img src="../Images/63a6a74ec4819f248891778ec80d8d1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L-QNpS7FTWShnp-28v2hUA.png"/></div></div></figure><p id="3d83" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">同样，我们还有 8.4%的缺失值。我们将不得不处理他们，之后会有一个特别的部分。</p><blockquote class="mk ml mm"><p id="f68c" class="jq jr kp js b jt ju jv jw jx jy jz ka mn kc kd ke mo kg kh ki mp kk kl km kn im bi translated">2.7)分类数据/因素:创建计数表以了解不同的类别。全部检查一下。</p></blockquote><p id="132d" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">除了我们的响应变量，我们不使用任何其他分类特征。</p><blockquote class="mk ml mm"><p id="eb97" class="jq jr kp js b jt ju jv jw jx jy jz ka mn kc kd ke mo kg kh ki mp kk kl km kn im bi translated">2.8)不必要的列？我们可以很快理解我们不需要的列。放下它们</p></blockquote><p id="f899" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">到目前为止，我们还没有检测到任何要删除的列。这个我们以后再说。</p><blockquote class="mk ml mm"><p id="4e2e" class="jq jr kp js b jt ju jv jw jx jy jz ka mn kc kd ke mo kg kh ki mp kk kl km kn im bi translated">2.9)检查是否有缺失值。多少？在哪里？删除它们？归咎于他们？</p></blockquote><p id="fb47" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们的特征平均存在超过 8%的缺失值。</p><p id="f1dd" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因为我们不想失去很多信息，所以我们的方法是<a class="ae ko" href="https://en.wikipedia.org/wiki/Imputation_(statistics)" rel="noopener ugc nofollow" target="_blank">估算</a>它们。但是首先，我们不想使用一种技术来分别估算我们的两个集合(训练和测试)。它必须是使用全部信息的一次性估算。为了做到这一点，我们将结合这两个集合，对它们进行处理，然后再次分离。</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="4cd2" class="lr ls it kt b gy mu mv l mw mx">#replicate our sets<br/>training_data_bind &lt;- training_data<br/>test_data_bind &lt;- test_data</span><span id="77cc" class="lr ls it kt b gy my mv l mw mx">#create a new column "set" to label the observations<br/>training_data_bind$set &lt;- "TRAIN"<br/>test_data_bind$set &lt;- "TEST"</span><span id="04f5" class="lr ls it kt b gy my mv l mw mx">#merge them into 1 single set<br/>full_dataset &lt;- rbind(training_data_bind, test_data_bind)<br/>dim(full_dataset)</span><span id="ca76" class="lr ls it kt b gy my mv l mw mx">[1] 76000   172</span></pre><p id="3a87" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们最终得到包含 76，000 个样本的单个集合(16，000 个来自测试集，60，000 个来自训练集)。列数为 172 (171 个功能+ 1 个“设置”列)</p><blockquote class="mk ml mm"><p id="2071" class="jq jr kp js b jt ju jv jw jx jy jz ka mn kc kd ke mo kg kh ki mp kk kl km kn im bi translated">缺失值插补</p></blockquote><p id="e9a4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们将使用包<em class="kp">鼠标</em>来估算缺失值。这里有一个关于鼠标如何工作的很好的解释</p><p id="83a1" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">下面的公式允许我们使用<em class="kp">均值</em>插补来插补整个数据集:</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="bee4" class="lr ls it kt b gy mu mv l mw mx">set.seed(123)<br/>imputed_full &lt;- mice(full_dataset, <br/>                     m=1, <br/>                     maxit = 5, <br/>                     method = "mean", <br/>                     seed = 500)</span></pre><p id="9889" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们存储估算值:</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="f1d7" class="lr ls it kt b gy mu mv l mw mx">full_imputed &lt;- complete(imputed_full, 1)</span></pre><p id="99a4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，我们检查是否仍然保持相同的尺寸:</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="8ccc" class="lr ls it kt b gy mu mv l mw mx">dim(full_imputed)</span><span id="d5c0" class="lr ls it kt b gy my mv l mw mx">[1] 76000   172</span></pre><p id="3ee5" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在让我们检查我们没有丢失值:</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="fc44" class="lr ls it kt b gy mu mv l mw mx">(na_count_full_imputed &lt;-data.frame(sapply(full_imputed, function(y) sum(length(which(is.na(y)))))))</span></pre><p id="e773" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">等等。如果您运行该代码并查看每一行，您会注意到有些特性仍然缺少值。具体来说有 9 行。</p><p id="890e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们来看看是什么导致了它们:</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="ad35" class="lr ls it kt b gy mu mv l mw mx">issue_columns &lt;- subset(imputed_full$loggedEvents, <br/>                        meth == "constant" | meth == "collinear")<br/>print(issue_columns)</span></pre><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi nk"><img src="../Images/3fb60d324228b22db12aa14e226e7fdd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*QOeAiI4-f0diQLMQoxpxig.png"/></div></figure><p id="69e6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我过滤了估算数据框的<code class="fe kq kr ks kt b">$loggedEvents</code>属性。这里我们看到一些特征被标记为<em class="kp">常数</em>或<em class="kp">共线</em>。其中一个是我们的<em class="kp">集合</em>列(我们用来把两个集合合二为一的那个)，所以我们不担心那个。其余的主要是共线变量和一个常量变量。鼠标会自动跳过这些栏，让我们知道问题。我们希望删除这些要素，这样我们就有了一个完整的数据集，不会丢失任何值。</p><p id="e9c8" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">为此，我们首先存储列名，注意不要存储<em class="kp">集合的</em>列名(我们需要它)</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="6ccf" class="lr ls it kt b gy mu mv l mw mx">#create vector of column names<br/>issue_columns_names &lt;- as.character(issue_columns[, "out"])<br/>issue_columns_names &lt;- issue_columns_names[-2]<br/>print(issue_columns_names)</span><span id="0e24" class="lr ls it kt b gy my mv l mw mx">[1] "cd_000" "bt_000" "ah_000" "bu_000" "bv_000" "cq_000" "cf_000" "co_000"</span></pre><p id="89ec" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">然后，我们使用存储的向量从数据框中移除这些列，并将其存储为最终的估算数据框:</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="bc51" class="lr ls it kt b gy mu mv l mw mx">full_imputed_filtered &lt;- full_imputed[ , !(names(full_imputed) %in% <br/>                                      issue_columns_names)]<br/>dim(full_imputed_filtered)</span><span id="683f" class="lr ls it kt b gy my mv l mw mx">[1] 76000   164</span></pre><p id="58f2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意，列数从 172 减少到了 164。</p><p id="7a3e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">现在我们不再有缺失值了！(查一下！)</p><p id="b6dc" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">最后，是时候将我们的完整估算数据集再次分成训练集和测试集，我们需要将其分成与之前完全相同的样本。为此，我们只需使用我们的<em class="kp"> set </em>列过滤数据帧。</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="c3a8" class="lr ls it kt b gy mu mv l mw mx">#subset the full_imputed_filtered dataset<br/>training_data_imp &lt;- subset(full_imputed_filtered, set == "TRAIN")<br/>test_data_imp &lt;- subset(full_imputed_filtered, set == "TEST")</span><span id="2733" class="lr ls it kt b gy my mv l mw mx">#drop the "set" column, we don't need it anymore<br/>training_data_imp$set &lt;- NULL<br/>test_data_imp$set &lt;- NULL</span><span id="f71d" class="lr ls it kt b gy my mv l mw mx">#check dimensions<br/>dim(training_data_imp)<br/>dim(test_data_imp)</span><span id="496c" class="lr ls it kt b gy my mv l mw mx">[1] 60000   163<br/>[1] 16000   163</span></pre><p id="7a38" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">太好了！，我们有我们的训练和测试集分裂，没有丢失值！</p><blockquote class="mk ml mm"><p id="d949" class="jq jr kp js b jt ju jv jw jx jy jz ka mn kc kd ke mo kg kh ki mp kk kl km kn im bi translated">2.10)检查异常值和其他不一致的数据点。箱线图。厨师的距离。DBSCAN？</p></blockquote><p id="386c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于该数据集，我们将使用<a class="ae ko" href="https://en.wikipedia.org/wiki/Cook%27s_distance" rel="noopener ugc nofollow" target="_blank">库克距离</a>:</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="173f" class="lr ls it kt b gy mu mv l mw mx">cooksd &lt;- cooks.distance(glm(class ~ ., <br/>                             family = "binomial", <br/>                             data = training_data_imp))</span></pre><p id="dbc6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们画出结果:</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="dd6b" class="lr ls it kt b gy mu mv l mw mx">plot(cooksd, <br/>     pch="*", <br/>     cex=2, <br/>     main="Influential Obs by Cooks distance")  </span><span id="3ffc" class="lr ls it kt b gy my mv l mw mx">abline(h = 4*mean(cooksd, na.rm=T), col="red")</span></pre><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi nl"><img src="../Images/83643c931e0d7ae39bdccbd93c57c167.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*Ag5b4wBE1bMvRXwtN6X71g.png"/></div></figure><p id="797c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">在这个图中，看似一条又黑又粗的黑线，实际上是我们所有的数据点。在右上角，我们还可以看到似乎有 1 个异常值，或者一堆异常值组合在一起。</p><p id="c17c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">让我们看看有多少:</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="5c37" class="lr ls it kt b gy mu mv l mw mx">outliers &lt;- rownames(training_data_imp[cooksd &gt; 4*mean(cooksd, na.rm=T), ])<br/>print(outliers)</span><span id="170c" class="lr ls it kt b gy my mv l mw mx">[1] "617"   "3993"  "5349"  "10383" "10829" "18764" "19301" "21138" "22787" "24360" "24975" "29146" "30633" "33684"<br/>[15] "38785" "45978" "50283" "51003" "52573" "53283" "54957" "57186"</span></pre><p id="42a0" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">根据 cook 的距离测试，总共有 22 个点被认为是异常值。</p><p id="67d6" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">因为与我们的总数 60，000 相比，这是一个非常低的观察值，所以我决定不删除它们。这似乎只是测量中的可变性，而不是实验误差。</p><blockquote class="mk ml mm"><p id="bbb3" class="jq jr kp js b jt ju jv jw jx jy jz ka mn kc kd ke mo kg kh ki mp kk kl km kn im bi translated">2.11)检查数字数据中的多重共线性</p></blockquote><p id="0b2c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">EDA 阶段的最后一步是检查多重共线性。我们已经删除了一些被小鼠检测为共线的列。这里，我们将分析有多少双变量关系具有高相关性，如果比例非常高:</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="5a45" class="lr ls it kt b gy mu mv l mw mx">sum((correlation &gt; 0.5 | correlation &lt; -0.5) &amp; correlation &lt; 1) / (162*162)<br/>[1] 0.12</span><span id="ff62" class="lr ls it kt b gy my mv l mw mx">sum((correlation &gt; 0.7 | correlation &lt; -0.7) &amp; correlation &lt; 1) / (162*162)<br/>[1] 0.047</span><span id="58ad" class="lr ls it kt b gy my mv l mw mx">sum((correlation &gt; 0.9 | correlation &lt; -0.9) &amp; correlation &lt; 1) / (162*162)<br/>[1] 0.0055</span></pre><p id="c7a2" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">这意味着在 26，244 个可能的变量相关性中:</p><ul class=""><li id="cab7" class="ku kv it js b jt ju jx jy kb kw kf kx kj ky kn nm la lb lc bi translated">12%的人得分高于 0.5</li><li id="70d5" class="ku kv it js b jt ld jx le kb lf kf lg kj lh kn nm la lb lc bi translated">比 0.7 高 4.7%</li><li id="edd5" class="ku kv it js b jt ld jx le kb lf kf lg kj lh kn nm la lb lc bi translated">比 0.9 高 0.55%</li></ul><p id="ad0c" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我不会做更多的讨论，并且认为多重共线性在这一点上不是一个大问题。</p><h2 id="375d" class="lr ls it bd lt lu lv dn lw lx ly dp lz kb ma mb mc kf md me mf kj mg mh mi mj bi translated">特征工程</h2><p id="f221" class="pw-post-body-paragraph jq jr it js b jt nn jv jw jx no jz ka kb np kd ke kf nq kh ki kj nr kl km kn im bi translated">我们也不会花时间在这个已经加载了大量功能的数据集中设计功能。没有我们可以使用的额外信息。</p><h2 id="cac5" class="lr ls it bd lt lu lv dn lw lx ly dp lz kb ma mb mc kf md me mf kj mg mh mi mj bi translated">系统模型化</h2><p id="43a1" class="pw-post-body-paragraph jq jr it js b jt nn jv jw jx no jz ka kb np kd ke kf nq kh ki kj nr kl km kn im bi translated">我们现在已经为建模准备好了训练和测试数据集。我们估算了缺失值，移除了共线要素，并验证了异常值和多重共线性不是我们应该关注的大问题。</p><p id="614b" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">由于数据的大小，我们将训练一个<em class="kp">逻辑回归</em>模型和一个<em class="kp">朴素贝叶斯</em>模型。与 r <em class="kp"> andom forests </em>、<em class="kp"> SVMs </em>或<em class="kp">梯度推进</em>模型等更先进的算法相比，两者都非常快。</p><p id="371e" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我在这里不是为了赢得比赛，而是为了证明自己有一个可以接受的分数。</p><p id="4205" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我将使用<code class="fe kq kr ks kt b">caretEnsemble</code>的<code class="fe kq kr ks kt b">caretList()</code>在同一时间用相同的重采样来训练两者。</p><p id="ecda" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意，我在<code class="fe kq kr ks kt b">trainControl()</code>中指定了<em class="kp">“上升”——采样</em>。这将解决<em class="kp">等级不平衡</em>。<a class="ae ko" href="https://en.wikipedia.org/wiki/Upsampling" rel="noopener ugc nofollow" target="_blank">关于上采样的更多信息</a>。</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="2ef2" class="lr ls it kt b gy mu mv l mw mx">registerDoParallel(3)<br/>getDoParWorkers()</span><span id="00c7" class="lr ls it kt b gy my mv l mw mx">set.seed(123)</span><span id="ff2e" class="lr ls it kt b gy my mv l mw mx">my_ctrl &lt;- trainControl(method = "cv", <br/>                        number = 5,<br/>                        classProbs = TRUE,<br/>                        savePredictions = "final",<br/>                        index = <br/>                        createResample(training_data_imp$class, 3),<br/>                        sampling = "up",<br/>                        allowParallel = TRUE)</span><span id="ba24" class="lr ls it kt b gy my mv l mw mx"><br/>model_list &lt;- caretList(class ~ .,<br/>                        data = training_data_imp,<br/>                        methodList = c("glm", "nb"),<br/>                        metric = "Kappa",<br/>                        tuneList = NULL,<br/>                        continue_on_fail = FALSE,  <br/>                        preProcess = c("center", "scale"),<br/>                        trControl = my_ctrl)</span></pre><p id="05eb" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">我们的结果:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi ns"><img src="../Images/02159ab003ff178438f18ce32ac6f1ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*r8uhaYoyV2QMfmjkMkQ5fw.png"/></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">Logistic Regression model</figcaption></figure><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/b56d3ea14ba523f9932e8a945b060bf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*FrOKLsFWvvpPf53_U9Pt6Q.png"/></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">Naive Bayes model</figcaption></figure><p id="36f3" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">请注意，我们的<em class="kp">准确性</em>得分低于我们的无用户<strong class="js iu"> <em class="kp">预测全否定</em> </strong> <em class="kp">模型</em>的 97.7%。我们没有获得更高分数的原因是因为我们对数据进行了上采样，从而生成了新的数据点来修复类别不平衡。我们在 caret 的 trainControl 中将其作为一个参数集，所以我不会显示任何细节，但通过这样做，我们提高了预测正类(在这种情况下为“neg”)的能力，而不仅仅是为了最大限度地提高准确性。</p><h2 id="eacd" class="lr ls it bd lt lu lv dn lw lx ly dp lz kb ma mb mc kf md me mf kj mg mh mi mj bi translated">对看不见的(测试)数据的性能</h2><p id="c9d3" class="pw-post-body-paragraph jq jr it js b jt nn jv jw jx no jz ka kb np kd ke kf nq kh ki kj nr kl km kn im bi translated">让我们快速检查一下混淆矩阵:</p><pre class="lj lk ll lm gt mq kt mr ms aw mt bi"><span id="1575" class="lr ls it kt b gy mu mv l mw mx">#Logistic Regression model<br/>confusionMatrix(predict(model_list$glm,test_data_imp, type = "raw"), test_data_imp$class)</span><span id="6e72" class="lr ls it kt b gy my mv l mw mx">#Naive Bayes model<br/>confusionMatrix(predict(model_list$nb,test_data_imp, type = "raw"), test_data_imp$class)</span></pre><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/1c50322519efd43def199179c48187e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*9XzYGFjjdhb7dhzCnPBnEg.png"/></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">Logistic Regression performance on test set</figcaption></figure><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/eaccc2752c47a1795337efdf845831f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*DJs6-f1TA2zZY-w9Hhf-ng.png"/></div><figcaption class="ne nf gj gh gi ng nh bd b be z dk">Naive Bayes performance on test set</figcaption></figure><p id="64db" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">根据每种错误的成本矩阵，我们的得分为:</p><p id="bbf4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">逻辑回归模型:52 x 500 + 834 x 10 = 34，340</p><p id="6be4" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">朴素贝叶斯模型:42 x 500 + 498 x 10 = 25，980</p><p id="8d5f" class="pw-post-body-paragraph jq jr it js b jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn im bi translated">对于这种快速的建模来说，这已经是不错的表现了。我敢打赌，通过更多的努力，我们可以非常接近最佳的 3 名选手:</p><figure class="lj lk ll lm gt ln gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nw"><img src="../Images/edf21e82929107df358d9d607b337b73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PhXdHbRYspY0bKlkr1eiaw.png"/></div></div></figure></div></div>    
</body>
</html>