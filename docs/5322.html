<html>
<head>
<title>Beyond Word Embeddings Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超越单词嵌入第 1 部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/beyond-word-embeddings-part-1-an-overview-of-neural-nlp-milestones-82b97a47977f?source=collection_archive---------6-----------------------#2018-10-11">https://towardsdatascience.com/beyond-word-embeddings-part-1-an-overview-of-neural-nlp-milestones-82b97a47977f?source=collection_archive---------6-----------------------#2018-10-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/5e37704c3c99c4e2d0a2bcbd9a98e3d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*K8eg3bUVu4AG-4FB"/></div></div></figure><div class=""/><p id="7e98" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">神经 NLP 里程碑综述</p><h1 id="081b" class="kw kx jb bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">TLDR；</h1><p id="d2a0" class="pw-post-body-paragraph jy jz jb ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">自从<a class="ae lz" href="https://en.wikipedia.org/wiki/Word2vec" rel="noopener ugc nofollow" target="_blank"> word2vec </a>的出现，神经单词嵌入已经成为在 NLP 应用中封装分布式语义的 goto 方法。本系列将回顾使用预训练单词嵌入的优点和缺点，并演示如何将更复杂的语义表示方案(如语义角色标记、抽象意义表示和语义依赖解析)整合到您的应用程序中。</p><h1 id="1d01" class="kw kx jb bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated"><strong class="ak">神经自然语言处理里程碑</strong></h1><p id="15b3" class="pw-post-body-paragraph jy jz jb ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">在过去的五年里，深度学习的出现在自然语言处理领域带来了一些令人印象深刻的里程碑。</p><p id="e4c3" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">本系列的第一篇文章将重点介绍一些里程碑的例子以及开始使用它们的链接。</p><h2 id="2d3e" class="ma kx jb bd ky mb mc dn lc md me dp lg kj mf mg lk kn mh mi lo kr mj mk ls ml bi translated">共参照分辨率</h2><figure class="mn mo mp mq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mm"><img src="../Images/68d15fa5ffa672fbda5b0e2902dbc82e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e9nc26IacQ8SbUbbAYZPCg.png"/></div></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">Allen NLP Co-Reference resolution</figcaption></figure><p id="d756" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><a class="ae lz" href="http://demo.allennlp.org/coreference-resolution" rel="noopener ugc nofollow" target="_blank">共指消解</a>的任务是找出文本中所有指代同一实体的表达式。对于涉及自然语言理解的核心 NLP 任务，如文档摘要、问题回答和信息提取，这是重要的一步。这个任务的两个最好的可用库是<a class="ae lz" href="https://huggingface.co/coref/" rel="noopener ugc nofollow" target="_blank"> huggingface </a>和<a class="ae lz" href="http://demo.allennlp.org/coreference-resolution" rel="noopener ugc nofollow" target="_blank"> Allen NLP </a>。</p><h2 id="d000" class="ma kx jb bd ky mb mc dn lc md me dp lg kj mf mg lk kn mh mi lo kr mj mk ls ml bi translated"><strong class="ak">情感分析</strong></h2><figure class="mn mo mp mq gt is gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/b01ca9e0554c3bfd9c68375578a8c650.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*kbl2djm1lorKoHTsriVWhQ.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">An example of the <a class="ae lz" href="https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics/?WT.mc_id=blog-medium-abornst" rel="noopener ugc nofollow" target="_blank">Azure Text Analytics</a> service</figcaption></figure><p id="ffe1" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这些模型能够检测给定文本的情感。这种功能对于检测社交媒体、客户评论和论坛中的积极和消极情绪非常有用。在基于云的服务中，如<a class="ae lz" href="https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics/?WT.mc_id=blog-medium-abornst" rel="noopener ugc nofollow" target="_blank"> Azure Text Analytics </a>内容由您提供；模型和训练数据由服务提供。</p><h2 id="2bca" class="ma kx jb bd ky mb mc dn lc md me dp lg kj mf mg lk kn mh mi lo kr mj mk ls ml bi translated">可训练命名实体识别和范围标记</h2><figure class="mn mo mp mq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mw"><img src="../Images/045e70de7ed11ac6e6f42e638e4319b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OR5Ctwd4kLYb-8-7E6L6Qw.png"/></div></div></figure><p id="4218" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">命名实体识别模型从文本中提取实体，如人员、位置、组织和杂项。<a class="ae lz" href="https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics/?WT.mc_id=blog-medium-abornst" rel="noopener ugc nofollow" target="_blank"> Azure Text Analytics </a>提供强大的预训练模型。对于那些喜欢训练自己模型的人来说，<a class="ae lz" href="https://spacy.io/usage/training#section-ner" rel="noopener ugc nofollow" target="_blank"> Spacy </a>和<a class="ae lz" href="http://demo.allennlp.org/named-entity-recognition" rel="noopener ugc nofollow" target="_blank"> Allen NLP </a>都提供了快速训练定制 NER 模型的文档，这些模型可以与<a class="ae lz" href="https://docs.microsoft.com/azure/machine-learning/service/overview-what-is-azure-ml?WT.mc_id=blog-medium-abornst" rel="noopener ugc nofollow" target="_blank"> Azure ML API </a>和<a class="ae lz" href="https://notebooks.azure.com/?WT.mc_id=blog-medium-abornst" rel="noopener ugc nofollow" target="_blank"> Azure 笔记本服务</a>一起使用。</p><h2 id="f5b8" class="ma kx jb bd ky mb mc dn lc md me dp lg kj mf mg lk kn mh mi lo kr mj mk ls ml bi translated">意图分类</h2><figure class="mn mo mp mq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mx"><img src="../Images/d8ab1281d15bc40a0bdbd9584c9cbcfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xk8lZCxgaqpO4_jNNdgF0w.png"/></div></div></figure><p id="ed28" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">意图分类系统旨在识别对话中有价值的信息，如<a class="ae lz" href="https://docs.microsoft.com/azure/cognitive-services/luis/what-is-luis?WT.mc_id=blog-medium-abornst" rel="noopener ugc nofollow" target="_blank"> LUIS 认知服务</a>解释用户目标(意图)并从句子(实体)中提取有价值的信息，以实现高质量、细致入微的语言模型。<a class="ae lz" href="https://docs.microsoft.com/azure/cognitive-services/luis/what-is-luis?WT.mc_id=blog-medium-abornst" rel="noopener ugc nofollow" target="_blank"> LUIS </a>与 Azure Bot 服务无缝集成，轻松创建复杂的 Bot。</p><h2 id="6711" class="ma kx jb bd ky mb mc dn lc md me dp lg kj mf mg lk kn mh mi lo kr mj mk ls ml bi translated"><strong class="ak">机器阅读理解 BiDAF </strong></h2><figure class="mn mo mp mq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi my"><img src="../Images/ac0a31982a76074c6efcd3eed71e7054.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cye3gSEBh298JPSFNNKuog.png"/></div></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">AllenNLP MC Model</figcaption></figure><p id="bc9f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">机器理解</strong> (MC)通过在证据文本内选择答案范围来回答自然语言问题。AllenNLP 工具包提供了以下 MC 可视化，可用于 AllenNLP 中的任何 MC 模型。有关机器阅读理解的更多信息，请参见《入门》,这里有一个很棒的关于<a class="ae lz" href="https://blogs.technet.microsoft.com/machinelearning/2018/04/25/transfer-learning-for-text-using-deep-learning-virtual-machine-dlvm/" rel="noopener ugc nofollow" target="_blank"> Azure DLVM </a>的演示，它包含了一些最新架构的实现，比如 BiDAF、SynNet、OpenNMT 和 Document QA。</p><p id="152f" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka jc">自然语言推理 SLNI 可分解注意力</strong></p><figure class="mn mo mp mq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mz"><img src="../Images/9da1d77523e7193c2f8904f6cdb1654b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cRkEQaXmqaHt-REFFng79g.png"/></div></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">Allen NLP NLI/TE model</figcaption></figure><p id="462c" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">文本蕴涵(TE) 获取一对句子，并预测第一个句子中的事实是否必然隐含第二个句子中的事实。文本蕴涵是信息抽取系统的关键组成部分，通常用于通过确保候选答案包含给定的抽取查询来过滤候选答案。AllenNLP 工具包提供了上述 TE 可视化，可以为您开发的任何 TE 模型运行，也可以为您的应用程序中使用的预训练模型运行。</p><h2 id="f7b5" class="ma kx jb bd ky mb mc dn lc md me dp lg kj mf mg lk kn mh mi lo kr mj mk ls ml bi translated"><strong class="ak">神经翻译 NMT </strong></h2><figure class="mn mo mp mq gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi mv"><img src="../Images/459c713d73606fb600bc98971fef3beb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*jOU77SROM3ONJb1uYJLLUg.png"/></div></div></figure><p id="a105" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">持续改进翻译很重要。然而，自 2010 年代中期以来，SMT 技术的性能改善一直停滞不前。通过利用微软人工智能超级计算机的规模和能力，像<a class="ae lz" href="https://blogs.technet.microsoft.com/machinelearning/2018/04/25/transfer-learning-for-text-using-deep-learning-virtual-machine-dlvm/?WT.mc_id=blog-medium-abornst" rel="noopener ugc nofollow" target="_blank">微软翻译器这样的工具现在提供基于神经的翻译</a>，这使得翻译质量的提高进入了一个新的十年。</p><h2 id="d0f9" class="ma kx jb bd ky mb mc dn lc md me dp lg kj mf mg lk kn mh mi lo kr mj mk ls ml bi translated">抽象单文档摘要</h2><figure class="mn mo mp mq gt is gh gi paragraph-image"><div class="gh gi na"><img src="../Images/29d44cccedbfe97f55748f3b66b995bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*_ZbKBpp1pffT-Byu9Or_Uw.png"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">Example of improvements in neural summarization Abigail See et. all</figcaption></figure><p id="0aa0" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">神经 NLP 也有助于抽象单文档摘要任务中的基准。这项任务使用户能够生成长文档的简短摘要。传统上，这是使用提取方法完成的，提取方法通过从文本中直接引用来生成摘要，但神经 NLP 的进步，如 Abigail See 的<a class="ae lz" href="https://github.com/mjc92/GetToThePoint" rel="noopener ugc nofollow" target="_blank">指针生成器网络</a>已经能够从长文档中创建可理解的简短抽象摘要。</p><h1 id="e23c" class="kw kx jb bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated">行动呼吁</h1><p id="61dd" class="pw-post-body-paragraph jy jz jb ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">下面是开始使用上述工具和模型的一些资源。</p><ul class=""><li id="d642" class="nb nc jb ka b kb kc kf kg kj nd kn ne kr nf kv ng nh ni nj bi translated"><a class="ae lz" href="https://azure.microsoft.com/en-us/services/cognitive-services/text-analytics/?WT.mc_id=blog-medium-abornst" rel="noopener ugc nofollow" target="_blank"><strong class="ka jc">【Azure Text Analytics</strong></a>—Text Analytics API 是一个基于云的服务，提供对原始文本的高级自然语言处理，包括四个主要功能:情感分析、关键短语提取、语言检测和实体链接。</li><li id="f045" class="nb nc jb ka b kb nk kf nl kj nm kn nn kr no kv ng nh ni nj bi translated"><a class="ae lz" href="https://docs.microsoft.com/azure/cognitive-services/luis/what-is-luis?WT.mc_id=blog-medium-abornst" rel="noopener ugc nofollow" target="_blank"> <strong class="ka jc"> Azure LUIS </strong> </a> —基于机器学习的服务，为定制意图分类和基本实体提取构建自然语言。</li><li id="55ea" class="nb nc jb ka b kb nk kf nl kj nm kn nn kr no kv ng nh ni nj bi translated"><a class="ae lz" href="https://allennlp.org/" rel="noopener ugc nofollow" target="_blank"><strong class="ka jc">Allen NLP</strong></a>—Allen NLP 是一个开源的 NLP 研究库，基于 PyTorch 构建，用于开发各种语言任务的最先进的深度学习模型。</li><li id="4490" class="nb nc jb ka b kb nk kf nl kj nm kn nn kr no kv ng nh ni nj bi translated"><a class="ae lz" href="https://blogs.technet.microsoft.com/machinelearning/2018/04/25/transfer-learning-for-text-using-deep-learning-virtual-machine-dlvm/?WT.mc_id=blog-medium-abornst" rel="noopener ugc nofollow" target="_blank"> <strong class="ka jc"> Azure DLVM </strong>机器阅读理解</a>——深度学习虚拟机(Deep Learning Virtual Machine)是数据科学虚拟机(Data Science Virtual Machine，DSVM)的一个特殊配置的变体，可以更直接地使用基于 GPU 的虚拟机实例来训练深度学习模型。DSVM 上有一个很棒的 pyTorch 入门模块，你可以在这里找到<a class="ae lz" href="https://docs.microsoft.com/en-us/learn/modules/interactive-deep-learning/?WT.mc_id=blog-medium-abornst" rel="noopener ugc nofollow" target="_blank"/>。</li><li id="92d4" class="nb nc jb ka b kb nk kf nl kj nm kn nn kr no kv ng nh ni nj bi translated"><a class="ae lz" href="https://spacy.io/" rel="noopener ugc nofollow" target="_blank"><strong class="ka jc">SpaCy</strong></a><strong class="ka jc"/>—SpaCy 是 Python 中自然语言处理的免费开源库。它具有 NER、词性标注、依存句法分析、词向量等功能。</li><li id="52c8" class="nb nc jb ka b kb nk kf nl kj nm kn nn kr no kv ng nh ni nj bi translated"><a class="ae lz" href="https://github.com/huggingface" rel="noopener ugc nofollow" target="_blank"><strong class="ka jc">hugging face</strong></a>——为模型提供空间的扩展，如相互参照和情感分析。</li></ul><h1 id="d6a4" class="kw kx jb bd ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt bi translated"><a class="ae lz" href="https://medium.com/@aribornstein/beyond-word-embeddings-part-2-word-vectors-nlp-modeling-from-bow-to-bert-4ebd4711d0ec" rel="noopener">下一篇文章</a></h1><p id="1189" class="pw-post-body-paragraph jy jz jb ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated"><a class="ae lz" href="https://medium.com/@aribornstein/beyond-word-embeddings-part-2-word-vectors-nlp-modeling-from-bow-to-bert-4ebd4711d0ec" rel="noopener">本系列的下一篇文章</a>将回顾用词向量表示和建模的进步是如何推动上述 NLP 系统的进步的。</p><p id="322e" class="pw-post-body-paragraph jy jz jb ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你有任何问题、评论或话题想让我讨论，请随时在<a class="ae lz" href="https://twitter.com/pythiccoder" rel="noopener ugc nofollow" target="_blank"> Twitter </a>上关注我。如果你觉得我错过了某个里程碑，请让我知道。</p><h2 id="3378" class="ma kx jb bd ky mb mc dn lc md me dp lg kj mf mg lk kn mh mi lo kr mj mk ls ml bi translated"><strong class="ak">关于作者</strong></h2><p id="4e4b" class="pw-post-body-paragraph jy jz jb ka b kb lu kd ke kf lv kh ki kj lw kl km kn lx kp kq kr ly kt ku kv ij bi translated">亚伦(阿里)博恩施泰因(阿里)是一个狂热的人工智能爱好者，对历史充满热情，致力于新技术和计算医学。作为微软云开发倡导团队的开源工程师，他与以色列高科技社区合作，用改变游戏规则的技术解决现实世界的问题，然后将这些技术记录在案、开源并与世界其他地方共享。</p></div></div>    
</body>
</html>