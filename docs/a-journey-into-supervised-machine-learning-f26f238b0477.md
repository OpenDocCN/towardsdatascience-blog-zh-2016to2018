# 监督机器学习之旅

> 原文：<https://towardsdatascience.com/a-journey-into-supervised-machine-learning-f26f238b0477?source=collection_archive---------22----------------------->

![](img/20a0b448240b84f9587e780a0307ce6a.png)

## 关于监督式 ML 的一些实例、提示和想法

今年早些时候，通过我在[康乃尔理工](https://medium.com/u/4731ae5e7942?source=post_page-----f26f238b0477--------------------------------)的 MBA 项目，我和一位了不起的教授[卢茨·芬格](https://medium.com/u/45b13ea8ea40?source=post_page-----f26f238b0477--------------------------------)一起上了一堂很棒的机器学习入门课。Lutz 的课程激励我更深入地挖掘 ML 和 AI，所以我最近在 Udacity 上开始了一个动手操作的[机器学习课程](https://www.udacity.com/course/intro-to-machine-learning--ud120)，我觉得这会很好地增加我的背景。到目前为止，我已经完成了关于监督学习的部分，并希望分享我的初学者对我所学到的东西的看法，并思考这项技术的潜在影响。

*你可以在这里* [的课程/项目中找到我的 python 文件。*相关文件夹*为`choose_your_own, decision_tree, naive_bayes, and svm`](https://github.com/shibby576/data_sandbox/tree/master/Udacity_ML_Course)

## **监督学习概述**

> **监督学习**是机器学习任务，它学习基于示例输入-输出对将输入映射到输出的函数(Stuart J. Russell，Peter Norvig (2010) [*人工智能:一种现代方法*](https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_Approach) *)*

我觉得这个定义相当直观；该算法从“监督”历史动作/数据点中学习以产生输出。在监督机器学习中，有几十种不同的方法，但我最近的研究集中在朴素贝叶斯、支持向量机(SVM)、决策树和随机森林，然后进一步讨论如何在 Python/ [scikit-learn](https://scikit-learn.org/stable/index.html) 中使用这些算法。

我不会在这里重复每种方法的细节，但是如果你想要一个概述，我建议你参加这个课程或者浏览 Google 了解细节。但是，我确实想指出一些重要的经验，以及我如何看待这些经验对我未来发展的影响。

## 监督/课程外卖

与任何数据驱动方法一样，数据质量和结构对受监督模型输出的有用性有着巨大的影响。这并不令人惊讶，但令人惊讶的是，为了改进模型或性能，可以修改传入数据的方式有多种。虽然我没有太深入地研究功能选择/工程，但简单地处理数据量以及测试与训练数据的比例对准确性、性能和潜在的过度拟合有着巨大的影响。

至少从我初学者的角度来看，Scikit-learn (sklearn)非常容易使用。对于每种算法(不包括导入)，只需 4 行代码即可训练、预测和计算模型的精度。这显然也忽略了之前发生的所有数据准备工作以及在初次运行之后发生的调整工作，但是通过这种简单的方式，在同一数据集上运行许多不同的模型是很快的。这使您有机会对同一数据尝试许多不同的模型，帮助您找到解决问题的正确方法。当我把我的工作从 PyCharm 转移到 Jupyter 笔记本电脑时，对同一数据运行许多不同的模型变得更加容易。

通过在同一数据集上创建和运行多个模型的练习，可以很容易地用各种各样的参数调整模型。幸运的是，Sklearn 和 Juypter 的结合使得这个游戏非常容易玩。我也没有使用大量的数据集，所以迭代相当快。正是在这一步，我开始看到经营这些模型的艺术方面。要在准确性、速度和可推广性之间取得适当的平衡，需要调整各种模型和数据方面。就过度拟合数据集的倾向而言，我所研究的每一个模型都有不同的弱点，但每一个都有独特的属性来防止这种情况。例如，使用 SVM，您可以调整 C 和 Gamma 级别以直接平衡分类边界，从而提高准确性和泛化能力。

# 分析文本识别数据

我想在野外发现的数据集上测试我所学的东西，所以我从加州大学欧文分校下载了[字母识别数据集](https://archive.ics.uci.edu/ml/datasets/letter+recognition)以供使用。数据集包含在一个文本文件中，其中包含 16 个代表扫描信件图像的标准化数字特征。然后，它会提供相应的标签。数据集相当简单，试图将这些数据点分类成不同的字母似乎是数据的一个很好的用例。

*从这个分析代码中可以发现* [*在这里*](https://github.com/shibby576/data_sandbox/blob/master/Udacity_ML_Course/choose_your_own/Supervised_Final_Letters.ipynb)

我首先将数据读入 Pandas 数据帧，研究一些数据点，然后将它们作为 NumPy 数组分成要素和标签。除了非常容易从数据帧中分离出数组之外，我还发现了另一个非常酷的 Sklearn 模块`preprocessing`，它允许我在一行中缩放特性的值。我后来发现，由于我的数据集相当小(~20k 行)，预处理最终只为我节省了几秒钟的训练和预测时间，但在处理更大的数据集时，这似乎是一个有用的步骤。最后，我使用 Sklearn 的`train_test_split`来创建我的训练和测试数据集，分别利用默认的 75%-25%分割。

我的下一步是根据我的问题/数据考虑我想尝试的模型类型。我知道我需要擅长分类的东西，可以在相当多的维度上分离数据，不需要超快，并且有参数来控制拟合。对我来说，SMV 和 Random Forest 符合这里的要求，所以我继续测试它们。

## 支持向量机

我在 SVM 的第一次测试获得了 94.6%的准确率，训练和预测总共只花了 4.5 秒。我认为这已经很不错了，但我继续调整一些参数，看看是否能提高精度。用`kernel`和`C`参数做实验，我能够得到超过 97%的准确率。将 C 值提高到 1000 似乎给了我最大的准确性提升，而内核似乎没有太多积极的影响(这是我需要进一步研究的)。内核的另一个奇特之处是，其中一些内核，如 sigmoid 内核，将精确度降低到了 43.44%。我不太精通如何应用“内核技巧”，所以这对于我来说可能比那些了解内核的人更有意思。

```
Training time: 2.0 s
Prediction time: 1.484 s
Accuracy 0.9718
```

对于其他数据集，我发现 SVM 非常慢，但由于这个数据集较小且没有时间限制，SVM 证明是一个很好的选择。随着时间的推移，我想做更多的验证，以确保我的模型不会过度拟合，并看看我是否可以通过调整伽马来提高准确性。

## 随机森林

我想尝试的另一个模型是随机森林。我过去曾使用决策树将数据分类成组，因此一个健壮的随机森林似乎是迎接这一挑战的一大进步。默认的射频分类器返回了 93.36%的准确率，但只用了 0.197 秒，明显快于 SVM。我首先尝试将`min_samples_split`修改为 25，然而这只会降低我的精确度。不知道为什么，我转向了`n_estimators`值，我首先将其更新为 200。这使我的准确率提高到了 96.4%，但总的训练/预测时间增加到了 3.5 秒，仍然比 SVM 快。最后，我试着将`n_estimators`提高到 1000，精度提高了 0.2%，但时间增加了 11 秒。为了改进 RF，我希望花时间调整或加权特征，并研究样本分割如何改进模型。

```
Training time: 2.998 s
Prediction time: 0.275 s
Accuracy 0.9692
```

按照我的标准，这两个模型似乎都表现得很好，但每次运行都会引发不同的问题。这些意想不到的结果使得 ML 成为一个有趣的话题，激发了许多人对这个主题的好奇心！

# 如果可以，应该吗？

在一个以技术为重点的大学校园里，我每天都会听到很多次“我们使用机器学习来做 x ”,通常我认为这是一件好事，但在应用这些工具之前，我们需要更加批判性地思考。我之前提到过 Sklearn“非常容易”使用，在某种程度上，我确实认为“预测”一个结果就像它这么容易有点儿*可怕*。人们抓住了使用 ML 的想法和它在某些情况下的强大力量，但是他们忘记了考虑正在做出的决策的含义或答案的有效性。仅仅因为我们**能**做到，我们就需要停下来想想我们**是否应该**做到。

感谢阅读！