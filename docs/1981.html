<html>
<head>
<title>ToneNet : A Musical Style Transfer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ToneNet:音乐风格的转变</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/tonenet-a-musical-style-transfer-c0a18903c910?source=collection_archive---------2-----------------------#2017-11-28">https://towardsdatascience.com/tonenet-a-musical-style-transfer-c0a18903c910?source=collection_archive---------2-----------------------#2017-11-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="f357" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作者:南加州大学Vesta团队。</p><p id="07f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">CSCI:599深度学习及其应用</p><p id="b03d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">suraj Jayakumar(sjayakum @ USC . edu)、拉凯什·拉梅什(rakeshr@usc.edu)、(thalasta@usc.edu帕拉德普·塔拉斯塔</p><h1 id="e102" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><strong class="ak">简介:</strong></h1><p id="9852" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">最近，生成对抗网络在视觉领域的成功，如风格转换，启发我们在音乐领域尝试这些技术。音乐一代主要钻研两个最重要的东西:作曲和演奏。作曲侧重于宋立科的积木符号、音调、音高和和弦。而演奏则侧重于演奏者如何演奏音符。这种独特性定义了音乐的风格。</p><h1 id="cde6" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><strong class="ak">数据集和预处理:</strong></h1><p id="8eff" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">我们有大约200首钢琴专用歌曲(MIDI文件),分类为爵士乐和古典音乐，训练数据的平均长度约为4分钟。</p><p id="9451" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">首先，我们量化每一个MIDI文件，以符合特定的时间间隔，从而消除表演者的不精确性。其次，我们将输入的MIDI文件编码到一个T ×P矩阵中，其中T是歌曲中的时间步长数，P是乐器中的音高数(例如，对于有88个键的钢琴，我们有88个音高)。此外，在矩阵的每个值中，我们使用2-D向量对关于音符的信息进行编码，即，[1-1]音符发音，[0-1]音符持续而[0-0]音符关闭。</p><p id="04af" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">类似地，我们生成T ×P形状的输出矩阵，但这里我们对歌曲的力度进行编码，即播放的下一个键的音量(1-127 ),而不是音符信息。</p><p id="44a2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">数据集链接:<a class="ae lo" href="http://imanmalik.com/assets/dataset/TPD.zip" rel="noopener ugc nofollow" target="_blank">钢琴数据集</a>【注:钢琴数据集配有<a class="ae lo" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank"> CC-BY 4.0许可证</a>。如果使用这个数据集，请参考这篇<a class="ae lo" href="https://arxiv.org/abs/1708.03535" rel="noopener ugc nofollow" target="_blank">论文</a> :]</p><p id="a743" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">数据集链接(SeqGAN) : <a class="ae lo" href="http://ifdo.ca/~seymour/nottingham/nottingham.html" rel="noopener ugc nofollow" target="_blank">诺丁汉数据库</a></p><h1 id="2bcc" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">建筑设计</h1><h1 id="2ffc" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><strong class="ak">序列间</strong></h1><p id="7264" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated">序列到序列模型在过去被证明在各种领域对于风格转换非常有效，特别是在语言(机器翻译)中</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/0830edff9101b72d92ba6da4ce4e1353.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k8fTcv5KtHilKndOIVxKNQ.png"/></div></div></figure><p id="5fca" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">基线— seq2seq </strong></p><p id="fa93" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意:基线架构在很大程度上借用了本文<a class="ae lo" href="https://arxiv.org/abs/1708.03535" rel="noopener ugc nofollow" target="_blank">的内容</a>。请参考同。还可以查看Iman Malik的StyleNet，了解更多关于基线音乐风格转换的信息</p><p id="b784" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">歌曲的预处理MIDI文件被传递到具有动态RNN展开的编码器LSTM，以处理不同歌曲中的不同时间步长并保持一致性。来自编码器的中间输出被传递到对应于其风格的LSTM，其学习音乐流派的内部动态。</p><p id="de28" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">输入歌曲被反馈给相反流派的LSTM。在风格转换过程中，输出被解码回一个MIDI文件，该文件代表风格转换后的MIDI文件。</p><p id="a446" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">基于注意力的seq2seq </strong></p><p id="94ce" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个架构被进一步调整，以利用注意力机制，这样我们就可以对歌曲中我们希望网络更加重视的部分进行加权，尤其是中间的即兴部分。</p><p id="f9bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">来自编码器LSTM的输出通过注意机制传递(Luong的版本)。这个包装器的输出被传递到解码器单元。</p><p id="2e43" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意力计算发生在每个解码器时间步骤，其中我们计算与每个上下文向量相关联的注意力权重，该权重用于计算注意力向量，该注意力向量然后最终用于计算分数。</p><p id="84b4" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">加工和后处理</strong></p><p id="c528" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要进行风格转换的歌曲(比如爵士歌曲)通过编码器传递到相反的风格(古典)，我们收集输出(古典输出)并使用此信息叠加到原始歌曲上，但使用ToneNet生成的古典速度。</p><p id="cc4e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">车型评测</strong></p><p id="83a8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了评估ToneNet的整体性能，我们将一首输入样本爵士乐歌曲传递到ToneNet上，并获得风格转换的古典歌曲。这种输出被反馈到网络中，我们试图将输入的歌曲重新生成为爵士乐类型，并与原始歌曲进行比较。原始歌曲和再生歌曲之间的这种数值MSE比较将决定ToneNet的性能。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mb"><img src="../Images/74fce036e0c91c0c8be6135a81055876.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hbcfODIxqpvNl73-n_S_2w.png"/></div></div></figure><h1 id="278e" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated"><strong class="ak">VAE-甘</strong></h1><p id="18b4" class="pw-post-body-paragraph jn jo iq jp b jq lj js jt ju lk jw jx jy ll ka kb kc lm ke kf kg ln ki kj kk ij bi translated"><strong class="jp ir">架构:</strong></p><p id="b849" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">提出的架构是VAE-甘(变分自动编码器生成对抗网络)的架构。通过将变分自动编码器与生成对抗网络相结合，我们可以在GAN鉴别器中使用学习到的特征表示作为VAE重建目标的基础。这使得训练过程明显更加稳定，因为生成器具有关于它试图生成的真实世界实体的信息，而不是在每次迭代中猜测真实世界实体应该是什么。此外，编码器学习图像到潜在空间的映射，这非常有用。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ca"><img src="../Images/cac915747b7acef2481467da3e70337d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nNBf9fm_TlFMVhUrp9HhoQ.png"/></div></div></figure><p id="8ef9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">变型自动编码器</strong></p><p id="eafa" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">VAE由两个网络组成，将数据样本x编码为潜在表示z，并将潜在表示解码回数据样本。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mc"><img src="../Images/2e2690e3736a7ffbdbf1e1b916bb534d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kw6MMMjzdxUNI2NR7HVQVA.png"/></div></div></figure><p id="b315" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">VAE损失减去预期对数似然(重建误差)和先前正则化项的总和</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi md"><img src="../Images/987326788087ee8f8d24b7fa91b9703b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wt3NVrg-uHfXjyrWM2N6dQ.png"/></div></div></figure><p id="c1c1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">生成对抗网络</strong></p><p id="7cc9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">GAN由两个网络组成:生成器网络Gen(z)将潜伏期z映射到数据空间，而鉴别器网络分配x是实际训练样本的概率y = Dis(x) ∈ [0，1]以及x由我们的模型通过x = Gen(z)与z∞p(z)生成的概率1y。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi me"><img src="../Images/ac12a8ee8066e8721c4e6595270eece7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XNAYTBrsk5kGa_wX448vHA.png"/></div></div></figure><p id="00a3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在我们的设计中，我们用多个88(时间步长数)X 88(音符数)图像来表示midi文件(钢琴轨道),其中每个像素值都是一个时间步长内给定音符的相应音量。</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi mf"><img src="../Images/a4145eb0db4ae8fb72782c1a5cdd7444.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*AmXnFrk3ZsU6NpP9AdqQ_Q.png"/></div></figure><p id="39e5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">为什么是干的？</strong></p><p id="7e26" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这是作为问题陈述的一个分支实现的，其中我们想要创建对应于不同类型的封面。这要求我们有能力从头开始创作完整的歌曲。对此的进一步扩展将是实现循环GAN，其中该架构可以用作导致音乐风格转换的构建块。简单的GAN对于训练来说是不稳定的，并且我们丢失了潜在空间和生成的歌曲之间的映射。因此，我们使用VAE氮化镓架构。Midi文件被转换成图像，以便更容易处理，因为基于卷积神经网络的GAN明显更稳定，更容易训练。</p><p id="6218" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">后处理</strong></p><p id="e54f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里，输出包含88×88的图像，这些图像对应于生成的音乐的量化时间步长、音符和音量。我们需要将图像转换成相应的歌曲表示。我们正在构建一个新的midi文件，其量化间隔与我们在预处理过程中设置的相同，音符和音量与从生成的图像中获得的信息相对应。</p><p id="caea" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">结果</strong></p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mg"><img src="../Images/4350ac4db40732b2171a2b3aecaeb52b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9ggbHMw4Ptr-Q4uQHVJfsg.png"/></div></div></figure><p id="7b9a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="mh">VAE-重建</em></p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mi"><img src="../Images/beb29235397ca3c625bc8a21947e37fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Db8wInFVr92wnObT3JfypQ.png"/></div></div></figure><p id="cc33" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="mh">利用噪声生成</em></p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mj"><img src="../Images/ba8d7c2126d6eb55e2099d521919f562.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k4wcAefthzmG-uVtzcjdzw.png"/></div></div></figure><p id="2b00" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">想法</strong></p><p id="73d9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> <em class="mh">为什么建筑不起作用:- </em> </strong>我们认为它不起作用的原因是因为我们做了一个简单的假设，即只用时间步长、音符和音量来表达歌曲。还缺少其他关键部分，如音符开始和结束时间。由于量化，每个音符在输入中都表示为一个单独的笔画。这会给生成的音乐带来刺耳的声音。从结果可以明显看出，模型正在学习如何以相对较好的方式重建输入，并且生成的音乐在结构上与输入歌曲表示非常相似。例如，大多数音符被设定为0音量，平均每次有2-3个音符活跃，这表示正常的钢琴音乐。彼此靠近的音符通常一起演奏，重复的模式信息被采集。这表明模型运行良好，这里的错误在于世界假设，而不是用于完成这项任务的架构。</p><p id="4ee0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">调查结果</strong></p><p id="d65a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">VAE-GAN明显比GAN更稳定。我们的许多简单的GAN实现导致生成器收敛到这样的模式</p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/066df03d4a608b69456853944ea02a6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*UuUHdxu8W1fzsg9DAWUpzQ.png"/></div></figure><p id="44af" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">无论我们训练多少个纪元，发电机都不会改进。当使用VAE-甘时，这种情况从未发生。</p><p id="1cad" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在训练模型时，动态调整学习速率非常有帮助。这是用来重新调整学习速度的确切代码。这确保了生成器和鉴别器都以稳定的速度改进，并且都不会超过对方。这里，learning_rate是一个恒定值，它从4e-4开始，每个时期衰减0.99。</p><blockquote class="ml mm mn"><p id="f3b6" class="jn jo mh jp b jq jr js jt ju jv jw jx mo jz ka kb mp kd ke kf mq kh ki kj kk ij bi translated">generator _ learning _ rate = max(learning _ rate，min(learning _ rate *(training _ loss _ gan _ g _ loss/training _ loss _ gan _ d _ loss)，gen_learning_rate*20))</p><p id="8033" class="jn jo mh jp b jq jr js jt ju jv jw jx mo jz ka kb mp kd ke kf mq kh ki kj kk ij bi translated">discriminator _ learning _ rate = min(learning _ rate，learning _ rate *(training _ loss _ gan _ d _ loss/training _ loss _ gan _ g _ loss))</p></blockquote><p id="448d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">未来前景</strong></p><p id="65f3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">更好的输入和输出表示，更大的潜在空间，更多的训练样本，运行更多的时期。我们仍然相信这种架构可以用于进行音乐生成，但是存在某些限制，例如关于扩展序列的信息没有被保留，不像我们使用基于LSTM的模型那样。把这个扩展到CycleGAN。</p><h1 id="017a" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">序列-GAN</h1><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi mr"><img src="../Images/4e3636d34248a3d0e594772403200aa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lTkW3m0jTj_O6CStKfI8uw.png"/></div></div></figure><p id="6242" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这里使用的架构是SeqGAN。以下步骤用于实现SeqGAN以生成音乐:</p><ol class=""><li id="83f3" class="ms mt iq jp b jq jr ju jv jy mu kc mv kg mw kk mx my mz na bi translated">建立一个递归发电机模型，在每个时间步从其softmax输出中取样。</li><li id="65f7" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">将采样序列传递给递归鉴别器模型，该模型区分采样序列和真实数据序列。</li><li id="762f" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">在标准GAN损耗下训练鉴频器。</li><li id="6479" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">用一个强化(政策梯度)目标训练生成器，其中每个轨迹被分配一个单独的情节奖励:由鉴别器分配给生成序列的分数。</li></ol><p id="c91d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">生成式模型</strong></p><p id="519c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">基于LSTM的RNN模型被用于对映射输入嵌入表示x1，.。。序列x1，.。。，xT转化为隐藏状态h1，…，hT的序列。</p><blockquote class="ml mm mn"><p id="7f9d" class="jn jo mh jp b jq jr js jt ju jv jw jx mo jz ka kb mp kd ke kf mq kh ki kj kk ij bi translated">ht = g(ht1，xt)</p></blockquote><p id="3d9e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">softmax输出层z将隐藏状态映射到输出令牌分布中。</p><blockquote class="ml mm mn"><p id="d9e2" class="jn jo mh jp b jq jr js jt ju jv jw jx mo jz ka kb mp kd ke kf mq kh ki kj kk ij bi translated">p(yt|x1，.。。，xt) = z(ht) = softmax(c + V ht)，(10)</p></blockquote><p id="9c82" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中参数是偏置向量c和权重矩阵v</p><p id="b986" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">判别模型</strong></p><p id="1ad2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们使用基于CNN的鉴别器，因为CNN最近在更准确地分类令牌序列方面非常有效。</p><p id="87b3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们首先将输入序列x1，…，xT表示为:</p><blockquote class="ml mm mn"><p id="e600" class="jn jo mh jp b jq jr js jt ju jv jw jx mo jz ka kb mp kd ke kf mq kh ki kj kk ij bi translated">E[1:T] =x1 ⊕x2 ⊕…⊕xT</p></blockquote><p id="4714" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中xt ∈ Rk是k维令牌嵌入，而⊕是构建矩阵E[1:T] ∈ T×k的串联算子。然后，核w ∈ l×k对l个令牌的窗口大小应用卷积运算，以产生新的特征图:</p><blockquote class="ml mm mn"><p id="aa6b" class="jn jo mh jp b jq jr js jt ju jv jw jx mo jz ka kb mp kd ke kf mq kh ki kj kk ij bi translated">ci =ρ(w⊗e[I:I+L1]+b)，</p></blockquote><p id="1248" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">其中，⊗算子是元素乘积的总和，b是偏差项，ρ是非线性函数。我们在鉴别器的模型中使用relu作为非线性函数，并且CNN具有以下配置步长=[1，1，1，1]，padding =“VALID”。</p><p id="e251" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们在特征图上应用最大时间池操作</p><blockquote class="ml mm mn"><p id="4ee2" class="jn jo mh jp b jq jr js jt ju jv jw jx mo jz ka kb mp kd ke kf mq kh ki kj kk ij bi translated">c ̃=最大值{c1，…，CTL+1 }</p></blockquote><p id="c348" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最后，我们应用基于汇集特征映射的高速公路架构，以在完全连接层之前增强性能，其中sigmoid激活给出了所生成的序列是真实的概率。</p><p id="268a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><em class="mh">鉴别器交叉熵损失函数:</em></p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ng"><img src="../Images/47e7b4ae0d647fd6576bb96b8e7cf2b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KcpmSa4FjTBxm9sjKyv4lg.png"/></div></div></figure><p id="64db" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">为什么Seq-GAN </strong></p><p id="4787" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于同样的原因，作为使用VAE干，我们尝试序列干创造相应的不同流派的封面。这要求我们有能力从头开始创作完整的歌曲。对此的进一步扩展将是实现循环GAN，其中该架构可以用作导致音乐风格转换的构建块。简单的GAN对于训练来说是不稳定的，并且我们丢失了潜在空间和生成的歌曲之间的映射。因此，我们使用Seq-GAN架构，它可以像RNNs一样提供反馈。</p><p id="d666" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">预处理:</strong></p><p id="d523" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">给定的音乐流被分成音符和和弦。音符按照我们用于其他模型的标准预处理进行处理</p><p id="6245" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">后处理:</strong></p><p id="82ab" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">生成的轨道被映射回它们各自的乐谱形式，并且80的恒定速度被用于再生。</p><p id="be5f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">思想:</strong></p><p id="d4e9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">SeqGANs工作良好，这是因为从鉴别器到发生器中的LSTMs使用了反馈机制。这有助于序列生成，让它看过去生成的序列。尽管序列生成对于随机的新音乐输出工作良好，但是它不能用于控制风格转换的输出生成，因为编码器使用的潜在向量表示不能按照我们的输入音乐来指导生成。</p><p id="4778" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">模型评估:</strong></p><p id="aa0d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们使用BLEU作为评估度量来模拟离散钢琴键模式和连续音高数据模式的均方误差。</p><h1 id="32b1" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">培训和设置</h1><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nh"><img src="../Images/ba5b3aefdf18b7cc7892f7faa5fd3127.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jgwsy26aPHC8hWrqhhM8zQ.png"/></div></div></figure><h1 id="be1c" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">结果</h1><h1 id="0591" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">序列对序列</h1><div class="lq lr ls lt gt ab cb"><figure class="ni lu nj nk nl nm nn paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/001843cdfe5b264cf3b72b59e6a79327.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*pxgSUPiZhSJk23zXS88H1A.png"/></div></figure><figure class="ni lu no nk nl nm nn paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/f4041905fed34a84e9d390666cc14c44.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*JtEPAcK9B6Sye_B2BPz16w.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk nt di nu nv">INPUT JAZZ PIANO SONG FOR TONE-NET</figcaption></figure></div><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nw nx l"/></div></figure><div class="lq lr ls lt gt ab cb"><figure class="ni lu nj nk nl nm nn paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/c2ed7b9616299930a6addad7527a55c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*JJJjrqKA7X4D1yefMsmQTw.png"/></div></figure><figure class="ni lu no nk nl nm nn paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/343876a31a5f190ef480cc72ab4f92c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*7az8UY_WJBOONVjOn1kKFw.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk nt di nu nv">OUTPUT CLASSICAL SONG (STYLE TRANSFERED)</figcaption></figure></div><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="aceb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如你可以很容易地认为，有一个明确的风格转换输入歌曲(爵士乐)到一个新的流派(古典)。可以观察到，网络已经理解了古典流派的动态。该网络剪切了爵士音乐的高音，使得在古典形式的输出中听起来非常流畅和愉快。</p><h1 id="7747" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">序列-GAN</h1><div class="lq lr ls lt gt ab cb"><figure class="ni lu no nk nl nm nn paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/649a201be4524033a62ab6879c3dc6e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*6WzKuZVW8Ijt6dxTe259sg.png"/></div></figure><figure class="ni lu nj nk nl nm nn paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/c5193eee4756394716538880835661e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*3Z4dzL4Sk1hRjdohl5ww_Q.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk ny di nz nv">SEQUENCE-GAN OUTPUT</figcaption></figure></div><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="4c13" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如我们可以从上面的音频中发现的，对于给定的潜在输入，存在很多随机性。因此，我们必须控制这种随机性来生成音频，并在风格转换中使用SeqGAN。</p><h1 id="5bf2" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">VAE甘</h1><div class="lq lr ls lt gt ab cb"><figure class="ni lu nj nk nl nm nn paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/b4afb1b22b5ac69671196b609c3ff5d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*Z_SQSZcbnj5p3Z9OMuP14w.png"/></div></figure><figure class="ni lu no nk nl nm nn paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><img src="../Images/671fd33d8824c975770cfcf5458213fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*o8hoeftsAL7D5CtfFVkftQ.png"/></div><figcaption class="np nq gj gh gi nr ns bd b be z dk nt di nu nv">VAE-GAN SONG OUTPUT</figcaption></figure></div><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nw nx l"/></div></figure><h1 id="f11a" class="kl km iq bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">参考</h1><ol class=""><li id="b30c" class="ms mt iq jp b jq lj ju lk jy oa kc ob kg oc kk mx my mz na bi translated">[1] JazzML，<a class="ae lo" href="https://github.com/evancchow/jazzml" rel="noopener ugc nofollow" target="_blank">https://github.com/evancchow/jazzml</a></li><li id="e9de" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">[2]https://github.com/jisungk/deepjazz.<a class="ae lo" href="https://github.com/jisungk/deepjazz." rel="noopener ugc nofollow" target="_blank">deep jazz</a></li><li id="1dd7" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">[3] Magenta，Melody RNN(基于谷歌大脑的LSTM音乐生成)。</li><li id="b778" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">[4] WaveNet，【https://arxiv.org/abs/1609.03499】T4(wave net:原始音频的生成模型)。</li><li id="9e09" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">[5]米迪特，<a class="ae lo" href="https://arxiv.org/abs/1703.10847." rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1703.10847.</a></li><li id="923e" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">【6】音乐风格的神经翻译，<a class="ae lo" href="http://imanmalik.com/cs/2017/06/05/neural-style.html" rel="noopener ugc nofollow" target="_blank">imanmalik.com/cs/2017/06/05/neural-style.html</a>。</li><li id="c167" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">[7] SeqGAN:具有策略梯度的序列生成对抗网，<a class="ae lo" href="https://arxiv.org/pdf/1609.05473.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1609.05473.pdf</a></li><li id="4bac" class="ms mt iq jp b jq nb ju nc jy nd kc ne kg nf kk mx my mz na bi translated">[8]使用学习的相似性度量自动编码像素以外的内容，<a class="ae lo" href="https://arxiv.org/pdf/1512.09300.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1512.09300.pdf</a></li></ol><p id="3b6e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">GITHUB链接:<a class="ae lo" href="https://github.com/sjayakum/csci599-final-project" rel="noopener ugc nofollow" target="_blank">https://github.com/sjayakum/csci599-final-project</a></p></div></div>    
</body>
</html>