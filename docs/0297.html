<html>
<head>
<title>An introduction to the MXNet API — part 4</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MXNet API介绍—第4部分</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-introduction-to-the-mxnet-api-part-4-df22560b83fe?source=collection_archive---------0-----------------------#2017-04-14">https://towardsdatascience.com/an-introduction-to-the-mxnet-api-part-4-df22560b83fe?source=collection_archive---------0-----------------------#2017-04-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="8749" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在<a class="ae kl" href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-3-1803112ba3a8" rel="noopener">第三部</a>中，我们建立并训练了我们的第一个神经网络。我们现在知道的足够多，可以举更高级的例子。</p><p id="0d86" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最先进的深度学习模型非常复杂。他们有数百层<strong class="jp ir"/>，需要几天——如果不是几周——来训练大量的数据。构建和调整这些模型需要大量的专业知识。</p><p id="7cce" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">幸运的是，使用这些模型要简单得多，只需要<strong class="jp ir">几行代码</strong>。在本文中，我们将使用一个名为<strong class="jp ir"> Inception v3 </strong>的预训练图像分类模型。</p><h2 id="61f5" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">盗梦空间v3</h2><p id="fc21" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated"><a class="ae kl" href="https://arxiv.org/abs/1512.00567" rel="noopener ugc nofollow" target="_blank"> Inception v3 </a>发布于2015年12月，是<a class="ae kl" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank"> GoogleNet </a>模型的一个进化版本(该模型赢得了<a class="ae kl" href="http://image-net.org/challenges/LSVRC/2014/" rel="noopener ugc nofollow" target="_blank"> 2014 ImageNet挑战赛</a>)。我们不会深入研究论文的细节，但转述其结论，Inception v3比当时可用的最佳模型精确15-25%，同时在计算上便宜6倍，使用的参数至少少5倍(即使用模型需要更少的RAM)。</p><p id="14df" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">那真是一头野兽。那么我们如何让它发挥作用呢？</p><h2 id="8683" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">MXNet模型动物园</h2><p id="b13f" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated"><a class="ae kl" href="http://mxnet.io/model_zoo/" rel="noopener ugc nofollow" target="_blank">模型动物园</a>是一群<strong class="jp ir">预先训练好的模型</strong>随时可以使用。你会发现<strong class="jp ir">模型定义</strong>、<strong class="jp ir">模型参数</strong>(即神经元权重)和指令(可能)。</p><p id="10bd" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们下载定义和参数(您可能需要更改文件名)。随意打开第一个文件:你会看到所有层的定义。第二个是二进制文件，别管它；)</p><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="b850" class="km kn iq lp b gy lt lu l lv lw">$ wget <a class="ae kl" href="http://data.dmlc.ml/models/imagenet/inception-bn/Inception-BN-symbol.json" rel="noopener ugc nofollow" target="_blank">http://data.dmlc.ml/models/imagenet/inception-bn/Inception-BN-symbol.json</a></span><span id="4578" class="km kn iq lp b gy lx lu l lv lw">$ wget <a class="ae kl" href="http://data.dmlc.ml/models/imagenet/inception-bn/Inception-BN-0126.params" rel="noopener ugc nofollow" target="_blank">http://data.dmlc.ml/models/imagenet/inception-bn/Inception-BN-0126.params</a></span><span id="3286" class="km kn iq lp b gy lx lu l lv lw">$ mv Inception-BN-0126.params Inception-BN-0000.params</span></pre><p id="51c6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">由于这个模型已经在<a class="ae kl" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>数据集上训练过，我们还需要下载相应的图像<strong class="jp ir">类别</strong>列表(其中1000个)。</p><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="c1c8" class="km kn iq lp b gy lt lu l lv lw">$ wget <a class="ae kl" href="http://data.dmlc.ml/models/imagenet/synset.txt" rel="noopener ugc nofollow" target="_blank">http://data.dmlc.ml/models/imagenet/synset.txt</a></span><span id="17df" class="km kn iq lp b gy lx lu l lv lw">$ wc -l synset.txt<br/>    1000 synset.txt</span><span id="ba49" class="km kn iq lp b gy lx lu l lv lw">$ head -5 synset.txt<br/>n01440764 tench, Tinca tinca<br/>n01443537 goldfish, Carassius auratus<br/>n01484850 great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias<br/>n01491361 tiger shark, Galeocerdo cuvieri<br/>n01494475 hammerhead, hammerhead shark</span></pre><p id="cf86" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">好了，完成了。现在我们开始工作吧。</p><h2 id="ba0b" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">加载模型</h2><p id="33c2" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">我们需要做的是:</p><ul class=""><li id="7c6f" class="ly lz iq jp b jq jr ju jv jy ma kc mb kg mc kk md me mf mg bi translated">从保存的状态加载模型:MXNet称之为<strong class="jp ir">检查点</strong>。作为回报，我们得到输入<em class="mh">符号</em>和模型参数。</li></ul><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="4276" class="km kn iq lp b gy lt lu l lv lw">import mxnet as mx<br/><br/>sym, arg_params, aux_params = mx.model.load_checkpoint('Inception-BN', 0)</span></pre><ul class=""><li id="8a1c" class="ly lz iq jp b jq jr ju jv jy ma kc mb kg mc kk md me mf mg bi translated">创建一个新的<em class="mh">模块</em>，并将其指定为输入<em class="mh">符号</em>。我们还可以使用一个<em class="mh">上下文</em>参数来指示我们想要在哪里运行模型:默认值是<em class="mh"> cpu(0) </em>，但是我们将使用<em class="mh"> gpu(0) </em>在gpu上运行它。</li></ul><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="9319" class="km kn iq lp b gy lt lu l lv lw">mod = mx.mod.Module(symbol=sym)</span></pre><ul class=""><li id="1ee7" class="ly lz iq jp b jq jr ju jv jy ma kc mb kg mc kk md me mf mg bi translated">将输入符号<em class="mh">绑定到输入数据。我们称它为‘data ’,因为这是它在网络的<strong class="jp ir">输入层</strong>中的名字(请看JSON文件的前几行)。</em></li><li id="767a" class="ly lz iq jp b jq mi ju mj jy mk kc ml kg mm kk md me mf mg bi translated">将“数据”的<strong class="jp ir">形状</strong>定义为1 x 3 x 224 x 224。不要慌；)‘224 x 224’是图像分辨率，模型就是这么训练的。‘3’是通道数:红、绿、蓝(按此顺序)。“1”是批量大小:我们将一次预测一个图像。</li></ul><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="0911" class="km kn iq lp b gy lt lu l lv lw">mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))])</span></pre><ul class=""><li id="0ddf" class="ly lz iq jp b jq jr ju jv jy ma kc mb kg mc kk md me mf mg bi translated">设置模型参数。</li></ul><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="35b2" class="km kn iq lp b gy lt lu l lv lw">mod.set_params(arg_params, aux_params)</span></pre><p id="7287" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这就够了。四行代码！现在需要把一些数据放进去，看看会发生什么。嗯……还没有。</p><h2 id="61d4" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">准备我们的数据</h2><p id="82d0" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">数据准备:让我们的生活变得悲惨自从七十年代以来…从关系数据库到机器学习到深度学习，在这方面没有什么真正改变。很无聊但是很有必要。让我们完成它。</p><p id="b0c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">请记住，该模型需要一个4维的<em class="mh">n数组</em>来保存一张224 x 224图像的红色、绿色和蓝色通道。我们将使用流行的<a class="ae kl" href="http://www.opencv.org" rel="noopener ugc nofollow" target="_blank"> OpenCV </a>库从我们的输入图像构建这个<em class="mh">n数组</em>。如果没有安装OpenCV，运行“<em class="mh">pip install OpenCV-python</em>”在大多数情况下应该足够了:)</p><p id="c7e0" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下是步骤:</p><ul class=""><li id="0c55" class="ly lz iq jp b jq jr ju jv jy ma kc mb kg mc kk md me mf mg bi translated"><strong class="jp ir">读取</strong>图像:这将返回一个<em class="mh"> numpy </em>数组，形状为(图像高度，图像宽度，3)，三个通道按照<strong class="jp ir"> BGR </strong>的顺序排列(蓝、绿、红)。</li></ul><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="d3ac" class="km kn iq lp b gy lt lu l lv lw">img = cv2.imread(filename)</span></pre><ul class=""><li id="a7b7" class="ly lz iq jp b jq jr ju jv jy ma kc mb kg mc kk md me mf mg bi translated"><strong class="jp ir">将</strong>图像转换为<strong class="jp ir"> RGB </strong>。</li></ul><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="801c" class="km kn iq lp b gy lt lu l lv lw">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span></pre><ul class=""><li id="eb69" class="ly lz iq jp b jq jr ju jv jy ma kc mb kg mc kk md me mf mg bi translated"><strong class="jp ir">将</strong>图像调整到<strong class="jp ir"> 224 x 224 </strong>。</li></ul><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="b1c4" class="km kn iq lp b gy lt lu l lv lw">img = cv2.resize(img, (224, 224,))</span></pre><ul class=""><li id="95a4" class="ly lz iq jp b jq jr ju jv jy ma kc mb kg mc kk md me mf mg bi translated"><strong class="jp ir">将</strong>数组从(图像高度，图像宽度，3)整形为(3，图像高度，图像宽度)。</li></ul><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="abd9" class="km kn iq lp b gy lt lu l lv lw">img = np.swapaxes(img, 0, 2)<br/>img = np.swapaxes(img, 1, 2)</span></pre><ul class=""><li id="d6b8" class="ly lz iq jp b jq jr ju jv jy ma kc mb kg mc kk md me mf mg bi translated">添加一个<strong class="jp ir">第四维</strong>并构建<em class="mh">n数组</em></li></ul><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="3f91" class="km kn iq lp b gy lt lu l lv lw">img = img[np.newaxis, :]<br/>array = mx.nd.array(img)</span><span id="ddcc" class="km kn iq lp b gy lx lu l lv lw">&gt;&gt;&gt; print array.shape<br/>(1L, 3L, 224L, 224L)</span></pre><p id="4291" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">头晕？让我们看一个例子。这是我们的输入图片。</p><figure class="lk ll lm ln gt mo gh gi paragraph-image"><div class="gh gi mn"><img src="../Images/4a580375341f50946ddf056057df1285.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/1*sPdrfGtDd_6RQfYvD5qcyg.jpeg"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">Input picture 448x336 (Source: metaltraveller.com)</figcaption></figure><p id="f1c2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦经过处理，这张图片已经被调整大小并被分割成RGB通道，存储在<em class="mh">数组【0】</em>(<a class="ae kl" href="https://gist.github.com/juliensimon/c62742b200396b4eadd8229a22c4cf0b" rel="noopener ugc nofollow" target="_blank">这里的</a>是用来生成下面图像的代码)。</p><figure class="lk ll lm ln gt mo gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/b92fb0abf6cee0647c600ede72c60e6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*yqdl78KIugYepzJ4-lMY8g.jpeg"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">array[0][0] : 224x224 red channel</figcaption></figure><figure class="lk ll lm ln gt mo gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/f70594e7efd34f54aa07ba8ad95a13bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*sitDwoAzPDLrav0dXQrcbA.jpeg"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">array[0][1] : 224x224 green channel</figcaption></figure><figure class="lk ll lm ln gt mo gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/dfdb09d091101dec6d3bd78eace44bd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*h1RyEPvd2fqIgd2jkfES-w.jpeg"/></div><figcaption class="mr ms gj gh gi mt mu bd b be z dk">array[0][2] : 224x224 blue channel</figcaption></figure><p id="47d8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果批处理大小大于1，那么我们将在<em class="mh">数组【1】</em>中有第二个图像，在<em class="mh">数组【2】</em>中有第三个图像，依此类推。</p><p id="b7ed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这很有趣吗？现在我们来预测一下！</p><h2 id="c119" class="km kn iq bd ko kp kq dn kr ks kt dp ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">预测</h2><p id="1ac8" class="pw-post-body-paragraph jn jo iq jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj kk ij bi translated">您可能还记得第三部分中的<a class="ae kl" href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-3-1803112ba3a8" rel="noopener">内容，一个<em class="mh">模块</em>对象必须在<strong class="jp ir">批次</strong>中向一个模型提供数据:通常的做法是使用一个<strong class="jp ir">数据迭代器</strong>(具体来说，我们使用了一个<em class="mh"> NDArrayIter </em>对象)。</a></p><p id="948a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这里，我们想要预测一个<strong class="jp ir">单个</strong>图像，所以尽管我们可以使用数据迭代器，但这可能是多余的。相反，我们将创建一个名为tuple 的<strong class="jp ir">，名为<em class="mh"> Batch </em>，当它的<em class="mh">数据</em>属性被引用时，它将通过返回我们的输入<em class="mh"> NDArray </em>来充当伪迭代器。</strong></p><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="125c" class="km kn iq lp b gy lt lu l lv lw">from collections import namedtuple<br/>Batch = namedtuple('Batch', ['data'])</span></pre><p id="9493" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在我们可以把这个“批”传递给模型，让它预测。</p><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="b399" class="km kn iq lp b gy lt lu l lv lw">mod.forward(Batch([array]))</span></pre><p id="c8c8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">该模型将输出一个<em class="mh">n数组</em>，包含<strong class="jp ir"> 1000个概率</strong>，对应于1000个类别。它只有一行，因为批大小等于1。</p><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="0fe4" class="km kn iq lp b gy lt lu l lv lw">prob = mod.get_outputs()[0].asnumpy()</span><span id="6402" class="km kn iq lp b gy lx lu l lv lw">&gt;&gt;&gt; prob.shape<br/>(1, 1000)</span></pre><p id="8631" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们用<em class="mh">挤压</em>()把这个变成一个数组。然后，使用<em class="mh"> argsort </em>()，我们创建第二个数组，保存这些概率的<strong class="jp ir">索引</strong>，按照<strong class="jp ir">降序</strong>排序。</p><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="40c6" class="km kn iq lp b gy lt lu l lv lw">prob = np.squeeze(prob)</span><span id="d118" class="km kn iq lp b gy lx lu l lv lw">&gt;&gt;&gt; prob.shape<br/>(1000,)<br/>&gt;&gt; prob<br/>[  4.14978594e-08   1.31608676e-05   2.51907986e-05   2.24045834e-05<br/>   2.30327873e-06   3.40798979e-05   7.41563645e-06   3.04062659e-08 <em class="mh">etc.</em></span><span id="1669" class="km kn iq lp b gy lx lu l lv lw">sortedprob = np.argsort(prob)[::-1]</span><span id="6ee2" class="km kn iq lp b gy lx lu l lv lw">&gt;&gt; sortedprob.shape<br/>(1000,)</span></pre><p id="8b91" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">根据模型，这张图最有可能的类别是<strong class="jp ir"> #546 </strong>，概率<strong class="jp ir"> 58% </strong>。</p><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="82c1" class="km kn iq lp b gy lt lu l lv lw">&gt;&gt; sortedprob<br/>[546 819 862 818 542 402 650 420 983 632 733 644 513 875 776 917 795<br/><em class="mh">etc.<br/></em>&gt;&gt; prob[546]<br/>0.58039135</span></pre><p id="0915" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我们找到这个类别的名称。使用<em class="mh"> synset.txt </em>文件，我们可以构建一个<strong class="jp ir">类别列表</strong>，并在索引546处找到它。</p><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="26fa" class="km kn iq lp b gy lt lu l lv lw">synsetfile = open('synset.txt', 'r')<br/>categorylist = []<br/>for line in synsetfile:<br/>  categorylist.append(line.rstrip())</span><span id="708d" class="km kn iq lp b gy lx lu l lv lw">&gt;&gt;&gt; categorylist[546]<br/>'n03272010 electric guitar'</span></pre><p id="6531" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">第二高的类别呢？</p><pre class="lk ll lm ln gt lo lp lq lr aw ls bi"><span id="1610" class="km kn iq lp b gy lt lu l lv lw">&gt;&gt;&gt; prob[819]<br/>0.27168664<br/>&gt;&gt;&gt; categorylist[819]<br/>'n04296562 stage</span></pre><p id="32ce" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">很好，你不觉得吗？</p><p id="391a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">所以你走吧。现在你知道如何使用一个<strong class="jp ir">预先训练好的，最先进的模型</strong>进行图像分类。它只需要<strong class="jp ir"> 4行代码</strong> …剩下的只是数据准备。</p><p id="ff06" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可以在下面找到完整的代码。玩得开心，请继续关注:D</p></div><div class="ab cl mw mx hu my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ij ik il im in"><p id="d037" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">接下来:</p><ul class=""><li id="2b71" class="ly lz iq jp b jq jr ju jv jy ma kc mb kg mc kk md me mf mg bi translated"><a class="ae kl" href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-5-9e78534096db" rel="noopener">第5部分</a>:更多预训练模型(VGG16和ResNet-152)</li><li id="9a63" class="ly lz iq jp b jq mi ju mj jy mk kc ml kg mm kk md me mf mg bi translated"><a class="ae kl" href="https://medium.com/@julsimon/an-introduction-to-the-mxnet-api-part-6-fcdd7521ae87" rel="noopener">第6部分</a>:树莓Pi上的实时物体检测(它还会说话！)</li></ul><figure class="lk ll lm ln gt mo"><div class="bz fp l di"><div class="nd ne l"/></div></figure></div></div>    
</body>
</html>