<html>
<head>
<title>Spam, Hip-Hop, &amp; Natural Language Processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">垃圾邮件、嘻哈音乐和自然语言处理</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/spam-hip-hop-natural-language-processing-156780b9210b?source=collection_archive---------4-----------------------#2017-04-23">https://towardsdatascience.com/spam-hip-hop-natural-language-processing-156780b9210b?source=collection_archive---------4-----------------------#2017-04-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="67b0" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解NLP的基础知识以及如何构建一个简单的垃圾邮件过滤器。</h2></div><p id="d8f1" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于大会为期12周的数据科学沉浸式计划节奏很快，我们在5周内已经覆盖了很多地方。为了在这样的项目中取得成功，我们每个人都必须融合自己的学习风格。对于我们处理的每一个新话题，我的方法是把话题浓缩成我能理解的要点。对基础知识有了扎实的理解后，我发现我对材料的整体记忆更强了，而且我可以很快积累关于该主题的额外细节的知识。我读到过<a class="ae lb" href="https://www.reddit.com/r/IAmA/comments/2rgsan/i_am_elon_musk_ceocto_of_a_rocket_company_ama/" rel="noopener ugc nofollow" target="_blank">埃隆·马斯克也有类似的方法</a>，所以我一定是做对了什么！</p><p id="b1d5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这周我被介绍给了NLP。从未听说过它，我承认这个缩写本身就让我望而生畏。NLP代表自然语言处理。都清理好了吗？没有吗？好吧，如果我告诉你“自然语言”是一堆单词。一条短信。一封邮件。一次演讲。歌词。一本小说。会议纪要。更好，对吗？</p><p id="d358" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好了，现在是最后一部分:加工。我们所说的处理是什么意思？我们需要一组基于文本的文档(例如书籍),并将内容分解成最适用的块(单词、句子、短语等)。).这个将我们的文本文档分割成小块或大块的过程被称为<em class="lc">标记化</em>。从那里，如果有必要，我们还可以做一些进一步的操作来更好地组织这些块。例如，如果我们在处理单词，我们可能想要识别词类(形容词、名词、动词等。)或将单词简化为基本形式或词根形式。在后一个叫做<em class="lc">的词汇化</em>过程中，“穿梭”变成了“穿梭”，“狼”变成了“狼”</p><p id="70af" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">一旦我们的语言块被组织起来，更先进的自然语言处理技术可以被应用于理解语言。也许我们想探究一部作品中是否有共同的主题。或者，我们可能想分析一个著名公众人物的一系列演讲的意图或真实性。我们正在分析的语言的情绪是另一个调查的候选对象，就像确定关于一家公司的推文主要是正面的还是负面的。</p><p id="48ec" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">以下是NLP在实践中的一些例子:</p><ul class=""><li id="8aa1" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated">这本书是谁写的？帕特里克·尤拉使用自然语言处理技术来量化单词长度的分布，最常见的单词，以及其他写作风格的选择，当他帮助确定JK·罗琳是《布谷鸟的呼唤》的作者时</li><li id="62b9" class="ld le iq kh b ki lm kl ln ko lo ks lp kw lq la li lj lk ll bi translated"><a class="ae lb" href="https://pudding.cool/2017/02/vocabulary/" rel="noopener ugc nofollow" target="_blank">哪些说唱歌手词汇量最大？</a>马特·丹尼尔斯利用自然语言处理技术筛选嘻哈歌词，根据专辑中的词汇种类对艺术家进行排名，并对他们的风格选择提出一些理论。</li></ul><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi lr"><img src="../Images/0cff510c9e2f4b7c5923042859351f05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y4gAsq2tCbhhf5HWzqN39A.jpeg"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Outkast’s Deep Vocabulary &amp; Unique Style Confirmed with NLP.</figcaption></figure><ul class=""><li id="1545" class="ld le iq kh b ki kj kl km ko lf ks lg kw lh la li lj lk ll bi translated"><a class="ae lb" href="https://research.google.com/pubs/NaturalLanguageProcessing.html" rel="noopener ugc nofollow" target="_blank">谷歌搜索和其他谷歌项目。</a>谷歌的人在不断调整和改进他们的自然语言处理技术，这样他们就可以通过你的随机搜索，如“我的蛋奶酥不会膨胀”或“为什么我在阳光下打喷嚏？”来弄清楚你到底在问什么</li></ul><p id="8426" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">除了Google之外，NLP还有一个我们大多数人认为理所当然的常见用途:垃圾邮件过滤器。在本文的剩余部分，让我们深入探讨如何为文本消息构建一个简单的垃圾邮件过滤器——同样的方法也适用于电子邮件垃圾邮件过滤器。我的Jupyter笔记本中描述这个练习的全部内容可以在我的公共Github库<a class="ae lb" href="https://github.com/eversdyk/spam-filter-nlp-countvectorization" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="0591" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">步骤1:获取、导入和浏览数据。</p><p id="f0a8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">像往常一样，获取数据通常是最困难的部分。幸运的是，在这个练习中，我们可以访问垃圾短信收集库，这是一个超过5000条短信的集合，每条短信都标有“ham”(合法短信)或“Spam”(不请自来或不受欢迎的短信)。为了收集这些数据，进行了大量的工作，这些数据从多个来源进行了整理，包括新加坡国立大学计算机科学系、José María Gómez Hidalgo和Caroline Tagg等人的个人努力。</p><p id="adff" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我使用熊猫导入文件。我们可以看到前5行是什么样子——基本上只是每条短信的内容以及它是否是垃圾邮件。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mh"><img src="../Images/843291d94f982df4a2d24667654eccf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FhyPzVshyopfvAat_f-_Vw.png"/></div></div></figure><p id="461a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">请记住，我们的目标是从内容中预测消息是否是垃圾邮件。为此，我们将所有“垃圾”消息设为1，将“垃圾”消息设为0。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mi"><img src="../Images/582a29a4f8755a1f37b66917ba73b105.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*orqAq_PhSJJmFKdh3qrNqA.png"/></div></div></figure><p id="5c30" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">使用1和0来表示spam vs ham允许我们做一些有趣的事情。例如，现在我们可以取该列的平均值，以获得垃圾邮件占邮件总数的百分比。从100%中减去86.6%，也就是说86.6%的消息是合法的。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mi"><img src="../Images/773885fff5da4775709121fa53439d77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mC8kIP83ZowNT2P2mE0axQ.png"/></div></div></figure><p id="da5b" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">这将成为我们模型的基线，因为我们可以随机猜测一封邮件不是垃圾邮件，我们的正确率为86.6%。这列1和0现在将成为我们二元分类模型(如逻辑回归)的目标特征。</p><p id="08c7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">步骤2:为建模准备数据并使用计数矢量化提取要素。</p><p id="a657" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在仔细阅读短信时，我们注意到有重复的内容——多条内容完全相同的短信。这些重复不会增加任何额外的价值，所以我们可以用一个简单的命令删除它们。请注意，这稍微影响了我们的基线，将其增加到87%多一点:</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mi"><img src="../Images/27ff11f0c650b0146d54fcb54105e336.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kULeHXePOH0QiY7fLbOowA.png"/></div></div></figure><p id="acf2" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好了，真正的奇迹发生了。使用sci-kit learn的特征提取库，有一个函数叫做CountVectorizer。CountVectorizer转换我们的文本消息数据，对每条文本消息中的每个单词进行分离和分类，并为整个文本消息正文中的每个唯一单词创建一个特征列！结果就是所谓的稀疏矩阵。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mi"><img src="../Images/6254c47a2c7c092fbd9d6163e698ffdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AB7iiItgPk0QBDDoG8dLtA.png"/></div></div></figure><p id="4877" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">可以将稀疏矩阵视为在大部分为零的表中存储数据的有效方式。它不是记录所有这些零，而是记录非零值的位置和值。在我们的例子中，该表有5169行——每条文本消息占一行，8444列——在我们的文本消息正文中出现的每个唯一的单词占一列。在一个常规的表格中，总计超过4300万个单元格，但是稀疏矩阵只需要记录其中的4万个。计数矢量器将数字1放入这4万个单元格中的每一个，其中文本消息实际上包含8444个单词中的一个。</p><p id="4af0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了更好地形象化，让我们看看数据集的第一条文本消息中的单词“cine”。我已经把我们的稀疏矩阵转换成一个数据帧，用于探索目的。我们可以看到在稀疏矩阵的第一行中，单词“cine”的值是1。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mi"><img src="../Images/8aa0009894159a2add91263d00a1c116.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*12Vf6kKKbquGz_RwTEMHAw.png"/></div></div></figure><p id="62a6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还可以查看其他特征，如文本中的总字数、美元符号($)等特殊字符的出现次数，以及其他可以帮助我们确定短信是否为垃圾邮件的项目。然而，现在让我们使用我们的稀疏单词矩阵作为特征，看看它们是否能帮助我们预测火腿或垃圾邮件。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/a227b9558d5b2a32b44066902f6ec2f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*uGjfLRsagMQRQLtJxsdJaQ.jpeg"/></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Fun Fact — Spam musubi is a popular snack in Hawaii. Photo Cred: <a class="ae lb" href="https://www.flickr.com/photos/mrjoro/8065327258/in/photostream/" rel="noopener ugc nofollow" target="_blank">Joey Rozier</a></figcaption></figure><p id="7ff6" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第三步:创建一个模型，看看它是否超过我们的基线。</p><p id="a817" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">由于这是一个二元分类问题，逻辑回归是一个模型的合理选择。在我上周的文章中，我检验了线性回归来预测爱荷华州埃姆斯的房屋销售价格。逻辑回归与线性回归的不同之处在于，尽管两种方法都为不同的特征变量分配权重，但逻辑回归模型并不预测连续变量的<em class="lc">值</em>。相反，它预测只有两个选项的结果的<em class="lc">概率</em>，比如抛硬币，正面或反面。</p><p id="ecb4" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">好的，让我们继续分割我们的数据，并将训练数据输入逻辑回归求解器。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mk"><img src="../Images/f29810500566852a6046b2d8701be1ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rl3QFea0jJGo02DhlkQRLA.png"/></div></div></figure><p id="db5d" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Sci-kit learn完成了繁重的工作，我们现在有了一个模型！换句话说，我们现在有了每个独特单词的最佳系数，来帮助我们判断一条消息是否是垃圾邮件。我们可以通过将系数放入数据帧来查看这些权重。通过对这些值进行排序，我们可以看到最有可能出现在垃圾邮件中的10个单词:</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mi"><img src="../Images/0e4120fa29e40daaa45646cd39b1b607.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wEptsHN1wJroPQ9zJoCKlA.png"/></div></div></figure><p id="67e8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">之前我们留出了一些数据用于测试。让我们使用我们模型对测试数据应用我们新奇的垃圾邮件过滤器，看看结果:</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mi"><img src="../Images/920f6ab366b6b9e276017ce9cae48e70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6j5stLQSmAnkTmVW7k4Fsw.png"/></div></div></figure><p id="c3da" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们的准确率是98%，这让我们的基线相形见绌。我们对此感觉良好，但我们需要意识到我们的假阳性和假阴性。详细的分析表明，我们错误地过滤掉了2封有效的垃圾邮件，而另一方面，有23封垃圾邮件被遗漏，并意外地被标记为垃圾邮件。这些值可以接受吗？最终这取决于客户。如果我们为电子邮件提供商设计过滤器，他们可能会提出更严格的要求。</p><p id="02ee" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">第四步:改进模型或尝试另一种技术…？</p><p id="f8be" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">上面描述的方法实际上在幕后结合了几个额外的参数。我调整了停用词，即在标记化过程中被忽略的词。功能的最大数量限于5000个最常出现的单词。只考虑出现在至少两个文档中的单词。所有这些参数都是特定于CountVectorizer类的。</p><figure class="ls lt lu lv gt lw gh gi paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="gh gi mi"><img src="../Images/742865efe0d6de605e74cab87b210229.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5nAkOA6F-YG2dv0AVc9gWQ.png"/></div></div></figure><p id="8bd5" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">我们还可以做很多其他的改进。我们可以使用TF-IFD(术语频率，逆文档频率)矢量器对每个单词进行加权，而不是简单地对每个单词进行计数，以强调在一个文档中出现频率高于整个文档中其他部分的单词。我们还可以添加前面讨论过的其他特性，如消息长度、特殊字符或其他我们认为可能预测垃圾邮件的项目。这些额外的功能将与我们的术语矢量化过程分开管理，它们肯定有可能影响我们的模型。</p><p id="c933" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">作为最后一个想法，肯定有更多的NLP方法还没有出现在我的工具包中。有人在课堂上建议，多项式朴素贝叶斯方法可能更适合这种应用。我不熟悉这个概念，但我的初步研究表明，它可以让我们根据字数而不是单词出现次数来调整我们的模型计算。如果我发现自己参与了类似的NLP项目，我会花一些时间消化McCallum和Nigam对朴素贝叶斯文本分类事件模型的比较，期望它能改进我的模型。</p></div></div>    
</body>
</html>