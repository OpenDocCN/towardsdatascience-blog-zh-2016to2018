<html>
<head>
<title>A wizard’s guide to Adversarial Autoencoders: Part 2, Exploring latent space with Adversarial Autoencoders.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">敌对自动编码器向导指南:第2部分，探索敌对自动编码器的潜在空间。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-wizards-guide-to-adversarial-autoencoders-part-2-exploring-latent-space-with-adversarial-2d53a6f8a4f9?source=collection_archive---------1-----------------------#2017-08-07">https://towardsdatascience.com/a-wizards-guide-to-adversarial-autoencoders-part-2-exploring-latent-space-with-adversarial-2d53a6f8a4f9?source=collection_archive---------1-----------------------#2017-08-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/59ddbf50b8cb72203564a5b2396f11e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kAhlZ-y-NU86LyxLtNus3A.png"/></div></div></figure><p id="4c3d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">“这篇文章是</em> <a class="ae kx" href="https://medium.com/towards-data-science/a-wizards-guide-to-adversarial-autoencoders-part-1-autoencoder-d9a5f8795af4" rel="noopener"> <em class="kw">自动编码器向导:第1部分</em> </a> <em class="kw">的延续，如果你没有读过它，但熟悉自动编码器的基础知识，那么请继续。你需要了解一点概率论，可以在这里找到</em><a class="ae kx" href="http://www.deeplearningbook.org/contents/prob.html" rel="noopener ugc nofollow" target="_blank"><em class="kw"/></a><em class="kw">。”</em></p><p id="5d9b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">第1部分:<a class="ae kx" href="https://medium.com/towards-data-science/a-wizards-guide-to-adversarial-autoencoders-part-1-autoencoder-d9a5f8795af4" rel="noopener">自动编码器？</a></p><p id="03a5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们省略了第1部分，将一个值(0，0)传递给我们训练过的解码器(在输入端有2个神经元),并找到它的输出。它看起来模糊不清，没有代表一个清晰的数字，让我们得出结论，编码器<strong class="ka ir"> h </strong>(也称为潜在代码)的输出在特定空间中分布不均匀。</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ky"><img src="../Images/ac45f889d0aa4c9cf2b5a9822e86db26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e6rBH-75bZ5eUdFVTMdcEg.png"/></div></div></figure><p id="e26e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，我们在这一部分的主要目标将是迫使编码器输出与给定的先验分布相匹配，这个要求的分布可以是正态(高斯)分布、均匀分布、伽玛分布…然后，这将导致潜在代码(编码器输出)在给定的先验分布上均匀分布，这将允许我们的解码器学习从先验到数据分布的映射(在我们的情况下是MNIST图像的分布)。</p><blockquote class="ld"><p id="197d" class="le lf iq bd lg lh li lj lk ll lm kv dk translated">如果你完全不理解上面的段落。</p></blockquote><p id="dfe7" class="pw-post-body-paragraph jy jz iq ka b kb ln kd ke kf lo kh ki kj lp kl km kn lq kp kq kr lr kt ku kv ij bi translated"><em class="kw">假设你在上大学，并且选择了机器学习(我想不出其他课程:p)作为你的课程之一。现在，如果课程老师不提供教学大纲指南或参考书，你将为期末考试学习什么？(假设你的课没有帮助)。</em></p><p id="d972" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你被问及ML的任何子领域的问题，你会怎么做？用你知道的东西化妆？？</p><p id="0437" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果我们不将编码器输出限制为遵循某种分布，解码器就无法学习任何数字到图像的映射，就会发生这种情况。</p><p id="3937" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">但是，如果你有一份合适的教学大纲指南，你可以在考试前浏览一下材料，这样你就会对考试有所了解。</p><p id="3393" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><em class="kw">同样，如果我们迫使编码器输出遵循一个已知的分布，如高斯分布，那么它可以学习扩展潜在代码以覆盖整个分布，并学习无任何间隙的映射。</em></p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ls"><img src="../Images/6d48d1c23933f40da5047e06431bf789.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k0vuBEEgmKcbbap_q_HeWQ.png"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Good or Bad?</figcaption></figure></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><p id="bcf1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们现在知道自动编码器有两个部分，每个部分执行完全相反的任务。</p><blockquote class="me mf mg"><p id="e3fd" class="jy jz kw ka b kb kc kd ke kf kg kh ki mh kk kl km mi ko kp kq mj ks kt ku kv ij bi translated">两个本性相似的人永远不可能单独相处，只有两个对立面才能和谐。</p><p id="9ecf" class="jy jz kw ka b kb kc kd ke kf kg kh ki mh kk kl km mi ko kp kq mj ks kt ku kv ij bi translated">—拉姆·莫汉</p></blockquote><p id="0dfc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">用于从输入获得潜在代码(编码器输出)的编码器，其约束条件是潜在代码的尺寸应小于输入尺寸，其次是接收该潜在代码并尝试重建原始图像的解码器。</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mk"><img src="../Images/0d6884e264da8cf003b8592d375ca217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E8lVf2XGg4uDSD9wUTnD9g.png"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Autoencoder Block diagram</figcaption></figure><p id="8cd5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">让我们看看当我们先前实现我们的自动编码器时，编码器输出是如何分布的(checkout <a class="ae kx" href="https://medium.com/towards-data-science/a-wizards-guide-to-adversarial-autoencoders-part-1-autoencoder-d9a5f8795af4" rel="noopener"> part 1 </a>):</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ml"><img src="../Images/5074a67c1e8b0dd3d177b6ba844f7cf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LSYKON0k8RjgPM5vZ0YYsg.png"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Encoder histogram and distribution</figcaption></figure><p id="ecb5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">从分布图(向右)我们可以清楚地看到，我们的编码器的输出分布无处不在。最初，似乎分布集中在0，大多数值为负。在训练的后期阶段，当与正样本相比时，负样本分布在远离0的地方(同样，如果我们再次运行实验，我们甚至可能得不到相同的分布)。这导致了编码器分布中的大量间隙，如果我们想将解码器用作生成模型，这不是一件好事。</p><blockquote class="ld"><p id="b360" class="le lf iq bd lg lh li lj lk ll lm kv dk translated">但是，为什么在我们的编码器分配中，这些差距是一件坏事呢？</p></blockquote><p id="4021" class="pw-post-body-paragraph jy jz iq ka b kb ln kd ke kf lo kh ki kj lp kl km kn lq kp kq kr lr kt ku kv ij bi translated">如果我们给一个训练有素的解码器一个落在这个间隙中的输入，那么它会给出看起来奇怪的图像，在输出端不代表数字(我知道，第三次)。</p><p id="e5ca" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">另一个重要的观察结果是，训练自动编码器给了我们具有相似图像的潜在代码(例如，全是2或3..)在欧几里得空间中彼此远离。例如，这可能导致我们数据集中的所有2被映射到空间中的不同区域。我们希望通过将相似数字的图像保持在一起，使潜在代码具有有意义的表示。有些事情是这样的:</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mm"><img src="../Images/9eaa4d28053536b7588450ede5c2748b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4RlC6Rbln8AOD3XdzrJhSA.png"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">A good 2D distribution</figcaption></figure><p id="1d5a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">不同颜色的区域代表一类图像，请注意相同颜色的区域是如何相互靠近的。</p><p id="b559" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们现在来看看可以解决上述一些问题的对抗性自动编码器。</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><p id="c314" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">对抗自动编码器与自动编码器非常相似，但是编码器以对抗的方式被训练，以迫使它输出所需的分布。</p><p id="4846" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">理解对抗性自动编码器(AAEs)需要生成性对抗性网络(GANs)的知识，我写了一篇关于GANs的文章，可以在这里找到:</p><div class="mn mo gp gr mp mq"><a href="https://medium.com/towards-data-science/gans-n-roses-c6652d513260" rel="noopener follow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd ir gy z fp mv fr fs mw fu fw ip bi translated">甘斯·恩罗斯</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">“本文假设读者熟悉神经网络和张量流的使用。如果没有，我们请求您…</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">medium.com</p></div></div><div class="mz l"><div class="na l nb nc nd mz ne jw mq"/></div></div></a></div><p id="b42c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果您已经了解GANs，这里有一个快速回顾(如果您记得接下来的两点，请随意跳过这一部分):</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div class="ab gu cl nf"><img src="../Images/aa80ad3a2c8c2ae2632b99e0759319f1.png" data-original-src="https://miro.medium.com/v2/format:webp/1*it0RKKXp5yjRqcyczEw_Kw.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Discriminator</figcaption></figure><figure class="kz la lb lc gt jr gh gi paragraph-image"><div class="ab gu cl nf"><img src="../Images/8b426a54f1b7da1528fb60f0e8442040.png" data-original-src="https://miro.medium.com/v2/format:webp/1*D6j2k23kKUGHJEBgJftH2A.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Generator</figcaption></figure><ul class=""><li id="ec0e" class="ng nh iq ka b kb kc kf kg kj ni kn nj kr nk kv nl nm nn no bi translated">GANs有两个神经网络，一个生成器和一个鉴别器。</li><li id="a281" class="ng nh iq ka b kb np kf nq kj nr kn ns kr nt kv nl nm nn no bi translated">生成器，很好地生成假图像。我们训练鉴别器来区分数据集的真实图像和生成器生成的假图像。</li><li id="9a5a" class="ng nh iq ka b kb np kf nq kj nr kn ns kr nt kv nl nm nn no bi translated">生成器最初会生成一些随机噪声(因为它的权重是随机的)。在训练我们的鉴别器来区分这种随机噪声和真实图像之后，我们将把我们的生成器连接到我们的鉴别器，并且仅通过具有鉴别器输出应该为1的约束的生成器进行反向传播(即，鉴别器应该将生成器的输出分类为真实图像)。</li><li id="b71b" class="ng nh iq ka b kb np kf nq kj nr kn ns kr nt kv nl nm nn no bi translated">我们将再次训练我们的鉴别器来区分来自我们的生成器的新的假图像和来自我们的数据库的真实图像。然后训练生成器生成更好的假图像。</li><li id="56d1" class="ng nh iq ka b kb np kf nq kj nr kn ns kr nt kv nl nm nn no bi translated">我们将继续这个过程，直到生成器变得非常擅长生成假图像，以至于鉴别器不再能够区分真实图像和假图像。</li><li id="6848" class="ng nh iq ka b kb np kf nq kj nr kn ns kr nt kv nl nm nn no bi translated">最后，我们将剩下一个生成器，它可以产生看起来真实的假图像，给定一组随机的数字作为输入。</li></ul></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><p id="0b22" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是一个对抗性自动编码器的框图:</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nu"><img src="../Images/73a52f45890b8024a367021a7216667c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nnf4UUq9Uuf2l19iCYaNfg.png"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">AAE block diagram</figcaption></figure><ul class=""><li id="aa99" class="ng nh iq ka b kb kc kf kg kj ni kn nj kr nk kv nl nm nn no bi translated">x →输入图像</li><li id="3bf0" class="ng nh iq ka b kb np kf nq kj nr kn ns kr nt kv nl nm nn no bi translated">q(z/x) →编码器输出给定输入x</li><li id="4638" class="ng nh iq ka b kb np kf nq kj nr kn ns kr nt kv nl nm nn no bi translated">z →潜码(假输入)，z由q(z/x)得出</li><li id="177e" class="ng nh iq ka b kb np kf nq kj nr kn ns kr nt kv nl nm nn no bi translated">z' →具有所需分布的实际输入</li><li id="66d5" class="ng nh iq ka b kb np kf nq kj nr kn ns kr nt kv nl nm nn no bi translated">p(x/z)→给定z的解码器输出</li><li id="d8a9" class="ng nh iq ka b kb np kf nq kj nr kn ns kr nt kv nl nm nn no bi translated">D() →鉴别器</li><li id="b40c" class="ng nh iq ka b kb np kf nq kj nr kn ns kr nt kv nl nm nn no bi translated">x _→重建图像</li></ul><p id="e890" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">同样，我们的主要目的是迫使编码器输出具有给定先验分布的值(这可以是正态分布，γ分布..分发)。我们将使用编码器(q(z/x))作为我们的生成器，鉴别器来判断样本是来自先前的分布(p(z))还是来自编码器(z)和解码器(p(x/z))的输出，以恢复原始输入图像。</p><p id="228b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了理解这种架构如何用于在编码器输出上强加先验分布，让我们看一下如何训练AAE。</p><p id="8910" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">训练AAE有两个阶段:</p><ul class=""><li id="1b2f" class="ng nh iq ka b kb kc kf kg kj ni kn nj kr nk kv nl nm nn no bi translated"><strong class="ka ir">重建阶段:</strong></li></ul><p id="7b5c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将训练编码器和解码器，以最小化重建损失(输入和解码器输出图像之间的均方误差，查看第1部分了解更多细节)。忘记鉴别器甚至存在于这个阶段(我已经将这个阶段不需要的部分变灰)。</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nu"><img src="../Images/d7d4d8e673823d5308bf1e48ff87bcfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DKPl7YOnX-8FJQuHAZop-g.png"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Reconstruction Phase</figcaption></figure><p id="989e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">像往常一样，我们将输入传递给编码器，编码器将给出我们的潜在代码，稍后，我们将把这个潜在代码传递给解码器，以取回输入图像。我们将反向传播编码器和解码器的权重，以便减少重建损失。</p><ul class=""><li id="51ef" class="ng nh iq ka b kb kc kf kg kj ni kn nj kr nk kv nl nm nn no bi translated"><strong class="ka ir">正规化阶段:</strong></li></ul><p id="826a" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在这一阶段，我们必须训练鉴别器和生成器(它只不过是我们的编码器)。忘了解码器的存在吧。</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nu"><img src="../Images/7915146777dc3c4e34531ce48d811671.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_pIXKcCCqJRNmIWTRymJzA.png"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Training the discriminator</figcaption></figure><p id="542f" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">首先，我们训练鉴别器来分类编码器输出(z)和一些随机输入(z '，这将有我们需要的分布)。例如，随机输入可以正态分布，平均值为0，标准偏差为5。</p><p id="c225" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，如果我们传入具有期望分布(真实值)的随机输入，鉴别器应该给我们输出1，当我们传入编码器输出时，应该给我们输出0(假值)。直观上，编码器输出和鉴别器的随机输入应该具有相同的大小。</p><p id="c4a3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下一步将是迫使编码器输出具有期望分布的潜在代码。为此，我们将把编码器输出作为输入连接到鉴频器:</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nu"><img src="../Images/894220f3909d07ffaf79b0b935d63622.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DoJESN2LvxpxNVYADRJXWw.png"/></div></div></figure><p id="9b07" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将把鉴别器权重固定为它们当前的值(使它们不可跟踪),并在鉴别器输出端把目标值固定为1。稍后，我们将图像传入编码器，并找到鉴别器输出，然后使用该输出来查找损失(交叉熵成本函数)。我们将仅通过编码器权重进行反向传播，这将导致编码器学习所需的分布，并产生具有该分布的输出(将鉴别器目标固定为1将导致编码器通过查看鉴别器权重来学习所需的分布)。</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><p id="06ef" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">既然理论部分已经完成，让我们看看如何使用tensorflow实现它。</p><p id="45bc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下面是第2部分的完整代码(它与我们在第1部分中讨论的内容非常相似):</p><div class="mn mo gp gr mp mq"><a href="https://github.com/Naresh1318/Adversarial_Autoencoder/blob/master/adversarial_autoencoder.py" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab fo"><div class="ms ab mt cl cj mu"><h2 class="bd ir gy z fp mv fr fs mw fu fw ip bi translated">naresh 1318/Adversarial _自动编码器</h2><div class="mx l"><h3 class="bd b gy z fp mv fr fs mw fu fw dk translated">对抗性自动编码器向导</h3></div><div class="my l"><p class="bd b dl z fp mv fr fs mw fu fw dk translated">github.com</p></div></div><div class="mz l"><div class="nv l nb nc nd mz ne jw mq"/></div></div></a></div><p id="27e8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">像往常一样，我们有帮手:</p><figure class="kz la lb lc gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="dd6e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我没有改变编码器和解码器的架构:</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div class="ab gu cl nf"><img src="../Images/c1cc5c257ca37057230d443d658dd647.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Hud7t2vLY2JIP3SXn4WTDA.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Encoder Architecture</figcaption></figure><figure class="kz la lb lc gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><figure class="kz la lb lc gt jr gh gi paragraph-image"><div class="ab gu cl nf"><img src="../Images/ad10a7ed678480b4dcb49247e2f7d460.png" data-original-src="https://miro.medium.com/v2/format:webp/1*0t7JrvUqyzg7AdQGDjZkRw.png"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Decoder Architecture</figcaption></figure><figure class="kz la lb lc gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="abb6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这是鉴别器架构:</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oc"><img src="../Images/8eb884362053ddaf7a721585c45d73fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Df3_l66beZqsqRe5i6lZRw.png"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Discriminator Architecture</figcaption></figure><p id="3ad8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">它类似于我们的编码器架构，输入形状是<code class="fe nw nx ny nz b">z_dim</code>(实际上是<code class="fe nw nx ny nz b">batch_size, z_dim</code>)，输出形状是1 ( <code class="fe nw nx ny nz b">batch_size, 1</code>)。</p><figure class="kz la lb lc gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="89da" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">注意，在分别为编码器、解码器和鉴别器定义密集层时，我使用了前缀<code class="fe nw nx ny nz b">e_</code>、<code class="fe nw nx ny nz b">d_</code>和<code class="fe nw nx ny nz b">dc_</code>。使用这些符号有助于我们轻松收集要训练的重量:</p><figure class="kz la lb lc gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="5db2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们现在知道训练AAE有两个部分，首先是重建阶段(我们将训练我们的自动编码器来重建输入)和正则化阶段(首先训练鉴别器，然后是编码器)。</p><p id="0b21" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将编码器输出连接到解码器输入，开始重建阶段:</p><figure class="kz la lb lc gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="8e09" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我每次调用我们定义的架构时都使用<code class="fe nw nx ny nz b">tf.variable_scope(tf.get_variable_scope())</code>，因为它允许我们在所有函数调用中共享权重(只有在<code class="fe nw nx ny nz b">reuse=True</code>时才会发生)。</p><p id="d4e9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">损失函数通常是均方误差(MSE)，我们在<a class="ae kx" href="https://medium.com/towards-data-science/a-wizards-guide-to-adversarial-autoencoders-part-1-autoencoder-d9a5f8795af4" rel="noopener">第1部分</a>中遇到过。</p><figure class="kz la lb lc gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="0375" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">类似于我们在第1部分中所做的，优化器(它将更新权重以减少损失[希望如此])实现如下:</p><figure class="kz la lb lc gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><figure class="kz la lb lc gt jr"><div class="bz fp l di"><div class="od ob l"/></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">I couldn’t help it :P</figcaption></figure><p id="aee4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">重建阶段到此结束，接下来我们进入正则化阶段:</p><p id="c8de" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们将首先训练鉴别器来区分真实的分布样本和来自生成器(这里是编码器)的假样本。</p><figure class="kz la lb lc gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><ul class=""><li id="2509" class="ng nh iq ka b kb kc kf kg kj ni kn nj kr nk kv nl nm nn no bi translated"><code class="fe nw nx ny nz b">real_distribution</code>是一个占位符，我用它将所需分布的值传递给鉴别器(这将是我们真正的输入)。</li><li id="18cc" class="ng nh iq ka b kb np kf nq kj nr kn ns kr nt kv nl nm nn no bi translated"><code class="fe nw nx ny nz b">encoder_output</code>连接到鉴别器，鉴别器将为我们提供伪输入的鉴别器输出<code class="fe nw nx ny nz b">d_fake</code>。</li><li id="9aec" class="ng nh iq ka b kb np kf nq kj nr kn ns kr nt kv nl nm nn no bi translated">这里是<code class="fe nw nx ny nz b">reuse=True</code>，因为我们希望在第二次调用中使用相同的鉴别器权重(如果没有指定，那么tensorflow会创建一组新的随机初始化的权重[但是因为我使用了<code class="fe nw nx ny nz b">get_variable()</code>来创建权重，所以会出错])。</li></ul><p id="20c6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我用来训练鉴别器的损失函数是:</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oe"><img src="../Images/d21c966ed20be315d3e1c383408146b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y4e01PCQS1shXfDNP9MXyw.png"/></div></div><figcaption class="lt lu gj gh gi lv lw bd b be z dk">Cross entropy cost</figcaption></figure><p id="efb8" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这很容易在tensorflow中实现，如下所示:</p><figure class="kz la lb lc gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="e354" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">下一步将是训练发电机(编码器)输出所需的分布。正如我们已经讨论过的，这需要将鉴别器的目标设置为1，并将<code class="fe nw nx ny nz b">d_fake</code>变量(连接到鉴别器的编码器【返回查看】)设置为1。发电机损耗又是交叉熵代价函数。</p><figure class="kz la lb lc gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="a910" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了在训练期间只更新所需的权重，我们需要将所有这些收集的权重传递给<code class="fe nw nx ny nz b">minimize()</code>下的<code class="fe nw nx ny nz b">var_list</code>参数。因此，我已经在它们的训练阶段传递了鉴别器变量(<code class="fe nw nx ny nz b">dc_var</code>)和生成器(编码器)变量(<code class="fe nw nx ny nz b">en_var</code>)。</p><figure class="kz la lb lc gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="56ce" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们差不多完成了，剩下的就是将我们的MNIST图像作为输入和目标，以及大小为<code class="fe nw nx ny nz b">batch_size, z_dim</code>的随机数作为鉴别器的输入(这将形成所需的分布)。</p><p id="2ba9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">训练部分可能看起来很吓人，但是盯着它看一会儿，你会发现它非常直观。</p><figure class="kz la lb lc gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="b308" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我在培训中使用的参数如下:</p><figure class="kz la lb lc gt jr"><div class="bz fp l di"><div class="oa ob l"/></div></figure><p id="5074" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我用所需的分布训练了300个时期的模型，开始一个正态(高斯)分布，平均值为0和5，作为它的标准分布。下面是编码器输出和所需的分布及其直方图:</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi of"><img src="../Images/c70cc51fe2c4ef35bdb0d43b27df5dbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l0qbCvNNTiUb5i_Nk9Uq9Q.png"/></div></div></figure><p id="8af4" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">编码器分布几乎与要求的分布相匹配，直方图显示其中心为零。很好，但是鉴别器呢，它的表现如何？</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi og"><img src="../Images/8dc0e1a79d2ee2f1f4bd6aba66a67ef3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F-W72TQ49-_XN9OhzUbkwg.png"/></div></div></figure><p id="33b2" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">好消息是，鉴频器损耗正在增加(变得更糟)，这告诉我们很难区分真假输入。</p><p id="272b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">最后，由于我们有了<code class="fe nw nx ny nz b">z_dim=2</code> (2D值)，我们可以将属于所需分布的随机输入传递给我们训练过的解码器，并将其用作生成器(我知道，我一直将编码器称为生成器，因为它向鉴别器生成假输入，但由于解码器已经学会映射这些假输入以在其输出端获得数字，所以我们可以将我们的解码器称为生成器)。我以固定的间隔将(-10，-10)到(10，10)的值传递给解码器，并存储其输出。下面是数字的分布情况:</p><figure class="kz la lb lc gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi oh"><img src="../Images/f9317eda7b743f5bb27b7e073dd9ee9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xhrZT9rJgNbVYo6V.png"/></div></div></figure><p id="01e9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">上图显示了一个清晰的数字聚类及其在我们探索解码器训练值时的转换。AAE使编码器输出分布中的间隙变得更近，这允许我们将解码器用作发电机。</p><p id="48bc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">就是这样！。在下一部分中，我们将重点讨论如何使用AAE将图像风格与其内容分开。这很容易实现，因为我们已经完成了大部分相对困难的部分。</p></div><div class="ab cl lx ly hu lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="ij ik il im in"><p id="34d6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">希望你喜欢AAEs上的这篇文章。我会公开鼓励任何批评或建议来改进我的工作。</p><p id="6936" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如果你认为这个内容值得分享点击❤️，我喜欢它发送给我的通知！！</p><p id="5701" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">← Part 1: <a class="ae kx" href="https://medium.com/towards-data-science/a-wizards-guide-to-adversarial-autoencoders-part-1-autoencoder-d9a5f8795af4" rel="noopener"> Autoencoder？</a></p><p id="9ab9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">→第3部分:<a class="ae kx" href="https://medium.com/towards-data-science/a-wizards-guide-to-adversarial-autoencoders-part-3-disentanglement-of-style-and-content-89262973a4d7" rel="noopener">风格与内容的解开。</a></p></div></div>    
</body>
</html>