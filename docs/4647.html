<html>
<head>
<title>Generative Adversarial Networks using Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用张量流的生成对抗网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/generative-adversarial-networks-using-tensorflow-c8f4518406df?source=collection_archive---------5-----------------------#2018-08-28">https://towardsdatascience.com/generative-adversarial-networks-using-tensorflow-c8f4518406df?source=collection_archive---------5-----------------------#2018-08-28</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="b4ab" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">这篇文章是关于生成对抗网络或简称 GANs 的初级读本。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e2294e80182787f4a43467044ad28f57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5uoa7hsDsdEdMdaB-hayXQ.jpeg"/></div></div></figure><p id="6f9c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">生成对抗网络(GANs)是深度神经网络架构，由一组两个相互竞争的网络组成，因此得名“对抗”。2014 年，伊恩·古德菲勒和蒙特利尔大学的其他研究人员，包括约舒阿·本吉奥在一篇论文中介绍了 gan。</p><p id="a70b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">甘旨在模拟任何数据分布。也就是说，甘人可以被训练创造出与我们的世界在任何领域都极其相似的世界:图像、音乐、演讲、散文。为了更好地理解我的意思，让我们看一个例子</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="ab gu cl lo"><img src="../Images/66be47cfb2c02531b762ed14b2996283.png" data-original-src="https://miro.medium.com/v2/format:webp/1*-gFsbymY9oJUQJ-A3GTfeg.png"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk">The Mona Lisa Analogy</figcaption></figure><p id="98d9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们考虑这样一个场景，一个伪造者试图伪造达芬奇的著名肖像画，一个侦探试图抓住伪造者的画。现在，侦探可以接触到真正的肖像，因此可以比较伪造者的画作，找出哪怕是最细微的差异。所以，在机器学习的术语中，伪造者被称为<strong class="kt ir">“生成器”</strong>并生成假数据，侦探被称为<strong class="kt ir">“鉴别器”</strong>，负责将生成器的输出分类为假或真。</p><p id="4c10" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">从某种意义上来说，gan 的计算成本很高，它们需要高性能的 GPU 来产生良好的结果。下面是 GANs 在 8 个特斯拉 V 100 的 GPU 上训练了 4 天的几个纪元后制作的一些假名人脸！！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi lt"><img src="../Images/fc9b417df717aef4d6999b52fb61a8fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/0*ZzIUVzjIpj3OnaQ3"/></div></figure><p id="47e3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我们将使用一个硬件不太密集的例子。在这篇文章中，我们将使用<strong class="kt ir"> MNIST </strong>数据集来玩一个简单的 GAN，它将使用<strong class="kt ir"> Tensorflow 的层 API </strong>来制作。在研究代码之前，我将讨论 GANs 通常会出现的两个问题:</p><ol class=""><li id="4b21" class="lu lv iq kt b ku kv kx ky la lw le lx li ly lm lz ma mb mc bi translated"><strong class="kt ir">鉴别器过功率发生器:</strong>有时鉴别器会因为最细微的差别而开始将所有生成的例子归类为假的。因此，为了纠正这一点，我们将使鉴频器的输出不缩放，而不是 sigmoid(它只产生 0 或 1)。</li><li id="6c33" class="lu lv iq kt b ku md kx me la mf le mg li mh lm lz ma mb mc bi translated"><strong class="kt ir">模式崩溃:</strong>生成器发现鉴别器中的一些潜在弱点，并利用该弱点连续产生类似的例子，而不管输入的变化。</li></ol><p id="50dc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">所以，最后，让我们来看看代码！！</p><p id="4835" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，我们导入必要的库并从<code class="fe mi mj mk ml b">tensorflow.examples.tutorials.mnist</code>读入 MNIST 数据集。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="26a6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，我们将创建代表两个网络的两个函数。注意第二个参数“重用”，稍后我会解释它的效用。</p><p id="3399" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">两个网络都有两个隐藏层和一个输出层，它们是密集或完全连接的层。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="a02f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">现在，我们为输入创建占位符。<code class="fe mi mj mk ml b">real_images</code>是来自 MNIST 的实际图像，<code class="fe mi mj mk ml b">z</code>是来自实际图像的 100 个随机像素。为了让鉴别器进行分类，它首先必须知道真实图像的样子，因此我们对鉴别器函数进行了两次调用，前两次调用学习真实图像，后两次调用识别假图像。<code class="fe mi mj mk ml b">reuse</code>设置为 true 是因为当两个函数调用中使用相同的变量时，张量流计算图会得到一个不明确的信号，并倾向于抛出值错误。因此，我们将重用参数设置为<code class="fe mi mj mk ml b">True</code>以避免这样的错误。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="e010" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，我们为我们的网络定义损失函数。<code class="fe mi mj mk ml b">labels_in</code>参数给出了损失函数的目标标签，基于该标签进行计算。<code class="fe mi mj mk ml b">D_real_loss</code>的第二个参数是<code class="fe mi mj mk ml b">tf.ones_like</code>,因为我们的目标是为所有真实图像生成真实标签，但是我们添加了一点噪声，以解决功率过大的问题。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="9015" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">当我们有两个独立的网络相互作用时，我们必须考虑每个网络范围内的变量。因此，在定义功能时，设置了<code class="fe mi mj mk ml b"><strong class="kt ir">tf.variable_scope</strong></code> <strong class="kt ir"> </strong>。在这个例子中，我们将使用 Adam 优化器。我们设置 batch_size 和 epochs 的数量。增加历元会带来更好的结果，所以可以尝试一下(如果你有 GPU 的话更好)。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="93b2" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">最后，我们启动会话，并使用 tensorflow 助手函数中的<code class="fe mi mj mk ml b">next_batch()</code>方法来训练网络。我们从生成器生成的样本中随机抽取一个样本，并将其添加到样本列表中。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mm mn l"/></div></figure><p id="a6dd" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">绘制来自<code class="fe mi mj mk ml b">samples</code>的第一个值显示了第一个时期后的发电机性能。将其与来自<code class="fe mi mj mk ml b">samples</code>的最后一个值进行比较，显示发电机的运行情况。</p><p id="8c7e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">输出如下所示:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mo"><img src="../Images/dcc488e025f0bbe4909b65936b9876e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:504/format:webp/1*hpvhkem97nXkpT1RZsygiw.png"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk">Sample after 0th epoch</figcaption></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mp"><img src="../Images/58a3b50ae2f80c8ff46a23ee0130ce9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:492/format:webp/1*5VLG32BAF8golzglyefKgg.png"/></div><figcaption class="lp lq gj gh gi lr ls bd b be z dk">Sample after 99th epoch</figcaption></figure><p id="d7dc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这些是非常差的结果，但是因为我们仅仅在 CPU 上训练我们的模型，所以学习是相当弱的。但是我们可以看到，模型开始以更简洁的方式生成像素，我们可以看出这个数字是“3”。</p><p id="31a8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">GANs 应该在 GPU 上接受训练，所以尝试使用 GPU 或者简单地使用 google colab 来获得更好的结果。</p><p id="a2a3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">好的，这是一个在 Tensorflow 上从零开始建立的生成性对抗网络模型。点击下面的横幅获得完整的代码。</p><p id="a55b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">下次见！！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><a href="https://github.com/Tathagatd96/Generative-Adversarial-Networks-using-Tensorflow"><div class="gh gi mq"><img src="../Images/d977fab5d327a6b41a730f512f9ab9ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jgckTkLuwup2wuqhRW3bfw.jpeg"/></div></a></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><a href="https://github.com/Tathagatd96"><div class="gh gi mq"><img src="../Images/860a29e8bf7f7488a2147bb0ec5e0bc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bgpX0os8Qrq1rLL1u4ealg.jpeg"/></div></a></figure></div></div>    
</body>
</html>