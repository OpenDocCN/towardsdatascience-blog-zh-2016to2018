<html>
<head>
<title>How to build a non-geographical map #1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何构建非地理地图#1</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-build-a-non-geographical-map-1-8d3373e83d6c?source=collection_archive---------7-----------------------#2018-08-30">https://towardsdatascience.com/how-to-build-a-non-geographical-map-1-8d3373e83d6c?source=collection_archive---------7-----------------------#2018-08-30</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="cd49" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">或者如何映射相似性以进行偶然的数据探索(使用 Python)</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/5fb9a6fcbb77a02e1d66d773899c53dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*algP9YGeEfWsJEqASMattQ.png"/></div></div></figure><p id="d1a5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">地图是数据可视化的强大设计对象。它们通常用于强调元素之间的空间关系和比较多个变量。在非地理数据的情况下，维度减少技术允许我们在二维空间中映射相似性，而不损害初始信息的丰富性。</p><p id="d7b1" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><em class="ln">🔗链接到</em><a class="ae lo" rel="noopener" target="_blank" href="/how-to-build-a-non-geographical-map-2-340256ad9f16"><em class="ln">#第二部分:如何将散点图变成交互式地图</em> </a></p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h1 id="6503" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">#第 1 部分:降维和可视化</h1><h1 id="ceb2" class="lw lx iq bd ly lz mo mb mc md mp mf mg jw mq jx mi jz mr ka mk kc ms kd mm mn bi translated"><strong class="ak"> <em class="mt">第一步。设置特征和初始尺寸</em>和</strong></h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mu"><img src="../Images/acaf23d49cccedb5efc791dbfd1e72b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U6JqXTIZk4VVXAiiQRmq8A.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk"><em class="mt">In a geographical map, each element’s coordinates are inherently defined by its position. An element’s position is made of three parameters: latitude, longitude and elevation. To represent locations on Earth, the geographic coordinate system uses either a spherical coordinate system (globe) or a cartesian coordinate system (flat map). To transform the Earth’s three-dimensional space into a two-dimensional map, we use map projection techniques, the most common of which is the Mercator’s cylindrical projection.</em></figcaption></figure><p id="34b6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">为了以类似地图的方式可视化您的非地理数据，您需要<strong class="kt ir">将每个元素(或地图上的点)视为由一组特定的特征(或属性)定义的。</strong></p><p id="f785" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这组要素在整个数据集中必须是<strong class="kt ir">常量</strong>。这意味着每个元素可以通过给相同的特征赋予不同的值来描述。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mz"><img src="../Images/bf44925fa8f78776dd3c7b95d3893336.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BQ9LkNUGPuP6zfEx-Q0R0g.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">This is what your dataset should look like.</figcaption></figure><p id="cd84" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">要确定哪些属性最能描述您的数据，您可以问自己:</p><p id="3ec6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> <em class="ln">“是什么直观地让两个元素相似，又是什么把它们区分开来？”</em>T19】</strong></p><p id="9b21" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在地图上，越靠近的两个元素越相似。距离越远，差异越大。</p><h2 id="3f44" class="na lx iq bd ly nb nc dn mc nd ne dp mg la nf ng mi le nh ni mk li nj nk mm nl bi translated"><strong class="ak">示例- </strong>根据技能和知识相似性绘制职业图</h2><p id="d404" class="pw-post-body-paragraph kr ks iq kt b ku nm jr kw kx nn ju kz la no lc ld le np lg lh li nq lk ll lm ij bi translated">在本例中，我想使用<a class="ae lo" href="https://www.onetcenter.org/database.html" rel="noopener ugc nofollow" target="_blank"> ONET 开放式数据库</a>，根据所需技能和知识的相似性来表示职位。</p><p id="e4ca" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我非常幸运，因为这个数据集组织得非常好。所有的职业都由相同的一套技能(知识也是一样)来描述，并且每个职业都根据重要性(这项技能对完成工作有多重要)和级别(工作所需的专业知识水平)来细分。“数据值”栏指定各自的等级。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nr"><img src="../Images/a6b6f2353b1d1df982dc6c2f04aea5fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fun9BDbCT06PBJKBL84tNg.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk"><a class="ae lo" href="https://www.onetcenter.org/dictionary/23.0/excel/skills.html" rel="noopener ugc nofollow" target="_blank">ONET skills.xlsx</a></figcaption></figure><p id="3cad" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我将每个技能和知识项目定义为一个单独的特性:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/9c0c2a9d60b6b1172f6c2793ec3634d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MYVXuEadEp8_767Spj3Jaw.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">This is what my dataset should look like after cleaning</figcaption></figure><p id="a0ec" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">由于原始数据集的质量，这一部分相当容易:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nt"><img src="../Images/7b813e41430633ac2339c749e0518fee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FmRNAz8vzM6vv5n5O9DepQ.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">📝&gt;&gt; Check out the full notebooks <a class="ae lo" href="https://github.com/fannykassapian/python_dimensionality_reduction" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="a125" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我现在只剩下一个矩阵，它的行向量是工作(n=640)，列是技能和知识参数(p=134)。</p><p id="4e00" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在机器学习中，“维度”只是指数据集中的特征(或属性，或变量)的数量。</p><p id="e296" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> <em class="ln">由于每个元素都是用 134 个参数来描述的，所以我们需要一个 134 维的空间来完整的表示它……很难描绘，不是吗？</em> </strong></p><p id="6d4c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">让我们看看如何因式分解这个矩阵，以便将其表示为一个二维空间。</p></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h1 id="e666" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">第二步。降低维度</h1><blockquote class="nu"><p id="f252" class="nv nw iq bd nx ny nz oa ob oc od lm dk translated">我们想要创建一个较低维度的表示，在这里我们保留一些来自较高维度空间的结构。T3】</p></blockquote><p id="9c9a" class="pw-post-body-paragraph kr ks iq kt b ku oe jr kw kx of ju kz la og lc ld le oh lg lh li oi lk ll lm ij bi translated">本能地，我们希望在原始空间中彼此靠近的点在 2D 中彼此靠近。这同样适用于远点。</p><p id="1f46" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">手工完成这项任务是不可能的。所以我四处寻找降维算法。</p><h2 id="b172" class="na lx iq bd ly nb nc dn mc nd ne dp mg la nf ng mi le nh ni mk li nj nk mm nl bi translated">没有免费的午餐</h2><p id="9cbb" class="pw-post-body-paragraph kr ks iq kt b ku nm jr kw kx nn ju kz la no lc ld le np lg lh li nq lk ll lm ij bi translated">在我们讨论它们之前，请注意<strong class="kt ir">没有一种算法适合所有问题。这个简单(但经常被遗忘)的事实被幽默地称为<strong class="kt ir">“没有免费的午餐”定理</strong>。每个模型都依赖于一些假设来简化现实。但是在某些情况下，这些假设会失效。因此，它们产生了不准确的现实版本。</strong></p><p id="ef50" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">因此，您必须根据数据的约束和问题的性质选择一些合适的算法。然后，尝试一下，看看哪一个最适合你。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oj"><img src="../Images/a98ee9dbaf7594a21203dc024b7da233.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*itwuf1H2flZ2EicUr6vFGQ.png"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Dimensionality reduction — Purpose &amp; method (far from exhaustive)</figcaption></figure><p id="fed8" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">例如，在我的项目中，我使用降维的唯一目的是数据可视化，而不是作为应用模式识别算法之前的预备步骤。另外，我想制作一张地图。因此，我对作为相似性代理的点之间距离的准确性感兴趣，但我并不真正关心新轴集的可解释性。</p><p id="4e80" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这就引出了<strong class="kt ir">特征提取算法</strong>。</p><h2 id="ee21" class="na lx iq bd ly nb nc dn mc nd ne dp mg la nf ng mi le nh ni mk li nj nk mm nl bi translated"><strong class="ak"> <em class="mt"> a .线性变换</em> </strong></h2><ul class=""><li id="1ff0" class="ok ol iq kt b ku nm kx nn la om le on li oo lm op oq or os bi translated"><strong class="kt ir"> <em class="ln">主成分分析</em> </strong></li></ul><p id="61b6" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一种众所周知且常用的线性变换算法是主成分分析(PCA)。</p><p id="f5fe" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">在上面的矩阵中，每项工作由 134 个维度描述。很可能在某种程度上，列是线性相关的。当两列完全相关时，我只需要一列来描述另一列。为了在删除维度时降低新表示的不准确性，我最好保留描述数据集中大多数变化的维度。换句话说，去掉不必要的、嘈杂的维度，只保留最有信息量的维度。但是，降低 132 个维度已经很多了。</p><p id="6372" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">PCA 不是识别差异最大的维度，而是识别差异最大的<strong class="kt ir">方向</strong>，即数据最分散的地方。</p><p id="667b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">这些方向被称为<strong class="kt ir">主成分</strong>(或特征向量)，由初始维度的“组合”组成。因此，它们比任何单独的维度提供的信息都多，但与初始维度不同，它们不能被标上特定的特征(因此很难解释)。</p><p id="c65b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">PCA 找到一个由一对具有最大方差的<strong class="kt ir">正交(不相关)主分量构成的<strong class="kt ir">新坐标系</strong>，并为数据集中的每个点分配新值以相应地定位它们。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ot"><img src="../Images/107c86534947de860fbe55bda6240719.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oXQ01435SVuc1jhs"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Illustration of what PCA does</figcaption></figure><p id="d523" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">本质上，<strong class="kt ir"> PCA 保留了数据</strong>的全局结构，因为它以一种“一刀切”的方式找到了将为整个数据集产生最高方差的坐标系。它不考虑点相对于彼此的初始位置。相反，考虑到维数减少，它关注于尽可能地传播数据。</p><p id="5087" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你很难想象我刚才解释的内容，看一看<a class="ae lo" href="http://setosa.io/ev/principal-component-analysis/" rel="noopener ugc nofollow" target="_blank">这个可怕的 PCA 互动可视化</a>。</p><p id="b549" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">好吧，我们来试试:</p><p id="fc93" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> 1/用 PCA 创建一组“新”特征</strong></p><p id="f0b4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">首先，您需要从<a class="ae lo" href="http://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>库中导入 PCA。</p><pre class="kg kh ki kj gt ou ov ow ox aw oy bi"><span id="184b" class="na lx iq ov b gy oz pa l pb pc">from sklearn.decomposition import PCA</span></pre><p id="8bdf" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">然后，设置<code class="fe pd pe pf ov b">n_components</code>。如果你想建立一个二维坐标系统，你设置它，使 PCA 找到 2 个主成分。</p><pre class="kg kh ki kj gt ou ov ow ox aw oy bi"><span id="a6e3" class="na lx iq ov b gy oz pa l pb pc">pca = PCA(n_components=2)</span></pre><p id="cf7b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">使用<code class="fe pd pe pf ov b">fit_transform</code>将模型与您的数据框架(X)相匹配，并应用维度缩减。</p><pre class="kg kh ki kj gt ou ov ow ox aw oy bi"><span id="b857" class="na lx iq ov b gy oz pa l pb pc">pc = pca.fit_transform(X)</span></pre><p id="f5a0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">PCA 分别沿着第一和第二主分量建立 640 对坐标的阵列。</p><p id="2332" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> 2/用 Plotly 可视化</strong></p><p id="c805" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一旦你导入了 plotly…</p><pre class="kg kh ki kj gt ou ov ow ox aw oy bi"><span id="e7c5" class="na lx iq ov b gy oz pa l pb pc">from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot</span><span id="c6f5" class="na lx iq ov b gy pg pa l pb pc">init_notebook_mode(connected=True)</span><span id="40ed" class="na lx iq ov b gy pg pa l pb pc">import plotly.graph_objs as go</span></pre><p id="03b7" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">…使用每对坐标的第一个和第二个元素分别作为 x 和 y，绘制散点图:</p><pre class="kg kh ki kj gt ou ov ow ox aw oy bi"><span id="94a0" class="na lx iq ov b gy oz pa l pb pc">data = [go.Scatter(x=pc[:,0], y=pc[:,1], mode=’markers’)]</span></pre><p id="ee07" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我的数据没有标记，所以检查其表示是否准确的唯一方法是将鼠标悬停在点上，并检查它们的邻居是否“有意义”。</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ph pi l"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">&gt;&gt; <a class="ae lo" href="https://github.com/fannykassapian/python_dimensionality_reduction/blob/master/PCA.ipynb" rel="noopener ugc nofollow" target="_blank">See notebook (Github)</a> &gt;&gt; <a class="ae lo" href="https://plot.ly/~fanny_kassapian/3/#/" rel="noopener ugc nofollow" target="_blank">See graph (Plotly)</a></figcaption></figure><p id="71a5" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如您所见，数据分布得很好，但似乎有很多“异常值”。请注意，我对该算法是否适用于该数据集的判断是高度主观的，取决于我自己对最终可视化的预期。</p><p id="6f60" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">对于这个项目，我对保存数据的本地结构非常感兴趣。我希望数据集中相邻的聚类在降维后仍然是相邻的。但如上所述，这不是 PCA 的最佳资产。</p><h2 id="e2a4" class="na lx iq bd ly nb nc dn mc nd ne dp mg la nf ng mi le nh ni mk li nj nk mm nl bi translated"><em class="mt"> b .非线性变换</em></h2><p id="ba9f" class="pw-post-body-paragraph kr ks iq kt b ku nm jr kw kx nn ju kz la no lc ld le np lg lh li nq lk ll lm ij bi translated">非线性降维(NLDR)方法假设在高维空间中，<strong class="kt ir">数据具有一些位于嵌入式非线性流形上的底层低维结构。</strong></p><p id="d3e9" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">我不是数学家，拓扑学是个相当复杂的领域，我就试着打个比方解释一下。</p><p id="1ed4" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">流形在每个点附近类似欧几里得空间。欧几里得空间是你在几何学中学习的最早的定理，如泰勒斯定理，适用的空间。二维流形包括曲面(它们类似于每个点附近的欧几里得平面)。</strong></p><p id="0c6d" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">NLDR 假设，<strong class="kt ir">如果嵌入流形是二维的</strong>(即使数据是三维或多维的)<strong class="kt ir">，那么数据也可以在二维空间上表示。</strong></p><p id="6dbc" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一个很好的方法是在你铺床之前看看你的羽绒被。想象你度过了一个糟糕的夜晚，你的床很乱。如果你要描述羽绒被上的每一点，你需要三个维度。但是羽绒被就像每个点附近的欧几里得平面。所以，可以展平成平面(二维)。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ot"><img src="../Images/3b4941e45fb0e32e2ecd43d83e5836be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LaeepsvlX9BVmYpB"/></div></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">Illustration of non-linear dimensionality reduction, from 3D to 2D</figcaption></figure><p id="8634" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir">非线性算法擅长保持数据的局部结构</strong>，因为它们适应底层数据，对流形的不同区域执行不同的变换。</p><ul class=""><li id="a686" class="ok ol iq kt b ku kv kx ky la pj le pk li pl lm op oq or os bi translated"><strong class="kt ir"><em class="ln">T-分布随机邻居嵌入(t-SNE) </em> </strong></li></ul><p id="603f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">TSNE 是最近流行的基于局部距离测量的非线性可视化方法，因此<strong class="kt ir">保留了近邻</strong>。然而，<strong class="kt ir">它不一定保留全局结构</strong>。这意味着它并不总是捕捉集群之间的距离。在我的项目中，这可能是一个问题。</p><p id="3a03" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">如果你想更好地理解 t-SNE 是如何工作的:<a class="ae lo" href="https://distill.pub/2016/misread-tsne/" rel="noopener ugc nofollow" target="_blank">这篇文章解释了如何正确阅读 t-SNE 的结果</a>。</p><p id="d7d0" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> 1/创建嵌入</strong></p><p id="5603" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">就像对 PCA 所做的那样，从 scikit-learn 库中导入 SNE，将<code class="fe pd pe pf ov b">n_components</code>设置为 2，并用<code class="fe pd pe pf ov b">fit_transform</code>创建嵌入:</p><pre class="kg kh ki kj gt ou ov ow ox aw oy bi"><span id="31cd" class="na lx iq ov b gy oz pa l pb pc">from sklearn.manifold import TSNE</span><span id="46b9" class="na lx iq ov b gy pg pa l pb pc">tsne = TSNE(n_components=2)</span><span id="839e" class="na lx iq ov b gy pg pa l pb pc">embedding = tsne.fit_transform(X)</span></pre><p id="ac3e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">2/看看结果:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ph pi l"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">&gt;&gt; <a class="ae lo" href="https://github.com/fannykassapian/python_dimensionality_reduction/blob/master/tSNE.ipynb" rel="noopener ugc nofollow" target="_blank">See notebook (Github)</a> &gt;&gt; <a class="ae lo" href="https://plot.ly/~fanny_kassapian/5/" rel="noopener ugc nofollow" target="_blank">See graph (Plotly)</a></figcaption></figure><p id="a83e" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">看起来已经很不错了。让我们试试最后一种方法。</p><ul class=""><li id="be35" class="ok ol iq kt b ku kv kx ky la pj le pk li pl lm op oq or os bi translated"><strong class="kt ir"> <em class="ln">【均匀流形逼近与投影】(UMAP) </em> </strong></li></ul><p id="586b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">新来的 UMAP 试图在保持本地和全球距离之间取得平衡，这正是我所需要的。</p><p id="fb7b" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">UMAP 是相当容易使用的，有几个参数你可以调整(默认是相当好的):</p><ul class=""><li id="aae1" class="ok ol iq kt b ku kv kx ky la pj le pk li pl lm op oq or os bi translated"><code class="fe pd pe pf ov b">n_neighbors</code>:当试图学习数据的流形结构时，限制局部邻域的大小</li><li id="2526" class="ok ol iq kt b ku pm kx pn la po le pp li pq lm op oq or os bi translated"><code class="fe pd pe pf ov b">n_components</code>:表示目标空间的维数</li><li id="ecb5" class="ok ol iq kt b ku pm kx pn la po le pp li pq lm op oq or os bi translated"><code class="fe pd pe pf ov b">min_dist</code>:设置低维表示中点之间的最小距离</li><li id="2a96" class="ok ol iq kt b ku pm kx pn la po le pp li pq lm op oq or os bi translated"><code class="fe pd pe pf ov b">metric</code>:控制如何在输入数据的环境空间(特征空间)中计算距离</li></ul><p id="f244" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">更多细节，你可以在这里找到文档<a class="ae lo" href="https://umap-learn.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">(链接到 UMAP) </a>。</p><p id="ee62" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> 1/创建嵌入</strong></p><p id="b04f" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">一旦导入了 UMAP，就可以创建嵌入并使用<code class="fe pd pe pf ov b">UMAP </code>和<code class="fe pd pe pf ov b">fit_transform </code>函数来创建最终的坐标数组(完整的笔记本<a class="ae lo" href="https://github.com/fannykassapian/python_dimensionality_reduction/blob/master/UMAP.ipynb" rel="noopener ugc nofollow" target="_blank">在这里</a>):</p><pre class="kg kh ki kj gt ou ov ow ox aw oy bi"><span id="0d67" class="na lx iq ov b gy oz pa l pb pc">import umap</span><span id="42f9" class="na lx iq ov b gy pg pa l pb pc">embedding = umap.UMAP(n_neighbors=15, n_components=2, min_dist=0.3, metric=’correlation’).fit_transform(X.values)</span></pre><p id="9013" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated"><strong class="kt ir"> 2/可视化</strong></p><p id="3d0c" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">分数的分配对我来说似乎很合理。集群在逻辑上相对于彼此定位:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="ph pi l"/></div><figcaption class="mv mw gj gh gi mx my bd b be z dk">&gt;&gt; <a class="ae lo" href="https://github.com/fannykassapian/python_dimensionality_reduction/blob/master/UMAP.ipynb" rel="noopener ugc nofollow" target="_blank">See notebook (Github)</a> &gt;&gt; <a class="ae lo" href="https://plot.ly/~fanny_kassapian/1/" rel="noopener ugc nofollow" target="_blank">See graph (Plotly)</a></figcaption></figure></div><div class="ab cl lp lq hu lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ij ik il im in"><h1 id="bd73" class="lw lx iq bd ly lz ma mb mc md me mf mg jw mh jx mi jz mj ka mk kc ml kd mm mn bi translated">包裹</h1><h2 id="e658" class="na lx iq bd ly nb nc dn mc nd ne dp mg la nf ng mi le nh ni mk li nj nk mm nl bi translated">谢谢你看完😃</h2><p id="74f3" class="pw-post-body-paragraph kr ks iq kt b ku nm jr kw kx nn ju kz la no lc ld le np lg lh li nq lk ll lm ij bi translated">到目前为止，我们已经构建了一个散点图，其坐标系本身并没有任何明显的意义，而是使用距离作为数据要素之间相似性的代理。可视化是非常基本的，但它展示了地图的前提。</p><p id="d1c3" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">接下来，我们将看到<a class="ae lo" rel="noopener" target="_blank" href="/how-to-build-a-non-geographical-map-2-340256ad9f16">如何给它一个在外观和使用上都类似于地图的格式(链接到#第 2 部分)</a>。</p><p id="2ded" class="pw-post-body-paragraph kr ks iq kt b ku kv jr kw kx ky ju kz la lb lc ld le lf lg lh li lj lk ll lm ij bi translated">与此同时，请随意分享您鼓舞人心的非地理地图和其他维度缩减方法。</p><h2 id="c108" class="na lx iq bd ly nb nc dn mc nd ne dp mg la nf ng mi le nh ni mk li nj nk mm nl bi translated">🔗链接到<a class="ae lo" rel="noopener" target="_blank" href="/how-to-build-a-non-geographical-map-2-340256ad9f16">#第 2 部分:如何将散点图变成交互式地图</a></h2><h2 id="bddb" class="na lx iq bd ly nb nc dn mc nd ne dp mg la nf ng mi le nh ni mk li nj nk mm nl bi translated">👉看看我是如何在实践中使用它的:<a class="ae lo" href="http://www.tailoredpath.com" rel="noopener ugc nofollow" target="_blank">www.tailoredpath.com</a></h2><h2 id="a76c" class="na lx iq bd ly nb nc dn mc nd ne dp mg la nf ng mi le nh ni mk li nj nk mm nl bi translated">📫让我知道你的想法:<a class="ae lo" href="mailto:tailoredpath@gmail.com" rel="noopener ugc nofollow" target="_blank">tailoredpath@gmail.com</a></h2></div></div>    
</body>
</html>