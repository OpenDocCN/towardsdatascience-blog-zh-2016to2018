<html>
<head>
<title>Word Distance between Word Embeddings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">单词嵌入之间的单词距离</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/word-distance-between-word-embeddings-cc3e9cf1d632?source=collection_archive---------4-----------------------#2018-08-25">https://towardsdatascience.com/word-distance-between-word-embeddings-cc3e9cf1d632?source=collection_archive---------4-----------------------#2018-08-25</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/68ce89f80730a330932ca79018a270f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zklkVl-sx8rH6dSy"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Photo by <a class="ae kf" href="https://unsplash.com/@inksurgeon?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Rob Bates</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="4d63" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">单词移动距离(WMD)被提出用于测量两个文档(或句子)之间的距离。它利用单词嵌入能力来克服这些基本的距离测量限制。</p><p id="d093" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">WMD[1]是由 Kusner 等人在 2015 年提出的。他们建议使用单词嵌入来计算相似度，而不是使用欧几里德距离和其他基于单词包的距离度量。准确地说，它使用标准化的<a class="ae kf" rel="noopener" target="_blank" href="/3-basic-approaches-in-bag-of-words-which-are-better-than-word-embeddings-c2cbc7398016">单词包</a>和<a class="ae kf" rel="noopener" target="_blank" href="/3-silver-bullets-of-word-embedding-in-nlp-10fa8f50cc5a">单词嵌入</a>来计算文档之间的距离。</p><p id="2b13" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">看完这篇文章，你会明白:</p><ul class=""><li id="8d86" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated">推土机距离(EMD)</li><li id="3bd3" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">字移动器的距离</li><li id="6b66" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">轻松单词移动距离(RWMD)</li><li id="c295" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">大规模杀伤性武器的实施</li><li id="7841" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">拿走</li></ul><h1 id="41ba" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">推土机距离(EMD)</h1><p id="8a55" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">在介绍大规模杀伤性武器之前，我必须先分享一下运土距离(EMD)的概念，因为大规模杀伤性武器的核心部分是 EMD。</p><p id="4991" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">EMD [2]解决运输问题。例如，我们有 m 和 n，而 m 和 n 表示一组供应商和仓库。目标是最小化运输成本，以便将所有货物从 m 运输到 n。给定约束条件:</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/0494d4f7eedb2775294f349ccaf36834.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*E74_rgPFynGLjYCWTl2Nkg.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Capture from wiki [3]</figcaption></figure><ul class=""><li id="59ba" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated">仅允许从 m 到 n 的传输。不允许从 n 到 m 的传输</li><li id="f267" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">发送货物总数不能超过总容量 m</li><li id="9f07" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">收货总数量不能超过总容量 n</li><li id="7eaf" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">最大运输次数是 m 中的货物总量和 n 中的货物总量之间的最小值</li></ul><p id="eb65" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">外延是:</p><ul class=""><li id="726b" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated">p:原产地设置</li><li id="650e" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">问:目的地集合</li><li id="922c" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">f(i，j):从 I 流向 j</li><li id="b6d8" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">m:原点数量</li><li id="a02d" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">n:目的地编号</li><li id="faec" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">w(i，j):从 I 到 j 的货物运输次数</li></ul><p id="5e9b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于最佳流量 F，线性公式为</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi na"><img src="../Images/cd15dabcd4c10bc5e96fa97cfbdf6cea.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/1*T1ExbOo5LooayRrIcpPrbA.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Capture from wiki [3]</figcaption></figure><h1 id="c643" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">字移动器的距离</h1><p id="b151" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">在之前的<a class="ae kf" rel="noopener" target="_blank" href="/3-basic-distance-measurement-in-text-mining-5852becff1d7">博客</a>中，我分享了我们如何用简单的方法找到两个文档(或句子)之间的“相似性”。当时引入了欧氏距离、余弦距离和 Jaccard 相似度，但都有一定的局限性。WMD 的设计是为了<strong class="ki iu">克服</strong> <strong class="ki iu">同义词问题</strong>。</p><p id="8997" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">典型的例子是</p><ul class=""><li id="5620" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated">第一句:奥巴马在伊利诺伊州对媒体讲话</li><li id="e6ab" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">总统在芝加哥迎接媒体</li></ul><p id="935f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">除了停用词，两个句子之间没有共同的词，但两个句子都在谈论同一个话题(当时)。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/59305e5bfea2a0c77a1bae103d5b0ecc.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*nTWAm46JMYWXpHVsS9MA5w.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Captured from Kusner et al. publication</figcaption></figure><p id="60d4" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">WMD 使用单词嵌入来计算距离，这样即使没有共同的单词，它也可以计算。假设相似的单词应该有相似的向量。</p><p id="c87b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，小写和删除停用词是减少复杂性和防止误导的必要步骤。</p><ul class=""><li id="1b0c" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated">第一句:奥巴马对伊利诺伊州媒体讲话</li><li id="46c3" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">第二句:总统问候芝加哥媒体</li></ul><p id="868b" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从任何预先训练的单词嵌入模型中检索向量。它可以是 GloVe、word2vec、fasttext 或自定义向量。然后用归一化的词袋(nBOW)来表示权重或重要性。它假设较高的频率意味着它更重要。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nc"><img src="../Images/2058cf66692aa4ac3490923291ee737c.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*WsoanugcDxX8Vq0USeX6YQ.png"/></div></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Captured from Kusner et al. publication</figcaption></figure><p id="a89f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">它允许将每个单词从句子 1 转移到句子 2，因为算法不知道“奥巴马”应该转移到“总统”。最后，它会选择最小的运输成本将每个单词从句子 1 运输到句子 2。</p><h1 id="7600" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">轻松单词移动距离(RWMD)</h1><p id="872a" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">求解 WMD 的最佳平均时间约为 O(p log p ),而 p 是唯一字的个数。它有点慢，所以有两种方法来改善减少计算时间。第一个是<strong class="ki iu">单词质心距离(WCD) </strong>，它概括了单词之间的下限距离。第二种方法是<strong class="ki iu">放松单词移动距离(RWMD) </strong>，这是使用最近距离，而不考虑有多个单词转换成单个单词。</p><figure class="mw mx my mz gt ju gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/3ceda840be4c6f36bff411c00b8fdf3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/1*apilmxJYYdA0e_8rGd9zYQ.png"/></div><figcaption class="kb kc gj gh gi kd ke bd b be z dk">Captured from Kusner et al. publication</figcaption></figure><p id="3044" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">以上一句话为例。假设句子 1 中所有单词中最短的单词是“president ”,它将使用汇总这些得分，而不是逐个配对。从而使时间复杂度降低到 O(p)。</p><h1 id="34f6" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">大规模杀伤性武器的实施</h1><p id="0de0" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">通过使用 gensim，我们只需要提供两个令牌列表，然后它将进行其余的计算</p><pre class="mw mx my mz gt ne nf ng nh aw ni bi"><span id="2250" class="nj lt it nf b gy nk nl l nm nn">subject_headline = news_headlines[0]<br/>subject_token = headline_tokens[0]</span><span id="01b3" class="nj lt it nf b gy no nl l nm nn">print('Headline: ', subject_headline)<br/>print('=' * 50)<br/>print()</span><span id="c5d5" class="nj lt it nf b gy no nl l nm nn">for token, headline in zip(headline_tokens, news_headlines):<br/>    print('-' * 50)<br/>    print('Comparing to:', headline)<br/>    distance = glove_model.wmdistance(subject_token, token)<br/>    print('distance = %.4f' % distance)</span></pre><p id="d8e6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">输出</p><pre class="mw mx my mz gt ne nf ng nh aw ni bi"><span id="c719" class="nj lt it nf b gy nk nl l nm nn">Headline:  Elon Musk's Boring Co to build high-speed airport link in Chicago<br/>==================================================<br/><br/>--------------------------------------------------<br/>Comparing to: Elon Musk's Boring Co to build high-speed airport link in Chicago<br/>distance = 0.0000<br/>--------------------------------------------------<br/>Comparing to: Elon Musk's Boring Company to build high-speed Chicago airport link<br/>distance = 0.3589<br/>--------------------------------------------------<br/>Comparing to: Elon Musk’s Boring Company approved to build high-speed transit between downtown Chicago and O’Hare Airport<br/>distance = 1.9456<br/>--------------------------------------------------<br/>Comparing to: Both apple and orange are fruit<br/>distance = 5.4350</span></pre><p id="2630" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在 gensim 实现中，OOV 将被删除，以便它不会抛出异常或使用随机向量。</p><h1 id="dfd2" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">拿走</h1><p id="a9d0" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">对于源代码，你可以从我的<a class="ae kf" href="https://github.com/makcedward/nlp/blob/master/sample/nlp-word_mover_distance.ipynb3" rel="noopener ugc nofollow" target="_blank"> github </a> repo 查看。</p><ul class=""><li id="31eb" class="le lf it ki b kj kk kn ko kr lg kv lh kz li ld lj lk ll lm bi translated">WMD 的优点是没有超参数和克服同义词问题。</li><li id="254f" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated">和那些简单的方法一样，WMD <strong class="ki iu">不考虑订购</strong>。</li><li id="d74c" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated"><strong class="ki iu">时间复杂度是一个问题</strong>。原版是 O(p log p)而增强版还是 O(p)。</li><li id="4024" class="le lf it ki b kj ln kn lo kr lp kv lq kz lr ld lj lk ll lm bi translated"><strong class="ki iu">预训练向量可能不适用于所有场景</strong>。</li></ul><h1 id="1849" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">关于我</h1><p id="49f6" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">我是湾区的数据科学家。专注于数据科学、人工智能，尤其是 NLP 和平台相关领域的最新发展。你可以通过<a class="ae kf" href="http://medium.com/@makcedward/" rel="noopener">媒体博客</a>、<a class="ae kf" href="https://www.linkedin.com/in/edwardma1026" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>或<a class="ae kf" href="https://github.com/makcedward" rel="noopener ugc nofollow" target="_blank"> Github </a>联系我。</p><h1 id="4ac0" class="ls lt it bd lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp bi translated">参考</h1><p id="97be" class="pw-post-body-paragraph kg kh it ki b kj mq kl km kn mr kp kq kr ms kt ku kv mt kx ky kz mu lb lc ld im bi translated">[1] Kusner Matt J，孙宇，Kolkin Nicholas I，Weinberger Kilian Q .从单词嵌入到文档距离.2015.<a class="ae kf" href="http://proceedings.mlr.press/v37/kusnerb15.pdf" rel="noopener ugc nofollow" target="_blank">http://proceedings.mlr.press/v37/kusnerb15.pdf</a></p><p id="cbbd" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2] EMD 理论:<a class="ae kf" href="https://en.wikipedia.org/wiki/Earth_mover%27s_distance" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Earth_mover%27s_distance</a></p></div></div>    
</body>
</html>