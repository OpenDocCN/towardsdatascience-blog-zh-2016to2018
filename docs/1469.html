<html>
<head>
<title>Implementing K-Nearest Neighbors in scikit-learn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在 scikit-learn 中实现 K 近邻</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/implementing-k-nearest-neighbors-with-scikit-learn-9e4858e231ea?source=collection_archive---------3-----------------------#2017-09-08">https://towardsdatascience.com/implementing-k-nearest-neighbors-with-scikit-learn-9e4858e231ea?source=collection_archive---------3-----------------------#2017-09-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="52d4" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">scikit-learn 的 KNeighbors 分类器演练</h2></div><p id="886f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们将使用 iris 数据集，这里的<a class="ae le" href="http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data" rel="noopener ugc nofollow" target="_blank">来自 UCI 机器学习。这是一个很小的数据集，具有容易区分的聚类，对于像这样的演示非常有用。它包含了对鸢尾属植物三个物种的 150 次观察:刚毛鸢尾、杂色鸢尾和海滨鸢尾。任务是根据最近的邻居来识别每种植物的种类。</a></p><p id="26ab" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">k-最近邻法是一种简单地查看与它试图预测的观测值最接近的观测值，并根据周围大多数的观测值对感兴趣点进行分类的方法。</p><p id="7d97" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我使用以下代码将数据加载到 pandas 数据帧中:</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="f81e" class="lo lp it lk b gy lq lr l ls lt">## load the iris data into a DataFrame<br/>import pandas as pd<br/>url = '<a class="ae le" href="http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'" rel="noopener ugc nofollow" target="_blank">http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'</a> <br/>## Specifying column names.<br/>col_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']<br/>iris = pd.read_csv(url, header=None, names=col_names)</span></pre><p id="21ec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是一些数据:</p><figure class="lf lg lh li gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi lu"><img src="../Images/5e0b3c434a18dff7f87bc99367d951e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FXnkbsQ8oHsWlY5tET1rOQ.png"/></div></div></figure><p id="d427" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面，我画出了花瓣的长度和宽度被类分开，这样你就可以看到类是如何分开的。</p><figure class="lf lg lh li gt lv gh gi paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="gh gi mc"><img src="../Images/3bd4de608c012c8b0598c6d3dafe97db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SSgEfKQdK4Z1p0MplcBhLg.png"/></div></div><figcaption class="md me gj gh gi mf mg bd b be z dk">Nice colors!</figcaption></figure><p id="6151" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，为了对数据建模，我运行了几个预处理步骤。首先，我将物种名称映射到一个数字上，这样我就可以用我的分类器对它进行分类。其代码如下:</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="83ed" class="lo lp it lk b gy lq lr l ls lt">## map each iris species to a number with a dictionary and list comprehension.<br/>iris_class = {'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}<br/>iris['species_num'] = [iris_class[i] for i in iris.species]</span></pre><p id="d3d0" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">将数据分成我们的建模和目标变量，我们的 X 和 y:</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="4730" class="lo lp it lk b gy lq lr l ls lt">## Create an 'X' matrix by dropping the irrelevant columns.<br/>X = iris.drop(['species', 'species_num'], axis=1)<br/>y = iris.species_num</span></pre><p id="02f8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">列车测试分离:</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="da91" class="lo lp it lk b gy lq lr l ls lt">from sklearn.model_selection import train_test_split<br/>## Split data into training and testing sets.<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)</span></pre><p id="5b80" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们已经准备好模型了。在下面的代码中，我们将导入分类器，实例化模型，使其适合训练数据，并根据测试数据对其进行评分。请注意，您可以更改用于对每个点进行分类的最近邻的数量。</p><pre class="lf lg lh li gt lj lk ll lm aw ln bi"><span id="8638" class="lo lp it lk b gy lq lr l ls lt">## Import the Classifier.<br/>from sklearn.neighbors import KNeighborsClassifier<br/>## Instantiate the model with 5 neighbors. <br/>knn = KNeighborsClassifier(n_neighbors=5)<br/>## Fit the model on the training data.<br/>knn.fit(X_train, y_train)<br/>## See how the model performs on the test data.<br/>knn.score(X_test, y_test)</span></pre><p id="a89f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">该模型实际上具有 100%的准确率，因为这是一个非常简单的数据集，具有明显可分离的类。但是现在你有了。这就是如何用 scikit-learn 实现 K 近邻。加载你最喜欢的数据集，试试吧！</p></div></div>    
</body>
</html>