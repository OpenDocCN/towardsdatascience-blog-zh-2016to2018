# 甘斯全神贯注

> 原文：<https://towardsdatascience.com/gans-with-attention-3b90802921af?source=collection_archive---------4----------------------->

**一点背景:**

一个**生成对抗网络** (GAN)串联着两个网络:一个*生成器*和一个*鉴别器*。解释 GANs 的流行例子涉及假币。生成器试图创建*一个看起来像美钞*的图像，鉴别器试图*将伪钞与真美钞的图像*区分开来。在训练了两个网络之后，生成器已经学会创建看起来非常像一美元钞票的图像，而鉴别器已经学会可靠地将这些伪造图像与真美元区分开来。

**不幸的是……**

这是一个*一次性过程*。生产者制造假货，鉴别者试图识别假货，然后根据他们的表现给他们打分。没有反馈，没有进一步调整；该伪造图像被丢弃。

在递归神经网络中使用的类似方法是演员-评论家模型。通常只有在表演结束时才能得到“分数”的演员，反而会在表演过程中被评论家“打分”。评论家学会**预测**哪些动作会影响最终得分，演员学会**执行**影响最终得分的动作，通过评论家的即时评分。这还是一个*一次性的过程*。作为对批评的回应，这位演员无法“再次拍摄那个场景”。

那么，修改呢？

另一个比喻，来描述一个更好的方法:一个**作者**产生他们的美元图像(或文本块，或动作串……)并将其发送给**编辑**。然后编辑器*在*中发现错误的地方*标记*该美元图像，并将其发送回作者。作者**将他们的*注意力*集中在那些错误**上，并改正它们，将*新草稿*发回给编辑……重复这个循环，直到编辑发现没有错误。作者网络学会了用注意力过滤器拍摄图像，然后*将变化应用到高亮显示的区域*。编辑器学习获取图像及其目标，并突出显示应该改变的*区域。*

这种作者-编辑模型支持有价值的新行为。一旦作者被训练根据编辑的标记改编图像，一个*人*也可以通过选择他们 *想要改变*的*区域* ***来纠正作者。这种用户输入可以引导*不同的作者*将他们的**注意力**集中在图像的*不同区域*上。用户可以选择图像的一些区域，并应用“冬至春作者”的注意力，而选择同一图像的其他区域，以应用“现实生活中的赤壁作者”。每个作者根据*自己的关注*进行修改。你可以做编辑。***

**不止如此……**

这位编辑受过突出错误的训练。因此，如果作者-编辑模型是在文本上训练的，那么编辑有一个直接的应用:纠正人类所写的错误！(比如语法上……)

此外，作者-编辑网络可以与人类实时合作。例如，你可以画一种动物——狐狸？—它被传递给编辑，编辑试图识别应该修改的区域*。例如，编辑可能会在你的 fox-drawing 上突出显示线条可以平滑的区域，或者建议在哪里改变它们的位置、比例和整体纹理。*

*编辑也会犯错！它可能会认为你在画一只**猫**，不恰当地突出了几个区域*。您可以**查看**这些高亮区域，*替换* *编辑的高亮*。然后这些区域可以交给作者，作者**将网络的注意力集中在区域**上，并进行修改。你审核作者的更新稿，*可以自己修改*。然后，发给编辑……重复，直到你满意为止。**

****选择备选方案:****

**这种作者-编辑模式也使得人们可以借助 ***多个*** *作者和编辑*共同创作 *内容。作者的注意力可以应用于不同的领域，也可以应用于同一领域。如果每个作者都活跃在**不同的**区域，(就像之前提到的《冬去春来》和《赤壁的真实生活》的作者)，他们的草稿可以合并。但是，当作者的关注区域 ***与*** 重叠时，作者各自提供一个替代方案，而*你可以* ***选择应用哪个替代方案****。****

**(你可能有三个绘画风格的作者，并突出显示图像的相同区域，以查看**他们每个人对该区域的建议**。然后，你可以用不透明滤镜将每个作者的作品应用到你高亮区域的*不同部分*。在它们之间选择，零敲碎打！)**

**拥有多个编辑器提供了类似的好处——每个编辑器突出显示它认为应该修改的区域，然后*你在他们建议的突出显示中进行选择*。你也可以阻止编辑修改你想保留的东西！**

****修订历史培训:****

**作者-编辑 GAN 不同于现有的 GAN 架构，它通过在由编辑器生成的*注意力*域上训练作者，并通过多次*修改*来产生最终输出。在这种方式下，作者-编辑模型类似于具有注意力的递归神经网络:修订历史可以像 RNN 的行动历史一样“展开”,并且每个修订将注意力集中在新的相关领域。不过，修订不同于循环——RNN 描述的是一个序列，就像在迷宫中选择路径一样，而作者-编辑修订描述的是一种平衡，一个编者停止突出修改的落脚点。递归的 NNs 不能包含修订，但修订可以包含递归:作者可以在迷宫中写出选择的序列，它写了又写，直到编辑满意为止。:]**