<html>
<head>
<title>Review: WRNs — Wide Residual Networks (Image Classification)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">综述:WRNs —宽残差网络(图像分类)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/review-wrns-wide-residual-networks-image-classification-d3feb3fb2004?source=collection_archive---------4-----------------------#2018-12-01">https://towardsdatascience.com/review-wrns-wide-residual-networks-image-classification-d3feb3fb2004?source=collection_archive---------4-----------------------#2018-12-01</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="f426" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi kl translated"><span class="l km kn ko bm kp kq kr ks kt di"> T </span>他的时代，<strong class="jp ir"> WRNs(广残网)</strong>呈现出来。通过<strong class="jp ir">加宽残差网络(</strong><a class="ae ku" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"><strong class="jp ir">【ResNet】</strong></a><strong class="jp ir">)</strong>，在精度相同或精度提高的情况下，网络可以更浅。<strong class="jp ir">较浅的网络</strong>表示:</p><ul class=""><li id="4356" class="kv kw iq jp b jq jr ju jv jy kx kc ky kg kz kk la lb lc ld bi translated"><strong class="jp ir">层数可以减少。</strong></li><li id="5ceb" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated"><strong class="jp ir">培训时间也可以缩短。</strong></li></ul><p id="39be" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一个更好的辍学也进行了调查。这是一篇<strong class="jp ir"> 2016 BMVC </strong>论文，引用<strong class="jp ir"> 700 余次</strong>。虽然这是一篇 2016 年的论文，但他们仍然在 2017 年 6 月继续更新这篇论文。(<a class="lj lk ep" href="https://medium.com/u/aff72a0c1243?source=post_page-----d3feb3fb2004--------------------------------" rel="noopener" target="_blank"> Sik-Ho Tsang </a> @中)</p><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi ll"><img src="../Images/d5f7362c08c915a50504a3e356f3f89a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bggPuUy0IyrcqsHt_Lxwvw.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk"><strong class="bd mb">Various ResNet Blocks</strong></figcaption></figure></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="5629" class="mj mk iq bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">涵盖哪些内容</h1><ol class=""><li id="c49c" class="kv kw iq jp b jq nh ju ni jy nj kc nk kg nl kk nm lb lc ld bi translated"><strong class="jp ir">残网上的问题(</strong><a class="ae ku" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"><strong class="jp ir">ResNet</strong></a><strong class="jp ir">)</strong></li><li id="9977" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk nm lb lc ld bi translated"><strong class="jp ir">宽残差网络</strong></li><li id="9cf5" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk nm lb lc ld bi translated"><strong class="jp ir">结果</strong></li></ol></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="48a8" class="mj mk iq bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">1.关于剩余网络的问题(<a class="ae ku" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"> ResNet </a></h1><h2 id="6535" class="nn mk iq bd ml no np dn mp nq nr dp mt jy ns nt mx kc nu nv nb kg nw nx nf ny bi translated">1.1.<strong class="ak">电路复杂性理论</strong></h2><p id="012e" class="pw-post-body-paragraph jn jo iq jp b jq nh js jt ju ni jw jx jy nz ka kb kc oa ke kf kg ob ki kj kk ij bi translated"><strong class="jp ir">电路复杂性理论</strong>文献表明:</p><blockquote class="oc od oe"><p id="ce23" class="jn jo of jp b jq jr js jt ju jv jw jx og jz ka kb oh kd ke kf oi kh ki kj kk ij bi translated">浅电路比深电路需要更多的元件。</p></blockquote><p id="270b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">残差网络的作者试图使它们<strong class="jp ir">尽可能薄，以利于增加它们的深度并具有更少的参数</strong>，甚至引入了一个瓶颈块，使 ResNet 块更薄。</p><h2 id="2a2f" class="nn mk iq bd ml no np dn mp nq nr dp mt jy ns nt mx kc nu nv nb kg nw nx nf ny bi translated">1.2.<strong class="ak">减少特征重用</strong></h2><p id="c21e" class="pw-post-body-paragraph jn jo iq jp b jq nh js jt ju ni jw jx jy nz ka kb kc oa ke kf kg ob ki kj kk ij bi translated">然而，当梯度流过网络时，没有任何东西迫使它通过剩余块权重，并且它可以避免在训练期间学习任何东西，因此有可能<strong class="jp ir">只有几个块学习有用的表示</strong>，或者<strong class="jp ir">许多块共享非常少的信息，对最终目标贡献很小</strong>。这个问题被表述为<strong class="jp ir">减少特征重用</strong>。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="eafc" class="mj mk iq bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">2.宽剩余网络</h1><p id="c740" class="pw-post-body-paragraph jn jo iq jp b jq nh js jt ju ni jw jx jy nz ka kb kc oa ke kf kg ob ki kj kk ij bi translated">在 WRNs 中，测试了大量参数，如 ResNet 块的设计、ResNet 块内的深度(加深系数<em class="of"> l </em>和宽度(加宽系数<em class="of"> k </em>)等。</p><p id="6c9c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">当<em class="of"> k </em> =1 时，与<a class="ae ku" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"> <em class="of"> ResNet </em> </a>宽度相同。而<em class="of">k</em>T68】1，比<a class="ae ku" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"> <em class="of"> ResNet </em> </a>宽<em class="of"> k </em>倍。</p><p id="b3f7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> WRN- <em class="of"> d </em> - <em class="of"> k </em></strong></p><ul class=""><li id="c050" class="kv kw iq jp b jq jr ju jv jy kx kc ky kg kz kk la lb lc ld bi translated"><a class="ae ku" rel="noopener" target="_blank" href="/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e"> <em class="of">预激活 ResNet </em> </a>用于 CIFAR-10、CIFAR-100 和 SVHN 数据集。ImageNet 数据集中使用了原始的<a class="ae ku" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"><em class="of">ResNet</em></a><em class="of"/>。</li><li id="5dd3" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated">主要区别在于<a class="ae ku" rel="noopener" target="_blank" href="/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e"> <em class="of">预激活 ResNet </em> </a>具有在卷积之前执行批范数和 ReLU 的结构(即 BN-ReLU-Conv)，而原始<a class="ae ku" rel="noopener" target="_blank" href="/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8"><em class="of">ResNet</em></a><em class="of"/>具有 Conv-BN-ReLU 的结构。而<a class="ae ku" rel="noopener" target="_blank" href="/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e"> <em class="of">预激活 ResNet </em> </a>一般比原版好，但在 ImageNet 只有 100 层左右的情况下没有明显提升。</li></ul><h2 id="db9f" class="nn mk iq bd ml no np dn mp nq nr dp mt jy ns nt mx kc nu nv nb kg nw nx nf ny bi translated">2.1.ResNet 块的设计</h2><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi oj"><img src="../Images/6af76f831a3e548cc03a8b8b57c34858.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*La-9heMgE5lv-QMbCL5eDA.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk"><strong class="bd mb">WRN-d-2 (k=2), Error Rate (%) in CIFAR-10 Dataset</strong></figcaption></figure><ul class=""><li id="1937" class="kv kw iq jp b jq jr ju jv jy kx kc ky kg kz kk la lb lc ld bi translated"><strong class="jp ir">B(3；3) </strong>:原始基本块，在第一个图(a)中</li><li id="df4b" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated"><strong class="jp ir">B(3；1;3) </strong>:在两个 3×3 层之间增加一个 1×1 层</li><li id="b5b4" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated"><strong class="jp ir">B(1；3;1) </strong>:所有卷积维数相同，拉直<strong class="jp ir">瓶颈</strong></li><li id="ca4a" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated"><strong class="jp ir">B(1；3) </strong>:网络具有交替的 1×1，3×3 卷积</li><li id="5080" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated"><strong class="jp ir">B(3；1) </strong>:网络具有交替的 3×3，1×1 卷积</li><li id="1fb3" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated"><strong class="jp ir">B(3；1;1) </strong>:网络中网络样式块</li></ul><p id="cdac" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">B(3；3)错误率最小(5.73%)。</strong></p><p id="4504" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意:深度(层)的数量不同是为了保持参数的数量彼此接近。</p><h2 id="32a2" class="nn mk iq bd ml no np dn mp nq nr dp mt jy ns nt mx kc nu nv nb kg nw nx nf ny bi translated">2.2.ResNet 块内的卷积层数</h2><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/ed3c37c3ac9d6f0bcafcb295598e368b.png" data-original-src="https://miro.medium.com/v2/resize:fit:496/format:webp/1*IqMHogpHTac26bBM3xx44Q.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk"><strong class="bd mb">WRN-40–2 with different l, Error Rate (%) in CIFAR-10 Dataset</strong></figcaption></figure><p id="2670" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">并且两个 3×3 卷积，即 B(3，3)具有最小的错误率。因为所有网络都需要保持接近相同的参数，<strong class="jp ir"> B(3，3，3)和 B(3，3，3，3) </strong>的<strong class="jp ir">更少，这使得精度下降。并且<strong class="jp ir"> B(3) </strong>只有一个 3×3 卷积，这<strong class="jp ir">使得特征提取在 ResNet 块内的这种浅网络内无效</strong>。</strong></p><p id="13e3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因此，<strong class="jp ir"> B(3，3)是最优的</strong>，并将在接下来的实验中使用。</p><h2 id="d5b1" class="nn mk iq bd ml no np dn mp nq nr dp mt jy ns nt mx kc nu nv nb kg nw nx nf ny bi translated">2.3.ResNet 块的宽度</h2><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/267912ea17c95996d34ac5d57bf92064.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*64G3yGb3p6UgXf-pFWzTrg.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk"><strong class="bd mb">Different Width (k) and Depth on CIFAR-10 and CIFAR-100</strong></figcaption></figure><ul class=""><li id="eb2b" class="kv kw iq jp b jq jr ju jv jy kx kc ky kg kz kk la lb lc ld bi translated">当宽度增加 1 到 12 倍时，所有具有 40、22 和 16 层的网络看到一致的增益。</li><li id="0dac" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated">另一方面，当保持相同的固定加宽因子 k = 8 或 k = 10 并且将深度从 16 改变到 28 时，有一致的改进，然而当我们进一步将深度增加到 40 时，精度降低。</li><li id="7137" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated">基于上述结果，选择了三组 wrn 与最先进的方法进行比较。</li></ul></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="239f" class="mj mk iq bd ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd ne nf ng bi translated">3.结果</h1><h2 id="92d0" class="nn mk iq bd ml no np dn mp nq nr dp mt jy ns nt mx kc nu nv nb kg nw nx nf ny bi translated">3.1.西法尔-10 和西法尔-100</h2><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi om"><img src="../Images/8ade913782d0b32261264635ad203455.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WzZ77MEa_Lr2bhE_lXtPWQ.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk"><strong class="bd mb">CIFAR-10 &amp; CIFAR-100</strong></figcaption></figure><ul class=""><li id="f19e" class="kv kw iq jp b jq jr ju jv jy kx kc ky kg kz kk la lb lc ld bi translated"><strong class="jp ir">WRN-40–4</strong>:参数(8.9M)比 1001 层<a class="ae ku" rel="noopener" target="_blank" href="/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e"> <em class="of">预激活 ResNet </em> </a> (10.2M)少。但是它也降低了错误率。(在 CIFAR-10 上为 4.52%，在 CIFAR-100 上为 21.18%)</li><li id="ca03" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated"><strong class="jp ir"> WRN-16-8 &amp; WRN-28-10 </strong>:比 WRN-40–4 更浅更宽，错误率更低。使用较浅的网络，训练时间可以更短，因为无论多宽，并行计算都是在 GPU 上执行的。</li><li id="5347" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated">并且它是第一篇在没有任何强大数据增强的情况下获得低于 20%的 CIFAR-100 的论文！！！</li></ul><h2 id="0d40" class="nn mk iq bd ml no np dn mp nq nr dp mt jy ns nt mx kc nu nv nb kg nw nx nf ny bi translated">3.2.拒绝传统社会的人</h2><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi on"><img src="../Images/00e81ecb04b72e66c784e05305b02612.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hRv4czy5Xm_fpSav_BT3pA.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk"><strong class="bd mb">Dropout in Original ResNet (Left) and Dropout in WRNs (Right)</strong></figcaption></figure><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi oo"><img src="../Images/d24cfe361477e7111724dad90e17ed6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j2-zsHcCKUMcq_CE2jW0kQ.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk"><strong class="bd mb">Dropout Is Better</strong></figcaption></figure><ul class=""><li id="acd8" class="kv kw iq jp b jq jr ju jv jy kx kc ky kg kz kk la lb lc ld bi translated">上图:使用 dropout，可以获得不同深度、k 和数据集的一致增益。</li><li id="f04e" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated">右下:对于辍学，训练损失较高，但测试误差较低，这意味着辍学成功地减少了过拟合。</li></ul><h2 id="1a96" class="nn mk iq bd ml no np dn mp nq nr dp mt jy ns nt mx kc nu nv nb kg nw nx nf ny bi translated">3.3.ImageNet &amp; COCO</h2><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi op"><img src="../Images/70325243db607fc10dd87af0d25d714f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W1elXJiVAq0FpqtJ_boyIQ.png"/></div></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk"><strong class="bd mb">Single Crop Single Model Validation Error, ImageNet</strong></figcaption></figure><ul class=""><li id="5a15" class="kv kw iq jp b jq jr ju jv jy kx kc ky kg kz kk la lb lc ld bi translated">上述网络获得了与原始网络相似的精度，但层数减少了 2 倍。</li></ul><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="gh gi oq"><img src="../Images/3c2bc37e221153c70f130dd10013b699.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YYOtcOU6bQRMJ51kwGzH6A.png"/></div></div></figure><ul class=""><li id="256b" class="kv kw iq jp b jq jr ju jv jy kx kc ky kg kz kk la lb lc ld bi translated"><strong class="jp ir">WRN-50–2-瓶颈</strong>:性能优于<a class="ae ku" href="http://ResNet" rel="noopener ugc nofollow" target="_blank">雷斯网-152 </a>，层数少 3 倍，这意味着训练时间明显更快。</li><li id="6956" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated"><strong class="jp ir">WRN-34–2</strong>:优于基于<a class="ae ku" href="http://ResNet" rel="noopener ugc nofollow" target="_blank">雷斯内特-152 </a>和<a class="ae ku" rel="noopener" target="_blank" href="/review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification-5e8c339d18bc">盗梦空间-v4 </a>的模型</li></ul><h2 id="f8ef" class="nn mk iq bd ml no np dn mp nq nr dp mt jy ns nt mx kc nu nv nb kg nw nx nf ny bi translated">3.4.训练时间</h2><figure class="lm ln lo lp gt lq gh gi paragraph-image"><div class="gh gi or"><img src="../Images/492a3887cd49c6aadb31e995938d84ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/1*2T5znSbvghZHfn_RqThw2w.png"/></div><figcaption class="lx ly gj gh gi lz ma bd b be z dk"><strong class="bd mb">Training Time for Each Batch with Batch Size of 32, CIFAR-10</strong></figcaption></figure><ul class=""><li id="c7b2" class="kv kw iq jp b jq jr ju jv jy kx kc ky kg kz kk la lb lc ld bi translated"><strong class="jp ir">WRN-16–10 和 WRN-28–10</strong>:训练时间远低于 1004 层<a class="ae ku" rel="noopener" target="_blank" href="/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e"> <em class="of">预激活 ResNet </em> </a>，错误率更低。</li><li id="aedd" class="kv kw iq jp b jq le ju lf jy lg kc lh kg li kk la lb lc ld bi translated"><strong class="jp ir">WRN-40–4</strong>:训练时间比 164 层<a class="ae ku" rel="noopener" target="_blank" href="/resnet-with-identity-mapping-over-1000-layers-reached-image-classification-bb50a42af03e"> <em class="of">预激活 ResNet </em> </a>短，错误率更低。</li></ul></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><p id="0b9d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">因为训练需要很多时间，所以可能需要几天甚至几周。当训练集越来越大时，需要一种更好的训练方法。事实上，在最近的研究中，许多研究人员仍然专注于如何减少训练时间或训练次数。</p><p id="1520" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在 WRNs 中，它减少了训练时间，但代价是由于网络的扩大而增加了参数的数量。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h2 id="74a0" class="nn mk iq bd ml no np dn mp nq nr dp mt jy ns nt mx kc nu nv nb kg nw nx nf ny bi translated">参考</h2><p id="bea7" class="pw-post-body-paragraph jn jo iq jp b jq nh js jt ju ni jw jx jy nz ka kb kc oa ke kf kg ob ki kj kk ij bi translated">【2016 BMVC】【WRNs】<br/><a class="ae ku" href="https://arxiv.org/abs/1605.07146" rel="noopener ugc nofollow" target="_blank">广残网</a></p><h2 id="0594" class="nn mk iq bd ml no np dn mp nq nr dp mt jy ns nt mx kc nu nv nb kg nw nx nf ny bi translated">我对图像分类的相关综述</h2><p id="d3f2" class="pw-post-body-paragraph jn jo iq jp b jq nh js jt ju ni jw jx jy nz ka kb kc oa ke kf kg ob ki kj kk ij bi translated">[<a class="ae ku" href="https://medium.com/@sh.tsang/paper-brief-review-of-lenet-1-lenet-4-lenet-5-boosted-lenet-4-image-classification-1f5f809dbf17" rel="noopener">LeNet</a>][<a class="ae ku" href="https://medium.com/coinmonks/paper-review-of-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160" rel="noopener">AlexNet</a>][<a class="ae ku" href="https://medium.com/coinmonks/paper-review-of-zfnet-the-winner-of-ilsvlc-2013-image-classification-d1a5a0c45103" rel="noopener">ZFNet</a>][<a class="ae ku" href="https://medium.com/coinmonks/paper-review-of-vggnet-1st-runner-up-of-ilsvlc-2014-image-classification-d02355543a11" rel="noopener">VGGNet</a>][<a class="ae ku" href="https://medium.com/coinmonks/review-sppnet-1st-runner-up-object-detection-2nd-runner-up-image-classification-in-ilsvrc-906da3753679" rel="noopener">SPPNet</a>][<a class="ae ku" href="https://medium.com/coinmonks/review-prelu-net-the-first-to-surpass-human-level-performance-in-ilsvrc-2015-image-f619dddd5617" rel="noopener">PReLU-Net</a>][<a class="ae ku" href="https://medium.com/coinmonks/paper-review-of-googlenet-inception-v1-winner-of-ilsvlc-2014-image-classification-c2b3565a64e7" rel="noopener">Google Net/Inception-v1</a>][<a class="ae ku" href="https://medium.com/@sh.tsang/review-batch-normalization-inception-v2-bn-inception-the-2nd-to-surpass-human-level-18e2d0f56651" rel="noopener">BN-Inception/Inception-v2</a>][<a class="ae ku" href="https://medium.com/@sh.tsang/review-inception-v3-1st-runner-up-image-classification-in-ilsvrc-2015-17915421f77c" rel="noopener">Inception-v3</a>][<a class="ae ku" rel="noopener" target="_blank" href="/review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification-5e8c339d18bc">Inception-v4</a><a class="ae ku" rel="noopener" target="_blank" href="/review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification-5e8c339d18bc"/></p></div></div>    
</body>
</html>