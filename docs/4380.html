<html>
<head>
<title>The what and what not of running deep learning inference on mobile</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在移动设备上运行深度学习推理的是什么和不是什么</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-what-and-what-not-of-running-deep-learning-inference-on-mobile-81aa394ad27d?source=collection_archive---------8-----------------------#2018-08-12">https://towardsdatascience.com/the-what-and-what-not-of-running-deep-learning-inference-on-mobile-81aa394ad27d?source=collection_archive---------8-----------------------#2018-08-12</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="a9c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个概念在我的草稿中已经存在很长时间了，我已经意识到缺乏相关的文档仍然会导致混乱，所以，我想把我的经验和理解发表出来。</p><p id="585a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">文章假设，深度学习如何工作的基础知识以及它们的实现。假设是，有一个模型在服务器或本地笔记本电脑上训练和工作，以预测事物。</p><p id="caf3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，如果你想在移动设备上做类似的事情，有多种方法，我们将一步一步地讨论相同的方法。从示例的角度来看，假设您有视频，并且希望通过深度学习模块对其进行处理，并获得输出的分析指标。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi kl"><img src="../Images/a9efc4c789ab3ba2105f3c8b031a6e66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zVX1gunVQXrPCJmyn2mn3w.png"/></div></div></figure><p id="972c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">整个解释将集中于在移动设备上实现上述框图时做什么和不做什么。</p><h1 id="a85f" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated"><strong class="ak"> 1。将数据发送到服务器进行处理</strong></h1><p id="b46e" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">这里的想法是建立通信模块，它与服务器通信，将内容发送到服务器，让服务器推断数据，并将元数据发送回设备。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi ma"><img src="../Images/a15b1ae5736b1b3fa1a3ecd4000b6c1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mJlwIb6Yg14MqfBrm93yxQ.png"/></div></div></figure><p id="3cbc" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">优势:</strong></p><blockquote class="mb mc md"><p id="065a" class="jn jo me jp b jq jr js jt ju jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj kk ij bi translated">移动开发团队和数据科学团队之间的交流没有任何问题，发送数据和获取数据</p></blockquote><p id="6687" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">缺点:</strong></p><blockquote class="mb mc md"><p id="2bf4" class="jn jo me jp b jq jr js jt ju jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj kk ij bi translated">--&gt;极高的延迟<br/> - &gt;互联网可用性，与服务器同步(完全是另一个问题)<br/>-&gt;-<strong class="jp ir">隐私</strong>(无法将数据发送到我的手机之外)</p></blockquote><p id="06be" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个缺点不容忽视，这就引出了下一个重要的想法，</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mi"><img src="../Images/04d5b711949a25d36b2e3de4e3e1b797.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w_-gAEsjRxY54Qd9WsG6HA.jpeg"/></div></div></figure><p id="6546" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有各种各样的方法可以达到同样的目的，我们将逐一讨论它们的利弊。这方面最简单的方法是</p><h1 id="390d" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">2.使用开发框架的现有包装器</h1><p id="5f22" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">我们将从著名的、容易开始考虑的开发框架开始。</p><p id="0a97" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">几乎没有相同方向的图书馆，</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mj"><img src="../Images/d6d094c9885a9dd8ce6d424b7db88055.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vhabcYo9FF8-bGv_hg7NkA.png"/></div></div></figure><h2 id="f59c" class="mk ky iq bd kz ml mm dn ld mn mo dp lh jy mp mq ll kc mr ms lp kg mt mu lt mv bi translated"><strong class="ak"> TensorFlow Lite </strong></h2><p id="856c" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">这是 Tensorflow 的移动版本，不会有太多的学习曲线，因为文档和支持都维护得很好。训练模型并在移动设备上运行推理，就好像您在本地计算机上运行一样。</p><p id="e92f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">优点:</strong></p><blockquote class="mb mc md"><p id="27c0" class="jn jo me jp b jq jr js jt ju jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj kk ij bi translated">-&gt;围绕模型转换运行的工作量最小，来自数据科学和移动开发团队的知识转移有限。<br/> - &gt;比服务器方法相对更快<br/> - &gt;无平台依赖性</p></blockquote><p id="4bc3" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">缺点:</strong></p><blockquote class="mb mc md"><p id="a9a8" class="jn jo me jp b jq jr js jt ju jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj kk ij bi translated">-&gt;大型号尺寸<br/> - &gt;与笔记本电脑运行时相比超级慢</p></blockquote><h2 id="6d34" class="mk ky iq bd kz ml mm dn ld mn mo dp lh jy mp mq ll kc mr ms lp kg mt mu lt mv bi translated">咖啡 2Go:</h2><p id="ad8f" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">这曾经是由脸书的 Caffe 团队支持的，现在，他们已经将它作为 PyTorch 的一部分嵌入其中。我没有做过这个的最新版本，但是，我会根据我一年前的经验给出我的分析。</p><p id="f6c7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">优点:</strong></p><blockquote class="mb mc md"><p id="c7bb" class="jn jo me jp b jq jr js jt ju jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj kk ij bi translated">--&gt;同样，从开发到生产的努力是最小的，如果你在 Caffe <br/> - &gt;上工作，比服务器方法和 tensorflow lite <br/> - &gt;相对更快，没有平台依赖性</p></blockquote><p id="f380" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">缺点:</strong></p><blockquote class="mb mc md"><p id="f468" class="jn jo me jp b jq jr js jt ju jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj kk ij bi translated">-&gt;大型号尺寸<br/> - &gt;又来了，相比笔记本时间超级慢<br/> - &gt;在我使用的时候非常不稳定(一年前)</p></blockquote><p id="60c1" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这个阶段，与服务器模式相比，我们已经大大提高了我们的性能，但是，这仍然不是我们可以开箱即用的东西。上述方法的主要问题是速度和模型大小，我们将尝试单独解决每个问题</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mw"><img src="../Images/c12efdb7d856798c75c75fc4099ca1df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P7Av52ll82OI_yUCo7evcQ.png"/></div></div></figure><h2 id="026b" class="mk ky iq bd kz ml mm dn ld mn mo dp lh jy mp mq ll kc mr ms lp kg mt mu lt mv bi translated"><strong class="ak">加工速度:</strong></h2><p id="644a" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">为了解决速度问题，我们将尝试在计算机上解决相同问题的相同路线，解决方案很简单，使用更好的硬件，特别是 GPU 的引入改变了事情</p><p id="662e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">同理，如果能在移动上使用硬件加速或者特定的硬件，就有加速的可能。这就引出了如何在手机上有效利用硬件的探索之路。<br/>这导致将整个硬件空间分为两种类型:</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mx"><img src="../Images/7af88e5b6c17fa8e946ec239bbe29fc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0VS_qa2bCy70-N8S3ndWYA.png"/></div></div></figure><p id="6890" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">受控硬件:</strong></p><p id="5bd2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">称之为一致的原因是，在不同型号的变化中，除了一些小的变化外，硬件方面没有什么大的变化。因此，在苹果设备上开发硬件特定模型更容易，这导致了对可用硬件能力的探索。</p><p id="9b61" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">有趣的是，我们在那个时间点接触到了 metal 框架，它刚刚发布了卷积内核操作，作为他们框架升级的一部分。我们使用金属框架围绕操作员建立了模型，它工作速度非常快！(<strong class="jp ir"> <em class="me">盗梦空间 V3:150 毫秒</em> </strong>)</p><p id="b6f9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">考虑到苹果最新的机器学习移动框架，金属的用法现在已经无关紧要了。</p><p id="0c00" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> CoreML！</strong></p><blockquote class="mb mc md"><p id="f0f6" class="jn jo me jp b jq jr js jt ju jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj kk ij bi translated">转换-&gt;加载-&gt;推断！</p></blockquote><p id="759e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">它支持大多数主要的运营商和图书馆。几乎所有库中的模型转换包装器都是可用的。在您感兴趣的任何框架中开发，使用可用的包装器将您的模型转换为 core ML 格式，然后加载模型并获得结果，您可以在少于 6 行代码中看到结果。</p><p id="81bb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">不受控制的硬件:</strong> <br/> Android 可以在这里找到，因为不同制造商在硬件方面有很大的差异</p><p id="9c7a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个平台本身有点复杂，要用我们为苹果做的同样的方式来解决它。我们的目标是通过硬件专用库来解决这一问题，如高通神经处理 SDK，它使用 snapdragon 820+手机额外的硬件功能。</p><p id="dd2e" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这个 SDK API 使用 snapdragon 的 GPU 和 DSP 功能，在推理方面让事情变得更快。流程与 Core ML 相同，在任何开发框架中训练，转换模型，使用 SDK 在设备上使用。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi my"><img src="../Images/3507d2b3d6fea459845e140e870b7951.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NiFL3IvATOjg1egb9nnMTw.png"/></div></div></figure><p id="6455" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">侧写！</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi mz"><img src="../Images/c4f8b8f1930e7a3ef491c26ff1f26272.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ohMi4G4NBK-IVaJlPbNJvg.png"/></div></div></figure><p id="eede" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这种方法粗略地解决了我们对速度的想法——至少在一个基本的方式上，根据你各自的应用程序，速度可以做更多的升级。</p><h2 id="a935" class="mk ky iq bd kz ml mm dn ld mn mo dp lh jy mp mq ll kc mr ms lp kg mt mu lt mv bi translated">模型尺寸:</h2><p id="f581" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">默认情况下，如果从服务器直接移植到移动设备，模型的大小会非常大。模型越大，它消耗的内存就越多，当用户注意到所有这些事情时，事情就会变得非常困难，并且您不希望每次升级模型时都迫使用户下载千兆字节的数据。更大的模型还有各种其他的技术难题。因此，解决方案是减小尺寸，这就让我们遵循一些有趣的方法。</p><p id="ae63" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">量化:</strong> <br/>将 float 或 double 值转换为 int 值，这导致模型大小减少了 4 倍，从技术上讲，做所有这些事情有点棘手，但是，有足够的资源来检查它。</p><figure class="km kn ko kp gt kq gh gi paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="gh gi na"><img src="../Images/47ffcfdcfb0f35da534997d59eeb0584.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b4ZyQsXoP_qOEKqh76NRfA.png"/></div></div></figure><p id="699b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我发现 P <a class="ae nb" href="https://petewarden.com/2016/05/03/how-to-quantize-neural-networks-with-tensorflow/" rel="noopener ugc nofollow" target="_blank">彼得·沃顿的</a>文章在当时非常有用，我建议每个人在尝试使用市场上现有的东西之前先浏览一下。</p><blockquote class="mb mc md"><p id="88e5" class="jn jo me jp b jq jr js jt ju jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj kk ij bi translated"><a class="ae nb" href="https://petewarden.com/2017/06/22/what-ive-learned-about-neural-network-quantization/" rel="noopener ugc nofollow" target="_blank">https://Pete warden . com/2017/06/22/what-ive-learned-on-neural-network-quantization/</a></p></blockquote><p id="2682" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">几个月前，甚至 tensorflow 也正式发布了相同的支持代码</p><blockquote class="mb mc md"><p id="47c4" class="jn jo me jp b jq jr js jt ju jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj kk ij bi translated"><a class="ae nb" href="https://www.tensorflow.org/performance/quantization" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/performance/quantization</a></p></blockquote><p id="cfed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">出于同样的原因，苹果的 Core ML 已经开始支持 16 位精度，而不是 32 位精度。</p><blockquote class="mb mc md"><p id="fbf3" class="jn jo me jp b jq jr js jt ju jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj kk ij bi translated"><a class="ae nb" href="https://developer.apple.com/documentation/coreml/reducing_the_size_of_your_core_ml_app" rel="noopener ugc nofollow" target="_blank">https://developer . apple . com/documentation/coreml/reducing _ the _ size _ of _ your _ core _ ml _ app</a></p></blockquote><p id="29a8" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">模型剪枝:</strong> <br/>通过了解哪些模型权重不是那么有用，从模型中移除不重要的节点权重。</p><blockquote class="mb mc md"><p id="81a9" class="jn jo me jp b jq jr js jt ju jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj kk ij bi translated"><a class="ae nb" href="https://jacobgil.github.io/deeplearning/pruning-deep-learning" rel="noopener ugc nofollow" target="_blank">https://Jacob Gil . github . io/deep learning/pruning-deep-learning</a></p><p id="41a7" class="jn jo me jp b jq jr js jt ju jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj kk ij bi translated"><a class="ae nb" href="https://arxiv.org/pdf/1611.06440.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1611.06440.pdf</a></p></blockquote><p id="fbfb" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">网络优化:</strong> <br/>了解什么是需要的，什么不是，这是一个重要的方面。<br/>人们必须相应地优化网络，比如用 1d 卷积替换全连接。如果一个人足够了解他们的网络，还有其他各种方法可以做到这一点。</p><h1 id="ed5e" class="kx ky iq bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">结论:</h1><p id="9300" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">我将以回答故事的标题来结束我的发言</p><h2 id="8662" class="mk ky iq bd kz ml mm dn ld mn mo dp lh jy mp mq ll kc mr ms lp kg mt mu lt mv bi translated"><strong class="ak">什么不该做？</strong></h2><p id="e4c7" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">如果数据是图像/视频，不要使用基于服务器的方法。您可以使用基于服务器的小文本和基于语音的数据。</p><h2 id="6538" class="mk ky iq bd kz ml mm dn ld mn mo dp lh jy mp mq ll kc mr ms lp kg mt mu lt mv bi translated">怎么办？</h2><p id="b9e6" class="pw-post-body-paragraph jn jo iq jp b jq lv js jt ju lw jw jx jy lx ka kb kc ly ke kf kg lz ki kj kk ij bi translated">考虑到我的经验，在如何处理这个问题上没有单一的解决方案，它应该完全基于你想要解决什么样的问题。</p><p id="04e2" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">话虽如此，如果问题是基于图像的，那么，我强烈建议围绕硬件特定的库编写您自己的包装器，这可以很好地提高模型速度并支持模型大小操作，您最终可能会这样做。</p><p id="03af" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">附言:我在 tensorflow lite 上的实验已经很老了，请随时再做一次实验，因为他们可能已经根据行业更新了他们的模块。</p><p id="5de7" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">你可能也有兴趣探索百度图书馆的移动版本 paddle-mobile。我还没有完全做好这方面的工作，但是我听到了一些很好的分析评论。话虽如此，据我所知，目前的图书馆还不稳定</p><blockquote class="mb mc md"><p id="3931" class="jn jo me jp b jq jr js jt ju jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj kk ij bi translated"><a class="ae nb" href="https://github.com/PaddlePaddle/paddle-mobile" rel="noopener ugc nofollow" target="_blank">https://github.com/PaddlePaddle/paddle-mobile</a></p></blockquote><p id="f957" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我想提出的另一个非常重要的建议是，使用 ONNX 作为开发中模型序列化/去序列化的首选格式。一年左右你会感谢我的。</p><blockquote class="mb mc md"><p id="9832" class="jn jo me jp b jq jr js jt ju jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj kk ij bi translated"><a class="ae nb" href="https://github.com/onnx/onnx" rel="noopener ugc nofollow" target="_blank">https://github.com/onnx/onnx</a>T10<a class="ae nb" href="https://onnx.ai/" rel="noopener ugc nofollow" target="_blank">https://onnx.ai/</a></p></blockquote><p id="7645" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir"> MnasNet </strong></p><p id="2941" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">如果你正在跟进谷歌最近的论文，你一定注意到了最近关于移动深度学习架构搜索的论文，这听起来非常有趣，我建议浏览一下这篇论文，这可能会给你一些关于设计网络以使其移动高效的见解。</p><blockquote class="mb mc md"><p id="fee9" class="jn jo me jp b jq jr js jt ju jv jw jx mf jz ka kb mg kd ke kf mh kh ki kj kk ij bi translated"><a class="ae nb" href="https://arxiv.org/pdf/1807.11626.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1807.11626.pdf</a></p></blockquote><p id="0a1b" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">这些观点完全基于我一年前的实验和经验，可能对你不起作用。所以，请随时反对，如果内容偏离事实，我将非常乐意根据最新的标准进行编辑。</p></div></div>    
</body>
</html>