<html>
<head>
<title>Speeding up the Housing Search in San Francisco with Data Science</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用数据科学加速旧金山的住房搜索</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-find-housing-in-san-francisco-with-data-science-2991ff503602?source=collection_archive---------4-----------------------#2018-03-13">https://towardsdatascience.com/how-to-find-housing-in-san-francisco-with-data-science-2991ff503602?source=collection_archive---------4-----------------------#2018-03-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/728575c333b58f1a9f8bab952b74c534.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o_c-ye-ViWKYZK6RZXP45A.jpeg"/></div></div></figure><p id="d02b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">不久前有人问我如何在旧金山找到住房。一年前，在我找到我现在的客厅沙发之前，我开始寻找住房，并且很快成为一种压倒性的经历，试图找到任何低于一只胳膊和一条腿的租金。我花越来越多的时间在网上搜索，并把搜索范围从金融区扩大到旧金山的几个地区，包括臭名昭著的嫩腰区。这种搜索慢慢消耗了我的精力，以至于我每天醒来至少花一个小时点击 Craigslist，看到熟悉的地方，一张疲惫的脸。</p><p id="aa57" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我心想:“一定有什么办法可以加快找房子的速度！”作为一名有抱负的数据科学家，我的解决方案是创建一个 web scraper，它可以收集旧金山几个地区的信息，并以简洁的方式呈现它们，而不是所有的绒毛。虽然不能保证找到房子，但至少我可以把 1 个多小时的搜索时间减少到 10 分钟。</p><p id="42f6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">TLDR:我写了一个脚本，以地点和价格为参数来抓取 Craigslist。代码位于底部，但除此之外继续阅读，看看整个网页抓取过程！</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi kw"><img src="../Images/acded64681550e78f6644af17b4ac6cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sMMHx_95TSwKSszZ5Zw81A.jpeg"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">One of the most helpful pictures I had in finding housing</figcaption></figure><p id="ca50" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">第 0 步:了解你的敌人</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lf"><img src="../Images/4d93c09d8de7f3376942d847d7f5d078.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TWL7YN4jJajWg5gwIGZtCw.jpeg"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">What the Craigslist interface looks like</figcaption></figure><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi lg"><img src="../Images/a71ab3621a0d69e47366c88eef2c341c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kW8cgZqUQ92mAMFdSfGhNw.jpeg"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">What I wanted the results to look like</figcaption></figure><p id="b70d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">很多时候，我们很容易超越自己，一头扎进问题中。对我的编码技能有很大帮助的一件事是从较小的目标开始，然后把它变成一个大的、宏伟的目标。我的大目标是得到每篇文章的标题以及它到个人页面的链接。然后我想从旧金山的一个地区(比如格伦公园)搬到另一个地区(比如巴尔博亚公园)。查看 Craigslist 界面，似乎每篇文章都有一个标题和一个蓝色超链接，显示在描述旁边会很有用。</p><p id="f160" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">因此，分解大目标，我的攻击计划是:</p><ol class=""><li id="04d6" class="lh li iq ka b kb kc kf kg kj lj kn lk kr ll kv lm ln lo lp bi translated">使用 Selenium 打开一个远程控制页面</li><li id="1b89" class="lh li iq ka b kb lq kf lr kj ls kn lt kr lu kv lm ln lo lp bi translated">刮一页 Craigslist 住房获得标题</li><li id="d19c" class="lh li iq ka b kb lq kf lr kj ls kn lt kr lu kv lm ln lo lp bi translated">进一步抓取以获得卖家帖子的链接</li><li id="df7e" class="lh li iq ka b kb lq kf lr kj ls kn lt kr lu kv lm ln lo lp bi translated">移动到另一个位置而不重写任何内容</li><li id="84e9" class="lh li iq ka b kb lq kf lr kj ls kn lt kr lu kv lm ln lo lp bi translated">重复此过程，直到所有位置都被刮除</li><li id="5a6b" class="lh li iq ka b kb lq kf lr kj ls kn lt kr lu kv lm ln lo lp bi translated">把所有的都集中到一个好的功能上</li></ol><p id="56c1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">第一步:引入网络抓取工具</strong></p><pre class="kx ky kz la gt lv lw lx ly aw lz bi"><span id="2ee3" class="ma mb iq lw b gy mc md l me mf">from selenium import webdriver<br/>from bs4 import BeautifulSoup<br/>import urllib2<br/>import re<br/>import pandas as pd<br/>import numpy as np<br/>pd.set_option('max_colwidth', 5000)<br/>pd.options.display.max_rows = 999</span></pre><p id="7692" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">第二步:用硒打开一个网页</strong></p><p id="7e9b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">Selenium 是一个工具，它让我们在浏览器中自动操作，就像我们像人一样点击或打字一样。这让我们可以登录并做任何人类在使用浏览器时可以做的事情。也许最重要的是，它允许我们从网页中抓取数据，这些网页使用在浏览器中执行的 JavaScript 生成 HTML 旧金山大学的 Terence Parr 教授说</p><p id="0c83" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">为了初始化 Selenium 工具，我们需要从 Chromedriver(或 geckodriver)所在的路径调用它。<a class="ae mg" href="http://www.seleniumhq.org/download/" rel="noopener ugc nofollow" target="_blank">(链接下载 Selenium) </a></p><pre class="kx ky kz la gt lv lw lx ly aw lz bi"><span id="b08a" class="ma mb iq lw b gy mc md l me mf">driver = webdriver.Chrome(executable_path="/Users/shsu/Downloads/chromedriver")</span></pre><p id="0527" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">在那里，我们可以使用驱动程序打开某些网页，例如:</p><pre class="kx ky kz la gt lv lw lx ly aw lz bi"><span id="cef9" class="ma mb iq lw b gy mc md l me mf">driver.get('http://google.com')</span></pre><p id="e61c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">这应该会在你的 Chrome 上打开一个新的浏览器，然后可以用代码自动完成。用你选择的任何网站试试吧！</p><p id="690b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">第三步:从页面上刮下帖子标题</strong></p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mh"><img src="../Images/88df8b7e52d5a41133bc94851c4ac5ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1IzaiL5YJ1v6_NHAzh5qWQ.jpeg"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">A general query for my housing limitations</figcaption></figure><p id="8ab1" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">如前所述，我们宏伟计划的第一个目标是抓取 Craigslist 的一个页面。让我们打开一个页面，实际输入一些过滤器(参数)，然后查看内容(左边的图片)。就我的预算而言，我正在寻找一个低于 900 美元的地方，并希望最近的帖子首先显示出来。当我查看由该查询创建的超链接时，我得到这样的结果:</p><p id="40b0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">"【https://sfbay.craigslist.org/search/roo?query=】T4<strong class="ka ir">格伦+公园</strong>T18】sort =<strong class="ka ir">date</strong>T19】max _ price =<strong class="ka ir">900</strong>T20】availability mode = 0</p><p id="b021" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">你知道什么？看起来 url 中的头包含了我输入的参数，也就是查询字符串<a class="ae mg" href="https://en.wikipedia.org/wiki/Query_string" rel="noopener ugc nofollow" target="_blank">和</a>。让我们从代码开始。</p><pre class="kx ky kz la gt lv lw lx ly aw lz bi"><span id="c057" class="ma mb iq lw b gy mc md l me mf">url = <a class="ae mg" href="https://sfbay.craigslist.org/search/roo?query=glen+park&amp;sort=date&amp;max_price=1000&amp;availabilityMode=0" rel="noopener ugc nofollow" target="_blank">https://sfbay.craigslist.org/search/roo?query=glen+park&amp;sort=date&amp;max_price=1000&amp;availabilityMode=0</a></span><span id="0168" class="ma mb iq lw b gy mi md l me mf">driver.get(url)</span></pre><p id="7004" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">此时，你可能会奇怪为什么我选择 Chromedriver 而不是其他 web 驱动。主要原因是因为开发者工具可以用这三个键打开:</p><p id="9005" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">选项+命令+ U </strong></p><p id="59b6" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">通过同时点击这三个键，您可以查看任何网页背后的 HTML 代码。</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mj"><img src="../Images/b2084e89aebb09f14a17c6671e7a0325.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E6tB6S0wIQoDPTE5fJ-XVw.jpeg"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Inside the developer source with the tag information we need</figcaption></figure><p id="7598" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">通过搜索单个标题文章，我们可以提取该文章的标签和标题。在这种情况下，请注意上图顶部带有“result-info”类的“p”标签。在这个标签中包含了关键文本(特别是“Lafayette 的出租房间”、“1100 美元”和“(Lafayette/or inda/moraga)”，我们可以用. text 来抓取。</p><pre class="kx ky kz la gt lv lw lx ly aw lz bi"><span id="f0c5" class="ma mb iq lw b gy mc md l me mf">craig_title = []<br/>all_posts = driver.find_elements_by_class_name("result-row")<br/>for post in all_posts:<br/>    craig_title.append(post.text)</span></pre><p id="d817" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">现在我们已经从帖子的标题中获得了所有重要的信息！接下来我们要做的就是抓取这个页面，不仅要获取标题信息，还要获取标题所指向的网页。</p><p id="5f6c" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">第四步:抓取个人帖子的链接</strong></p><p id="9812" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">棘手的部分来了:如果我不能在不重定向 Selenium 浏览器的情况下点击链接并获得它的超链接，我如何获得到个人卖家页面的链接？</p><p id="1cfc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">解决方案:使用我们的网络抓取工具寻找一个标题，然后将其推广到页面上的所有帖子。</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mk"><img src="../Images/eca633a6c62b6447ebb680c4ca281e20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Xhpkg6tR7_iPiefMLMqfw.jpeg"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">What we see on the website</figcaption></figure><figure class="kx ky kz la gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ml"><img src="../Images/cb6744015e0d29ed21c92dc743e9e6dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3iOWjG-SB6tNJ_aOTGdDYg.jpeg"/></div></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">What the code on the website looks like</figcaption></figure><p id="71c7" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">通过搜索原始标题文章，我们可以看到“a”标签和“href”类等同于我们正在搜索的文章链接。我们将首先用 urllib2 打开 url(因为我们不想用 selenium 远程打开另一个页面)，然后按照与步骤 2 类似的过程获得 post 超链接。</p><pre class="kx ky kz la gt lv lw lx ly aw lz bi"><span id="3904" class="ma mb iq lw b gy mc md l me mf">link_list = []<br/>html_page = urllib2.urlopen(url)<br/>soup = BeautifulSoup(html_page, "lxml")<br/>for element in soup.findAll("a", {"class": "result-title hdrlnk"}):<br/>    print element['href']</span></pre><p id="bccc" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们现在已经抓取了文章标题和它们各自的链接。</p><p id="0f59" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">第 5 步和第 6 步:迭代整个过程并进行归纳</strong></p><p id="d97d" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们可以用变量代替所有参数来概括我们的刮削。</p><p id="05c5" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">例如，转动这个:</p><pre class="kx ky kz la gt lv lw lx ly aw lz bi"><span id="5369" class="ma mb iq lw b gy mc md l me mf">craig_title = []<br/>url = <strong class="lw ir">"https://sfbay.craigslist.org/search/roo?query=glen+park&amp;sort=date&amp;max_price=1000&amp;availabilityMode=0"</strong><br/>driver.get(url)<br/>allthing = driver.find_elements_by_class_name("result-row")<br/>for post in allthing:<br/>    craig_title.append(post.text)</span></pre><p id="baf3" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">变成这样:</p><pre class="kx ky kz la gt lv lw lx ly aw lz bi"><span id="5d76" class="ma mb iq lw b gy mc md l me mf"><strong class="lw ir">place = ['glen+park']<br/>price = '900'</strong></span><span id="2977" class="ma mb iq lw b gy mi md l me mf">craig_title = []<br/>url = <strong class="lw ir">"</strong><a class="ae mg" href="https://sfbay.craigslist.org/search/roo?query=" rel="noopener ugc nofollow" target="_blank"><strong class="lw ir">https://sfbay.craigslist.org/search/roo?query=</strong></a><strong class="lw ir">"+ \<br/>                str(place)+ <br/>                "&amp;sort=date&amp;max_price="+<br/>                str(price)+<br/>                "&amp;availabilityMode=0"</strong><br/>driver.get(url)<br/>all_posts = driver.find_elements_by_class_name("result-row")<br/>for post in all_posts:<br/>    craig_title.append(post.text)</span></pre><p id="c71b" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们可以对所有其他变量重复这个过程，比如当我们遍历页面并添加到列表中时。</p><p id="6ead" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated"><strong class="ka ir">第七步:把所有东西放在一起</strong></p><p id="b09e" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">我们有(1)抓取一个页面的标题和链接，(2)移动到另一个页面并重复步骤 1，以及(3)将所有信息附加到一个列表。所以现在，我们要做的就是创建一个漂亮的小函数，允许我们包含一些参数并返回一个数据帧。姑且称之为:<strong class="ka ir"> craig_list() </strong>。</p><pre class="kx ky kz la gt lv lw lx ly aw lz bi"><span id="761b" class="ma mb iq lw b gy mc md l me mf">from selenium import webdriver<br/>from bs4 import BeautifulSoup<br/>import urllib2<br/>import re<br/>import pandas as pd<br/>import numpy as np<br/>pd.set_option('max_colwidth', 5000)<br/>pd.options.display.max_rows = 999<br/>from IPython.display import display, HTML</span><span id="f8f9" class="ma mb iq lw b gy mi md l me mf">driver = webdriver.Chrome(executable_path="/Users/shsu/Downloads/chromedriver")</span><span id="af50" class="ma mb iq lw b gy mi md l me mf">def craig_list(price, location_list=list):<br/>    """<br/>    craig_list is a function that creates the condensed Craigslist post information<br/>    Inputs:<br/>        price_max: integer of the maximum price of houses one wants<br/>        places: list of strings where the string represents the region of choice <br/>    Output:<br/>        a dataframe with the description and the link of the post <br/>    """<br/>    craig_title = []<br/>    link_list = []<br/>    for place in location_list:<br/>        print("--------- MOVING TO PLACE: " + str(place) + " -----")<br/>        link_list.append(" ")<br/>        craig_title.append(str(place).upper())<br/>        <br/>        url = "<a class="ae mg" href="https://sfbay.craigslist.org/search/roo?query=" rel="noopener ugc nofollow" target="_blank">https://sfbay.craigslist.org/search/roo?query=</a>"+ \<br/>                str(place)+ "&amp;sort=date&amp;max_price="+ str(price)+"&amp;availabilityMode=0"<br/>        driver.get(url)<br/>        all_posts = driver.find_elements_by_class_name("result-row")<br/>        for post in all_posts:<br/>            craig_title.append(post.text)<br/>    <br/>        html_page = urllib2.urlopen(url)<br/>        soup = BeautifulSoup(html_page, "lxml")<br/>        for pid in soup.findAll("a", {"class": "result-title hdrlnk"}):<br/>         link_list.append(pid['href'])<br/>    craig_df = pd.DataFrame(np.column_stack([craig_title,link_list]), <br/>columns = ["Info", "Link"])<br/>    return craig_df</span><span id="0055" class="ma mb iq lw b gy mi md l me mf">places = ["glen+park", "balboa+park"]<br/>price_max = 900<br/>craig_df = craig_list(price_max, places)<br/>display(craig_df)</span></pre><p id="4fb0" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">就像这样，你现在也可以节省 40 分钟在 Craigslist 上搜索房屋的时间，最终在一个改造过的客厅里租到一张沙发！</p><figure class="kx ky kz la gt jr gh gi paragraph-image"><div class="gh gi mm"><img src="../Images/1602be48c66ae7ec053fb63f756e1013.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*oB1HdwulfnhV0vmHMH1rXw.jpeg"/></div><figcaption class="lb lc gj gh gi ld le bd b be z dk">Even San Francisco is not safe from satire</figcaption></figure><p id="74f9" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">总之，我们了解到，虽然抓取看起来困难且耗时，但它可以被分解为更容易的部分，在实际的用户界面和背后的 HTML 源代码之间可视化，并最终概括为模拟整个人类行为。感谢你的阅读，祝你找房子好运！</p><p id="7398" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">附言:很多帖子都是垃圾邮件制造者，他们复制真实的帖子，并给出一个通用的消息“请把你的联系电话发给我，我会尽快与你联系。”</p><p id="3709" class="pw-post-body-paragraph jy jz iq ka b kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv ij bi translated">参考资料:</p><ol class=""><li id="a032" class="lh li iq ka b kb kc kf kg kj lj kn lk kr ll kv lm ln lo lp bi translated"><a class="ae mg" href="http://www.seleniumhq.org/download/" rel="noopener ugc nofollow" target="_blank">硒下载页面</a></li><li id="f02c" class="lh li iq ka b kb lq kf lr kj ls kn lt kr lu kv lm ln lo lp bi translated"><a class="ae mg" href="https://github.com/parrt/msan692/blob/master/notes/selenium.md" rel="noopener ugc nofollow" target="_blank">特伦斯·帕尔教授的硒教程</a></li><li id="bde5" class="lh li iq ka b kb lq kf lr kj ls kn lt kr lu kv lm ln lo lp bi translated"><a class="ae mg" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">美汤文档</a></li><li id="e345" class="lh li iq ka b kb lq kf lr kj ls kn lt kr lu kv lm ln lo lp bi translated"><a class="ae mg" href="https://en.wikipedia.org/wiki/Query_string" rel="noopener ugc nofollow" target="_blank">查询字符串</a></li><li id="b774" class="lh li iq ka b kb lq kf lr kj ls kn lt kr lu kv lm ln lo lp bi translated">【Beautifulsoup 网页抓取教程</li><li id="30a5" class="lh li iq ka b kb lq kf lr kj ls kn lt kr lu kv lm ln lo lp bi translated"><a class="ae mg" href="https://sfbay.craigslist.org/" rel="noopener ugc nofollow" target="_blank">旧金山 Craigslist </a></li></ol></div></div>    
</body>
</html>