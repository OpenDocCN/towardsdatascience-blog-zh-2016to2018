<html>
<head>
<title>RecSys 2017</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">RecSys 2017</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/recsys-2017-2d0879351097?source=collection_archive---------7-----------------------#2017-10-02">https://towardsdatascience.com/recsys-2017-2d0879351097?source=collection_archive---------7-----------------------#2017-10-02</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/cdfed779ce958fe735ce8df35decbe35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jYbugeJWZCCWbDHEwifKXg.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">Not a bad location for a conferance</figcaption></figure><p id="2cf0" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">每年推荐系统社区(学术界和工业界都一样)聚集在一起分享关于推荐系统的研究、思想和想法。今年的会议在科莫湖举行，有40多场演讲、11场行业讲座、10场研讨会和4场辅导课，吸引了600多名与会者。</p><p id="d086" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">如果我对下面的文章有任何误解，请纠正我。</p><h1 id="5883" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">关键主题</h1><p id="0bda" class="pw-post-body-paragraph kc kd iq ke b kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv mc kx ky kz ij bi translated">在整个会议中，我认为有三个强有力的主题贯穿始终；</p><ul class=""><li id="4710" class="md me iq ke b kf kg kj kk kn mf kr mg kv mh kz mi mj mk ml bi translated"><em class="mm">深度学习</em> —正如在许多其他学科(NLP和计算机视觉)中看到的那样，深度学习继续变得越来越受欢迎。尽管这些论文声称在测试数据集的准确性方面取得了显著的进步，但许多论文已经开始批评它的有效性，并质疑与类似模型相比，这种复杂系统的价值。</li><li id="ba59" class="md me iq ke b kf mn kj mo kn mp kr mq kv mr kz mi mj mk ml bi translated"><em class="mm">个性化</em>——和任何推荐器一样，其目标之一是在正确的时间呈现用户想要的信息。个性化推荐采取了多种形式，从尝试在LtR模型中使用个人信息对项目进行排序，使用更高层次的RNNs对会话推荐进行个性化，到为系统内的每个用户训练模型。每个放映效果导致对用户的个性化推荐。</li><li id="126e" class="md me iq ke b kf mn kj mo kn mp kr mq kv mr kz mi mj mk ml bi translated"><em class="mm">工业界与学术界</em>——这场战斗已经持续了多年，尽管这两者之间似乎是一种健康的关系。工业似乎带来了有趣的数据和真实的生活结果。然而学术界展示了许多关于推荐的有趣模型和理论(例如会话式推荐系统)。尽管在将学术界应用到工业规模之间，甚至在如何将一些模型应用到一台机器之外之间，似乎存在着差距。</li></ul><h1 id="64e8" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">有趣的论文</h1><p id="7f9f" class="pw-post-body-paragraph kc kd iq ke b kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv mc kx ky kz ij bi translated">提交了一些有趣的论文，以下是非常好的。这些论文通常简单明了地表达了他们想要达到的目标，并有效地传达了一个概念。</p><p id="f6b1" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> <em class="mm">控制学习排名推荐中的人气偏差</em> </strong></p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="f2de" class="nb lb iq mx b gy nc nd l ne nf">Abdollahpouri, H., Burke, R., &amp; Mobasher, B. (2017). Controlling Popularity Bias in Learning-to-Rank Recommendation (pp. 42–46). Presented at the the Eleventh ACM Conference, New York, New York, USA: ACM Press. <a class="ae ng" href="http://doi.org/10.1145/3109859.3109912" rel="noopener ugc nofollow" target="_blank">http://doi.org/10.1145/3109859.3109912</a></span></pre><p id="1556" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">推荐面临的挑战之一是如何让用户发现日志尾部的项目。因为长尾中的项目可能比高度流行的项目更与用户相关。本文作者将项目分为高、中、低三个等级。目的是最终的推荐列表应该由50/50的高等级和中等级项目组成。为了实现这一点，研究人员引入了矩阵分解方法的调节阶段，该方法基于指示项目对是否在不同等级类别中的相异矩阵。这只会影响项目嵌入，而不会影响用户嵌入。</p><p id="dd5c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">结果表明，用户可以在不降低质量的情况下向用户推荐大量的长尾项目(通过NDCG@10测量)。在实施这种简单的方法中，有两个潜在的好处，首先，探索了目录的更大推广，因此如果在生产环境中实施，可以获得更大量的反馈。第二，用户之间推荐的多样性增加，从而减少了正在创建的<em class="mm">过滤器bubel </em>的变化。</p><p id="c957" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">尽管这可能不是突破性的，但简单的想法有时会对产生建议产生最大的影响。尽管与任何矩阵工厂方法一样，将它扩展到真实世界数据的能力总是引起我的兴趣，但与之前的实验一样，矩阵分解似乎只适用于用户活动大小变化较小的数据集，并且容易受到噪声数据集的影响。</p><p id="d38b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> <em class="mm">当递归神经网络遇到邻居时进行基于会话的推荐</em> </strong></p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="e3cd" class="nb lb iq mx b gy nc nd l ne nf">Jannach, D., &amp; Ludewig, M. (2017). When Recurrent Neural Networks meet the Neighborhood for Session-Based Recommendation (pp. 306–310). Presented at the the Eleventh ACM Conference, New York, New York, USA: ACM Press. <a class="ae ng" href="http://doi.org/10.1145/3109859.3109872" rel="noopener ugc nofollow" target="_blank">http://doi.org/10.1145/3109859.3109872</a></span></pre><p id="17a2" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">在演示结束时，这篇论文似乎在房间里引起了一点紧张。尽管它强调了使用深度学习系统的一个问题，即人们可以使用基本(更简单)的ML模型获得类似(或更好)的结果。作者比较了门控循环单元(GRU4REC) <a class="ae ng" href="#fn1-15433" rel="noopener ugc nofollow"> 1 </a>和kNN的一些设置，以生成会话推荐。结果表明，与使用复杂的GRUs相比，使用kNN方法可以获得相似或更好的精度。尽管当两种方法结合使用时可以达到最佳效果。</p><p id="e0b8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> <em class="mm">在Zalando </em> </strong>开发大规模推荐系统的实践经验</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="f601" class="nb lb iq mx b gy nc nd l ne nf">Freno, A. (2017). Practical Lessons from Developing a Large-Scale Recommender System at Zalando (pp. 251–259). Presented at the the Eleventh ACM Conference, New York, New York, USA: ACM Press. <a class="ae ng" href="http://doi.org/10.1145/3109859.3109897" rel="noopener ugc nofollow" target="_blank">http://doi.org/10.1145/3109859.3109897</a></span></pre><p id="90d8" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">RecSys的一个优点是在会议记录中混合了行业领先的论文。来自Zalando的这篇文章重点介绍了他们如何在多个产品中大规模部署学习排名(LTR)。为了扩展模型学习，他们采用成对方法，这样就可以使用Spark和SparkML等分布式框架进行大规模学习。</p><p id="914b" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> <em class="mm">一种基于梯度的自适应学习框架，用于高效的个人推荐</em> </strong></p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="7919" class="nb lb iq mx b gy nc nd l ne nf">Ning, Y., Shi, Y., Hong, L., Rangwala, H., &amp; Ramakrishnan, N. (2017). A Gradient-based Adaptive Learning Framework for Efficient Personal Recommendation (pp. 23–31). Presented at the the Eleventh ACM Conference, New York, New York, USA: ACM Press. <a class="ae ng" href="http://doi.org/10.1145/3109859.3109909" rel="noopener ugc nofollow" target="_blank">http://doi.org/10.1145/3109859.3109909</a></span></pre><p id="ba16" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">本文提出了一个有趣的模型(或多个模型)。其前提是，当训练一个模型来生成推荐时，它是根据一个全局目标函数来学习的，该目标函数产生系统内用户的平均模型。为了使用户或用户组的模型个性化，作者建议可以首先训练多个时期的“全局”模型，然后将模型的模型权重转移到“局部”模型，以继续对用户子集进行训练，从而提高个性化推荐器模型的个性化和训练速度。</p><h1 id="bf97" class="la lb iq bd lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx bi translated">有趣的礼物</h1><p id="47d0" class="pw-post-body-paragraph kc kd iq ke b kf ly kh ki kj lz kl km kn ma kp kq kr mb kt ku kv mc kx ky kz ij bi translated">在整个会议中，许多行业的焦点都集中在演讲上。这些研究本质上不一定是学术性的，但却很好地揭示了建议研究如何在实践中应用，以及如何在规模上进行编排。</p><p id="d173" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">网飞——如果没有网飞的介绍，这就不是一个推荐会议。正如在推荐和推荐系统的介绍中所强调的，它们受到过去用户行为的影响，并影响未来用户的意图。因此，如何在推荐器中建模时间，允许开发的模型与时间的时间效应隔离。</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="4b30" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><a class="ae ng" href="//www.slideshare.net/justinbasilico/deja-vu-the-importance-of-time-and-causality-in-recommender-systems" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ir"> Déjà Vu:推荐系统中时间和因果关系的重要性</strong> </a> <strong class="ke ir"> </strong>出自<a class="ae ng" href="//www.slideshare.net/justinbasilico" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ir">贾斯汀巴西利科</strong> </a></p><ul class=""><li id="737b" class="md me iq ke b kf kg kj kk kn mf kr mg kv mh kz mi mj mk ml bi translated">最大限度地减少系统内的反馈循环</li><li id="50b1" class="md me iq ke b kf mn kj mo kn mp kr mq kv mr kz mi mj mk ml bi translated">允许有控制地探索建议</li><li id="e5f0" class="md me iq ke b kf mn kj mo kn mp kr mq kv mr kz mi mj mk ml bi translated">增量</li></ul><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nj"><img src="../Images/d85cf07aa99a0c452c513fcc0e7b8437.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bnB7CmltbW-A-T2LQyr2nA.jpeg"/></div></div></figure><p id="fa9c" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated">Blendal是一家专注于新闻推荐的丹麦公司。他们展示的产品/挑战是他们如何每天获取7000篇新文章，并在早上7点前通过个性化电子邮件推荐给用户(供他们评论工作时使用)。通过使用用户建模和基于内容的功能，他们能够为用户选择相关的文章。尽管这个演讲有趣的部分是他们使用了一个带交错的凌渡bandit来在线调整模型的参数，允许系统从用户的隐含反馈中学习。</p><figure class="ms mt mu mv gt jr"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="a465" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><a class="ae ng" href="//www.slideshare.net/dodijk/blendle-recsys17-online-learning-to-rank-for-recommender-systems" rel="noopener ugc nofollow" target="_blank"><strong class="ke ir">blend le @ rec sys’17:在线学习推荐系统排名</strong> </a> <strong class="ke ir"> </strong>来自<a class="ae ng" href="https://www.slideshare.net/dodijk" rel="noopener ugc nofollow" target="_blank"> <strong class="ke ir">金奎大奥迪克</strong> </a></p><ul class=""><li id="b1ca" class="md me iq ke b kf kg kj kk kn mf kr mg kv mh kz mi mj mk ml bi translated">人类策划的候选集</li><li id="8ef9" class="md me iq ke b kf mn kj mo kn mp kr mq kv mr kz mi mj mk ml bi translated">德国强盗</li><li id="de01" class="md me iq ke b kf mn kj mo kn mp kr mq kv mr kz mi mj mk ml bi translated">团队草稿交错</li><li id="69e8" class="md me iq ke b kf mn kj mo kn mp kr mq kv mr kz mi mj mk ml bi translated">多样化</li></ul><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nk"><img src="../Images/8fed5ffe59ad31617d88cc7299b5c7fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KJcV1uFHF5UMwhiHgALfnA.jpeg"/></div></div></figure><p id="f5ed" class="pw-post-body-paragraph kc kd iq ke b kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz ij bi translated"><strong class="ke ir"> EA(在游戏里)</strong> —我被这个演示给惊喜了。它展示了推荐不仅仅是整个系统的一种算法，它会影响用户体验的每一个阶段。然而，这不仅仅是一个推荐者，而是一套互动系统，所有这些系统都旨在引导玩家完成游戏，优化用户流失率。</p><h2 id="bdc3" class="nb lb iq bd lc nl nm dn lg nn no dp lk kn np nq lo kr nr ns ls kv nt nu lw nv bi translated">总的来说，这是一个了不起的会议，我等不及明年的温哥华了。</h2><figure class="ms mt mu mv gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nj"><img src="../Images/4ac09a924b131d0f166b41e893d68a7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ab5fg6dVi10UIJkRdI3rSA.jpeg"/></div></div><figcaption class="jy jz gj gh gi ka kb bd b be z dk">See you next year</figcaption></figure></div><div class="ab cl nw nx hu ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="ij ik il im in"><ol class=""><li id="2aa7" class="md me iq ke b kf kg kj kk kn mf kr mg kv mh kz od mj mk ml bi translated">Bala zs hid ASI、Alexandros Karatzoglou、Linas Baltrunas和Domonkos Tikk。2016.基于会话的递归神经网络推荐。学习表征国际会议论文集(ICLR 16)。ACM。h p://arxiv . org/ABS/1511.06939<a class="ae ng" href="#fnr1-15433" rel="noopener ugc nofollow">↩︎</a></li></ol></div></div>    
</body>
</html>