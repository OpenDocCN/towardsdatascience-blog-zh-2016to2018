<html>
<head>
<title>Building and Testing Recommender Systems With Surprise, Step-By-Step</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一步一步地建立和测试推荐系统</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-and-testing-recommender-systems-with-surprise-step-by-step-d4ba702ef80b?source=collection_archive---------1-----------------------#2018-12-26">https://towardsdatascience.com/building-and-testing-recommender-systems-with-surprise-step-by-step-d4ba702ef80b?source=collection_archive---------1-----------------------#2018-12-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/71893eb8c94611dd1f95adda807b7769.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dOM8OeGZq6FkquXQq-l7HA.jpeg"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Photo credit: Pixabay</figcaption></figure><div class=""/><div class=""><h2 id="3b02" class="pw-subtitle-paragraph kc je jf bd b kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dk translated">了解如何借助 Python 和惊喜库、协同过滤来构建自己的推荐引擎</h2></div><p id="25b6" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><a class="ae lq" href="https://en.wikipedia.org/wiki/Recommender_system" rel="noopener ugc nofollow" target="_blank">推荐系统</a>是数据科学最常用和最容易理解的应用之一。关于这个主题已经做了很多工作，由于互联网的快速发展和信息过载问题，人们对这个领域的兴趣和需求仍然很高。帮助用户处理信息过载并向他们提供个性化的推荐、内容和服务已经成为在线企业的必要工作。</p><p id="3084" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">推荐系统最流行的两种方法是<a class="ae lq" href="https://en.wikipedia.org/wiki/Collaborative_filtering" rel="noopener ugc nofollow" target="_blank">协同过滤</a>和<a class="ae lq" href="https://www.analyticsvidhya.com/blog/2015/08/beginners-guide-learn-content-based-recommender-systems/" rel="noopener ugc nofollow" target="_blank">基于内容的推荐</a>。在本帖中，我们将重点介绍协同过滤方法，即:向用户推荐过去有相似品味和偏好的人喜欢的项目。换句话说，这种方法通过使用用户之间的相似性来预测未知的评级。</p><p id="73fb" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们将与<a class="ae lq" href="http://www2.informatik.uni-freiburg.de/~cziegler/BX/" rel="noopener ugc nofollow" target="_blank">图书交叉</a>，一个图书评级数据集一起开发推荐系统算法，与<a class="ae lq" href="http://surpriselib.com/" rel="noopener ugc nofollow" target="_blank">惊喜图书馆</a>，它是由<a class="ae lq" href="http://nicolas-hug.com/" rel="noopener ugc nofollow" target="_blank"> Nicolas Hug </a>建立的。我们开始吧！</p><h1 id="a2f7" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated">数据</h1><p id="2931" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated">图书交叉数据由三个表组成，我们将使用其中的两个:用户表和图书评级表。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="4916" class="mx ls jf mt b gy my mz l na nb">user = pd.read_csv('BX-Users.csv', sep=';', error_bad_lines=False, encoding="latin-1")<br/>user.columns = ['userID', 'Location', 'Age']<br/>rating = pd.read_csv('BX-Book-Ratings.csv', sep=';', error_bad_lines=False, encoding="latin-1")<br/>rating.columns = ['userID', 'ISBN', 'bookRating']<br/>df = pd.merge(user, rating, on='userID', how='inner')<br/>df.drop(['Location', 'Age'], axis=1, inplace=True)<br/>df.head()</span></pre><figure class="mo mp mq mr gt is gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/375d0be8a46019a181893ccdae955269.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*S_EVTbhOHD-p9MoM2Mh-bg.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Figure 1</figcaption></figure><h1 id="6e25" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated">电子设计自动化(Electronic Design Automation)</h1><h2 id="499d" class="mx ls jf bd lt nd ne dn lx nf ng dp mb ld nh ni md lh nj nk mf ll nl nm mh nn bi translated"><strong class="ak">收视率分布</strong></h2><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="no np l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">ratings_distribution.py</figcaption></figure><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nq"><img src="../Images/e242a65e2a4f45435a14a2af16f76044.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OiPHSMaQJKBhx3hxHxwDLQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Figure 2</figcaption></figure><p id="5c98" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们可以看到，数据中超过 62%的评级为 0，极少数评级为 1 或 2，或 3，低评级书意味着它们通常非常糟糕。</p><h2 id="e3cc" class="mx ls jf bd lt nd ne dn lx nf ng dp mb ld nh ni md lh nj nk mf ll nl nm mh nn bi translated"><strong class="ak">图书收视率分布</strong></h2><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="no np l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">ratings_distribution_by_book.py</figcaption></figure><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nr"><img src="../Images/661214fc45dd62b1ff44fe8e7bd81caf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C2MvdF2DtWO2KDwdjYEWHA.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Figure 3</figcaption></figure><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="d2c5" class="mx ls jf mt b gy my mz l na nb">df.groupby('ISBN')['bookRating'].count().reset_index().sort_values('bookRating', ascending=False)[:10]</span></pre><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ns"><img src="../Images/2b68d90dc5682ca041c929ad3af36a48.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*ROMqDkiIVYDl9rLtn7VB8A.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Figure 4</figcaption></figure><p id="34b6" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">数据中的大部分书获得的评分都在 5 分以下，极少数书获得了很多评分，尽管评分最高的书获得了 2502 分。</p><h2 id="0040" class="mx ls jf bd lt nd ne dn lx nf ng dp mb ld nh ni md lh nj nk mf ll nl nm mh nn bi translated"><strong class="ak">用户评分分布</strong></h2><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="no np l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">ratings_distribution_by_user.py</figcaption></figure><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nt"><img src="../Images/782cc13b8bfa47f795e9b8138c9ac890.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1IRSk5qEjDp_S6kf6jmb9w.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Figure 5</figcaption></figure><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="18c0" class="mx ls jf mt b gy my mz l na nb">df.groupby('userID')['bookRating'].count().reset_index().sort_values('bookRating', ascending=False)[:10]</span></pre><figure class="mo mp mq mr gt is gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/162b9c914c070e587c0f7888700f83f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*Ia6GPaH9HcxhFNuLCHC9XQ.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Figure 6</figcaption></figure><p id="6403" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">数据中的大多数用户给出的评分少于 5 分，给出很多评分的用户也不多，尽管最有生产力的用户给出了 13，602 个评分。</p><p id="47a1" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我相信你已经注意到了上面两个图有相同的分布。每本书的评分数和每个用户的评分数呈指数衰减。</p><p id="39dc" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">为了降低数据集的维度，避免陷入“记忆错误”，我们将过滤掉很少评级的书籍和很少评级的用户。</p><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="no np l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">filter_dataframe.py</figcaption></figure><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nv"><img src="../Images/df4c408be19af872cbd15e83ee50db9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AY7A-Cy8wJ4N6ZA3a4ym7g.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Figure 7</figcaption></figure><h1 id="85d8" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated">惊喜</h1><p id="3cea" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated">为了从上面的 pandas 数据框加载一个数据集，我们将使用<code class="fe nw nx ny mt b">load_from_df()</code>方法，我们还需要一个<code class="fe nw nx ny mt b">Reader</code>对象，并且必须指定<code class="fe nw nx ny mt b">rating_scale</code>参数。数据框必须有三列，依次对应于用户 id、项目 id 和等级。因此，每一行对应于一个给定的等级。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="2e7d" class="mx ls jf mt b gy my mz l na nb">reader = Reader(rating_scale=(0, 9))<br/>data = Dataset.load_from_df(df_new[['userID', 'ISBN', 'bookRating']], reader)</span></pre><p id="8df7" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">借助惊喜库，我们将对以下算法进行基准测试:</p><h2 id="af2a" class="mx ls jf bd lt nd ne dn lx nf ng dp mb ld nh ni md lh nj nk mf ll nl nm mh nn bi translated">基本算法</h2><p id="5913" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated"><strong class="kw jg">正常预测值</strong></p><ul class=""><li id="cf16" class="nz oa jf kw b kx ky la lb ld ob lh oc ll od lp oe of og oh bi translated"><code class="fe nw nx ny mt b">NormalPredictor</code>算法根据假设为正态的训练集分布预测随机评分。这是最基本的算法之一，不需要做很多工作。</li></ul><p id="f241" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">仅基线</strong></p><ul class=""><li id="13a0" class="nz oa jf kw b kx ky la lb ld ob lh oc ll od lp oe of og oh bi translated"><code class="fe nw nx ny mt b">BaselineOnly</code>算法预测给定用户和项目的基线估计值。</li></ul><h2 id="f403" class="mx ls jf bd lt nd ne dn lx nf ng dp mb ld nh ni md lh nj nk mf ll nl nm mh nn bi translated">k-NN 算法</h2><p id="edc0" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated"><strong class="kw jg"> KNNBasic </strong></p><ul class=""><li id="6d79" class="nz oa jf kw b kx ky la lb ld ob lh oc ll od lp oe of og oh bi translated"><code class="fe nw nx ny mt b">KNNBasic</code>是一种基本的协同过滤算法。</li></ul><p id="d470" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> KNNWithMeans </strong></p><ul class=""><li id="5ce5" class="nz oa jf kw b kx ky la lb ld ob lh oc ll od lp oe of og oh bi translated"><code class="fe nw nx ny mt b">KNNWithMeans</code>是基本的协同过滤算法，考虑了每个用户的平均评分。</li></ul><p id="94cb" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> KNNWithZScore </strong></p><ul class=""><li id="3706" class="nz oa jf kw b kx ky la lb ld ob lh oc ll od lp oe of og oh bi translated"><code class="fe nw nx ny mt b">KNNWithZScore</code>是一个基本的协同过滤算法，考虑到每个用户的 z-score 归一化。</li></ul><p id="7681" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> KNNBaseline </strong></p><ul class=""><li id="5917" class="nz oa jf kw b kx ky la lb ld ob lh oc ll od lp oe of og oh bi translated"><code class="fe nw nx ny mt b">KNNBaseline</code>是一种考虑基线评级的基本协作过滤算法。</li></ul><h2 id="3150" class="mx ls jf bd lt nd ne dn lx nf ng dp mb ld nh ni md lh nj nk mf ll nl nm mh nn bi translated">基于矩阵分解的算法</h2><p id="2a7b" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated"><strong class="kw jg">奇异值分解</strong></p><ul class=""><li id="b8af" class="nz oa jf kw b kx ky la lb ld ob lh oc ll od lp oe of og oh bi translated"><code class="fe nw nx ny mt b">SVD</code>算法相当于<a class="ae lq" href="http://papers.nips.cc/paper/3208-probabilistic-matrix-factorization.pdf" rel="noopener ugc nofollow" target="_blank">概率矩阵分解</a></li></ul><p id="5d23" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> SVDpp </strong></p><ul class=""><li id="55a8" class="nz oa jf kw b kx ky la lb ld ob lh oc ll od lp oe of og oh bi translated"><code class="fe nw nx ny mt b">SVDpp</code>算法是 SVD 的扩展，它考虑了隐式评级。</li></ul><p id="278e" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg"> NMF </strong></p><ul class=""><li id="6bd0" class="nz oa jf kw b kx ky la lb ld ob lh oc ll od lp oe of og oh bi translated"><code class="fe nw nx ny mt b">NMF</code>是一种基于非负矩阵分解的协同过滤算法。它与奇异值分解非常相似。</li></ul><h2 id="2911" class="mx ls jf bd lt nd ne dn lx nf ng dp mb ld nh ni md lh nj nk mf ll nl nm mh nn bi translated">一号斜坡</h2><ul class=""><li id="261a" class="nz oa jf kw b kx mj la mk ld oi lh oj ll ok lp oe of og oh bi translated"><code class="fe nw nx ny mt b">SlopeOne</code>是<a class="ae lq" href="https://arxiv.org/abs/cs/0702144" rel="noopener ugc nofollow" target="_blank"> SlopeOne 算法</a>的简单实现。</li></ul><h2 id="9e91" class="mx ls jf bd lt nd ne dn lx nf ng dp mb ld nh ni md lh nj nk mf ll nl nm mh nn bi translated">共聚类</h2><ul class=""><li id="233c" class="nz oa jf kw b kx mj la mk ld oi lh oj ll ok lp oe of og oh bi translated"><code class="fe nw nx ny mt b">Coclustering</code>是基于<a class="ae lq" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.6458&amp;rep=rep1&amp;type=pdf" rel="noopener ugc nofollow" target="_blank">协同聚类</a>的协同过滤算法。</li></ul><p id="d68a" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们使用“rmse”作为预测的准确性指标。</p><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="no np l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">benchmark.py</figcaption></figure><figure class="mo mp mq mr gt is gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/311f066e69cab36bab4ded49bc9ac6d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*FXsZ2qM4fUA_82-p4XGaiw.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Figure 8</figcaption></figure><h1 id="ee05" class="lr ls jf bd lt lu lv lw lx ly lz ma mb kl mc km md ko me kp mf kr mg ks mh mi bi translated">训练和预测</h1><p id="b2f3" class="pw-post-body-paragraph ku kv jf kw b kx mj kg kz la mk kj lc ld ml lf lg lh mm lj lk ll mn ln lo lp ij bi translated"><code class="fe nw nx ny mt b">BaselineOnly</code>算法给了我们最好的 rmse，因此，我们将使用<code class="fe nw nx ny mt b">BaselineOnly</code>和交替最小二乘法(ALS)进行训练和预测。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="6ee0" class="mx ls jf mt b gy my mz l na nb">print('Using ALS')<br/>bsl_options = {'method': 'als',<br/>               'n_epochs': 5,<br/>               'reg_u': 12,<br/>               'reg_i': 5<br/>               }<br/>algo = BaselineOnly(bsl_options=bsl_options)<br/>cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=False)</span></pre><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi om"><img src="../Images/1abe6ec3a0cf233b126c8c82072dc33b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_dzaXRoZ78z5So-RymrDTQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Figure 9</figcaption></figure><p id="ece0" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">我们使用<code class="fe nw nx ny mt b">train_test_split()</code>对给定大小的训练集和测试集进行采样，并使用 rmse 的精度度量。然后我们将使用<code class="fe nw nx ny mt b">fit()</code>方法在训练集上训练算法，使用<code class="fe nw nx ny mt b">test()</code>方法从测试集返回预测。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="e53b" class="mx ls jf mt b gy my mz l na nb">trainset, testset = train_test_split(data, test_size=0.25)<br/>algo = BaselineOnly(bsl_options=bsl_options)<br/>predictions = algo.fit(trainset).test(testset)<br/>accuracy.rmse(predictions)</span></pre><figure class="mo mp mq mr gt is gh gi paragraph-image"><div class="gh gi on"><img src="../Images/686b549b30446b9cefab5e41748a96fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*s7AwIVfuWC8LYpVIxQPwKA.png"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Figure 10</figcaption></figure><p id="da98" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">为了详细检查我们的预测，我们将建立一个包含所有预测的熊猫数据框。下面的代码大部分摘自这个<a class="ae lq" href="http://nbviewer.jupyter.org/github/NicolasHug/Surprise/blob/master/examples/notebooks/KNNBasic_analysis.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>。</p><figure class="mo mp mq mr gt is"><div class="bz fp l di"><div class="no np l"/></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">predictions_details.py</figcaption></figure><p id="3703" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">最佳预测</strong>:</p><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi oo"><img src="../Images/a18124b90eba13903314df863388bf29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QQzsp06yKOEXYj05tIVc7A.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Figure 11</figcaption></figure><p id="b20c" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">以上是最好的预测，不是侥幸的猜测。因为 Ui 介于 25 到 146 之间，所以它们并不小，这意味着大量用户对目标图书进行了评级。</p><p id="182f" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated"><strong class="kw jg">最坏的预测</strong>:</p><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi op"><img src="../Images/2cdf1099c1f54287cf7cea7d00b16d00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*omNqnQA37yEZOUmrHurJeQ.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Figure 12</figcaption></figure><p id="8186" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">最糟糕的预测看起来相当令人惊讶。让我们看看最后一个 ISBN“055358264 x”的更多细节。这本书被 47 个用户评分，用户“26544”评分为 10，我们的 BaselineOnly 算法预测该用户评分为 0。</p><pre class="mo mp mq mr gt ms mt mu mv aw mw bi"><span id="21bc" class="mx ls jf mt b gy my mz l na nb">import matplotlib.pyplot as plt<br/>%matplotlib notebook</span><span id="0c0f" class="mx ls jf mt b gy oq mz l na nb">df_new.loc[df_new['ISBN'] == '055358264X']['bookRating'].hist()<br/>plt.xlabel('rating')<br/>plt.ylabel('Number of ratings')<br/>plt.title('Number of ratings book ISBN 055358264X has received')<br/>plt.show();</span></pre><figure class="mo mp mq mr gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi or"><img src="../Images/d3e3a4d8e6143d06a8b446385c3539b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D2UJoF1BiVHm8tBL5LWiHA.png"/></div></div><figcaption class="iz ja gj gh gi jb jc bd b be z dk">Figure 13</figcaption></figure><p id="25b7" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">结果发现，这本书获得的大部分评分是 0，换句话说，数据中的大部分用户给这本书的评分是 0，只有极少数用户给了 10。与“最差预测”列表中的其他预测相同。似乎对于每一个预测，用户都是某种局外人。</p><p id="60a7" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">就是这样！我希望你喜欢这个推荐(或者更确切地说，一个评级预测)之旅。<a class="ae lq" href="https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Building%20Recommender%20System%20with%20Surprise.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter 笔记本</a>可以在<a class="ae lq" href="https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Building%20Recommender%20System%20with%20Surprise.ipynb" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。节日快乐！</p><p id="efbf" class="pw-post-body-paragraph ku kv jf kw b kx ky kg kz la lb kj lc ld le lf lg lh li lj lk ll lm ln lo lp ij bi translated">参考:<a class="ae lq" href="https://surprise.readthedocs.io/en/stable/index.html" rel="noopener ugc nofollow" target="_blank">惊喜’文档</a></p></div></div>    
</body>
</html>