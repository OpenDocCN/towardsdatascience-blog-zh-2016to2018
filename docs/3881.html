<html>
<head>
<title>[ Paper Summary ] Evolutionary design of context-free attentional operators</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">[论文摘要]上下文无关注意算子的进化设计</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/paper-summary-evolutionary-design-of-context-free-attentional-operators-85b0cc2df9cd?source=collection_archive---------11-----------------------#2018-06-27">https://towardsdatascience.com/paper-summary-evolutionary-design-of-context-free-attentional-operators-85b0cc2df9cd?source=collection_archive---------11-----------------------#2018-06-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div class="gh gi jn"><img src="../Images/07a731d673a7662c0f12576eec7f69d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*-p35hHRxBQ9XmvM0fQ9RTw.gif"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">GIF from this <a class="ae jy" href="https://giphy.com/gifs/cat-lasers-laser-pointer-3oEjIacPJYAJubIDLO" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure><p id="5bf6" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">让我们做一个简单的实验，见下图。</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div class="gh gi kx"><img src="../Images/730e4aad3a7237d9b5dd8dd99e1c0426.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/format:webp/1*54WDbEivRN7n6zViLV0ZmA.png"/></div></figure><p id="dcdb" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">你的眼睛最关注哪个区域？蓝色的商店标志还是电话亭？甚至棕色的墙壁。向下滚动一点，我给你看另一张图片……</p><p id="7d78" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">更多</p><p id="db5a" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">更多</p><p id="f68d" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">更多</p><p id="7044" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">更多</p><p id="548b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">更多</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div class="gh gi lc"><img src="../Images/24aa5419486bd239ac57ab4b5fc0dda8.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/1*Qj7P8sByKULEYAxHX95t0w.png"/></div></figure><p id="f0d4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">是你眼睛最关注的圆圈区域吗？对我来说肯定是。我们关注这些地区有什么原因吗？我们能预测人类会最关注哪个区域吗？甚至围绕它开发一个框架？本文提出了一个示例框架。</p></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><figure class="ky kz la lb gt jr"><div class="bz fp l di"><div class="lk ll l"/></div><figcaption class="ju jv gj gh gi jw jx bd b be z dk">Paper from this <a class="ae jy" href="http://www-sop.inria.fr/members/Neil.Bruce/ICIPnbruce.pdf" rel="noopener ugc nofollow" target="_blank">website</a></figcaption></figure></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><p id="ee49" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">摘要</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="gh gi lm"><img src="../Images/63a0d9a329bfd54889aaf581127eb325.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*146WagJpXIlNnuPZio7_Fw.png"/></div></div></figure><p id="1c16" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在这篇论文中，作者介绍了一个模仿灵长类动物视觉注意系统的框架。这个框架不仅考虑了心理物理学方面的原因，也考虑了数学方面的原因。通过应用一组注意力算子，每个图像被转换成表示该图像的感知重要性的图。</p></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><p id="063b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">简介</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="gh gi lr"><img src="../Images/da12e7e557daf0c53fcd2db3d4c0dbec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q2N1yjV4UmNCrWDJUNfi3A.png"/></div></div></figure><p id="1f03" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">当我们看一幅图像，(或一个场景)时，我们认为我们在看一切，但我们真的不是。我们周围的信息中只有很少一部分能真正解释我们的行为。目前，我们有大量的证据支持引导我们视觉注意系统的双组分系统。</p><p id="251f" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir"> 1。自下而上的图元组件</strong> →纯图像刺激<br/> <strong class="kb ir"> 2。自上而下组件</strong> →认知控制</p><p id="83ec" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在本文中，作者将模拟一个自下而上的注意系统。在这个主题上已经有了先前的工作，例如选择性视觉注意力的'<a class="ae jy" href="https://cseweb.ucsd.edu/classes/fa09/cse258a/papers/koch-ullman-1985.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="ls">'转移:朝向潜在的神经回路</em> </a>'或用于定义视觉感兴趣区域的'<a class="ae jy" href="https://ieeexplore.ieee.org/document/877520/" rel="noopener ugc nofollow" target="_blank"> <em class="ls">算法:与眼睛注视</em> </a>的比较。一个有趣的发现是，图像局部中特定特征的强度本身并不能保证人们的注意力会被吸引到该图像区域。例如，如果一幅图像有很大的变化，那么我们将主要关注同质区域，即变化较少的区域。所以换句话说，彼此不同的区域会获得人类更多的关注。最后，虽然有不同的方法来模仿人类的视觉注意机制，但似乎有一个重叠的区域，在那里他们开始从给定的图像中提取较低层次的特征。</p></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><p id="3acf" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">型号</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="gh gi lt"><img src="../Images/6094f6bcf72df282003b20d6c653daaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dG6VyxhiMf8NCsgE6F5L-g.png"/></div></div></figure><p id="56e2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">在本节中，作者描述了该模型的 4 个关键组成部分。</p><ol class=""><li id="b5fc" class="lu lv iq kb b kc kd kg kh kk lw ko lx ks ly kw lz ma mb mc bi translated">RGB 图像被分为强度/色调/方向通道(这是通过应用<a class="ae jy" href="https://en.wikipedia.org/wiki/Gabor_filter" rel="noopener ugc nofollow" target="_blank">方向的 Gabor 滤波器</a>完成的)。)</li><li id="5646" class="lu lv iq kb b kc md kg me kk mf ko mg ks mh kw lz ma mb mc bi translated">非线性滤波运算符，用于响应引起更多关注的信号。(这些滤波器是通过随机搜索由局部范围的<a class="ae jy" href="https://www.researchgate.net/post/how_are_volterra_filters_applied_to_images" rel="noopener ugc nofollow" target="_blank">二次</a>T4】沃尔泰拉滤波器组成的函数空间找到的。)和过滤器的结构可以在下面看到。</li></ol><figure class="ky kz la lb gt jr gh gi paragraph-image"><div class="gh gi mi"><img src="../Images/8ff96a4ab1a7cedc587101b910a4c4b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*ol3bomDth83tqm10T2uB3Q.png"/></div></figure><p id="15b1" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">其中 S 代表滤波器起作用的区域。h 的参数通过遗传算法优化确定。看到成本函数</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div class="gh gi mj"><img src="../Images/c48dbebbfcd3521e89665d2b64cea4f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*5OP6zfX3J1GSJgmraHSa0Q.png"/></div></figure><p id="c8c2" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">SI → <a class="ae jy" href="https://en.wikipedia.org/wiki/Self-information" rel="noopener ugc nofollow" target="_blank">香农自我信息测度</a> <br/> D →图像 I 对应的实验密度图</p><p id="a4ee" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">3.信息操作者接受高级特征，并将其放入更准确地反映人类视觉系统可能预期的响应的域中。</p><p id="8362" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">4.将每个通道的平均运算转换为一个单一输出。</p><p id="0e8c" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这种架构不同于其他架构的原因是 1)定制过滤器的训练和 2)包含信息操作符。</p></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><p id="d6a0" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">结果</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div class="gh gi mk"><img src="../Images/a2da822c06da753c0e011583e95b3003.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*L_Ua-AaNVHUcIPtABlqrsQ.png"/></div></figure><p id="f354" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如上所述，我们可以看到该模型运行良好，并对人类可能最关注的地方做出了很好的预测。黄色圆圈代表置信度最高的地方，下面是不同图像的结果。</p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="gh gi ml"><img src="../Images/3e7280002a8d8a2c23ddbdd20502363d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LnCg2IO0vjhaOv5VK9HYZA.png"/></div></div></figure></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><p id="cea4" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">讨论</strong></p><figure class="ky kz la lb gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="gh gi mm"><img src="../Images/12f97360462c32f6dcad85b4ded49ccd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_dqtoKUQYcG_7AX0HK2zjw.png"/></div></div></figure><p id="3f5b" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这篇论文的作者能够成功地创建一个模仿人类视觉注意系统的模型。</p></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><p id="76f7" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">最后的话</strong></p><p id="1620" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">这篇论文令人印象深刻的一点是，这篇论文发表于 2003 年，当时深度学习甚至还不存在。但是如果你观察这个模型，你会发现它非常像一个卷积神经网络。</p><p id="bc89" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">如果发现任何错误，请发电子邮件到 jae.duk.seo@gmail.com 给我，如果你想看我所有写作的列表，请在这里查看我的网站。</p><p id="ccc9" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated">同时，在我的 twitter 上关注我<a class="ae jy" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>，访问<a class="ae jy" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或者我的<a class="ae jy" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube 频道</a>了解更多内容。我还实现了<a class="ae jy" href="https://medium.com/@SeoJaeDuk/wide-residual-networks-with-interactive-code-5e190f8f25ec" rel="noopener">广残网，请点击这里查看博文</a> t。</p></div><div class="ab cl ld le hu lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ij ik il im in"><p id="a7b8" class="pw-post-body-paragraph jz ka iq kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw ij bi translated"><strong class="kb ir">参考</strong></p><ol class=""><li id="d0be" class="lu lv iq kb b kc kd kg kh kk lw ko lx ks ly kw lz ma mb mc bi translated">(2018).Www-sop.inria.fr .于 2018 年 6 月 26 日检索，来自<a class="ae jy" href="http://www-sop.inria.fr/members/Neil.Bruce/ICIPnbruce.pdf" rel="noopener ugc nofollow" target="_blank">http://www-sop.inria.fr/members/Neil.Bruce/ICIPnbruce.pdf</a></li><li id="e37f" class="lu lv iq kb b kc md kg me kk mf ko mg ks mh kw lz ma mb mc bi translated">(2018).Cseweb.ucsd.edu。检索于 2018 年 6 月 27 日，来自<a class="ae jy" href="https://cseweb.ucsd.edu/classes/fa09/cse258a/papers/koch-ullman-1985.pdf" rel="noopener ugc nofollow" target="_blank">https://CSE web . ucsd . edu/classes/fa09/CSE 258 a/papers/Koch-ull man-1985 . pdf</a></li><li id="161b" class="lu lv iq kb b kc md kg me kk mf ko mg ks mh kw lz ma mb mc bi translated">Gabor 滤波器。(2018).En.wikipedia.org。检索于 2018 年 6 月 27 日，来自<a class="ae jy" href="https://en.wikipedia.org/wiki/Gabor_filter" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Gabor_filter</a></li><li id="8fe9" class="lu lv iq kb b kc md kg me kk mf ko mg ks mh kw lz ma mb mc bi translated">5 个非线性滤波器。(2018).Dspalgorithms.com。检索于 2018 年 6 月 27 日，来自<a class="ae jy" href="https://www.dspalgorithms.com/aspt/asptnode24.html" rel="noopener ugc nofollow" target="_blank">https://www.dspalgorithms.com/aspt/asptnode24.html</a></li><li id="9120" class="lu lv iq kb b kc md kg me kk mf ko mg ks mh kw lz ma mb mc bi translated">(2018).[在线]见:<a class="ae jy" href="https://www.researchgate.net/post/how_are_volterra_filters_applied_to_images" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/post/how _ are _ Volterra _ filters _ applied _ to _ images</a>【2018 年 6 月 27 日访问】。</li><li id="7169" class="lu lv iq kb b kc md kg me kk mf ko mg ks mh kw lz ma mb mc bi translated">自我信息。(2018).En.wikipedia.org。检索于 2018 年 6 月 27 日，来自<a class="ae jy" href="https://en.wikipedia.org/wiki/Self-information" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Self-information</a></li></ol></div></div>    
</body>
</html>