<html>
<head>
<title>Linear Regression in Python; Predict The Bay Area’s Home Prices</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python 中的线性回归；预测湾区的房价</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878?source=collection_archive---------0-----------------------#2017-10-25">https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878?source=collection_archive---------0-----------------------#2017-10-25</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/5d3f1c83af4892324cc91ecaf9fd3d70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c35fClNox4OebSmnCNZFKg.jpeg"/></div></div></figure><h1 id="faaa" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">动机</h1><p id="25dd" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">为了预测湾区的房价，我选择了来自<a class="ae lu" href="http://www.sfgate.com/webdb/homesales/" rel="noopener ugc nofollow" target="_blank">湾区房屋销售数据库</a>和<a class="ae lu" href="https://www.zillow.com/san-francisco-ca/home-values/" rel="noopener ugc nofollow" target="_blank"> Zillow </a>的房价数据集。该数据集基于 2013 年 1 月至 2015 年 12 月期间售出的房屋。它有很多学习的特点，数据集可以从<a class="ae lu" href="https://raw.githubusercontent.com/RuiChang123/Regression_for_house_price_estimation/master/final_data.csv" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><h1 id="ea5a" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">数据预处理</h1><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="d129" class="me jz iq ma b gy mf mg l mh mi">import pandas as pd<br/>sf = pd.read_csv('final_data.csv')<br/>sf.head()</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mj"><img src="../Images/f4a16f86154143a8af493cdde0def95a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VjoTlFg5qUPDaB5DZy_KSw.png"/></div></div></figure><p id="12f3" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">有几个功能是我们不需要的，比如“info”、“z_address”、“zipcode”(我们有“neighborhood”作为位置变量)、“zipid”和“zestimate”(这是<a class="ae lu" href="https://www.zillow.com/how-much-is-my-home-worth/" rel="noopener ugc nofollow" target="_blank"> Zillow </a>估算的价格，我们不希望我们的模型受此影响)，所以，我们将放弃它们。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="117f" class="me jz iq ma b gy mf mg l mh mi">sf.drop(sf.columns[[0, 2, 3, 15, 17, 18]], axis=1, inplace=True)</span><span id="e813" class="me jz iq ma b gy mp mg l mh mi">sf.info()</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/26cd03a6906cbfe16f0ad691ec9ec8d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*cS3kf6rsZKkTRTXfOH9fSA.png"/></div></figure><p id="b835" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">“zindexvalue”的数据类型应该是数字，所以让我们更改一下。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="ee99" class="me jz iq ma b gy mf mg l mh mi">sf['zindexvalue'] = sf['zindexvalue'].str.replace(',', '')<br/>sf['zindexvalue'] = sf['zindexvalue'].convert_objects(convert_numeric=True)</span><span id="270f" class="me jz iq ma b gy mp mg l mh mi">sf.lastsolddate.min(), sf.lastsolddate.max()</span></pre><p id="dfac" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="ky ir"> <em class="mr"> ('01/02/2013 '，' 12/31/2015') </em> </strong></p><p id="bbbb" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">日期集中的房屋出售时间在 2013 年 1 月至 2015 年 12 月之间。</p><p id="f28b" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">我现在使用 describe()方法来显示数字变量的汇总统计信息。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="6de0" class="me jz iq ma b gy mf mg l mh mi">sf.describe()</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ms"><img src="../Images/565ba8a486c8a8b2206c07726f5e2b8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1eVNHB5y-y6AhBcVsBUujw.png"/></div></div></figure><p id="6dea" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">计数、平均值、最小值和最大值行是不言自明的。std 显示标准偏差，25%、50%和 75%的行显示相应的百分位数。</p><p id="259d" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">为了了解我们正在处理的数据类型，我们为每个数字变量绘制了一个直方图。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="c83c" class="me jz iq ma b gy mf mg l mh mi">%matplotlib inline<br/>import matplotlib.pyplot as plt<br/>sf.hist(bins=50, figsize=(20,15))<br/>plt.savefig("attribute_histogram_plots")<br/>plt.show()</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi mt"><img src="../Images/40508e6e54dd43ee30a8a0fc0faaecd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gGa7NdAyRTpOYMZKmEi3tA.png"/></div></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk">Figure 1. <em class="my">A histogram for each numerical variable</em></figcaption></figure><p id="ba3b" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">一些直方图有点向右倾斜，但这并不异常。</p><p id="b244" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">让我们创建一个带有纬度和经度的散点图来可视化数据:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="147f" class="me jz iq ma b gy mf mg l mh mi">sf.plot(kind="scatter", x="longitude", y="latitude", alpha=0.2)<br/>plt.savefig('map1.png')</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/d6a3bb081d871ca5100525588cd37541.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*dSi7yIjC90ahX_JGzvl-3A.png"/></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk">Figure 2. A scatter plot of the data</figcaption></figure><p id="ef49" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">现在让我们从最贵到最便宜的区域进行颜色编码:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="1bfe" class="me jz iq ma b gy mf mg l mh mi">sf.plot(kind="scatter", x="longitude", y="latitude", alpha=0.4, figsize=(10,7),<br/>    c="lastsoldprice", cmap=plt.get_cmap("jet"), colorbar=True,<br/>    sharex=False)</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi na"><img src="../Images/28f2abc92ef108d660ddfecdc5bce9d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CIa5y6-EKIVB47yzKOW3Zw.png"/></div></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk">Figure 3. The Bay Area housing prices</figcaption></figure><p id="ddc9" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">这张图片告诉我们，最贵的房子是在北部地区。</p><p id="55bf" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">我们要预测的变量是“最后成交价格”。所以我们来看看每个自变量和这个因变量的相关程度。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="e80e" class="me jz iq ma b gy mf mg l mh mi">corr_matrix = sf.corr()<br/>corr_matrix["lastsoldprice"].sort_values(ascending=False)</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/fa4926cf65c097aaead2074e93225924.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/format:webp/1*oD24mEdgaOby4a-w31zJbw.png"/></div></figure><p id="735e" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">当完工面积和浴室数量增加时，最终售价往往会上升。你可以看到建造年份和上一次销售价格之间有一个小的负相关。最后，接近零的系数表示没有线性相关性。</p><p id="663d" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">我们现在将使用 Pandas 的<code class="fe nc nd ne ma b">scatter_matrix</code>函数来可视化变量之间的相关性。我们将只关注几个有希望的变量，它们似乎与最后的销售价格最相关。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="ac55" class="me jz iq ma b gy mf mg l mh mi">from pandas.tools.plotting import scatter_matrix</span><span id="1ddb" class="me jz iq ma b gy mp mg l mh mi">attributes = ["lastsoldprice", "finishedsqft", "bathrooms", "zindexvalue"]<br/>scatter_matrix(sf[attributes], figsize=(12, 8))<br/>plt.savefig('matrix.png')</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nf"><img src="../Images/50af5f88890788d89767b3b96fd4e730.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Evexl1o2Z5pvpKp3TUK2g.png"/></div></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk">Figure 4. a scatter matrix</figcaption></figure><p id="74ee" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">预测最后销售价格的最有希望的变量是完成的平方英尺，所以让我们放大它们的相关散点图。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="95ac" class="me jz iq ma b gy mf mg l mh mi">sf.plot(kind="scatter", x="finishedsqft", y="lastsoldprice", alpha=0.5)<br/>plt.savefig('scatter.png')</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/d5172bcb08a999d86471113043f47b89.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*mRPjnt1G9oIosOkRb1mMOA.png"/></div><figcaption class="mu mv gj gh gi mw mx bd b be z dk">Figure 5. Finished sqft vs. Last Sold Price</figcaption></figure><p id="51ac" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">相关性确实很强；你可以清楚地看到上升的趋势，而且这些点不是太分散。</p><p id="a46c" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">因为每个房子有不同的平方英尺，每个社区有不同的房价，我们真正需要的是每平方英尺的价格。于是，我们添加了一个新的变量“price_per_sqft”。然后，我们检查这个新的独立变量与最后销售价格的相关性。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="b3d1" class="me jz iq ma b gy mf mg l mh mi">sf['price_per_sqft'] = sf['lastsoldprice']/sf['finishedsqft']<br/>corr_matrix = sf.corr()<br/>corr_matrix["lastsoldprice"].sort_values(ascending=False)</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/c66d43fbac120b07237e3286610d3f85.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*EvaJgdF5crJCCnsKRu1xzg.png"/></div></figure><p id="e986" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">不幸的是，新的 price_per_sqft 变量只显示了与最后销售价格非常小的正相关性。但是我们仍然需要这个变量来对邻居进行分组。</p><p id="c18f" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">数据里有 71 个小区，我们准备分组。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="e49e" class="me jz iq ma b gy mf mg l mh mi">len(sf['neighborhood'].value_counts())</span></pre><p id="30ea" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="ky ir"> <em class="mr"> 71 </em> </strong></p><p id="43f9" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">以下步骤将邻域聚类成三组:1 .价格低；2.高价低频；3.高价高频。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="bbd4" class="me jz iq ma b gy mf mg l mh mi">freq = sf.groupby('neighborhood').count()['address']<br/>mean = sf.groupby('neighborhood').mean()['price_per_sqft']<br/>cluster = pd.concat([freq, mean], axis=1)<br/>cluster['neighborhood'] = cluster.index</span><span id="0503" class="me jz iq ma b gy mp mg l mh mi">cluster.columns = ['freq', 'price_per_sqft','neighborhood']</span><span id="d61d" class="me jz iq ma b gy mp mg l mh mi">cluster.describe()</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/1796c221abcd10fb040aa34f60b390ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/format:webp/1*qlTsi1ROEwvKF6NuI8h7Pg.png"/></div></figure><p id="8970" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">这些是低价格社区:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="89a2" class="me jz iq ma b gy mf mg l mh mi">cluster1 = cluster[cluster.price_per_sqft &lt; 756]<br/>cluster1.index</span></pre><p id="da7d" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="ky ir"> <em class="mr">索引(【‘湾景’，‘中央里士满’，‘中央日落’，‘克罗克亚马逊’，<br/>‘戴利市’，‘钻石高地’，‘精益求精’，‘森林山’，<br/>‘森林山延伸’，‘金门高地’，‘英格莱赛德’，‘英格莱赛德高地’，‘英格莱赛德露台’，‘内公园边’，<br/>‘内里士满’，‘内日落’，‘湖岸’，‘小好莱坞’，<br/>‘默塞德高地’，‘米申台’，‘戴维森山庄园’，<br/>‘海景’，‘外宣’，‘外</em></strong></p><p id="138c" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">这些是高价格和低频率的社区:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="f277" class="me jz iq ma b gy mf mg l mh mi">cluster_temp = cluster[cluster.price_per_sqft &gt;= 756]<br/>cluster2 = cluster_temp[cluster_temp.freq &lt;123]<br/>cluster2.index</span></pre><p id="dab3" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="ky ir"> <em class="mr">索引(['布埃纳维斯塔公园'，'中央滨水区—多克帕奇'，'科罗纳高地'，'海特—阿什伯里'，'湖边'，'孤山'，'中城露台'，<br/>'北海滩'，'北部滨水区'，'帕纳萨斯—阿什伯里'，'普雷斯迪奥高地'，'海崖'，'圣弗朗西斯伍德'，'电报山'，'双峰']，dtype='object '，name='neighborhood') </em> </strong></p><p id="e7a4" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">这些是高价格和高频率的社区:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="1337" class="me jz iq ma b gy mf mg l mh mi">cluster3 = cluster_temp[cluster_temp.freq &gt;=123]<br/>cluster3.index</span></pre><p id="c0b1" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="ky ir"> <em class="mr">索引(['Bernal Heights '，' Cow Hollow '，' Downtown '，' Eureka Valley-Dolores Heights-Castro '，' Glen Park '，' Hayes Valley '，' Lake '，' Lower Pacific Heights '，' Marina '，' Miraloma Park '，' Mission '，' Nob Hill '，' Noe Valley '，' North Panhandle '，' Pacific Heights '，' Potrero Hill '，' Russian Hill '，' South Beach '，' South ' Market '，' Van Ness-civice centre '，' Yerba</em></strong></p><p id="19b6" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">我们根据集群添加一个组列:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="00ba" class="me jz iq ma b gy mf mg l mh mi">def get_group(x):<br/>    if x in cluster1.index:<br/>        return 'low_price'<br/>    elif x in cluster2.index:<br/>        return 'high_price_low_freq'<br/>    else:<br/>        return 'high_price_high_freq'<br/>sf['group'] = sf.neighborhood.apply(get_group)</span></pre><p id="c801" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">在执行上述预处理后，我们不再需要以下列:“address，lastsolddate，latitude，longitude，neighborhood，price_per_sqft”，因此，我们从分析中删除它们。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="aa32" class="me jz iq ma b gy mf mg l mh mi">sf.drop(sf.columns[[0, 4, 6, 7, 8, 13]], axis=1, inplace=True)<br/>sf = sf[['bathrooms', 'bedrooms', 'finishedsqft', 'totalrooms', 'usecode', 'yearbuilt','zindexvalue', 'group', 'lastsoldprice']]<br/>sf.head()</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi ni"><img src="../Images/1ffa122e78bb40a318ae8dad84c01bcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MPMF1NM1b856Lsp31MBE9A.png"/></div></div></figure><p id="5b6e" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">我们的数据看起来很完美！</p><p id="63a9" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">但是在构建模型之前，我们需要为这两个分类变量创建虚拟变量:“usecode”和“group”。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="c92c" class="me jz iq ma b gy mf mg l mh mi">X = sf[['bathrooms', 'bedrooms', 'finishedsqft', 'totalrooms', 'usecode', 'yearbuilt', <br/>         'zindexvalue', 'group']]<br/>Y = sf['lastsoldprice']<br/><br/>n = pd.get_dummies(sf.group)<br/>X = pd.concat([X, n], axis=1)</span><span id="8422" class="me jz iq ma b gy mp mg l mh mi">m = pd.get_dummies(sf.usecode)<br/>X = pd.concat([X, m], axis=1)</span><span id="b7ad" class="me jz iq ma b gy mp mg l mh mi">drops = ['group', 'usecode']<br/>X.drop(drops, inplace=True, axis=1)</span><span id="ea3b" class="me jz iq ma b gy mp mg l mh mi">X.head()</span></pre><p id="d1df" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">这是我们的数据在创建虚拟变量后的样子:</p><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi nj"><img src="../Images/8cc31bf26f8e7a75812b232208de946f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7kJQlEFwuBA6IPcGHBdDyQ.png"/></div></div></figure><h1 id="984b" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">训练并建立线性回归模型</h1><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="a358" class="me jz iq ma b gy mf mg l mh mi">from sklearn.cross_validation import train_test_split</span><span id="21dc" class="me jz iq ma b gy mp mg l mh mi">X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)</span><span id="48ec" class="me jz iq ma b gy mp mg l mh mi">from sklearn.linear_model import LinearRegression<br/>regressor = LinearRegression()<br/>regressor.fit(X_train, y_train)</span></pre><p id="cb2a" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="ky ir"><em class="mr"/></strong></p><p id="1a6a" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">搞定了。我们现在有一个工作的线性回归模型。</p><p id="b261" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">计算 R 的平方:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="01b0" class="me jz iq ma b gy mf mg l mh mi">y_pred = regressor.predict(X_test)<br/>print('Linear Regression R squared": %.4f' % regressor.score(X_test, y_test))</span></pre><p id="9d73" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="ky ir"> <em class="mr">线性回归 R 的平方:0.5619 </em> </strong></p><p id="b58a" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">因此，在我们的模型中，Y 的 56.19%的可变性可以用 x 来解释。这并不令人兴奋。</p><p id="f5e0" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">计算均方根误差(RMSE)</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="2e18" class="me jz iq ma b gy mf mg l mh mi">import numpy as np<br/>from sklearn.metrics import mean_squared_error<br/>lin_mse = mean_squared_error(y_pred, y_test)<br/>lin_rmse = np.sqrt(lin_mse)<br/>print('Linear Regression RMSE: %.4f' % lin_rmse)</span></pre><p id="3e0f" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="ky ir"> <em class="mr">线性回归 RMSE: 616071.5748 </em> </strong></p><p id="2176" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">我们的模型能够预测测试集中每栋房子的价格，误差在 616071 美元以内。</p><p id="607a" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">计算平均绝对误差(MAE):</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="6b2f" class="me jz iq ma b gy mf mg l mh mi">from sklearn.metrics import mean_absolute_error</span><span id="813d" class="me jz iq ma b gy mp mg l mh mi">lin_mae = mean_absolute_error(y_pred, y_test)<br/>print('Linear Regression MAE: %.4f' % lin_mae)</span></pre><p id="6a56" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="ky ir"> <em class="mr">线性回归 MAE: 363742.1631 </em> </strong></p><h1 id="4cb3" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">随机森林</h1><p id="5007" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">让我们尝试一个更复杂的模型，看看结果是否可以改进 RandomForestRegressor:</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="3dad" class="me jz iq ma b gy mf mg l mh mi">from sklearn.ensemble import RandomForestRegressor</span><span id="d4f9" class="me jz iq ma b gy mp mg l mh mi">forest_reg = RandomForestRegressor(random_state=42)<br/>forest_reg.fit(X_train, y_train)</span></pre><p id="ca07" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="ky ir"><em class="mr">RandomForestRegressor(bootstrap = True，criterion='mse '，max_depth=None，max_features='auto '，max_leaf_nodes=None，<br/>min _ infinity _ split = 1e-07，min_samples_leaf=1，<br/> min_samples_split=2，min_weight_fraction_leaf=0.0，<br/> n_estimators=10，n_jobs=1，oob_score=False，random_state=42，<br/>详细</em></strong></p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="b1ea" class="me jz iq ma b gy mf mg l mh mi">print('Random Forest R squared": %.4f' % forest_reg.score(X_test, y_test))</span></pre><p id="b018" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="ky ir"> <em class="mr">随机森林 R 的平方】:0.6491 </em> </strong></p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="9b1c" class="me jz iq ma b gy mf mg l mh mi">y_pred = forest_reg.predict(X_test)<br/>forest_mse = mean_squared_error(y_pred, y_test)<br/>forest_rmse = np.sqrt(forest_mse)<br/>print('Random Forest RMSE: %.4f' % forest_rmse)</span></pre><p id="a5b0" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="ky ir"> <em class="mr">随机森林 RMSE: 551406.0926 </em> </strong></p><p id="ed0b" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">好多了！让我们再试一次。</p><h1 id="104a" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">梯度推进</h1><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="f169" class="me jz iq ma b gy mf mg l mh mi">from sklearn import ensemble<br/>from sklearn.ensemble import GradientBoostingRegressor<br/>model = ensemble.GradientBoostingRegressor()<br/>model.fit(X_train, y_train)</span></pre><p id="5836" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="ky ir"><em class="mr">GradientBoostingRegressor(alpha = 0.9，criterion='friedman_mse '，init=None，learning_rate=0.1，loss='ls '，max_depth=3，max_features=None，max_leaf_nodes=None，min _ infinity _ split = 1e-07，<br/> min_samples_leaf=1，min_samples_split=2，min_weight_fraction_leaf=0.0，n _ estimators = 100，预排序='auto '，random_state</em></strong></p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="fd4f" class="me jz iq ma b gy mf mg l mh mi">print('Gradient Boosting R squared": %.4f' % model.score(X_test, y_test))</span></pre><p id="5434" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="ky ir"> <em class="mr">梯度增强 R 的平方】:0.6616 </em> </strong></p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="a222" class="me jz iq ma b gy mf mg l mh mi">y_pred = model.predict(X_test)<br/>model_mse = mean_squared_error(y_pred, y_test)<br/>model_rmse = np.sqrt(model_mse)<br/>print('Gradient Boosting RMSE: %.4f' % model_rmse)</span></pre><p id="b254" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated"><strong class="ky ir"> <em class="mr">渐变助推 RMSE: 541503.7962 </em> </strong></p><p id="3b09" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">这是我们迄今为止最好的结果，所以，我认为这是我们的最终模型。</p><h2 id="f030" class="me jz iq bd ka nk nl dn ke nm nn dp ki lh no np km ll nq nr kq lp ns nt ku nu bi translated">特征重要性</h2><p id="ef2c" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">我们在模型中使用了 19 个特征(变量)。让我们找出哪些特性是重要的，反之亦然。</p><pre class="lv lw lx ly gt lz ma mb mc aw md bi"><span id="7330" class="me jz iq ma b gy mf mg l mh mi">feature_labels = np.array(['bathrooms', 'bedrooms', 'finishedsqft', 'totalrooms', 'yearbuilt', 'zindexvalue', <br/>                           'high_price_high_freq', 'high_price_low_freq', 'low_price', 'Apartment', 'Condominium', 'Cooperative', <br/>                          'Duplex', 'Miscellaneous', 'Mobile', 'MultiFamily2To4', 'MultiFamily5Plus', 'SingleFamily', <br/>                           'Townhouse'])<br/>importance = model.feature_importances_<br/>feature_indexes_by_importance = importance.argsort()<br/>for index in feature_indexes_by_importance:<br/>    print('{}-{:.2f}%'.format(feature_labels[index], (importance[index] *100.0)))</span></pre><figure class="lv lw lx ly gt jr gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/8d046d9f072a8ba3a88c7376e7df83c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*l9c26_1mvbPrdbmiZS4VBQ.png"/></div></figure><p id="c495" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">最重要的特征是完工面积、zindex 值、浴室数量、总房间数、建造年份等等。最不重要的特征是公寓，这意味着不管这个单元是否是公寓，对出售价格都无关紧要。总的来说，这 19 个特性大部分都用上了。</p><h1 id="aaf0" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">轮到你了！</h1><p id="b233" class="pw-post-body-paragraph kw kx iq ky b kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt ij bi translated">希望这篇文章能让你对机器学习回归项目有一个好的了解。正如你所看到的，大部分工作都在数据争论和准备步骤中，这些程序消耗了花在机器学习上的大部分时间。</p><p id="f99c" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">现在是时候走出去，开始探索和清理您的数据了。尝试两三个算法，然后告诉我进展如何。</p><p id="3585" class="pw-post-body-paragraph kw kx iq ky b kz mk lb lc ld ml lf lg lh mm lj lk ll mn ln lo lp mo lr ls lt ij bi translated">创建这篇文章的源代码可以在<a class="ae lu" href="https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Predict_Bay_Area_Home_Price.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。我将很高兴收到关于上述任何反馈或问题。</p></div></div>    
</body>
</html>