<html>
<head>
<title>Can python be used for Facebook chat backup? of course, it can!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">python 可以用于脸书聊天备份吗？当然可以！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/can-python-be-used-for-facebook-chat-backup-of-course-it-can-877226b57ac8?source=collection_archive---------14-----------------------#2018-12-14">https://towardsdatascience.com/can-python-be-used-for-facebook-chat-backup-of-course-it-can-877226b57ac8?source=collection_archive---------14-----------------------#2018-12-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="c43b" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">Web 抓取和 Scrapy 框架的简单演练</h2></div></div><div class="ab cl kf kg hu kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="ij ik il im in"><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="gh gi km"><img src="../Images/39131d32d9e763ebe0c1a76f1be965bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*F5uxDBatPMG_21OX"/></div></div><figcaption class="ky kz gj gh gi la lb bd b be z dk">Photo by <a class="ae lc" href="https://unsplash.com/@glencarrie?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Glen Carrie</a> on <a class="ae lc" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="79a7" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">你好世界！！我们中的大多数人都会有这样的情况，我们必须滚动浏览我们在脸书的对话，以回忆事情，重温时刻或开怀大笑我们的旧对话，你经常这样做，希望有一个备份，这是给你的。在文章的最后，你可以用 csv 或 json 格式的结构化方式备份你的对话。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi lz"><img src="../Images/61df89ed0b0814946545a3133b3fdbe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*1Q-4gi06KnHf0ilqINGDrg.jpeg"/></div></figure><h1 id="1a1b" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">放弃</h1><p id="7b6c" class="pw-post-body-paragraph ld le iq lf b lg ms jr li lj mt ju ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">这篇文章不是为像<strong class="lf ir"> <em class="mx">【鲍勃】</em> </strong>这样的人写的。抱歉<strong class="lf ir"> <em class="mx">鲍勃</em> </strong>，如果这以任何方式冒犯了你！！</p><h1 id="525e" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">为什么？？怎么会？？</h1><p id="a4f2" class="pw-post-body-paragraph ld le iq lf b lg ms jr li lj mt ju ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">在继续之前，我想回答几个你在阅读这篇文章时可能会想到的问题。</p><ol class=""><li id="40a6" class="my mz iq lf b lg lh lj lk lm na lq nb lu nc ly nd ne nf ng bi translated">为什么要这么做！因为我们可以。😎</li><li id="efe3" class="my mz iq lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated">为什么我们不点击<em class="mx">加载更多</em>/向上滚动几个小时到达我们希望阅读的对话！，每次都要滚动对话，超级无聊。</li><li id="7454" class="my mz iq lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated">为什么我们不能使用脸书的默认数据备份功能！，我们不能得到全部的内容，有一个上限。</li><li id="4a15" class="my mz iq lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated">为什么是 python！，它是一种广泛用于网络抓取的语言，拥有许多有用的库，如 scrapy，request。<strong class="lf ir"><em class="mx">#还是我熟悉的那个！！</em>:-)</strong></li><li id="aa4b" class="my mz iq lf b lg nh lj ni lm nj lq nk lu nl ly nd ne nf ng bi translated">为什么刺儿头！，这是一个相当全面和易于使用的数据抓取库，当遇到困难时，它有一个活跃的社区帮助！</li></ol><h1 id="0768" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">安装/设置</h1><p id="5728" class="pw-post-body-paragraph ld le iq lf b lg ms jr li lj mt ju ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">Python 安装:Windows 安装文件 zip 可以在<a class="ae lc" href="https://www.python.org/downloads/windows/" rel="noopener ugc nofollow" target="_blank">这里找到</a>，Ubuntu 运行命令</p><blockquote class="nm nn no"><p id="e91e" class="ld le mx lf b lg lh jr li lj lk ju ll np ln lo lp nq lr ls lt nr lv lw lx ly ij bi translated">sudo apt-get 安装 python3</p></blockquote><p id="0ce9" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">零碎安装:在 Windows 和 Ubuntu 上，运行下面的命令</p><blockquote class="nm nn no"><p id="e31c" class="ld le mx lf b lg lh jr li lj lk ju ll np ln lo lp nq lr ls lt nr lv lw lx ly ij bi translated">pip 安装废料</p></blockquote><h1 id="2746" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">事情是怎么做的！</h1><p id="ba14" class="pw-post-body-paragraph ld le iq lf b lg ms jr li lj mt ju ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">如果你还没有进入如何刮是如何完成的，你可以跳到"<strong class="lf ir"> <em class="mx">如何使用"</em> </strong>部分。</p><p id="8515" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在深入到编码部分之前，在技术方面存在挑战，比如访问脸书数据、处理 javascript 和 ajax 调用。通过请求库重新创建相同的 ajax 调用是一件非常令人头疼的事情，但却失败得很惨。</p><p id="4290" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">然后，我试着用工具<strong class="lf ir">【硒】</strong>刮数据。如果您对此不熟悉，Selenium 可以用于自动化您在浏览器上的活动，允许您像人类一样控制和使用您的浏览器(如单击搜索框、输入关键字和单击搜索按钮)。</p><p id="69b4" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我的 Selenium 所做的是:进入 Facebook.com-&gt;登录-&gt;进入聊天列表并选择一个对话-&gt;向上滚动时开始抓取。脸书拒绝在几页之内从他们的服务器访问更多的数据！！是的，他们擅长检测机器人。</p><p id="6c54" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">花了几个小时在谷歌上搜索后，找到了尝试“移动优化网站”的建议，它实际上是一个不使用任何 AJAX 的老派网站<a class="ae lc" href="http://mobile.facebook.com" rel="noopener ugc nofollow" target="_blank">mobile.facebook.com</a>。终于！！能够使用<strong class="lf ir"> scrapy </strong>不间断地获取数据。</p><h2 id="1887" class="ns mb iq bd mc nt nu dn mg nv nw dp mk lm nx ny mm lq nz oa mo lu ob oc mq od bi translated">入门指南</h2><p id="0557" class="pw-post-body-paragraph ld le iq lf b lg ms jr li lj mt ju ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">在你开始刮之前，你必须建立一个新的刮项目。输入您想要存储代码并运行的目录</p><blockquote class="nm nn no"><p id="af27" class="ld le mx lf b lg lh jr li lj lk ju ll np ln lo lp nq lr ls lt nr lv lw lx ly ij bi translated">scrapy startproject facebook</p></blockquote><p id="89db" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">这将创建一个包含以下内容的<code class="fe oe of og oh b">facebook</code>目录:</p><pre class="kn ko kp kq gt oi oh oj ok aw ol bi"><span id="27ab" class="ns mb iq oh b gy om on l oo op">facebook/<br/>    scrapy.cfg            <em class="mx"># deploy configuration file</em></span><span id="ccf3" class="ns mb iq oh b gy oq on l oo op">    facebook/             <em class="mx"># project's Python module, you'll import your code from here</em><br/>        __init__.py</span><span id="3c87" class="ns mb iq oh b gy oq on l oo op">        items.py          <em class="mx"># project items definition file</em></span><span id="609d" class="ns mb iq oh b gy oq on l oo op">        middlewares.py    <em class="mx"># project middlewares file</em></span><span id="caf4" class="ns mb iq oh b gy oq on l oo op">        pipelines.py      <em class="mx"># project pipelines file</em></span><span id="ceb1" class="ns mb iq oh b gy oq on l oo op">        settings.py       <em class="mx"># project settings file</em></span><span id="18dd" class="ns mb iq oh b gy oq on l oo op">        spiders/          <em class="mx"># a directory where you'll later put your spiders</em><br/>            __init__.py</span></pre><p id="a1bf" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">如果你没有得到，不要担心发生了什么，我们不会担心他们中的大多数人，我们唯一的改变是写一个<strong class="lf ir"> <em class="mx">蜘蛛</em> </strong>抓取内容，并改变<em class="mx">ROBOTSTXT _ observe = False</em><em class="mx">在</em> settings.py 文件中脸书不允许僵尸程序登录。你可以在这里了解更多关于 robots.txt <a class="ae lc" href="http://www.robotstxt.org/robotstxt.html" rel="noopener ugc nofollow" target="_blank">。</a></p><h2 id="0a2d" class="ns mb iq bd mc nt nu dn mg nv nw dp mk lm nx ny mm lq nz oa mo lu ob oc mq od bi translated">让我们建造我们的蜘蛛</h2><p id="1a46" class="pw-post-body-paragraph ld le iq lf b lg ms jr li lj mt ju ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">在 spiders 目录下创建一个 python 文件，然后导入 scrapy、pandas 和 FormRequest，我们将使用它们来提供登录凭证。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="or os l"/></div></figure><p id="19e2" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">这里<em class="mx"> fb_text </em>是我们的蜘蛛的名字，我们可以在我们的蜘蛛目录下写任意数量的蜘蛛，它们可能服务于不同的目的，在我们的例子中，我们可以写一个用于抓取帖子和评论等。每个蜘蛛都应该有自己独特的名字。</p><p id="7ba5" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">然后我们通过终端获取登录凭证，在那里我们将运行我们的蜘蛛</p><blockquote class="nm nn no"><p id="934c" class="ld le mx lf b lg lh jr li lj lk ju ll np ln lo lp nq lr ls lt nr lv lw lx ly ij bi translated">scrapy crawl fb_text -a email="FB 用户电子邮件"-a password="FB 用户密码"</p></blockquote><p id="4c12" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">在我们将凭证提供给 FormRequest 之后，它将在<em class="mx">start _ URLs</em><strong class="lf ir"><em class="mx">' https://mbasic . Facebook . com '</em></strong><em class="mx">中填写表单(<em class="mx"> user_email and password) </em>，并返回主页。</em></p><h2 id="b110" class="ns mb iq bd mc nt nu dn mg nv nw dp mk lm nx ny mm lq nz oa mo lu ob oc mq od bi translated">让我们给我们的蜘蛛增加一些超能力吧</h2><p id="7572" class="pw-post-body-paragraph ld le iq lf b lg ms jr li lj mt ju ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">完成了结构的定义，是时候给我们的蜘蛛一些超能力了。一个是它应该能够通过网页抓取内容，另一个是抓取内容/数据。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="or os l"/></div></figure><p id="225d" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">请求函数将向回调函数发送响应，在我们的例子中，我们到达消息页面，然后获取我们对话的人及其链接。从那份名单中，我们会刮出一个。</p><figure class="kn ko kp kq gt kr"><div class="bz fp l di"><div class="or os l"/></div></figure><p id="b2ed" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">以上是蜘蛛的核心部分，它获取实体之间的对话，并把它写在一个 csv 文件中。完整的蜘蛛文件可以在<a class="ae lc" href="https://github.com/vj-09/FaceBook-Scrape/blob/master/facebook/facebook/spiders/fb_txt.py" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="03d5" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><em class="mx">为了简单和容易理解，items.py 不用于存储数据。</em></p><h1 id="6b2b" class="ma mb iq bd mc md me mf mg mh mi mj mk jw ml jx mm jz mn ka mo kc mp kd mq mr bi translated">如何使用</h1><p id="3472" class="pw-post-body-paragraph ld le iq lf b lg ms jr li lj mt ju ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">如果您跳过了前一部分，请确保克隆这个存储库<a class="ae lc" href="https://github.com/vj-09/FaceBook-Scrape" rel="noopener ugc nofollow" target="_blank">。浏览项目的顶级目录，并使用以下内容启动 scrapy:</a></p><pre class="kn ko kp kq gt oi oh oj ok aw ol bi"><span id="0855" class="ns mb iq oh b gy om on l oo op">scrapy crawl fb -a email="EMAILTOLOGIN" -a password="PASSWORDTOLOGIN"</span></pre><p id="33f5" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">这将给出最近的 10 个对话，从中选择要废弃的对话，机器人/蜘蛛将抓取对话，直到该对话中的最后一个文本，并返回一个 csv 文件，其中包含列-&gt;名称，文本，日期。看看下面的例子。</p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/b4d5d9ce29614224a5659d5cb99ab532.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*yVrzaILTOSPqbSztiVHKag.png"/></div></figure><p id="7039" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated"><em class="mx">路到此为止。</em></p><p id="b5cd" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">Github <a class="ae lc" href="https://github.com/vj-09/FaceBook-Scrape" rel="noopener ugc nofollow" target="_blank">回购</a></p><h2 id="e549" class="ns mb iq bd mc nt nu dn mg nv nw dp mk lm nx ny mm lq nz oa mo lu ob oc mq od bi translated">在准备中</h2><p id="7320" class="pw-post-body-paragraph ld le iq lf b lg ms jr li lj mt ju ll lm mu lo lp lq mv ls lt lu mw lw lx ly ij bi translated">数据是解决任何 ml/ai 问题的来源，而不是每次我们拥有一个结构良好的数据。这就是网络抓取派上用场的地方，用它我们可以从网站上抓取/获取数据。关于基础网页抓取的教程将会在未来发布，请务必关注和支持。</p><p id="30fe" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">我们到此结束，希望我已经对 word2vec 嵌入做了一些介绍。在这里检查其他作品<a class="ae lc" href="https://medium.com/@athithyavijay" rel="noopener">。</a></p><figure class="kn ko kp kq gt kr gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/3b4017befed4da03dd99f0f668b61b38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*m-QzmucEeah2H-RzD7u_rQ.jpeg"/></div></figure><p id="ae9a" class="pw-post-body-paragraph ld le iq lf b lg lh jr li lj lk ju ll lm ln lo lp lq lr ls lt lu lv lw lx ly ij bi translated">哈哈，如果你这么认为，我们就在同一页上。下面我们来连线<a class="ae lc" href="https://medium.com/@athithyavijay" rel="noopener">中</a>、<a class="ae lc" href="https://www.linkedin.com/in/vijay-athithya-79830ba1/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>、<a class="ae lc" href="https://www.facebook.com/vakky.vj" rel="noopener ugc nofollow" target="_blank">脸书</a>。</p></div></div>    
</body>
</html>