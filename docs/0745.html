<html>
<head>
<title>Weekly Selection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">每周精选</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/object-detection-with-neural-networks-a-simple-tutorial-using-keras-20fbb88a88e7?source=collection_archive---------3-----------------------#2017-06-16">https://towardsdatascience.com/object-detection-with-neural-networks-a-simple-tutorial-using-keras-20fbb88a88e7?source=collection_archive---------3-----------------------#2017-06-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><figure class="gl gn jo jp jq jr gh gi paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="gh gi jn"><img src="../Images/57aa4dcc18e16e559328f1e705745133.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HtrgltuffUuuua6ydX-oCg.jpeg"/></div></div></figure><h1 id="bf8e" class="jy jz iq bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated"><a class="ae kw" href="https://medium.com/towards-data-science/object-detection-with-neural-networks-a4e2c46b4491" rel="noopener">使用神经网络进行物体检测——使用 keras 的简单教程</a></h1><p id="2695" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">由<a class="lv lw ep" href="https://medium.com/u/474ab97e14d2?source=post_page-----20fbb88a88e7--------------------------------" rel="noopener" target="_blank">约翰尼斯·里克</a> — 10 分钟阅读。</p><p id="252d" class="pw-post-body-paragraph kx ky iq kz b la lx lc ld le ly lg lh li lz lk ll lm ma lo lp lq mb ls lt lu ij bi translated">图像分析是深度学习中最突出的领域之一。图像很容易生成和处理，它们正是机器学习的正确数据类型:对人类来说容易理解，但对计算机来说很难。毫不奇怪，图像分析在深度神经网络的历史中发挥了关键作用。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="6dc0" class="jy jz iq bd ka kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv bi translated"><a class="ae kw" href="https://medium.com/towards-data-science/you-cant-make-this-stuff-up-or-can-you-66a6d21ab7f1" rel="noopener">你不能编造这些东西…或者，你能吗？</a></h1><p id="1732" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">到<a class="lv lw ep" href="https://medium.com/u/6292f6223477?source=post_page-----20fbb88a88e7--------------------------------" rel="noopener" target="_blank">埃里克森</a> — 10 分钟读取。</p><p id="6be0" class="pw-post-body-paragraph kx ky iq kz b la lx lc ld le ly lg lh li lz lk ll lm ma lo lp lq mb ls lt lu ij bi translated">2016 年 11 月 7 日，我们见证了篮球史上最伟大的时刻之一。金州勇士队的斯蒂芬·库里打破了一场比赛最多三分球的记录。但是，他做的不止这些。这是一种回归——库里一直在努力，就在一场比赛前，他和他的勇士队输给了湖人队。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="0cc5" class="jy jz iq bd ka kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv bi translated">Word2Vec (skip-gram model): <a class="ae kw" href="https://medium.com/towards-data-science/word2vec-skip-gram-model-part-1-intuition-78614e4d6e0b" rel="noopener">直觉</a> &amp; <a class="ae kw" href="https://medium.com/towards-data-science/word2vec-skip-gram-model-part-2-implementation-in-tf-7efdf6f58a27" rel="noopener">在 TF </a>中实现</h1><p id="d655" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">通过<a class="lv lw ep" href="https://medium.com/u/abdb2f923028?source=post_page-----20fbb88a88e7--------------------------------" rel="noopener" target="_blank">Manish Chablani</a>—7&amp;2 分钟读取。</p><p id="5a68" class="pw-post-body-paragraph kx ky iq kz b la lx lc ld le ly lg lh li lz lk ll lm ma lo lp lq mb ls lt lu ij bi translated">skip-gram 神经网络模型的最基本形式实际上非常简单。训练一个只有一个隐藏层的简单神经网络来执行某项任务，但是我们实际上不会将该神经网络用于我们训练它的任务！相反，目标实际上只是学习隐藏层的权重——我们将看到这些权重实际上是我们试图学习的“单词向量”。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="125a" class="jy jz iq bd ka kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv bi translated"><a class="ae kw" href="https://medium.com/towards-data-science/if-taxi-trips-were-fireflies-1-3-billion-nyc-taxi-trips-plotted-b34e89f96cfa" rel="noopener">如果出租车旅行是萤火虫:13 亿次纽约出租车旅行被绘制</a></h1><p id="7cdf" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">由<a class="lv lw ep" href="https://medium.com/u/fb103ffcb316?source=post_page-----20fbb88a88e7--------------------------------" rel="noopener" target="_blank"> Ravi Shekhar </a> — 9 分钟读取。</p><p id="5356" class="pw-post-body-paragraph kx ky iq kz b la lx lc ld le ly lg lh li lz lk ll lm ma lo lp lq mb ls lt lu ij bi translated">纽约市出租车和豪华轿车委员会(TLC)公开发布了一个从 2009 年 1 月到 2016 年 6 月的出租车出行数据集，其中包含起点和终点的 GPS 坐标。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="aaad" class="jy jz iq bd ka kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv bi translated">我们能复制大脑吗？</h1><p id="a78b" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">由<a class="lv lw ep" href="https://medium.com/u/e53b1a2a902f?source=post_page-----20fbb88a88e7--------------------------------" rel="noopener" target="_blank">Eugenio culrciello</a>—15 分钟阅读。</p><p id="eb41" class="pw-post-body-paragraph kx ky iq kz b la lx lc ld le ly lg lh li lz lk ll lm ma lo lp lq mb ls lt lu ij bi translated">本月的<a class="ae kw" href="http://spectrum.ieee.org/static/special-report-can-we-copy-the-brain" rel="noopener ugc nofollow" target="_blank"> IEEE Spectrum 有一个关于合成大脑的故事</a>。在这篇文章中，我将回顾这个故事，并对探索的现状进行评论:在合成系统中复制人脑。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="9ff9" class="jy jz iq bd ka kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv bi translated"><a class="ae kw" href="https://medium.com/towards-data-science/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f" rel="noopener">神经网络中使用的优化算法类型和优化梯度下降的方法</a></h1><p id="8b27" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">安尼施·辛格·瓦利亚，13 分钟。</p><p id="a7d3" class="pw-post-body-paragraph kx ky iq kz b la lx lc ld le ly lg lh li lz lk ll lm ma lo lp lq mb ls lt lu ij bi translated">您是否曾经想过，通过更新模型参数，如<strong class="kz ir">权重</strong>和<strong class="kz ir">偏差</strong>值，为您的神经网络模型使用哪种优化算法来产生稍好且更快的结果。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="3012" class="jy jz iq bd ka kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv bi translated"><a class="ae kw" href="https://medium.com/towards-data-science/ai-roadmap-bc43d4cce490" rel="noopener">黄砖路线图</a></h1><p id="2f59" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">通过<a class="lv lw ep" href="https://medium.com/u/4aa599f60bc8?source=post_page-----20fbb88a88e7--------------------------------" rel="noopener" target="_blank">彼得·斯威尼</a> — 7 分钟读取。</p><p id="7404" class="pw-post-body-paragraph kx ky iq kz b la lx lc ld le ly lg lh li lz lk ll lm ma lo lp lq mb ls lt lu ij bi translated">每个伟大的项目都需要路线图。对许多人来说，通往人工智能的道路需要对人类智能的深刻理解。如果这看起来很明显，你会惊讶于这个故事是如何展开的，以及你的专业知识在其中可能扮演的关键角色。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="dd60" class="jy jz iq bd ka kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv bi translated"><a class="ae kw" href="https://medium.com/towards-data-science/adversarial-examples-in-deep-learning-be0b08a94953" rel="noopener">深度学习中的对立例子</a></h1><p id="c535" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">由<a class="lv lw ep" href="https://medium.com/u/56d8e184a72a?source=post_page-----20fbb88a88e7--------------------------------" rel="noopener" target="_blank">格雷戈里城堡</a> — 9 分钟阅读。</p><p id="7961" class="pw-post-body-paragraph kx ky iq kz b la lx lc ld le ly lg lh li lz lk ll lm ma lo lp lq mb ls lt lu ij bi translated">这篇文章将包含与我在上次<a class="ae kw" href="https://www.meetup.com/Deep-Learning-Paris-Meetup/" rel="noopener ugc nofollow" target="_blank">深度学习会议</a>上的<a class="ae kw" href="https://github.com/rodgzilla/Deep-learning-presentation/blob/master/adversarial_samples/gchatel_adversarial_samples.pdf" rel="noopener ugc nofollow" target="_blank">演讲</a>基本相同的信息。我觉得随着越来越多的领域开始在关键系统中使用深度学习，让人们意识到神经网络如何被愚弄以产生奇怪和潜在危险的行为是很重要的。</p></div><div class="ab cl mc md hu me" role="separator"><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh mi"/><span class="mf bw bk mg mh"/></div><div class="ij ik il im in"><h1 id="bc41" class="jy jz iq bd ka kb mj kd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv bi translated"><a class="ae kw" href="https://medium.com/towards-data-science/virtue-signals-or-news-reading-an-exploration-on-why-senators-follow-each-others-on-twitter-f9805ab381c2" rel="noopener">美德信号还是新闻阅读？参议员在推特上相互追随的原因探究</a></h1><p id="1c17" class="pw-post-body-paragraph kx ky iq kz b la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu ij bi translated">通过<a class="lv lw ep" href="https://medium.com/u/3c636f3dcd72?source=post_page-----20fbb88a88e7--------------------------------" rel="noopener" target="_blank"> Viet Vu </a> — 7 分钟读取。</p><p id="fb36" class="pw-post-body-paragraph kx ky iq kz b la lx lc ld le ly lg lh li lz lk ll lm ma lo lp lq mb ls lt lu ij bi translated">当你上唐纳德·特朗普的推特时，你首先注意到的一件事是他关注的账户很少。截至 2017 年 6 月 13 日，这一数字为 45。<a class="ae kw" href="https://www.aol.com/article/news/2017/04/12/every-account-president-donald-trump-follows-on-twitter/22037246/" rel="noopener ugc nofollow" target="_blank">新闻</a> <a class="ae kw" href="http://mashable.com/2016/11/22/donald-trump-twitter-follows/" rel="noopener ugc nofollow" target="_blank">文章</a>的<a class="ae kw" href="http://edition.cnn.com/2017/03/06/politics/trump-twitter-list-trnd/index.html" rel="noopener ugc nofollow" target="_blank">号</a>对他关注的账号进行了报道。</p></div></div>    
</body>
</html>