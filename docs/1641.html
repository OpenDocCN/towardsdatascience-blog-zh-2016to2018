<html>
<head>
<title>Language Independent Document Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">独立于语言的文档聚类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/language-independent-document-clustering-3907dafb32fd?source=collection_archive---------6-----------------------#2017-09-29">https://towardsdatascience.com/language-independent-document-clustering-3907dafb32fd?source=collection_archive---------6-----------------------#2017-09-29</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="b7bf" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我探索了一种新颖的独立于语言的文档聚类方法。关键是，它适用于任何语言的任何文本。数据发生变化时，过程保持不变。</p><p id="aad5" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">让我用要点来说明这种方法:</p><ol class=""><li id="656a" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk kq kr ks kt bi translated">从可用数据中构建单词向量。</li><li id="23cc" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">建立文档词向量的词簇。</li><li id="caad" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">找出最能代表文档的聚类。</li><li id="ec01" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">聚集这些集群(相似的集群聚集在一起)。</li><li id="c885" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">具有相似簇的文档放在一起。</li></ol><p id="0310" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，我们将浏览流程和代码。我们将从创建单词向量开始。在那之前</p><blockquote class="kz"><p id="b99f" class="la lb iq bd lc ld le lf lg lh li kk dk translated"><em class="lj">在自然语言处理(NLP)中，90%的工作是预处理——某研究人员</em></p></blockquote><p id="8fdd" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">因此，请确保您对数据做了所有需要做的预处理。因为这是一个概念验证，所以我排除了进行预处理的部分。</p><p id="3807" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我们将使用gensim python包来构建单词向量。下面的函数创建向量，并以二进制格式保存它们。</p><pre class="lp lq lr ls gt lt lu lv lw aw lx bi"><span id="e8b7" class="ly lz iq lu b gy ma mb l mc md"># Create wordvectors<br/>def create_vectors(filename):<br/>    sentences = []<br/>    with bz2.open(filename, 'rt') as df:<br/>        for l in df:<br/>            sentences.append(" ".join(l.split(",")).split())<br/>    model = Word2Vec(sentences, size=25, window=5, min_count=1, workers=4)<br/>    model.save(r"filename.vec") # Line changed refer code on github<br/>    return model</span></pre><p id="4b76" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">一旦单词向量准备好了，我们就可以进入下一步，这是一个非常有趣的步骤。我从博客<a class="ae me" href="https://medium.com/kifi-engineering/from-word2vec-to-doc2vec-an-approach-driven-by-chinese-restaurant-process-93d3602eaa31" rel="noopener">这里</a>偷来的。它非常简单而且有效！</p><p id="c109" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">假设我们有一个包含n个单词的文档。我们将从第一个单词开始，并在模型中查找该单词的向量(单词向量)，该向量进入一个聚类，然后向前移动，我们以概率1/(1+n)将该单词分配给预先创建的聚类或新的聚类。如果我们决定分配给一个现有的聚类，我们就把这个词分配给最相似的聚类。这种方法创建的簇或多或少地将单词分成有意义的组，请看。</p><figure class="lp lq lr ls gt mg gh gi paragraph-image"><div role="button" tabindex="0" class="mh mi di mj bf mk"><div class="gh gi mf"><img src="../Images/4ab5753937ad68dffd76d3e32047c927.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gdLuYD9gV63ZGmwD-cESvQ.png"/></div></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">Language Independent Document Clustering</figcaption></figure><p id="4450" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">更多例子在本笔记本<a class="ae me" href="https://github.com/kaustubhn/doc_clust/blob/master/scripts/doc_clust.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><p id="7770" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">以下函数是上述算法的实现，也称为中餐厅流程。</p><figure class="lp lq lr ls gt mg"><div class="bz fp l di"><div class="mr ms l"/></div><figcaption class="mn mo gj gh gi mp mq bd b be z dk">Python Implementation of CRP</figcaption></figure><p id="26fe" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">我已经把代码放在github上了，还有一个附带的笔记本，你可以看看。<a class="ae me" href="https://github.com/kaustubhn/doc_clust" rel="noopener ugc nofollow" target="_blank">https://github.com/kaustubhn/doc_clust</a></p><h2 id="fa79" class="ly lz iq bd mt mu mv dn mw mx my dp mz jy na nb nc kc nd ne nf kg ng nh ni nj bi translated">丰富</h2><p id="25ec" class="pw-post-body-paragraph jn jo iq jp b jq nk js jt ju nl jw jx jy nm ka kb kc nn ke kf kg no ki kj kk ij bi translated">对上述算法的几点改进建议。</p><ol class=""><li id="da8f" class="kl km iq jp b jq jr ju jv jy kn kc ko kg kp kk kq kr ks kt bi translated">更多数据</li><li id="cfc5" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">更好的预处理</li><li id="6af9" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">多维向量(我们使用25维)</li><li id="c54e" class="kl km iq jp b jq ku ju kv jy kw kc kx kg ky kk kq kr ks kt bi translated">匹配聚类的更好方法(除了余弦方法)</li></ol><p id="ecba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">注意:这是一个非常实验性的方法，到目前为止还有很多不清楚和不明确的地方，我会继续改进和完善这个方法。感谢您的评论。</p></div><div class="ab cl np nq hu nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="ij ik il im in"><p id="ef5c" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">要取得联系，请发微博给我，地址是<a class="ae me" href="https://twitter.com/kaustubhn" rel="noopener ugc nofollow" target="_blank"> kaustubhn </a>。</p></div></div>    
</body>
</html>